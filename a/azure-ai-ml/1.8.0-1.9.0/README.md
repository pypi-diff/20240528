# Comparing `tmp/azure-ai-ml-1.8.0.zip` & `tmp/azure-ai-ml-1.9.0.zip`

## zipinfo {}

```diff
@@ -1,2620 +1,2740 @@
-Zip file size: 6958768 bytes, number of entries: 2618
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure_ai_ml.egg-info/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/samples/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/
--rw-rw-r--  2.0 unx    14372 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/CHANGELOG.md
--rw-rw-r--  2.0 unx     6810 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/README.md
--rw-rw-r--  2.0 unx     3532 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/setup.py
--rw-rw-r--  2.0 unx   881940 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/NOTICE.txt
--rw-rw-r--  2.0 unx     5578 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/documentation_guidelines.md
--rw-rw-r--  2.0 unx      287 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/pyproject.toml
--rw-rw-r--  2.0 unx       38 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/setup.cfg
--rw-rw-r--  2.0 unx    22231 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/PKG-INFO
--rw-rw-r--  2.0 unx      280 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/MANIFEST.in
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/local_endpoint/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/monitoring/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/schedule/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/virtual_cluster/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/dsl/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/datastore/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/internal/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_utilities/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/workspace/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/model/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/batch_services/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/import_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/spark_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/code_asset/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/pipeline_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/dataset/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/compute/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_set/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/sweep_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/online_services/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_store_entity/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/environment/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_store/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/command_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/data_import/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/job_common/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/registry/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/batch_online_common/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/internal_utils/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/automl_job/
--rw-rw-r--  2.0 unx    42105 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/conftest.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/local_endpoint/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/e2etests/__init__.py
--rw-rw-r--  2.0 unx    11051 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/e2etests/test_local_endpoint.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/__init__.py
--rw-rw-r--  2.0 unx     4681 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_mdc_config_resolver.py
--rw-rw-r--  2.0 unx     2608 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_dockerfile_resolver.py
--rw-rw-r--  2.0 unx     9567 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_local_endpoint_validator.py
--rw-rw-r--  2.0 unx     1580 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_dockerfile_instructions.py
--rw-rw-r--  2.0 unx     4036 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_devcontainer_resolver.py
--rw-rw-r--  2.0 unx     2153 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_endpoint_stub.py
--rw-rw-r--  2.0 unx    10985 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_docker_client.py
--rw-rw-r--  2.0 unx     3329 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_devcontainer_properties.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/monitoring/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/monitoring/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/monitoring/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/monitoring/e2etests/__init__.py
--rw-rw-r--  2.0 unx    13168 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/monitoring/e2etests/test_monitor_schedule.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/monitoring/unittests/__init__.py
--rw-rw-r--  2.0 unx     4396 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/monitoring/unittests/test_monitor_schedule.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/schedule/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/schedule/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/schedule/__init__.py
--rw-rw-r--  2.0 unx      317 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/schedule/_util.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/schedule/e2etests/__init__.py
--rw-rw-r--  2.0 unx    12396 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/schedule/e2etests/test_schedule.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/schedule/unittests/__init__.py
--rw-rw-r--  2.0 unx     7827 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/schedule/unittests/test_schedule_schema.py
--rw-rw-r--  2.0 unx     9122 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/schedule/unittests/test_schedule_entity.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/virtual_cluster/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/virtual_cluster/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/virtual_cluster/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/virtual_cluster/e2etests/__init__.py
--rw-rw-r--  2.0 unx     3902 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/virtual_cluster/e2etests/test_vc.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/virtual_cluster/unittests/__init__.py
--rw-rw-r--  2.0 unx     3397 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/virtual_cluster/unittests/test_vc_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/dsl/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/dsl/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/__init__.py
--rw-rw-r--  2.0 unx     2743 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/_util.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/__init__.py
--rw-rw-r--  2.0 unx    19621 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_samples.py
--rw-rw-r--  2.0 unx   157567 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline.py
--rw-rw-r--  2.0 unx     4441 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_on_registry.py
--rw-rw-r--  2.0 unx    12855 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_with_specific_nodes.py
--rw-rw-r--  2.0 unx    34209 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/test_automl_dsl_pipeline.py
--rw-rw-r--  2.0 unx    44729 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/test_controlflow_pipeline.py
--rw-rw-r--  2.0 unx    10442 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_fl.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/__init__.py
--rw-rw-r--  2.0 unx    15955 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_component_func.py
--rw-rw-r--  2.0 unx     8042 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_pipeline_builder.py
--rw-rw-r--  2.0 unx     2911 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_mldesigner_imports.py
--rw-rw-r--  2.0 unx    24561 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_samples.py
--rw-rw-r--  2.0 unx    48038 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_command_builder.py
--rw-rw-r--  2.0 unx    25199 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_group.py
--rw-rw-r--  2.0 unx   165655 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline.py
--rw-rw-r--  2.0 unx     2184 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_component.py
--rw-rw-r--  2.0 unx   126050 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_with_specific_nodes.py
--rw-rw-r--  2.0 unx    20373 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_io_builder.py
--rw-rw-r--  2.0 unx     8357 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_init_finalize_job.py
--rw-rw-r--  2.0 unx    30938 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_controlflow_pipeline.py
--rw-rw-r--  2.0 unx    19998 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_fl.py
--rw-rw-r--  2.0 unx     3746 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dsl/unittests/test_attr_dict.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/datastore/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/datastore/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/datastore/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/datastore/e2etests/__init__.py
--rw-rw-r--  2.0 unx    12879 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/datastore/e2etests/test_datastore.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/datastore/unittests/__init__.py
--rw-rw-r--  2.0 unx    14420 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/datastore/unittests/test_datastore_schema.py
--rw-rw-r--  2.0 unx     3390 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/datastore/unittests/test_datastore_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/internal/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/internal/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/__init__.py
--rw-rw-r--  2.0 unx    13541 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/_utils.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/e2etests/__init__.py
--rw-rw-r--  2.0 unx     5215 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/e2etests/test_component.py
--rw-rw-r--  2.0 unx    17339 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/e2etests/test_pipeline_job.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/unittests/__init__.py
--rw-rw-r--  2.0 unx     1309 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/unittests/test_internal_disabled.py
--rw-rw-r--  2.0 unx    47966 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/unittests/test_component.py
--rw-rw-r--  2.0 unx    31544 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal/unittests/test_pipeline_job.py
--rw-rw-r--  2.0 unx    16895 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_utilities/utils.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_utilities/__init__.py
--rw-rw-r--  2.0 unx      170 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_utilities/constants.py
--rw-rw-r--  2.0 unx     5555 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_utilities/json_schema.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/workspace/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/workspace/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/__init__.py
--rw-rw-r--  2.0 unx     8726 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace_outbound_rule_operations.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/e2etests/__init__.py
--rw-rw-r--  2.0 unx    20544 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace.py
--rw-rw-r--  2.0 unx    17008 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace_connections.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/unittests/__init__.py
--rw-rw-r--  2.0 unx     7946 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_connection_entity.py
--rw-rw-r--  2.0 unx     3399 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_connection_operations.py
--rw-rw-r--  2.0 unx     5822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_operations.py
--rw-rw-r--  2.0 unx    12030 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_operations_base.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/model/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/model/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/model/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/model/e2etests/__init__.py
--rw-rw-r--  2.0 unx    10131 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/model/e2etests/test_model.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/model/unittests/__init__.py
--rw-rw-r--  2.0 unx     2993 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/model/unittests/test_model_schema.py
--rw-rw-r--  2.0 unx    13574 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/model/unittests/test_model_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/batch_services/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/batch_services/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/e2etests/__init__.py
--rw-rw-r--  2.0 unx     8099 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/e2etests/test_batch_deployment.py
--rw-rw-r--  2.0 unx     8009 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/e2etests/test_batch_endpoint.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/unittests/__init__.py
--rw-rw-r--  2.0 unx     5062 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_deployment.py
--rw-rw-r--  2.0 unx     2816 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_deployment_schema.py
--rw-rw-r--  2.0 unx    12821 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_endpoints.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/import_job/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/import_job/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/import_job/__init__.py
--rw-rw-r--  2.0 unx     9567 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/import_job/e2etests/test_import_job.py
--rw-rw-r--  2.0 unx     6504 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/import_job/unittests/test_import_job_schema_builder_entity.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/spark_job/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/spark_job/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/spark_job/__init__.py
--rw-rw-r--  2.0 unx     4757 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/spark_job/e2etests/test_spark_job.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/spark_job/unittests/__init__.py
--rw-rw-r--  2.0 unx     4881 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/spark_job/unittests/test_spark_job_schema.py
--rw-rw-r--  2.0 unx    25089 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/spark_job/unittests/test_spark_job_entity.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/code_asset/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/code_asset/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/code_asset/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/code_asset/e2etests/__init__.py
--rw-rw-r--  2.0 unx     2604 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/code_asset/e2etests/test_code.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/code_asset/unittests/__init__.py
--rw-rw-r--  2.0 unx     3356 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/code_asset/unittests/test_code_operations.py
--rw-rw-r--  2.0 unx     3925 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/code_asset/unittests/test_federated_learning_silo.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/pipeline_job/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/__init__.py
--rw-rw-r--  2.0 unx     2968 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/_util.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/__init__.py
--rw-rw-r--  2.0 unx    16876 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/test_control_flow_pipeline.py
--rw-rw-r--  2.0 unx   100335 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/test_pipeline_job.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/unittests/__init__.py
--rw-rw-r--  2.0 unx     1097 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_private_preview_disabled.py
--rw-rw-r--  2.0 unx   101769 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_entity.py
--rw-rw-r--  2.0 unx    91232 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_schema.py
--rw-rw-r--  2.0 unx     6890 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_controlflow_pipeline_job.py
--rw-rw-r--  2.0 unx    38343 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_validate.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/dataset/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/dataset/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/e2etests/__init__.py
--rw-rw-r--  2.0 unx     2630 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/e2etests/test_data_utils.py
--rw-rw-r--  2.0 unx    13099 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/e2etests/test_data.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/unittests/__init__.py
--rw-rw-r--  2.0 unx     4156 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_schema.py
--rw-rw-r--  2.0 unx    25789 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_operations.py
--rw-rw-r--  2.0 unx     4284 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_utils.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/spark_component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/script_parallel/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/training/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/spark_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/python/
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-4/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-3/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-1/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/byoc/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/endpoint_scoring/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/mnist/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-2/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-4/onlinescoring/
--rw-rw-r--  2.0 unx      983 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-4/onlinescoring/cloud_score.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/hello-component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/hello-component/src/
--rw-rw-r--  2.0 unx       21 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/hello-component/src/hello.py
--rw-rw-r--  2.0 unx     1019 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-3/score.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-1/onlinescoring/
--rw-rw-r--  2.0 unx     1019 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-1/onlinescoring/score.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/byoc/sklearn/
--rw-rw-r--  2.0 unx     1019 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/byoc/sklearn/score.py
--rw-rw-r--  2.0 unx      961 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/endpoint_scoring/main.py
--rw-rw-r--  2.0 unx      103 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/endpoint_scoring/do_nothing.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/mnist/code/
--rw-rw-r--  2.0 unx     1507 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/mnist/code/digit_identification.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-2/onlinescoring/
--rw-rw-r--  2.0 unx     1003 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/deployments/model-2/onlinescoring/score.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/write_jokes/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/component_with_conditional_output/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/do_while_test/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/aggregate/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/training/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/preprocessing/
--rw-rw-r--  2.0 unx     2271 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/aggregate/run.py
--rw-rw-r--  2.0 unx     2882 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/training/run.py
--rw-rw-r--  2.0 unx     2377 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/preprocessing/run.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/write_jokes/src/
--rw-rw-r--  2.0 unx      157 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/write_jokes/src/hello.py
--rw-rw-r--  2.0 unx      518 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/component_with_conditional_output/entry.py
--rw-rw-r--  2.0 unx     4772 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/do_while_test/entry.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library1/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library2/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library1/
--rw-rw-r--  2.0 unx       57 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library2/greetings.py
--rw-rw-r--  2.0 unx       65 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library1/__init__.py
--rw-rw-r--  2.0 unx       53 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library1/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/utils/
--rw-rw-r--  2.0 unx       65 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/__init__.py
--rw-rw-r--  2.0 unx       65 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/utils/__init__.py
--rw-rw-r--  2.0 unx       51 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/utils/salute.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library/world.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library/hello.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library1/world.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library1/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/my_exp/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/
--rw-rw-r--  2.0 unx      528 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/wordcount.py
--rw-rw-r--  2.0 unx      457 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/sampleword.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/
--rw-rw-r--  2.0 unx       28 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/
--rw-rw-r--  2.0 unx     1443 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/basic_component.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/
--rw-rw-r--  2.0 unx     2047 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/register.py
--rw-rw-r--  2.0 unx     3055 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/preprocess.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/
--rw-rw-r--  2.0 unx      210 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/greet.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/
--rw-rw-r--  2.0 unx     2047 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/register.py
--rw-rw-r--  2.0 unx     3055 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/preprocess.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/
--rw-rw-r--  2.0 unx     3552 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/partition_data.py
--rw-rw-r--  2.0 unx     3057 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/parallel_train.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/
--rw-rw-r--  2.0 unx      528 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/wordcount.py
--rw-rw-r--  2.0 unx      457 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/sampleword.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/
--rw-rw-r--  2.0 unx      210 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/greet.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/
--rw-rw-r--  2.0 unx      457 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/sampleword.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/
--rw-rw-r--  2.0 unx      523 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/score.py
--rw-rw-r--  2.0 unx      299 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/my_exp/main.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/spark_component/src/
--rw-rw-r--  2.0 unx     1219 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/spark_component/src/kmeans_example.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/v2_style/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/batch_inference/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/hdi-component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/spark-component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/ipp-component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/v2_style/hd_insight_component/
--rw-rw-r--  2.0 unx     2790 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/v2_style/hd_insight_component/train-spark.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes/
--rw-rw-r--  2.0 unx      465 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/run.py
--rw-rw-r--  2.0 unx      465 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes/run.py
--rw-rw-r--  2.0 unx      612 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/eval.py
--rw-rw-r--  2.0 unx      876 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/train.py
--rw-rw-r--  2.0 unx      850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/score.py
--rw-rw-r--  2.0 unx     1753 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/batch_inference/batch_score.py
--rw-rw-r--  2.0 unx     2790 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/hdi-component/train-spark.py
--rw-rw-r--  2.0 unx      128 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/spark-component/run.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library3/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library2/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library1/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library2/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library1/
--rw-rw-r--  2.0 unx       57 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library2/greetings.py
--rw-rw-r--  2.0 unx       65 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library1/__init__.py
--rw-rw-r--  2.0 unx       53 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library1/hello.py
--rw-rw-r--  2.0 unx      180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library3/__init__.py
--rw-rw-r--  2.0 unx      235 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library3/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/utils/
--rw-rw-r--  2.0 unx       65 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/__init__.py
--rw-rw-r--  2.0 unx       65 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/utils/__init__.py
--rw-rw-r--  2.0 unx       51 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/utils/salute.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library/world.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library/hello.py
--rw-rw-r--  2.0 unx      239 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library2/greetings.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library1/world.py
--rw-rw-r--  2.0 unx       16 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library1/hello.py
--rw-rw-r--  2.0 unx     4540 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/internal/ipp-component/train_wrapper.py
--rw-rw-r--  2.0 unx     1064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/script_parallel/tabular_run_with_model.py
--rw-rw-r--  2.0 unx     1509 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/script_parallel/digit_identification.py
--rw-rw-r--  2.0 unx     1340 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/script_parallel/pass_through.py
--rw-rw-r--  2.0 unx     2295 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/training/train_mlflow.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_hello_world/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/mpi_hello_world/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/primitive_type_components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/
--rw-rw-r--  2.0 unx     2904 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/pipeline.py
--rw-rw-r--  2.0 unx     1340 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/file_batch_inference.py
--rw-rw-r--  2.0 unx     1064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/tabular_batch_inference.py
--rw-rw-r--  2.0 unx     1884 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/get_data.py
--rw-rw-r--  2.0 unx      938 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/convert_data.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/
--rw-rw-r--  2.0 unx     1765 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/pipeline.py
--rw-rw-r--  2.0 unx     1340 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/score.py
--rw-rw-r--  2.0 unx      938 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/convert_data.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/src/
--rw-rw-r--  2.0 unx      531 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/pipeline.py
--rw-rw-r--  2.0 unx       28 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/
--rw-rw-r--  2.0 unx     1027 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/pipeline.py
--rw-rw-r--  2.0 unx       52 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/hello.py
--rw-rw-r--  2.0 unx       52 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/hello.py
--rw-rw-r--  2.0 unx       52 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/basic_component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/
--rw-rw-r--  2.0 unx     1443 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/baisc_component.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/src/
--rw-rw-r--  2.0 unx     1089 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/pipeline.py
--rw-rw-r--  2.0 unx     1291 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/
--rw-rw-r--  2.0 unx     1462 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/pipeline.py
--rw-rw-r--  2.0 unx     1064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/tabular_run_with_model.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/
--rw-rw-r--  2.0 unx     1482 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/pipeline.py
--rw-rw-r--  2.0 unx      979 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/hello.py
--rw-rw-r--  2.0 unx      979 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/hello.py
--rw-rw-r--  2.0 unx      979 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/
--rw-rw-r--  2.0 unx     2334 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/pipeline.py
--rw-rw-r--  2.0 unx     2343 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/predict.py
--rw-rw-r--  2.0 unx     5373 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/transform.py
--rw-rw-r--  2.0 unx     2336 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/train.py
--rw-rw-r--  2.0 unx     2158 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/score.py
--rw-rw-r--  2.0 unx     4006 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/prep.py
--rw-rw-r--  2.0 unx      853 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_hello_world/pipeline.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/
--rw-rw-r--  2.0 unx     3127 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/pipeline.py
--rw-rw-r--  2.0 unx     1758 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train1.py
--rw-rw-r--  2.0 unx     1455 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train.py
--rw-rw-r--  2.0 unx      770 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/eval.py
--rw-rw-r--  2.0 unx      910 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/score.py
--rw-rw-r--  2.0 unx      792 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/mpi_hello_world/pipeline.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/
--rw-rw-r--  2.0 unx      602 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/pipeline.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/
--rw-rw-r--  2.0 unx       28 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/
--rw-rw-r--  2.0 unx     2750 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/pipeline.py
--rw-rw-r--  2.0 unx     1455 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/train.py
--rw-rw-r--  2.0 unx      770 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/eval.py
--rw-rw-r--  2.0 unx      910 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/score.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/
--rw-rw-r--  2.0 unx     2336 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/invalid_pipeline.py
--rw-rw-r--  2.0 unx     3019 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/pipeline.py
--rw-rw-r--  2.0 unx      395 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/count_by_row.py
--rw-rw-r--  2.0 unx      474 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/add_greeting_column.py
--rw-rw-r--  2.0 unx      528 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/wordcount.py
--rw-rw-r--  2.0 unx      776 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword.py
--rw-rw-r--  2.0 unx      497 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword_with_optional_input.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/
--rw-rw-r--  2.0 unx     1391 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/pipeline.py
--rw-rw-r--  2.0 unx     1219 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/kmeans_example.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/
--rw-rw-r--  2.0 unx      549 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/pipeline.py
--rw-rw-r--  2.0 unx       28 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/src/
--rw-rw-r--  2.0 unx      531 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/pipeline.py
--rw-rw-r--  2.0 unx      157 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/
--rw-rw-r--  2.0 unx     1118 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/pipeline.py
--rw-rw-r--  2.0 unx     1016 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/hello.py
--rw-rw-r--  2.0 unx      976 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/__init__.py
--rw-rw-r--  2.0 unx     1346 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_meta.py
--rw-rw-r--  2.0 unx     1744 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_basic.py
--rw-rw-r--  2.0 unx     1431 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_reason_expression.py
--rw-rw-r--  2.0 unx     1358 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_string_concatenate.py
--rw-rw-r--  2.0 unx     1205 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_compute.py
--rw-rw-r--  2.0 unx     1368 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path.py
--rw-rw-r--  2.0 unx     1342 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_cross_type.py
--rw-rw-r--  2.0 unx     1329 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path_concatenate.py
--rw-rw-r--  2.0 unx     1987 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_choice.py
--rw-rw-r--  2.0 unx     1984 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_limits.py
--rw-rw-r--  2.0 unx     1990 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_literal.py
--rw-rw-r--  2.0 unx     1253 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_literal.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/
--rw-rw-r--  2.0 unx     1347 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/pipeline.py
--rw-rw-r--  2.0 unx     1016 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/
--rw-rw-r--  2.0 unx     2006 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/pipeline.py
--rw-rw-r--  2.0 unx     2723 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/pipeline.py
--rw-rw-r--  2.0 unx     1496 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/pipeline.py
--rw-rw-r--  2.0 unx     1232 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/pipeline.py
--rw-rw-r--  2.0 unx     1433 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/pipeline.py
--rw-rw-r--  2.0 unx     4763 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/pipeline.py
--rw-rw-r--  2.0 unx     1321 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/pipeline.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/src/
--rw-rw-r--  2.0 unx      591 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/pipeline.py
--rw-rw-r--  2.0 unx       28 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/
--rw-rw-r--  2.0 unx      830 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/primitive_type_components.py
--rw-rw-r--  2.0 unx      924 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/pipeline.py
--rw-rw-r--  2.0 unx     1077 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/pipeline.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/
--rw-rw-r--  2.0 unx     3622 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/pipeline.py
--rw-rw-r--  2.0 unx     1455 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/train.py
--rw-rw-r--  2.0 unx      770 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/eval.py
--rw-rw-r--  2.0 unx      910 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/score.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/
--rw-rw-r--  2.0 unx     3292 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline.py
--rw-rw-r--  2.0 unx     3462 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline_with_data_as_input.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/
--rw-rw-r--  2.0 unx     1459 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/train.py
--rw-rw-r--  2.0 unx     1320 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/compare2.py
--rw-rw-r--  2.0 unx      770 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/eval.py
--rw-rw-r--  2.0 unx      910 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/score.py
--rw-rw-r--  2.0 unx     1130 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/pipeline.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/
--rw-rw-r--  2.0 unx     1977 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/pipeline.py
--rw-rw-r--  2.0 unx     1455 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/train.py
--rw-rw-r--  2.0 unx      770 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/eval.py
--rw-rw-r--  2.0 unx      910 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/score.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/src/
--rw-rw-r--  2.0 unx     1771 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/pipeline.py
--rw-rw-r--  2.0 unx     1016 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/
--rw-rw-r--  2.0 unx     1297 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/pipeline.py
--rw-rw-r--  2.0 unx     1219 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/hello.py
--rw-rw-r--  2.0 unx     2182 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/pipeline.py
--rw-rw-r--  2.0 unx      755 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/pipeline.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/src/
--rw-rw-r--  2.0 unx     1056 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/pipeline.py
--rw-rw-r--  2.0 unx     1016 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/src/hello.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/
--rw-rw-r--  2.0 unx     8027 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/pipeline.py
--rw-rw-r--  2.0 unx     1459 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/train.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/src/
--rw-rw-r--  2.0 unx      850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/pipeline.py
--rw-rw-r--  2.0 unx     4119 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/src/train.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/
--rw-rw-r--  2.0 unx     1788 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/plot_example.py
--rw-rw-r--  2.0 unx     1261 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/simple_example.py
--rw-rw-r--  2.0 unx     3626 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/logistic_regression.py
--rw-rw-r--  2.0 unx     2445 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/sklearn_example.py
--rw-rw-r--  2.0 unx     7042 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/advanced_example.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/spark_job/basic_spark_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/spark_job/spark_job_word_count/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/spark_job/basic_spark_job/src/
--rw-rw-r--  2.0 unx      454 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/spark_job/basic_spark_job/src/main.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/test_configs/spark_job/spark_job_word_count/src/
--rw-rw-r--  2.0 unx      528 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/spark_job/spark_job_word_count/src/wordcount.py
--rw-rw-r--  2.0 unx     2797 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/python/sweep_script_search.py
--rw-rw-r--  2.0 unx     1036 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/python/train.py
--rw-rw-r--  2.0 unx     1010 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/python/simple_train.py
--rw-rw-r--  2.0 unx      515 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/test_configs/python/sweep_script.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/compute/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/compute/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/compute/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/compute/e2etests/__init__.py
--rw-rw-r--  2.0 unx     5392 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/compute/e2etests/test_compute.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/compute/unittests/__init__.py
--rw-rw-r--  2.0 unx     4865 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/compute/unittests/test_compute_operations.py
--rw-rw-r--  2.0 unx    19268 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/compute/unittests/test_compute_entity.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_set/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_set/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_set/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_set/e2etests/__init__.py
--rw-rw-r--  2.0 unx     5348 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_set/e2etests/test_feature_set.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_set/unittests/__init__.py
--rw-rw-r--  2.0 unx     1474 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_set/unittests/test_list_materialization_job_request.py
--rw-rw-r--  2.0 unx     7636 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_set/unittests/test_feature_set_operations.py
--rw-rw-r--  2.0 unx     1164 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_set/unittests/test_feature_set_schema.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/sweep_job/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/sweep_job/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/sweep_job/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/sweep_job/e2etests/__init__.py
--rw-rw-r--  2.0 unx     8646 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/sweep_job/e2etests/test_sweep_job.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/sweep_job/unittests/__init__.py
--rw-rw-r--  2.0 unx    13957 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/sweep_job/unittests/test_sweep_job.py
--rw-rw-r--  2.0 unx    18261 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/sweep_job/unittests/test_sweep_job_schema.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/online_services/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/online_services/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/e2etests/__init__.py
--rw-rw-r--  2.0 unx     3909 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/e2etests/test_online_deployment.py
--rw-rw-r--  2.0 unx    13667 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/e2etests/test_online_endpoint.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/__init__.py
--rw-rw-r--  2.0 unx    17934 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_online_endpoints.py
--rw-rw-r--  2.0 unx     1185 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_schema.py
--rw-rw-r--  2.0 unx     5638 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_online_deployments.py
--rw-rw-r--  2.0 unx     1439 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_scale_settings.py
--rw-rw-r--  2.0 unx     1054 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_resource_requirements_settings.py
--rw-rw-r--  2.0 unx     1754 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_operations.py
--rw-rw-r--  2.0 unx     2704 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_scale_settings_schema.py
--rw-rw-r--  2.0 unx     2701 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_executor.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_store_entity/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store_entity/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store_entity/e2etests/__init__.py
--rw-rw-r--  2.0 unx     2406 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store_entity/e2etests/test_feature_store_entity.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/__init__.py
--rw-rw-r--  2.0 unx     1212 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/test_feature_store_entity_schema.py
--rw-rw-r--  2.0 unx     4778 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/test_feature_store_entity_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/environment/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/environment/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/e2etests/__init__.py
--rw-rw-r--  2.0 unx    11060 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/e2etests/test_environment.py
--rw-rw-r--  2.0 unx     9896 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_operations.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/unittests/__init__.py
--rw-rw-r--  2.0 unx     8232 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_schema.py
--rw-rw-r--  2.0 unx     2430 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_operations_registry.py
--rw-rw-r--  2.0 unx     7636 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/environment/unittests/test_env_entity.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_store/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/feature_store/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store/e2etests/__init__.py
--rw-rw-r--  2.0 unx     2417 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store/e2etests/test_feature_store.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store/unittests/__init__.py
--rw-rw-r--  2.0 unx     1104 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store/unittests/test_feature_store_schema.py
--rw-rw-r--  2.0 unx     4472 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/feature_store/unittests/test_feature_store_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/component/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/component/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/__init__.py
--rw-rw-r--  2.0 unx       86 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/_util.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/e2etests/__init__.py
--rw-rw-r--  2.0 unx     4371 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/e2etests/test_component_hash.py
--rw-rw-r--  2.0 unx    46931 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/e2etests/test_component.py
--rw-rw-r--  2.0 unx     2501 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/e2etests/test_component_validate.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/__init__.py
--rw-rw-r--  2.0 unx    17778 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_component_schema.py
--rw-rw-r--  2.0 unx     9385 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_component_operations.py
--rw-rw-r--  2.0 unx     7284 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_data_transfer_component_entity.py
--rw-rw-r--  2.0 unx     4864 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_spark_component_entity.py
--rw-rw-r--  2.0 unx    23199 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_pipeline_component_entity.py
--rw-rw-r--  2.0 unx     6571 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_component_operations_registry.py
--rw-rw-r--  2.0 unx    45187 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_command_component_entity.py
--rw-rw-r--  2.0 unx     1811 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_automl_component.py
--rw-rw-r--  2.0 unx     5191 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_operations.py
--rw-rw-r--  2.0 unx     5072 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_entity.py
--rw-rw-r--  2.0 unx     5457 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_schema.py
--rw-rw-r--  2.0 unx     7826 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/component/unittests/test_component_validate.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/command_job/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/command_job/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/command_job/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/command_job/e2etests/__init__.py
--rw-rw-r--  2.0 unx    24391 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/command_job/e2etests/test_command_job.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/command_job/unittests/__init__.py
--rw-rw-r--  2.0 unx     6719 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/command_job/unittests/test_command_job_entity.py
--rw-rw-r--  2.0 unx    14240 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/command_job/unittests/test_command_job_schema.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/data_import/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/data_import/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/data_import/e2etests/__init__.py
--rw-rw-r--  2.0 unx     1570 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/data_import/e2etests/test_data_import.py
--rw-rw-r--  2.0 unx     2239 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/data_import/e2etests/test_schedule.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/data_import/unittests/__init__.py
--rw-rw-r--  2.0 unx     2388 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/data_import/unittests/test_data_import.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/job_common/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/job_common/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/job_common/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/job_common/e2etests/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/job_common/unittests/__init__.py
--rw-rw-r--  2.0 unx     2292 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/job_common/unittests/test_local_job_invoker.py
--rw-rw-r--  2.0 unx    13507 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/job_common/unittests/test_job_operations.py
--rw-rw-r--  2.0 unx    22931 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/job_common/unittests/test_job_ops_helper.py
--rw-rw-r--  2.0 unx      931 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/job_common/unittests/test_vcr_utils.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/registry/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/registry/unittests/
--rw-rw-r--  2.0 unx     4860 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/registry/e2etests/test_registry.py
--rw-rw-r--  2.0 unx     2983 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_operations.py
--rw-rw-r--  2.0 unx    14607 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_entity.py
--rw-rw-r--  2.0 unx     6093 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_schema.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/batch_online_common/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/batch_online_common/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_online_common/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_online_common/e2etests/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_online_common/unittests/__init__.py
--rw-rw-r--  2.0 unx     4367 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_endpoint_entity.py
--rw-rw-r--  2.0 unx    13469 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_deployment_entity.py
--rw-rw-r--  2.0 unx      575 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_code_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/internal_utils/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/internal_utils/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/__init__.py
--rw-rw-r--  2.0 unx       76 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/_util.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/e2etests/__init__.py
--rw-rw-r--  2.0 unx    19826 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/e2etests/test_upload_download.py
--rw-rw-r--  2.0 unx      955 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/e2etests/test_telemetry_value.py
--rw-rw-r--  2.0 unx     2405 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_logger_utils.py
--rw-rw-r--  2.0 unx     9762 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_persistent_locals.py
--rw-rw-r--  2.0 unx    11626 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_storage_utils.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/__init__.py
--rw-rw-r--  2.0 unx     6668 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_fields.py
--rw-rw-r--  2.0 unx     1397 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_file_utils.py
--rw-rw-r--  2.0 unx     6985 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_cloud_environments.py
--rw-rw-r--  2.0 unx     1480 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_smoke.py
--rw-rw-r--  2.0 unx      615 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_arm_id_utils.py
--rw-rw-r--  2.0 unx     7061 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_experimental_utils.py
--rw-rw-r--  2.0 unx     9721 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_asset_utils.py
--rw-rw-r--  2.0 unx    25206 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_ml_client.py
--rw-rw-r--  2.0 unx     2357 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_get_content_hash.py
--rw-rw-r--  2.0 unx      451 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_artifact_entity.py
--rw-rw-r--  2.0 unx     3451 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_exceptions.py
--rw-rw-r--  2.0 unx     3469 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_validation.py
--rw-rw-r--  2.0 unx     5564 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_utils.py
--rw-rw-r--  2.0 unx    22611 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_operation_orchestrator.py
--rw-rw-r--  2.0 unx      575 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_asset_entity.py
--rw-rw-r--  2.0 unx     6301 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_telemetry_value.py
--rw-rw-r--  2.0 unx     3473 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_cache_utils.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/automl_job/e2etests/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/tests/automl_job/unittests/
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/__init__.py
--rw-rw-r--  2.0 unx     7142 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/jsonl_converter.py
--rw-rw-r--  2.0 unx     6858 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/conftest.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/__init__.py
--rw-rw-r--  2.0 unx     8403 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_object_detection.py
--rw-rw-r--  2.0 unx     1702 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_classification.py
--rw-rw-r--  2.0 unx     7300 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_classification_multilabel.py
--rw-rw-r--  2.0 unx     6325 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_classification.py
--rw-rw-r--  2.0 unx     1727 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_classification_multilabel.py
--rw-rw-r--  2.0 unx     5792 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_segmentation.py
--rw-rw-r--  2.0 unx     1487 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_ner.py
--rw-rw-r--  2.0 unx     5357 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_classification.py
--rw-rw-r--  2.0 unx     5076 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_regression.py
--rw-rw-r--  2.0 unx     3479 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_forecasting.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/__init__.py
--rw-rw-r--  2.0 unx     9604 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_regression_job.py
--rw-rw-r--  2.0 unx    11112 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_forecasting_job.py
--rw-rw-r--  2.0 unx    11620 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_classification_job.py
--rw-rw-r--  2.0 unx    11285 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_object_detection.py
--rw-rw-r--  2.0 unx    23455 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_tabular_schema.py
--rw-rw-r--  2.0 unx     3528 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_limit_settings.py
--rw-rw-r--  2.0 unx    33199 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_schema.py
--rw-rw-r--  2.0 unx     5993 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_n_cross_validation_settings.py
--rw-rw-r--  2.0 unx     9995 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_classification_multilabel.py
--rw-rw-r--  2.0 unx     3375 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_featurization_settings.py
--rw-rw-r--  2.0 unx     5714 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_nlp_sweep_settings.py
--rw-rw-r--  2.0 unx     9187 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_classification.py
--rw-rw-r--  2.0 unx    15114 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_ner_job.py
--rw-rw-r--  2.0 unx     6198 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_sweep_setting.py
--rw-rw-r--  2.0 unx    11175 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_instance_segmentation.py
--rw-rw-r--  2.0 unx    14380 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_nlp_schema.py
--rw-rw-r--  2.0 unx    16641 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_classification_multilabel_job.py
--rw-rw-r--  2.0 unx     3040 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_setsearchspace.py
--rw-rw-r--  2.0 unx     7668 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_forecasting_settings.py
--rw-rw-r--  2.0 unx    16341 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_classification_job.py
--rw-rw-r--  2.0 unx        6 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure_ai_ml.egg-info/top_level.txt
--rw-rw-r--  2.0 unx      419 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure_ai_ml.egg-info/requires.txt
--rw-rw-r--  2.0 unx        1 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure_ai_ml.egg-info/dependency_links.txt
--rw-rw-r--  2.0 unx        1 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure_ai_ml.egg-info/not-zip-safe
--rw-rw-r--  2.0 unx    22231 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure_ai_ml.egg-info/PKG-INFO
--rw-rw-r--  2.0 unx   137866 b- defN 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure_ai_ml.egg-info/SOURCES.txt
--rw-rw-r--  2.0 unx     1714 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/samples/README.md
--rw-rw-r--  2.0 unx    12322 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/samples/ml_samples_sweep_configurations.py
--rw-rw-r--  2.0 unx     2951 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/samples/ml_samples_authentication_sovereign_cloud.py
--rw-rw-r--  2.0 unx     3738 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/samples/ml_samples_cloud_configurations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/
--rw-rw-r--  2.0 unx      647 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/dsl/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/constants/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/automl/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/parallel/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_logging/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/identity/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_internal/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/data_transfer/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/sweep/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_file_utils/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/operations/
--rw-rw-r--  2.0 unx     2004 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/__init__.py
--rw-rw-r--  2.0 unx    12376 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_exception_helper.py
--rw-rw-r--  2.0 unx     4850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_scope_dependent_operations.py
--rw-rw-r--  2.0 unx    42758 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_ml_client.py
--rw-rw-r--  2.0 unx      274 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_user_agent.py
--rw-rw-r--  2.0 unx       27 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/py.typed
--rw-rw-r--  2.0 unx    12504 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_azure_environments.py
--rw-rw-r--  2.0 unx      199 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_version.py
--rw-rw-r--  2.0 unx    29494 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/exceptions.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/
--rw-rw-r--  2.0 unx      360 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/__init__.py
--rw-rw-r--  2.0 unx     2955 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_helper.py
--rw-rw-r--  2.0 unx    12362 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_deployment_executor.py
--rw-rw-r--  2.0 unx    40296 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_base.json
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/__init__.py
--rw-rw-r--  2.0 unx      489 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/code_version.json
--rw-rw-r--  2.0 unx      721 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/online_deployment.json
--rw-rw-r--  2.0 unx     3110 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_param.json
--rw-rw-r--  2.0 unx      596 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/online_endpoint.json
--rw-rw-r--  2.0 unx      197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/base_template.json
--rw-rw-r--  2.0 unx      403 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/model.json
--rw-rw-r--  2.0 unx      495 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/model_version.json
--rw-rw-r--  2.0 unx     1137 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/update_online_endpoint.json
--rw-rw-r--  2.0 unx      531 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/environment_version.json
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/
--rw-rw-r--  2.0 unx     2659 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_package_utils.py
--rw-rw-r--  2.0 unx    37209 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/utils.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/__init__.py
--rw-rw-r--  2.0 unx    19161 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_cache_utils.py
--rw-rw-r--  2.0 unx     1625 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_azureml_polling.py
--rw-rw-r--  2.0 unx     1064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_preflight_utils.py
--rw-rw-r--  2.0 unx     5569 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_html_utils.py
--rw-rw-r--  2.0 unx     6603 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_http_utils.py
--rw-rw-r--  2.0 unx     3778 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_experimental.py
--rw-rw-r--  2.0 unx     7004 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_registry_utils.py
--rw-rw-r--  2.0 unx    22470 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_pathspec.py
--rw-rw-r--  2.0 unx     3170 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/azure_resource_utils.py
--rw-rw-r--  2.0 unx     3322 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_data_utils.py
--rw-rw-r--  2.0 unx     1105 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_logger_utils.py
--rw-rw-r--  2.0 unx     7567 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_storage_utils.py
--rw-rw-r--  2.0 unx      560 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_appinsights_utils.py
--rw-rw-r--  2.0 unx    17142 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_arm_id_utils.py
--rw-rw-r--  2.0 unx    16585 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_func_utils.py
--rw-rw-r--  2.0 unx     4184 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_feature_store_utils.py
--rw-rw-r--  2.0 unx    40729 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_asset_utils.py
--rw-rw-r--  2.0 unx     8937 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_endpoint_utils.py
--rw-rw-r--  2.0 unx     2487 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_workspace_utils.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/
--rw-rw-r--  2.0 unx     2002 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/
--rw-rw-r--  2.0 unx      731 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/__init__.py
--rw-rw-r--  2.0 unx      676 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_vendor.py
--rw-rw-r--  2.0 unx     1531 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_patch.py
--rw-rw-r--  2.0 unx     3474 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_index_service_apis.py
--rw-rw-r--  2.0 unx      384 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_version.py
--rw-rw-r--  2.0 unx     2918 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/
--rw-rw-r--  2.0 unx      679 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/__init__.py
--rw-rw-r--  2.0 unx     1531 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_patch.py
--rw-rw-r--  2.0 unx     3361 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_index_service_apis.py
--rw-rw-r--  2.0 unx     2831 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_configuration.py
--rw-rw-r--  2.0 unx      476 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/__init__.py
--rw-rw-r--  2.0 unx     5419 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/_index_entities_operations.py
--rw-rw-r--  2.0 unx    24536 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/__init__.py
--rw-rw-r--  2.0 unx   387848 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models.py
--rw-rw-r--  2.0 unx    10008 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_index_service_apis_enums.py
--rw-rw-r--  2.0 unx   419787 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models_py3.py
--rw-rw-r--  2.0 unx      476 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/__init__.py
--rw-rw-r--  2.0 unx     5804 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/_index_entities_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/
--rw-rw-r--  2.0 unx     1821 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_parallel_for.py
--rw-rw-r--  2.0 unx     4644 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_settings.py
--rw-rw-r--  2.0 unx      344 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/__init__.py
--rw-rw-r--  2.0 unx    14069 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_pipeline_decorator.py
--rw-rw-r--  2.0 unx     2702 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_condition.py
--rw-rw-r--  2.0 unx     1782 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_load_import.py
--rw-rw-r--  2.0 unx      272 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_constants.py
--rw-rw-r--  2.0 unx     7334 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_fl_scatter_gather_node.py
--rw-rw-r--  2.0 unx    24695 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_pipeline_component_builder.py
--rw-rw-r--  2.0 unx     6625 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_utils.py
--rw-rw-r--  2.0 unx     8977 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_group_decorator.py
--rw-rw-r--  2.0 unx     2883 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_component_func.py
--rw-rw-r--  2.0 unx     6578 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_dynamic.py
--rw-rw-r--  2.0 unx      685 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_overrides_definition.py
--rw-rw-r--  2.0 unx     4087 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_do_while.py
--rw-rw-r--  2.0 unx     1851 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/__init__.py
--rw-rw-r--  2.0 unx      991 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/_constants.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/
--rw-rw-r--  2.0 unx     1389 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_registry.py
--rw-rw-r--  2.0 unx     5595 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_compute.py
--rw-rw-r--  2.0 unx     1747 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/__init__.py
--rw-rw-r--  2.0 unx     4185 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_component.py
--rw-rw-r--  2.0 unx     2996 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_monitoring.py
--rw-rw-r--  2.0 unx     2952 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_endpoint.py
--rw-rw-r--  2.0 unx    34156 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_common.py
--rw-rw-r--  2.0 unx      429 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_assets.py
--rw-rw-r--  2.0 unx     1168 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_workspace.py
--rw-rw-r--  2.0 unx      814 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_deployment.py
--rw-rw-r--  2.0 unx      690 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/sweep.py
--rw-rw-r--  2.0 unx     1019 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/__init__.py
--rw-rw-r--  2.0 unx     1639 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/pipeline.py
--rw-rw-r--  2.0 unx     4161 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/automl.py
--rw-rw-r--  2.0 unx     4590 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/job.py
--rw-rw-r--  2.0 unx     4166 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/automl/__init__.py
--rw-rw-r--  2.0 unx    11378 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_image.py
--rw-rw-r--  2.0 unx     5886 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_nlp.py
--rw-rw-r--  2.0 unx    24885 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_tabular.py
--rw-rw-r--  2.0 unx      471 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/parallel/__init__.py
--rw-rw-r--  2.0 unx      343 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_logging/__init__.py
--rw-rw-r--  2.0 unx     2362 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_logging/chained_identity.py
--rw-rw-r--  2.0 unx     5950 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_logging/debug_mode.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/
--rw-rw-r--  2.0 unx      634 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/__init__.py
--rw-rw-r--  2.0 unx    22670 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/docker_client.py
--rw-rw-r--  2.0 unx     2334 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/dockerfile_instructions.py
--rw-rw-r--  2.0 unx      377 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/local_endpoint_mode.py
--rw-rw-r--  2.0 unx     4203 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/endpoint_stub.py
--rw-rw-r--  2.0 unx     5129 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/azureml_image_context.py
--rw-rw-r--  2.0 unx     2943 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/mdc_config_resolver.py
--rw-rw-r--  2.0 unx     5604 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/dockerfile_resolver.py
--rw-rw-r--  2.0 unx      534 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/__init__.py
--rw-rw-r--  2.0 unx     6720 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/environment_validator.py
--rw-rw-r--  2.0 unx     3183 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/model_validator.py
--rw-rw-r--  2.0 unx     4317 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/code_validator.py
--rw-rw-r--  2.0 unx      180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/__init__.py
--rw-rw-r--  2.0 unx      763 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/wsl_utility.py
--rw-rw-r--  2.0 unx     3670 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/commandline_utility.py
--rw-rw-r--  2.0 unx      180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/__init__.py
--rw-rw-r--  2.0 unx     2130 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/vscode_client.py
--rw-rw-r--  2.0 unx     6812 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_resolver.py
--rw-rw-r--  2.0 unx     4391 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_properties.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/
--rw-rw-r--  2.0 unx      408 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_exceptions.py
--rw-rw-r--  2.0 unx      443 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/__init__.py
--rw-rw-r--  2.0 unx      250 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_constants.py
--rw-rw-r--  2.0 unx      290 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/__init__.py
--rw-rw-r--  2.0 unx     4013 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/_AzureMLSparkOnBehalfOfCredential.py
--rw-rw-r--  2.0 unx     3073 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/aml_on_behalf_of.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_credentials/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/
--rw-rw-r--  2.0 unx      180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/__init__.py
--rw-rw-r--  2.0 unx      180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_credentials/__init__.py
--rw-rw-r--  2.0 unx     2861 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_credentials/aml_on_behalf_of.py
--rw-rw-r--  2.0 unx      448 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/__init__.py
--rw-rw-r--  2.0 unx     2094 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/managed_identity_base.py
--rw-rw-r--  2.0 unx     1637 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/managed_identity_client.py
--rw-rw-r--  2.0 unx     3656 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/get_token_mixin.py
--rw-rw-r--  2.0 unx     1176 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/__init__.py
--rw-rw-r--  2.0 unx     2089 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/managed_identity_base.py
--rw-rw-r--  2.0 unx     2585 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/pipeline.py
--rw-rw-r--  2.0 unx     5330 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/managed_identity_client.py
--rw-rw-r--  2.0 unx     3817 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/get_token_mixin.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_utils/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_internal/dsl/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/
--rw-rw-r--  2.0 unx     1311 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/__init__.py
--rw-rw-r--  2.0 unx     3480 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_setup.py
--rw-rw-r--  2.0 unx      289 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_utils/__init__.py
--rw-rw-r--  2.0 unx     2507 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_utils/_yaml_utils.py
--rw-rw-r--  2.0 unx      269 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/dsl/__init__.py
--rw-rw-r--  2.0 unx     1879 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/command.py
--rw-rw-r--  2.0 unx      180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/__init__.py
--rw-rw-r--  2.0 unx      713 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/environment.py
--rw-rw-r--  2.0 unx     2614 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/input_output.py
--rw-rw-r--  2.0 unx     8396 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/component.py
--rw-rw-r--  2.0 unx     2646 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/node.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/
--rw-rw-r--  2.0 unx     3469 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/parallel.py
--rw-rw-r--  2.0 unx     6419 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/command.py
--rw-rw-r--  2.0 unx     1853 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_additional_includes.py
--rw-rw-r--  2.0 unx     1307 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/__init__.py
--rw-rw-r--  2.0 unx     1570 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/code.py
--rw-rw-r--  2.0 unx     6735 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/spark.py
--rw-rw-r--  2.0 unx     3295 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/scope.py
--rw-rw-r--  2.0 unx     6717 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_merkle_tree.py
--rw-rw-r--  2.0 unx     6486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/environment.py
--rw-rw-r--  2.0 unx    12220 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/component.py
--rw-rw-r--  2.0 unx     5668 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_input_outputs.py
--rw-rw-r--  2.0 unx     9983 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/node.py
--rw-rw-r--  2.0 unx      868 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/__init__.py
--rw-rw-r--  2.0 unx     5411 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/itp_configuration.py
--rw-rw-r--  2.0 unx     9154 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/ai_super_computer_configuration.py
--rw-rw-r--  2.0 unx     2052 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/target_selector.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_notification/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/
--rw-rw-r--  2.0 unx     2750 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/identity.py
--rw-rw-r--  2.0 unx     1736 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/__init__.py
--rw-rw-r--  2.0 unx      873 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/queue_settings.py
--rw-rw-r--  2.0 unx      756 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/resource_configuration.py
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/spark_resource_configuration.py
--rw-rw-r--  2.0 unx     1227 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job_resource_configuration.py
--rw-rw-r--  2.0 unx      340 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_notification/__init__.py
--rw-rw-r--  2.0 unx      815 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_notification/notification_schema.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/__init__.py
--rw-rw-r--  2.0 unx     7858 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/signals.py
--rw-rw-r--  2.0 unx     4005 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/thresholds.py
--rw-rw-r--  2.0 unx      493 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/schedule.py
--rw-rw-r--  2.0 unx     1110 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/input_data.py
--rw-rw-r--  2.0 unx     1907 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/monitor_definition.py
--rw-rw-r--  2.0 unx      800 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/target.py
--rw-rw-r--  2.0 unx      616 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/alert_notification.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/__init__.py
--rw-rw-r--  2.0 unx     3042 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/trigger.py
--rw-rw-r--  2.0 unx     5827 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/create_job.py
--rw-rw-r--  2.0 unx     1668 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/schedule.py
--rw-rw-r--  2.0 unx     2522 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/utils.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/__init__.py
--rw-rw-r--  2.0 unx     3605 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/data_binding_expression.py
--rw-rw-r--  2.0 unx      433 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/__init__.py
--rw-rw-r--  2.0 unx      918 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/feature_store_entity_schema.py
--rw-rw-r--  2.0 unx      717 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/data_column_schema.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/
--rw-rw-r--  2.0 unx     2477 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/forecasting_settings.py
--rw-rw-r--  2.0 unx     1259 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/__init__.py
--rw-rw-r--  2.0 unx     1035 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/automl_job.py
--rw-rw-r--  2.0 unx     2572 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/featurization_settings.py
--rw-rw-r--  2.0 unx      839 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/automl_vertical.py
--rw-rw-r--  2.0 unx     4633 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/training_settings.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/__init__.py
--rw-rw-r--  2.0 unx     1404 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification.py
--rw-rw-r--  2.0 unx     1223 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_fixed_parameters.py
--rw-rw-r--  2.0 unx      768 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical_limit_settings.py
--rw-rw-r--  2.0 unx     4156 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_parameter_subspace.py
--rw-rw-r--  2.0 unx     1295 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_ner.py
--rw-rw-r--  2.0 unx     1445 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification_multilabel.py
--rw-rw-r--  2.0 unx     1485 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical.py
--rw-rw-r--  2.0 unx      950 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_sweep_settings.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/__init__.py
--rw-rw-r--  2.0 unx     1558 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/classification.py
--rw-rw-r--  2.0 unx     1714 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/forecasting.py
--rw-rw-r--  2.0 unx     1075 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical_limit_settings.py
--rw-rw-r--  2.0 unx     1510 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/regression.py
--rw-rw-r--  2.0 unx     1609 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/__init__.py
--rw-rw-r--  2.0 unx     1055 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_vertical.py
--rw-rw-r--  2.0 unx     2552 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_classification.py
--rw-rw-r--  2.0 unx      956 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_sweep_settings.py
--rw-rw-r--  2.0 unx      665 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_limit_settings.py
--rw-rw-r--  2.0 unx     3458 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_model_settings.py
--rw-rw-r--  2.0 unx     9629 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_model_distribution_settings.py
--rw-rw-r--  2.0 unx     2752 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_object_detection.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/__init__.py
--rw-rw-r--  2.0 unx      693 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/code_configuration_schema.py
--rw-rw-r--  2.0 unx     1963 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/deployment.py
--rw-rw-r--  2.0 unx     1491 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/compute_binding.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/__init__.py
--rw-rw-r--  2.0 unx      911 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment_settings.py
--rw-rw-r--  2.0 unx     2449 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment_settings.py
--rw-rw-r--  2.0 unx     6806 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_job.py
--rw-rw-r--  2.0 unx     1654 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_pipeline_component_deployment_configurations_schema.py
--rw-rw-r--  2.0 unx      839 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/run_settings_schema.py
--rw-rw-r--  2.0 unx     1620 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/job_definition_schema.py
--rw-rw-r--  2.0 unx     4438 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment.py
--rw-rw-r--  2.0 unx     1604 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/pipeline_component_batch_deployment_schema.py
--rw-rw-r--  2.0 unx     1990 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment.py
--rw-rw-r--  2.0 unx     1664 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/scale_settings_schema.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/__init__.py
--rw-rw-r--  2.0 unx      707 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/request_logging_schema.py
--rw-rw-r--  2.0 unx      797 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/liveness_probe.py
--rw-rw-r--  2.0 unx     1109 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/deployment_collection_schema.py
--rw-rw-r--  2.0 unx     1122 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/oversize_data_config_schema.py
--rw-rw-r--  2.0 unx     1078 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/event_hub_schema.py
--rw-rw-r--  2.0 unx     1642 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/data_collector_schema.py
--rw-rw-r--  2.0 unx      959 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/resource_settings_schema.py
--rw-rw-r--  2.0 unx      825 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/payload_response_schema.py
--rw-rw-r--  2.0 unx      757 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/data_asset_schema.py
--rw-rw-r--  2.0 unx      828 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/request_settings_schema.py
--rw-rw-r--  2.0 unx      911 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/resource_requirements_schema.py
--rw-rw-r--  2.0 unx     3130 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/online_deployment.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/__init__.py
--rw-rw-r--  2.0 unx     1293 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/intellectual_property.py
--rw-rw-r--  2.0 unx    36403 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/fields.py
--rw-rw-r--  2.0 unx     1271 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/auto_delete_setting.py
--rw-rw-r--  2.0 unx     1577 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/schema_meta.py
--rw-rw-r--  2.0 unx     5201 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/schema.py
--rw-rw-r--  2.0 unx     1887 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/resource.py
--rw-rw-r--  2.0 unx      909 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/__init__.py
--rw-rw-r--  2.0 unx     2020 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/_on_prem_credentials.py
--rw-rw-r--  2.0 unx     1432 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/_on_prem.py
--rw-rw-r--  2.0 unx     1461 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/adls_gen1.py
--rw-rw-r--  2.0 unx     3027 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/credentials.py
--rw-rw-r--  2.0 unx     2902 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/azure_storage.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/online/
--rw-rw-r--  2.0 unx      513 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/__init__.py
--rw-rw-r--  2.0 unx     1780 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/endpoint.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/__init__.py
--rw-rw-r--  2.0 unx      945 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint.py
--rw-rw-r--  2.0 unx      943 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint_defaults.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/online/__init__.py
--rw-rw-r--  2.0 unx     2444 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/online/online_endpoint.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/
--rw-rw-r--  2.0 unx     3195 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/identity.py
--rw-rw-r--  2.0 unx     5521 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/networking.py
--rw-rw-r--  2.0 unx      333 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/__init__.py
--rw-rw-r--  2.0 unx     1996 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/workspace.py
--rw-rw-r--  2.0 unx      785 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/private_endpoint.py
--rw-rw-r--  2.0 unx      709 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/endpoint_connection.py
--rw-rw-r--  2.0 unx      697 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/customer_managed_key.py
--rw-rw-r--  2.0 unx      364 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/__init__.py
--rw-rw-r--  2.0 unx     2453 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/workspace_connection.py
--rw-rw-r--  2.0 unx     3607 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/credentials.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/
--rw-rw-r--  2.0 unx      315 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/__init__.py
--rw-rw-r--  2.0 unx     3137 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_termination.py
--rw-rw-r--  2.0 unx      236 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/_constants.py
--rw-rw-r--  2.0 unx      952 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_job.py
--rw-rw-r--  2.0 unx     2430 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_fields_provider.py
--rw-rw-r--  2.0 unx     1010 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_objective.py
--rw-rw-r--  2.0 unx     3200 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_sampling_algorithm.py
--rw-rw-r--  2.0 unx     1157 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/parameterized_sweep.py
--rw-rw-r--  2.0 unx     2244 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/choice.py
--rw-rw-r--  2.0 unx     1041 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/randint.py
--rw-rw-r--  2.0 unx      656 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/__init__.py
--rw-rw-r--  2.0 unx     2496 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/normal.py
--rw-rw-r--  2.0 unx     2796 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/uniform.py
--rw-rw-r--  2.0 unx      563 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/__init__.py
--rw-rw-r--  2.0 unx     2968 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_job.py
--rw-rw-r--  2.0 unx     1535 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/settings.py
--rw-rw-r--  2.0 unx      907 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_spark_job.py
--rw-rw-r--  2.0 unx     6588 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/automl_node.py
--rw-rw-r--  2.0 unx      718 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_import_job.py
--rw-rw-r--  2.0 unx     5063 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/control_flow_job.py
--rw-rw-r--  2.0 unx     1401 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_command_job.py
--rw-rw-r--  2.0 unx     1859 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_datatransfer_job.py
--rw-rw-r--  2.0 unx     1904 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_job_io.py
--rw-rw-r--  2.0 unx     2281 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/condition_node.py
--rw-rw-r--  2.0 unx    20368 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/component_job.py
--rw-rw-r--  2.0 unx     1434 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_parallel_job.py
--rw-rw-r--  2.0 unx    12904 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_component.py
--rw-rw-r--  2.0 unx     1914 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/import_job.py
--rw-rw-r--  2.0 unx     1940 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/identity.py
--rw-rw-r--  2.0 unx      983 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/__init__.py
--rw-rw-r--  2.0 unx     3001 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/services.py
--rw-rw-r--  2.0 unx     2597 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/base_job.py
--rw-rw-r--  2.0 unx      673 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parallel_job.py
--rw-rw-r--  2.0 unx     2028 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_output_fields_provider.py
--rw-rw-r--  2.0 unx      776 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_port.py
--rw-rw-r--  2.0 unx     5892 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_spark.py
--rw-rw-r--  2.0 unx     1850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_command.py
--rw-rw-r--  2.0 unx      597 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/job_output.py
--rw-rw-r--  2.0 unx     1229 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/spark_job.py
--rw-rw-r--  2.0 unx     7131 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_output_entry.py
--rw-rw-r--  2.0 unx     3150 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_parallel.py
--rw-rw-r--  2.0 unx      553 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/creation_context.py
--rw-rw-r--  2.0 unx      927 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/command_job.py
--rw-rw-r--  2.0 unx     2871 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/data_transfer_job.py
--rw-rw-r--  2.0 unx     3430 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/distribution.py
--rw-rw-r--  2.0 unx     1500 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/job_limits.py
--rw-rw-r--  2.0 unx     3169 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/compute.py
--rw-rw-r--  2.0 unx      534 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/aml_compute_node_info.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/__init__.py
--rw-rw-r--  2.0 unx     1297 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/usage.py
--rw-rw-r--  2.0 unx      657 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/kubernetes_compute.py
--rw-rw-r--  2.0 unx     1920 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/aml_compute.py
--rw-rw-r--  2.0 unx     1701 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/synapsespark_compute.py
--rw-rw-r--  2.0 unx     1981 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/custom_applications.py
--rw-rw-r--  2.0 unx     3638 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/schedule.py
--rw-rw-r--  2.0 unx      401 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/attached_compute.py
--rw-rw-r--  2.0 unx     1087 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/setup_scripts.py
--rw-rw-r--  2.0 unx      653 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/vm_size.py
--rw-rw-r--  2.0 unx     2979 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/compute_instance.py
--rw-rw-r--  2.0 unx     1202 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/virtual_machine_compute.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/
--rw-rw-r--  2.0 unx     2492 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/model.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/__init__.py
--rw-rw-r--  2.0 unx     1028 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/data.py
--rw-rw-r--  2.0 unx      719 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/artifact.py
--rw-rw-r--  2.0 unx      849 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/workspace_asset_reference.py
--rw-rw-r--  2.0 unx     1023 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/federated_learning_silo.py
--rw-rw-r--  2.0 unx     1601 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/code_asset.py
--rw-rw-r--  2.0 unx     5956 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/environment.py
--rw-rw-r--  2.0 unx     1513 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/asset.py
--rw-rw-r--  2.0 unx      824 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_configuration.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/__init__.py
--rw-rw-r--  2.0 unx      685 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/route.py
--rw-rw-r--  2.0 unx      649 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/base_environment_source.py
--rw-rw-r--  2.0 unx     2405 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_package_input.py
--rw-rw-r--  2.0 unx     1435 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_package.py
--rw-rw-r--  2.0 unx     1985 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/inference_server.py
--rw-rw-r--  2.0 unx      990 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/online_inference_configuration.py
--rw-rw-r--  2.0 unx     1208 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/parallel_task.py
--rw-rw-r--  2.0 unx     2039 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/__init__.py
--rw-rw-r--  2.0 unx     4785 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/parallel_component.py
--rw-rw-r--  2.0 unx     2716 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/spark_component.py
--rw-rw-r--  2.0 unx    10227 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/data_transfer_component.py
--rw-rw-r--  2.0 unx     3095 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/import_component.py
--rw-rw-r--  2.0 unx      981 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/automl_component.py
--rw-rw-r--  2.0 unx      667 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/resource.py
--rw-rw-r--  2.0 unx      391 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/retry_settings.py
--rw-rw-r--  2.0 unx     5566 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/input_output.py
--rw-rw-r--  2.0 unx     5504 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/command_component.py
--rw-rw-r--  2.0 unx     3624 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/component.py
--rw-rw-r--  2.0 unx     1013 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/__init__.py
--rw-rw-r--  2.0 unx     1520 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/featureset_spec_metadata_schema.py
--rw-rw-r--  2.0 unx      682 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/timestamp_column_metadata_schema.py
--rw-rw-r--  2.0 unx      682 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/delay_metadata_schema.py
--rw-rw-r--  2.0 unx      892 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_schema.py
--rw-rw-r--  2.0 unx      958 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/source_metadata_schema.py
--rw-rw-r--  2.0 unx     1915 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/featureset_spec_properties_schema.py
--rw-rw-r--  2.0 unx     1135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_set_schema.py
--rw-rw-r--  2.0 unx      760 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_transformation_code_metadata_schema.py
--rw-rw-r--  2.0 unx      660 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_set_specification_schema.py
--rw-rw-r--  2.0 unx     1527 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/materialization_settings_schema.py
--rw-rw-r--  2.0 unx      330 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/__init__.py
--rw-rw-r--  2.0 unx     2596 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/registry.py
--rw-rw-r--  2.0 unx     2569 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/registry_region_arm_details.py
--rw-rw-r--  2.0 unx     1614 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/system_created_storage_account.py
--rw-rw-r--  2.0 unx      542 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/util.py
--rw-rw-r--  2.0 unx     1328 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/system_created_acr_account.py
--rw-rw-r--  2.0 unx      529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/__init__.py
--rw-rw-r--  2.0 unx     2009 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/feature_store_schema.py
--rw-rw-r--  2.0 unx      783 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/materialization_store_schema.py
--rw-rw-r--  2.0 unx      656 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/compute_runtime_schema.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/__init__.py
--rw-rw-r--  2.0 unx      958 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/mltable_metadata_path_schemas.py
--rw-rw-r--  2.0 unx     1410 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/mltable_metadata_schema.py
--rw-rw-r--  2.0 unx      321 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/__init__.py
--rw-rw-r--  2.0 unx      874 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/data_import.py
--rw-rw-r--  2.0 unx     1355 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/schedule.py
--rw-rw-r--  2.0 unx      629 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/__init__.py
--rw-rw-r--  2.0 unx     8860 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/logging_handler.py
--rw-rw-r--  2.0 unx    14401 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/activity.py
--rw-rw-r--  2.0 unx     6600 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/_customtraceback.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_notification/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_data/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/
--rw-rw-r--  2.0 unx    28226 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_credentials.py
--rw-rw-r--  2.0 unx    14338 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/__init__.py
--rw-rw-r--  2.0 unx    31133 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_validation.py
--rw-rw-r--  2.0 unx    37637 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_load_functions.py
--rw-rw-r--  2.0 unx     4238 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_mixins.py
--rw-rw-r--  2.0 unx     3036 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_validate_funcs.py
--rw-rw-r--  2.0 unx     3628 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_system_data.py
--rw-rw-r--  2.0 unx    21593 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_util.py
--rw-rw-r--  2.0 unx     8485 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_resource.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_notification/__init__.py
--rw-rw-r--  2.0 unx     1463 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_notification/notification.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/__init__.py
--rw-rw-r--  2.0 unx     5542 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/feature_store_entity.py
--rw-rw-r--  2.0 unx     2786 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/data_column.py
--rw-rw-r--  2.0 unx      622 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/data_column_type.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/__init__.py
--rw-rw-r--  2.0 unx    10634 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/registry.py
--rw-rw-r--  2.0 unx    12637 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/registry_support_classes.py
--rw-rw-r--  2.0 unx      847 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/util.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/__init__.py
--rw-rw-r--  2.0 unx    26438 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/signals.py
--rw-rw-r--  2.0 unx    17148 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/thresholds.py
--rw-rw-r--  2.0 unx     7543 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/schedule.py
--rw-rw-r--  2.0 unx     2672 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/input_data.py
--rw-rw-r--  2.0 unx     5535 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/definition.py
--rw-rw-r--  2.0 unx      795 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/target.py
--rw-rw-r--  2.0 unx     1366 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/alert_notification.py
--rw-rw-r--  2.0 unx     8665 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/compute.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/__init__.py
--rw-rw-r--  2.0 unx     4416 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_vm_size.py
--rw-rw-r--  2.0 unx     2259 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/unsupported_compute.py
--rw-rw-r--  2.0 unx     4638 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/kubernetes_compute.py
--rw-rw-r--  2.0 unx    11023 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/aml_compute.py
--rw-rw-r--  2.0 unx     7751 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/synapsespark_compute.py
--rw-rw-r--  2.0 unx     5038 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_schedule.py
--rw-rw-r--  2.0 unx     1365 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_aml_compute_node_info.py
--rw-rw-r--  2.0 unx     1396 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_image_metadata.py
--rw-rw-r--  2.0 unx     3882 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_usage.py
--rw-rw-r--  2.0 unx     8037 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_custom_applications.py
--rw-rw-r--  2.0 unx    19197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/compute_instance.py
--rw-rw-r--  2.0 unx     6187 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/virtual_machine_compute.py
--rw-rw-r--  2.0 unx     3710 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_setup_scripts.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/__init__.py
--rw-rw-r--  2.0 unx     2370 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/model_batch_deployment_settings.py
--rw-rw-r--  2.0 unx     1163 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/batch_job.py
--rw-rw-r--  2.0 unx     1788 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/container_resource_settings.py
--rw-rw-r--  2.0 unx      810 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/payload_response.py
--rw-rw-r--  2.0 unx     1354 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/request_logging.py
--rw-rw-r--  2.0 unx     3589 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/data_collector.py
--rw-rw-r--  2.0 unx     2121 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment_collection.py
--rw-rw-r--  2.0 unx     2457 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/resource_requirements_settings.py
--rw-rw-r--  2.0 unx     1670 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/run_settings.py
--rw-rw-r--  2.0 unx     4693 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/pipeline_component_batch_deployment.py
--rw-rw-r--  2.0 unx    10808 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment.py
--rw-rw-r--  2.0 unx     1181 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/event_hub.py
--rw-rw-r--  2.0 unx     7855 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment_settings.py
--rw-rw-r--  2.0 unx    14565 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/batch_deployment.py
--rw-rw-r--  2.0 unx     2629 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/code_configuration.py
--rw-rw-r--  2.0 unx     1273 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/data_asset.py
--rw-rw-r--  2.0 unx     8459 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/model_batch_deployment.py
--rw-rw-r--  2.0 unx    46375 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/online_deployment.py
--rw-rw-r--  2.0 unx      843 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/oversize_data_config.py
--rw-rw-r--  2.0 unx     6646 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/scale_settings.py
--rw-rw-r--  2.0 unx     1892 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/job_definition.py
--rw-rw-r--  2.0 unx     1811 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/utils.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/__init__.py
--rw-rw-r--  2.0 unx     4918 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_on_prem_credentials.py
--rw-rw-r--  2.0 unx      271 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_constants.py
--rw-rw-r--  2.0 unx     7440 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/datastore.py
--rw-rw-r--  2.0 unx     4842 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_on_prem.py
--rw-rw-r--  2.0 unx     3989 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/adls_gen1.py
--rw-rw-r--  2.0 unx    12652 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/azure_storage.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/__init__.py
--rw-rw-r--  2.0 unx     5378 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/batch_endpoint.py
--rw-rw-r--  2.0 unx     5986 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/endpoint.py
--rw-rw-r--  2.0 unx    26686 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/online_endpoint.py
--rw-rw-r--  2.0 unx     2210 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/_endpoint_helpers.py
--rw-rw-r--  2.0 unx    17217 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel.py
--rw-rw-r--  2.0 unx    15464 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/sweep.py
--rw-rw-r--  2.0 unx    33618 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/command.py
--rw-rw-r--  2.0 unx      792 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/__init__.py
--rw-rw-r--  2.0 unx    13926 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/do_while.py
--rw-rw-r--  2.0 unx     7396 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/pipeline.py
--rw-rw-r--  2.0 unx    25636 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/spark.py
--rw-rw-r--  2.0 unx    11695 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel_func.py
--rw-rw-r--  2.0 unx    37703 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/fl_scatter_gather.py
--rw-rw-r--  2.0 unx     7729 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/import_node.py
--rw-rw-r--  2.0 unx     3516 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/import_func.py
--rw-rw-r--  2.0 unx    21674 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/base_node.py
--rw-rw-r--  2.0 unx    12787 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/data_transfer_func.py
--rw-rw-r--  2.0 unx    12062 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/command_func.py
--rw-rw-r--  2.0 unx     6050 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/control_flow_node.py
--rw-rw-r--  2.0 unx    11948 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/spark_func.py
--rw-rw-r--  2.0 unx    14340 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel_for.py
--rw-rw-r--  2.0 unx     5670 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/condition_node.py
--rw-rw-r--  2.0 unx    22449 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/data_transfer.py
--rw-rw-r--  2.0 unx     1488 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/subcomponents.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/data_transfer/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/
--rw-rw-r--  2.0 unx     9460 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/import_job.py
--rw-rw-r--  2.0 unx     2671 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job_entry_mixin.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/__init__.py
--rw-rw-r--  2.0 unx    14219 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_service.py
--rw-rw-r--  2.0 unx     3216 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/base_job.py
--rw-rw-r--  2.0 unx     1986 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/service_instance.py
--rw-rw-r--  2.0 unx    13883 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job.py
--rw-rw-r--  2.0 unx      662 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/input_port.py
--rw-rw-r--  2.0 unx     1044 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/_studio_url_from_job_id.py
--rw-rw-r--  2.0 unx     2720 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parameterized_spark.py
--rw-rw-r--  2.0 unx     3885 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/compute_configuration.py
--rw-rw-r--  2.0 unx     4852 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parameterized_command.py
--rw-rw-r--  2.0 unx     6639 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_name_generator.py
--rw-rw-r--  2.0 unx     3730 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/queue_settings.py
--rw-rw-r--  2.0 unx     3565 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/resource_configuration.py
--rw-rw-r--  2.0 unx    16863 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job.py
--rw-rw-r--  2.0 unx      939 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/input_output_entry.py
--rw-rw-r--  2.0 unx     2482 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/to_rest_functions.py
--rw-rw-r--  2.0 unx    17177 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/_input_output_helpers.py
--rw-rw-r--  2.0 unx     1898 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job_entry.py
--rw-rw-r--  2.0 unx    13093 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/command_job.py
--rw-rw-r--  2.0 unx     1151 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_io_mixin.py
--rw-rw-r--  2.0 unx     5047 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_resource_configuration.py
--rw-rw-r--  2.0 unx     8001 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_resource_configuration.py
--rw-rw-r--  2.0 unx     7333 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/distribution.py
--rw-rw-r--  2.0 unx     6449 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_limits.py
--rw-rw-r--  2.0 unx    10426 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_helpers.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/
--rw-rw-r--  2.0 unx     1930 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/utils.py
--rw-rw-r--  2.0 unx      549 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/__init__.py
--rw-rw-r--  2.0 unx    10972 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/search_space_utils.py
--rw-rw-r--  2.0 unx      362 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/search_space.py
--rw-rw-r--  2.0 unx    11450 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/automl_job.py
--rw-rw-r--  2.0 unx      910 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/featurization_settings.py
--rw-rw-r--  2.0 unx     4176 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/automl_vertical.py
--rw-rw-r--  2.0 unx     3355 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/stack_ensemble_settings.py
--rw-rw-r--  2.0 unx    16998 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/training_settings.py
--rw-rw-r--  2.0 unx    10011 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_settings.py
--rw-rw-r--  2.0 unx      766 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/__init__.py
--rw-rw-r--  2.0 unx    32190 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/automl_tabular.py
--rw-rw-r--  2.0 unx    14943 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/classification_job.py
--rw-rw-r--  2.0 unx     4672 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/limit_settings.py
--rw-rw-r--  2.0 unx     9838 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/regression_job.py
--rw-rw-r--  2.0 unx     7269 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/featurization_settings.py
--rw-rw-r--  2.0 unx    34166 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_job.py
--rw-rw-r--  2.0 unx      908 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/__init__.py
--rw-rw-r--  2.0 unx     3476 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_fixed_parameters.py
--rw-rw-r--  2.0 unx     7799 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_search_space.py
--rw-rw-r--  2.0 unx     2774 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_limit_settings.py
--rw-rw-r--  2.0 unx     9859 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_job.py
--rw-rw-r--  2.0 unx     1391 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_featurization_settings.py
--rw-rw-r--  2.0 unx    10273 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_multilabel_job.py
--rw-rw-r--  2.0 unx     9172 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_ner_job.py
--rw-rw-r--  2.0 unx     1925 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_sweep_settings.py
--rw-rw-r--  2.0 unx    15254 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/automl_nlp_job.py
--rw-rw-r--  2.0 unx    20428 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image_classification_base.py
--rw-rw-r--  2.0 unx    27219 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_search_space.py
--rw-rw-r--  2.0 unx     1248 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/__init__.py
--rw-rw-r--  2.0 unx    25210 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image_object_detection_base.py
--rw-rw-r--  2.0 unx    10143 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_instance_segmentation_job.py
--rw-rw-r--  2.0 unx     9929 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_job.py
--rw-rw-r--  2.0 unx     6917 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image.py
--rw-rw-r--  2.0 unx     2903 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_sweep_settings.py
--rw-rw-r--  2.0 unx     6380 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_limit_settings.py
--rw-rw-r--  2.0 unx    10315 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_multilabel_job.py
--rw-rw-r--  2.0 unx    43738 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_model_settings.py
--rw-rw-r--  2.0 unx    55726 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_search_space.py
--rw-rw-r--  2.0 unx     9831 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_job.py
--rw-rw-r--  2.0 unx     5350 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parallel_task.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/__init__.py
--rw-rw-r--  2.0 unx     3039 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/run_function.py
--rw-rw-r--  2.0 unx     7267 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parallel_job.py
--rw-rw-r--  2.0 unx     3550 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parameterized_parallel.py
--rw-rw-r--  2.0 unx     2817 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/retry_settings.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/data/
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/__init__.py
--rw-rw-r--  2.0 unx    29989 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/pipeline_job.py
--rw-rw-r--  2.0 unx     8852 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_pipeline_job_helpers.py
--rw-rw-r--  2.0 unx    13152 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_load_component.py
--rw-rw-r--  2.0 unx    28660 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_pipeline_expression.py
--rw-rw-r--  2.0 unx     2351 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/pipeline_job_settings.py
--rw-rw-r--  2.0 unx     6465 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_attr_dict.py
--rw-rw-r--  2.0 unx    16195 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_component_translatable.py
--rw-rw-r--  2.0 unx      733 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/__init__.py
--rw-rw-r--  2.0 unx     7370 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/attr_dict.py
--rw-rw-r--  2.0 unx    29427 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/base.py
--rw-rw-r--  2.0 unx    19451 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/mixin.py
--rw-rw-r--  2.0 unx      307 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/data/expression_component_template.yml
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/data_transfer/__init__.py
--rw-rw-r--  2.0 unx    13245 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/data_transfer/data_transfer_job.py
--rw-rw-r--  2.0 unx     5928 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/sampling_algorithm.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/__init__.py
--rw-rw-r--  2.0 unx    16425 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/search_space.py
--rw-rw-r--  2.0 unx    16042 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/sweep_job.py
--rw-rw-r--  2.0 unx     9779 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/early_termination_policy.py
--rw-rw-r--  2.0 unx     1959 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/objective.py
--rw-rw-r--  2.0 unx    11491 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/parameterized_sweep.py
--rw-rw-r--  2.0 unx    13238 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/utils.py
--rw-rw-r--  2.0 unx     2640 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/__init__.py
--rw-rw-r--  2.0 unx     8543 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/group_input.py
--rw-rw-r--  2.0 unx     7138 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/external_data.py
--rw-rw-r--  2.0 unx    21461 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/input.py
--rw-rw-r--  2.0 unx     4328 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/enum_input.py
--rw-rw-r--  2.0 unx      927 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/base.py
--rw-rw-r--  2.0 unx     7608 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/output.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/
--rw-rw-r--  2.0 unx     8363 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/networking.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/__init__.py
--rw-rw-r--  2.0 unx    13135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/workspace.py
--rw-rw-r--  2.0 unx     4364 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/workspace_keys.py
--rw-rw-r--  2.0 unx      890 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/private_endpoint.py
--rw-rw-r--  2.0 unx     8080 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/diagnose.py
--rw-rw-r--  2.0 unx     1135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/compute_runtime.py
--rw-rw-r--  2.0 unx     2202 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/feature_store_settings.py
--rw-rw-r--  2.0 unx      678 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/customer_managed_key.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/__init__.py
--rw-rw-r--  2.0 unx    10551 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/workspace_connection.py
--rw-rw-r--  2.0 unx     6208 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/credentials.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/__init__.py
--rw-rw-r--  2.0 unx     1071 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_specification.py
--rw-rw-r--  2.0 unx     2410 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_materialization_metadata.py
--rw-rw-r--  2.0 unx     2858 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/featureset_spec_metadata.py
--rw-rw-r--  2.0 unx     4298 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_settings.py
--rw-rw-r--  2.0 unx     1182 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_compute_resource.py
--rw-rw-r--  2.0 unx      465 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_type.py
--rw-rw-r--  2.0 unx     1088 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_backfill_metadata.py
--rw-rw-r--  2.0 unx      404 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/timestamp_column_metadata.py
--rw-rw-r--  2.0 unx      424 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/delay_metadata.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_transformation_code_metadata.py
--rw-rw-r--  2.0 unx      719 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/source_metadata.py
--rw-rw-r--  2.0 unx     1447 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/__init__.py
--rw-rw-r--  2.0 unx      571 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/_constants.py
--rw-rw-r--  2.0 unx    10033 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/feature_store.py
--rw-rw-r--  2.0 unx      588 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/materialization_store.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_data/__init__.py
--rw-rw-r--  2.0 unx     2952 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_data/mltable_metadata.py
--rw-rw-r--  2.0 unx    18791 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/_additional_includes.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/__init__.py
--rw-rw-r--  2.0 unx     2846 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/code.py
--rw-rw-r--  2.0 unx    11032 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/parallel_component.py
--rw-rw-r--  2.0 unx     6908 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/component_factory.py
--rw-rw-r--  2.0 unx    11303 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/datatransfer_component.py
--rw-rw-r--  2.0 unx     7572 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/spark_component.py
--rw-rw-r--  2.0 unx     3085 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/import_component.py
--rw-rw-r--  2.0 unx     1543 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/automl_component.py
--rw-rw-r--  2.0 unx    16264 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/_artifact_cache.py
--rw-rw-r--  2.0 unx    13094 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/command_component.py
--rw-rw-r--  2.0 unx    24624 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/component.py
--rw-rw-r--  2.0 unx    22783 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/pipeline_component.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/__init__.py
--rw-rw-r--  2.0 unx    11160 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/trigger.py
--rw-rw-r--  2.0 unx    17066 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/schedule.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/__init__.py
--rw-rw-r--  2.0 unx     4563 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/data_import.py
--rw-rw-r--  2.0 unx     4555 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/schedule.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/
--rw-rw-r--  2.0 unx      661 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/__init__.py
--rw-rw-r--  2.0 unx     1631 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/intellectual_property.py
--rw-rw-r--  2.0 unx     1591 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/auto_delete_setting.py
--rw-rw-r--  2.0 unx     3096 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/workspace_asset_reference.py
--rw-rw-r--  2.0 unx     4999 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/federated_learning_silo.py
--rw-rw-r--  2.0 unx    16289 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/environment.py
--rw-rw-r--  2.0 unx     4867 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/asset.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/
--rw-rw-r--  2.0 unx     8398 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/model.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/__init__.py
--rw-rw-r--  2.0 unx     5705 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/code.py
--rw-rw-r--  2.0 unx     9100 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/data.py
--rw-rw-r--  2.0 unx     4145 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/artifact.py
--rw-rw-r--  2.0 unx     7510 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/feature_set.py
--rw-rw-r--  2.0 unx     1099 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_configuration.py
--rw-rw-r--  2.0 unx      246 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/__init__.py
--rw-rw-r--  2.0 unx     1581 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/base_environment_source.py
--rw-rw-r--  2.0 unx    11686 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_package.py
--rw-rw-r--  2.0 unx     7087 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/inferencing_server.py
--rw-rw-r--  2.0 unx      180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/__init__.py
--rw-rw-r--  2.0 unx    19677 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_artifact_utilities.py
--rw-rw-r--  2.0 unx     2774 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_constants.py
--rw-rw-r--  2.0 unx     9274 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_gen2_storage_helper.py
--rw-rw-r--  2.0 unx    13123 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_blob_storage_helper.py
--rw-rw-r--  2.0 unx    14204 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_fileshare_storage_helper.py
--rw-rw-r--  2.0 unx      961 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/data_transfer/__init__.py
--rw-rw-r--  2.0 unx     1395 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/sweep/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/
--rw-rw-r--  2.0 unx      693 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/__init__.py
--rw-rw-r--  2.0 unx    95488 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx      648 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/models.py
--rw-rw-r--  2.0 unx      344 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_version.py
--rw-rw-r--  2.0 unx     3307 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/__init__.py
--rw-rw-r--  2.0 unx     6863 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_version.py
--rw-rw-r--  2.0 unx     3345 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/__init__.py
--rw-rw-r--  2.0 unx     6846 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_patch.py
--rw-rw-r--  2.0 unx     3294 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_configuration.py
--rw-rw-r--  2.0 unx    14310 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    14317 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     1433 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx     7774 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx     5180 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx     5679 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4053 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     4850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    47000 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx     4384 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    55593 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    22447 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/__init__.py
--rw-rw-r--  2.0 unx   278877 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models.py
--rw-rw-r--  2.0 unx    12038 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx   296235 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models_py3.py
--rw-rw-r--  2.0 unx    21033 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    20971 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     1433 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/__init__.py
--rw-rw-r--  2.0 unx    10460 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx     6448 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_usages_operations.py
--rw-rw-r--  2.0 unx     7149 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5419 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5700 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_operations.py
--rw-rw-r--  2.0 unx    63168 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_compute_operations.py
--rw-rw-r--  2.0 unx     5974 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    75739 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspaces_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/__init__.py
--rw-rw-r--  2.0 unx     4457 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_version.py
--rw-rw-r--  2.0 unx     3004 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/__init__.py
--rw-rw-r--  2.0 unx     4424 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_patch.py
--rw-rw-r--  2.0 unx     2961 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_configuration.py
--rw-rw-r--  2.0 unx      809 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    36859 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_models_operations.py
--rw-rw-r--  2.0 unx     4341 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_extensive_model_operations.py
--rw-rw-r--  2.0 unx     4016 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_migration_operations.py
--rw-rw-r--  2.0 unx    15975 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_assets_operations.py
--rw-rw-r--  2.0 unx     7571 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/__init__.py
--rw-rw-r--  2.0 unx    78857 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_models.py
--rw-rw-r--  2.0 unx     2618 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx    85714 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_models_py3.py
--rw-rw-r--  2.0 unx      809 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/__init__.py
--rw-rw-r--  2.0 unx    55242 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_models_operations.py
--rw-rw-r--  2.0 unx     5747 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_extensive_model_operations.py
--rw-rw-r--  2.0 unx     5385 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_migration_operations.py
--rw-rw-r--  2.0 unx    24220 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_assets_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/__init__.py
--rw-rw-r--  2.0 unx    19439 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_version.py
--rw-rw-r--  2.0 unx     3663 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/__init__.py
--rw-rw-r--  2.0 unx    19586 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_patch.py
--rw-rw-r--  2.0 unx     3612 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_configuration.py
--rw-rw-r--  2.0 unx    38217 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    15231 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    15238 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     5406 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    21658 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    26710 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_versions_operations.py
--rw-rw-r--  2.0 unx    21212 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx     8900 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_provisions_operations.py
--rw-rw-r--  2.0 unx    14881 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    14570 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    22006 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    30224 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    16135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23146 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    16073 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    24187 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_versions_operations.py
--rw-rw-r--  2.0 unx    21431 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_containers_operations.py
--rw-rw-r--  2.0 unx    18632 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    32380 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    15153 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    21215 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    41913 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    21472 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx     8239 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    15172 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     5490 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    27290 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    36020 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_versions_operations.py
--rw-rw-r--  2.0 unx    15025 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    22778 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_containers_operations.py
--rw-rw-r--  2.0 unx    21009 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_settings_rule_operations.py
--rw-rw-r--  2.0 unx    31308 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     5871 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4361 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    56352 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    23058 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_containers_operations.py
--rw-rw-r--  2.0 unx    10483 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_features_operations.py
--rw-rw-r--  2.0 unx    33245 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    16580 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     4692 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    27543 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    19605 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    25862 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    59901 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    24217 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    22739 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_versions_operations.py
--rw-rw-r--  2.0 unx    89964 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/__init__.py
--rw-rw-r--  2.0 unx  1359041 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models.py
--rw-rw-r--  2.0 unx    69169 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx  1465971 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models_py3.py
--rw-rw-r--  2.0 unx    52661 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    22472 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    22409 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     5406 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/__init__.py
--rw-rw-r--  2.0 unx    28898 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    36768 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_versions_operations.py
--rw-rw-r--  2.0 unx    28218 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    10799 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_provisions_operations.py
--rw-rw-r--  2.0 unx    22042 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    21481 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    29401 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    40450 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    24121 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    31415 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    24224 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    33160 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_versions_operations.py
--rw-rw-r--  2.0 unx    28524 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_containers_operations.py
--rw-rw-r--  2.0 unx    28612 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    43119 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    22339 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    28367 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    57313 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    28577 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx    11094 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    22511 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     6914 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    38266 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    49845 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_versions_operations.py
--rw-rw-r--  2.0 unx    22205 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    30856 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_containers_operations.py
--rw-rw-r--  2.0 unx    27895 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_settings_rule_operations.py
--rw-rw-r--  2.0 unx    42135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     7542 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5812 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     6035 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_operations.py
--rw-rw-r--  2.0 unx    77622 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    31163 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_containers_operations.py
--rw-rw-r--  2.0 unx    15303 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_features_operations.py
--rw-rw-r--  2.0 unx    45951 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    24878 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     6412 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    39050 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    29672 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    35799 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    82325 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    35452 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    30926 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_versions_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/__init__.py
--rw-rw-r--  2.0 unx     8364 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_version.py
--rw-rw-r--  2.0 unx     3681 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/__init__.py
--rw-rw-r--  2.0 unx     8374 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_patch.py
--rw-rw-r--  2.0 unx     3630 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_configuration.py
--rw-rw-r--  2.0 unx     1889 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    14726 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    14420 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    19238 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx     9216 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_resource_management_asset_reference_operations.py
--rw-rw-r--  2.0 unx    18602 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    15020 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx     5293 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_references_operations.py
--rw-rw-r--  2.0 unx    18604 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx    14545 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx     5469 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_temporary_data_references_operations.py
--rw-rw-r--  2.0 unx    19503 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx    18492 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    19876 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    17754 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/__init__.py
--rw-rw-r--  2.0 unx   230548 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models.py
--rw-rw-r--  2.0 unx     5979 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx   248404 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models_py3.py
--rw-rw-r--  2.0 unx     1889 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/__init__.py
--rw-rw-r--  2.0 unx    21753 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    21197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    27250 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    11052 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_resource_management_asset_reference_operations.py
--rw-rw-r--  2.0 unx    26183 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    22072 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx     7440 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_references_operations.py
--rw-rw-r--  2.0 unx    25612 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx    21337 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx     7616 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_temporary_data_references_operations.py
--rw-rw-r--  2.0 unx    27485 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx    26058 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    28455 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_versions_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/__init__.py
--rw-rw-r--  2.0 unx     4123 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_version.py
--rw-rw-r--  2.0 unx     3004 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/__init__.py
--rw-rw-r--  2.0 unx     4082 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_patch.py
--rw-rw-r--  2.0 unx     2961 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_configuration.py
--rw-rw-r--  2.0 unx      732 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/__init__.py
--rw-rw-r--  2.0 unx     4050 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_registry_management_non_workspace_operations.py
--rw-rw-r--  2.0 unx     3630 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_async_operations_operations.py
--rw-rw-r--  2.0 unx     1291 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/__init__.py
--rw-rw-r--  2.0 unx    12342 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/_models.py
--rw-rw-r--  2.0 unx    13501 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/_models_py3.py
--rw-rw-r--  2.0 unx      732 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/__init__.py
--rw-rw-r--  2.0 unx     4969 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/_registry_management_non_workspace_operations.py
--rw-rw-r--  2.0 unx     4296 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/_async_operations_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/__init__.py
--rw-rw-r--  2.0 unx     5590 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_version.py
--rw-rw-r--  2.0 unx     3052 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/__init__.py
--rw-rw-r--  2.0 unx     5578 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_patch.py
--rw-rw-r--  2.0 unx     3009 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_configuration.py
--rw-rw-r--  2.0 unx    27292 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_experiments_operations.py
--rw-rw-r--  2.0 unx     1083 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    13305 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_spans_operations.py
--rw-rw-r--  2.0 unx    55228 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_artifacts_operations.py
--rw-rw-r--  2.0 unx     7660 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_delete_operations.py
--rw-rw-r--  2.0 unx    39025 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_metric_operations.py
--rw-rw-r--  2.0 unx    20580 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_events_operations.py
--rw-rw-r--  2.0 unx     7855 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_operations.py
--rw-rw-r--  2.0 unx   115528 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_runs_operations.py
--rw-rw-r--  2.0 unx    12026 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/__init__.py
--rw-rw-r--  2.0 unx   175831 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_models.py
--rw-rw-r--  2.0 unx     2471 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx   189590 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_models_py3.py
--rw-rw-r--  2.0 unx    37464 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_experiments_operations.py
--rw-rw-r--  2.0 unx     1083 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/__init__.py
--rw-rw-r--  2.0 unx    18266 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_spans_operations.py
--rw-rw-r--  2.0 unx    80722 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_run_artifacts_operations.py
--rw-rw-r--  2.0 unx    10429 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_delete_operations.py
--rw-rw-r--  2.0 unx    51983 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_metric_operations.py
--rw-rw-r--  2.0 unx    29980 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_events_operations.py
--rw-rw-r--  2.0 unx    10619 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_run_operations.py
--rw-rw-r--  2.0 unx   169474 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_runs_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/__init__.py
--rw-rw-r--  2.0 unx    12428 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_version.py
--rw-rw-r--  2.0 unx     3647 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/__init__.py
--rw-rw-r--  2.0 unx    12494 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_patch.py
--rw-rw-r--  2.0 unx     3596 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_configuration.py
--rw-rw-r--  2.0 unx    38034 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    15199 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    15206 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     3105 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    14849 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    14538 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    30057 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    16103 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    15874 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    18592 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    15121 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    21064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    41714 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx     8223 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    15140 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     5482 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    14993 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    31133 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     5863 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4353 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5058 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    49956 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    16386 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     4684 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    23675 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    15515 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    59123 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    17194 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    57995 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/__init__.py
--rw-rw-r--  2.0 unx   894487 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_models.py
--rw-rw-r--  2.0 unx    50573 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx   965813 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_models_py3.py
--rw-rw-r--  2.0 unx    52107 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    22228 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    22165 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     3105 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/__init__.py
--rw-rw-r--  2.0 unx    21798 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    21237 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    40018 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    23877 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23642 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    28307 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    22095 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    28004 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    56690 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    11062 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    22267 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     6898 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    21961 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    41642 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     7481 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5796 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     6021 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_operations.py
--rw-rw-r--  2.0 unx    66885 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    24301 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     6351 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    32480 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    23014 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    80334 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    26048 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_versions_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/__init__.py
--rw-rw-r--  2.0 unx    16922 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_version.py
--rw-rw-r--  2.0 unx     3663 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/__init__.py
--rw-rw-r--  2.0 unx    17041 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_patch.py
--rw-rw-r--  2.0 unx     3612 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_configuration.py
--rw-rw-r--  2.0 unx    38114 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    15231 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    15238 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     4585 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    21545 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    21069 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx     8900 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_provisions_operations.py
--rw-rw-r--  2.0 unx    14881 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    14570 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    21893 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    30121 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    16135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23033 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    15906 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    18632 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    29620 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    15153 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    21112 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    41810 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    21359 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx     8239 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    15172 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     5490 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    23557 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    15025 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    21009 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_settings_rule_operations.py
--rw-rw-r--  2.0 unx    31205 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     5871 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4361 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    56352 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    33187 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    16418 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     4692 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    24200 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    15547 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    22129 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    59283 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    17226 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    22459 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_versions_operations.py
--rw-rw-r--  2.0 unx    70920 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/__init__.py
--rw-rw-r--  2.0 unx  1106044 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models.py
--rw-rw-r--  2.0 unx    57507 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx  1193595 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models_py3.py
--rw-rw-r--  2.0 unx    52243 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    22292 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    22229 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     4585 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/__init__.py
--rw-rw-r--  2.0 unx    28554 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    27797 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    10754 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_provisions_operations.py
--rw-rw-r--  2.0 unx    21862 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    21301 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    29010 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    40122 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    23941 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    31024 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23706 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    28387 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    38892 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    22159 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    28084 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    56850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    28186 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx    11094 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    22331 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     6914 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    32157 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    22025 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    27715 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_settings_rule_operations.py
--rw-rw-r--  2.0 unx    41762 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     7497 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5812 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     6035 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_operations.py
--rw-rw-r--  2.0 unx    77082 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    45578 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    24365 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     6367 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    33448 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    23078 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    29696 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    80606 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    26112 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    30150 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_versions_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/__init__.py
--rw-rw-r--  2.0 unx     5870 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_version.py
--rw-rw-r--  2.0 unx     3004 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/__init__.py
--rw-rw-r--  2.0 unx     5858 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_patch.py
--rw-rw-r--  2.0 unx     2961 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_configuration.py
--rw-rw-r--  2.0 unx    37470 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_controller_v2_operations.py
--rw-rw-r--  2.0 unx     1214 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    25817 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_v2_operations.py
--rw-rw-r--  2.0 unx     4594 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_delete_operations.py
--rw-rw-r--  2.0 unx    37442 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_datasets_v1_operations.py
--rw-rw-r--  2.0 unx    11030 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_call_operations.py
--rw-rw-r--  2.0 unx    14473 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_container_operations.py
--rw-rw-r--  2.0 unx    35004 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_version_operations.py
--rw-rw-r--  2.0 unx     8427 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_get_operation_status_operations.py
--rw-rw-r--  2.0 unx     7806 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/__init__.py
--rw-rw-r--  2.0 unx    96571 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models.py
--rw-rw-r--  2.0 unx     4233 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx   104034 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models_py3.py
--rw-rw-r--  2.0 unx    57349 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_controller_v2_operations.py
--rw-rw-r--  2.0 unx     1214 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/__init__.py
--rw-rw-r--  2.0 unx    38056 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_v2_operations.py
--rw-rw-r--  2.0 unx     6000 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_delete_operations.py
--rw-rw-r--  2.0 unx    57331 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_datasets_v1_operations.py
--rw-rw-r--  2.0 unx    15249 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_call_operations.py
--rw-rw-r--  2.0 unx    19656 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_container_operations.py
--rw-rw-r--  2.0 unx    50561 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_version_operations.py
--rw-rw-r--  2.0 unx     9828 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_get_operation_status_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/__init__.py
--rw-rw-r--  2.0 unx     8789 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_version.py
--rw-rw-r--  2.0 unx     3345 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/__init__.py
--rw-rw-r--  2.0 unx     8811 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_patch.py
--rw-rw-r--  2.0 unx     3294 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_configuration.py
--rw-rw-r--  2.0 unx    36355 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx     2073 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    14016 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    13712 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    28707 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    15270 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    15041 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    17571 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    14288 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    39693 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    14307 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx    14160 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    29676 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx    15553 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx    20057 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    14689 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    16361 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    38536 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/__init__.py
--rw-rw-r--  2.0 unx   643720 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models.py
--rw-rw-r--  2.0 unx    37652 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx   698083 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models_py3.py
--rw-rw-r--  2.0 unx    49892 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx     2073 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/__init__.py
--rw-rw-r--  2.0 unx    20659 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    20106 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    38285 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    22736 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    22501 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    26898 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    20956 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    54054 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    21127 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx    20822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    39745 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx    23159 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx    28887 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    21881 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    24901 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx      592 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/__init__.py
--rw-rw-r--  2.0 unx    97359 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     3264 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/__init__.py
--rw-rw-r--  2.0 unx    16559 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_version.py
--rw-rw-r--  2.0 unx     3647 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/__init__.py
--rw-rw-r--  2.0 unx    16669 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_patch.py
--rw-rw-r--  2.0 unx     3596 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_configuration.py
--rw-rw-r--  2.0 unx    38128 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    15199 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    15206 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     4468 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    21601 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    26645 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_versions_operations.py
--rw-rw-r--  2.0 unx    21155 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    14849 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    14538 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    21949 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    30151 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    16103 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23089 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    15874 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    21374 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_containers_operations.py
--rw-rw-r--  2.0 unx    18592 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    32300 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    15121 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    21158 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    41808 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    21415 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx     8223 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    15140 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     5482 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    27225 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    14993 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    31227 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     5863 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4353 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5058 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    49956 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    16386 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     4684 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    23720 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    19565 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    25797 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    59123 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    17194 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    22515 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_versions_operations.py
--rw-rw-r--  2.0 unx    63652 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/__init__.py
--rw-rw-r--  2.0 unx   969264 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_models.py
--rw-rw-r--  2.0 unx    52567 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx  1046338 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_models_py3.py
--rw-rw-r--  2.0 unx    52516 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    22408 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    22345 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     4468 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/__init__.py
--rw-rw-r--  2.0 unx    28856 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    36663 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_versions_operations.py
--rw-rw-r--  2.0 unx    28129 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    21978 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    21417 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    29312 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    40337 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    24057 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    31373 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    28435 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_containers_operations.py
--rw-rw-r--  2.0 unx    28532 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    42983 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    22275 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    28278 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    57144 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    28488 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx    11062 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    22447 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     6898 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    38161 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    22141 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    42006 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     7526 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5796 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     6021 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_operations.py
--rw-rw-r--  2.0 unx    67335 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    24481 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     6396 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    32750 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    29592 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    35694 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    80874 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    26228 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    30499 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_versions_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/__init__.py
--rw-rw-r--  2.0 unx    16129 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_version.py
--rw-rw-r--  2.0 unx     3663 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/__init__.py
--rw-rw-r--  2.0 unx    16240 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_patch.py
--rw-rw-r--  2.0 unx     3612 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_configuration.py
--rw-rw-r--  2.0 unx    38114 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    15231 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    15238 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     4320 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    21545 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    21069 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    14881 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    14570 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    21893 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    30121 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    16135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23033 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    15906 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    18632 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    26496 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    15153 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    21112 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    41810 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    21359 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx     8239 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    15172 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     5490 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    23557 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    15025 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    31205 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     5871 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4361 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5064 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    56352 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    33201 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    16418 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     4692 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    24200 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    15547 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    22129 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    59283 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    17226 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    22459 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_versions_operations.py
--rw-rw-r--  2.0 unx    68867 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/__init__.py
--rw-rw-r--  2.0 unx  1066789 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models.py
--rw-rw-r--  2.0 unx    54945 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx  1149677 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models_py3.py
--rw-rw-r--  2.0 unx    52243 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    22292 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    22229 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     4320 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/__init__.py
--rw-rw-r--  2.0 unx    28554 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    27797 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    21862 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    21301 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    29010 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    40122 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    23941 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    31024 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23706 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    28387 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    35738 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    22159 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    28084 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    56850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    28186 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx    11094 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    22331 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     6914 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    32157 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    22025 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    41762 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     7497 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5812 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     6035 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_operations.py
--rw-rw-r--  2.0 unx    77082 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    45603 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    24365 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     6367 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    33448 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    23078 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    29696 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    80606 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    26112 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    30150 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_versions_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/__init__.py
--rw-rw-r--  2.0 unx    11928 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_version.py
--rw-rw-r--  2.0 unx     3337 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/__init__.py
--rw-rw-r--  2.0 unx    11990 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_patch.py
--rw-rw-r--  2.0 unx     3286 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_configuration.py
--rw-rw-r--  2.0 unx    36355 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    14310 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    14317 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     3023 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    14016 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    13712 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    28707 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    15270 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    15041 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    17571 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    14288 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    39693 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx     7774 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    14307 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     5298 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    14160 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    29676 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     5679 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4167 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     4874 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    47005 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    15553 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     4498 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    22339 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    14689 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    55593 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    16361 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    49054 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/__init__.py
--rw-rw-r--  2.0 unx   640114 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_models.py
--rw-rw-r--  2.0 unx    22828 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx   682901 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_models_py3.py
--rw-rw-r--  2.0 unx    49836 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    21001 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    20939 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     3023 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/__init__.py
--rw-rw-r--  2.0 unx    20627 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    20074 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    38245 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    22704 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    22469 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    26858 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    20924 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    53990 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    10444 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    21095 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     6558 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    20790 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    39697 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     7141 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5525 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5716 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_operations.py
--rw-rw-r--  2.0 unx    63093 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    23127 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     6080 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    30720 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    21849 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    75627 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    24869 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_versions_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/
--rw-rw-r--  2.0 unx      875 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/__init__.py
--rw-rw-r--  2.0 unx     4462 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1197 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_vendor.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_version.py
--rw-rw-r--  2.0 unx     3681 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/
--rw-rw-r--  2.0 unx      822 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/__init__.py
--rw-rw-r--  2.0 unx     4413 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1529 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_patch.py
--rw-rw-r--  2.0 unx     3630 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_configuration.py
--rw-rw-r--  2.0 unx      699 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    13384 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_deployment_operations.py
--rw-rw-r--  2.0 unx    12992 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_endpoint_operations.py
--rw-rw-r--  2.0 unx     5396 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/__init__.py
--rw-rw-r--  2.0 unx    64673 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models.py
--rw-rw-r--  2.0 unx     3260 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx    68366 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models_py3.py
--rw-rw-r--  2.0 unx      699 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/__init__.py
--rw-rw-r--  2.0 unx    19353 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_deployment_operations.py
--rw-rw-r--  2.0 unx    18740 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_endpoint_operations.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/
--rw-rw-r--  2.0 unx      876 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/__init__.py
--rw-rw-r--  2.0 unx    19172 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1169 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_vendor.py
--rw-rw-r--  2.0 unx     1530 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_patch.py
--rw-rw-r--  2.0 unx      486 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_version.py
--rw-rw-r--  2.0 unx     3685 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_configuration.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/
--rw-rw-r--  2.0 unx      824 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/__init__.py
--rw-rw-r--  2.0 unx    19277 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_azure_machine_learning_workspaces.py
--rw-rw-r--  2.0 unx     1530 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_patch.py
--rw-rw-r--  2.0 unx     3582 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_configuration.py
--rw-rw-r--  2.0 unx    37791 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    15001 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    14932 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     5062 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    21314 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    22756 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_versions_operations.py
--rw-rw-r--  2.0 unx    20726 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    14559 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    14216 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    21662 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    29944 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    15837 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    22778 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    15608 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    22676 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_versions_operations.py
--rw-rw-r--  2.0 unx    20997 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_containers_operations.py
--rw-rw-r--  2.0 unx    18252 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    29123 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    14871 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    20881 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    41441 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    21096 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx     8058 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    14850 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     5380 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    23302 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    42257 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_versions_operations.py
--rw-rw-r--  2.0 unx    14743 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    21752 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_containers_operations.py
--rw-rw-r--  2.0 unx    30968 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     5767 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     4302 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     4962 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    55439 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    22015 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_containers_operations.py
--rw-rw-r--  2.0 unx    32629 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    16120 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     4639 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    24022 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    15249 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    21874 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    58121 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    23508 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    22204 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_versions_operations.py
--rw-rw-r--  2.0 unx    76305 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/__init__.py
--rw-rw-r--  2.0 unx  1157391 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models.py
--rw-rw-r--  2.0 unx    58289 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
--rw-rw-r--  2.0 unx  1259260 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models_py3.py
--rw-rw-r--  2.0 unx    52006 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_deployments_operations.py
--rw-rw-r--  2.0 unx    22104 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    21989 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_endpoint_connections_operations.py
--rw-rw-r--  2.0 unx     5062 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/__init__.py
--rw-rw-r--  2.0 unx    28397 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_containers_operations.py
--rw-rw-r--  2.0 unx    30754 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_versions_operations.py
--rw-rw-r--  2.0 unx    27640 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_containers_operations.py
--rw-rw-r--  2.0 unx    21622 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_containers_operations.py
--rw-rw-r--  2.0 unx    21061 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_containers_operations.py
--rw-rw-r--  2.0 unx    28853 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_containers_operations.py
--rw-rw-r--  2.0 unx    40039 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_deployments_operations.py
--rw-rw-r--  2.0 unx    23701 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_versions_operations.py
--rw-rw-r--  2.0 unx    30867 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_versions_operations.py
--rw-rw-r--  2.0 unx    23466 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_versions_operations.py
--rw-rw-r--  2.0 unx    30402 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_versions_operations.py
--rw-rw-r--  2.0 unx    28060 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_containers_operations.py
--rw-rw-r--  2.0 unx    28091 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_datastores_operations.py
--rw-rw-r--  2.0 unx    38525 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registries_operations.py
--rw-rw-r--  2.0 unx    21919 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_containers_operations.py
--rw-rw-r--  2.0 unx    28021 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_schedules_operations.py
--rw-rw-r--  2.0 unx    56603 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_endpoints_operations.py
--rw-rw-r--  2.0 unx    28029 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_containers_operations.py
--rw-rw-r--  2.0 unx    10966 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_quotas_operations.py
--rw-rw-r--  2.0 unx    22091 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_containers_operations.py
--rw-rw-r--  2.0 unx     6833 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_usages_operations.py
--rw-rw-r--  2.0 unx    32000 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_versions_operations.py
--rw-rw-r--  2.0 unx    58390 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_versions_operations.py
--rw-rw-r--  2.0 unx    21785 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_containers_operations.py
--rw-rw-r--  2.0 unx    28960 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_containers_operations.py
--rw-rw-r--  2.0 unx    41623 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_endpoints_operations.py
--rw-rw-r--  2.0 unx     7416 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_features_operations.py
--rw-rw-r--  2.0 unx     5782 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_virtual_machine_sizes_operations.py
--rw-rw-r--  2.0 unx     5946 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_operations.py
--rw-rw-r--  2.0 unx    76435 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    29250 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_containers_operations.py
--rw-rw-r--  2.0 unx    45274 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_labeling_jobs_operations.py
--rw-rw-r--  2.0 unx    24125 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_versions_operations.py
--rw-rw-r--  2.0 unx     6337 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_link_resources_operations.py
--rw-rw-r--  2.0 unx    33658 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_jobs_operations.py
--rw-rw-r--  2.0 unx    22838 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_versions_operations.py
--rw-rw-r--  2.0 unx    29539 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_versions_operations.py
--rw-rw-r--  2.0 unx    79788 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspaces_operations.py
--rw-rw-r--  2.0 unx    34497 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_versions_operations.py
--rw-rw-r--  2.0 unx    29993 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_versions_operations.py
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_file_utils/__init__.py
--rw-rw-r--  2.0 unx     2089 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_file_utils/file_utils.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/
--rw-rw-r--  2.0 unx      262 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/flatten_json/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/
--rw-rw-r--  2.0 unx      676 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/__init__.py
--rw-rw-r--  2.0 unx     4645 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/_resource_management_client.py
--rw-rw-r--  2.0 unx     3285 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/_configuration.py
--rw-rw-r--  2.0 unx    16591 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/flatten_json/__init__.py
-drwxrwxr-x  2.0 unx        0 b- stor 23-Jun-12 16:09 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/
--rw-rw-r--  2.0 unx      574 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/__init__.py
--rw-rw-r--  2.0 unx     4586 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/_resource_management_client.py
--rw-rw-r--  2.0 unx     3177 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/_configuration.py
--rw-rw-r--  2.0 unx     1070 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/__init__.py
--rw-rw-r--  2.0 unx    19624 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_providers_operations.py
--rw-rw-r--  2.0 unx    75003 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resources_operations.py
--rw-rw-r--  2.0 unx    28537 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resource_groups_operations.py
--rw-rw-r--  2.0 unx     4637 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_operations.py
--rw-rw-r--  2.0 unx    35924 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployment_operations_operations.py
--rw-rw-r--  2.0 unx    26532 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_tags_operations.py
--rw-rw-r--  2.0 unx   188818 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployments_operations.py
--rw-rw-r--  2.0 unx    10329 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/__init__.py
--rw-rw-r--  2.0 unx    83782 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_models.py
--rw-rw-r--  2.0 unx     8008 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_resource_management_client_enums.py
--rw-rw-r--  2.0 unx    90071 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_models_py3.py
--rw-rw-r--  2.0 unx     1070 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/__init__.py
--rw-rw-r--  2.0 unx    20010 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_providers_operations.py
--rw-rw-r--  2.0 unx    76225 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_resources_operations.py
--rw-rw-r--  2.0 unx    28988 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_resource_groups_operations.py
--rw-rw-r--  2.0 unx     4716 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_operations.py
--rw-rw-r--  2.0 unx    36554 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_deployment_operations_operations.py
--rw-rw-r--  2.0 unx    27135 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_tags_operations.py
--rw-rw-r--  2.0 unx   192309 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_deployments_operations.py
--rw-rw-r--  2.0 unx     4676 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_connections_operations.py
--rw-rw-r--  2.0 unx    18447 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_online_deployment_operations.py
--rw-rw-r--  2.0 unx     2061 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/__init__.py
--rw-rw-r--  2.0 unx     8718 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_endpoint_helper.py
--rw-rw-r--  2.0 unx     3954 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_outbound_rule_operations.py
--rw-rw-r--  2.0 unx    23633 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_operation_orchestrator.py
--rw-rw-r--  2.0 unx     9786 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_code_operations.py
--rw-rw-r--  2.0 unx     3206 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_run_history_constants.py
--rw-rw-r--  2.0 unx    19567 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_job_ops_helper.py
--rw-rw-r--  2.0 unx    27658 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_model_operations.py
--rw-rw-r--  2.0 unx    20772 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_batch_endpoint_operations.py
--rw-rw-r--  2.0 unx     1352 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_dataset_dataplane_operations.py
--rw-rw-r--  2.0 unx    15981 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_deployment_helper.py
--rw-rw-r--  2.0 unx     1346 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_model_dataplane_operations.py
--rw-rw-r--  2.0 unx     6961 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_virtual_cluster_operations.py
--rw-rw-r--  2.0 unx    17694 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_job_invoker.py
--rw-rw-r--  2.0 unx    18837 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_store_operations.py
--rw-rw-r--  2.0 unx    14000 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_batch_deployment_operations.py
--rw-rw-r--  2.0 unx     6511 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_registry_operations.py
--rw-rw-r--  2.0 unx    20066 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_schedule_operations.py
--rw-rw-r--  2.0 unx    28013 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_data_operations.py
--rw-rw-r--  2.0 unx     3165 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_run_operations.py
--rw-rw-r--  2.0 unx    11543 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_compute_operations.py
--rw-rw-r--  2.0 unx    20537 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_online_endpoint_operations.py
--rw-rw-r--  2.0 unx    10459 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_operations.py
--rw-rw-r--  2.0 unx     7667 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_store_entity_operations.py
--rw-rw-r--  2.0 unx     7487 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_datastore_operations.py
--rw-rw-r--  2.0 unx    19208 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_environment_operations.py
--rw-rw-r--  2.0 unx    60605 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_job_operations.py
--rw-rw-r--  2.0 unx    25437 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_operations_base.py
--rw-rw-r--  2.0 unx    38852 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_component_operations.py
--rw-rw-r--  2.0 unx    18244 b- defN 23-Jun-12 16:08 azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_set_operations.py
-2618 files, 45723545 bytes uncompressed, 6350554 bytes compressed:  86.1%
+Zip file size: 7723693 bytes, number of entries: 2738
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/samples/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure_ai_ml.egg-info/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/
+-rw-rw-r--  2.0 unx      280 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/MANIFEST.in
+-rw-rw-r--  2.0 unx    14898 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/CHANGELOG.md
+-rw-rw-r--  2.0 unx      590 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/pyproject.toml
+-rw-rw-r--  2.0 unx       38 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/setup.cfg
+-rw-rw-r--  2.0 unx   881940 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/NOTICE.txt
+-rw-rw-r--  2.0 unx    22757 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/PKG-INFO
+-rw-rw-r--  2.0 unx     3532 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/setup.py
+-rw-rw-r--  2.0 unx     5726 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/documentation_guidelines.md
+-rw-rw-r--  2.0 unx     6810 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/README.md
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/virtual_cluster/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/batch_online_common/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/import_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/spark_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/environment/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/schedule/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/pipeline_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/workspace/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/sweep_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/batch_services/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/automl_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/code_asset/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_store_entity/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/local_endpoint/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_store/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/job_common/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/model/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/data_import/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/command_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/internal/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/online_services/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/monitoring/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/internal_utils/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_set/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/registry/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_utilities/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/compute/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/datastore/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/dsl/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/dataset/
+-rw-rw-r--  2.0 unx    41710 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/conftest.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/virtual_cluster/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/virtual_cluster/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/virtual_cluster/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/virtual_cluster/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     3902 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/virtual_cluster/e2etests/test_vc.py
+-rw-rw-r--  2.0 unx     3397 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/virtual_cluster/unittests/test_vc_operations.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/virtual_cluster/unittests/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/batch_online_common/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/batch_online_common/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_online_common/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_online_common/e2etests/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_online_common/unittests/__init__.py
+-rw-rw-r--  2.0 unx    13469 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_deployment_entity.py
+-rw-rw-r--  2.0 unx      575 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_code_configuration.py
+-rw-rw-r--  2.0 unx     4367 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_endpoint_entity.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/import_job/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/import_job/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/import_job/__init__.py
+-rw-rw-r--  2.0 unx     9567 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/import_job/e2etests/test_import_job.py
+-rw-rw-r--  2.0 unx     6504 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/import_job/unittests/test_import_job_schema_builder_entity.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/spark_job/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/spark_job/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/spark_job/__init__.py
+-rw-rw-r--  2.0 unx     4757 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/spark_job/e2etests/test_spark_job.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/spark_job/unittests/__init__.py
+-rw-rw-r--  2.0 unx    25089 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/spark_job/unittests/test_spark_job_entity.py
+-rw-rw-r--  2.0 unx     4881 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/spark_job/unittests/test_spark_job_schema.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/environment/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/environment/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    11060 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/e2etests/test_environment.py
+-rw-rw-r--  2.0 unx     2430 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_operations_registry.py
+-rw-rw-r--  2.0 unx     9896 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_operations.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/unittests/__init__.py
+-rw-rw-r--  2.0 unx     7636 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/unittests/test_env_entity.py
+-rw-rw-r--  2.0 unx     8232 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_schema.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/schedule/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/schedule/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/schedule/__init__.py
+-rw-rw-r--  2.0 unx      317 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/schedule/_util.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/schedule/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    12396 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/schedule/e2etests/test_schedule.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/schedule/unittests/__init__.py
+-rw-rw-r--  2.0 unx     9122 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/schedule/unittests/test_schedule_entity.py
+-rw-rw-r--  2.0 unx     7827 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/schedule/unittests/test_schedule_schema.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/pipeline_job/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/__init__.py
+-rw-rw-r--  2.0 unx     2968 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/_util.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    16876 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/test_control_flow_pipeline.py
+-rw-rw-r--  2.0 unx   100973 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/test_pipeline_job.py
+-rw-rw-r--  2.0 unx    38449 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_validate.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/unittests/__init__.py
+-rw-rw-r--  2.0 unx     1097 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_private_preview_disabled.py
+-rw-rw-r--  2.0 unx    91452 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_schema.py
+-rw-rw-r--  2.0 unx   101769 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_entity.py
+-rw-rw-r--  2.0 unx     6890 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_controlflow_pipeline_job.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/workspace/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/workspace/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     8726 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace_outbound_rule_operations.py
+-rw-rw-r--  2.0 unx    17008 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace_connections.py
+-rw-rw-r--  2.0 unx    20544 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/unittests/__init__.py
+-rw-rw-r--  2.0 unx     5822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_operations.py
+-rw-rw-r--  2.0 unx     7946 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_connection_entity.py
+-rw-rw-r--  2.0 unx    12030 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_operations_base.py
+-rw-rw-r--  2.0 unx     3399 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_connection_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/sweep_job/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/sweep_job/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/sweep_job/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/sweep_job/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     8646 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/sweep_job/e2etests/test_sweep_job.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/sweep_job/unittests/__init__.py
+-rw-rw-r--  2.0 unx    13957 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/sweep_job/unittests/test_sweep_job.py
+-rw-rw-r--  2.0 unx    18261 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/sweep_job/unittests/test_sweep_job_schema.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/batch_services/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/batch_services/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     8009 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/e2etests/test_batch_endpoint.py
+-rw-rw-r--  2.0 unx     8099 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/e2etests/test_batch_deployment.py
+-rw-rw-r--  2.0 unx    12821 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_endpoints.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/unittests/__init__.py
+-rw-rw-r--  2.0 unx     5062 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_deployment.py
+-rw-rw-r--  2.0 unx     2816 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_deployment_schema.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/automl_job/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/automl_job/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/__init__.py
+-rw-rw-r--  2.0 unx     6858 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/conftest.py
+-rw-rw-r--  2.0 unx     7142 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/jsonl_converter.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     2258 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_classification.py
+-rw-rw-r--  2.0 unx     5076 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_regression.py
+-rw-rw-r--  2.0 unx    10317 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_object_detection.py
+-rw-rw-r--  2.0 unx     3479 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_forecasting.py
+-rw-rw-r--  2.0 unx     5357 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_classification.py
+-rw-rw-r--  2.0 unx     2017 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_ner.py
+-rw-rw-r--  2.0 unx     8102 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_classification.py
+-rw-rw-r--  2.0 unx     2295 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_classification_multilabel.py
+-rw-rw-r--  2.0 unx     7770 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_segmentation.py
+-rw-rw-r--  2.0 unx     9286 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_classification_multilabel.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/__init__.py
+-rw-rw-r--  2.0 unx     7668 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_forecasting_settings.py
+-rw-rw-r--  2.0 unx    33199 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_schema.py
+-rw-rw-r--  2.0 unx    11620 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_classification_job.py
+-rw-rw-r--  2.0 unx     3528 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_limit_settings.py
+-rw-rw-r--  2.0 unx     6198 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_sweep_setting.py
+-rw-rw-r--  2.0 unx     3040 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_setsearchspace.py
+-rw-rw-r--  2.0 unx    11285 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_object_detection.py
+-rw-rw-r--  2.0 unx     3375 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_featurization_settings.py
+-rw-rw-r--  2.0 unx    14380 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_nlp_schema.py
+-rw-rw-r--  2.0 unx    16641 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_classification_multilabel_job.py
+-rw-rw-r--  2.0 unx    11112 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_forecasting_job.py
+-rw-rw-r--  2.0 unx     9187 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_classification.py
+-rw-rw-r--  2.0 unx    11175 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_instance_segmentation.py
+-rw-rw-r--  2.0 unx     5993 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_n_cross_validation_settings.py
+-rw-rw-r--  2.0 unx    16341 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_classification_job.py
+-rw-rw-r--  2.0 unx     9604 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_regression_job.py
+-rw-rw-r--  2.0 unx     5714 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_nlp_sweep_settings.py
+-rw-rw-r--  2.0 unx    15114 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_ner_job.py
+-rw-rw-r--  2.0 unx     9995 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_classification_multilabel.py
+-rw-rw-r--  2.0 unx    23455 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_tabular_schema.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/code_asset/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/code_asset/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/code_asset/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/code_asset/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     2604 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/code_asset/e2etests/test_code.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/code_asset/unittests/__init__.py
+-rw-rw-r--  2.0 unx     3925 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/code_asset/unittests/test_federated_learning_silo.py
+-rw-rw-r--  2.0 unx     3356 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/code_asset/unittests/test_code_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_store_entity/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store_entity/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store_entity/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     2406 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store_entity/e2etests/test_feature_store_entity.py
+-rw-rw-r--  2.0 unx     4778 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/test_feature_store_entity_operations.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/__init__.py
+-rw-rw-r--  2.0 unx     1212 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/test_feature_store_entity_schema.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/local_endpoint/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    11268 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/e2etests/test_local_endpoint.py
+-rw-rw-r--  2.0 unx     4036 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_devcontainer_resolver.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/__init__.py
+-rw-rw-r--  2.0 unx     2608 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_dockerfile_resolver.py
+-rw-rw-r--  2.0 unx     4681 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_mdc_config_resolver.py
+-rw-rw-r--  2.0 unx     9567 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_local_endpoint_validator.py
+-rw-rw-r--  2.0 unx     3329 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_devcontainer_properties.py
+-rw-rw-r--  2.0 unx     2153 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_endpoint_stub.py
+-rw-rw-r--  2.0 unx    10985 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_docker_client.py
+-rw-rw-r--  2.0 unx     1580 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_dockerfile_instructions.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/spark_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/script_parallel/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/training/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/python/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/spark_component/
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/spark_job/basic_spark_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/spark_job/spark_job_word_count/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/spark_job/basic_spark_job/src/
+-rw-rw-r--  2.0 unx      454 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/spark_job/basic_spark_job/src/main.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/spark_job/spark_job_word_count/src/
+-rw-rw-r--  2.0 unx      528 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/spark_job/spark_job_word_count/src/wordcount.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/primitive_type_components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_hello_world/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/mpi_hello_world/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/
+-rw-rw-r--  2.0 unx     1977 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/pipeline.py
+-rw-rw-r--  2.0 unx     1455 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/train.py
+-rw-rw-r--  2.0 unx      770 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/eval.py
+-rw-rw-r--  2.0 unx      910 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/src/
+-rw-rw-r--  2.0 unx     1056 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/pipeline.py
+-rw-rw-r--  2.0 unx     1016 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/
+-rw-rw-r--  2.0 unx     3292 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline.py
+-rw-rw-r--  2.0 unx     3462 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline_with_data_as_input.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/
+-rw-rw-r--  2.0 unx     1320 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/compare2.py
+-rw-rw-r--  2.0 unx     1459 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/train.py
+-rw-rw-r--  2.0 unx      770 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/eval.py
+-rw-rw-r--  2.0 unx      910 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/
+-rw-rw-r--  2.0 unx     1347 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/pipeline.py
+-rw-rw-r--  2.0 unx     1016 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/
+-rw-rw-r--  2.0 unx     1027 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/pipeline.py
+-rw-rw-r--  2.0 unx       52 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/hello.py
+-rw-rw-r--  2.0 unx       52 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/hello.py
+-rw-rw-r--  2.0 unx       52 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/
+-rw-rw-r--  2.0 unx     1118 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/pipeline.py
+-rw-rw-r--  2.0 unx     1016 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/
+-rw-rw-r--  2.0 unx     1297 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/pipeline.py
+-rw-rw-r--  2.0 unx     1219 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/
+-rw-rw-r--  2.0 unx     2006 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/pipeline.py
+-rw-rw-r--  2.0 unx     4763 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/pipeline.py
+-rw-rw-r--  2.0 unx     1232 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/pipeline.py
+-rw-rw-r--  2.0 unx     1433 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/pipeline.py
+-rw-rw-r--  2.0 unx     1321 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/pipeline.py
+-rw-rw-r--  2.0 unx     1496 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/pipeline.py
+-rw-rw-r--  2.0 unx     2723 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/
+-rw-rw-r--  2.0 unx      549 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/pipeline.py
+-rw-rw-r--  2.0 unx       28 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/
+-rw-rw-r--  2.0 unx      830 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/primitive_type_components.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/
+-rw-rw-r--  2.0 unx     2336 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/invalid_pipeline.py
+-rw-rw-r--  2.0 unx     3019 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/
+-rw-rw-r--  2.0 unx     1391 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/pipeline.py
+-rw-rw-r--  2.0 unx     1219 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/kmeans_example.py
+-rw-rw-r--  2.0 unx      776 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword.py
+-rw-rw-r--  2.0 unx      528 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/wordcount.py
+-rw-rw-r--  2.0 unx      497 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword_with_optional_input.py
+-rw-rw-r--  2.0 unx      474 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/add_greeting_column.py
+-rw-rw-r--  2.0 unx      395 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/count_by_row.py
+-rw-rw-r--  2.0 unx     2182 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/
+-rw-rw-r--  2.0 unx     1765 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/pipeline.py
+-rw-rw-r--  2.0 unx     1340 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/score.py
+-rw-rw-r--  2.0 unx      938 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/convert_data.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/src/
+-rw-rw-r--  2.0 unx      850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/pipeline.py
+-rw-rw-r--  2.0 unx     4119 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/src/train.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/src/
+-rw-rw-r--  2.0 unx     1089 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/pipeline.py
+-rw-rw-r--  2.0 unx     1291 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/
+-rw-rw-r--  2.0 unx     3622 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/pipeline.py
+-rw-rw-r--  2.0 unx     1455 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/train.py
+-rw-rw-r--  2.0 unx      770 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/eval.py
+-rw-rw-r--  2.0 unx      910 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/
+-rw-rw-r--  2.0 unx     2904 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/pipeline.py
+-rw-rw-r--  2.0 unx     1064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/tabular_batch_inference.py
+-rw-rw-r--  2.0 unx      938 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/convert_data.py
+-rw-rw-r--  2.0 unx     1340 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/file_batch_inference.py
+-rw-rw-r--  2.0 unx     1884 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/get_data.py
+-rw-rw-r--  2.0 unx     1130 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/
+-rw-rw-r--  2.0 unx     1482 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/pipeline.py
+-rw-rw-r--  2.0 unx      979 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/hello.py
+-rw-rw-r--  2.0 unx      979 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/hello.py
+-rw-rw-r--  2.0 unx      979 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/
+-rw-rw-r--  2.0 unx     2334 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/pipeline.py
+-rw-rw-r--  2.0 unx     4006 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/prep.py
+-rw-rw-r--  2.0 unx     2336 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/train.py
+-rw-rw-r--  2.0 unx     5373 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/transform.py
+-rw-rw-r--  2.0 unx     2343 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/predict.py
+-rw-rw-r--  2.0 unx     2158 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/basic_component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/
+-rw-rw-r--  2.0 unx     1443 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/baisc_component.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/
+-rw-rw-r--  2.0 unx      602 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/
+-rw-rw-r--  2.0 unx       28 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/src/
+-rw-rw-r--  2.0 unx      591 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/pipeline.py
+-rw-rw-r--  2.0 unx       28 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/src/
+-rw-rw-r--  2.0 unx      531 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/pipeline.py
+-rw-rw-r--  2.0 unx      157 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/
+-rw-rw-r--  2.0 unx     8027 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/pipeline.py
+-rw-rw-r--  2.0 unx     1459 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/train.py
+-rw-rw-r--  2.0 unx      924 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/pipeline.py
+-rw-rw-r--  2.0 unx     1346 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_meta.py
+-rw-rw-r--  2.0 unx      976 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/__init__.py
+-rw-rw-r--  2.0 unx     1368 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path.py
+-rw-rw-r--  2.0 unx     1987 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_choice.py
+-rw-rw-r--  2.0 unx     1744 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_basic.py
+-rw-rw-r--  2.0 unx     1358 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_string_concatenate.py
+-rw-rw-r--  2.0 unx     1990 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_literal.py
+-rw-rw-r--  2.0 unx     1329 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path_concatenate.py
+-rw-rw-r--  2.0 unx     1984 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_limits.py
+-rw-rw-r--  2.0 unx     1205 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_compute.py
+-rw-rw-r--  2.0 unx     1342 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_cross_type.py
+-rw-rw-r--  2.0 unx     1431 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_reason_expression.py
+-rw-rw-r--  2.0 unx     1253 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_literal.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/
+-rw-rw-r--  2.0 unx     2750 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/pipeline.py
+-rw-rw-r--  2.0 unx     1455 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/train.py
+-rw-rw-r--  2.0 unx      770 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/eval.py
+-rw-rw-r--  2.0 unx      910 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/score.py
+-rw-rw-r--  2.0 unx      853 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_hello_world/pipeline.py
+-rw-rw-r--  2.0 unx      792 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/mpi_hello_world/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/src/
+-rw-rw-r--  2.0 unx      531 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/pipeline.py
+-rw-rw-r--  2.0 unx       28 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/
+-rw-rw-r--  2.0 unx     3127 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/pipeline.py
+-rw-rw-r--  2.0 unx     1758 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train1.py
+-rw-rw-r--  2.0 unx     1455 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train.py
+-rw-rw-r--  2.0 unx      770 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/eval.py
+-rw-rw-r--  2.0 unx      910 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/score.py
+-rw-rw-r--  2.0 unx      755 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/
+-rw-rw-r--  2.0 unx     1462 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/pipeline.py
+-rw-rw-r--  2.0 unx     1064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/tabular_run_with_model.py
+-rw-rw-r--  2.0 unx     1077 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/src/
+-rw-rw-r--  2.0 unx     1771 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/pipeline.py
+-rw-rw-r--  2.0 unx     1016 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/src/hello.py
+-rw-rw-r--  2.0 unx     1064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/script_parallel/tabular_run_with_model.py
+-rw-rw-r--  2.0 unx     1340 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/script_parallel/pass_through.py
+-rw-rw-r--  2.0 unx     1509 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/script_parallel/digit_identification.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/do_while_test/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/component_with_conditional_output/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/write_jokes/
+-rw-rw-r--  2.0 unx     4772 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/do_while_test/entry.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/preprocessing/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/aggregate/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/training/
+-rw-rw-r--  2.0 unx     2377 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/preprocessing/run.py
+-rw-rw-r--  2.0 unx     2271 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/aggregate/run.py
+-rw-rw-r--  2.0 unx     2882 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/training/run.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library1/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library1/world.py
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library1/hello.py
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library/world.py
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library1/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library2/
+-rw-rw-r--  2.0 unx       65 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library1/__init__.py
+-rw-rw-r--  2.0 unx       53 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library1/hello.py
+-rw-rw-r--  2.0 unx       57 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library2/greetings.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/utils/
+-rw-rw-r--  2.0 unx       65 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/__init__.py
+-rw-rw-r--  2.0 unx       65 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/utils/__init__.py
+-rw-rw-r--  2.0 unx       51 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/utils/salute.py
+-rw-rw-r--  2.0 unx      518 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/component_with_conditional_output/entry.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/components/write_jokes/src/
+-rw-rw-r--  2.0 unx      157 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/components/write_jokes/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/
+-rw-rw-r--  2.0 unx     7042 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/advanced_example.py
+-rw-rw-r--  2.0 unx     1261 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/simple_example.py
+-rw-rw-r--  2.0 unx     1788 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/plot_example.py
+-rw-rw-r--  2.0 unx     2445 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/sklearn_example.py
+-rw-rw-r--  2.0 unx     3626 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/logistic_regression.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/ipp-component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/v2_style/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/spark-component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/hdi-component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/batch_inference/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/
+-rw-rw-r--  2.0 unx      465 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes/run.py
+-rw-rw-r--  2.0 unx      465 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/run.py
+-rw-rw-r--  2.0 unx     4540 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/ipp-component/train_wrapper.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/v2_style/hd_insight_component/
+-rw-rw-r--  2.0 unx     2790 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/v2_style/hd_insight_component/train-spark.py
+-rw-rw-r--  2.0 unx      128 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/spark-component/run.py
+-rw-rw-r--  2.0 unx     2790 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/hdi-component/train-spark.py
+-rw-rw-r--  2.0 unx     1753 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/batch_inference/batch_score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library1/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library3/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library2/
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library1/world.py
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library1/hello.py
+-rw-rw-r--  2.0 unx      180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library3/__init__.py
+-rw-rw-r--  2.0 unx      235 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library3/hello.py
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library/world.py
+-rw-rw-r--  2.0 unx       16 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library1/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library2/
+-rw-rw-r--  2.0 unx       65 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library1/__init__.py
+-rw-rw-r--  2.0 unx       53 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library1/hello.py
+-rw-rw-r--  2.0 unx       57 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library2/greetings.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/utils/
+-rw-rw-r--  2.0 unx       65 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/__init__.py
+-rw-rw-r--  2.0 unx       65 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/utils/__init__.py
+-rw-rw-r--  2.0 unx       51 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/utils/salute.py
+-rw-rw-r--  2.0 unx      239 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library2/greetings.py
+-rw-rw-r--  2.0 unx      850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/score.py
+-rw-rw-r--  2.0 unx      876 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/train.py
+-rw-rw-r--  2.0 unx      612 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/eval.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-3/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/endpoint_scoring/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-2/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-4/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/byoc/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/mnist/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-1/
+-rw-rw-r--  2.0 unx     1019 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-3/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/onlinescoring/
+-rw-rw-r--  2.0 unx     3598 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/onlinescoring/score_managedidentity.py
+-rw-rw-r--  2.0 unx     1273 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/onlinescoring/score.py
+-rw-rw-r--  2.0 unx      961 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/endpoint_scoring/main.py
+-rw-rw-r--  2.0 unx      103 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/endpoint_scoring/do_nothing.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/hello-component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/hello-component/src/
+-rw-rw-r--  2.0 unx       21 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/hello-component/src/hello.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-2/onlinescoring/
+-rw-rw-r--  2.0 unx     1003 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-2/onlinescoring/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-4/onlinescoring/
+-rw-rw-r--  2.0 unx      983 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-4/onlinescoring/cloud_score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/byoc/sklearn/
+-rw-rw-r--  2.0 unx     1019 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/byoc/sklearn/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/mnist/code/
+-rw-rw-r--  2.0 unx     1507 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/mnist/code/digit_identification.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-1/onlinescoring/
+-rw-rw-r--  2.0 unx     1019 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/deployments/model-1/onlinescoring/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/my_exp/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/
+-rw-rw-r--  2.0 unx     1443 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/basic_component.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/
+-rw-rw-r--  2.0 unx      457 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/sampleword.py
+-rw-rw-r--  2.0 unx      528 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/wordcount.py
+-rw-rw-r--  2.0 unx      299 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/my_exp/main.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/
+-rw-rw-r--  2.0 unx      523 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/score.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/
+-rw-rw-r--  2.0 unx      210 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/greet.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/
+-rw-rw-r--  2.0 unx     3055 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/preprocess.py
+-rw-rw-r--  2.0 unx     2047 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/register.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/
+-rw-rw-r--  2.0 unx      457 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/sampleword.py
+-rw-rw-r--  2.0 unx      528 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/wordcount.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/
+-rw-rw-r--  2.0 unx     3057 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/parallel_train.py
+-rw-rw-r--  2.0 unx     3552 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/partition_data.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/
+-rw-rw-r--  2.0 unx      210 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/greet.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/
+-rw-rw-r--  2.0 unx     3055 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/preprocess.py
+-rw-rw-r--  2.0 unx     2047 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/register.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/
+-rw-rw-r--  2.0 unx      457 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/sampleword.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/
+-rw-rw-r--  2.0 unx       28 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/hello.py
+-rw-rw-r--  2.0 unx     2295 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/training/train_mlflow.py
+-rw-rw-r--  2.0 unx      515 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/python/sweep_script.py
+-rw-rw-r--  2.0 unx     2797 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/python/sweep_script_search.py
+-rw-rw-r--  2.0 unx     1036 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/python/train.py
+-rw-rw-r--  2.0 unx     1010 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/python/simple_train.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/test_configs/spark_component/src/
+-rw-rw-r--  2.0 unx     1219 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_configs/spark_component/src/kmeans_example.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_store/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_store/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     2417 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store/e2etests/test_feature_store.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store/unittests/__init__.py
+-rw-rw-r--  2.0 unx     1104 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store/unittests/test_feature_store_schema.py
+-rw-rw-r--  2.0 unx     5038 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_store/unittests/test_feature_store_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/job_common/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/job_common/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/job_common/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/job_common/e2etests/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/job_common/unittests/__init__.py
+-rw-rw-r--  2.0 unx    22931 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/job_common/unittests/test_job_ops_helper.py
+-rw-rw-r--  2.0 unx      931 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/job_common/unittests/test_vcr_utils.py
+-rw-rw-r--  2.0 unx    13634 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/job_common/unittests/test_job_operations.py
+-rw-rw-r--  2.0 unx     2292 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/job_common/unittests/test_local_job_invoker.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/model/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/model/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/model/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/model/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    10116 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/model/e2etests/test_model.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/model/unittests/__init__.py
+-rw-rw-r--  2.0 unx     2993 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/model/unittests/test_model_schema.py
+-rw-rw-r--  2.0 unx    13574 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/model/unittests/test_model_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/data_import/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/data_import/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/data_import/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     2239 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/data_import/e2etests/test_schedule.py
+-rw-rw-r--  2.0 unx     1570 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/data_import/e2etests/test_data_import.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/data_import/unittests/__init__.py
+-rw-rw-r--  2.0 unx     2388 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/data_import/unittests/test_data_import.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/command_job/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/command_job/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/command_job/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/command_job/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    24391 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/command_job/e2etests/test_command_job.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/command_job/unittests/__init__.py
+-rw-rw-r--  2.0 unx    14240 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/command_job/unittests/test_command_job_schema.py
+-rw-rw-r--  2.0 unx     6719 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/command_job/unittests/test_command_job_entity.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/internal/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/internal/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/__init__.py
+-rw-rw-r--  2.0 unx    13541 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/_utils.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    17339 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/e2etests/test_pipeline_job.py
+-rw-rw-r--  2.0 unx     5215 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/e2etests/test_component.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/unittests/__init__.py
+-rw-rw-r--  2.0 unx     1309 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/unittests/test_internal_disabled.py
+-rw-rw-r--  2.0 unx    31544 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/unittests/test_pipeline_job.py
+-rw-rw-r--  2.0 unx    47267 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal/unittests/test_component.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/component/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/component/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/__init__.py
+-rw-rw-r--  2.0 unx       86 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/_util.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     2501 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/e2etests/test_component_validate.py
+-rw-rw-r--  2.0 unx     4398 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/e2etests/test_component_hash.py
+-rw-rw-r--  2.0 unx    49625 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/e2etests/test_component.py
+-rw-rw-r--  2.0 unx     1363 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/e2etests/test_component_without_mock.py
+-rw-rw-r--  2.0 unx     5131 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_entity.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/__init__.py
+-rw-rw-r--  2.0 unx     4923 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_spark_component_entity.py
+-rw-rw-r--  2.0 unx     5457 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_schema.py
+-rw-rw-r--  2.0 unx     9385 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_component_operations.py
+-rw-rw-r--  2.0 unx    23199 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_pipeline_component_entity.py
+-rw-rw-r--  2.0 unx     1811 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_automl_component.py
+-rw-rw-r--  2.0 unx    17778 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_component_schema.py
+-rw-rw-r--  2.0 unx     7514 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_component_validate.py
+-rw-rw-r--  2.0 unx    43639 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_command_component_entity.py
+-rw-rw-r--  2.0 unx     6571 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_component_operations_registry.py
+-rw-rw-r--  2.0 unx     7308 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_data_transfer_component_entity.py
+-rw-rw-r--  2.0 unx     5191 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/online_services/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/online_services/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     3909 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/e2etests/test_online_deployment.py
+-rw-rw-r--  2.0 unx    13667 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/e2etests/test_online_endpoint.py
+-rw-rw-r--  2.0 unx     1439 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_scale_settings.py
+-rw-rw-r--  2.0 unx     5638 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_online_deployments.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/__init__.py
+-rw-rw-r--  2.0 unx     1185 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_schema.py
+-rw-rw-r--  2.0 unx     1054 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_resource_requirements_settings.py
+-rw-rw-r--  2.0 unx     1754 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_operations.py
+-rw-rw-r--  2.0 unx     2704 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_scale_settings_schema.py
+-rw-rw-r--  2.0 unx     2701 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_executor.py
+-rw-rw-r--  2.0 unx    18249 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/online_services/unittests/test_online_endpoints.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/monitoring/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/monitoring/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/monitoring/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/monitoring/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    13204 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/monitoring/e2etests/test_monitor_schedule.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/monitoring/unittests/__init__.py
+-rw-rw-r--  2.0 unx     4449 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/monitoring/unittests/test_monitor_schedule.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/internal_utils/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/internal_utils/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/__init__.py
+-rw-rw-r--  2.0 unx       76 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/_util.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    19826 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/e2etests/test_upload_download.py
+-rw-rw-r--  2.0 unx      955 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/e2etests/test_telemetry_value.py
+-rw-rw-r--  2.0 unx     2405 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_logger_utils.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/__init__.py
+-rw-rw-r--  2.0 unx     3469 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_validation.py
+-rw-rw-r--  2.0 unx    22611 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_operation_orchestrator.py
+-rw-rw-r--  2.0 unx     9762 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_persistent_locals.py
+-rw-rw-r--  2.0 unx     6668 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_fields.py
+-rw-rw-r--  2.0 unx     9721 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_asset_utils.py
+-rw-rw-r--  2.0 unx     6301 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_telemetry_value.py
+-rw-rw-r--  2.0 unx     7061 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_experimental_utils.py
+-rw-rw-r--  2.0 unx      575 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_asset_entity.py
+-rw-rw-r--  2.0 unx     1397 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_file_utils.py
+-rw-rw-r--  2.0 unx     3451 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_exceptions.py
+-rw-rw-r--  2.0 unx    25206 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_ml_client.py
+-rw-rw-r--  2.0 unx      615 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_arm_id_utils.py
+-rw-rw-r--  2.0 unx     6985 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_cloud_environments.py
+-rw-rw-r--  2.0 unx     3307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_cache_utils.py
+-rw-rw-r--  2.0 unx    11626 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_storage_utils.py
+-rw-rw-r--  2.0 unx     1480 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_smoke.py
+-rw-rw-r--  2.0 unx     5564 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_utils.py
+-rw-rw-r--  2.0 unx     2357 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_get_content_hash.py
+-rw-rw-r--  2.0 unx      451 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_artifact_entity.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_set/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/feature_set/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_set/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_set/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     5348 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_set/e2etests/test_feature_set.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_set/unittests/__init__.py
+-rw-rw-r--  2.0 unx     2072 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_set/unittests/test_feature_set_schema.py
+-rw-rw-r--  2.0 unx     1474 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_set/unittests/test_list_materialization_job_request.py
+-rw-rw-r--  2.0 unx     7636 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/feature_set/unittests/test_feature_set_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/registry/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/registry/unittests/
+-rw-rw-r--  2.0 unx     4860 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/registry/e2etests/test_registry.py
+-rw-rw-r--  2.0 unx     6093 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_schema.py
+-rw-rw-r--  2.0 unx     2983 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_operations.py
+-rw-rw-r--  2.0 unx    14607 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_entity.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_utilities/__init__.py
+-rw-rw-r--  2.0 unx      170 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_utilities/constants.py
+-rw-rw-r--  2.0 unx     5555 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_utilities/json_schema.py
+-rw-rw-r--  2.0 unx    17769 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/test_utilities/utils.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/compute/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/compute/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/compute/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/compute/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     5392 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/compute/e2etests/test_compute.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/compute/unittests/__init__.py
+-rw-rw-r--  2.0 unx     4865 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/compute/unittests/test_compute_operations.py
+-rw-rw-r--  2.0 unx    19268 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/compute/unittests/test_compute_entity.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/datastore/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/datastore/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/datastore/__init__.py
+-rw-rw-r--  2.0 unx    12879 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/datastore/e2etests/test_datastore.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/datastore/e2etests/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/datastore/unittests/__init__.py
+-rw-rw-r--  2.0 unx    14420 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/datastore/unittests/test_datastore_schema.py
+-rw-rw-r--  2.0 unx     3390 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/datastore/unittests/test_datastore_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/dsl/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/dsl/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/__init__.py
+-rw-rw-r--  2.0 unx     2743 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/_util.py
+-rw-rw-r--  2.0 unx    15585 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_with_specific_nodes.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/__init__.py
+-rw-rw-r--  2.0 unx    36235 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/test_automl_dsl_pipeline.py
+-rw-rw-r--  2.0 unx    19621 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_samples.py
+-rw-rw-r--  2.0 unx    44729 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/test_controlflow_pipeline.py
+-rw-rw-r--  2.0 unx     4441 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_on_registry.py
+-rw-rw-r--  2.0 unx   157494 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline.py
+-rw-rw-r--  2.0 unx    10442 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_fl.py
+-rw-rw-r--  2.0 unx   126050 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_with_specific_nodes.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/__init__.py
+-rw-rw-r--  2.0 unx     2184 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_component.py
+-rw-rw-r--  2.0 unx     8357 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_init_finalize_job.py
+-rw-rw-r--  2.0 unx    20373 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_io_builder.py
+-rw-rw-r--  2.0 unx     8042 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_pipeline_builder.py
+-rw-rw-r--  2.0 unx    16163 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_component_func.py
+-rw-rw-r--  2.0 unx     3238 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_mldesigner_imports.py
+-rw-rw-r--  2.0 unx    48349 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_command_builder.py
+-rw-rw-r--  2.0 unx     3746 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_attr_dict.py
+-rw-rw-r--  2.0 unx    24561 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_samples.py
+-rw-rw-r--  2.0 unx    25199 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_group.py
+-rw-rw-r--  2.0 unx    32314 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_controlflow_pipeline.py
+-rw-rw-r--  2.0 unx   165655 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline.py
+-rw-rw-r--  2.0 unx    19998 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_fl.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/dataset/e2etests/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/tests/dataset/unittests/
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/e2etests/__init__.py
+-rw-rw-r--  2.0 unx     2630 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/e2etests/test_data_utils.py
+-rw-rw-r--  2.0 unx    13099 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/e2etests/test_data.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/unittests/__init__.py
+-rw-rw-r--  2.0 unx     4284 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_utils.py
+-rw-rw-r--  2.0 unx     4156 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_schema.py
+-rw-rw-r--  2.0 unx    25789 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_operations.py
+-rw-rw-r--  2.0 unx     2951 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/samples/ml_samples_authentication_sovereign_cloud.py
+-rw-rw-r--  2.0 unx    12322 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/samples/ml_samples_sweep_configurations.py
+-rw-rw-r--  2.0 unx     5860 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/samples/ml_samples_command_configurations.py
+-rw-rw-r--  2.0 unx     3738 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/samples/ml_samples_cloud_configurations.py
+-rw-rw-r--  2.0 unx    11790 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/samples/ml_samples_spark_configurations.py
+-rw-rw-r--  2.0 unx     1714 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/samples/README.md
+-rw-rw-r--  2.0 unx        1 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure_ai_ml.egg-info/dependency_links.txt
+-rw-rw-r--  2.0 unx      419 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure_ai_ml.egg-info/requires.txt
+-rw-rw-r--  2.0 unx    22757 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure_ai_ml.egg-info/PKG-INFO
+-rw-rw-r--  2.0 unx        6 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure_ai_ml.egg-info/top_level.txt
+-rw-rw-r--  2.0 unx        1 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure_ai_ml.egg-info/not-zip-safe
+-rw-rw-r--  2.0 unx   147578 b- defN 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure_ai_ml.egg-info/SOURCES.txt
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/
+-rw-rw-r--  2.0 unx      647 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/parallel/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/constants/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/identity/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_internal/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/data_transfer/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_file_utils/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_logging/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/sweep/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/dsl/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/automl/
+-rw-rw-r--  2.0 unx    42756 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_ml_client.py
+-rw-rw-r--  2.0 unx       27 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/py.typed
+-rw-rw-r--  2.0 unx     2004 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/__init__.py
+-rw-rw-r--  2.0 unx      199 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_version.py
+-rw-rw-r--  2.0 unx    12372 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_exception_helper.py
+-rw-rw-r--  2.0 unx     4850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_scope_dependent_operations.py
+-rw-rw-r--  2.0 unx    29905 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/exceptions.py
+-rw-rw-r--  2.0 unx      274 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_user_agent.py
+-rw-rw-r--  2.0 unx    12528 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_azure_environments.py
+-rw-rw-r--  2.0 unx      629 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/__init__.py
+-rw-rw-r--  2.0 unx    14406 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/activity.py
+-rw-rw-r--  2.0 unx     6600 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/_customtraceback.py
+-rw-rw-r--  2.0 unx     8860 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/logging_handler.py
+-rw-rw-r--  2.0 unx    19677 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_artifact_utilities.py
+-rw-rw-r--  2.0 unx      180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/__init__.py
+-rw-rw-r--  2.0 unx     9288 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_gen2_storage_helper.py
+-rw-rw-r--  2.0 unx    14216 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_fileshare_storage_helper.py
+-rw-rw-r--  2.0 unx     2774 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_constants.py
+-rw-rw-r--  2.0 unx    13137 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_blob_storage_helper.py
+-rw-rw-r--  2.0 unx      471 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/parallel/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/flatten_json/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/
+-rw-rw-r--  2.0 unx      676 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/__init__.py
+-rw-rw-r--  2.0 unx     4645 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/_resource_management_client.py
+-rw-rw-r--  2.0 unx     3285 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/
+-rw-rw-r--  2.0 unx      574 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/__init__.py
+-rw-rw-r--  2.0 unx     4586 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/_resource_management_client.py
+-rw-rw-r--  2.0 unx     3177 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/_configuration.py
+-rw-rw-r--  2.0 unx     1070 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    19624 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_providers_operations.py
+-rw-rw-r--  2.0 unx    28537 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resource_groups_operations.py
+-rw-rw-r--  2.0 unx    35924 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployment_operations_operations.py
+-rw-rw-r--  2.0 unx    75003 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resources_operations.py
+-rw-rw-r--  2.0 unx    26532 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_tags_operations.py
+-rw-rw-r--  2.0 unx     4637 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx   188818 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployments_operations.py
+-rw-rw-r--  2.0 unx     1070 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/__init__.py
+-rw-rw-r--  2.0 unx    20010 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_providers_operations.py
+-rw-rw-r--  2.0 unx    28988 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_resource_groups_operations.py
+-rw-rw-r--  2.0 unx    36554 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_deployment_operations_operations.py
+-rw-rw-r--  2.0 unx    76225 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_resources_operations.py
+-rw-rw-r--  2.0 unx    27135 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_tags_operations.py
+-rw-rw-r--  2.0 unx     4716 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_operations.py
+-rw-rw-r--  2.0 unx   192309 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_deployments_operations.py
+-rw-rw-r--  2.0 unx    16494 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/flatten_json/__init__.py
+-rw-rw-r--  2.0 unx    10329 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/__init__.py
+-rw-rw-r--  2.0 unx    90071 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_models_py3.py
+-rw-rw-r--  2.0 unx    83782 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_models.py
+-rw-rw-r--  2.0 unx     7315 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_resource_management_client_enums.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/
+-rw-rw-r--  2.0 unx     1389 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_registry.py
+-rw-rw-r--  2.0 unx      814 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_deployment.py
+-rw-rw-r--  2.0 unx     1747 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/__init__.py
+-rw-rw-r--  2.0 unx    34156 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_common.py
+-rw-rw-r--  2.0 unx      429 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_assets.py
+-rw-rw-r--  2.0 unx     2996 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_monitoring.py
+-rw-rw-r--  2.0 unx     2952 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_endpoint.py
+-rw-rw-r--  2.0 unx     1168 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_workspace.py
+-rw-rw-r--  2.0 unx     5595 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_compute.py
+-rw-rw-r--  2.0 unx     4185 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_component.py
+-rw-rw-r--  2.0 unx     1019 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/__init__.py
+-rw-rw-r--  2.0 unx     4161 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/automl.py
+-rw-rw-r--  2.0 unx      690 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/sweep.py
+-rw-rw-r--  2.0 unx     1685 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/pipeline.py
+-rw-rw-r--  2.0 unx     4590 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/job.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/
+-rw-rw-r--  2.0 unx      443 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/__init__.py
+-rw-rw-r--  2.0 unx      250 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_constants.py
+-rw-rw-r--  2.0 unx      408 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_exceptions.py
+-rw-rw-r--  2.0 unx      290 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/__init__.py
+-rw-rw-r--  2.0 unx     4226 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/_AzureMLSparkOnBehalfOfCredential.py
+-rw-rw-r--  2.0 unx     3073 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/aml_on_behalf_of.py
+-rw-rw-r--  2.0 unx     1176 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/__init__.py
+-rw-rw-r--  2.0 unx     3817 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/get_token_mixin.py
+-rw-rw-r--  2.0 unx     2089 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/managed_identity_base.py
+-rw-rw-r--  2.0 unx     5108 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/managed_identity_client.py
+-rw-rw-r--  2.0 unx     2585 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/pipeline.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_credentials/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/
+-rw-rw-r--  2.0 unx      180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/__init__.py
+-rw-rw-r--  2.0 unx      180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_credentials/__init__.py
+-rw-rw-r--  2.0 unx     2861 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_credentials/aml_on_behalf_of.py
+-rw-rw-r--  2.0 unx      448 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/__init__.py
+-rw-rw-r--  2.0 unx     3656 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/get_token_mixin.py
+-rw-rw-r--  2.0 unx     2094 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/managed_identity_base.py
+-rw-rw-r--  2.0 unx     1637 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/managed_identity_client.py
+-rw-rw-r--  2.0 unx    23666 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_operation_orchestrator.py
+-rw-rw-r--  2.0 unx     2061 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/__init__.py
+-rw-rw-r--  2.0 unx     4676 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx     1352 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_dataset_dataplane_operations.py
+-rw-rw-r--  2.0 unx    19579 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_job_ops_helper.py
+-rw-rw-r--  2.0 unx     9794 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_code_operations.py
+-rw-rw-r--  2.0 unx     6511 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_registry_operations.py
+-rw-rw-r--  2.0 unx     7487 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_datastore_operations.py
+-rw-rw-r--  2.0 unx     3206 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_run_history_constants.py
+-rw-rw-r--  2.0 unx    28021 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_data_operations.py
+-rw-rw-r--  2.0 unx    14000 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_batch_deployment_operations.py
+-rw-rw-r--  2.0 unx     6973 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_virtual_cluster_operations.py
+-rw-rw-r--  2.0 unx    10459 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_operations.py
+-rw-rw-r--  2.0 unx    19208 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_environment_operations.py
+-rw-rw-r--  2.0 unx    16410 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_deployment_helper.py
+-rw-rw-r--  2.0 unx    17750 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_job_invoker.py
+-rw-rw-r--  2.0 unx     8718 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_endpoint_helper.py
+-rw-rw-r--  2.0 unx    42654 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_component_operations.py
+-rw-rw-r--  2.0 unx    27665 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_model_operations.py
+-rw-rw-r--  2.0 unx    60744 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_job_operations.py
+-rw-rw-r--  2.0 unx     1346 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_model_dataplane_operations.py
+-rw-rw-r--  2.0 unx    20537 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_online_endpoint_operations.py
+-rw-rw-r--  2.0 unx     3165 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_run_operations.py
+-rw-rw-r--  2.0 unx    20920 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_schedule_operations.py
+-rw-rw-r--  2.0 unx    18244 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_set_operations.py
+-rw-rw-r--  2.0 unx    11543 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    25437 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_operations_base.py
+-rw-rw-r--  2.0 unx    19791 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_store_operations.py
+-rw-rw-r--  2.0 unx     7667 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_store_entity_operations.py
+-rw-rw-r--  2.0 unx    20779 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_batch_endpoint_operations.py
+-rw-rw-r--  2.0 unx     3954 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_outbound_rule_operations.py
+-rw-rw-r--  2.0 unx    19397 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/operations/_online_deployment_operations.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/
+-rw-rw-r--  2.0 unx      693 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/__init__.py
+-rw-rw-r--  2.0 unx    95488 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      344 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_version.py
+-rw-rw-r--  2.0 unx      648 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/models.py
+-rw-rw-r--  2.0 unx     3307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_patch.py
+-rw-rw-r--  2.0 unx    11928 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_vendor.py
+-rw-rw-r--  2.0 unx     3337 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_patch.py
+-rw-rw-r--  2.0 unx    11990 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3286 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_configuration.py
+-rw-rw-r--  2.0 unx     3023 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    14310 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    29676 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx     5298 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    14288 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    15041 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    13712 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    15270 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     4498 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    22339 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    16361 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    14307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    14160 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    28707 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     7774 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14016 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    14689 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    15553 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     4874 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx     4167 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    39693 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    47005 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    14317 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    17571 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    55593 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx     5679 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    36355 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx     3023 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/__init__.py
+-rw-rw-r--  2.0 unx    21001 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    39697 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx     6558 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    20924 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    22469 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    20074 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    22704 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6080 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    30720 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    24869 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    21095 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    20790 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    38245 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    10444 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    20627 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    21849 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    23127 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5716 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_operations.py
+-rw-rw-r--  2.0 unx     5525 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    53990 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    63093 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    20939 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    26858 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    75627 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx     7141 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    49836 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    49054 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/__init__.py
+-rw-rw-r--  2.0 unx    22305 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx   682901 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_models_py3.py
+-rw-rw-r--  2.0 unx   640114 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_patch.py
+-rw-rw-r--  2.0 unx     8556 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_vendor.py
+-rw-rw-r--  2.0 unx     3650 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_patch.py
+-rw-rw-r--  2.0 unx     8536 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3547 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_configuration.py
+-rw-rw-r--  2.0 unx     5616 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_temporary_data_references_operations.py
+-rw-rw-r--  2.0 unx     1889 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx     5440 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_references_operations.py
+-rw-rw-r--  2.0 unx    15307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    18855 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14635 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    19491 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    26959 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    18952 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    14800 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    14973 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    18745 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    19756 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     9395 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_resource_management_asset_reference_operations.py
+-rw-rw-r--  2.0 unx     7717 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_temporary_data_references_operations.py
+-rw-rw-r--  2.0 unx     1889 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/__init__.py
+-rw-rw-r--  2.0 unx     7541 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_references_operations.py
+-rw-rw-r--  2.0 unx    22239 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    26317 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21365 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    27382 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    37349 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    25920 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21505 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    21920 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    26192 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    27617 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx    11185 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_resource_management_asset_reference_operations.py
+-rw-rw-r--  2.0 unx    20313 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/__init__.py
+-rw-rw-r--  2.0 unx     6896 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx   274942 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models_py3.py
+-rw-rw-r--  2.0 unx   254311 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_patch.py
+-rw-rw-r--  2.0 unx     4123 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_vendor.py
+-rw-rw-r--  2.0 unx     3004 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_patch.py
+-rw-rw-r--  2.0 unx     4082 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     2961 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_configuration.py
+-rw-rw-r--  2.0 unx     3630 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_async_operations_operations.py
+-rw-rw-r--  2.0 unx      732 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx     4050 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_registry_management_non_workspace_operations.py
+-rw-rw-r--  2.0 unx     4296 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/_async_operations_operations.py
+-rw-rw-r--  2.0 unx      732 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/__init__.py
+-rw-rw-r--  2.0 unx     4969 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/_registry_management_non_workspace_operations.py
+-rw-rw-r--  2.0 unx     1291 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/__init__.py
+-rw-rw-r--  2.0 unx    13501 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/_models_py3.py
+-rw-rw-r--  2.0 unx    12342 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_patch.py
+-rw-rw-r--  2.0 unx     5590 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_vendor.py
+-rw-rw-r--  2.0 unx     3052 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_patch.py
+-rw-rw-r--  2.0 unx     5578 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3009 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_configuration.py
+-rw-rw-r--  2.0 unx     1083 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    39025 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_metric_operations.py
+-rw-rw-r--  2.0 unx    55228 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_artifacts_operations.py
+-rw-rw-r--  2.0 unx     7660 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_delete_operations.py
+-rw-rw-r--  2.0 unx   115528 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_runs_operations.py
+-rw-rw-r--  2.0 unx    13305 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_spans_operations.py
+-rw-rw-r--  2.0 unx    27292 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_experiments_operations.py
+-rw-rw-r--  2.0 unx     7855 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_operations.py
+-rw-rw-r--  2.0 unx    20580 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_events_operations.py
+-rw-rw-r--  2.0 unx     1083 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/__init__.py
+-rw-rw-r--  2.0 unx    51983 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_metric_operations.py
+-rw-rw-r--  2.0 unx    80722 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_run_artifacts_operations.py
+-rw-rw-r--  2.0 unx    10429 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_delete_operations.py
+-rw-rw-r--  2.0 unx   169474 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_runs_operations.py
+-rw-rw-r--  2.0 unx    18266 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_spans_operations.py
+-rw-rw-r--  2.0 unx    37464 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_experiments_operations.py
+-rw-rw-r--  2.0 unx    10619 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_run_operations.py
+-rw-rw-r--  2.0 unx    29980 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_events_operations.py
+-rw-rw-r--  2.0 unx    12026 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/__init__.py
+-rw-rw-r--  2.0 unx     2392 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx   189590 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_models_py3.py
+-rw-rw-r--  2.0 unx   175831 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_patch.py
+-rw-rw-r--  2.0 unx    16922 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_vendor.py
+-rw-rw-r--  2.0 unx     3663 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_patch.py
+-rw-rw-r--  2.0 unx    17041 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3612 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_configuration.py
+-rw-rw-r--  2.0 unx    21545 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21069 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23033 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    22129 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     4585 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    15231 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    31205 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    21112 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    21009 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_settings_rule_operations.py
+-rw-rw-r--  2.0 unx    22459 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    33187 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    23557 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     5490 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    15153 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    15906 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14570 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    16135 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     4692 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    24200 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    17226 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    15172 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    15025 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    30121 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     8239 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14881 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx     8900 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_provisions_operations.py
+-rw-rw-r--  2.0 unx    21359 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    15547 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    16418 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx    21893 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     4361 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    41810 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    56352 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    15238 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    18632 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    59283 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    29620 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     5871 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    38114 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    28554 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    27797 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    31024 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    29696 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     4585 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/__init__.py
+-rw-rw-r--  2.0 unx    22292 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    41762 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    28084 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    27715 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_settings_rule_operations.py
+-rw-rw-r--  2.0 unx    30150 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    45578 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    32157 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     6914 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    22159 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    23706 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21301 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23941 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6367 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    33448 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    26112 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    22331 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    22025 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    40122 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    11094 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    21862 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    10754 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_provisions_operations.py
+-rw-rw-r--  2.0 unx    28186 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    23078 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    24365 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     6035 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_operations.py
+-rw-rw-r--  2.0 unx    29010 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     5812 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    56850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    77082 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    22229 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    28387 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    80606 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    38892 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     7497 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    52243 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    70920 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/__init__.py
+-rw-rw-r--  2.0 unx    56630 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx  1193595 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models_py3.py
+-rw-rw-r--  2.0 unx  1106044 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models.py
+-rw-rw-r--  2.0 unx      592 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/__init__.py
+-rw-rw-r--  2.0 unx    97359 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3264 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_patch.py
+-rw-rw-r--  2.0 unx     5870 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_vendor.py
+-rw-rw-r--  2.0 unx     3004 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_patch.py
+-rw-rw-r--  2.0 unx     5858 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     2961 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_configuration.py
+-rw-rw-r--  2.0 unx    35004 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_version_operations.py
+-rw-rw-r--  2.0 unx     1214 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    37442 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_datasets_v1_operations.py
+-rw-rw-r--  2.0 unx    25817 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_v2_operations.py
+-rw-rw-r--  2.0 unx     4594 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_delete_operations.py
+-rw-rw-r--  2.0 unx     8427 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_get_operation_status_operations.py
+-rw-rw-r--  2.0 unx    11030 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_call_operations.py
+-rw-rw-r--  2.0 unx    14473 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_container_operations.py
+-rw-rw-r--  2.0 unx    37470 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_controller_v2_operations.py
+-rw-rw-r--  2.0 unx    50561 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_version_operations.py
+-rw-rw-r--  2.0 unx     1214 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/__init__.py
+-rw-rw-r--  2.0 unx    57331 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_datasets_v1_operations.py
+-rw-rw-r--  2.0 unx    38056 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_v2_operations.py
+-rw-rw-r--  2.0 unx     6000 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_delete_operations.py
+-rw-rw-r--  2.0 unx     9828 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_get_operation_status_operations.py
+-rw-rw-r--  2.0 unx    15249 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_call_operations.py
+-rw-rw-r--  2.0 unx    19656 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_container_operations.py
+-rw-rw-r--  2.0 unx    57349 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_controller_v2_operations.py
+-rw-rw-r--  2.0 unx     7806 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/__init__.py
+-rw-rw-r--  2.0 unx     4166 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx   104034 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models_py3.py
+-rw-rw-r--  2.0 unx    96571 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_patch.py
+-rw-rw-r--  2.0 unx    16129 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_vendor.py
+-rw-rw-r--  2.0 unx     3663 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_patch.py
+-rw-rw-r--  2.0 unx    16240 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3612 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_configuration.py
+-rw-rw-r--  2.0 unx    21545 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21069 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23033 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    22129 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     4320 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    15231 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    31205 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    21112 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    22459 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    33201 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    23557 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     5490 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    15153 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    15906 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14570 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    16135 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     4692 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    24200 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    17226 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    15172 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    15025 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    30121 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     8239 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14881 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    21359 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    15547 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    16418 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx    21893 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     4361 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    41810 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    56352 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    15238 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    18632 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    59283 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    26496 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     5871 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    38114 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    28554 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    27797 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    31024 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    29696 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     4320 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/__init__.py
+-rw-rw-r--  2.0 unx    22292 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    41762 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    28084 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    30150 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    45603 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    32157 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     6914 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    22159 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    23706 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21301 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23941 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6367 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    33448 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    26112 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    22331 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    22025 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    40122 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    11094 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    21862 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    28186 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    23078 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    24365 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     6035 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_operations.py
+-rw-rw-r--  2.0 unx    29010 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     5812 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    56850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    77082 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    22229 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    28387 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    80606 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    35738 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     7497 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    52243 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    68867 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/__init__.py
+-rw-rw-r--  2.0 unx    54122 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx  1149677 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models_py3.py
+-rw-rw-r--  2.0 unx  1066789 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_patch.py
+-rw-rw-r--  2.0 unx    19439 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_vendor.py
+-rw-rw-r--  2.0 unx     3663 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_patch.py
+-rw-rw-r--  2.0 unx    19586 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3612 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_configuration.py
+-rw-rw-r--  2.0 unx    21658 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21212 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23146 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    25862 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     5406 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    21431 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    15231 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    31308 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    21215 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    21009 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_settings_rule_operations.py
+-rw-rw-r--  2.0 unx    36020 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_versions_operations.py
+-rw-rw-r--  2.0 unx    22739 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    23058 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_containers_operations.py
+-rw-rw-r--  2.0 unx    33245 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    27290 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     5490 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    15153 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    16073 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14570 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    16135 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     4692 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    27543 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    24217 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    22778 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_containers_operations.py
+-rw-rw-r--  2.0 unx    15172 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    15025 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    30224 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     8239 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14881 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx     8900 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_provisions_operations.py
+-rw-rw-r--  2.0 unx    10483 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_features_operations.py
+-rw-rw-r--  2.0 unx    21472 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    19605 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    16580 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx    24187 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_versions_operations.py
+-rw-rw-r--  2.0 unx    22006 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     4361 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    41913 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    56352 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    15238 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    18632 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    59901 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    26710 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    32380 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     5871 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    38217 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    28898 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    28218 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    31415 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    35799 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     5406 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/__init__.py
+-rw-rw-r--  2.0 unx    28524 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    22472 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    42135 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    28367 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    27895 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_settings_rule_operations.py
+-rw-rw-r--  2.0 unx    49845 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_versions_operations.py
+-rw-rw-r--  2.0 unx    30926 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    31163 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_containers_operations.py
+-rw-rw-r--  2.0 unx    45951 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    38266 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     6914 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    22339 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    24224 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21481 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    24121 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6412 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    39050 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    35452 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    30856 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_containers_operations.py
+-rw-rw-r--  2.0 unx    22511 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    22205 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    40450 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    11094 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    22042 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    10799 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_provisions_operations.py
+-rw-rw-r--  2.0 unx    15303 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_features_operations.py
+-rw-rw-r--  2.0 unx    28577 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    29672 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    24878 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     6035 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_operations.py
+-rw-rw-r--  2.0 unx    33160 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_versions_operations.py
+-rw-rw-r--  2.0 unx    29401 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     5812 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    57313 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    77622 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    22409 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    28612 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    82325 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    36768 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    43119 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     7542 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    52661 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    89964 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/__init__.py
+-rw-rw-r--  2.0 unx    68052 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx  1465971 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models_py3.py
+-rw-rw-r--  2.0 unx  1359041 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_patch.py
+-rw-rw-r--  2.0 unx    12428 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_vendor.py
+-rw-rw-r--  2.0 unx     3647 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_patch.py
+-rw-rw-r--  2.0 unx    12494 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3596 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_configuration.py
+-rw-rw-r--  2.0 unx     3105 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    15199 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    31133 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    21064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx     5482 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    15121 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    15874 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14538 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    16103 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     4684 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    23675 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    17194 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    15140 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    14993 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    30057 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     8223 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14849 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    15515 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    16386 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5058 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx     4353 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    41714 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    49956 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    15206 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    18592 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    59123 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx     5863 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    38034 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx     3105 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/__init__.py
+-rw-rw-r--  2.0 unx    22228 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    41642 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    28004 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx     6898 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    22095 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    23642 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21237 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23877 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6351 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    32480 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    26048 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    22267 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21961 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    40018 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    11062 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    21798 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    23014 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    24301 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     6021 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_operations.py
+-rw-rw-r--  2.0 unx     5796 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    56690 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    66885 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    22165 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    28307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    80334 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx     7481 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    52107 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    57995 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/__init__.py
+-rw-rw-r--  2.0 unx    49846 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx   965813 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_models_py3.py
+-rw-rw-r--  2.0 unx   894487 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_patch.py
+-rw-rw-r--  2.0 unx    19439 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_vendor.py
+-rw-rw-r--  2.0 unx     3663 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_patch.py
+-rw-rw-r--  2.0 unx    19586 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3612 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_configuration.py
+-rw-rw-r--  2.0 unx    21649 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21203 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23393 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    25853 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     5406 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    21422 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    22448 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    31299 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    21206 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    21394 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_managed_network_settings_rule_operations.py
+-rw-rw-r--  2.0 unx    36011 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featureset_versions_operations.py
+-rw-rw-r--  2.0 unx    22730 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    23049 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featurestore_entity_containers_operations.py
+-rw-rw-r--  2.0 unx    33236 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    34030 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     5490 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    15153 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    16073 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14570 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    16391 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6857 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    27543 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    24217 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    22769 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featureset_containers_operations.py
+-rw-rw-r--  2.0 unx    15172 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    15025 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    30215 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     8239 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14881 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx     9031 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_managed_network_provisions_operations.py
+-rw-rw-r--  2.0 unx    10483 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_features_operations.py
+-rw-rw-r--  2.0 unx    21463 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    19605 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    16580 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5157 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx    24178 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featurestore_entity_versions_operations.py
+-rw-rw-r--  2.0 unx    21997 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     4361 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    41904 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    56352 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    15299 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    18632 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    61950 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    26701 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    32380 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     5871 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    38208 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    28936 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    28209 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    31880 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    35790 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     5406 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/__init__.py
+-rw-rw-r--  2.0 unx    28515 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    33512 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    42126 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    28358 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    28280 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_managed_network_settings_rule_operations.py
+-rw-rw-r--  2.0 unx    49533 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featureset_versions_operations.py
+-rw-rw-r--  2.0 unx    30917 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    31154 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featurestore_entity_containers_operations.py
+-rw-rw-r--  2.0 unx    45942 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    47054 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     6914 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    22339 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    24224 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21481 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    24548 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     8536 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    39050 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    35452 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    30847 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featureset_containers_operations.py
+-rw-rw-r--  2.0 unx    22511 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    22205 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    40441 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    11094 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    22042 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    10930 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_managed_network_provisions_operations.py
+-rw-rw-r--  2.0 unx    15303 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_features_operations.py
+-rw-rw-r--  2.0 unx    28568 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    29672 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    24878 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     6128 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_operations.py
+-rw-rw-r--  2.0 unx    33151 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featurestore_entity_versions_operations.py
+-rw-rw-r--  2.0 unx    29392 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     5812 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    57304 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    77622 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    22470 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    28612 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    84375 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    36759 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    43119 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     7542 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    52652 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    93069 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/__init__.py
+-rw-rw-r--  2.0 unx    70696 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx  1512198 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/_models_py3.py
+-rw-rw-r--  2.0 unx  1402091 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_patch.py
+-rw-rw-r--  2.0 unx    16559 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_vendor.py
+-rw-rw-r--  2.0 unx     3647 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_patch.py
+-rw-rw-r--  2.0 unx    16669 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3596 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_configuration.py
+-rw-rw-r--  2.0 unx    21601 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21155 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23089 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    25797 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     4468 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    21374 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    15199 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    31227 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    21158 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    22515 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    27225 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     5482 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    15121 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    15874 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14538 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    16103 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     4684 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    23720 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    17194 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    15140 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    14993 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    30151 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     8223 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14849 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    21415 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    19565 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    16386 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5058 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx    21949 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     4353 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    41808 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    49956 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    15206 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    18592 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    59123 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    26645 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    32300 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     5863 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    38128 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    28856 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    28129 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    31373 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    35694 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     4468 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/__init__.py
+-rw-rw-r--  2.0 unx    28435 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    22408 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    42006 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    28278 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    30499 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    38161 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     6898 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    22275 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    23822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21417 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    24057 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6396 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    32750 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    26228 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    22447 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    22141 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    40337 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    11062 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    21978 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    28488 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    29592 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    24481 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     6021 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_operations.py
+-rw-rw-r--  2.0 unx    29312 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     5796 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    57144 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    67335 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    22345 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    28532 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    80874 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    36663 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    42983 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     7526 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    52516 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    63652 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/__init__.py
+-rw-rw-r--  2.0 unx    51786 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx  1046338 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_models_py3.py
+-rw-rw-r--  2.0 unx   969264 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/
+-rw-rw-r--  2.0 unx      876 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/__init__.py
+-rw-rw-r--  2.0 unx     1530 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_patch.py
+-rw-rw-r--  2.0 unx    19172 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_version.py
+-rw-rw-r--  2.0 unx     1169 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_vendor.py
+-rw-rw-r--  2.0 unx     3685 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/
+-rw-rw-r--  2.0 unx      824 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1530 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_patch.py
+-rw-rw-r--  2.0 unx    19277 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3582 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_configuration.py
+-rw-rw-r--  2.0 unx    21314 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    20726 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    22778 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    21874 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     5062 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    20997 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    15001 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    30968 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    20881 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    42257 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_versions_operations.py
+-rw-rw-r--  2.0 unx    22204 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    22015 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_containers_operations.py
+-rw-rw-r--  2.0 unx    32629 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    23302 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     5380 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    14871 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    15608 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    14216 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    15837 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     4639 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    24022 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    23508 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    21752 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_containers_operations.py
+-rw-rw-r--  2.0 unx    14850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    14743 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    29944 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx     8058 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    14559 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    21096 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    15249 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    16120 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     4962 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx    22676 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_versions_operations.py
+-rw-rw-r--  2.0 unx    21662 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     4302 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    41441 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    55439 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    14932 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    18252 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    58121 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    22756 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    29123 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     5767 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    37791 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    28397 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_containers_operations.py
+-rw-rw-r--  2.0 unx    27640 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_containers_operations.py
+-rw-rw-r--  2.0 unx    30867 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    29539 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_versions_operations.py
+-rw-rw-r--  2.0 unx     5062 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/__init__.py
+-rw-rw-r--  2.0 unx    28060 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_containers_operations.py
+-rw-rw-r--  2.0 unx    22104 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx    41623 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    28021 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_schedules_operations.py
+-rw-rw-r--  2.0 unx    58390 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_versions_operations.py
+-rw-rw-r--  2.0 unx    29993 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_versions_operations.py
+-rw-rw-r--  2.0 unx    29250 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_containers_operations.py
+-rw-rw-r--  2.0 unx    45274 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_labeling_jobs_operations.py
+-rw-rw-r--  2.0 unx    32000 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_versions_operations.py
+-rw-rw-r--  2.0 unx     6833 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx    21919 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    23466 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    21061 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    23701 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx     6337 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    33658 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    34497 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    28960 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_containers_operations.py
+-rw-rw-r--  2.0 unx    22091 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    21785 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    40039 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    10966 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx    21622 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    28029 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_containers_operations.py
+-rw-rw-r--  2.0 unx    22838 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    24125 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx     5946 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_operations.py
+-rw-rw-r--  2.0 unx    30402 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_versions_operations.py
+-rw-rw-r--  2.0 unx    28853 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_containers_operations.py
+-rw-rw-r--  2.0 unx     5782 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    56603 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    76435 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    21989 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    28091 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    79788 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx    30754 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_versions_operations.py
+-rw-rw-r--  2.0 unx    38525 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registries_operations.py
+-rw-rw-r--  2.0 unx     7416 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    52006 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    76305 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/__init__.py
+-rw-rw-r--  2.0 unx    57370 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx  1259260 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models_py3.py
+-rw-rw-r--  2.0 unx  1157391 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_patch.py
+-rw-rw-r--  2.0 unx     4457 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_vendor.py
+-rw-rw-r--  2.0 unx     3004 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_patch.py
+-rw-rw-r--  2.0 unx     4424 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     2961 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_configuration.py
+-rw-rw-r--  2.0 unx      809 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    36859 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_models_operations.py
+-rw-rw-r--  2.0 unx    15975 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_assets_operations.py
+-rw-rw-r--  2.0 unx     4016 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_migration_operations.py
+-rw-rw-r--  2.0 unx     4341 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_extensive_model_operations.py
+-rw-rw-r--  2.0 unx      809 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/__init__.py
+-rw-rw-r--  2.0 unx    55242 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_models_operations.py
+-rw-rw-r--  2.0 unx    24220 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_assets_operations.py
+-rw-rw-r--  2.0 unx     5385 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_migration_operations.py
+-rw-rw-r--  2.0 unx     5747 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_extensive_model_operations.py
+-rw-rw-r--  2.0 unx     7571 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/__init__.py
+-rw-rw-r--  2.0 unx     2539 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx    85714 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_models_py3.py
+-rw-rw-r--  2.0 unx    78857 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_patch.py
+-rw-rw-r--  2.0 unx     4462 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_vendor.py
+-rw-rw-r--  2.0 unx     3681 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_patch.py
+-rw-rw-r--  2.0 unx     4413 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3630 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_configuration.py
+-rw-rw-r--  2.0 unx      699 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    13384 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_deployment_operations.py
+-rw-rw-r--  2.0 unx    12992 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_endpoint_operations.py
+-rw-rw-r--  2.0 unx      699 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/__init__.py
+-rw-rw-r--  2.0 unx    19353 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_deployment_operations.py
+-rw-rw-r--  2.0 unx    18740 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_endpoint_operations.py
+-rw-rw-r--  2.0 unx     5396 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/__init__.py
+-rw-rw-r--  2.0 unx     3169 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx    68366 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models_py3.py
+-rw-rw-r--  2.0 unx    64673 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_patch.py
+-rw-rw-r--  2.0 unx     8789 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_vendor.py
+-rw-rw-r--  2.0 unx     3345 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_patch.py
+-rw-rw-r--  2.0 unx     8811 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3294 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_configuration.py
+-rw-rw-r--  2.0 unx     2073 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    29676 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    14288 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    15041 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    13712 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    15270 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    20057 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    16361 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    14307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    14160 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    28707 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    14016 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    14689 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    15553 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx    39693 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    17571 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    36355 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx     2073 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/__init__.py
+-rw-rw-r--  2.0 unx    39745 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_endpoints_operations.py
+-rw-rw-r--  2.0 unx    20956 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_containers_operations.py
+-rw-rw-r--  2.0 unx    22501 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_versions_operations.py
+-rw-rw-r--  2.0 unx    20106 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_containers_operations.py
+-rw-rw-r--  2.0 unx    22736 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_versions_operations.py
+-rw-rw-r--  2.0 unx    28887 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_jobs_operations.py
+-rw-rw-r--  2.0 unx    24901 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_versions_operations.py
+-rw-rw-r--  2.0 unx    21127 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_containers_operations.py
+-rw-rw-r--  2.0 unx    20822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_containers_operations.py
+-rw-rw-r--  2.0 unx    38285 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_deployments_operations.py
+-rw-rw-r--  2.0 unx    20659 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_containers_operations.py
+-rw-rw-r--  2.0 unx    21881 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_versions_operations.py
+-rw-rw-r--  2.0 unx    23159 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_versions_operations.py
+-rw-rw-r--  2.0 unx    54054 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py
+-rw-rw-r--  2.0 unx    26898 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_datastores_operations.py
+-rw-rw-r--  2.0 unx    49892 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py
+-rw-rw-r--  2.0 unx    38536 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/__init__.py
+-rw-rw-r--  2.0 unx    37207 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx   698083 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models_py3.py
+-rw-rw-r--  2.0 unx   643720 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/
+-rw-rw-r--  2.0 unx      875 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_patch.py
+-rw-rw-r--  2.0 unx     6863 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_version.py
+-rw-rw-r--  2.0 unx     1197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_vendor.py
+-rw-rw-r--  2.0 unx     3345 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/__init__.py
+-rw-rw-r--  2.0 unx     1529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_patch.py
+-rw-rw-r--  2.0 unx     6846 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_azure_machine_learning_workspaces.py
+-rw-rw-r--  2.0 unx     3294 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_configuration.py
+-rw-rw-r--  2.0 unx     1433 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx    14310 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx     5180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx     4384 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx     7774 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx     4850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_operations.py
+-rw-rw-r--  2.0 unx     4053 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    47000 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    14317 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    55593 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx     5679 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx     1433 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/__init__.py
+-rw-rw-r--  2.0 unx    21033 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_connections_operations.py
+-rw-rw-r--  2.0 unx     6448 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_usages_operations.py
+-rw-rw-r--  2.0 unx     5974 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_link_resources_operations.py
+-rw-rw-r--  2.0 unx    10460 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_quotas_operations.py
+-rw-rw-r--  2.0 unx     5700 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_operations.py
+-rw-rw-r--  2.0 unx     5419 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_virtual_machine_sizes_operations.py
+-rw-rw-r--  2.0 unx    63168 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_compute_operations.py
+-rw-rw-r--  2.0 unx    20971 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_endpoint_connections_operations.py
+-rw-rw-r--  2.0 unx    75739 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspaces_operations.py
+-rw-rw-r--  2.0 unx     7149 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_features_operations.py
+-rw-rw-r--  2.0 unx    22447 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/__init__.py
+-rw-rw-r--  2.0 unx    11749 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_azure_machine_learning_workspaces_enums.py
+-rw-rw-r--  2.0 unx   296235 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models_py3.py
+-rw-rw-r--  2.0 unx   278877 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_utils/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_internal/dsl/
+-rw-rw-r--  2.0 unx     1311 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/__init__.py
+-rw-rw-r--  2.0 unx     3421 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_setup.py
+-rw-rw-r--  2.0 unx      289 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_utils/__init__.py
+-rw-rw-r--  2.0 unx     2507 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_utils/_yaml_utils.py
+-rw-rw-r--  2.0 unx      713 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/environment.py
+-rw-rw-r--  2.0 unx      180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/__init__.py
+-rw-rw-r--  2.0 unx     2646 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/node.py
+-rw-rw-r--  2.0 unx     2614 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/input_output.py
+-rw-rw-r--  2.0 unx     1879 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/command.py
+-rw-rw-r--  2.0 unx     8396 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/component.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/
+-rw-rw-r--  2.0 unx     6652 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/environment.py
+-rw-rw-r--  2.0 unx     1307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/__init__.py
+-rw-rw-r--  2.0 unx     3295 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/scope.py
+-rw-rw-r--  2.0 unx     1570 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/code.py
+-rw-rw-r--  2.0 unx     9985 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/node.py
+-rw-rw-r--  2.0 unx     6735 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/spark.py
+-rw-rw-r--  2.0 unx     5668 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_input_outputs.py
+-rw-rw-r--  2.0 unx     3469 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/parallel.py
+-rw-rw-r--  2.0 unx      984 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_additional_includes.py
+-rw-rw-r--  2.0 unx     6420 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/command.py
+-rw-rw-r--  2.0 unx    14209 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/component.py
+-rw-rw-r--  2.0 unx     6717 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_merkle_tree.py
+-rw-rw-r--  2.0 unx      868 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/__init__.py
+-rw-rw-r--  2.0 unx     5411 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/itp_configuration.py
+-rw-rw-r--  2.0 unx     2052 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/target_selector.py
+-rw-rw-r--  2.0 unx     9154 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/ai_super_computer_configuration.py
+-rw-rw-r--  2.0 unx      269 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_internal/dsl/__init__.py
+-rw-rw-r--  2.0 unx      961 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/data_transfer/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/__init__.py
+-rw-rw-r--  2.0 unx     1105 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_logger_utils.py
+-rw-rw-r--  2.0 unx     5546 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_html_utils.py
+-rw-rw-r--  2.0 unx     1625 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_azureml_polling.py
+-rw-rw-r--  2.0 unx     4184 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_feature_store_utils.py
+-rw-rw-r--  2.0 unx     7591 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_storage_utils.py
+-rw-rw-r--  2.0 unx    16585 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_func_utils.py
+-rw-rw-r--  2.0 unx     3778 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_experimental.py
+-rw-rw-r--  2.0 unx    18537 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_cache_utils.py
+-rw-rw-r--  2.0 unx    40741 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_asset_utils.py
+-rw-rw-r--  2.0 unx     3194 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/azure_resource_utils.py
+-rw-rw-r--  2.0 unx     2659 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_package_utils.py
+-rw-rw-r--  2.0 unx     7049 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_registry_utils.py
+-rw-rw-r--  2.0 unx     2487 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_workspace_utils.py
+-rw-rw-r--  2.0 unx     8967 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_endpoint_utils.py
+-rw-rw-r--  2.0 unx     6519 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_http_utils.py
+-rw-rw-r--  2.0 unx     1064 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_preflight_utils.py
+-rw-rw-r--  2.0 unx    17142 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_arm_id_utils.py
+-rw-rw-r--  2.0 unx    16270 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_artifact_utils.py
+-rw-rw-r--  2.0 unx    22470 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_pathspec.py
+-rw-rw-r--  2.0 unx     3322 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_data_utils.py
+-rw-rw-r--  2.0 unx    36604 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/utils.py
+-rw-rw-r--  2.0 unx      560 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_appinsights_utils.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/
+-rw-rw-r--  2.0 unx     1998 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/
+-rw-rw-r--  2.0 unx      731 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/__init__.py
+-rw-rw-r--  2.0 unx     1531 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_patch.py
+-rw-rw-r--  2.0 unx      384 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_version.py
+-rw-rw-r--  2.0 unx      676 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_vendor.py
+-rw-rw-r--  2.0 unx     2918 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_configuration.py
+-rw-rw-r--  2.0 unx     3474 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_index_service_apis.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/
+-rw-rw-r--  2.0 unx      679 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/__init__.py
+-rw-rw-r--  2.0 unx     1531 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_patch.py
+-rw-rw-r--  2.0 unx     2831 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_configuration.py
+-rw-rw-r--  2.0 unx     3361 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_index_service_apis.py
+-rw-rw-r--  2.0 unx      476 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/__init__.py
+-rw-rw-r--  2.0 unx     5419 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/_index_entities_operations.py
+-rw-rw-r--  2.0 unx      476 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/__init__.py
+-rw-rw-r--  2.0 unx     5804 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/_index_entities_operations.py
+-rw-rw-r--  2.0 unx    24536 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/__init__.py
+-rw-rw-r--  2.0 unx   419787 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models_py3.py
+-rw-rw-r--  2.0 unx   387848 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models.py
+-rw-rw-r--  2.0 unx     9701 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_index_service_apis_enums.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_notification/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/
+-rw-rw-r--  2.0 unx     1736 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/__init__.py
+-rw-rw-r--  2.0 unx     1227 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job_resource_configuration.py
+-rw-rw-r--  2.0 unx     2750 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/identity.py
+-rw-rw-r--  2.0 unx      756 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/resource_configuration.py
+-rw-rw-r--  2.0 unx      873 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/queue_settings.py
+-rw-rw-r--  2.0 unx      822 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/spark_resource_configuration.py
+-rw-rw-r--  2.0 unx     1355 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/schedule.py
+-rw-rw-r--  2.0 unx      321 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/__init__.py
+-rw-rw-r--  2.0 unx      874 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/data_import.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/
+-rw-rw-r--  2.0 unx     2492 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/model.py
+-rw-rw-r--  2.0 unx     5963 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/environment.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/__init__.py
+-rw-rw-r--  2.0 unx     1028 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/data.py
+-rw-rw-r--  2.0 unx     1023 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/federated_learning_silo.py
+-rw-rw-r--  2.0 unx     1513 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/asset.py
+-rw-rw-r--  2.0 unx     1601 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/code_asset.py
+-rw-rw-r--  2.0 unx      719 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/artifact.py
+-rw-rw-r--  2.0 unx      849 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/workspace_asset_reference.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/__init__.py
+-rw-rw-r--  2.0 unx     1435 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_package.py
+-rw-rw-r--  2.0 unx      649 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/base_environment_source.py
+-rw-rw-r--  2.0 unx      685 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/route.py
+-rw-rw-r--  2.0 unx      990 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/online_inference_configuration.py
+-rw-rw-r--  2.0 unx     1985 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/inference_server.py
+-rw-rw-r--  2.0 unx      824 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_configuration.py
+-rw-rw-r--  2.0 unx     2405 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_package_input.py
+-rw-rw-r--  2.0 unx     1668 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/schedule.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/__init__.py
+-rw-rw-r--  2.0 unx     5827 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/create_job.py
+-rw-rw-r--  2.0 unx     3042 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/trigger.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/
+-rw-rw-r--  2.0 unx      333 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/__init__.py
+-rw-rw-r--  2.0 unx     1996 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/workspace.py
+-rw-rw-r--  2.0 unx     7195 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/networking.py
+-rw-rw-r--  2.0 unx     3195 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/identity.py
+-rw-rw-r--  2.0 unx      709 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/endpoint_connection.py
+-rw-rw-r--  2.0 unx      697 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/customer_managed_key.py
+-rw-rw-r--  2.0 unx      785 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/private_endpoint.py
+-rw-rw-r--  2.0 unx      364 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/__init__.py
+-rw-rw-r--  2.0 unx     3607 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/credentials.py
+-rw-rw-r--  2.0 unx     2453 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/workspace_connection.py
+-rw-rw-r--  2.0 unx      433 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/__init__.py
+-rw-rw-r--  2.0 unx      717 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/data_column_schema.py
+-rw-rw-r--  2.0 unx     1147 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/feature_store_entity_schema.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/__init__.py
+-rw-rw-r--  2.0 unx     1293 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/intellectual_property.py
+-rw-rw-r--  2.0 unx     1577 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/schema_meta.py
+-rw-rw-r--  2.0 unx     5201 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/schema.py
+-rw-rw-r--  2.0 unx     1887 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/resource.py
+-rw-rw-r--  2.0 unx     1271 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/auto_delete_setting.py
+-rw-rw-r--  2.0 unx    37052 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/fields.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/__init__.py
+-rw-rw-r--  2.0 unx      693 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/code_configuration_schema.py
+-rw-rw-r--  2.0 unx     1963 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/deployment.py
+-rw-rw-r--  2.0 unx     2449 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment_settings.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/__init__.py
+-rw-rw-r--  2.0 unx     6806 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_job.py
+-rw-rw-r--  2.0 unx     1990 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment.py
+-rw-rw-r--  2.0 unx     1604 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/pipeline_component_batch_deployment_schema.py
+-rw-rw-r--  2.0 unx     1491 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/compute_binding.py
+-rw-rw-r--  2.0 unx     4438 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment.py
+-rw-rw-r--  2.0 unx      911 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment_settings.py
+-rw-rw-r--  2.0 unx     1620 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/job_definition_schema.py
+-rw-rw-r--  2.0 unx      839 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/run_settings_schema.py
+-rw-rw-r--  2.0 unx     1654 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_pipeline_component_deployment_configurations_schema.py
+-rw-rw-r--  2.0 unx     1642 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/data_collector_schema.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/__init__.py
+-rw-rw-r--  2.0 unx      911 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/resource_requirements_schema.py
+-rw-rw-r--  2.0 unx     1664 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/scale_settings_schema.py
+-rw-rw-r--  2.0 unx     3130 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/online_deployment.py
+-rw-rw-r--  2.0 unx      825 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/payload_response_schema.py
+-rw-rw-r--  2.0 unx     1122 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/oversize_data_config_schema.py
+-rw-rw-r--  2.0 unx     1078 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/event_hub_schema.py
+-rw-rw-r--  2.0 unx      828 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/request_settings_schema.py
+-rw-rw-r--  2.0 unx      797 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/liveness_probe.py
+-rw-rw-r--  2.0 unx      757 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/data_asset_schema.py
+-rw-rw-r--  2.0 unx     1109 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/deployment_collection_schema.py
+-rw-rw-r--  2.0 unx      707 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/request_logging_schema.py
+-rw-rw-r--  2.0 unx      959 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/resource_settings_schema.py
+-rw-rw-r--  2.0 unx     2902 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/azure_storage.py
+-rw-rw-r--  2.0 unx     1432 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/_on_prem.py
+-rw-rw-r--  2.0 unx      909 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/__init__.py
+-rw-rw-r--  2.0 unx     3027 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/credentials.py
+-rw-rw-r--  2.0 unx     1461 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/adls_gen1.py
+-rw-rw-r--  2.0 unx     2020 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/_on_prem_credentials.py
+-rw-rw-r--  2.0 unx     1364 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_set_schema.py
+-rw-rw-r--  2.0 unx     1013 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/__init__.py
+-rw-rw-r--  2.0 unx      660 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_set_specification_schema.py
+-rw-rw-r--  2.0 unx      682 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/delay_metadata_schema.py
+-rw-rw-r--  2.0 unx     1465 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/materialization_settings_schema.py
+-rw-rw-r--  2.0 unx      892 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_schema.py
+-rw-rw-r--  2.0 unx      682 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/timestamp_column_metadata_schema.py
+-rw-rw-r--  2.0 unx      958 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/source_metadata_schema.py
+-rw-rw-r--  2.0 unx      760 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_transformation_code_metadata_schema.py
+-rw-rw-r--  2.0 unx     1520 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/featureset_spec_metadata_schema.py
+-rw-rw-r--  2.0 unx     1915 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/featureset_spec_properties_schema.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/__init__.py
+-rw-rw-r--  2.0 unx     3605 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/data_binding_expression.py
+-rw-rw-r--  2.0 unx     3162 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/utils.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/online/
+-rw-rw-r--  2.0 unx      513 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/__init__.py
+-rw-rw-r--  2.0 unx     1780 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/endpoint.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/__init__.py
+-rw-rw-r--  2.0 unx      943 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint_defaults.py
+-rw-rw-r--  2.0 unx      945 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/online/__init__.py
+-rw-rw-r--  2.0 unx     2444 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/online/online_endpoint.py
+-rw-rw-r--  2.0 unx      391 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/retry_settings.py
+-rw-rw-r--  2.0 unx     2716 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/spark_component.py
+-rw-rw-r--  2.0 unx     2039 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/__init__.py
+-rw-rw-r--  2.0 unx     5504 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/command_component.py
+-rw-rw-r--  2.0 unx     1208 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/parallel_task.py
+-rw-rw-r--  2.0 unx     3095 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/import_component.py
+-rw-rw-r--  2.0 unx      981 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/automl_component.py
+-rw-rw-r--  2.0 unx    10227 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/data_transfer_component.py
+-rw-rw-r--  2.0 unx      667 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/resource.py
+-rw-rw-r--  2.0 unx     5566 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/input_output.py
+-rw-rw-r--  2.0 unx     3859 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/component.py
+-rw-rw-r--  2.0 unx     4785 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/parallel_component.py
+-rw-rw-r--  2.0 unx      340 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_notification/__init__.py
+-rw-rw-r--  2.0 unx      815 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_notification/notification_schema.py
+-rw-rw-r--  2.0 unx      529 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/__init__.py
+-rw-rw-r--  2.0 unx     2009 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/feature_store_schema.py
+-rw-rw-r--  2.0 unx      783 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/materialization_store_schema.py
+-rw-rw-r--  2.0 unx      656 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/compute_runtime_schema.py
+-rw-rw-r--  2.0 unx     2968 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_job.py
+-rw-rw-r--  2.0 unx      563 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/__init__.py
+-rw-rw-r--  2.0 unx    12461 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_component.py
+-rw-rw-r--  2.0 unx    20403 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/component_job.py
+-rw-rw-r--  2.0 unx     1434 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_parallel_job.py
+-rw-rw-r--  2.0 unx     1904 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_job_io.py
+-rw-rw-r--  2.0 unx     2281 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/condition_node.py
+-rw-rw-r--  2.0 unx      907 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_spark_job.py
+-rw-rw-r--  2.0 unx     1535 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/settings.py
+-rw-rw-r--  2.0 unx     6588 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/automl_node.py
+-rw-rw-r--  2.0 unx     1401 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_command_job.py
+-rw-rw-r--  2.0 unx     1859 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_datatransfer_job.py
+-rw-rw-r--  2.0 unx      718 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_import_job.py
+-rw-rw-r--  2.0 unx     5063 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/control_flow_job.py
+-rw-rw-r--  2.0 unx      493 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/schedule.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/__init__.py
+-rw-rw-r--  2.0 unx      616 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/alert_notification.py
+-rw-rw-r--  2.0 unx     7894 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/signals.py
+-rw-rw-r--  2.0 unx     1110 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/input_data.py
+-rw-rw-r--  2.0 unx      800 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/target.py
+-rw-rw-r--  2.0 unx     1907 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/monitor_definition.py
+-rw-rw-r--  2.0 unx     4005 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/thresholds.py
+-rw-rw-r--  2.0 unx     7131 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_output_entry.py
+-rw-rw-r--  2.0 unx      673 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parallel_job.py
+-rw-rw-r--  2.0 unx      597 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/job_output.py
+-rw-rw-r--  2.0 unx      983 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/__init__.py
+-rw-rw-r--  2.0 unx      927 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/command_job.py
+-rw-rw-r--  2.0 unx     1914 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/import_job.py
+-rw-rw-r--  2.0 unx     1500 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/job_limits.py
+-rw-rw-r--  2.0 unx      776 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_port.py
+-rw-rw-r--  2.0 unx     1229 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/spark_job.py
+-rw-rw-r--  2.0 unx     3150 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_parallel.py
+-rw-rw-r--  2.0 unx     1940 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/identity.py
+-rw-rw-r--  2.0 unx     2597 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/base_job.py
+-rw-rw-r--  2.0 unx     3001 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/services.py
+-rw-rw-r--  2.0 unx     1850 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_command.py
+-rw-rw-r--  2.0 unx      553 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/creation_context.py
+-rw-rw-r--  2.0 unx     2028 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_output_fields_provider.py
+-rw-rw-r--  2.0 unx     6457 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_spark.py
+-rw-rw-r--  2.0 unx     3430 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/distribution.py
+-rw-rw-r--  2.0 unx     2871 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/data_transfer_job.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/__init__.py
+-rw-rw-r--  2.0 unx     1410 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/mltable_metadata_schema.py
+-rw-rw-r--  2.0 unx      958 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/mltable_metadata_path_schemas.py
+-rw-rw-r--  2.0 unx      542 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/util.py
+-rw-rw-r--  2.0 unx      330 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/__init__.py
+-rw-rw-r--  2.0 unx     1614 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/system_created_storage_account.py
+-rw-rw-r--  2.0 unx     2596 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/registry.py
+-rw-rw-r--  2.0 unx     1328 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/system_created_acr_account.py
+-rw-rw-r--  2.0 unx     2569 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/registry_region_arm_details.py
+-rw-rw-r--  2.0 unx      657 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/kubernetes_compute.py
+-rw-rw-r--  2.0 unx     3638 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/schedule.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/__init__.py
+-rw-rw-r--  2.0 unx      534 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/aml_compute_node_info.py
+-rw-rw-r--  2.0 unx     1701 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/synapsespark_compute.py
+-rw-rw-r--  2.0 unx     1981 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/custom_applications.py
+-rw-rw-r--  2.0 unx     1087 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/setup_scripts.py
+-rw-rw-r--  2.0 unx     1202 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/virtual_machine_compute.py
+-rw-rw-r--  2.0 unx      401 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/attached_compute.py
+-rw-rw-r--  2.0 unx     1920 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/aml_compute.py
+-rw-rw-r--  2.0 unx     2979 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/compute_instance.py
+-rw-rw-r--  2.0 unx     3169 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/compute.py
+-rw-rw-r--  2.0 unx     1297 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/usage.py
+-rw-rw-r--  2.0 unx      653 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/vm_size.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/
+-rw-rw-r--  2.0 unx      315 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/__init__.py
+-rw-rw-r--  2.0 unx     1157 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/parameterized_sweep.py
+-rw-rw-r--  2.0 unx      952 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_job.py
+-rw-rw-r--  2.0 unx      236 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/_constants.py
+-rw-rw-r--  2.0 unx     2430 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_fields_provider.py
+-rw-rw-r--  2.0 unx     3200 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_sampling_algorithm.py
+-rw-rw-r--  2.0 unx     3137 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_termination.py
+-rw-rw-r--  2.0 unx     1010 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_objective.py
+-rw-rw-r--  2.0 unx      656 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/__init__.py
+-rw-rw-r--  2.0 unx     1041 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/randint.py
+-rw-rw-r--  2.0 unx     2496 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/normal.py
+-rw-rw-r--  2.0 unx     2796 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/uniform.py
+-rw-rw-r--  2.0 unx     2244 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/choice.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/
+-rw-rw-r--  2.0 unx     1259 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/__init__.py
+-rw-rw-r--  2.0 unx     2572 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/featurization_settings.py
+-rw-rw-r--  2.0 unx     1035 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/automl_job.py
+-rw-rw-r--  2.0 unx     4633 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/training_settings.py
+-rw-rw-r--  2.0 unx      839 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/automl_vertical.py
+-rw-rw-r--  2.0 unx     2477 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/forecasting_settings.py
+-rw-rw-r--  2.0 unx     1510 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/regression.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/__init__.py
+-rw-rw-r--  2.0 unx     1714 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/forecasting.py
+-rw-rw-r--  2.0 unx     1075 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical_limit_settings.py
+-rw-rw-r--  2.0 unx     1558 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/classification.py
+-rw-rw-r--  2.0 unx     1609 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/__init__.py
+-rw-rw-r--  2.0 unx     2752 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_object_detection.py
+-rw-rw-r--  2.0 unx     3458 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_model_settings.py
+-rw-rw-r--  2.0 unx     9629 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_model_distribution_settings.py
+-rw-rw-r--  2.0 unx      956 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_sweep_settings.py
+-rw-rw-r--  2.0 unx      665 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_limit_settings.py
+-rw-rw-r--  2.0 unx     2552 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_classification.py
+-rw-rw-r--  2.0 unx     1055 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_vertical.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/__init__.py
+-rw-rw-r--  2.0 unx     1445 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification_multilabel.py
+-rw-rw-r--  2.0 unx     1223 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_fixed_parameters.py
+-rw-rw-r--  2.0 unx     1295 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_ner.py
+-rw-rw-r--  2.0 unx     1485 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical.py
+-rw-rw-r--  2.0 unx     4156 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_parameter_subspace.py
+-rw-rw-r--  2.0 unx      950 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_sweep_settings.py
+-rw-rw-r--  2.0 unx     1404 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification.py
+-rw-rw-r--  2.0 unx      768 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical_limit_settings.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_notification/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_data/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/
+-rw-rw-r--  2.0 unx    14338 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/__init__.py
+-rw-rw-r--  2.0 unx     3036 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_validate_funcs.py
+-rw-rw-r--  2.0 unx    31080 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_validation.py
+-rw-rw-r--  2.0 unx    28226 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_credentials.py
+-rw-rw-r--  2.0 unx    37637 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_load_functions.py
+-rw-rw-r--  2.0 unx     3628 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_system_data.py
+-rw-rw-r--  2.0 unx     4238 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_mixins.py
+-rw-rw-r--  2.0 unx     8485 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_resource.py
+-rw-rw-r--  2.0 unx    21598 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_util.py
+-rw-rw-r--  2.0 unx     4555 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/schedule.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/__init__.py
+-rw-rw-r--  2.0 unx     4563 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/data_import.py
+-rw-rw-r--  2.0 unx     8739 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/spark_component.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/__init__.py
+-rw-rw-r--  2.0 unx    22145 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/pipeline_component.py
+-rw-rw-r--  2.0 unx    12487 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/command_component.py
+-rw-rw-r--  2.0 unx     9550 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/code.py
+-rw-rw-r--  2.0 unx    11303 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/datatransfer_component.py
+-rw-rw-r--  2.0 unx     3085 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/import_component.py
+-rw-rw-r--  2.0 unx    21655 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/_additional_includes.py
+-rw-rw-r--  2.0 unx     1543 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/automl_component.py
+-rw-rw-r--  2.0 unx     6908 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/component_factory.py
+-rw-rw-r--  2.0 unx    22814 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/component.py
+-rw-rw-r--  2.0 unx    11460 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/parallel_component.py
+-rw-rw-r--  2.0 unx    21567 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/input.py
+-rw-rw-r--  2.0 unx     2640 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/__init__.py
+-rw-rw-r--  2.0 unx     1080 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/base.py
+-rw-rw-r--  2.0 unx     7138 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/external_data.py
+-rw-rw-r--  2.0 unx     7638 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/output.py
+-rw-rw-r--  2.0 unx     4328 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/enum_input.py
+-rw-rw-r--  2.0 unx     8914 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/group_input.py
+-rw-rw-r--  2.0 unx    14428 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/utils.py
+-rw-rw-r--  2.0 unx     4638 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/kubernetes_compute.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/__init__.py
+-rw-rw-r--  2.0 unx     3882 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_usage.py
+-rw-rw-r--  2.0 unx     5038 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_schedule.py
+-rw-rw-r--  2.0 unx     9285 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/synapsespark_compute.py
+-rw-rw-r--  2.0 unx     4416 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_vm_size.py
+-rw-rw-r--  2.0 unx     6187 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/virtual_machine_compute.py
+-rw-rw-r--  2.0 unx     1396 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_image_metadata.py
+-rw-rw-r--  2.0 unx    11023 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/aml_compute.py
+-rw-rw-r--  2.0 unx    19197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/compute_instance.py
+-rw-rw-r--  2.0 unx     1365 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_aml_compute_node_info.py
+-rw-rw-r--  2.0 unx     8037 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_custom_applications.py
+-rw-rw-r--  2.0 unx     3710 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_setup_scripts.py
+-rw-rw-r--  2.0 unx     8684 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/compute.py
+-rw-rw-r--  2.0 unx     2259 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/unsupported_compute.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/
+-rw-rw-r--  2.0 unx    16289 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/environment.py
+-rw-rw-r--  2.0 unx      661 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/__init__.py
+-rw-rw-r--  2.0 unx     1631 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/intellectual_property.py
+-rw-rw-r--  2.0 unx     4999 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/federated_learning_silo.py
+-rw-rw-r--  2.0 unx     4867 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/asset.py
+-rw-rw-r--  2.0 unx     1591 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/auto_delete_setting.py
+-rw-rw-r--  2.0 unx     3096 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/workspace_asset_reference.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/
+-rw-rw-r--  2.0 unx     8398 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/model.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/__init__.py
+-rw-rw-r--  2.0 unx     9100 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/data.py
+-rw-rw-r--  2.0 unx     5644 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/code.py
+-rw-rw-r--  2.0 unx     4145 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/artifact.py
+-rw-rw-r--  2.0 unx     7520 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/feature_set.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/__init__.py
+-rw-rw-r--  2.0 unx    11686 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_package.py
+-rw-rw-r--  2.0 unx     1581 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/base_environment_source.py
+-rw-rw-r--  2.0 unx     7087 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/inferencing_server.py
+-rw-rw-r--  2.0 unx     1099 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_configuration.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/__init__.py
+-rw-rw-r--  2.0 unx    13169 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/workspace.py
+-rw-rw-r--  2.0 unx     8080 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/diagnose.py
+-rw-rw-r--  2.0 unx     8363 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/networking.py
+-rw-rw-r--  2.0 unx      678 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/customer_managed_key.py
+-rw-rw-r--  2.0 unx     1135 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/compute_runtime.py
+-rw-rw-r--  2.0 unx     4364 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/workspace_keys.py
+-rw-rw-r--  2.0 unx     2197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/feature_store_settings.py
+-rw-rw-r--  2.0 unx      890 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/private_endpoint.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/__init__.py
+-rw-rw-r--  2.0 unx     6208 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/credentials.py
+-rw-rw-r--  2.0 unx    10551 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/workspace_connection.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/__init__.py
+-rw-rw-r--  2.0 unx     5552 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/feature_store_entity.py
+-rw-rw-r--  2.0 unx     2786 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/data_column.py
+-rw-rw-r--  2.0 unx      622 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/data_column_type.py
+-rw-rw-r--  2.0 unx     1892 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/job_definition.py
+-rw-rw-r--  2.0 unx     2457 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/resource_requirements_settings.py
+-rw-rw-r--  2.0 unx     2370 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/model_batch_deployment_settings.py
+-rw-rw-r--  2.0 unx     3648 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/data_collector.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/__init__.py
+-rw-rw-r--  2.0 unx     1163 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/batch_job.py
+-rw-rw-r--  2.0 unx     7855 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment_settings.py
+-rw-rw-r--  2.0 unx    46370 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/online_deployment.py
+-rw-rw-r--  2.0 unx     2629 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/code_configuration.py
+-rw-rw-r--  2.0 unx     1354 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/request_logging.py
+-rw-rw-r--  2.0 unx     8459 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/model_batch_deployment.py
+-rw-rw-r--  2.0 unx      843 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/oversize_data_config.py
+-rw-rw-r--  2.0 unx     1788 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/container_resource_settings.py
+-rw-rw-r--  2.0 unx    14565 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/batch_deployment.py
+-rw-rw-r--  2.0 unx     2121 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment_collection.py
+-rw-rw-r--  2.0 unx     4688 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/pipeline_component_batch_deployment.py
+-rw-rw-r--  2.0 unx     6646 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/scale_settings.py
+-rw-rw-r--  2.0 unx      810 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/payload_response.py
+-rw-rw-r--  2.0 unx     1181 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/event_hub.py
+-rw-rw-r--  2.0 unx     1268 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/data_asset.py
+-rw-rw-r--  2.0 unx     1670 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/run_settings.py
+-rw-rw-r--  2.0 unx    10808 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment.py
+-rw-rw-r--  2.0 unx    12652 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/azure_storage.py
+-rw-rw-r--  2.0 unx     4842 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_on_prem.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/__init__.py
+-rw-rw-r--  2.0 unx      271 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_constants.py
+-rw-rw-r--  2.0 unx     7431 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/datastore.py
+-rw-rw-r--  2.0 unx     3989 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/adls_gen1.py
+-rw-rw-r--  2.0 unx     1811 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/utils.py
+-rw-rw-r--  2.0 unx     4918 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_on_prem_credentials.py
+-rw-rw-r--  2.0 unx     6050 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/control_flow_node.py
+-rw-rw-r--  2.0 unx     7728 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/import_node.py
+-rw-rw-r--  2.0 unx      792 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/__init__.py
+-rw-rw-r--  2.0 unx     1488 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/subcomponents.py
+-rw-rw-r--  2.0 unx    37702 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/fl_scatter_gather.py
+-rw-rw-r--  2.0 unx    15465 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/sweep.py
+-rw-rw-r--  2.0 unx     3516 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/import_func.py
+-rw-rw-r--  2.0 unx    14008 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/do_while.py
+-rw-rw-r--  2.0 unx    12787 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/data_transfer_func.py
+-rw-rw-r--  2.0 unx    19823 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/base_node.py
+-rw-rw-r--  2.0 unx    14329 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel_for.py
+-rw-rw-r--  2.0 unx    27517 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/spark.py
+-rw-rw-r--  2.0 unx    17293 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel.py
+-rw-rw-r--  2.0 unx    12910 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/command_func.py
+-rw-rw-r--  2.0 unx     5729 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/condition_node.py
+-rw-rw-r--  2.0 unx     7395 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/pipeline.py
+-rw-rw-r--  2.0 unx    11695 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel_func.py
+-rw-rw-r--  2.0 unx    13510 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/spark_func.py
+-rw-rw-r--  2.0 unx    40887 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/command.py
+-rw-rw-r--  2.0 unx    22449 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/data_transfer.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/data_transfer/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/
+-rw-rw-r--  2.0 unx      939 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/input_output_entry.py
+-rw-rw-r--  2.0 unx     2482 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/to_rest_functions.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/__init__.py
+-rw-rw-r--  2.0 unx     6639 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_name_generator.py
+-rw-rw-r--  2.0 unx    14219 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_service.py
+-rw-rw-r--  2.0 unx    13496 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/command_job.py
+-rw-rw-r--  2.0 unx     1044 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/_studio_url_from_job_id.py
+-rw-rw-r--  2.0 unx     9460 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/import_job.py
+-rw-rw-r--  2.0 unx     6752 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_limits.py
+-rw-rw-r--  2.0 unx     8874 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_resource_configuration.py
+-rw-rw-r--  2.0 unx      662 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/input_port.py
+-rw-rw-r--  2.0 unx    18648 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job.py
+-rw-rw-r--  2.0 unx     3216 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/base_job.py
+-rw-rw-r--  2.0 unx    17177 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/_input_output_helpers.py
+-rw-rw-r--  2.0 unx     3565 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/resource_configuration.py
+-rw-rw-r--  2.0 unx     6666 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parameterized_command.py
+-rw-rw-r--  2.0 unx     3730 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/queue_settings.py
+-rw-rw-r--  2.0 unx     1986 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/service_instance.py
+-rw-rw-r--  2.0 unx     1151 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_io_mixin.py
+-rw-rw-r--  2.0 unx     3036 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parameterized_spark.py
+-rw-rw-r--  2.0 unx     2671 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job_entry_mixin.py
+-rw-rw-r--  2.0 unx     2507 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job_entry.py
+-rw-rw-r--  2.0 unx     5712 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_resource_configuration.py
+-rw-rw-r--  2.0 unx    10426 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_helpers.py
+-rw-rw-r--  2.0 unx     7333 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/distribution.py
+-rw-rw-r--  2.0 unx    13882 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job.py
+-rw-rw-r--  2.0 unx     3885 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/compute_configuration.py
+-rw-rw-r--  2.0 unx     7267 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parallel_job.py
+-rw-rw-r--  2.0 unx     2817 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/retry_settings.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/__init__.py
+-rw-rw-r--  2.0 unx     3039 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/run_function.py
+-rw-rw-r--  2.0 unx     5350 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parallel_task.py
+-rw-rw-r--  2.0 unx     3550 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parameterized_parallel.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/data_transfer/__init__.py
+-rw-rw-r--  2.0 unx    13245 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/data_transfer/data_transfer_job.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/data/
+-rw-rw-r--  2.0 unx    30015 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/pipeline_job.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/__init__.py
+-rw-rw-r--  2.0 unx     2351 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/pipeline_job_settings.py
+-rw-rw-r--  2.0 unx    28869 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_pipeline_expression.py
+-rw-rw-r--  2.0 unx     6465 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_attr_dict.py
+-rw-rw-r--  2.0 unx    16207 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_component_translatable.py
+-rw-rw-r--  2.0 unx    13157 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_load_component.py
+-rw-rw-r--  2.0 unx     8846 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_pipeline_job_helpers.py
+-rw-rw-r--  2.0 unx     7370 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/attr_dict.py
+-rw-rw-r--  2.0 unx      747 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/__init__.py
+-rw-rw-r--  2.0 unx    29691 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/base.py
+-rw-rw-r--  2.0 unx    22441 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/mixin.py
+-rw-rw-r--  2.0 unx      307 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/data/expression_component_template.yml
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/__init__.py
+-rw-rw-r--  2.0 unx    11491 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/parameterized_sweep.py
+-rw-rw-r--  2.0 unx    16042 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/sweep_job.py
+-rw-rw-r--  2.0 unx    16425 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/search_space.py
+-rw-rw-r--  2.0 unx     5928 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/sampling_algorithm.py
+-rw-rw-r--  2.0 unx     1945 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/objective.py
+-rw-rw-r--  2.0 unx     9689 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/early_termination_policy.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/
+-rw-rw-r--  2.0 unx      549 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/__init__.py
+-rw-rw-r--  2.0 unx      910 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/featurization_settings.py
+-rw-rw-r--  2.0 unx     3355 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/stack_ensemble_settings.py
+-rw-rw-r--  2.0 unx    11450 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/automl_job.py
+-rw-rw-r--  2.0 unx    16998 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/training_settings.py
+-rw-rw-r--  2.0 unx      362 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/search_space.py
+-rw-rw-r--  2.0 unx    10972 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/search_space_utils.py
+-rw-rw-r--  2.0 unx     1930 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/utils.py
+-rw-rw-r--  2.0 unx     4176 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/automl_vertical.py
+-rw-rw-r--  2.0 unx      766 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/__init__.py
+-rw-rw-r--  2.0 unx    34166 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_job.py
+-rw-rw-r--  2.0 unx     7269 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/featurization_settings.py
+-rw-rw-r--  2.0 unx     9838 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/regression_job.py
+-rw-rw-r--  2.0 unx    32190 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/automl_tabular.py
+-rw-rw-r--  2.0 unx    14943 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/classification_job.py
+-rw-rw-r--  2.0 unx     4672 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/limit_settings.py
+-rw-rw-r--  2.0 unx    10011 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_settings.py
+-rw-rw-r--  2.0 unx    20428 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image_classification_base.py
+-rw-rw-r--  2.0 unx     1248 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/__init__.py
+-rw-rw-r--  2.0 unx    10143 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_instance_segmentation_job.py
+-rw-rw-r--  2.0 unx    43738 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_model_settings.py
+-rw-rw-r--  2.0 unx    10315 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_multilabel_job.py
+-rw-rw-r--  2.0 unx    25210 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image_object_detection_base.py
+-rw-rw-r--  2.0 unx     6917 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image.py
+-rw-rw-r--  2.0 unx    27219 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_search_space.py
+-rw-rw-r--  2.0 unx     2903 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_sweep_settings.py
+-rw-rw-r--  2.0 unx     9831 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_job.py
+-rw-rw-r--  2.0 unx     9929 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_job.py
+-rw-rw-r--  2.0 unx     6380 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_limit_settings.py
+-rw-rw-r--  2.0 unx    55726 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_search_space.py
+-rw-rw-r--  2.0 unx    10273 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_multilabel_job.py
+-rw-rw-r--  2.0 unx      908 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/__init__.py
+-rw-rw-r--  2.0 unx     3476 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_fixed_parameters.py
+-rw-rw-r--  2.0 unx     2774 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_limit_settings.py
+-rw-rw-r--  2.0 unx     9859 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_job.py
+-rw-rw-r--  2.0 unx     1391 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_featurization_settings.py
+-rw-rw-r--  2.0 unx     9172 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_ner_job.py
+-rw-rw-r--  2.0 unx     1925 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_sweep_settings.py
+-rw-rw-r--  2.0 unx     7799 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_search_space.py
+-rw-rw-r--  2.0 unx    15254 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/automl_nlp_job.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/__init__.py
+-rw-rw-r--  2.0 unx     1182 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_compute_resource.py
+-rw-rw-r--  2.0 unx      719 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/source_metadata.py
+-rw-rw-r--  2.0 unx     2410 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_materialization_metadata.py
+-rw-rw-r--  2.0 unx     4597 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_settings.py
+-rw-rw-r--  2.0 unx      486 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_transformation_code_metadata.py
+-rw-rw-r--  2.0 unx     1447 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature.py
+-rw-rw-r--  2.0 unx     2858 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/featureset_spec_metadata.py
+-rw-rw-r--  2.0 unx     1088 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_backfill_metadata.py
+-rw-rw-r--  2.0 unx     1071 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_specification.py
+-rw-rw-r--  2.0 unx      424 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/delay_metadata.py
+-rw-rw-r--  2.0 unx      465 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_type.py
+-rw-rw-r--  2.0 unx      404 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/timestamp_column_metadata.py
+-rw-rw-r--  2.0 unx      847 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/util.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/__init__.py
+-rw-rw-r--  2.0 unx    12637 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/registry_support_classes.py
+-rw-rw-r--  2.0 unx    10634 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/registry.py
+-rw-rw-r--  2.0 unx    17066 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/schedule.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/__init__.py
+-rw-rw-r--  2.0 unx    11160 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/trigger.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/__init__.py
+-rw-rw-r--  2.0 unx     5986 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/endpoint.py
+-rw-rw-r--  2.0 unx     2210 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/_endpoint_helpers.py
+-rw-rw-r--  2.0 unx    26686 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/online_endpoint.py
+-rw-rw-r--  2.0 unx     5378 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/batch_endpoint.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_notification/__init__.py
+-rw-rw-r--  2.0 unx     1463 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_notification/notification.py
+-rw-rw-r--  2.0 unx      246 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/__init__.py
+-rw-rw-r--  2.0 unx      571 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/_constants.py
+-rw-rw-r--  2.0 unx     9680 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/feature_store.py
+-rw-rw-r--  2.0 unx      588 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/materialization_store.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_data/__init__.py
+-rw-rw-r--  2.0 unx     2952 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_data/mltable_metadata.py
+-rw-rw-r--  2.0 unx     7543 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/schedule.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/__init__.py
+-rw-rw-r--  2.0 unx     1366 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/alert_notification.py
+-rw-rw-r--  2.0 unx    26891 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/signals.py
+-rw-rw-r--  2.0 unx     6300 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/definition.py
+-rw-rw-r--  2.0 unx     2672 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/input_data.py
+-rw-rw-r--  2.0 unx      795 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/target.py
+-rw-rw-r--  2.0 unx    17148 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/thresholds.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_file_utils/__init__.py
+-rw-rw-r--  2.0 unx     2089 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_file_utils/file_utils.py
+-rw-rw-r--  2.0 unx      343 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_logging/__init__.py
+-rw-rw-r--  2.0 unx     2408 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_logging/chained_identity.py
+-rw-rw-r--  2.0 unx     5927 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_logging/debug_mode.py
+-rw-rw-r--  2.0 unx     1395 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/sweep/__init__.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/
+-rw-rw-r--  2.0 unx     5604 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/dockerfile_resolver.py
+-rw-rw-r--  2.0 unx      634 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/__init__.py
+-rw-rw-r--  2.0 unx    23024 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/docker_client.py
+-rw-rw-r--  2.0 unx     5129 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/azureml_image_context.py
+-rw-rw-r--  2.0 unx     2943 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/mdc_config_resolver.py
+-rw-rw-r--  2.0 unx     2334 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/dockerfile_instructions.py
+-rw-rw-r--  2.0 unx     4203 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/endpoint_stub.py
+-rw-rw-r--  2.0 unx      377 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/local_endpoint_mode.py
+-rw-rw-r--  2.0 unx      180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/__init__.py
+-rw-rw-r--  2.0 unx     2137 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/vscode_client.py
+-rw-rw-r--  2.0 unx     4391 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_properties.py
+-rw-rw-r--  2.0 unx     6812 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_resolver.py
+-rw-rw-r--  2.0 unx      534 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/__init__.py
+-rw-rw-r--  2.0 unx     3356 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/model_validator.py
+-rw-rw-r--  2.0 unx     4317 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/code_validator.py
+-rw-rw-r--  2.0 unx     6931 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/environment_validator.py
+-rw-rw-r--  2.0 unx      180 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/__init__.py
+-rw-rw-r--  2.0 unx     3682 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/commandline_utility.py
+-rw-rw-r--  2.0 unx      763 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/wsl_utility.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/
+-rw-rw-r--  2.0 unx     2702 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_condition.py
+-rw-rw-r--  2.0 unx     1782 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_load_import.py
+-rw-rw-r--  2.0 unx      344 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/__init__.py
+-rw-rw-r--  2.0 unx     2883 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_component_func.py
+-rw-rw-r--  2.0 unx      272 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_constants.py
+-rw-rw-r--  2.0 unx     6625 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_utils.py
+-rw-rw-r--  2.0 unx     4087 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_do_while.py
+-rw-rw-r--  2.0 unx     8977 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_group_decorator.py
+-rw-rw-r--  2.0 unx    14066 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_pipeline_decorator.py
+-rw-rw-r--  2.0 unx    24695 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_pipeline_component_builder.py
+-rw-rw-r--  2.0 unx      685 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_overrides_definition.py
+-rw-rw-r--  2.0 unx     1821 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_parallel_for.py
+-rw-rw-r--  2.0 unx     7346 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_fl_scatter_gather_node.py
+-rw-rw-r--  2.0 unx     4644 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_settings.py
+-rw-rw-r--  2.0 unx     6578 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_dynamic.py
+-rw-rw-r--  2.0 unx     1851 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/__init__.py
+-rw-rw-r--  2.0 unx      991 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/_constants.py
+drwxrwxr-x  2.0 unx        0 b- stor 23-Jul-25 21:54 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/
+-rw-rw-r--  2.0 unx      360 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/__init__.py
+-rw-rw-r--  2.0 unx    12356 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_deployment_executor.py
+-rw-rw-r--  2.0 unx     2955 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_helper.py
+-rw-rw-r--  2.0 unx      262 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/__init__.py
+-rw-rw-r--  2.0 unx    40296 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_base.json
+-rw-rw-r--  2.0 unx      596 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/online_endpoint.json
+-rw-rw-r--  2.0 unx      495 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/model_version.json
+-rw-rw-r--  2.0 unx     3110 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_param.json
+-rw-rw-r--  2.0 unx      489 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/code_version.json
+-rw-rw-r--  2.0 unx     1137 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/update_online_endpoint.json
+-rw-rw-r--  2.0 unx      197 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/base_template.json
+-rw-rw-r--  2.0 unx      403 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/model.json
+-rw-rw-r--  2.0 unx      721 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/online_deployment.json
+-rw-rw-r--  2.0 unx      531 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/environment_version.json
+-rw-rw-r--  2.0 unx    11378 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_image.py
+-rw-rw-r--  2.0 unx     4166 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/automl/__init__.py
+-rw-rw-r--  2.0 unx     5886 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_nlp.py
+-rw-rw-r--  2.0 unx    24885 b- defN 23-Jul-25 21:53 azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_tabular.py
+2738 files, 51470517 bytes uncompressed, 7082143 bytes compressed:  86.2%
```

## zipnote {}

```diff
@@ -1,7855 +1,8215 @@
-Filename: azure-ai-ml-1.8.0/
+Filename: azure-ai-ml-1.9.0/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/
+Filename: azure-ai-ml-1.9.0/tests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure_ai_ml.egg-info/
+Filename: azure-ai-ml-1.9.0/samples/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/samples/
+Filename: azure-ai-ml-1.9.0/azure_ai_ml.egg-info/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/
+Filename: azure-ai-ml-1.9.0/azure/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/CHANGELOG.md
+Filename: azure-ai-ml-1.9.0/MANIFEST.in
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/README.md
+Filename: azure-ai-ml-1.9.0/CHANGELOG.md
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/setup.py
+Filename: azure-ai-ml-1.9.0/pyproject.toml
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/NOTICE.txt
+Filename: azure-ai-ml-1.9.0/setup.cfg
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/documentation_guidelines.md
+Filename: azure-ai-ml-1.9.0/NOTICE.txt
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/pyproject.toml
+Filename: azure-ai-ml-1.9.0/PKG-INFO
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/setup.cfg
+Filename: azure-ai-ml-1.9.0/setup.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/PKG-INFO
+Filename: azure-ai-ml-1.9.0/documentation_guidelines.md
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/MANIFEST.in
+Filename: azure-ai-ml-1.9.0/README.md
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/
+Filename: azure-ai-ml-1.9.0/tests/import_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/
+Filename: azure-ai-ml-1.9.0/tests/spark_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/
+Filename: azure-ai-ml-1.9.0/tests/environment/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/
+Filename: azure-ai-ml-1.9.0/tests/schedule/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_utilities/
+Filename: azure-ai-ml-1.9.0/tests/workspace/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/
+Filename: azure-ai-ml-1.9.0/tests/batch_services/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/import_job/
+Filename: azure-ai-ml-1.9.0/tests/code_asset/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/
+Filename: azure-ai-ml-1.9.0/tests/feature_store/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/
+Filename: azure-ai-ml-1.9.0/tests/job_common/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/
+Filename: azure-ai-ml-1.9.0/tests/model/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/
+Filename: azure-ai-ml-1.9.0/tests/data_import/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/
+Filename: azure-ai-ml-1.9.0/tests/command_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/
+Filename: azure-ai-ml-1.9.0/tests/internal/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/
+Filename: azure-ai-ml-1.9.0/tests/component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/
+Filename: azure-ai-ml-1.9.0/tests/online_services/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/
+Filename: azure-ai-ml-1.9.0/tests/monitoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/
+Filename: azure-ai-ml-1.9.0/tests/feature_set/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/
+Filename: azure-ai-ml-1.9.0/tests/registry/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/
+Filename: azure-ai-ml-1.9.0/tests/test_utilities/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/registry/
+Filename: azure-ai-ml-1.9.0/tests/compute/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/
+Filename: azure-ai-ml-1.9.0/tests/datastore/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/
+Filename: azure-ai-ml-1.9.0/tests/dsl/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/
+Filename: azure-ai-ml-1.9.0/tests/dataset/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/conftest.py
+Filename: azure-ai-ml-1.9.0/tests/conftest.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/e2etests/test_local_endpoint.py
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/e2etests/test_vc.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/unittests/test_vc_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_mdc_config_resolver.py
+Filename: azure-ai-ml-1.9.0/tests/virtual_cluster/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_dockerfile_resolver.py
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_local_endpoint_validator.py
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_dockerfile_instructions.py
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_devcontainer_resolver.py
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_endpoint_stub.py
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_docker_client.py
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_deployment_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_devcontainer_properties.py
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_code_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_endpoint_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/unittests/
+Filename: azure-ai-ml-1.9.0/tests/import_job/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/import_job/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/import_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/e2etests/test_monitor_schedule.py
+Filename: azure-ai-ml-1.9.0/tests/import_job/e2etests/test_import_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/import_job/unittests/test_import_job_schema_builder_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/monitoring/unittests/test_monitor_schedule.py
+Filename: azure-ai-ml-1.9.0/tests/spark_job/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/spark_job/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/unittests/
+Filename: azure-ai-ml-1.9.0/tests/spark_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/spark_job/e2etests/test_spark_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/_util.py
+Filename: azure-ai-ml-1.9.0/tests/spark_job/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/spark_job/unittests/test_spark_job_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/e2etests/test_schedule.py
+Filename: azure-ai-ml-1.9.0/tests/spark_job/unittests/test_spark_job_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/environment/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/unittests/test_schedule_schema.py
+Filename: azure-ai-ml-1.9.0/tests/environment/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/schedule/unittests/test_schedule_entity.py
+Filename: azure-ai-ml-1.9.0/tests/environment/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/environment/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/unittests/
+Filename: azure-ai-ml-1.9.0/tests/environment/e2etests/test_environment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_operations_registry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/e2etests/test_vc.py
+Filename: azure-ai-ml-1.9.0/tests/environment/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/environment/unittests/test_env_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/virtual_cluster/unittests/test_vc_operations.py
+Filename: azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/schedule/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/
+Filename: azure-ai-ml-1.9.0/tests/schedule/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/schedule/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/_util.py
+Filename: azure-ai-ml-1.9.0/tests/schedule/_util.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/schedule/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_samples.py
+Filename: azure-ai-ml-1.9.0/tests/schedule/e2etests/test_schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/schedule/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_on_registry.py
+Filename: azure-ai-ml-1.9.0/tests/schedule/unittests/test_schedule_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_with_specific_nodes.py
+Filename: azure-ai-ml-1.9.0/tests/schedule/unittests/test_schedule_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/test_automl_dsl_pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/test_controlflow_pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_fl.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/_util.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_component_func.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_pipeline_builder.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/test_control_flow_pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_mldesigner_imports.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/test_pipeline_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_samples.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_validate.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_command_builder.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_group.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_private_preview_disabled.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_component.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_with_specific_nodes.py
+Filename: azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_controlflow_pipeline_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_io_builder.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_init_finalize_job.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_controlflow_pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_fl.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dsl/unittests/test_attr_dict.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace_outbound_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace_connections.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/unittests/
+Filename: azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/e2etests/test_datastore.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_connection_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_operations_base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/unittests/test_datastore_schema.py
+Filename: azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_connection_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/datastore/unittests/test_datastore_operations.py
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/unittests/
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/_utils.py
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/e2etests/test_sweep_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/e2etests/test_component.py
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/unittests/test_sweep_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/e2etests/test_pipeline_job.py
+Filename: azure-ai-ml-1.9.0/tests/sweep_job/unittests/test_sweep_job_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/unittests/test_internal_disabled.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/unittests/test_component.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal/unittests/test_pipeline_job.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_utilities/utils.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/e2etests/test_batch_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_utilities/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/e2etests/test_batch_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_utilities/constants.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_endpoints.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_utilities/json_schema.py
+Filename: azure-ai-ml-1.9.0/tests/batch_services/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/unittests/
+Filename: azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_deployment_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace_outbound_rule_operations.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/conftest.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace_connections.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/jsonl_converter.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_connection_entity.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_classification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_connection_operations.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_regression.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_operations.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_object_detection.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_operations_base.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_forecasting.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_classification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/unittests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_ner.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_classification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_classification_multilabel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/e2etests/test_model.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_segmentation.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_classification_multilabel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/unittests/test_model_schema.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/model/unittests/test_model_operations.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_forecasting_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/unittests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_classification_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_limit_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_sweep_setting.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/e2etests/test_batch_deployment.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_setsearchspace.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/e2etests/test_batch_endpoint.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_object_detection.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_featurization_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_deployment.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_nlp_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_deployment_schema.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_classification_multilabel_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_endpoints.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_forecasting_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/import_job/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_classification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/import_job/unittests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_instance_segmentation.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/import_job/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_n_cross_validation_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/import_job/e2etests/test_import_job.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_classification_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/import_job/unittests/test_import_job_schema_builder_entity.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_regression_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_nlp_sweep_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/unittests/
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_ner_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_classification_multilabel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/e2etests/test_spark_job.py
+Filename: azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_tabular_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/code_asset/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/unittests/test_spark_job_schema.py
+Filename: azure-ai-ml-1.9.0/tests/code_asset/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/spark_job/unittests/test_spark_job_entity.py
+Filename: azure-ai-ml-1.9.0/tests/code_asset/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/code_asset/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/unittests/
+Filename: azure-ai-ml-1.9.0/tests/code_asset/e2etests/test_code.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/code_asset/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/code_asset/unittests/test_federated_learning_silo.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/e2etests/test_code.py
+Filename: azure-ai-ml-1.9.0/tests/code_asset/unittests/test_code_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/unittests/test_code_operations.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/code_asset/unittests/test_federated_learning_silo.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/unittests/
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/e2etests/test_feature_store_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/test_feature_store_entity_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/_util.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/test_feature_store_entity_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/test_control_flow_pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/test_pipeline_job.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_private_preview_disabled.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_entity.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/e2etests/test_local_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_schema.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_devcontainer_resolver.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_controlflow_pipeline_job.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_validate.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_dockerfile_resolver.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_mdc_config_resolver.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/unittests/
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_local_endpoint_validator.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_devcontainer_properties.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_endpoint_stub.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/e2etests/test_data_utils.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_docker_client.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/e2etests/test_data.py
+Filename: azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_dockerfile_instructions.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_schema.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_operations.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/script_parallel/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_utils.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/training/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/script_parallel/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/python/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/training/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_job/basic_spark_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_job/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_job/spark_job_word_count/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/python/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_job/basic_spark_job/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_job/basic_spark_job/src/main.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-4/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_job/spark_job_word_count/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_job/spark_job_word_count/src/wordcount.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-3/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/byoc/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/endpoint_scoring/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/mnist/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-2/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-4/onlinescoring/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-4/onlinescoring/cloud_score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/hello-component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/hello-component/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/primitive_type_components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/batch/hello-component/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-3/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-1/onlinescoring/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-1/onlinescoring/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/byoc/sklearn/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/byoc/sklearn/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/endpoint_scoring/main.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/endpoint_scoring/do_nothing.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/mnist/code/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/mnist/code/digit_identification.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-2/onlinescoring/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/deployments/model-2/onlinescoring/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/write_jokes/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/component_with_conditional_output/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/do_while_test/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/aggregate/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/training/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_hello_world/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/preprocessing/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/mpi_hello_world/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/aggregate/run.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/training/run.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/preprocessing/run.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/write_jokes/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/write_jokes/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/component_with_conditional_output/entry.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/do_while_test/entry.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/eval.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library2/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library2/greetings.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library1/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src/python/library1/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/utils/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline_with_data_as_input.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/utils/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/src1/library1/utils/salute.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library/world.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/compare2.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library1/world.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/components/additional_includes/library1/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/eval.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/my_exp/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/wordcount.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/sampleword.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/basic_component.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/register.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/preprocess.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/greet.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/register.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/preprocess.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/primitive_type_components.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/partition_data.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/parallel_train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/invalid_pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/wordcount.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/sampleword.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/kmeans_example.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/greet.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/wordcount.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword_with_optional_input.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/sampleword.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/add_greeting_column.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/count_by_row.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/my_exp/main.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_component/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_component/src/kmeans_example.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/v2_style/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/convert_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/batch_inference/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/hdi-component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/spark-component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/ipp-component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/v2_style/hd_insight_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/v2_style/hd_insight_component/train-spark.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/run.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/eval.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/component-reuse/additional-includes/run.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/eval.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/tabular_batch_inference.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/batch_inference/batch_score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/convert_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/hdi-component/train-spark.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/file_batch_inference.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/spark-component/run.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/get_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library3/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library2/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library2/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library2/greetings.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library1/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src/python/library1/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library3/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library3/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/prep.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/utils/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/transform.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/utils/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/predict.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/src1/library1/utils/salute.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library/world.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/basic_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library2/greetings.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/baisc_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library1/world.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/additional_includes/library1/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/internal/ipp-component/train_wrapper.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/script_parallel/tabular_run_with_model.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/script_parallel/digit_identification.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/script_parallel/pass_through.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/training/train_mlflow.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_meta.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_hello_world/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_choice.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/mpi_hello_world/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_basic.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_string_concatenate.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_literal.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path_concatenate.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_limits.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_cross_type.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_reason_expression.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_literal.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/primitive_type_components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/eval.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_hello_world/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/mpi_hello_world/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train1.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/file_batch_inference.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/eval.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/tabular_batch_inference.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/get_data.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/convert_data.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/tabular_run_with_model.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/convert_data.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/script_parallel/tabular_run_with_model.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/script_parallel/pass_through.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/script_parallel/digit_identification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/do_while_test/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentB_src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/component_with_conditional_output/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/componentC_src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/write_jokes/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/basic_component/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/do_while_test/entry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/preprocessing/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/baisc_component.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/aggregate/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/training/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/preprocessing/run.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/aggregate/run.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/training/run.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/tabular_run_with_model.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library1/world.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library1/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library/world.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/library/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library2/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library1/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library1/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src/python/library2/greetings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/predict.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/transform.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/utils/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/additional_includes/src1/library1/utils/salute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/prep.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/component_with_conditional_output/entry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_hello_world/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/write_jokes/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/components/write_jokes/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/advanced_example.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train1.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/simple_example.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/plot_example.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/eval.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/sklearn_example.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/logistic_regression.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/mpi_hello_world/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/ipp-component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/v2_style/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/spark-component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/hdi-component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/batch_inference/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/eval.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes/run.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/component-reuse/additional-includes-in-zip/run.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/ipp-component/train_wrapper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/v2_style/hd_insight_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/v2_style/hd_insight_component/train-spark.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/invalid_pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/spark-component/run.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/hdi-component/train-spark.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/count_by_row.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/batch_inference/batch_score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/src/add_greeting_column.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/wordcount.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library3/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword_with_optional_input.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library2/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/kmeans_example.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library1/world.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library1/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library3/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library3/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library/world.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library2/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library1/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library1/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_meta.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src/python/library2/greetings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_basic.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_reason_expression.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_string_concatenate.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_compute.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/utils/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/src1/library1/utils/salute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_cross_type.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/additional_includes/library2/greetings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path_concatenate.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_choice.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_limits.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/eval.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_literal.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-3/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_literal.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/endpoint_scoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-2/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-4/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/byoc/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/mnist/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-1/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-3/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/onlinescoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/onlinescoring/score_managedidentity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-5/onlinescoring/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/endpoint_scoring/main.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/endpoint_scoring/do_nothing.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/hello-component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/hello-component/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/batch/hello-component/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-2/onlinescoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-2/onlinescoring/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-4/onlinescoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-4/onlinescoring/cloud_score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/primitive_type_components.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/byoc/sklearn/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/byoc/sklearn/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/mnist/code/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/mnist/code/digit_identification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-1/onlinescoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/deployments/model-1/onlinescoring/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/eval.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/my_exp/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline_with_data_as_input.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/basic_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/compare2.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/sampleword.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/eval.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/wordcount.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/my_exp/main.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/score.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/eval.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/score.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/sweep_in_pipeline/src/greet.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/preprocess.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/register.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/sampleword.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/src/hello.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/wordcount.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/parallel_train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/pipeline.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/partition_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/src/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/sweep/src/greet.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/plot_example.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/simple_example.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/preprocess.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/logistic_regression.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/register.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/sklearn_example.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/advanced_example.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_job/basic_spark_job/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/invalid/invalid_component/src/sampleword.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_job/spark_job_word_count/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_job/basic_spark_job/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_incorrect_component_content/src/hello.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_job/basic_spark_job/src/main.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/training/train_mlflow.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_job/spark_job_word_count/src/
+Filename: azure-ai-ml-1.9.0/tests/test_configs/python/sweep_script.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/spark_job/spark_job_word_count/src/wordcount.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/python/sweep_script_search.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/python/sweep_script_search.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/python/train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/python/train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/python/simple_train.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/python/simple_train.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_component/src/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/test_configs/python/sweep_script.py
+Filename: azure-ai-ml-1.9.0/tests/test_configs/spark_component/src/kmeans_example.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/feature_store/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/unittests/
+Filename: azure-ai-ml-1.9.0/tests/feature_store/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/e2etests/test_compute.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store/e2etests/test_feature_store.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/unittests/test_compute_operations.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store/unittests/test_feature_store_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/compute/unittests/test_compute_entity.py
+Filename: azure-ai-ml-1.9.0/tests/feature_store/unittests/test_feature_store_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/job_common/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/unittests/
+Filename: azure-ai-ml-1.9.0/tests/job_common/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/job_common/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/job_common/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/e2etests/test_feature_set.py
+Filename: azure-ai-ml-1.9.0/tests/job_common/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/job_common/unittests/test_job_ops_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/unittests/test_list_materialization_job_request.py
+Filename: azure-ai-ml-1.9.0/tests/job_common/unittests/test_vcr_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/unittests/test_feature_set_operations.py
+Filename: azure-ai-ml-1.9.0/tests/job_common/unittests/test_job_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_set/unittests/test_feature_set_schema.py
+Filename: azure-ai-ml-1.9.0/tests/job_common/unittests/test_local_job_invoker.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/model/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/unittests/
+Filename: azure-ai-ml-1.9.0/tests/model/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/model/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/model/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/e2etests/test_sweep_job.py
+Filename: azure-ai-ml-1.9.0/tests/model/e2etests/test_model.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/model/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/unittests/test_sweep_job.py
+Filename: azure-ai-ml-1.9.0/tests/model/unittests/test_model_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/sweep_job/unittests/test_sweep_job_schema.py
+Filename: azure-ai-ml-1.9.0/tests/model/unittests/test_model_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/data_import/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/
+Filename: azure-ai-ml-1.9.0/tests/data_import/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/data_import/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/data_import/e2etests/test_schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/e2etests/test_online_deployment.py
+Filename: azure-ai-ml-1.9.0/tests/data_import/e2etests/test_data_import.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/e2etests/test_online_endpoint.py
+Filename: azure-ai-ml-1.9.0/tests/data_import/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/data_import/unittests/test_data_import.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_online_endpoints.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_schema.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_online_deployments.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_scale_settings.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_resource_requirements_settings.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/e2etests/test_command_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_operations.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_scale_settings_schema.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/unittests/test_command_job_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_executor.py
+Filename: azure-ai-ml-1.9.0/tests/command_job/unittests/test_command_job_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/internal/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/
+Filename: azure-ai-ml-1.9.0/tests/internal/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal/_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/e2etests/test_feature_store_entity.py
+Filename: azure-ai-ml-1.9.0/tests/internal/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal/e2etests/test_pipeline_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/test_feature_store_entity_schema.py
+Filename: azure-ai-ml-1.9.0/tests/internal/e2etests/test_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/test_feature_store_entity_operations.py
+Filename: azure-ai-ml-1.9.0/tests/internal/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/internal/unittests/test_internal_disabled.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/unittests/
+Filename: azure-ai-ml-1.9.0/tests/internal/unittests/test_pipeline_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal/unittests/test_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/component/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/e2etests/test_environment.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_operations.py
+Filename: azure-ai-ml-1.9.0/tests/component/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/component/_util.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_schema.py
+Filename: azure-ai-ml-1.9.0/tests/component/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_operations_registry.py
+Filename: azure-ai-ml-1.9.0/tests/component/e2etests/test_component_validate.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/environment/unittests/test_env_entity.py
+Filename: azure-ai-ml-1.9.0/tests/component/e2etests/test_component_hash.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/component/e2etests/test_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/unittests/
+Filename: azure-ai-ml-1.9.0/tests/component/e2etests/test_component_without_mock.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/e2etests/test_feature_store.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_spark_component_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/unittests/test_feature_store_schema.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_component_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/feature_store/unittests/test_feature_store_operations.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_pipeline_component_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_automl_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_component_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_component_validate.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/_util.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_command_component_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_component_operations_registry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/e2etests/test_component_hash.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_data_transfer_component_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/e2etests/test_component.py
+Filename: azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/e2etests/test_component_validate.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_component_schema.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_component_operations.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_data_transfer_component_entity.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/e2etests/test_online_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_spark_component_entity.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/e2etests/test_online_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_pipeline_component_entity.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_scale_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_component_operations_registry.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_online_deployments.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_command_component_entity.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_automl_component.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_operations.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_resource_requirements_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_entity.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_schema.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_scale_settings_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/component/unittests/test_component_validate.py
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_executor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/online_services/unittests/test_online_endpoints.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/unittests/
+Filename: azure-ai-ml-1.9.0/tests/monitoring/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/monitoring/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/monitoring/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/e2etests/test_command_job.py
+Filename: azure-ai-ml-1.9.0/tests/monitoring/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/monitoring/e2etests/test_monitor_schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/unittests/test_command_job_entity.py
+Filename: azure-ai-ml-1.9.0/tests/monitoring/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/command_job/unittests/test_command_job_schema.py
+Filename: azure-ai-ml-1.9.0/tests/monitoring/unittests/test_monitor_schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/unittests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/e2etests/test_data_import.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/_util.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/e2etests/test_schedule.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/e2etests/test_upload_download.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/data_import/unittests/test_data_import.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/e2etests/test_telemetry_value.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_logger_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/unittests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_validation.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_operation_orchestrator.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_persistent_locals.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/unittests/test_local_job_invoker.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_fields.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/unittests/test_job_operations.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_asset_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/unittests/test_job_ops_helper.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_telemetry_value.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/job_common/unittests/test_vcr_utils.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_experimental_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/registry/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_asset_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/registry/unittests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_file_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/registry/e2etests/test_registry.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_exceptions.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_operations.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_ml_client.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_entity.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_arm_id_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_schema.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_cloud_environments.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_cache_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/unittests/
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_storage_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_smoke.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_get_content_hash.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_endpoint_entity.py
+Filename: azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_artifact_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_deployment_entity.py
+Filename: azure-ai-ml-1.9.0/tests/feature_set/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_code_configuration.py
+Filename: azure-ai-ml-1.9.0/tests/feature_set/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/feature_set/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/
+Filename: azure-ai-ml-1.9.0/tests/feature_set/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_set/e2etests/test_feature_set.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/_util.py
+Filename: azure-ai-ml-1.9.0/tests/feature_set/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/feature_set/unittests/test_feature_set_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/e2etests/test_upload_download.py
+Filename: azure-ai-ml-1.9.0/tests/feature_set/unittests/test_list_materialization_job_request.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/e2etests/test_telemetry_value.py
+Filename: azure-ai-ml-1.9.0/tests/feature_set/unittests/test_feature_set_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_logger_utils.py
+Filename: azure-ai-ml-1.9.0/tests/registry/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_persistent_locals.py
+Filename: azure-ai-ml-1.9.0/tests/registry/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_storage_utils.py
+Filename: azure-ai-ml-1.9.0/tests/registry/e2etests/test_registry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_fields.py
+Filename: azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_file_utils.py
+Filename: azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_cloud_environments.py
+Filename: azure-ai-ml-1.9.0/tests/test_utilities/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_smoke.py
+Filename: azure-ai-ml-1.9.0/tests/test_utilities/constants.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_arm_id_utils.py
+Filename: azure-ai-ml-1.9.0/tests/test_utilities/json_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_experimental_utils.py
+Filename: azure-ai-ml-1.9.0/tests/test_utilities/utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_asset_utils.py
+Filename: azure-ai-ml-1.9.0/tests/compute/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_ml_client.py
+Filename: azure-ai-ml-1.9.0/tests/compute/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_get_content_hash.py
+Filename: azure-ai-ml-1.9.0/tests/compute/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_artifact_entity.py
+Filename: azure-ai-ml-1.9.0/tests/compute/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_exceptions.py
+Filename: azure-ai-ml-1.9.0/tests/compute/e2etests/test_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_validation.py
+Filename: azure-ai-ml-1.9.0/tests/compute/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_utils.py
+Filename: azure-ai-ml-1.9.0/tests/compute/unittests/test_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_operation_orchestrator.py
+Filename: azure-ai-ml-1.9.0/tests/compute/unittests/test_compute_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_asset_entity.py
+Filename: azure-ai-ml-1.9.0/tests/datastore/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_telemetry_value.py
+Filename: azure-ai-ml-1.9.0/tests/datastore/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_cache_utils.py
+Filename: azure-ai-ml-1.9.0/tests/datastore/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/
+Filename: azure-ai-ml-1.9.0/tests/datastore/e2etests/test_datastore.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/
+Filename: azure-ai-ml-1.9.0/tests/datastore/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/datastore/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/jsonl_converter.py
+Filename: azure-ai-ml-1.9.0/tests/datastore/unittests/test_datastore_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/conftest.py
+Filename: azure-ai-ml-1.9.0/tests/datastore/unittests/test_datastore_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_object_detection.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_classification.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_classification_multilabel.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/_util.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_classification.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_with_specific_nodes.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_classification_multilabel.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_segmentation.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/test_automl_dsl_pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_ner.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_samples.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_classification.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/test_controlflow_pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_regression.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_on_registry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_forecasting.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/__init__.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_fl.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_regression_job.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_with_specific_nodes.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_forecasting_job.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_classification_job.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_object_detection.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_init_finalize_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_tabular_schema.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_io_builder.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_limit_settings.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_pipeline_builder.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_schema.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_component_func.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_n_cross_validation_settings.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_mldesigner_imports.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_classification_multilabel.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_command_builder.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_featurization_settings.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_attr_dict.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_nlp_sweep_settings.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_samples.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_classification.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_group.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_ner_job.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_controlflow_pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_sweep_setting.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_instance_segmentation.py
+Filename: azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_fl.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_nlp_schema.py
+Filename: azure-ai-ml-1.9.0/tests/dataset/e2etests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_classification_multilabel_job.py
+Filename: azure-ai-ml-1.9.0/tests/dataset/unittests/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_setsearchspace.py
+Filename: azure-ai-ml-1.9.0/tests/dataset/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_forecasting_settings.py
+Filename: azure-ai-ml-1.9.0/tests/dataset/e2etests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_classification_job.py
+Filename: azure-ai-ml-1.9.0/tests/dataset/e2etests/test_data_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure_ai_ml.egg-info/top_level.txt
+Filename: azure-ai-ml-1.9.0/tests/dataset/e2etests/test_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure_ai_ml.egg-info/requires.txt
+Filename: azure-ai-ml-1.9.0/tests/dataset/unittests/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure_ai_ml.egg-info/dependency_links.txt
+Filename: azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure_ai_ml.egg-info/not-zip-safe
+Filename: azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure_ai_ml.egg-info/PKG-INFO
+Filename: azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure_ai_ml.egg-info/SOURCES.txt
+Filename: azure-ai-ml-1.9.0/samples/ml_samples_authentication_sovereign_cloud.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/samples/README.md
+Filename: azure-ai-ml-1.9.0/samples/ml_samples_sweep_configurations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/samples/ml_samples_sweep_configurations.py
+Filename: azure-ai-ml-1.9.0/samples/ml_samples_command_configurations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/samples/ml_samples_authentication_sovereign_cloud.py
+Filename: azure-ai-ml-1.9.0/samples/ml_samples_cloud_configurations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/samples/ml_samples_cloud_configurations.py
+Filename: azure-ai-ml-1.9.0/samples/ml_samples_spark_configurations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/
+Filename: azure-ai-ml-1.9.0/samples/README.md
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/__init__.py
+Filename: azure-ai-ml-1.9.0/azure_ai_ml.egg-info/dependency_links.txt
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/
+Filename: azure-ai-ml-1.9.0/azure_ai_ml.egg-info/requires.txt
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/__init__.py
+Filename: azure-ai-ml-1.9.0/azure_ai_ml.egg-info/PKG-INFO
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/
+Filename: azure-ai-ml-1.9.0/azure_ai_ml.egg-info/top_level.txt
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/
+Filename: azure-ai-ml-1.9.0/azure_ai_ml.egg-info/not-zip-safe
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/
+Filename: azure-ai-ml-1.9.0/azure_ai_ml.egg-info/SOURCES.txt
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/
+Filename: azure-ai-ml-1.9.0/azure/ai/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/automl/
+Filename: azure-ai-ml-1.9.0/azure/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/parallel/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_logging/
+Filename: azure-ai-ml-1.9.0/azure/ai/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/parallel/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/data_transfer/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/sweep/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/data_transfer/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_file_utils/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_file_utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_exception_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_logging/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_scope_dependent_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/sweep/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_ml_client.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_user_agent.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/py.typed
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_azure_environments.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/automl/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_ml_client.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/exceptions.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/py.typed
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_exception_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_deployment_executor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_scope_dependent_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_base.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/exceptions.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_user_agent.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/code_version.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_azure_environments.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/online_deployment.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_param.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/activity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/online_endpoint.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/_customtraceback.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/base_template.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/logging_handler.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/model.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_artifact_utilities.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/model_version.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/update_online_endpoint.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_gen2_storage_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/environment_version.json
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_fileshare_storage_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_constants.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_package_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_blob_storage_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/parallel/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_cache_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_azureml_polling.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_preflight_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_html_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/flatten_json/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_http_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_experimental.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_registry_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/_resource_management_client.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_pathspec.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/azure_resource_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_data_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_logger_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/_resource_management_client.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_storage_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_appinsights_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_arm_id_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_providers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_func_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resource_groups_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_feature_store_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployment_operations_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_asset_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_endpoint_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_tags_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_workspace_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_providers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_resource_groups_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_deployment_operations_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_tags_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/flatten_json/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_index_service_apis.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_resource_management_client_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_registry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_index_service_apis.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_common.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/_index_entities_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_assets.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_monitoring.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_index_service_apis_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_workspace.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/_index_entities_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/automl.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_parallel_for.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/sweep.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_pipeline_decorator.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_condition.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_load_import.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_fl_scatter_gather_node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_constants.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_pipeline_component_builder.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_exceptions.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_group_decorator.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/_AzureMLSparkOnBehalfOfCredential.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_component_func.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/aml_on_behalf_of.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_dynamic.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_overrides_definition.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/get_token_mixin.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_do_while.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/managed_identity_base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/managed_identity_client.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_credentials/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_registry.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_credentials/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_credentials/aml_on_behalf_of.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_monitoring.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/get_token_mixin.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_common.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/managed_identity_base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_assets.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/managed_identity_client.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_workspace.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_operation_orchestrator.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/sweep.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_dataset_dataplane_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/pipeline.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_job_ops_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/automl.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_code_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_registry_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/automl/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_datastore_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_image.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_run_history_constants.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_nlp.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_data_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_tabular.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_batch_deployment_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/parallel/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_virtual_cluster_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_logging/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_logging/chained_identity.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_environment_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_logging/debug_mode.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_deployment_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_job_invoker.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_endpoint_helper.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_component_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_model_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/docker_client.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_job_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/dockerfile_instructions.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_model_dataplane_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/local_endpoint_mode.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_online_endpoint_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/endpoint_stub.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_run_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/azureml_image_context.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_schedule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/mdc_config_resolver.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_set_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/dockerfile_resolver.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_operations_base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/environment_validator.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_store_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/model_validator.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_store_entity_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/code_validator.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_batch_endpoint_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_outbound_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/wsl_utility.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/operations/_online_deployment_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/commandline_utility.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/vscode_client.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_resolver.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_properties.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_exceptions.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/_AzureMLSparkOnBehalfOfCredential.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/aml_on_behalf_of.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_credentials/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_credentials/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_credentials/aml_on_behalf_of.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/managed_identity_base.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/managed_identity_client.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/get_token_mixin.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/managed_identity_base.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/pipeline.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/managed_identity_client.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/get_token_mixin.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_utils/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/dsl/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_setup.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_utils/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_utils/_yaml_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/dsl/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/command.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/environment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/input_output.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/parallel.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/command.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_additional_includes.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/code.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/spark.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/scope.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_merkle_tree.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/environment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_input_outputs.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/itp_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/ai_super_computer_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/target_selector.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_notification/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/identity.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/queue_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/resource_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/spark_resource_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job_resource_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_notification/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_notification/notification_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/signals.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/thresholds.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/input_data.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/monitor_definition.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/target.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/alert_notification.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/trigger.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/create_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/data_binding_expression.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/feature_store_entity_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/data_column_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_temporary_data_references_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_references_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/forecasting_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/automl_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/featurization_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/automl_vertical.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/training_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_fixed_parameters.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical_limit_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_parameter_subspace.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_resource_management_asset_reference_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_ner.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_temporary_data_references_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification_multilabel.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_references_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_sweep_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/classification.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/forecasting.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical_limit_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/regression.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_vertical.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_classification.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_sweep_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_resource_management_asset_reference_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_limit_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_model_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_model_distribution_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_object_detection.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/code_configuration_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/compute_binding.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_pipeline_component_deployment_configurations_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/run_settings_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/job_definition_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/pipeline_component_batch_deployment_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_async_operations_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/scale_settings_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_registry_management_non_workspace_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/_async_operations_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/request_logging_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/liveness_probe.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/_registry_management_non_workspace_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/deployment_collection_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/oversize_data_config_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/event_hub_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/data_collector_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/resource_settings_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/payload_response_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/data_asset_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/request_settings_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/resource_requirements_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/online_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/intellectual_property.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/fields.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/auto_delete_setting.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/schema_meta.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/resource.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/_on_prem_credentials.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_metric_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/_on_prem.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_artifacts_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/adls_gen1.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_delete_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/credentials.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_runs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/azure_storage.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_spans_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_experiments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/online/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_events_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_metric_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_run_artifacts_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint_defaults.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_delete_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/online/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_runs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/online/online_endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_spans_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_experiments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/identity.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_run_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/networking.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_events_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/workspace.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/private_endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/endpoint_connection.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/customer_managed_key.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/workspace_connection.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/credentials.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_termination.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_fields_provider.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_objective.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_sampling_algorithm.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/parameterized_sweep.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/choice.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/randint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/normal.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/uniform.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_spark_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/automl_node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_settings_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_import_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/control_flow_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_command_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_datatransfer_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_job_io.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/condition_node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/component_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_parallel_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/import_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/identity.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/services.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/base_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parallel_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_output_fields_provider.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_port.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_provisions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_spark.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_command.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/job_output.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/spark_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_output_entry.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_parallel.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/creation_context.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/command_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/data_transfer_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/distribution.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/job_limits.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/aml_compute_node_info.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/usage.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/kubernetes_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/aml_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/synapsespark_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/custom_applications.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/attached_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/setup_scripts.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/vm_size.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_settings_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/compute_instance.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/virtual_machine_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/model.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/data.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/artifact.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/workspace_asset_reference.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/federated_learning_silo.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/code_asset.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/environment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/asset.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/route.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/base_environment_source.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_package_input.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_provisions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_package.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/inference_server.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/online_inference_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/parallel_task.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/parallel_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/spark_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/data_transfer_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/import_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/automl_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/resource.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/retry_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/input_output.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/command_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/featureset_spec_metadata_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/timestamp_column_metadata_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/delay_metadata_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/source_metadata_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/featureset_spec_properties_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_set_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_transformation_code_metadata_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_set_specification_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/materialization_settings_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/registry.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/registry_region_arm_details.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/system_created_storage_account.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/util.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/system_created_acr_account.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/feature_store_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/materialization_store_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/compute_runtime_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_version_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/mltable_metadata_path_schemas.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_datasets_v1_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/mltable_metadata_schema.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_v2_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_delete_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/data_import.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_get_operation_status_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_call_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_container_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/logging_handler.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_controller_v2_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/activity.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_version_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/_customtraceback.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_notification/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_datasets_v1_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_v2_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_delete_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_get_operation_status_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_call_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_container_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_controller_v2_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_data/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_credentials.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_validation.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_load_functions.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_mixins.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_validate_funcs.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_system_data.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_util.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_resource.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_notification/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_notification/notification.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/feature_store_entity.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/data_column.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/data_column_type.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/registry.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/registry_support_classes.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/util.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/signals.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/thresholds.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/input_data.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/definition.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/target.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/alert_notification.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_vm_size.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/unsupported_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/kubernetes_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/aml_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/synapsespark_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_aml_compute_node_info.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_image_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_usage.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_custom_applications.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/compute_instance.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/virtual_machine_compute.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_setup_scripts.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/model_batch_deployment_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/batch_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/container_resource_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/payload_response.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/request_logging.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/data_collector.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment_collection.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/resource_requirements_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/run_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/pipeline_component_batch_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/event_hub.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/batch_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/code_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/data_asset.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/model_batch_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/online_deployment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/oversize_data_config.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/scale_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/job_definition.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_on_prem_credentials.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/datastore.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_on_prem.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/adls_gen1.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/azure_storage.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/batch_endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/online_endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/_endpoint_helpers.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/sweep.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/command.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/do_while.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/pipeline.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/spark.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel_func.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/fl_scatter_gather.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/import_node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/import_func.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/base_node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/data_transfer_func.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/command_func.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/control_flow_node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/spark_func.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel_for.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/condition_node.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/data_transfer.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/subcomponents.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/data_transfer/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/import_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job_entry_mixin.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_service.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/base_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/service_instance.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/input_port.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_settings_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/_studio_url_from_job_id.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parameterized_spark.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/compute_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parameterized_command.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_name_generator.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/queue_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/resource_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/input_output_entry.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/to_rest_functions.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/_input_output_helpers.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job_entry.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/command_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_io_mixin.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_resource_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_resource_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/distribution.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_limits.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_helpers.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_provisions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/search_space_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/search_space.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/automl_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/featurization_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/automl_vertical.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/stack_ensemble_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/training_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/automl_tabular.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/classification_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/limit_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/regression_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/featurization_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_fixed_parameters.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_search_space.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_limit_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_featurization_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_multilabel_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_ner_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_settings_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_sweep_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/automl_nlp_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image_classification_base.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_search_space.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image_object_detection_base.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_instance_segmentation_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_sweep_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_limit_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_multilabel_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_model_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_search_space.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parallel_task.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/run_function.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parallel_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parameterized_parallel.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_provisions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/retry_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/data/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/pipeline_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_pipeline_job_helpers.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_load_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_pipeline_expression.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/pipeline_job_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_attr_dict.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_component_translatable.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/attr_dict.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/base.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/mixin.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/data/expression_component_template.yml
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/data_transfer/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/data_transfer/data_transfer_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/sampling_algorithm.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/search_space.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/sweep_job.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/early_termination_policy.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/objective.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/parameterized_sweep.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/group_input.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/external_data.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/input.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/enum_input.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/base.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/output.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/networking.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/workspace.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/workspace_keys.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/private_endpoint.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/diagnose.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/compute_runtime.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/feature_store_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/customer_managed_key.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/workspace_connection.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/credentials.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_specification.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_materialization_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/featureset_spec_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_settings.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_compute_resource.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_type.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_backfill_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/timestamp_column_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/delay_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_transformation_code_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/source_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/feature_store.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/materialization_store.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_data/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_data/mltable_metadata.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/_additional_includes.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/code.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/parallel_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/component_factory.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/datatransfer_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/spark_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/import_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/automl_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/_artifact_cache.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/command_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/pipeline_component.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/trigger.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/data_import.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/schedule.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/intellectual_property.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/auto_delete_setting.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/workspace_asset_reference.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/federated_learning_silo.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/environment.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/asset.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/model.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/code.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/data.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/artifact.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/feature_set.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/base_environment_source.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_package.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/inferencing_server.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_artifact_utilities.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_gen2_storage_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_blob_storage_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_fileshare_storage_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/data_transfer/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/sweep/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_managed_network_settings_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featureset_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featurestore_entity_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featureset_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_managed_network_provisions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featurestore_entity_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_managed_network_settings_rule_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featureset_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featurestore_entity_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featureset_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_managed_network_provisions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_models_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_extensive_model_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_migration_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_assets_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featurestore_entity_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_models_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_extensive_model_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_migration_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_assets_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_provisions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_settings_rule_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_provisions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_settings_rule_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_resource_management_asset_reference_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_references_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_temporary_data_references_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_resource_management_asset_reference_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_references_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_temporary_data_references_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_schedules_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_labeling_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_registry_management_non_workspace_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_async_operations_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/_registry_management_non_workspace_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/_async_operations_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_experiments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_spans_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_artifacts_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_delete_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_metric_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_events_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registries_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_runs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_experiments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_spans_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_run_artifacts_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_delete_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_metric_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_events_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_run_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_runs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_models_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_assets_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_migration_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_extensive_model_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_models_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_assets_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_migration_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_extensive_model_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_deployment_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_endpoint_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_deployment_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_endpoint_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_jobs_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_containers_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_versions_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_datastores_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_provisions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_azure_machine_learning_workspaces.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_settings_rule_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_usages_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_link_resources_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_quotas_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_virtual_machine_sizes_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_compute_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_endpoint_connections_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspaces_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_features_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_azure_machine_learning_workspaces_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_provisions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/dsl/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_setup.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_utils/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_utils/_yaml_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/environment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/input_output.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/command.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/environment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/scope.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/code.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/spark.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_input_outputs.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_settings_rule_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/parallel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_additional_includes.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/command.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_merkle_tree.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/itp_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/target_selector.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/ai_super_computer_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_internal/dsl/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/data_transfer/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_logger_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_html_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_azureml_polling.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_feature_store_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_storage_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_func_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_experimental.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_cache_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_asset_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/azure_resource_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_package_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_registry_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_workspace_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_endpoint_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_http_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_preflight_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_controller_v2_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_arm_id_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_artifact_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_v2_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_pathspec.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_delete_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_data_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_datasets_v1_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_call_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_appinsights_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_container_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_version_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_get_operation_status_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_controller_v2_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_v2_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_version.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_delete_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_vendor.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_datasets_v1_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_call_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_index_service_apis.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_container_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_version_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_get_operation_status_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_patch.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_index_service_apis.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/_index_entities_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/_index_entities_operations.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models_py3.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_index_service_apis_enums.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_notification/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job_resource_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/identity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/resource_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/queue_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/spark_resource_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/data_import.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/model.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/environment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/federated_learning_silo.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/asset.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/code_asset.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/artifact.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/workspace_asset_reference.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_package.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/base_environment_source.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/route.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/online_inference_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/inference_server.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_package_input.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/create_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/trigger.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/workspace.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/networking.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/identity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/endpoint_connection.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/customer_managed_key.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/private_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/credentials.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/workspace_connection.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/data_column_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/feature_store_entity_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/intellectual_property.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/schema_meta.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/resource.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/auto_delete_setting.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/fields.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/code_configuration_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/pipeline_component_batch_deployment_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/compute_binding.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/job_definition_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/run_settings_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_pipeline_component_deployment_configurations_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/data_collector_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/resource_requirements_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/scale_settings_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/online_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/payload_response_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/oversize_data_config_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/event_hub_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/request_settings_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/liveness_probe.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/data_asset_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/deployment_collection_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/request_logging_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/resource_settings_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/azure_storage.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/_on_prem.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/credentials.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/adls_gen1.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/_on_prem_credentials.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_set_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_set_specification_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/delay_metadata_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/materialization_settings_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/timestamp_column_metadata_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/source_metadata_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_transformation_code_metadata_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/featureset_spec_metadata_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/featureset_spec_properties_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/data_binding_expression.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/online/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint_defaults.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/online/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/online/online_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/retry_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/spark_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/command_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/parallel_task.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/import_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/automl_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/data_transfer_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/resource.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/input_output.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/parallel_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_notification/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_notification/notification_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/feature_store_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/materialization_store_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/compute_runtime_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/component_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_parallel_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_job_io.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/condition_node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_spark_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/automl_node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_command_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_datatransfer_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_import_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/control_flow_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/alert_notification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/signals.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/input_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/target.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/monitor_definition.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/thresholds.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_output_entry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parallel_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/job_output.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/command_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/import_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/job_limits.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_port.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/spark_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_parallel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/identity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/base_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/services.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_command.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/creation_context.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_output_fields_provider.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_spark.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/distribution.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/data_transfer_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/mltable_metadata_schema.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/mltable_metadata_path_schemas.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/util.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/system_created_storage_account.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/registry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/system_created_acr_account.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/registry_region_arm_details.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/kubernetes_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/aml_compute_node_info.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/synapsespark_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/custom_applications.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/setup_scripts.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/virtual_machine_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/attached_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/aml_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/compute_instance.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/usage.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/vm_size.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/parameterized_sweep.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/_constants.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_fields_provider.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_sampling_algorithm.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_termination.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_objective.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/randint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/normal.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/uniform.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/choice.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/featurization_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/automl_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/training_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/automl_vertical.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/forecasting_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/regression.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/forecasting.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical_limit_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/classification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_object_detection.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_model_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_model_distribution_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_sweep_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_limit_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_classification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_vertical.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification_multilabel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_fixed_parameters.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_ner.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_parameter_subspace.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_sweep_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical_limit_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_notification/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_data/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_validate_funcs.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_validation.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_credentials.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_load_functions.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_system_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_mixins.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_resource.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_util.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/data_import.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/spark_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/pipeline_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/command_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/code.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/datatransfer_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/import_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/_additional_includes.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/automl_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/component_factory.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/parallel_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/input.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/external_data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/output.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/enum_input.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/group_input.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/kubernetes_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_usage.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_schedule.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/synapsespark_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_vm_size.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/virtual_machine_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_image_metadata.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/aml_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/compute_instance.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_deployment_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_aml_compute_node_info.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_endpoint_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_custom_applications.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_setup_scripts.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/unsupported_compute.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/environment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_deployment_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_endpoint_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/intellectual_property.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/federated_learning_silo.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/asset.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/auto_delete_setting.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/workspace_asset_reference.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_vendor.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/model.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_version.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/data.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/code.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/artifact.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/feature_set.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_azure_machine_learning_workspaces.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_patch.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_package.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/base_environment_source.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/inferencing_server.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/workspace.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/diagnose.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/networking.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/customer_managed_key.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/compute_runtime.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/workspace_keys.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/feature_store_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/private_endpoint.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/credentials.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/workspace_connection.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/feature_store_entity.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/data_column.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/data_column_type.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/job_definition.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/resource_requirements_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/model_batch_deployment_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/data_collector.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/batch_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/online_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/code_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/request_logging.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/model_batch_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/oversize_data_config.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/container_resource_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/batch_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment_collection.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/pipeline_component_batch_deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/scale_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/payload_response.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/event_hub.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/data_asset.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/run_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/azure_storage.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_on_prem.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_constants.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/datastore.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_azure_machine_learning_workspaces_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/adls_gen1.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_on_prem_credentials.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/control_flow_node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_endpoint_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/import_node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/subcomponents.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/fl_scatter_gather.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/sweep.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/import_func.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/do_while.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/data_transfer_func.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/base_node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel_for.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/spark.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/command_func.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/condition_node.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_datastores_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/pipeline.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registries_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel_func.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/spark_func.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_schedules_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/command.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/data_transfer.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_quotas_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/data_transfer/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_usages_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/input_output_entry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/to_rest_functions.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_endpoints_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_name_generator.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_features_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_service.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_virtual_machine_sizes_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/command_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/_studio_url_from_job_id.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/import_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_containers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_limits.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_labeling_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_resource_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/input_port.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_link_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_jobs_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/base_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/_input_output_helpers.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/resource_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspaces_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parameterized_command.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/queue_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_versions_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/service_instance.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_file_utils/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_io_mixin.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_file_utils/file_utils.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parameterized_spark.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job_entry_mixin.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job_entry.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/flatten_json/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_resource_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_helpers.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/distribution.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/compute_configuration.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/_resource_management_client.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parallel_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/retry_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/flatten_json/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/run_function.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parallel_task.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/_resource_management_client.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parameterized_parallel.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/_configuration.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/data_transfer/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/data_transfer/data_transfer_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_providers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/data/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resource_groups_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/pipeline_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployment_operations_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/pipeline_job_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_tags_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_pipeline_expression.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_attr_dict.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_component_translatable.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_models.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_load_component.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_resource_management_client_enums.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_pipeline_job_helpers.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_models_py3.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/attr_dict.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_providers_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_resources_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/mixin.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_resource_groups_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/data/expression_component_template.yml
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_deployment_operations_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/parameterized_sweep.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_tags_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/sweep_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_deployments_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/search_space.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_connections_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/sampling_algorithm.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_online_deployment_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/objective.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/__init__.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/early_termination_policy.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_endpoint_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_outbound_rule_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_operation_orchestrator.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_code_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_run_history_constants.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/featurization_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_job_ops_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/stack_ensemble_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_model_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/automl_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_batch_endpoint_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/training_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_dataset_dataplane_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/search_space.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_deployment_helper.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/search_space_utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_model_dataplane_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/utils.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_virtual_cluster_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/automl_vertical.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_job_invoker.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_store_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_batch_deployment_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/featurization_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_registry_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/regression_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_schedule_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/automl_tabular.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_data_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/classification_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_run_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/limit_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_compute_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_online_endpoint_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image_classification_base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/__init__.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_store_entity_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_instance_segmentation_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_datastore_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_model_settings.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_environment_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_multilabel_job.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_job_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image_object_detection_base.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_operations_base.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_component_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_search_space.py
 Comment: 
 
-Filename: azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_set_operations.py
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_sweep_settings.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_job.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_job.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_limit_settings.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_search_space.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_multilabel_job.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_fixed_parameters.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_limit_settings.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_job.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_featurization_settings.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_ner_job.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_sweep_settings.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_search_space.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/automl_nlp_job.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_compute_resource.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/source_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_materialization_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_settings.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_transformation_code_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/featureset_spec_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_backfill_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_specification.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/delay_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_type.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/timestamp_column_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/util.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/registry_support_classes.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/registry.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/schedule.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/trigger.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/endpoint.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/_endpoint_helpers.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/online_endpoint.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/batch_endpoint.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_notification/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_notification/notification.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/_constants.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/feature_store.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/materialization_store.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_data/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_data/mltable_metadata.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/schedule.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/alert_notification.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/signals.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/definition.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/input_data.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/target.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/thresholds.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_file_utils/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_file_utils/file_utils.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_logging/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_logging/chained_identity.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_logging/debug_mode.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/sweep/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/dockerfile_resolver.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/docker_client.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/azureml_image_context.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/mdc_config_resolver.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/dockerfile_instructions.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/endpoint_stub.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/local_endpoint_mode.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/vscode_client.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_properties.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_resolver.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/model_validator.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/code_validator.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/environment_validator.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/commandline_utility.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/wsl_utility.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_condition.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_load_import.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_component_func.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_constants.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_utils.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_do_while.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_group_decorator.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_pipeline_decorator.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_pipeline_component_builder.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_overrides_definition.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_parallel_for.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_fl_scatter_gather_node.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_settings.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_dynamic.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/_constants.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_deployment_executor.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_helper.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_base.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/online_endpoint.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/model_version.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_param.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/code_version.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/update_online_endpoint.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/base_template.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/model.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/online_deployment.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/environment_version.json
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_image.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/automl/__init__.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_nlp.py
+Comment: 
+
+Filename: azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_tabular.py
 Comment: 
 
 Zip file comment:
```

## Comparing `azure-ai-ml-1.8.0/CHANGELOG.md` & `azure-ai-ml-1.9.0/CHANGELOG.md`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,34 @@
 # Release History
 
+## 1.9.0 (2023-07-25)
+### Features Added
+- Added support to enable gpu access (local_enable_gpu) for local deployment.
+
+### Other Changes
+- Improved the output when printing a workspace object to be more clean and readable.
+- Log level of unknown field notifications for pipeline nodes raised from INFO to WARNING.
+
 ## 1.8.0 (2023-06-12)
 
 ### Features Added
 - Added support to enable set workspace connection secret expiry time.
 - Added support for `stage` on model version
+- Added support to enable gpu access (local_enable_gpu) for local deployment.
 
 ### Bugs Fixed
 
 - Fixed an issue affecting authentication to registry-related services in sovereign regions.
 - Made job_tier and priority values case insensitive
 
+### Breaking Changes
+
+### Other Changes
+- Log level of unknown field notifications for pipeline nodes raised from INFO to WARNING.
+
 
 ## 1.7.2 (2023-05-18)
 
 ### Features Added
 - Public preview support for new schedule type `MonitorSchedule`
```

## Comparing `azure-ai-ml-1.8.0/README.md` & `azure-ai-ml-1.9.0/README.md`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/setup.py` & `azure-ai-ml-1.9.0/setup.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/NOTICE.txt` & `azure-ai-ml-1.9.0/NOTICE.txt`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/documentation_guidelines.md` & `azure-ai-ml-1.9.0/documentation_guidelines.md`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 ## **AzureML v2 Reference Documentation Guide**
 
-When updating the codebase, please note the following guidelines for creating user-friendly docstrings.
+When updating the codebase, please note the following guidelines for creating user-friendly docstrings. These are in alignment with the [Azure SDK for Python documentation guidelines](https://azure.github.io/azure-sdk/python_documentation.html#docstrings).
  
 #### Principles 
 
 1. **Accuracy**: The documentation accurately reflects the features and functionality of the product.
 2. **Completeness**: The documentation covers all relevant features and functionality of the product.
 3. **Clarity**: The documentation is written in clear, concise language that is easy to understand.  
 4. **Consistency**: The documentation has a consistent format and structure, making it easy to navigate and follow.  
@@ -42,16 +42,16 @@
        :class: info 
        This is an informational admonition. 
     ```
  
 
 ##### Clarity 
 
- - Use Union/Optional when appropriate in function declaration, but not in docstring. Instead, note the default value in the docstring (e.g. Defaults to 0.).
- - For classes, include summary in definition only. If you include in both class definition and constructor (init method) docstrings, it will show up twice in the reference docs.
+ - Use Union/Optional when appropriate in function declaration, and note the default value in the docstring (e.g. Defaults to 0.).
+ - For classes, include docstring in definition only. If you include a docstring in both the class definition and the constructor (init method) docstrings, it will show up twice in the reference docs.
  - When referencing an AzureML v2 class as a type in a docstring, use the full path to the class and prepend it with a "~". This will create a link when the documentation is rendered on learn.microsoft.com that will take the user to the class reference documentation for more information.
 
 ```python
 """
 :param sampling_algorithm: Sampling algorithm for sweep job.
 :type sampling_algorithm: ~azure.ai.ml.sweep.SamplingAlgorithm
 """
```

## Comparing `azure-ai-ml-1.8.0/PKG-INFO` & `azure-ai-ml-1.9.0/PKG-INFO`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: azure-ai-ml
-Version: 1.8.0
+Version: 1.9.0
 Summary: Microsoft Azure Machine Learning Client Library for Python
 Home-page: https://github.com/Azure/azure-sdk-for-python
 Author: Microsoft Corporation
 Author-email: azuresdkengsysadmins@microsoft.com
 License: MIT License
 Project-URL: Bug Reports, https://github.com/Azure/azure-sdk-for-python/issues
 Project-URL: Source, https://github.com/Azure/azure-sdk-python
@@ -164,25 +164,39 @@
 [code_of_conduct]: https://opensource.microsoft.com/codeofconduct/
 [coc_faq]: https://opensource.microsoft.com/codeofconduct/faq/
 [coc_contact]: mailto:opencode@microsoft.com
 
 
 # Release History
 
+## 1.9.0 (2023-07-25)
+### Features Added
+- Added support to enable gpu access (local_enable_gpu) for local deployment.
+
+### Other Changes
+- Improved the output when printing a workspace object to be more clean and readable.
+- Log level of unknown field notifications for pipeline nodes raised from INFO to WARNING.
+
 ## 1.8.0 (2023-06-12)
 
 ### Features Added
 - Added support to enable set workspace connection secret expiry time.
 - Added support for `stage` on model version
+- Added support to enable gpu access (local_enable_gpu) for local deployment.
 
 ### Bugs Fixed
 
 - Fixed an issue affecting authentication to registry-related services in sovereign regions.
 - Made job_tier and priority values case insensitive
 
+### Breaking Changes
+
+### Other Changes
+- Log level of unknown field notifications for pipeline nodes raised from INFO to WARNING.
+
 
 ## 1.7.2 (2023-05-18)
 
 ### Features Added
 - Public preview support for new schedule type `MonitorSchedule`
```

## Comparing `azure-ai-ml-1.8.0/tests/conftest.py` & `azure-ai-ml-1.9.0/tests/conftest.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,21 @@
 import base64
-import hashlib
 import json
 import os
 import random
 import re
 import shutil
 import time
 import uuid
 from collections import namedtuple
 from datetime import datetime
-from functools import partial
 from importlib import reload
 from os import getenv
 from pathlib import Path
-from typing import Callable, Optional, Tuple, Union
+from typing import Callable, Tuple, Union
 from unittest.mock import Mock, patch
 
 import pytest
 from _pytest.fixtures import FixtureRequest
 from azure.core.exceptions import ResourceNotFoundError
 from azure.core.pipeline.transport import HttpTransport
 from azure.identity import AzureCliCredential, ClientSecretCredential, DefaultAzureCredential
@@ -660,34 +658,14 @@
     """Normalize component dict with sanitized value and return hash."""
     dict_hash = hash_dict(*args, **kwargs)
     normalized_dict_hash = normalized_hash_dict(*args, **kwargs)
     add_general_string_sanitizer(value=normalized_dict_hash, target=dict_hash)
     return dict_hash
 
 
-def get_client_hash_with_request_node_name(
-    subscription_id: Optional[str],
-    resource_group_name: Optional[str],
-    workspace_name: Optional[str],
-    registry_name: Optional[str],
-    random_seed: str,
-):
-    """Generate a hash for the client."""
-    object_hash = hashlib.sha256()
-    for s in [
-        subscription_id,
-        resource_group_name,
-        workspace_name,
-        registry_name,
-        random_seed,
-    ]:
-        object_hash.update(str(s).encode("utf-8"))
-    return object_hash.hexdigest()
-
-
 def clear_on_disk_cache(cached_resolver):
     """Clear on disk cache for current client."""
     cached_resolver._lock.acquire()
     shutil.rmtree(cached_resolver._on_disk_cache_dir, ignore_errors=True)
     cached_resolver._lock.release()
 
 
@@ -720,34 +698,38 @@
     # 1) We can't guarantee that server-side will return the same version for 2 anonymous component
     #   with the same on-disk hash.
     # 2) Server-side may return different version for the same anonymous component in different workspace,
     #   while workspace information will be normalized in recordings. If we record test1 in workspace A
     #   and test2 in workspace B, the version in recordings can be different.
     # So we use a random (probably unique) on-disk cache base directory for each test, and on-disk cache operations
     # will be thread-safe when concurrently running different tests.
-    mocker.patch(
-        "azure.ai.ml._utils._cache_utils.CachedNodeResolver._get_client_hash",
-        side_effect=partial(get_client_hash_with_request_node_name, random_seed=uuid.uuid4().hex),
-    )
+    involved_client_keys = set()
+    if not is_live_and_not_recording():
+        # Get client id will involve a new request to server, which is specifically tested in some tests.
+        # We mock it in playback mode to avoid changing recordings for most tests.
+        mock_workspace_id, mock_registry_id = uuid.uuid4().hex, uuid.uuid4().hex
+        mocker.patch(
+            "azure.ai.ml.operations._component_operations.ComponentOperations._get_workspace_key",
+            return_value=mock_workspace_id,
+        )
+        mocker.patch(
+            "azure.ai.ml.operations._component_operations.ComponentOperations._get_registry_key",
+            return_value=mock_registry_id,
+        )
+        involved_client_keys = {mock_workspace_id, mock_registry_id}
 
     # Collect involved resolvers before yield, as fixtures may be destroyed after yield.
     from azure.ai.ml._utils._cache_utils import CachedNodeResolver
 
     involved_resolvers = []
-    for client_fixture_name in ["client", "registry_client"]:
-        if client_fixture_name not in request.fixturenames:
-            continue
-        client: MLClient = request.getfixturevalue(client_fixture_name)
+    for client_key in involved_client_keys:
         involved_resolvers.append(
             CachedNodeResolver(
                 resolver=None,
-                subscription_id=client.subscription_id,
-                resource_group_name=client.resource_group_name,
-                workspace_name=client.workspace_name,
-                registry_name=client._operation_scope.registry_name,
+                client_key=client_key,
             )
         )
 
     yield
 
     # clear on-disk cache after each test
     for resolver in involved_resolvers:
```

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/e2etests/test_local_endpoint.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/e2etests/test_local_endpoint.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,12 @@
 import random
 
 import pytest
+import platform
+import sys
 
 from azure.ai.ml import MLClient, load_online_deployment, load_online_endpoint
 from azure.ai.ml.entities import OnlineDeployment, OnlineEndpoint
 from azure.ai.ml.entities._assets._artifacts.code import Code
 from azure.ai.ml.entities._assets._artifacts.model import Model
 from azure.ai.ml.entities._assets.environment import Environment
 from azure.core.exceptions import ResourceNotFoundError
@@ -38,24 +40,27 @@
 @pytest.fixture
 def request_file() -> str:
     return "./tests/test_configs/deployments/model-1/sample-request.json"
 
 
 @pytest.mark.e2etest
 @pytest.mark.local_endpoint_local_assets
-@pytest.mark.skip()
+@pytest.mark.skipif(
+    platform.python_implementation() == "PyPy" or sys.platform.startswith("darwin"),
+    reason="Skipping for PyPy and macOS as docker installation is not supported and skipped in dev_requirement.txt",
+)
 def test_local_endpoint_mir_e2e(
     endpoint_mir_yaml: str,
     mir_endpoint_name: str,
     request_file: str,
     client: MLClient,
 ) -> None:
     endpoint = load_online_endpoint(endpoint_mir_yaml)
     endpoint.name = mir_endpoint_name
-    client.online_endpoints.begin_create_or_update(endpoint=endpoint, no_wait=False, local=True)
+    client.online_endpoints.begin_create_or_update(endpoint=endpoint, local=True)
 
     get_obj = client.online_endpoints.get(name=mir_endpoint_name, local=True)
     assert get_obj is not None
 
     list_obj = client.online_endpoints.list(local=True)
     assert list_obj is not None
     assert len(list(list_obj)) > 0
```

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_mdc_config_resolver.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_mdc_config_resolver.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_dockerfile_resolver.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_dockerfile_resolver.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_local_endpoint_validator.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_local_endpoint_validator.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_dockerfile_instructions.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_dockerfile_instructions.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_devcontainer_resolver.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_devcontainer_resolver.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_endpoint_stub.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_endpoint_stub.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_docker_client.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_docker_client.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/local_endpoint/unittests/test_devcontainer_properties.py` & `azure-ai-ml-1.9.0/tests/local_endpoint/unittests/test_devcontainer_properties.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/monitoring/e2etests/test_monitor_schedule.py` & `azure-ai-ml-1.9.0/tests/monitoring/e2etests/test_monitor_schedule.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,15 +21,19 @@
 from azure.ai.ml.entities._load_functions import load_schedule
 from azure.ai.ml.entities import MonitorSchedule, DataDriftSignal, DataQualitySignal, PredictionDriftSignal
 from azure.ai.ml.entities._monitoring.thresholds import (
     DataDriftMetricThreshold,
     DataQualityMetricThreshold,
     PredictionDriftMetricThreshold,
 )
-from azure.ai.ml._utils._arm_id_utils import is_ARM_id_for_resource, is_ARM_id_for_parented_resource
+from azure.ai.ml._utils._arm_id_utils import (
+    is_ARM_id_for_resource,
+    is_ARM_id_for_parented_resource,
+    AMLVersionedArmId,
+)
 from azure.ai.ml._utils.utils import snake_to_camel
 
 
 @pytest.mark.timeout(600)
 @pytest.mark.usefixtures("recorded_test")
 @pytest.mark.core_sdk_test
 class TestMonitorSchedule(AzureRecordedTestCase):
```

## Comparing `azure-ai-ml-1.8.0/tests/monitoring/unittests/test_monitor_schedule.py` & `azure-ai-ml-1.9.0/tests/monitoring/unittests/test_monitor_schedule.py`

 * *Files 2% similar despite different names*

```diff
@@ -57,14 +57,15 @@
     @pytest.mark.skip(reason="model performance not supported in PuP")
     def test_model_performance_basic(self) -> None:
         json_path = "tests/test_configs/monitoring/rest_json_configs/model_performance_rest.json"
         yaml_path = "tests/test_configs/monitoring/yaml_configs/model_performance.yaml"
 
         validate_to_from_rest_translation(json_path, yaml_path)
 
+    @pytest.mark.skip(reason="Temporarily disabled")
     def test_custom_basic(self) -> None:
         json_path = "tests/test_configs/monitoring/rest_json_configs/custom_rest.json"
         yaml_path = "tests/test_configs/monitoring/yaml_configs/custom.yaml"
 
         validate_to_from_rest_translation(json_path, yaml_path)
 
     @pytest.mark.parametrize(
```

## Comparing `azure-ai-ml-1.8.0/tests/schedule/e2etests/test_schedule.py` & `azure-ai-ml-1.9.0/tests/schedule/e2etests/test_schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/schedule/unittests/test_schedule_schema.py` & `azure-ai-ml-1.9.0/tests/schedule/unittests/test_schedule_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/schedule/unittests/test_schedule_entity.py` & `azure-ai-ml-1.9.0/tests/schedule/unittests/test_schedule_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/virtual_cluster/e2etests/test_vc.py` & `azure-ai-ml-1.9.0/tests/virtual_cluster/e2etests/test_vc.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/virtual_cluster/unittests/test_vc_operations.py` & `azure-ai-ml-1.9.0/tests/virtual_cluster/unittests/test_vc_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/_util.py` & `azure-ai-ml-1.9.0/tests/dsl/_util.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_samples.py` & `azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_samples.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline.py` & `azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,20 +4,15 @@
 from typing import Callable
 from unittest.mock import patch
 
 import pydash
 import pytest
 from devtools_testutils import AzureRecordedTestCase, is_live
 from pipeline_job.e2etests.test_pipeline_job import assert_job_input_output_types
-from test_utilities.utils import (
-    _PYTEST_TIMEOUT_METHOD,
-    assert_job_cancel,
-    omit_with_wildcard,
-    sleep_if_live,
-)
+from test_utilities.utils import _PYTEST_TIMEOUT_METHOD, assert_job_cancel, omit_with_wildcard, sleep_if_live
 
 from azure.ai.ml import (
     AmlTokenConfiguration,
     Input,
     ManagedIdentityConfiguration,
     MLClient,
     MpiDistribution,
@@ -25,36 +20,23 @@
     PyTorchDistribution,
     TensorFlowDistribution,
     UserIdentityConfiguration,
     command,
     dsl,
     load_component,
 )
-from azure.ai.ml._utils._arm_id_utils import (
-    is_ARM_id_for_resource,
-    is_singularity_id_for_resource,
-)
-from azure.ai.ml.constants._common import (
-    ANONYMOUS_COMPONENT_NAME,
-    SINGULARITY_ID_FORMAT,
-    AssetTypes,
-    InputOutputModes,
-)
+from azure.ai.ml._utils._arm_id_utils import is_ARM_id_for_resource, is_singularity_id_for_resource
+from azure.ai.ml.constants._common import ANONYMOUS_COMPONENT_NAME, SINGULARITY_ID_FORMAT, AssetTypes, InputOutputModes
 from azure.ai.ml.constants._job.pipeline import PipelineConstants
 from azure.ai.ml.dsl._group_decorator import group
 from azure.ai.ml.dsl._load_import import to_component
 from azure.ai.ml.entities import CommandComponent, CommandJob
 from azure.ai.ml.entities import Component
 from azure.ai.ml.entities import Component as ComponentEntity
-from azure.ai.ml.entities import (
-    Data,
-    JobResourceConfiguration,
-    PipelineJob,
-    QueueSettings,
-)
+from azure.ai.ml.entities import Data, JobResourceConfiguration, PipelineJob, QueueSettings
 from azure.ai.ml.exceptions import UnexpectedKeywordError, ValidationException
 from azure.ai.ml.parallel import ParallelJob, RunFunction, parallel_run_function
 
 from .._util import _DSL_TIMEOUT_SECOND
 
 tests_root_dir = Path(__file__).parent.parent.parent
 components_dir = tests_root_dir / "test_configs/components/"
@@ -1533,15 +1515,15 @@
         @dsl.pipeline()
         def pipeline(component_in_number, component_in_path):
             node1 = component_func1(component_in_number=component_in_number, component_in_path=component_in_path)
             node1.jeff_special_option.foo = "bar"
             node1.compute = "cpu-cluster"
 
         dsl_pipeline: PipelineJob = pipeline(10, job_input)
-        with patch("azure.ai.ml.entities._validation.module_logger.info") as mock_logging:
+        with patch("azure.ai.ml.entities._validation.module_logger.warning") as mock_logging:
             _ = client.jobs.create_or_update(dsl_pipeline)
             mock_logging.assert_called_with("Warnings: [jobs.node1.jeff_special_option: Unknown field.]")
 
     def test_anon_component_in_pipeline(
         self, client: MLClient, randstr: Callable[[str], str], hello_world_component: Component
     ) -> None:
         hello_world_func = load_component(
```

## Comparing `azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_on_registry.py` & `azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_on_registry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_pipeline_with_specific_nodes.py` & `azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_pipeline_with_specific_nodes.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,35 +1,37 @@
-import multiprocessing
-import uuid
+from dataclasses import field
 from functools import partial
 from pathlib import Path
 from typing import Callable, Union
 
 import pytest
 from devtools_testutils import AzureRecordedTestCase
 from mock import mock
 from pytest_mock import MockFixture
-
-from azure.ai.ml.operations._operation_orchestrator import OperationOrchestrator
 from test_utilities.utils import (
     _PYTEST_TIMEOUT_METHOD,
     assert_job_cancel,
-    submit_and_cancel_new_dsl_pipeline,
     omit_with_wildcard,
+    submit_and_cancel_new_dsl_pipeline,
 )
 
-from azure.ai.ml import (
-    Input,
-    MLClient,
-    dsl,
-    load_component,
-)
+from azure.ai.ml import Input, MLClient, dsl, load_component
 from azure.ai.ml.constants._common import AssetTypes
-from azure.ai.ml.entities import CommandComponent, Command, Choice, Sweep, Component, Environment, PipelineComponent
-from azure.ai.ml.entities import PipelineJob
+from azure.ai.ml.dsl._group_decorator import group
+from azure.ai.ml.entities import (
+    Choice,
+    Command,
+    CommandComponent,
+    Component,
+    Environment,
+    PipelineComponent,
+    PipelineJob,
+    Sweep,
+)
+from azure.ai.ml.operations._operation_orchestrator import OperationOrchestrator
 
 from .._util import _DSL_TIMEOUT_SECOND
 
 tests_root_dir = Path(__file__).parent.parent.parent
 components_dir = tests_root_dir / "test_configs/components/"
 job_input = Input(
     type=AssetTypes.URI_FILE,
@@ -59,14 +61,27 @@
     elif len(_result) == 3:
         _, _name, _version = _result
     else:
         raise ValueError("Invalid component arm string: {}".format(_result))
     return client.components.get(_name, _version)
 
 
+@group
+class SubGroup:
+    integer: int = None
+    number: float = None
+
+
+@group
+class Group:
+    number: float = None
+    sub1: SubGroup = None
+    sub2: SubGroup = None
+
+
 @pytest.mark.usefixtures(
     "enable_environment_id_arm_expansion",
     "enable_pipeline_private_preview_features",
     "mock_code_hash",
     "mock_component_hash",
     "mock_set_headers_with_user_aml_token",
     "recorded_test",
@@ -300,7 +315,82 @@
             )
             base = _get_component_in_first_child(base, client)
             treat = _get_component_in_first_child(treat, client)
 
         # The last layer contains the command components
         omit_fields.pop()
         assert omit_with_wildcard(base._to_dict(), *omit_fields) == omit_with_wildcard(treat._to_dict(), *omit_fields)
+
+    @pytest.mark.parametrize(
+        "group_param_input, use_remote_component",
+        [
+            pytest.param(
+                Group(
+                    number=1.0,
+                    sub1=SubGroup(integer=1),
+                ),
+                False,
+                id="strong-typed-group",
+            ),
+            pytest.param(
+                {
+                    "number": 1.0,
+                    "sub1": {"integer": 1},
+                },
+                False,
+                id="dict-group",
+            ),
+            pytest.param(
+                Group(
+                    number=1.0,
+                    sub1=SubGroup(integer=1),
+                ),
+                True,
+                id="strong-typed-group-remote",
+            ),
+            pytest.param(
+                {
+                    "number": 1.0,
+                    "sub1": {"integer": 1},
+                },
+                True,
+                id="dict-group-remote",
+            ),
+        ],
+    )
+    def test_dsl_pipeline_with_param_group_in_command_component(
+        self,
+        client,
+        group_param_input,
+        use_remote_component: bool,
+        randstr: Callable[[str], str],
+    ):
+        command_func = load_component("./tests/test_configs/components/helloworld_component_with_parameter_group.yml")
+        input_data_path = "./tests/test_configs/data/"
+
+        if use_remote_component:
+            command_func.name = randstr("component_name")
+            command_func = client.components.create_or_update(
+                command_func,
+            )
+
+        @dsl.pipeline
+        def pipeline_with_command(input_data):
+            command_node = command_func(
+                component_in_path=input_data,
+                component_in_group=group_param_input,
+            )
+            return command_node.outputs
+
+        pipeline: PipelineJob = pipeline_with_command(
+            input_data=Input(
+                path=input_data_path,
+                type=AssetTypes.URI_FOLDER,
+            ),
+        )
+        pipeline.settings.default_compute = "cpu-cluster"
+        created_pipeline = client.jobs.create_or_update(pipeline)
+        assert created_pipeline.jobs["command_node"]._to_rest_inputs() == {
+            "component_in_path": {"job_input_type": "literal", "value": "${{parent.inputs.input_data}}"},
+            "component_in_group.number": {"job_input_type": "literal", "value": "1.0"},
+            "component_in_group.sub1.integer": {"job_input_type": "literal", "value": "1"},
+        }
```

## Comparing `azure-ai-ml-1.8.0/tests/dsl/e2etests/test_automl_dsl_pipeline.py` & `azure-ai-ml-1.9.0/tests/dsl/e2etests/test_automl_dsl_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from pathlib import Path
 
 import pydash
 import pytest
 from devtools_testutils import AzureRecordedTestCase
-from test_utilities.utils import cancel_job
+from test_utilities.utils import cancel_job, get_automl_job_properties
 
 from azure.ai.ml import Input, MLClient, automl, dsl, Output
 from azure.ai.ml.automl import (
     classification,
     forecasting,
     regression,
     text_classification,
@@ -425,14 +425,18 @@
                         model_name=Choice(["vits16r224"]),
                         learning_rate=Uniform(0.001, 0.01),
                     ),
                     SearchSpace(
                         model_name=Choice(["seresnext"]),
                         learning_rate=Uniform(0.001, 0.01),
                     ),
+                    SearchSpace(
+                        model_name=Choice(["microsoft/beit-base-patch16-224"]),
+                        learning_rate=Uniform(0.001, 0.01),
+                    ),
                 ]
             )
             image_multiclass_node.set_sweep(
                 sampling_algorithm="Random",
                 early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
             )
             image_multiclass_node.set_limits(
@@ -485,14 +489,18 @@
                     "learning_rate": "uniform(0.001,0.01)",
                     "model_name": "choice('vits16r224')",
                 },
                 {
                     "learning_rate": "uniform(0.001,0.01)",
                     "model_name": "choice('seresnext')",
                 },
+                {
+                    "learning_rate": "uniform(0.001,0.01)",
+                    "model_name": "choice('microsoft/beit-base-patch16-224')",
+                },
             ],
         }
 
     def test_automl_vision_multilabel_node_in_pipeline(self, client: MLClient):
         @dsl.pipeline(name="train_multilabel_with_automl_in_pipeline")
         def train_multilabel_with_automl_in_pipeline(
             image_multilabel_train_data,
@@ -513,14 +521,18 @@
                         model_name=Choice(["vitb16r224"]),
                         learning_rate=Uniform(0.001, 0.01),
                     ),
                     SearchSpace(
                         model_name=Choice(["seresnext"]),
                         learning_rate=Uniform(0.001, 0.01),
                     ),
+                    SearchSpace(
+                        model_name=Choice(["microsoft/beit-base-patch16-224"]),
+                        learning_rate=Uniform(0.001, 0.01),
+                    ),
                 ]
             )
             image_multilabel_node.set_sweep(
                 sampling_algorithm="Random",
                 early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
             )
             image_multilabel_node.set_limits(
@@ -573,14 +585,18 @@
                     "model_name": "choice('vitb16r224')",
                     "learning_rate": "uniform(0.001,0.01)",
                 },
                 {
                     "model_name": "choice('seresnext')",
                     "learning_rate": "uniform(0.001,0.01)",
                 },
+                {
+                    "model_name": "choice('microsoft/beit-base-patch16-224')",
+                    "learning_rate": "uniform(0.001,0.01)",
+                },
             ],
         }
 
     def test_automl_vision_od_node_in_pipeline(self, client: MLClient):
         @dsl.pipeline(name="train_od_with_automl_in_pipeline")
         def train_od_with_automl_in_pipeline(
             image_object_detection_train_data,
@@ -602,14 +618,20 @@
                     ),
                     SearchSpace(
                         model_name=Choice(["fasterrcnn_resnet50_fpn"]),
                         learning_rate=Uniform(0.0001, 0.001),
                         optimizer=Choice(["sgd", "adam", "adamw"]),
                         min_size=Choice([600, 800]),  # model-specific
                     ),
+                    SearchSpace(
+                        model_name=Choice(["atss_r50_fpn_1x_coco"]),
+                        learning_rate=Uniform(0.0001, 0.001),
+                        optimizer=Choice(["sgd", "adam", "adamw"]),
+                        min_size=Choice([600, 800]),  # model-specific
+                    ),
                 ]
             )
             image_object_detection_node.set_training_parameters(nms_iou_threshold=0.7)
             image_object_detection_node.set_limits(
                 timeout_minutes=60,
             )
             image_object_detection_node.set_sweep(
@@ -672,14 +694,20 @@
                 },
                 {
                     "learning_rate": "uniform(0.0001,0.001)",
                     "min_size": "choice(600,800)",
                     "model_name": "choice('fasterrcnn_resnet50_fpn')",
                     "optimizer": "choice('sgd','adam','adamw')",
                 },
+                {
+                    "learning_rate": "uniform(0.0001,0.001)",
+                    "min_size": "choice(600,800)",
+                    "model_name": "choice('atss_r50_fpn_1x_coco')",
+                    "optimizer": "choice('sgd','adam','adamw')",
+                },
             ],
         }
 
     def test_automl_vision_segmentation_node_in_pipeline(self, client: MLClient):
         @dsl.pipeline(name="train_with_automl_in_pipeline")
         def train_segmentation_with_automl_in_pipeline(
             image_instance_segmentation_train_data,
@@ -699,14 +727,20 @@
                 [
                     SearchSpace(
                         model_name=Choice(["maskrcnn_resnet50_fpn"]),
                         learning_rate=Uniform(0.0001, 0.001),
                         optimizer=Choice(["sgd", "adam", "adamw"]),
                         min_size=Choice([600, 800]),
                     ),
+                    SearchSpace(
+                        model_name=Choice(["mask_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco"]),
+                        learning_rate=Uniform(0.0001, 0.001),
+                        optimizer=Choice(["sgd", "adam", "adamw"]),
+                        min_size=Choice([600, 800]),
+                    ),
                 ]
             )
 
             image_instance_segmentation_node.set_sweep(
                 sampling_algorithm="Random",
                 early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
             )
@@ -762,10 +796,16 @@
             },
             "search_space": [
                 {
                     "learning_rate": "uniform(0.0001,0.001)",
                     "model_name": "choice('maskrcnn_resnet50_fpn')",
                     "optimizer": "choice('sgd','adam','adamw')",
                     "min_size": "choice(600,800)",
-                }
+                },
+                {
+                    "learning_rate": "uniform(0.0001,0.001)",
+                    "model_name": "choice('mask_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco')",
+                    "optimizer": "choice('sgd','adam','adamw')",
+                    "min_size": "choice(600,800)",
+                },
             ],
         }
```

## Comparing `azure-ai-ml-1.8.0/tests/dsl/e2etests/test_controlflow_pipeline.py` & `azure-ai-ml-1.9.0/tests/dsl/e2etests/test_controlflow_pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/e2etests/test_dsl_fl.py` & `azure-ai-ml-1.9.0/tests/dsl/e2etests/test_dsl_fl.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_component_func.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_component_func.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 import sys
 from pathlib import Path
 from typing import Callable, Union
 
+import pydash
 import pytest
 from marshmallow import ValidationError
 
 from azure.ai.ml import PyTorchDistribution, load_component
 from azure.ai.ml.entities import Data, JobResourceConfiguration
 from azure.ai.ml.entities._builders import Command
 from azure.ai.ml.entities._inputs_outputs import Input, Output
@@ -331,8 +332,10 @@
         invalid_name = "invalid-name"
         component.name = invalid_name
         assert not component._validate().passed
         cmp_rest_obj, cmp_dict = component._to_rest_object(), component._to_dict()
         base_dict["name"] = invalid_name
         base_rest_obj.name, base_rest_obj.properties.component_spec["name"] = invalid_name, invalid_name
         assert cmp_dict == base_dict
-        assert cmp_rest_obj.as_dict() == base_rest_obj.as_dict()
+        cmp_rest_obj = pydash.omit(cmp_rest_obj.as_dict(), "properties.properties.client_component_hash")
+        base_rest_obj = pydash.omit(base_rest_obj.as_dict(), "properties.properties.client_component_hash")
+        assert cmp_rest_obj == base_rest_obj
```

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_pipeline_builder.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_pipeline_builder.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_samples.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_samples.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_command_builder.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_command_builder.py`

 * *Files 2% similar despite different names*

```diff
@@ -167,15 +167,18 @@
                 "is_anonymous": False,
                 "is_archived": False,
                 "properties": {},
                 "tags": {},
             }
         }
         actual_component = pydash.omit(
-            test_command._component._to_rest_object().as_dict(), "name", "properties.component_spec.name"
+            test_command._component._to_rest_object().as_dict(),
+            "name",
+            "properties.component_spec.name",
+            "properties.properties.client_component_hash",
         )
         assert actual_component == expected_component
 
     def test_no_deterministic_command_function(self, test_no_deterministic_command):
         assert isinstance(test_no_deterministic_command, Command)
         assert test_no_deterministic_command._source == "BUILDER"
 
@@ -208,14 +211,15 @@
                 "tags": {},
             }
         }
         actual_component = pydash.omit(
             test_no_deterministic_command._component._to_rest_object().as_dict(),
             "name",
             "properties.component_spec.name",
+            "properties.properties.client_component_hash",
         )
         assert actual_component == expected_component
 
     def test_command_function_set_inputs(self, test_command):
         test_data = Input(type="uri_folder", path="https://my-blob/path/to/data", mode="download")
         # Command can be called as a function, returning a new Component instance
         node1 = test_command(uri_folder=test_data, float=0.02)
@@ -360,15 +364,18 @@
             },
             "outputs": {"my_model": {"job_output_type": "mlflow_model"}},
         }
         assert node1_dict == expected_dict
 
         # node1's component stores proper inputs & outputs
         actual_component = pydash.omit(
-            node1._component._to_rest_object().as_dict(), "name", "properties.component_spec.name"
+            node1._component._to_rest_object().as_dict(),
+            "name",
+            "properties.component_spec.name",
+            "properties.properties.client_component_hash",
         )
         expected_component = {
             "properties": {
                 "component_spec": {
                     "_source": "BUILDER",
                     "description": "This is a fancy job",
                     "code": parse_local_path("./tests"),
@@ -534,15 +541,18 @@
             assert re.match(pattern, str(e.value)), str(e.value)
 
     def test_command_unprovided_inputs_outputs(self, test_command_params):
         test_command_params.update({"inputs": None, "outputs": None, "command": "echo hello"})
         node1 = command(**test_command_params)
 
         actual_component = pydash.omit(
-            node1._component._to_rest_object().as_dict(), "name", "properties.component_spec.name"
+            node1._component._to_rest_object().as_dict(),
+            "name",
+            "properties.component_spec.name",
+            "properties.properties.client_component_hash",
         )
         expected_component = {
             "properties": {
                 "component_spec": {
                     "_source": "BUILDER",
                     "description": "This is a fancy job",
                     "code": parse_local_path("./tests"),
```

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_group.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_group.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_component.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_pipeline_with_specific_nodes.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_pipeline_with_specific_nodes.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_io_builder.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_io_builder.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_init_finalize_job.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_init_finalize_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_controlflow_pipeline.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_controlflow_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,22 +1,23 @@
 from pathlib import Path
 
 import pytest
 from marshmallow import ValidationError
+from test_utilities.utils import omit_with_wildcard
 
 from azure.ai.ml import Input, load_component
 from azure.ai.ml.constants._component import ComponentSource
 from azure.ai.ml.dsl import pipeline
 from azure.ai.ml.dsl._condition import condition
 from azure.ai.ml.dsl._do_while import do_while
+from azure.ai.ml.dsl._group_decorator import group
 from azure.ai.ml.dsl._parallel_for import parallel_for
 from azure.ai.ml.entities._builders.parallel_for import ParallelFor
 from azure.ai.ml.entities._job.pipeline._io import InputOutputBase, PipelineInput
 from azure.ai.ml.exceptions import ValidationException
-from test_utilities.utils import omit_with_wildcard
 
 from .._util import _DSL_TIMEOUT_SECOND
 
 
 @pytest.mark.usefixtures(
     "enable_pipeline_private_preview_features",
     "enable_private_preview_schema_features",
@@ -99,19 +100,16 @@
 
         with pytest.raises(ValidationException) as e:
             node = condition(condition=1, true_block=basic_node)
             node._validate(raise_error=True)
 
         assert f"must be an instance of {str}, {bool} or {InputOutputBase}" in str(e.value)
 
-        with pytest.raises(ValidationException) as e:
-            node = condition(condition=basic_node.outputs.output3, true_block=basic_node)
-            node._validate(raise_error=True)
-
-        assert "must have 'is_control' field with value 'True'" in str(e.value)
+        node = condition(condition=basic_node.outputs.output3, true_block=basic_node)
+        node._validate(raise_error=True)
 
         with pytest.raises(ValidationError) as e:
             node = condition(condition="${{parent.jobs.xxx.outputs.output}}")
             node._validate(raise_error=True)
 
         assert "True block and false block cannot be empty at the same time." in str(e.value)
 
@@ -204,14 +202,50 @@
                 "inputs": {"component_in_number": {"job_input_type": "literal", "value": "2"}},
                 "name": "node2",
                 "type": "command",
             },
             "result": {"_source": "YAML.COMPONENT", "name": "result", "type": "command"},
         }
 
+    def test_condition_with_group_input(self):
+        hello_world_component_no_paths = load_component(
+            source=r"./tests/test_configs/components/helloworld_component_no_paths.yml"
+        )
+
+        @group
+        class SubGroup:
+            num: int
+
+        @group
+        class ParentGroup:
+            input_group: SubGroup
+
+        @pipeline(
+            compute="cpu-cluster",
+        )
+        def condition_pipeline(group_input: ParentGroup):
+            node1 = hello_world_component_no_paths(component_in_number=1)
+            condition(condition=group_input.input_group.num < 100, true_block=node1)
+
+        pipeline_job = condition_pipeline(group_input=ParentGroup(input_group=SubGroup(num=10)))
+        omit_fields = [
+            "name",
+            "properties.display_name",
+            "properties.jobs.*.componentId",
+            "properties.settings",
+        ]
+        dsl_pipeline_job_dict = omit_with_wildcard(pipeline_job._to_rest_object().as_dict(), *omit_fields)
+        assert dsl_pipeline_job_dict["properties"]["jobs"]["expression_component"] == {
+            "environment_variables": {"AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED": "true"},
+            "name": "expression_component",
+            "type": "command",
+            "inputs": {"num": {"job_input_type": "literal", "value": "${{parent.inputs.group_input.input_group.num}}"}},
+            "_source": "YAML.COMPONENT",
+        }
+
 
 class TestDoWhilePipelineUT(TestControlFlowPipelineUT):
     def test_invalid_do_while_pipeline(self):
         basic_component_func = load_component(
             "./tests/test_configs/dsl_pipeline/do_while/basic_component/component.yml"
         )
 
@@ -340,15 +374,15 @@
                 "is_number_larger_than_zero is the output of do_while_body_pipeline_1, dowhile only accept output of the body: do_while_body_pipeline_3."
             ],
             "jobs.invalid_mapping.mapping": [
                 "component_in_number_1 is the input of do_while_body_pipeline_1, dowhile only accept input of the body: do_while_body_pipeline_3.",
                 "output_in_path is the output of do_while_body_pipeline_1, dowhile only accept output of the body: do_while_body_pipeline_3.",
             ],
             "jobs.invalid_condition.condition": [
-                "output_in_path is not a control output. The condition of dowhile must be the control output of the body."
+                "output_in_path is not a control output and is not primitive type. The condition of dowhile must be the control output or primitive type of the body."
             ],
         }
         validate_error_message(expect_errors, validate_errors)
 
     def test_infer_dynamic_input_type_from_mapping(self):
         # Pass None to dynamic input in do-while loop body, and provide it in mapping for next iteration,
         # which is a valid case in federated learning.
```

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_dsl_fl.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_dsl_fl.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dsl/unittests/test_attr_dict.py` & `azure-ai-ml-1.9.0/tests/dsl/unittests/test_attr_dict.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/datastore/e2etests/test_datastore.py` & `azure-ai-ml-1.9.0/tests/datastore/e2etests/test_datastore.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/datastore/unittests/test_datastore_schema.py` & `azure-ai-ml-1.9.0/tests/datastore/unittests/test_datastore_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/datastore/unittests/test_datastore_operations.py` & `azure-ai-ml-1.9.0/tests/datastore/unittests/test_datastore_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal/_utils.py` & `azure-ai-ml-1.9.0/tests/internal/_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal/e2etests/test_component.py` & `azure-ai-ml-1.9.0/tests/internal/e2etests/test_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal/e2etests/test_pipeline_job.py` & `azure-ai-ml-1.9.0/tests/internal/e2etests/test_pipeline_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal/unittests/test_internal_disabled.py` & `azure-ai-ml-1.9.0/tests/internal/unittests/test_internal_disabled.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal/unittests/test_component.py` & `azure-ai-ml-1.9.0/tests/internal/unittests/test_component.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 from typing import Dict
 from zipfile import ZipFile
 
 import pydash
 import pytest
 import yaml
 from pytest_mock import MockFixture
-from test_utilities.utils import build_temp_folder, parse_local_path
+from test_utilities.utils import build_temp_folder, mock_artifact_download_to_temp_directory, parse_local_path
 
 from azure.ai.ml import load_component
 from azure.ai.ml._internal._schema.component import NodeType
 from azure.ai.ml._internal.entities.component import InternalComponent
 from azure.ai.ml._internal.entities.spark import InternalSparkComponent
 from azure.ai.ml._utils.utils import load_yaml
 from azure.ai.ml.constants._common import AZUREML_INTERNAL_COMPONENTS_ENV_VAR
@@ -427,23 +427,23 @@
     def test_additional_includes(self) -> None:
         yaml_path = (
             "./tests/test_configs/internal/component_with_additional_includes/helloworld_additional_includes.yml"
         )
         component: InternalComponent = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
         # resolve
-        with component._resolve_local_code() as code:
+        with component._build_code() as code:
             code_path: Path = code.path
             assert code_path.is_dir()
             assert (code_path / "LICENSE").is_file()
             assert (code_path / "library.zip").is_file()
             assert ZipFile(code_path / "library.zip").namelist() == ["library/", "library/hello.py", "library/world.py"]
             assert (code_path / "library1" / "hello.py").is_file()
             assert (code_path / "library1" / "world.py").is_file()
-            assert not (code_path / "helloworld_additional_includes.additional_includes").exists()
+            assert code._ignore_file.is_file_excluded(code_path / "helloworld_additional_includes.additional_includes")
 
         assert not code_path.is_dir()
 
     @pytest.mark.parametrize(
         "test_files",
         [
             pytest.param(
@@ -598,15 +598,15 @@
             yaml_path = (
                 Path(test_configs_dir) / "component_with_additional_includes" / "helloworld_additional_includes.yml"
             )
 
             component: InternalComponent = load_component(source=yaml_path)
 
             # resolve and check snapshot directory
-            with component._resolve_local_code() as code:
+            with component._build_code() as code:
                 for file, content, check_func in test_files:
                     # original file is based on test_configs_dir, need to remove the leading
                     # "component_with_additional_includes" or "additional_includes" to get the relative path
                     resolved_file_path = Path(os.path.join(code.path, *Path(file).parts[1:]))
                     if check_func == AdditionalIncludesCheckFunc.NO_PARENT:
                         assert not resolved_file_path.parent.exists(), f"{file} should not have parent"
                     elif check_func == AdditionalIncludesCheckFunc.SELF_IS_FILE:
@@ -624,15 +624,15 @@
 
     def test_additional_includes_merge_folder(self) -> None:
         yaml_path = (
             "./tests/test_configs/internal/component_with_additional_includes/additional_includes_merge_folder.yml"
         )
         component: InternalComponent = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
-        with component._resolve_local_code() as code:
+        with component._build_code() as code:
             code_path = code.path
             # first folder
             assert (code_path / "library1" / "__init__.py").is_file()
             assert (code_path / "library1" / "hello.py").is_file()
             # second folder content
             assert (code_path / "library1" / "utils").is_dir()
             assert (code_path / "library1" / "utils" / "__init__.py").is_file()
@@ -647,15 +647,15 @@
         ],
     )
     def test_additional_includes_with_code_specified(self, yaml_path: str, has_additional_includes: bool) -> None:
         yaml_path = os.path.join("./tests/test_configs/internal/component_with_additional_includes/", yaml_path)
         component: InternalComponent = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
         # resolve
-        with component._resolve_local_code() as code:
+        with component._build_code() as code:
             code_path = code.path
             assert code_path.is_dir()
             if has_additional_includes:
                 # additional includes is specified, code will be tmp folder and need to check each item
                 # manually list here to avoid temp folder like __pycache__ breaking test.
                 for path in [
                     "additional_includes_merge_folder.yml",
@@ -682,15 +682,15 @@
 
         docker_file_path = "./tests/test_configs/internal/additional_includes/docker/DockerFile"
         with open(docker_file_path, "r") as docker_file:
             docker_file_content = docker_file.read()
 
         component: InternalComponent = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
-        with component._resolve_local_code():
+        with component._build_code():
             environment_rest_obj = component._to_rest_object().properties.component_spec["environment"]
             assert environment_rest_obj == {
                 "docker": {
                     "build": {
                         "dockerfile": docker_file_content,
                     }
                 },
@@ -704,45 +704,29 @@
 
         conda_file_path = "./tests/test_configs/internal/env-conda-dependencies/conda.yaml"
         with open(conda_file_path, "r") as conda_file:
             conda_file_content = yaml.safe_load(conda_file)
 
         component: InternalComponent = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
-        with component._resolve_local_code():
+        with component._build_code():
             environment_rest_obj = component._to_rest_object().properties.component_spec["environment"]
             assert environment_rest_obj == {
                 "conda": {
                     "conda_dependencies": conda_file_content,
                 },
                 "os": "Linux",
             }
 
-    def test_artifacts_in_additional_includes(self, mocker: MockFixture):
-        with tempfile.TemporaryDirectory() as temp_dir:
-
-            def mock_get_artifacts(**kwargs):
-                version = kwargs.get("version")
-                artifact = Path(temp_dir) / version
-                if version in ["version_1", "version_3"]:
-                    version = "version_1"
-                artifact.mkdir(parents=True, exist_ok=True)
-                (artifact / version).mkdir(exist_ok=True)
-                (artifact / version / "file").touch(exist_ok=True)
-                (artifact / f"file_{version}").touch(exist_ok=True)
-                return str(artifact)
-
-            mocker.patch(
-                "azure.ai.ml.entities._component._artifact_cache.ArtifactCache.get", side_effect=mock_get_artifacts
-            )
-
+    def test_artifacts_in_additional_includes(self):
+        with mock_artifact_download_to_temp_directory():
             yaml_path = "./tests/test_configs/internal/component_with_additional_includes/with_artifacts.yml"
             component: InternalComponent = load_component(source=yaml_path)
             assert component._validate().passed, repr(component._validate())
-            with component._resolve_local_code() as code:
+            with component._build_code() as code:
                 code_path = code.path
                 assert code_path.is_dir()
                 for path in [
                     "version_1/",
                     "version_1/file",
                     "version_2/",
                     "version_2/file",
@@ -753,38 +737,40 @@
                     assert (code_path / path).exists()
 
             yaml_path = (
                 "./tests/test_configs/internal/component_with_additional_includes/"
                 "artifacts_additional_includes_with_conflict.yml"
             )
             component: InternalComponent = load_component(source=yaml_path)
-            validation_result = component._validate()
-            assert validation_result.passed is False
-            assert "There are conflict files in additional include" in validation_result.error_messages["*"]
-            assert (
-                "test_additional_include:version_1 in component-sdk-test-feed" in validation_result.error_messages["*"]
-            )
-            assert (
-                "test_additional_include:version_3 in component-sdk-test-feed" in validation_result.error_messages["*"]
-            )
+            with pytest.raises(
+                RuntimeError,
+                match="There are conflict files in additional include"
+                ".*test_additional_include:version_1 in component-sdk-test-feed"
+                ".*test_additional_include:version_3 in component-sdk-test-feed",
+            ):
+                with component._build_code():
+                    pass
 
     @pytest.mark.parametrize(
         "yaml_path,expected_error_msg_prefix",
         [
-            (
+            pytest.param(
                 "helloworld_invalid_additional_includes_root_directory.yml",
                 "Root directory is not supported for additional includes",
+                id="root_as_additional_includes",
             ),
-            (
+            pytest.param(
                 "helloworld_invalid_additional_includes_existing_file.yml",
                 "A file already exists for additional include",
+                id="file_already_exists",
             ),
-            (
+            pytest.param(
                 "helloworld_invalid_additional_includes_zip_file_not_found.yml",
                 "Unable to find additional include ../additional_includes/assets/LICENSE.zip",
+                id="zip_file_not_found",
             ),
         ],
     )
     def test_invalid_additional_includes(self, yaml_path: str, expected_error_msg_prefix: str) -> None:
         component = load_component(
             os.path.join("./tests/test_configs/internal/component_with_additional_includes", yaml_path)
         )
@@ -905,15 +891,15 @@
         "relative_yaml_path,expected_snapshot_id",
         ANONYMOUS_COMPONENT_TEST_PARAMS,
     )
     def test_anonymous_component_reuse(self, relative_yaml_path: str, expected_snapshot_id: str):
         component: InternalComponent = load_component(
             source=Path("./tests/test_configs/internal/component-reuse/") / relative_yaml_path
         )
-        with component._resolve_local_code() as code:
+        with component._build_code() as code:
             assert code.name == expected_snapshot_id
 
             code.name = expected_snapshot_id
             with pytest.raises(
                 AttributeError, match="InternalCode name are calculated based on its content and cannot be changed.*"
             ):
                 code.name = expected_snapshot_id + "1"
@@ -930,15 +916,15 @@
             component: InternalComponent = load_component(source=yaml_path)
             # create some files/folders expected to ignore
             code_pycache = yaml_path.parent / "__pycache__"
             code_pycache.mkdir()
             (code_pycache / "a.pyc").touch()
 
             # resolve and check snapshot directory
-            with component._resolve_local_code() as code:
+            with component._build_code() as code:
                 # ANONYMOUS_COMPONENT_TEST_PARAMS[0] is the test params for simple-command
                 assert code.name == ANONYMOUS_COMPONENT_TEST_PARAMS[0][1]
 
     def test_component_serialization_corner_case(self):
         yaml_path = "./tests/test_configs/internal/command-component-serialization-core-case/component_spec.yaml"
         component: InternalComponent = load_component(source=yaml_path)
         assert component
```

## Comparing `azure-ai-ml-1.8.0/tests/internal/unittests/test_pipeline_job.py` & `azure-ai-ml-1.9.0/tests/internal/unittests/test_pipeline_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_utilities/utils.py` & `azure-ai-ml-1.9.0/tests/test_utilities/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 import signal
 import tempfile
 import time
 from contextlib import contextmanager
 from io import StringIO
 from pathlib import Path
 from typing import Callable, Dict, List, Optional, Union
+from unittest.mock import patch
 from zipfile import ZipFile
 
 import pydash
 import urllib3
 from azure.core.exceptions import HttpResponseError
 from azure.core.polling import LROPoller
 from devtools_testutils import is_live
@@ -104,14 +105,15 @@
                     "properties.jobs.*.trial.properties.componentSpec.name",
                     "properties.jobs.*.trial.properties.componentSpec.version",
                     "properties.jobs.*.trial.properties.componentSpec.$schema",
                     "properties.jobs.*.trial.properties.componentSpec.schema",
                     "properties.jobs.*.trial.properties.isAnonymous",
                     "properties.jobs.*.trial.properties.componentSpec._source",
                     "properties.settings",
+                    "properties.jobs.*.trial.properties.properties.client_component_hash",
                 ]
             )
     else:
         dsl_pipeline_job_dict = pipeline._to_dict()  # pylint: disable=protected-access
         pipeline_job_dict = pipeline_from_yaml._to_dict()  # pylint: disable=protected-access
         if enable_default_omit_fields:
             omit_fields.extend(
@@ -423,7 +425,26 @@
     declared_fields["jobs"] = pipeline_job.PipelineJobsField()
 
     try:
         yield
     finally:
         if revert_after_yield:
             declared_fields["jobs"] = original_jobs
+
+
+@contextmanager
+def mock_artifact_download_to_temp_directory():
+    with tempfile.TemporaryDirectory() as temp_dir:
+
+        def mock_get_artifacts(**kwargs):
+            version = kwargs.get("version")
+            artifact = Path(temp_dir) / version
+            if version in ["version_1", "version_3"]:
+                version = "version_1"
+            artifact.mkdir(parents=True, exist_ok=True)
+            (artifact / version).mkdir(exist_ok=True)
+            (artifact / version / "file").touch(exist_ok=True)
+            (artifact / f"file_{version}").touch(exist_ok=True)
+            return str(artifact)
+
+        with patch("azure.ai.ml._utils._artifact_utils.ArtifactCache.get", side_effect=mock_get_artifacts):
+            yield temp_dir
```

## Comparing `azure-ai-ml-1.8.0/tests/test_utilities/json_schema.py` & `azure-ai-ml-1.9.0/tests/test_utilities/json_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace_outbound_rule_operations.py` & `azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace_outbound_rule_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace.py` & `azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/workspace/e2etests/test_workspace_connections.py` & `azure-ai-ml-1.9.0/tests/workspace/e2etests/test_workspace_connections.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_connection_entity.py` & `azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_connection_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_connection_operations.py` & `azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_connection_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_operations.py` & `azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/workspace/unittests/test_workspace_operations_base.py` & `azure-ai-ml-1.9.0/tests/workspace/unittests/test_workspace_operations_base.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/model/e2etests/test_model.py` & `azure-ai-ml-1.9.0/tests/model/e2etests/test_model.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,17 +1,16 @@
 import os
 import re
 import uuid
 from pathlib import Path
-from typing import Callable
+from typing import Callable, Iterator
 from unittest.mock import patch
 
 import pytest
 from devtools_testutils import AzureRecordedTestCase, is_live
-from six import Iterator
 from test_utilities.utils import sleep_if_live
 
 from azure.ai.ml import MLClient, load_model
 from azure.ai.ml._restclient.v2022_05_01.models import ListViewType
 from azure.ai.ml.constants._common import LONG_URI_REGEX_FORMAT
 from azure.ai.ml.entities._assets import Model
 from azure.core.paging import ItemPaged
```

## Comparing `azure-ai-ml-1.8.0/tests/model/unittests/test_model_schema.py` & `azure-ai-ml-1.9.0/tests/model/unittests/test_model_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/model/unittests/test_model_operations.py` & `azure-ai-ml-1.9.0/tests/model/unittests/test_model_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_services/e2etests/test_batch_deployment.py` & `azure-ai-ml-1.9.0/tests/batch_services/e2etests/test_batch_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_services/e2etests/test_batch_endpoint.py` & `azure-ai-ml-1.9.0/tests/batch_services/e2etests/test_batch_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_deployment.py` & `azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_deployment_schema.py` & `azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_deployment_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_services/unittests/test_batch_endpoints.py` & `azure-ai-ml-1.9.0/tests/batch_services/unittests/test_batch_endpoints.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/import_job/e2etests/test_import_job.py` & `azure-ai-ml-1.9.0/tests/import_job/e2etests/test_import_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/import_job/unittests/test_import_job_schema_builder_entity.py` & `azure-ai-ml-1.9.0/tests/import_job/unittests/test_import_job_schema_builder_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/spark_job/e2etests/test_spark_job.py` & `azure-ai-ml-1.9.0/tests/spark_job/e2etests/test_spark_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/spark_job/unittests/test_spark_job_schema.py` & `azure-ai-ml-1.9.0/tests/spark_job/unittests/test_spark_job_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/spark_job/unittests/test_spark_job_entity.py` & `azure-ai-ml-1.9.0/tests/spark_job/unittests/test_spark_job_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/code_asset/e2etests/test_code.py` & `azure-ai-ml-1.9.0/tests/code_asset/e2etests/test_code.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/code_asset/unittests/test_code_operations.py` & `azure-ai-ml-1.9.0/tests/code_asset/unittests/test_code_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/code_asset/unittests/test_federated_learning_silo.py` & `azure-ai-ml-1.9.0/tests/code_asset/unittests/test_federated_learning_silo.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/_util.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/_util.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/test_control_flow_pipeline.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/test_control_flow_pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/e2etests/test_pipeline_job.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/e2etests/test_pipeline_job.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,26 +2,18 @@
 from pathlib import Path
 from typing import Any, Callable, Dict
 
 import pydash
 import pytest
 from azure.core.exceptions import HttpResponseError
 from devtools_testutils import AzureRecordedTestCase, is_live
-from test_utilities.utils import (
-    _PYTEST_TIMEOUT_METHOD,
-    assert_job_cancel,
-    sleep_if_live,
-    wait_until_done,
-)
+from test_utilities.utils import _PYTEST_TIMEOUT_METHOD, assert_job_cancel, sleep_if_live, wait_until_done
 
 from azure.ai.ml import Input, MLClient, load_component, load_data, load_job
-from azure.ai.ml._utils._arm_id_utils import (
-    AMLVersionedArmId,
-    is_singularity_id_for_resource,
-)
+from azure.ai.ml._utils._arm_id_utils import AMLVersionedArmId, is_singularity_id_for_resource
 from azure.ai.ml._utils.utils import load_yaml
 from azure.ai.ml.constants import InputOutputModes
 from azure.ai.ml.constants._job.pipeline import PipelineConstants
 from azure.ai.ml.entities import Component, Job, PipelineJob
 from azure.ai.ml.entities._builders import Command, Pipeline
 from azure.ai.ml.entities._builders.parallel import Parallel
 from azure.ai.ml.entities._builders.spark import Spark
@@ -32,20 +24,15 @@
     _PIPELINE_JOB_TIMEOUT_SECOND,
     DATABINDING_EXPRESSION_TEST_CASE_ENUMERATE,
     DATABINDING_EXPRESSION_TEST_CASES,
 )
 
 
 def assert_job_input_output_types(job: PipelineJob):
-    from azure.ai.ml.entities._job.pipeline._io import (
-        NodeInput,
-        NodeOutput,
-        PipelineInput,
-        PipelineOutput,
-    )
+    from azure.ai.ml.entities._job.pipeline._io import NodeInput, NodeOutput, PipelineInput, PipelineOutput
 
     for _, input in job.inputs.items():
         assert isinstance(input, PipelineInput)
     for _, output in job.outputs.items():
         assert isinstance(output, PipelineOutput)
     for _, component in job.jobs.items():
         for _, input in component.inputs.items():
@@ -1942,14 +1929,29 @@
         rest_obj = created_pipeline_job._to_rest_object()
 
         assert is_singularity_id_for_resource(rest_obj.properties.jobs["full_name"]["computeId"])
         assert rest_obj.properties.jobs["full_name"]["computeId"].endswith(singularity_vc.name)
         assert is_singularity_id_for_resource(rest_obj.properties.jobs["short_name"]["computeId"])
         assert rest_obj.properties.jobs["short_name"]["computeId"].endswith(singularity_vc.name)
 
+    def test_pipeline_with_param_group_in_command_component(
+        self,
+        client,
+        randstr: Callable[[str], str],
+    ):
+        pipeline_job = load_job("./tests/test_configs/pipeline_jobs/helloworld_pipeline_job_group_input_for_node.yml")
+        created_pipeline_job = assert_job_cancel(pipeline_job, client)
+        assert created_pipeline_job.jobs["dot_input_name"]._to_dict()["inputs"] == {
+            "component_in_group.number": "10.99",
+            "component_in_group.sub1.integer": "10",
+            "component_in_group.sub1.number": "10.99",
+            "component_in_group.sub2.number": "10.99",
+            "component_in_path": {"path": "${{parent.inputs.job_in_path}}"},
+        }
+
 
 @pytest.mark.usefixtures("enable_pipeline_private_preview_features")
 @pytest.mark.e2etest
 @pytest.mark.pipeline_test
 @pytest.mark.skipif(condition=not is_live(), reason="no need to run in playback mode")
 @pytest.mark.timeout(timeout=_PIPELINE_JOB_LONG_RUNNING_TIMEOUT_SECOND, method=_PYTEST_TIMEOUT_METHOD)
 class TestPipelineJobLongRunning:
```

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_private_preview_disabled.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_private_preview_disabled.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_entity.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_schema.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_schema.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,21 +17,21 @@
 from azure.ai.ml._restclient.v2023_04_01_preview.models import PipelineJob as RestPipelineJob
 from azure.ai.ml._restclient.v2023_04_01_preview.models import UriFolderJobInput
 from azure.ai.ml._restclient.v2023_04_01_preview.models._azure_machine_learning_workspaces_enums import (
     LearningRateScheduler,
     StochasticOptimizer,
 )
 from azure.ai.ml._utils.utils import camel_to_snake, dump_yaml_to_file, is_data_binding_expression, load_yaml
-from azure.ai.ml.constants._common import ARM_ID_PREFIX
+from azure.ai.ml.constants._common import ARM_ID_PREFIX, AssetTypes, InputOutputModes
 from azure.ai.ml.constants._component import ComponentJobConstants
 from azure.ai.ml.constants._job.pipeline import PipelineConstants
 from azure.ai.ml.entities import CommandComponent, Component, Job, PipelineJob, SparkComponent
 from azure.ai.ml.entities._assets import Code
-from azure.ai.ml.entities._component.parallel_component import ParallelComponent
 from azure.ai.ml.entities._component.datatransfer_component import DataTransferComponent
+from azure.ai.ml.entities._component.parallel_component import ParallelComponent
 from azure.ai.ml.entities._inputs_outputs import Input, Output
 from azure.ai.ml.entities._job._input_output_helpers import (
     INPUT_MOUNT_MAPPING_FROM_REST,
     validate_pipeline_input_key_contains_allowed_characters,
 )
 from azure.ai.ml.entities._job.automl.search_space_utils import _convert_sweep_dist_dict_to_str_dict
 from azure.ai.ml.entities._job.job_service import (
@@ -1844,7 +1844,11 @@
         DATABINDING_EXPRESSION_TEST_CASES,
     )
     def test_pipeline_job_with_data_binding_expression(
         self, client: MLClient, pipeline_job_path: str, expected_error: Optional[Exception]
     ):
         pipeline: PipelineJob = load_job(source=pipeline_job_path)
         pipeline._to_rest_object()
+
+    def test_pipeline_job_with_spark_component(self):
+        yaml_path = r"./tests/test_configs/pipeline_jobs/helloworld_pipeline_job_with_spark_component.yml"
+        load_job(yaml_path)
```

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_controlflow_pipeline_job.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_controlflow_pipeline_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/pipeline_job/unittests/test_pipeline_job_validate.py` & `azure-ai-ml-1.9.0/tests/pipeline_job/unittests/test_pipeline_job_validate.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 from typing import List, Optional
 from unittest.mock import patch
 
 import pytest
 from marshmallow import ValidationError
 from pytest_mock import MockFixture
 
-from azure.ai.ml import Input, Output, MLClient, dsl, load_component, load_job
+from azure.ai.ml import Input, MLClient, Output, dsl, load_component, load_job
 from azure.ai.ml.constants._common import AssetTypes, InputOutputModes
 from azure.ai.ml.entities import Choice, CommandComponent, PipelineJob
 from azure.ai.ml.entities._validate_funcs import validate_job
-from azure.ai.ml.exceptions import ValidationException, UserErrorException
+from azure.ai.ml.exceptions import UserErrorException, ValidationException
 
 from .._util import _PIPELINE_JOB_TIMEOUT_SECOND, SERVERLESS_COMPUTE_TEST_PARAMETERS
 
 
 def assert_the_same_path(actual_path, expected_path):
     if actual_path is None or expected_path is None:
         assert actual_path == expected_path
@@ -338,14 +338,15 @@
         pipeline2 = pipeline(None, None)
         validate_result = pipeline2._validate()
         assert validate_result.passed is False
         assert validate_result.error_messages == {
             "jobs.microsoftsamples_command_component_basic.compute": "Compute not set",
             "inputs.component_in_path": "Required input 'component_in_path' for pipeline 'pipeline' not provided.",
         }
+        validate_result.resolve_location_for_diagnostics(source_path=pipeline2.component._source_path)
 
     def test_pipeline_with_none_parameter_no_default_optional_false(self) -> None:
         default_optional_func = load_component(str(components_dir / "default_optional_component.yml"))
 
         # None input is binding to a required input
         @dsl.pipeline(
             default_compute="cpu-cluster",
@@ -591,15 +592,15 @@
         def pipeline(component_in_number, component_in_path):
             node1 = component_func1(component_in_number=component_in_number, component_in_path=component_in_path)
             node1.jeff_special_option.foo = "bar"
             node1.compute = "cpu-cluster"
 
         dsl_pipeline: PipelineJob = pipeline(10, job_input)
 
-        with patch("azure.ai.ml.entities._validation.module_logger.info") as mock_logging:
+        with patch("azure.ai.ml.entities._validation.module_logger.warning") as mock_logging:
             dsl_pipeline._validate(raise_error=True)
             mock_logging.assert_called_with("Warnings: [jobs.node1.jeff_special_option: Unknown field.]")
 
     def test_node_required_field_missing(self) -> None:
         path = "./tests/test_configs/components/helloworld_component.yml"
         component_func1 = load_component(path)
         job_input = Input(
```

## Comparing `azure-ai-ml-1.8.0/tests/dataset/e2etests/test_data_utils.py` & `azure-ai-ml-1.9.0/tests/dataset/e2etests/test_data_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dataset/e2etests/test_data.py` & `azure-ai-ml-1.9.0/tests/dataset/e2etests/test_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_schema.py` & `azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_operations.py` & `azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/dataset/unittests/test_data_utils.py` & `azure-ai-ml-1.9.0/tests/dataset/unittests/test_data_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/deployments/model-4/onlinescoring/cloud_score.py` & `azure-ai-ml-1.9.0/tests/test_configs/deployments/model-4/onlinescoring/cloud_score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/deployments/model-3/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/deployments/model-3/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/deployments/model-1/onlinescoring/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/deployments/byoc/sklearn/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/deployments/byoc/sklearn/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/deployments/model-1/onlinescoring/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/deployments/endpoint_scoring/main.py` & `azure-ai-ml-1.9.0/tests/test_configs/deployments/endpoint_scoring/main.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/deployments/mnist/code/digit_identification.py` & `azure-ai-ml-1.9.0/tests/test_configs/deployments/mnist/code/digit_identification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/deployments/model-2/onlinescoring/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/deployments/model-2/onlinescoring/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/aggregate/run.py` & `azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/aggregate/run.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/training/run.py` & `azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/training/run.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/components/fl_test_components/preprocessing/run.py` & `azure-ai-ml-1.9.0/tests/test_configs/components/fl_test_components/preprocessing/run.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/components/component_with_conditional_output/entry.py` & `azure-ai-ml-1.9.0/tests/test_configs/components/component_with_conditional_output/entry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/components/do_while_test/entry.py` & `azure-ai-ml-1.9.0/tests/test_configs/components/do_while_test/entry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/wordcount.py` & `azure-ai-ml-1.9.0/tests/test_configs/spark_job/spark_job_word_count/src/wordcount.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/basic_component.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/baisc_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/register.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/register.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/preprocess.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/job_tier/automl_in_pipeline/components/src/preprocess.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/register.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/register.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/preprocess.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/automl/components/src/preprocess.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/partition_data.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/partition_data/partition_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/parallel_train.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/parallel/src/parallel_train/parallel_train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/wordcount.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/wordcount.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/job_with_registry_model_as_input/score_src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/spark_component/src/kmeans_example.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/kmeans_example.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/internal/v2_style/hd_insight_component/train-spark.py` & `azure-ai-ml-1.9.0/tests/test_configs/internal/v2_style/hd_insight_component/train-spark.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/eval.py` & `azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/eval.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/internal/get_started_train_score_eval/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/internal/get_started_train_score_eval/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/internal/batch_inference/batch_score.py` & `azure-ai-ml-1.9.0/tests/test_configs/internal/batch_inference/batch_score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/internal/hdi-component/train-spark.py` & `azure-ai-ml-1.9.0/tests/test_configs/internal/hdi-component/train-spark.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/internal/ipp-component/train_wrapper.py` & `azure-ai-ml-1.9.0/tests/test_configs/internal/ipp-component/train_wrapper.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/script_parallel/tabular_run_with_model.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/tabular_batch_inference.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/script_parallel/digit_identification.py` & `azure-ai-ml-1.9.0/tests/test_configs/script_parallel/digit_identification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/script_parallel/pass_through.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/training/train_mlflow.py` & `azure-ai-ml-1.9.0/tests/test_configs/training/train_mlflow.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/file_batch_inference.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/file_batch_inference.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/tabular_batch_inference.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/tabular_run_with_model.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/get_data.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/get_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component/src/convert_data.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/convert_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/script_parallel/pass_through.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_file_input/src/convert_data.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component/src/convert_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_registered/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_registered/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_pipeline/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_pipeline/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/do_while/basic_component/src/baisc_component.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/control_flow/do_while/components/basic_component/basic_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/web_url_input/src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/web_url_input/src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/parallel_component_with_tabular_input/src/tabular_run_with_model.py` & `azure-ai-ml-1.9.0/tests/test_configs/script_parallel/tabular_run_with_model.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentA_src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentB_src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipline_with_data/componentC_src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/predict.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/predict_src/predict.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/transform.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/transform_src/transform.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/train_src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/score_src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/prep.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/nyc_taxi_data_regression/prep_src/prep.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_hello_world/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_hello_world/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train1.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train1.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/eval.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/eval.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/mpi_hello_world/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/mpi_hello_world/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/eval.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/eval.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/invalid_pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/invalid_pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/wordcount.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/shakespear_sample/src/wordcount.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/basic_src/sampleword.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/spark_job_in_pipeline/kmeans_sample/src/kmeans_example.py` & `azure-ai-ml-1.9.0/tests/test_configs/spark_component/src/kmeans_example.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_public_docker_image/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_public_docker_image/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/env_conda_file/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/env_conda_file/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/__init__.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_meta.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_meta.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_basic.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_basic.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_reason_expression.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_reason_expression.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_string_concatenate.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_string_concatenate.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_compute.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_cross_type.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_literal_cross_type.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path_concatenate.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/input_path_concatenate.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_choice.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_choice.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_limits.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_limits.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_literal.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_sweep_literal.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_literal.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_binding_expression/run_settings_literal.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_folder/src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_database/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_file_system/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_file_system/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/export_database/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/copy_data/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/data_transfer_job_in_pipeline/import_stored_database/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/basic_component/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/basic_component/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/primitive_type_components.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/primitive_type_components/src/primitive_type_components.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pytorch_hello_world/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dynamic_input_do_while/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/train_src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/train_src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/eval.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/eval_src/eval.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_inline_components/score_src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline_with_data_as_input.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/pipeline_with_data_as_input.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/train_src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/compare2.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/compare2_src/compare2.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/eval_src/eval.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/eval_src/eval.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_pipeline_component/components/score_src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_registered_components/score_src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_component_with_group/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/e2e_local_components/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/train_src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/train_src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/eval_src/eval.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/eval_src/eval.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/e2e_local_components/score_src/score.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/command_job_in_pipeline/score_src/score.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/dataset_input/src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/component_with_input_output/src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/datastore_datapath_uri_file/src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/automl_job_in_pipeline/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_keyword_in_node_io/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/local_data_input/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/local_data_input/src/hello.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/dataset_input/src/hello.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/pipeline_with_set_binding_output_input/train_src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/pipeline.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/dsl_pipeline/tf_mnist/src/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/dsl_pipeline/tf_mnist/src/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/plot_example.py` & `azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/plot_example.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/simple_example.py` & `azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/simple_example.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/logistic_regression.py` & `azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/logistic_regression.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/sklearn_example.py` & `azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/sklearn_example.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/advanced_example.py` & `azure-ai-ml-1.9.0/tests/test_configs/batch_setup/light_gbm_examples/python-guide/advanced_example.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/spark_job/spark_job_word_count/src/wordcount.py` & `azure-ai-ml-1.9.0/tests/test_configs/pipeline_jobs/serverless_compute/all_types/spark/src/wordcount.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/python/sweep_script_search.py` & `azure-ai-ml-1.9.0/tests/test_configs/python/sweep_script_search.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/python/train.py` & `azure-ai-ml-1.9.0/tests/test_configs/python/train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/python/simple_train.py` & `azure-ai-ml-1.9.0/tests/test_configs/python/simple_train.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/test_configs/python/sweep_script.py` & `azure-ai-ml-1.9.0/tests/test_configs/python/sweep_script.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/compute/e2etests/test_compute.py` & `azure-ai-ml-1.9.0/tests/compute/e2etests/test_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/compute/unittests/test_compute_operations.py` & `azure-ai-ml-1.9.0/tests/compute/unittests/test_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/compute/unittests/test_compute_entity.py` & `azure-ai-ml-1.9.0/tests/compute/unittests/test_compute_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_set/e2etests/test_feature_set.py` & `azure-ai-ml-1.9.0/tests/feature_set/e2etests/test_feature_set.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_set/unittests/test_list_materialization_job_request.py` & `azure-ai-ml-1.9.0/tests/feature_set/unittests/test_list_materialization_job_request.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_set/unittests/test_feature_set_operations.py` & `azure-ai-ml-1.9.0/tests/feature_set/unittests/test_feature_set_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_set/unittests/test_feature_set_schema.py` & `azure-ai-ml-1.9.0/tests/feature_set/unittests/test_feature_set_schema.py`

 * *Files 26% similar despite different names*

```diff
@@ -22,7 +22,24 @@
         assert featureset.version == target["version"]
         assert featureset.description == target["description"]
         assert featureset.entities is not None
         assert featureset.specification is not None
         assert featureset.specification.path is not None
         assert featureset.tags is not None
         assert featureset.properties is not None
+
+    def test_feature_set_load_minimal_with_mat(self) -> None:
+        test_path = "./tests/test_configs/feature_set/feature_set_minimal.yaml"
+        with open(test_path, "r") as f:
+            target = yaml.safe_load(f)
+        with open(test_path, "r") as f:
+            featureset: FeatureSet = load_feature_set(source=test_path)
+        assert featureset.name == target["name"]
+        assert featureset.version == target["version"]
+        assert featureset.entities is not None
+        assert featureset.specification is not None
+        assert featureset.specification.path is not None
+        assert featureset.stage is not None
+        assert featureset.properties is not None
+        assert featureset.materialization_settings is not None
+        assert featureset.materialization_settings.spark_configuration is not None
+        assert featureset.materialization_settings.offline_enabled is None
```

## Comparing `azure-ai-ml-1.8.0/tests/sweep_job/e2etests/test_sweep_job.py` & `azure-ai-ml-1.9.0/tests/sweep_job/e2etests/test_sweep_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/sweep_job/unittests/test_sweep_job.py` & `azure-ai-ml-1.9.0/tests/sweep_job/unittests/test_sweep_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/sweep_job/unittests/test_sweep_job_schema.py` & `azure-ai-ml-1.9.0/tests/sweep_job/unittests/test_sweep_job_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/e2etests/test_online_deployment.py` & `azure-ai-ml-1.9.0/tests/online_services/e2etests/test_online_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/e2etests/test_online_endpoint.py` & `azure-ai-ml-1.9.0/tests/online_services/e2etests/test_online_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_online_endpoints.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_online_endpoints.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,39 +1,36 @@
 from pathlib import Path
-from typing import Callable
-from unittest.mock import Mock, patch
+from unittest.mock import Mock
 
 import pytest
 from pytest_mock import MockFixture
-from requests import Response
-
-from azure.ai.ml import load_online_endpoint
+from azure.ai.ml import load_online_endpoint, load_online_deployment
 from azure.ai.ml._restclient.v2022_10_01.models import EndpointAuthKeys
 from azure.ai.ml._restclient.v2022_02_01_preview.models import (
     KubernetesOnlineDeployment as RestKubernetesOnlineDeployment,
 )
+from azure.ai.ml.entities._util import load_from_dict
 from azure.ai.ml._restclient.v2022_02_01_preview.models import (
     OnlineDeploymentData,
     OnlineDeploymentDetails,
     OnlineEndpointData,
 )
 from azure.ai.ml._restclient.v2022_02_01_preview.models import OnlineEndpointDetails as RestOnlineEndpoint
 from azure.ai.ml._scope_dependent_operations import OperationConfig, OperationScope
 from azure.ai.ml.constants._common import AzureMLResourceType, HttpResponseStatusCode
-from azure.ai.ml.entities import OnlineEndpoint
 from azure.ai.ml.operations import (
     DatastoreOperations,
     EnvironmentOperations,
     ModelOperations,
     OnlineEndpointOperations,
     WorkspaceOperations,
 )
 from azure.ai.ml.operations._code_operations import CodeOperations
 from azure.ai.ml.operations._online_endpoint_operations import _strip_zeroes_from_traffic
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError
+from azure.core.exceptions import HttpResponseError
 from azure.core.polling import LROPoller
 from azure.identity import DefaultAzureCredential
 
 
 @pytest.fixture()
 def mock_delete_poller() -> LROPoller:
     poller = Mock(spec_set=LROPoller)
@@ -444,7 +441,15 @@
 )
 def test_strip_traffic_from_traffic_map(traffic, expected_traffic) -> None:
     result = _strip_zeroes_from_traffic(traffic)
     for k, v in result.items():
         assert expected_traffic[k] == v
     for k, v in expected_traffic.items():
         assert result[k] == v
+
+
+def test_deployment_with_data_collector() -> None:
+    online_deployment = load_online_deployment(
+        source="./tests/test_configs/deployments/online/online_deployment_data_storage_basic.yaml"
+    )
+    assert online_deployment.data_collector.collections["request"].enabled == "true"
+    assert online_deployment.data_collector.collections["response"].enabled == "false"
```

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_schema.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_online_deployments.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_online_deployments.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_scale_settings.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_scale_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_resource_requirements_settings.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_resource_requirements_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_operations.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_scale_settings_schema.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_scale_settings_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/online_services/unittests/test_deployment_executor.py` & `azure-ai-ml-1.9.0/tests/online_services/unittests/test_deployment_executor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_store_entity/e2etests/test_feature_store_entity.py` & `azure-ai-ml-1.9.0/tests/feature_store_entity/e2etests/test_feature_store_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/test_feature_store_entity_schema.py` & `azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/test_feature_store_entity_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_store_entity/unittests/test_feature_store_entity_operations.py` & `azure-ai-ml-1.9.0/tests/feature_store_entity/unittests/test_feature_store_entity_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/environment/e2etests/test_environment.py` & `azure-ai-ml-1.9.0/tests/environment/e2etests/test_environment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_operations.py` & `azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_schema.py` & `azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/environment/unittests/test_environment_operations_registry.py` & `azure-ai-ml-1.9.0/tests/environment/unittests/test_environment_operations_registry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/environment/unittests/test_env_entity.py` & `azure-ai-ml-1.9.0/tests/environment/unittests/test_env_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_store/e2etests/test_feature_store.py` & `azure-ai-ml-1.9.0/tests/feature_store/e2etests/test_feature_store.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_store/unittests/test_feature_store_schema.py` & `azure-ai-ml-1.9.0/tests/feature_store/unittests/test_feature_store_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/feature_store/unittests/test_feature_store_operations.py` & `azure-ai-ml-1.9.0/tests/feature_store/unittests/test_feature_store_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,36 +1,33 @@
 from unittest.mock import DEFAULT, Mock
 
 import pytest
 from pytest_mock import MockFixture
 
 from azure.ai.ml._scope_dependent_operations import OperationScope
-from azure.ai.ml.entities import (
-    FeatureStore,
-    Workspace,
-)
+from azure.ai.ml.entities import FeatureStore, Workspace
 from azure.ai.ml.operations._feature_store_operations import FeatureStoreOperations
 from azure.core.polling import LROPoller
 
 
 @pytest.fixture
 def mock_credential() -> Mock:
     yield Mock()
 
 
 @pytest.fixture
 def mock_feature_store_operation(
     mock_workspace_scope: OperationScope,
-    mock_aml_services_2022_12_01_preview: Mock,
+    mock_aml_services_2023_04_01_preview: Mock,
     mock_machinelearning_client: Mock,
     mock_credential: Mock,
 ) -> FeatureStoreOperations:
     yield FeatureStoreOperations(
         operation_scope=mock_workspace_scope,
-        service_client=mock_aml_services_2022_12_01_preview,
+        service_client=mock_aml_services_2023_04_01_preview,
         all_operations=mock_machinelearning_client._operation_container,
         credentials=mock_credential,
     )
 
 
 @pytest.mark.unittest
 @pytest.mark.data_experiences_test
@@ -48,21 +45,33 @@
         mock_feature_store_operation._operation.get.assert_called_once()
 
     def test_begin_create(
         self,
         mock_feature_store_operation: FeatureStoreOperations,
         mocker: MockFixture,
     ):
+        def outgoing_get_call(rg, name):
+            return Workspace(name=name, kind="featurestore")._to_rest_object()
+
         mocker.patch("azure.ai.ml.operations._feature_store_operations.FeatureStoreOperations.get", return_value=None)
         mocker.patch(
             "azure.ai.ml.operations._feature_store_operations.FeatureStoreOperations._populate_arm_paramaters",
             return_value=({}, {}, {}),
         )
         mocker.patch("azure.ai.ml._arm_deployments.ArmDeploymentExecutor.deploy_resource", return_value=LROPoller)
+
+        # create
+        mock_feature_store_operation._operation.get.side_effect = Exception()
+        mock_feature_store_operation.begin_create(feature_store=FeatureStore(name="name"))
+
+        # double create call
+        mock_feature_store_operation._operation.get.side_effect = outgoing_get_call
+        mock_feature_store_operation._operation.begin_update.side_effect = None
         mock_feature_store_operation.begin_create(feature_store=FeatureStore(name="name"))
+        mock_feature_store_operation._operation.begin_update.assert_called()
 
     def test_update(self, mock_feature_store_operation: FeatureStoreOperations) -> None:
         fs = FeatureStore(
             name="name",
             description="description",
         )
```

## Comparing `azure-ai-ml-1.8.0/tests/component/e2etests/test_component_hash.py` & `azure-ai-ml-1.9.0/tests/component/e2etests/test_component_hash.py`

 * *Files 1% similar despite different names*

```diff
@@ -35,14 +35,15 @@
 
 
 @pytest.mark.e2etest
 @pytest.mark.timeout(_COMPONENT_TIMEOUT_SECOND)
 @pytest.mark.usefixtures(
     "recorded_test",
     "mock_asset_name",
+    "mock_component_hash",
 )
 @pytest.mark.pipeline_test
 class TestComponentHash(AzureRecordedTestCase):
     @classmethod
     def _assert_recreated_component_no_change(cls, base_dir, client, randstr, with_code_diff=False):
         component_name = randstr("component_name")
         component: CommandComponent = create_component(
```

## Comparing `azure-ai-ml-1.8.0/tests/component/e2etests/test_component.py` & `azure-ai-ml-1.9.0/tests/component/e2etests/test_component.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,55 +1,58 @@
 import re
+import time
 import uuid
 from itertools import tee
 from pathlib import Path
 from typing import Callable
 
 import pydash
 import pytest
+from azure.core.exceptions import HttpResponseError
+from azure.core.paging import ItemPaged
+from devtools_testutils import AzureRecordedTestCase, is_live
+from test_utilities.utils import assert_job_cancel, omit_with_wildcard, sleep_if_live
+
 from azure.ai.ml import MLClient, MpiDistribution, load_component, load_environment
 from azure.ai.ml._restclient.v2022_05_01.models import ListViewType
 from azure.ai.ml._utils._arm_id_utils import is_ARM_id_for_resource
+from azure.ai.ml.constants._assets import IPProtectionLevel
 from azure.ai.ml.constants._common import (
     ANONYMOUS_COMPONENT_NAME,
     ARM_ID_PREFIX,
     PROVIDER_RESOURCE_ID_WITH_VERSION,
     AzureMLResourceType,
 )
-from azure.ai.ml.constants._assets import IPProtectionLevel
 from azure.ai.ml.dsl._utils import _sanitize_python_variable_name
 from azure.ai.ml.entities import CommandComponent, Component, PipelineComponent
 from azure.ai.ml.entities._load_functions import load_code, load_job
-from azure.core.exceptions import HttpResponseError
-from azure.core.paging import ItemPaged
-from devtools_testutils import AzureRecordedTestCase, is_live
-from test_utilities.utils import assert_job_cancel, omit_with_wildcard, sleep_if_live
 
 from .._util import _COMPONENT_TIMEOUT_SECOND
 from ..unittests.test_component_schema import load_component_entity_from_rest_json
 
 
 def create_component(
     client: MLClient,
     component_name: str,
     path="./tests/test_configs/components/helloworld_component.yml",
     params_override=None,
     is_anonymous=False,
+    **kwargs,
 ):
     default_param_override = [{"name": component_name}]
     if params_override is None:
         params_override = default_param_override
     else:
         params_override += default_param_override
 
     command_component = load_component(
         source=path,
         params_override=params_override,
     )
-    return client.components.create_or_update(command_component, is_anonymous=is_anonymous)
+    return client.components.create_or_update(command_component, is_anonymous=is_anonymous, **kwargs)
 
 
 @pytest.fixture
 def torch_distribution():
     def create_torch_distribution(has_strs: bool = False):
         # service returns component with stringified integer values
         # need to do comparison with object returned by service with strings
@@ -379,15 +382,15 @@
         target_entity = client.components.create_or_update(component_entity)
         target_entity._creation_context = None
         target_entity.resources = None
         component_entity._creation_context = None
         assert target_entity.id
         # server side will remove \n from the code now. Skip them given it's not targeted to check in this test
         # server side will return optional False for optional None input
-        omit_fields = ["id", "command", "environment", "inputs.*.optional"]
+        omit_fields = ["id", "command", "environment", "inputs.*.optional", "properties"]
         assert omit_with_wildcard(component_entity._to_dict(), *omit_fields) == omit_with_wildcard(
             target_entity._to_dict(), *omit_fields
         )
 
     def test_command_component_with_code(self, client: MLClient, randstr: Callable[[str], str]) -> None:
         component_name = randstr("component_name")
 
@@ -1022,7 +1025,57 @@
         )
 
         assert from_rest_component.outputs["model_output_ipp"]._intellectual_property
         assert (
             from_rest_component.outputs["model_output_ipp"]._intellectual_property
             == command_component.outputs["model_output_ipp"]._intellectual_property
         )
+
+    def test_create_component_skip_if_no_change(self, client: MLClient, randstr):
+        component_operation = client._operation_container.all_operations[AzureMLResourceType.COMPONENT]
+        component_name = "test_skip_if_no_change"
+        try:
+            default_component = component_operation.get(name=component_name)
+        except Exception:
+            default_component = None
+        default_version = default_component.version if default_component else "1"
+        # update  default component by current local component data.
+        default_component = create_component(client, component_name=component_name, version=default_version)
+
+        # test component has no change and use skip_if_no_change parameter
+        new_version = randstr("component_version")
+        new_component = create_component(
+            client, component_name=component_name, version=new_version, skip_if_no_change=True
+        )
+        assert default_component._get_component_hash(
+            keys_to_omit=["creation_context"]
+        ) == new_component._get_component_hash(keys_to_omit=["creation_context"])
+
+        # test component has change and use skip_if_no_change parameter
+        new_version = randstr("component_version")
+        params_override = [
+            {"description": "description_{0}".format(new_version)},
+            {"display_name": "display_name_{0}".format(new_version)},
+            {"tags": {"tags": "tags_{0}".format(new_version)}},
+        ]
+        new_component = create_component(
+            client,
+            component_name=component_name,
+            version=new_version,
+            params_override=params_override,
+            skip_if_no_change=True,
+        )
+        assert default_component._get_component_hash(
+            keys_to_omit=["creation_context"]
+        ) != new_component._get_component_hash(keys_to_omit=["creation_context"])
+        assert new_component.description == "description_{0}".format(new_version)
+        assert new_component.display_name == "display_name_{0}".format(new_version)
+        assert new_component.tags == {"tags": "tags_{0}".format(new_version)}
+        assert new_component.version == new_version
+
+        # test component has no change and not use skip_if_no_change parameter
+        new_version = randstr("component_version")
+        new_component = create_component(client, component_name=component_name, version=new_version)
+        assert default_component._get_component_hash(
+            keys_to_omit=["creation_context"]
+        ) != new_component._get_component_hash(keys_to_omit=["creation_context"])
+        assert new_component.version == new_version
```

## Comparing `azure-ai-ml-1.8.0/tests/component/e2etests/test_component_validate.py` & `azure-ai-ml-1.9.0/tests/component/e2etests/test_component_validate.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_component_schema.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_component_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_component_operations.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_component_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_data_transfer_component_entity.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_data_transfer_component_entity.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,20 @@
 import pydash
 import pytest
 
-from azure.ai.ml import MLClient
-from azure.ai.ml import load_component
+from azure.ai.ml import MLClient, load_component
+from azure.ai.ml.constants._component import DataCopyMode, DataTransferTaskType
 from azure.ai.ml.entities._component.datatransfer_component import (
     DataTransferCopyComponent,
-    DataTransferImportComponent,
     DataTransferExportComponent,
+    DataTransferImportComponent,
 )
-from azure.ai.ml.constants._component import DataCopyMode, DataTransferTaskType
-from .test_component_schema import (
-    load_component_entity_from_rest_json,
-    load_component_entity_from_yaml,
-)
+
 from .._util import _COMPONENT_TIMEOUT_SECOND
+from .test_component_schema import load_component_entity_from_rest_json, load_component_entity_from_yaml
 
 
 @pytest.mark.timeout(_COMPONENT_TIMEOUT_SECOND)
 @pytest.mark.unittest
 @pytest.mark.pipeline_test
 class TestDataTransferComponentEntity:
     def test_serialize_deserialize_copy_task_component(self, mock_machinelearning_client: MLClient):
@@ -144,14 +141,15 @@
             },
             data_copy_mode=DataCopyMode.MERGE_WITH_OVERWRITE,
             base_path="./tests/test_configs/components/data_transfer",
         )
         omit_fields = [
             "properties.component_spec.$schema",
             "properties.component_spec._source",
+            "properties.properties.client_component_hash",
         ]
         component._validate()
         component_dict = component._to_rest_object().as_dict()
         component_dict = pydash.omit(component_dict, *omit_fields)
 
         yaml_path = "./tests/test_configs/components/data_transfer/copy_files.yaml"
         yaml_component = load_component(yaml_path)
```

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_spark_component_entity.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_spark_component_entity.py`

 * *Files 2% similar despite different names*

```diff
@@ -57,14 +57,15 @@
             files=["my_files.txt"],
             args="--file_input ${{inputs.file_input}}",
             base_path="./tests/test_configs/dsl_pipeline/spark_job_in_pipeline",
         )
         omit_fields = [
             "properties.component_spec.$schema",
             "properties.component_spec._source",
+            "properties.properties.client_component_hash",
         ]
         component_dict = component._to_rest_object().as_dict()
         component_dict = pydash.omit(component_dict, *omit_fields)
 
         yaml_path = "./tests/test_configs/dsl_pipeline/spark_job_in_pipeline/add_greeting_column_component.yml"
         yaml_component = load_component(yaml_path)
         yaml_component_dict = yaml_component._to_rest_object().as_dict()
```

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_pipeline_component_entity.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_pipeline_component_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_component_operations_registry.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_component_operations_registry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_command_component_entity.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_command_component_entity.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,34 @@
+import enum
 import os
 import sys
+import tempfile
 from io import StringIO
-import enum
 from pathlib import Path
-import tempfile
 from unittest.mock import patch
 from zipfile import ZipFile
 
 import pydash
 import pytest
-
-from conftest import normalized_arm_id_in_object
-from test_utilities.utils import verify_entity_load_and_dump, build_temp_folder
+from test_utilities.utils import (
+    build_temp_folder,
+    mock_artifact_download_to_temp_directory,
+    verify_entity_load_and_dump,
+)
 
 from azure.ai.ml import Input, MpiDistribution, Output, TensorFlowDistribution, command, load_component
 from azure.ai.ml._utils.utils import load_yaml
 from azure.ai.ml.constants._common import AzureMLResourceType
-from azure.ai.ml.entities import Component, CommandComponent, CommandJobLimits, JobResourceConfiguration
-from azure.ai.ml.entities._assets import Code
-from azure.ai.ml.entities._assets import Environment
+from azure.ai.ml.entities import CommandComponent, CommandJobLimits, Component, JobResourceConfiguration
+from azure.ai.ml.entities._assets import Code, Environment
 from azure.ai.ml.entities._builders import Command, Sweep
 from azure.ai.ml.entities._job.pipeline._io import PipelineInput
 from azure.ai.ml.exceptions import UnexpectedKeywordError, ValidationException
 from azure.ai.ml.sweep import Choice
+from conftest import normalized_arm_id_in_object
 
 from .._util import _COMPONENT_TIMEOUT_SECOND
 
 
 class AdditionalIncludesCheckFunc(enum.Enum):
     """Enum for additional includes check function"""
 
@@ -88,82 +90,71 @@
             version="1",
             outputs={"component_out_path": {"type": "uri_folder"}},
             command="echo Hello World",
             code=code,
             environment="AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:33",
         )
         component_dict = component._to_rest_object().as_dict()
-        omits = ["properties.component_spec.$schema", "properties.component_spec._source"]
+        omits = [
+            "properties.component_spec.$schema",
+            "properties.component_spec._source",
+            "properties.properties.client_component_hash",
+        ]
         component_dict = pydash.omit(component_dict, *omits)
 
         yaml_path = "./tests/test_configs/components/basic_component_code_arm_id.yml"
         yaml_component = load_component(source=yaml_path)
         yaml_component_dict = yaml_component._to_rest_object().as_dict()
         yaml_component_dict = pydash.omit(yaml_component_dict, *omits)
 
         assert component_dict == yaml_component_dict
 
     def test_command_component_with_additional_includes(self):
         tests_root_dir = Path(__file__).parent.parent.parent
         samples_dir = tests_root_dir / "test_configs/components/"
-        with tempfile.TemporaryDirectory() as temp_dir:
-
-            def mock_get_artifacts(**kwargs):
-                version = kwargs.get("version")
-                artifact = Path(temp_dir) / version
-                if version in ["version_1", "version_3"]:
-                    version = "version_1"
-                artifact.mkdir(parents=True, exist_ok=True)
-                (artifact / version).mkdir(exist_ok=True)
-                (artifact / version / "file").touch(exist_ok=True)
-                (artifact / f"file_{version}").touch(exist_ok=True)
-                return str(artifact)
-
-            with patch(
-                "azure.ai.ml.entities._component._artifact_cache.ArtifactCache.get", side_effect=mock_get_artifacts
-            ):
-                component = CommandComponent(
-                    name="additional_files",
-                    description="A sample to demonstrate component with additional files",
-                    version="0.0.1",
-                    command="echo Hello World",
-                    environment=Environment(image="zzn2/azureml_sdk"),
-                    # as sdk will take working directory as root folder, so we need to specify the absolution path
-                    additional_includes=[
-                        str(samples_dir / "additional_includes/assets/LICENSE"),
-                        str(samples_dir / "additional_includes/library.zip"),
-                        str(samples_dir / "additional_includes/library1"),
-                    ],
-                )
-                component.additional_includes.append(
-                    {
-                        "type": "artifact",
-                        "organization": "https://msdata.visualstudio.com/",
-                        "project": "Vienna",
-                        "feed": "component-sdk-test-feed",
-                        "name": "test_additional_include",
-                        "version": "version_2",
-                        "scope": "project",
-                    }
-                )
-                assert component._validate().passed, repr(component._validate())
-                with component._resolve_local_code() as code:
-                    code_path: Path = code.path
-                    assert code_path.is_dir()
-                    assert (code_path / "LICENSE").is_file()
-                    assert (code_path / "library.zip").is_file()
-                    assert ZipFile(code_path / "library.zip").namelist() == [
-                        "library/",
-                        "library/hello.py",
-                        "library/world.py",
-                    ]
-                    assert (code_path / "library1" / "hello.py").is_file()
-                    assert (code_path / "library1" / "world.py").is_file()
-                    assert (code_path / "file_version_2").is_file()
-                    assert (code_path / "version_2" / "file").is_file()
+        with mock_artifact_download_to_temp_directory():
+            component = CommandComponent(
+                name="additional_files",
+                description="A sample to demonstrate component with additional files",
+                version="0.0.1",
+                command="echo Hello World",
+                environment=Environment(image="zzn2/azureml_sdk"),
+                # as sdk will take working directory as root folder, so we need to specify the absolution path
+                additional_includes=[
+                    str(samples_dir / "additional_includes/assets/LICENSE"),
+                    str(samples_dir / "additional_includes/library.zip"),
+                    str(samples_dir / "additional_includes/library1"),
+                ],
+            )
+            component.additional_includes.append(
+                {
+                    "type": "artifact",
+                    "organization": "https://msdata.visualstudio.com/",
+                    "project": "Vienna",
+                    "feed": "component-sdk-test-feed",
+                    "name": "test_additional_include",
+                    "version": "version_2",
+                    "scope": "project",
+                }
+            )
+            assert component._validate().passed, repr(component._validate())
+            with component._build_code() as code:
+                code_path: Path = code.path
+                assert code_path.is_dir()
+                assert (code_path / "LICENSE").is_file()
+                assert (code_path / "library.zip").is_file()
+                assert ZipFile(code_path / "library.zip").namelist() == [
+                    "library/",
+                    "library/hello.py",
+                    "library/world.py",
+                ]
+                assert (code_path / "library1" / "hello.py").is_file()
+                assert (code_path / "library1" / "world.py").is_file()
+                assert (code_path / "file_version_2").is_file()
+                assert (code_path / "version_2" / "file").is_file()
 
     def test_command_component_entity_with_io_class(self):
         component = CommandComponent(
             name="sample_command_component_entity_with_io_class",
             display_name="Preprocess data for training",
             description="reads raw price data, normalize and split the data",
             inputs={
@@ -231,21 +222,23 @@
 
         component_dict = pydash.omit(
             component_dict,
             "properties.component_spec.$schema",
             "properties.component_spec.distribution.added_property",
             "properties.component_spec.resources.properties",
             "properties.component_spec._source",
+            "properties.properties.client_component_hash",
         )
         yaml_component_dict = pydash.omit(
             yaml_component_dict,
             "properties.component_spec.$schema",
             "properties.component_spec.distribution.added_property",
             "properties.component_spec.resources.properties",
             "properties.component_spec._source",
+            "properties.properties.client_component_hash",
         )
         assert component_dict == yaml_component_dict
 
     def test_command_component_code(self):
         component = CommandComponent(
             name="SampleCommandComponentBasic",
             display_name="CommandComponentBasic",
@@ -264,15 +257,15 @@
 
     def test_command_component_code_with_current_folder(self):
         old_cwd = os.getcwd()
         os.chdir("./tests/test_configs/components")
         try:
             yaml_path = "./basic_component_code_current_folder.yml"
             component = load_component(yaml_path)
-            with component._resolve_local_code() as code:
+            with component._build_code() as code:
                 Path(code.path).resolve().name == "components"
         finally:
             os.chdir(old_cwd)
 
     def test_command_component_code_git_path(self):
         from azure.ai.ml.operations._component_operations import _try_resolve_code_for_component
 
@@ -552,17 +545,14 @@
             component2._to_rest_object().as_dict()["properties"]["component_spec"], *omits
         )
         assert actual_component_dict2 == expected_rest_component
 
     def test_invalid_component_outputs(self) -> None:
         yaml_path = "./tests/test_configs/components/invalid/helloworld_component_invalid_early_available_output.yml"
         component = load_component(yaml_path)
-        with pytest.raises(ValidationException) as e:
-            component._validate(raise_error=True)
-        assert "Early available output 'component_out_string' requires is_control as True, got None." in str(e.value)
         params_override = [
             {
                 "outputs": {
                     "component_out_string": {
                         "description": "A string",
                         "type": "string",
                         "is_control": True,
@@ -581,22 +571,25 @@
         with build_temp_folder(
             source_base_dir="./tests/test_configs/components",
             relative_files_to_copy=["helloworld_component.yml"],
             extra_files_to_create={"__pycache__/a.pyc": None},
         ) as temp_dir:
             # resolve and test for ignore_file's is_file_excluded
             component.code = temp_dir
-            with component._resolve_local_code() as code:
+            with component._build_code() as code:
                 excluded = []
                 for root, _, files in os.walk(code.path):
                     for name in files:
                         path = os.path.join(root, name)
                         if code._ignore_file.is_file_excluded(path):
                             excluded.append(path)
-                assert excluded == [str((Path(temp_dir) / "__pycache__/a.pyc").absolute())]
+                # use samefile to avoid windows path auto shortening issue
+                assert len(excluded) == 1
+                assert os.path.isabs(excluded[0])
+                assert Path(excluded[0]).samefile((Path(temp_dir) / "__pycache__/a.pyc"))
 
     def test_normalized_arm_id_in_component_dict(self):
         component_dict = {
             "code": "azureml:/subscriptions/123ABC_+-=/resourceGroups/123ABC_+-=/providers/Microsoft.MachineLearningServices/workspaces/123ABC_+-=/codes/xxx",
             "environment": "azureml:/subscriptions/123ABC_+-=/resourceGroups/123ABC_+-=/providers/Microsoft.MachineLearningServices/workspaces/123ABC_+-=/environments/xxx",
         }
         normalized_arm_id_in_object(component_dict)
@@ -666,15 +659,15 @@
 
     def test_additional_includes(self) -> None:
         yaml_path = (
             "./tests/test_configs/components/component_with_additional_includes/helloworld_additional_includes.yml"
         )
         component = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
-        with component._resolve_local_code() as code:
+        with component._build_code() as code:
             code_path: Path = code.path
             assert code_path.is_dir()
             assert (code_path / "LICENSE").is_file()
             assert (code_path / "library.zip").is_file()
             assert ZipFile(code_path / "library.zip").namelist() == ["library/", "library/hello.py", "library/world.py"]
             assert (code_path / "library1" / "hello.py").is_file()
             assert (code_path / "library1" / "world.py").is_file()
@@ -788,15 +781,15 @@
                 / "code_and_additional_includes"
                 / "component_spec.yml"
             )
 
             component = load_component(source=yaml_path)
 
             # resolve and check snapshot directory
-            with component._resolve_local_code() as code:
+            with component._build_code() as code:
                 for file, content, check_func in test_files:
                     # original file is based on test_configs_dir, need to remove the leading
                     # "component_with_additional_includes" or "additional_includes" to get the relative path
                     resolved_file_path = Path(os.path.join(code.path, *Path(file).parts[1:]))
                     if check_func == AdditionalIncludesCheckFunc.NO_PARENT:
                         assert not resolved_file_path.parent.exists(), f"{file} should not have parent"
                     elif check_func == AdditionalIncludesCheckFunc.SELF_IS_FILE:
@@ -814,15 +807,15 @@
 
     def test_additional_includes_merge_folder(self) -> None:
         yaml_path = (
             "./tests/test_configs/components/component_with_additional_includes/additional_includes_merge_folder.yml"
         )
         component = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
-        with component._resolve_local_code() as code:
+        with component._build_code() as code:
             code_path = code.path
             # first folder
             assert (code_path / "library1" / "__init__.py").is_file()
             assert (code_path / "library1" / "hello.py").is_file()
             # second folder content
             assert (code_path / "library1" / "utils").is_dir()
             assert (code_path / "library1" / "utils" / "__init__.py").is_file()
@@ -836,15 +829,15 @@
         ],
     )
     def test_additional_includes_with_code_specified(self, yaml_path: str, has_additional_includes: bool) -> None:
         yaml_path = os.path.join("./tests/test_configs/components/component_with_additional_includes/", yaml_path)
         component = load_component(source=yaml_path)
         assert component._validate().passed, repr(component._validate())
         # resolve
-        with component._resolve_local_code() as code:
+        with component._build_code() as code:
             code_path = code.path
             assert code_path.is_dir()
             if has_additional_includes:
                 # additional includes is specified, code will be tmp folder and need to check each item
                 # manually list here to avoid temp folder like __pycache__ breaking test.
                 for path in [
                     "additional_includes_merge_folder.yml",
@@ -860,81 +853,66 @@
             else:
                 # additional includes not specified, code should be specified path (default yaml folder)
                 yaml_dict = load_yaml(yaml_path)
                 specified_code_path = Path(yaml_path).parent / yaml_dict.get("code", "./")
                 assert code_path.resolve() == specified_code_path.resolve()
 
     def test_artifacts_in_additional_includes(self):
-        with tempfile.TemporaryDirectory() as temp_dir:
-
-            def mock_get_artifacts(**kwargs):
-                version = kwargs.get("version")
-                artifact = Path(temp_dir) / version
-                if version in ["version_1", "version_3"]:
-                    version = "version_1"
-                artifact.mkdir(parents=True, exist_ok=True)
-                (artifact / version).mkdir(exist_ok=True)
-                (artifact / version / "file").touch(exist_ok=True)
-                (artifact / f"file_{version}").touch(exist_ok=True)
-                return str(artifact)
+        with mock_artifact_download_to_temp_directory():
+            yaml_path = "./tests/test_configs/components/component_with_additional_includes/with_artifacts.yml"
+            component = load_component(source=yaml_path)
+            assert component._validate().passed, repr(component._validate())
+            with component._build_code() as code:
+                code_path = code.path
+                assert code_path.is_dir()
+                for path in [
+                    "version_1/",
+                    "version_1/file",
+                    "version_2/",
+                    "version_2/file",
+                    "file_version_1",
+                    "file_version_2",
+                    "DockerFile",
+                ]:
+                    assert (code_path / path).exists()
 
-            with patch(
-                "azure.ai.ml.entities._component._artifact_cache.ArtifactCache.get", side_effect=mock_get_artifacts
+            yaml_path = (
+                "./tests/test_configs/components/component_with_additional_includes/"
+                "artifacts_additional_includes_with_conflict.yml"
+            )
+            component = load_component(source=yaml_path)
+            with pytest.raises(
+                RuntimeError,
+                match="There are conflict files in additional include"
+                ".*test_additional_include:version_1 in component-sdk-test-feed"
+                ".*test_additional_include:version_3 in component-sdk-test-feed",
             ):
-                yaml_path = "./tests/test_configs/components/component_with_additional_includes/with_artifacts.yml"
-                component = load_component(source=yaml_path)
-                assert component._validate().passed, repr(component._validate())
-                with component._resolve_local_code() as code:
-                    code_path = code.path
-                    assert code_path.is_dir()
-                    for path in [
-                        "version_1/",
-                        "version_1/file",
-                        "version_2/",
-                        "version_2/file",
-                        "file_version_1",
-                        "file_version_2",
-                        "DockerFile",
-                    ]:
-                        assert (code_path / path).exists()
-
-                yaml_path = (
-                    "./tests/test_configs/components/component_with_additional_includes/"
-                    "artifacts_additional_includes_with_conflict.yml"
-                )
-                component = load_component(source=yaml_path)
-                validation_result = component._validate()
-                assert validation_result.passed is False
-                assert "There are conflict files in additional include" in validation_result.error_messages["*"]
-                assert (
-                    "test_additional_include:version_1 in component-sdk-test-feed"
-                    in validation_result.error_messages["*"]
-                )
-                assert (
-                    "test_additional_include:version_3 in component-sdk-test-feed"
-                    in validation_result.error_messages["*"]
-                )
+                with component._build_code():
+                    pass
 
     @pytest.mark.parametrize(
         "yaml_path,expected_error_msg_prefix",
         [
-            (
+            pytest.param(
                 "helloworld_invalid_additional_includes_root_directory.yml",
                 "Root directory is not supported for additional includes",
+                id="root_as_additional_includes",
             ),
-            (
+            pytest.param(
                 "helloworld_invalid_additional_includes_existing_file.yml",
                 "A file already exists for additional include",
+                id="file_already_exists",
             ),
-            (
+            pytest.param(
                 "helloworld_invalid_additional_includes_zip_file_not_found.yml",
                 "Unable to find additional include ../additional_includes/assets/LICENSE.zip",
+                id="zip_file_not_found",
             ),
         ],
     )
     def test_invalid_additional_includes(self, yaml_path: str, expected_error_msg_prefix: str) -> None:
         component = load_component(
             os.path.join("./tests/test_configs/components/component_with_additional_includes", yaml_path)
         )
         validation_result = component._validate()
         assert validation_result.passed is False
-        assert validation_result.error_messages["*"].startswith(expected_error_msg_prefix)
+        assert validation_result.error_messages["additional_includes"].startswith(expected_error_msg_prefix)
```

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_automl_component.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_automl_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_operations.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_entity.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_entity.py`

 * *Files 2% similar despite different names*

```diff
@@ -64,14 +64,15 @@
             task=task,
             base_path="./tests/test_configs/components",
         )
         omit_fields = [
             "properties.component_spec.$schema",
             "properties.component_spec.inputs",
             "properties.component_spec._source",
+            "properties.properties.client_component_hash",
         ]
         component_dict = component._to_rest_object().as_dict()
         component_dict = pydash.omit(component_dict, *omit_fields)
 
         yaml_path = "./tests/test_configs/components/basic_parallel_component_score.yml"
         yaml_component = load_component(source=yaml_path)
         yaml_component_dict = yaml_component._to_rest_object().as_dict()
```

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_parallel_component_schema.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_parallel_component_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/component/unittests/test_component_validate.py` & `azure-ai-ml-1.9.0/tests/component/unittests/test_component_validate.py`

 * *Files 6% similar despite different names*

```diff
@@ -71,18 +71,15 @@
                 component()
 
     @pytest.mark.usefixtures("enable_private_preview_schema_features")
     def test_component_early_available_output_not_set_is_control(self):
         yaml_file = str(components_dir / "invalid/helloworld_component_early_available_output_not_set_is_control.yml")
         component = load_component(yaml_file)
         validation_result = component._validate()
-        assert not validation_result.passed
-        assert "outputs.component_out_string" in validation_result.error_messages
-        expected_error_message = "Early available output 'component_out_string' requires is_control as True, got None."
-        assert validation_result.error_messages["outputs.component_out_string"] == expected_error_message
+        assert validation_result.passed
 
     @pytest.mark.parametrize(
         "expected_location,asset_object",
         [
             (
                 "code",
                 Code(name="AzureML-Code", version="1"),
```

## Comparing `azure-ai-ml-1.8.0/tests/command_job/e2etests/test_command_job.py` & `azure-ai-ml-1.9.0/tests/command_job/e2etests/test_command_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/command_job/unittests/test_command_job_entity.py` & `azure-ai-ml-1.9.0/tests/command_job/unittests/test_command_job_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/command_job/unittests/test_command_job_schema.py` & `azure-ai-ml-1.9.0/tests/command_job/unittests/test_command_job_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/data_import/e2etests/test_data_import.py` & `azure-ai-ml-1.9.0/tests/data_import/e2etests/test_data_import.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/data_import/e2etests/test_schedule.py` & `azure-ai-ml-1.9.0/tests/data_import/e2etests/test_schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/data_import/unittests/test_data_import.py` & `azure-ai-ml-1.9.0/tests/data_import/unittests/test_data_import.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/job_common/unittests/test_local_job_invoker.py` & `azure-ai-ml-1.9.0/tests/job_common/unittests/test_local_job_invoker.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/job_common/unittests/test_job_operations.py` & `azure-ai-ml-1.9.0/tests/job_common/unittests/test_job_operations.py`

 * *Files 5% similar despite different names*

```diff
@@ -3,36 +3,36 @@
 from typing import Callable
 from unittest.mock import Mock, patch
 
 import jwt
 import pytest
 import vcr
 import yaml
-from azure.ai.ml._azure_environments import _get_aml_resource_id_from_metadata, _resource_to_scopes
-from azure.ai.ml.exceptions import ValidationException
 from azure.core.credentials import AccessToken
+from azure.core.exceptions import HttpResponseError
+from azure.identity import DefaultAzureCredential
 from msrest import Deserializer
 from pytest_mock import MockFixture
 
 from azure.ai.ml import MLClient, load_job
+from azure.ai.ml._azure_environments import _get_aml_resource_id_from_metadata, _resource_to_scopes
 from azure.ai.ml._restclient.v2023_04_01_preview import models
 from azure.ai.ml._scope_dependent_operations import OperationConfig, OperationScope
 from azure.ai.ml.constants._common import AZUREML_PRIVATE_FEATURES_ENV_VAR, AzureMLResourceType
 from azure.ai.ml.entities._builders import Command
 from azure.ai.ml.entities._job.automl.automl_job import AutoMLJob
 from azure.ai.ml.entities._job.automl.training_settings import TrainingSettings
 from azure.ai.ml.entities._job.job import Job
 from azure.ai.ml.entities._job.sweep.sweep_job import SweepJob
+from azure.ai.ml.exceptions import ValidationException
 from azure.ai.ml.operations import DatastoreOperations, EnvironmentOperations, JobOperations, WorkspaceOperations
 from azure.ai.ml.operations._code_operations import CodeOperations
 from azure.ai.ml.operations._job_ops_helper import get_git_properties
 from azure.ai.ml.operations._run_history_constants import RunHistoryConstants
 from azure.ai.ml.operations._run_operations import RunOperations
-from azure.core.exceptions import HttpResponseError
-from azure.identity import DefaultAzureCredential
 
 from .test_vcr_utils import before_record_cb, vcr_header_filters
 
 
 @pytest.fixture
 def mock_datastore_operation(
     mock_workspace_scope: OperationScope, mock_operation_config: OperationConfig, mock_aml_services_2022_10_01: Mock
@@ -143,14 +143,16 @@
 
     @patch.object(Job, "_from_rest_object")
     def test_get(self, mock_method, mock_job_operation: JobOperations) -> None:
         mock_method.return_value = Command(component=None)
         mock_job_operation.get("randon_name")
         mock_job_operation._operation_2023_02_preview.get.assert_called_once()
 
+    # use mock_component_hash to avoid passing a Mock object as client key
+    @pytest.mark.usefixtures("mock_component_hash")
     @patch.object(JobOperations, "_get_job")
     def test_get_job(self, mock_method, mock_job_operation: JobOperations) -> None:
         from azure.ai.ml import Input, dsl, load_component
 
         component = load_component(source="./tests/test_configs/components/helloworld_component.yml")
         component_input = Input(type="uri_file", path="https://dprepdata.blob.core.windows.net/demo/Titanic.csv")
```

## Comparing `azure-ai-ml-1.8.0/tests/job_common/unittests/test_job_ops_helper.py` & `azure-ai-ml-1.9.0/tests/job_common/unittests/test_job_ops_helper.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/job_common/unittests/test_vcr_utils.py` & `azure-ai-ml-1.9.0/tests/job_common/unittests/test_vcr_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/registry/e2etests/test_registry.py` & `azure-ai-ml-1.9.0/tests/registry/e2etests/test_registry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_operations.py` & `azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_entity.py` & `azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/registry/unittests/test_registry_schema.py` & `azure-ai-ml-1.9.0/tests/registry/unittests/test_registry_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_endpoint_entity.py` & `azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_endpoint_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_deployment_entity.py` & `azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_deployment_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/batch_online_common/unittests/test_code_configuration.py` & `azure-ai-ml-1.9.0/tests/batch_online_common/unittests/test_code_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/e2etests/test_upload_download.py` & `azure-ai-ml-1.9.0/tests/internal_utils/e2etests/test_upload_download.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/e2etests/test_telemetry_value.py` & `azure-ai-ml-1.9.0/tests/internal_utils/e2etests/test_telemetry_value.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_logger_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_logger_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_persistent_locals.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_persistent_locals.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_storage_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_storage_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_fields.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_fields.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_file_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_file_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_cloud_environments.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_cloud_environments.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_smoke.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_smoke.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_arm_id_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_arm_id_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_experimental_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_experimental_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_asset_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_asset_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_ml_client.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_ml_client.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_get_content_hash.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_get_content_hash.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_exceptions.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_exceptions.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_validation.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_validation.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_operation_orchestrator.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_operation_orchestrator.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_asset_entity.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_asset_entity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_telemetry_value.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_telemetry_value.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/internal_utils/unittests/test_cache_utils.py` & `azure-ai-ml-1.9.0/tests/internal_utils/unittests/test_cache_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 import os
 import stat
 from pathlib import Path
 from typing import Union
 
 import mock
 import pytest
+
 from azure.ai.ml import MLClient, load_job
 from azure.ai.ml._utils._cache_utils import CachedNodeResolver
 from azure.ai.ml.entities import Component, PipelineJob
 
 
 @pytest.mark.unittest
 @pytest.mark.pipeline_test
@@ -26,18 +27,15 @@
         on_disk_hash = resolver.calc_on_disk_hash_for_component(component=component, in_memory_hash=in_memory_hash)
         return resolver._get_on_disk_cache_path(on_disk_hash)
 
     @staticmethod
     def create_resolver(client: MLClient) -> CachedNodeResolver:
         return CachedNodeResolver(
             resolver=TestCacheUtils._mock_resolver,
-            subscription_id=client.subscription_id,
-            resource_group_name=client.resource_group_name,
-            workspace_name=client.workspace_name,
-            registry_name=client._operation_scope.registry_name,
+            client_key=client.components._get_client_key(),
         )
 
     @staticmethod
     def get_target_node():
         pipeline_job: PipelineJob = load_job(
             source="./tests/test_configs/pipeline_jobs/helloworld_pipeline_job_inline_comps.yml",
         )
```

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/jsonl_converter.py` & `azure-ai-ml-1.9.0/tests/automl_job/jsonl_converter.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/conftest.py` & `azure-ai-ml-1.9.0/tests/automl_job/conftest.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_object_detection.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_object_detection.py`

 * *Files 11% similar despite different names*

```diff
@@ -96,57 +96,67 @@
                             validation_f.write(json.dumps(json_line) + "\n")
                         else:
                             # train annotation
                             train_f.write(json.dumps(json_line) + "\n")
                     else:
                         print("Skipping unknown file: {}".format(filename))
 
+    @pytest.mark.parametrize("components", [(False), (True)])
     def test_image_object_detection_run(
-        self, image_object_detection_dataset: Tuple[Input, Input], client: MLClient
+        self, image_object_detection_dataset: Tuple[Input, Input], client: MLClient, components: bool
     ) -> None:
         # Note: this test launches two jobs in order to avoid calling the dataset fixture more than once. Ideally, it
         # would have sufficed to mark the fixture with session scope, but pytest-xdist breaks this functionality:
         # https://github.com/pytest-dev/pytest-xdist/issues/271.
 
         # Get training and validation data
         train_path, val_path = image_object_detection_dataset
 
         # Create jsonl file
         self._create_jsonl_object_detection(client=client, train_path=train_path, val_path=val_path)
 
         training_data = Input(type=AssetTypes.MLTABLE, path=train_path)
         validation_data = Input(type=AssetTypes.MLTABLE, path=val_path)
 
+        properties = get_automl_job_properties()
+        if components:
+            properties["_automl_subgraph_orchestration"] = "true"
+            properties[
+                "_pipeline_id_override"
+            ] = "azureml://registries/azmlft-dev-registry01/components/image_object_detection_pipeline"
+
         # Make generic detection job
         image_object_detection_job = automl.image_object_detection(
             compute="gpu-cluster",
             experiment_name="image-e2e-tests",
             training_data=training_data,
             validation_data=validation_data,
             target_column_name="label",
             primary_metric="MeanAveragePrecision",
             # These are temporal properties needed in Private Preview
-            properties=get_automl_job_properties(),
+            properties=properties,
         )
 
         # Configure regular sweep job
         image_object_detection_job_sweep = copy.deepcopy(image_object_detection_job)
         image_object_detection_job_sweep.set_training_parameters(early_stopping=True, evaluation_frequency=1)
         image_object_detection_job_sweep.extend_search_space(
             [
                 SearchSpace(
                     model_name=Choice(["yolov5"]),
                     learning_rate=Uniform(0.0001, 0.01),
                     model_size=Choice(["small", "medium"]),  # model-specific
+                    number_of_epochs=Choice([1]),
                 ),
                 SearchSpace(
                     model_name=Choice(["fasterrcnn_resnet50_fpn"]),
                     learning_rate=Uniform(0.0001, 0.001),
                     optimizer=Choice(["sgd", "adam", "adamw"]),
                     min_size=Choice([600, 800]),  # model-specific
+                    number_of_epochs=Choice([1]),
                 ),
             ]
         )
         image_object_detection_job_sweep.set_limits(max_trials=1, max_concurrent_trials=1)
         image_object_detection_job_sweep.set_sweep(
             sampling_algorithm="Random",
             early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
@@ -156,18 +166,49 @@
         image_object_detection_job_automode = copy.deepcopy(image_object_detection_job)
         # TODO: after shipping the AutoMode feature, do not set flag and call `set_limits()` instead of changing
         # the limits object directly.
         image_object_detection_job_automode.properties["enable_automode"] = True
         image_object_detection_job_automode.limits.max_trials = 2
         image_object_detection_job_automode.limits.max_concurrent_trials = 2
 
+        # Configure Finetune Sweep Job
+        if components:
+            # Configure component sweep job
+            image_object_detection_job_finetune_sweep = copy.deepcopy(image_object_detection_job)
+            image_object_detection_job_finetune_sweep.set_training_parameters(
+                early_stopping=True, evaluation_frequency=1
+            )
+            image_object_detection_job_finetune_sweep.extend_search_space(
+                [
+                    SearchSpace(
+                        model_name=Choice(["atss_r50_fpn_1x_coco"]),
+                        learning_rate=Uniform(0.0001, 0.01),
+                        number_of_epochs=Choice([1]),
+                    ),
+                ]
+            )
+            image_object_detection_job_finetune_sweep.set_limits(max_trials=1, max_concurrent_trials=1)
+            image_object_detection_job_finetune_sweep.set_sweep(
+                sampling_algorithm="Random",
+                early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
+            )
+
+            # Trigger finetune sweep
+            submitted_finetune_sweep = client.jobs.create_or_update(image_object_detection_job_finetune_sweep)
+
         # Trigger regular sweep and then AutoMode job
         submitted_job_sweep = client.jobs.create_or_update(image_object_detection_job_sweep)
         submitted_job_automode = client.jobs.create_or_update(image_object_detection_job_automode)
 
+        # Assert completion of finetune sweep job
+        if components:
+            assert_final_job_status(
+                submitted_finetune_sweep, client, ImageObjectDetectionJob, JobStatus.COMPLETED, deadline=3600
+            )
+
         # Assert completion of regular sweep job
         assert_final_job_status(
             submitted_job_sweep, client, ImageObjectDetectionJob, JobStatus.COMPLETED, deadline=3600
         )
 
         # Assert completion of Automode job
         assert_final_job_status(
```

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_classification.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_classification_multilabel.py`

 * *Files 25% similar despite different names*

```diff
@@ -5,37 +5,48 @@
 from typing import Tuple
 
 import pytest
 from devtools_testutils import AzureRecordedTestCase, is_live
 from test_utilities.utils import assert_final_job_status, get_automl_job_properties
 
 from azure.ai.ml import MLClient
-from azure.ai.ml.automl import text_classification
+from azure.ai.ml.automl import text_classification_multilabel
 from azure.ai.ml.entities._inputs_outputs import Input
-from azure.ai.ml.entities._job.automl.nlp import TextClassificationJob
+from azure.ai.ml.entities._job.automl.nlp import TextClassificationMultilabelJob
 from azure.ai.ml.operations._run_history_constants import JobStatus
 
 
 @pytest.mark.automl_test
 @pytest.mark.usefixtures("recorded_test")
 @pytest.mark.skipif(condition=not is_live(), reason="Datasets downloaded by test are too large to record reliably")
-class TestTextClassification(AzureRecordedTestCase):
-    def test_remote_run_text_classification(
-        self,
-        newsgroup: Tuple[Input, Input, str],
-        client: MLClient,
+class TestTextClassificationMultilabel(AzureRecordedTestCase):
+    @pytest.mark.parametrize("components", [(False), (True)])
+    def test_remote_run_text_classification_multilabel(
+        self, paper_categorization: Tuple[Input, Input, str], client: MLClient, components: bool
     ) -> None:
-        training_data, validation_data, target_column_name = newsgroup
-        job = text_classification(
+        training_data, validation_data, target_column_name = paper_categorization
+
+        properties = get_automl_job_properties()
+        if components:
+            properties["_automl_subgraph_orchestration"] = "true"
+            properties[
+                "_pipeline_id_override"
+            ] = "azureml://registries/azmlft-dev-registry01/components/nlp_textclassification_multilabel"
+
+        job = text_classification_multilabel(
             training_data=training_data,
             validation_data=validation_data,
             target_column_name=target_column_name,
             compute="gpu-cluster",
-            experiment_name="DPv2-text-classification",
-            properties=get_automl_job_properties(),
+            experiment_name="DPv2-text-classification-multilabel",
+            properties=properties,
         )
+
+        # use component specific model name so that the test fails if components are not run
+        if components:
+            job.set_training_parameters(model_name="microsoft/deberta-base")
+
         job.set_limits(timeout_minutes=60, max_concurrent_trials=1)
-        job.set_featurization(dataset_language="eng")
 
         created_job = client.jobs.create_or_update(job)
 
-        assert_final_job_status(created_job, client, TextClassificationJob, JobStatus.COMPLETED)
+        assert_final_job_status(created_job, client, TextClassificationMultilabelJob, JobStatus.COMPLETED)
```

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_classification_multilabel.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_classification.py`

 * *Files 18% similar despite different names*

```diff
@@ -12,140 +12,163 @@
 from test_utilities.utils import assert_final_job_status, get_automl_job_properties
 
 from azure.ai.ml import MLClient, automl
 from azure.ai.ml.constants._common import AssetTypes
 from azure.ai.ml.entities import Data
 from azure.ai.ml.entities._inputs_outputs import Input
 from azure.ai.ml.entities._job.automl import SearchSpace
-from azure.ai.ml.entities._job.automl.image import ImageClassificationMultilabelJob, ImageClassificationSearchSpace
+from azure.ai.ml.entities._job.automl.image import ImageClassificationJob, ImageClassificationSearchSpace
 from azure.ai.ml.operations._run_history_constants import JobStatus
 from azure.ai.ml.sweep import BanditPolicy, Choice, Uniform
 
 
 @pytest.mark.automl_test
-@pytest.mark.usefixtures(
-    "recorded_test",
-    "mock_asset_name",
-    "mock_code_hash",
-)
+@pytest.mark.usefixtures("recorded_test")
 @pytest.mark.skipif(condition=not is_live(), reason="Datasets downloaded by test are too large to record reliably")
-class TestAutoMLImageClassificationMultilabel(AzureRecordedTestCase):
-    def _create_jsonl_multilabel(self, client: MLClient, train_path: str, val_path: str):
-        src_images = "./multilabelFridgeObjects/"
-
+class TestAutoMLImageClassification(AzureRecordedTestCase):
+    def _create_jsonl_multiclass(self, client, train_path, val_path):
+        src_images = "./fridgeObjects/"
         train_validation_ratio = 5
 
         # Path to the training and validation files
         train_annotations_file = os.path.join(train_path, "train_annotations.jsonl")
         validation_annotations_file = os.path.join(val_path, "validation_annotations.jsonl")
 
-        multilabel_data = Data(path="./multilabelFridgeObjects", type=AssetTypes.URI_FOLDER)
-        uri_folder_data_asset = client.data.create_or_update(multilabel_data)
+        fridge_data = Data(
+            path="./fridgeObjects",
+            type=AssetTypes.URI_FOLDER,
+        )
+        data_path_uri = client.data.create_or_update(fridge_data)
 
         # Baseline of json line dictionary
         json_line_sample = {
-            "image_url": uri_folder_data_asset.path,
-            "label": [],
+            "image_url": data_path_uri.path,
+            "label": "",
         }
 
-        # Path to the labels file.
-        labelFile = os.path.join(src_images, "labels.csv")
-
-        # Read each annotation and convert it to jsonl line
+        index = 0
+        # Scan each sub directary and generate a jsonl line per image, distributed on train and valid JSONL files
         with open(train_annotations_file, "w") as train_f:
             with open(validation_annotations_file, "w") as validation_f:
-                with open(labelFile, "r") as labels:
-                    for i, line in enumerate(labels):
-                        # Skipping the title line and any empty lines.
-                        if i == 0 or len(line.strip()) == 0:
-                            continue
-                        line_split = line.strip().split(",")
-                        if len(line_split) != 2:
-                            print("Skipping the invalid line: {}".format(line))
-                            continue
+                for className in os.listdir(src_images):
+                    subDir = src_images + className
+                    if not os.path.isdir(subDir):
+                        continue
+                    # Scan each sub directary
+                    print("Parsing " + subDir)
+                    for image in os.listdir(subDir):
                         json_line = dict(json_line_sample)
-                        json_line["image_url"] += f"images/{line_split[0]}"
-                        json_line["label"] = line_split[1].strip().split(" ")
+                        json_line["image_url"] += f"{className}/{image}"
+                        json_line["label"] = className
 
-                        if i % train_validation_ratio == 0:
+                        if index % train_validation_ratio == 0:
                             # validation annotation
                             validation_f.write(json.dumps(json_line) + "\n")
                         else:
                             # train annotation
                             train_f.write(json.dumps(json_line) + "\n")
+                        index += 1
 
-    def test_image_classification_multilabel_run(
-        self, image_classification_multilabel_dataset: Tuple[Input, Input], client: MLClient
+    @pytest.mark.parametrize("components", [(False), (True)])
+    def test_image_classification_multiclass_run(
+        self, image_classification_dataset: Tuple[Input, Input], client: MLClient, components: bool
     ) -> None:
         # Note: this test launches two jobs in order to avoid calling the dataset fixture more than once. Ideally, it
         # would have sufficed to mark the fixture with session scope, but pytest-xdist breaks this functionality:
         # https://github.com/pytest-dev/pytest-xdist/issues/271.
 
         # Get training and validation data paths
-        train_path, val_path = image_classification_multilabel_dataset
+        train_path, val_path = image_classification_dataset
 
         # Create jsonl file
-        self._create_jsonl_multilabel(client=client, train_path=train_path, val_path=val_path)
+        self._create_jsonl_multiclass(client=client, train_path=train_path, val_path=val_path)
 
         training_data = Input(type=AssetTypes.MLTABLE, path=train_path)
         validation_data = Input(type=AssetTypes.MLTABLE, path=val_path)
 
-        # Make generic multilabel classification job
-        image_classification_multilabel_job = automl.image_classification_multilabel(
-            compute="gpu-cluster",
-            experiment_name="image-e2e-tests",
+        properties = get_automl_job_properties()
+        if components:
+            properties["_automl_subgraph_orchestration"] = "true"
+            properties[
+                "_pipeline_id_override"
+            ] = "azureml://registries/azmlft-dev-registry01/components/image_classification_pipeline"
+
+        # Make generic classification job
+        image_classification_job = automl.image_classification(
             training_data=training_data,
-            validation_data=validation_data,
             target_column_name="label",
-            primary_metric="iou",
-            # These are temporal properties needed in Private Preview
-            properties=get_automl_job_properties(),
+            validation_data=validation_data,
+            primary_metric="accuracy",
+            compute="gpu-cluster",
+            experiment_name="image-e2e-tests",
+            properties=properties,
         )
 
         # Configure regular sweep job
-        image_classification_multilabel_job_sweep = copy.deepcopy(image_classification_multilabel_job)
-        image_classification_multilabel_job_sweep.set_training_parameters(early_stopping=True, evaluation_frequency=1)
-        image_classification_multilabel_job_sweep.extend_search_space(
+        image_classification_job_sweep = copy.deepcopy(image_classification_job)
+        image_classification_job_sweep.set_training_parameters(early_stopping=True, evaluation_frequency=1)
+        image_classification_job_sweep.extend_search_space(
             [
                 SearchSpace(
                     model_name=Choice(["vitb16r224"]),
-                    learning_rate=Uniform(0.005, 0.05),
-                    number_of_epochs=Choice([15, 30]),
-                    gradient_accumulation_step=Choice([1, 2]),
+                    learning_rate=Uniform(0.001, 0.01),
+                    number_of_epochs=Choice([1]),
                 ),
                 SearchSpace(
                     model_name=Choice(["seresnext"]),
-                    learning_rate=Uniform(0.005, 0.05),
-                    # model-specific, valid_resize_size should be larger or equal than valid_crop_size
-                    validation_resize_size=Choice([288, 320, 352]),
-                    validation_crop_size=Choice([224, 256]),  # model-specific
-                    training_crop_size=Choice([224, 256]),  # model-specific
+                    layers_to_freeze=Choice([0, 2]),
+                    number_of_epochs=Choice([1]),
                 ),
             ]
         )
-        image_classification_multilabel_job_sweep.set_limits(max_trials=1, max_concurrent_trials=1)
-        image_classification_multilabel_job_sweep.set_sweep(
+        image_classification_job_sweep.set_limits(max_trials=1, max_concurrent_trials=1)
+        image_classification_job_sweep.set_sweep(
             sampling_algorithm="Random",
             early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
         )
 
         # Configure AutoMode job
-        image_classification_multilabel_job_automode = copy.deepcopy(image_classification_multilabel_job)
+        image_classification_job_automode = copy.deepcopy(image_classification_job)
         # TODO: after shipping the AutoMode feature, do not set flag and call `set_limits()` instead of changing
         # the limits object directly.
-        image_classification_multilabel_job_automode.properties["enable_automode"] = True
-        image_classification_multilabel_job_automode.limits.max_trials = 2
-        image_classification_multilabel_job_automode.limits.max_concurrent_trials = 2
+        image_classification_job_automode.properties["enable_automode"] = True
+        image_classification_job_automode.limits.max_trials = 2
+        image_classification_job_automode.limits.max_concurrent_trials = 2
+
+        # Configure Finetune Sweep Job
+        if components:
+            image_classification_job_finetune_sweep = copy.deepcopy(image_classification_job)
+            image_classification_job_finetune_sweep.set_training_parameters(early_stopping=True, evaluation_frequency=1)
+            image_classification_job_finetune_sweep.extend_search_space(
+                [
+                    SearchSpace(
+                        model_name=Choice(["microsoft/beit-base-patch16-224"]),
+                        learning_rate=Uniform(0.001, 0.01),
+                        number_of_epochs=Choice([1]),
+                    ),
+                ]
+            )
+            image_classification_job_finetune_sweep.set_limits(max_trials=1, max_concurrent_trials=1)
+            image_classification_job_finetune_sweep.set_sweep(
+                sampling_algorithm="Random",
+                early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
+            )
+            # Trigger finetune sweep
+            submitted_finetune_sweep = client.jobs.create_or_update(image_classification_job_finetune_sweep)
 
         # Trigger regular sweep and then AutoMode job
-        submitted_job_sweep = client.jobs.create_or_update(image_classification_multilabel_job_sweep)
-        submitted_job_automode = client.jobs.create_or_update(image_classification_multilabel_job_automode)
+        submitted_job_sweep = client.jobs.create_or_update(image_classification_job_sweep)
+        submitted_job_automode = client.jobs.create_or_update(image_classification_job_automode)
+
+        # Assert completion of finetune sweep job
+        if components:
+            assert_final_job_status(
+                submitted_finetune_sweep, client, ImageClassificationJob, JobStatus.COMPLETED, deadline=3600
+            )
 
         # Assert completion of regular sweep job
-        assert_final_job_status(
-            submitted_job_sweep, client, ImageClassificationMultilabelJob, JobStatus.COMPLETED, deadline=3600
-        )
+        assert_final_job_status(submitted_job_sweep, client, ImageClassificationJob, JobStatus.COMPLETED, deadline=3600)
 
         # Assert completion of Automode job
         assert_final_job_status(
-            submitted_job_automode, client, ImageClassificationMultilabelJob, JobStatus.COMPLETED, deadline=3600
+            submitted_job_automode, client, ImageClassificationJob, JobStatus.COMPLETED, deadline=3600
         )
```

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_automl_image_segmentation.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_automl_image_segmentation.py`

 * *Files 18% similar despite different names*

```diff
@@ -57,49 +57,60 @@
                 old_url = json_line["image_url"]
                 result = old_url.find(data_path)
 
                 # Update image url
                 json_line["image_url"] = remote_path + old_url[result + len(data_path) :]
                 jsonl_file_write.write(json.dumps(json_line) + "\n")
 
-    def test_image_segmentation_run(self, image_segmentation_dataset: Tuple[Input, Input], client: MLClient) -> None:
+    @pytest.mark.parametrize("components", [(False), (True)])
+    def test_image_segmentation_run(
+        self, image_segmentation_dataset: Tuple[Input, Input], client: MLClient, components: bool
+    ) -> None:
         # Note: this test launches two jobs in order to avoid calling the dataset fixture more than once. Ideally, it
         # would have sufficed to mark the fixture with session scope, but pytest-xdist breaks this functionality:
         # https://github.com/pytest-dev/pytest-xdist/issues/271.
 
         # Get training and validation data
         train_path, val_path = image_segmentation_dataset
 
         # Create jsonl file
         self._create_jsonl_segmentation(client=client, train_path=train_path, val_path=val_path)
 
         training_data = Input(type=AssetTypes.MLTABLE, path=train_path)
         validation_data = Input(type=AssetTypes.MLTABLE, path=val_path)
 
+        properties = get_automl_job_properties()
+        if components:
+            properties["_automl_subgraph_orchestration"] = "true"
+            properties[
+                "_pipeline_id_override"
+            ] = "azureml://registries/azmlft-dev-registry01/components/image_instance_segmentation_pipeline"
+
         # Make generic segmentation job
         image_instance_segmentation_job = automl.image_instance_segmentation(
             compute="gpu-cluster",
             experiment_name="image-e2e-tests",
             training_data=training_data,
             validation_data=validation_data,
             target_column_name="label",
             primary_metric="MeanAveragePrecision",
-            properties=get_automl_job_properties(),
+            properties=properties,
         )
 
         # Configure regular sweep job
         image_instance_segmentation_job_sweep = copy.deepcopy(image_instance_segmentation_job)
         image_instance_segmentation_job_sweep.set_training_parameters(early_stopping=True, evaluation_frequency=1)
         image_instance_segmentation_job_sweep.extend_search_space(
             [
                 SearchSpace(
                     model_name=Choice(["maskrcnn_resnet50_fpn"]),
                     learning_rate=Uniform(0.0001, 0.001),
                     optimizer=Choice(["sgd", "adam", "adamw"]),
                     min_size=Choice([600, 800]),
+                    number_of_epochs=Choice([1]),
                 ),
             ]
         )
         image_instance_segmentation_job_sweep.set_limits(max_trials=1, max_concurrent_trials=1)
         image_instance_segmentation_job_sweep.set_sweep(
             sampling_algorithm="Random",
             early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
@@ -109,18 +120,48 @@
         image_instance_segmentation_job_automode = copy.deepcopy(image_instance_segmentation_job)
         # TODO: after shipping the AutoMode feature, do not set flag and call `set_limits()` instead of changing
         # the limits object directly.
         image_instance_segmentation_job_automode.properties["enable_automode"] = True
         image_instance_segmentation_job_automode.limits.max_trials = 2
         image_instance_segmentation_job_automode.limits.max_concurrent_trials = 2
 
+        # Configure Finetune Sweep Job
+        if components:
+            image_instance_segmentation_job_finetune_sweep = copy.deepcopy(image_instance_segmentation_job)
+            image_instance_segmentation_job_finetune_sweep.set_training_parameters(
+                early_stopping=True, evaluation_frequency=1
+            )
+            image_instance_segmentation_job_finetune_sweep.extend_search_space(
+                [
+                    SearchSpace(
+                        model_name=Choice(["mask_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco"]),
+                        learning_rate=Uniform(0.0001, 0.001),
+                        optimizer=Choice(["sgd", "adamw_hf", "adamw"]),
+                        number_of_epochs=Choice([1]),
+                    ),
+                ]
+            )
+            image_instance_segmentation_job_finetune_sweep.set_limits(max_trials=1, max_concurrent_trials=1)
+            image_instance_segmentation_job_finetune_sweep.set_sweep(
+                sampling_algorithm="Random",
+                early_termination=BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=6),
+            )
+            # Trigger finetune sweep
+            submitted_finetune_sweep = client.jobs.create_or_update(image_instance_segmentation_job_finetune_sweep)
+
         # Trigger regular sweep and then AutoMode job
         submitted_job_sweep = client.jobs.create_or_update(image_instance_segmentation_job_sweep)
         submitted_job_automode = client.jobs.create_or_update(image_instance_segmentation_job_automode)
 
+        # Assert completion of finetune sweep job
+        if components:
+            assert_final_job_status(
+                submitted_finetune_sweep, client, ImageInstanceSegmentationJob, JobStatus.COMPLETED, deadline=3600
+            )
+
         # Assert completion of regular sweep job
         assert_final_job_status(
             submitted_job_sweep, client, ImageInstanceSegmentationJob, JobStatus.COMPLETED, deadline=3600
         )
 
         # Assert completion of Automode job
         assert_final_job_status(
```

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_text_ner.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_text_ner.py`

 * *Files 16% similar despite different names*

```diff
@@ -15,25 +15,35 @@
 from azure.ai.ml.operations._run_history_constants import JobStatus
 
 
 @pytest.mark.automl_test
 @pytest.mark.usefixtures("recorded_test")
 @pytest.mark.skipif(condition=not is_live(), reason="Datasets downloaded by test are too large to record reliably")
 class TestTextNer(AzureRecordedTestCase):
-    def test_remote_run_text_ner(
-        self,
-        conll: Tuple[Input, Input],
-        client: MLClient,
-    ) -> None:
+    @pytest.mark.parametrize("components", [(False), (True)])
+    def test_remote_run_text_ner(self, conll: Tuple[Input, Input], client: MLClient, components: bool) -> None:
         training_data, validation_data = conll
+
+        properties = get_automl_job_properties()
+        if components:
+            properties["_automl_subgraph_orchestration"] = "true"
+            properties[
+                "_pipeline_id_override"
+            ] = "azureml://registries/azmlft-dev-registry01/components/nlp_textclassification_ner"
+
         job = text_ner(
             training_data=training_data,
             validation_data=validation_data,
             compute="gpu-cluster",
             experiment_name="DPv2-text-ner",
-            properties=get_automl_job_properties(),
+            properties=properties,
         )
+
+        # use component specific model name so that the test fails if components are not run
+        if components:
+            job.set_training_parameters(model_name="microsoft/deberta-base")
+
         job.set_limits(timeout_minutes=60, max_concurrent_trials=1)
 
         created_job = client.jobs.create_or_update(job)
 
         assert_final_job_status(created_job, client, TextNerJob, JobStatus.COMPLETED)
```

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_classification.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_classification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_regression.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_regression.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/e2etests/test_remote_forecasting.py` & `azure-ai-ml-1.9.0/tests/automl_job/e2etests/test_remote_forecasting.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_regression_job.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_regression_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_forecasting_job.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_forecasting_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_classification_job.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_classification_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_object_detection.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_object_detection.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_tabular_schema.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_tabular_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_limit_settings.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_limit_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_schema.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_n_cross_validation_settings.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_n_cross_validation_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_classification_multilabel.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_classification_multilabel.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_tabular_featurization_settings.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_tabular_featurization_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_nlp_sweep_settings.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_nlp_sweep_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_classification.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_classification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_ner_job.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_ner_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_sweep_setting.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_sweep_setting.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_image_instance_segmentation.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_image_instance_segmentation.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_automl_nlp_schema.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_automl_nlp_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_classification_multilabel_job.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_classification_multilabel_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_setsearchspace.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_setsearchspace.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_forecasting_settings.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_forecasting_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/tests/automl_job/unittests/test_text_classification_job.py` & `azure-ai-ml-1.9.0/tests/automl_job/unittests/test_text_classification_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure_ai_ml.egg-info/PKG-INFO` & `azure-ai-ml-1.9.0/azure_ai_ml.egg-info/PKG-INFO`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: azure-ai-ml
-Version: 1.8.0
+Version: 1.9.0
 Summary: Microsoft Azure Machine Learning Client Library for Python
 Home-page: https://github.com/Azure/azure-sdk-for-python
 Author: Microsoft Corporation
 Author-email: azuresdkengsysadmins@microsoft.com
 License: MIT License
 Project-URL: Bug Reports, https://github.com/Azure/azure-sdk-for-python/issues
 Project-URL: Source, https://github.com/Azure/azure-sdk-python
@@ -164,25 +164,39 @@
 [code_of_conduct]: https://opensource.microsoft.com/codeofconduct/
 [coc_faq]: https://opensource.microsoft.com/codeofconduct/faq/
 [coc_contact]: mailto:opencode@microsoft.com
 
 
 # Release History
 
+## 1.9.0 (2023-07-25)
+### Features Added
+- Added support to enable gpu access (local_enable_gpu) for local deployment.
+
+### Other Changes
+- Improved the output when printing a workspace object to be more clean and readable.
+- Log level of unknown field notifications for pipeline nodes raised from INFO to WARNING.
+
 ## 1.8.0 (2023-06-12)
 
 ### Features Added
 - Added support to enable set workspace connection secret expiry time.
 - Added support for `stage` on model version
+- Added support to enable gpu access (local_enable_gpu) for local deployment.
 
 ### Bugs Fixed
 
 - Fixed an issue affecting authentication to registry-related services in sovereign regions.
 - Made job_tier and priority values case insensitive
 
+### Breaking Changes
+
+### Other Changes
+- Log level of unknown field notifications for pipeline nodes raised from INFO to WARNING.
+
 
 ## 1.7.2 (2023-05-18)
 
 ### Features Added
 - Public preview support for new schedule type `MonitorSchedule`
```

## Comparing `azure-ai-ml-1.8.0/azure_ai_ml.egg-info/SOURCES.txt` & `azure-ai-ml-1.9.0/azure_ai_ml.egg-info/SOURCES.txt`

 * *Files 2% similar despite different names*

```diff
@@ -968,14 +968,122 @@
 azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_versions_operations.py
 azure/ai/ml/_restclient/v2023_04_01_preview/operations/_schedules_operations.py
 azure/ai/ml/_restclient/v2023_04_01_preview/operations/_usages_operations.py
 azure/ai/ml/_restclient/v2023_04_01_preview/operations/_virtual_machine_sizes_operations.py
 azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_connections_operations.py
 azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_features_operations.py
 azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspaces_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/__init__.py
+azure/ai/ml/_restclient/v2023_06_01_preview/_azure_machine_learning_workspaces.py
+azure/ai/ml/_restclient/v2023_06_01_preview/_configuration.py
+azure/ai/ml/_restclient/v2023_06_01_preview/_patch.py
+azure/ai/ml/_restclient/v2023_06_01_preview/_vendor.py
+azure/ai/ml/_restclient/v2023_06_01_preview/_version.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/__init__.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/_azure_machine_learning_workspaces.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/_configuration.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/_patch.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/__init__.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_batch_deployments_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_batch_endpoints_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_code_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_code_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_component_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_component_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_compute_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_data_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_data_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_datastores_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_environment_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_environment_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_features_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featureset_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featureset_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featurestore_entity_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_featurestore_entity_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_jobs_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_labeling_jobs_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_managed_network_provisions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_managed_network_settings_rule_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_model_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_model_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_online_deployments_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_online_endpoints_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_private_endpoint_connections_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_private_link_resources_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_quotas_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registries_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_code_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_code_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_component_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_component_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_data_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_data_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_environment_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_environment_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_model_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_model_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_schedules_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_usages_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_virtual_machine_sizes_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspace_connections_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspace_features_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_workspaces_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/models/__init__.py
+azure/ai/ml/_restclient/v2023_06_01_preview/models/_azure_machine_learning_workspaces_enums.py
+azure/ai/ml/_restclient/v2023_06_01_preview/models/_models.py
+azure/ai/ml/_restclient/v2023_06_01_preview/models/_models_py3.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/__init__.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_batch_deployments_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_batch_endpoints_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_code_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_code_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_component_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_component_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_compute_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_data_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_data_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_datastores_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_environment_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_environment_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_features_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featureset_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featureset_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featurestore_entity_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_featurestore_entity_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_jobs_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_labeling_jobs_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_managed_network_provisions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_managed_network_settings_rule_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_model_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_model_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_online_deployments_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_online_endpoints_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_private_endpoint_connections_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_private_link_resources_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_quotas_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registries_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_code_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_code_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_component_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_component_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_data_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_data_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_environment_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_environment_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_model_containers_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_model_versions_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_schedules_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_usages_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_virtual_machine_sizes_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspace_connections_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspace_features_operations.py
+azure/ai/ml/_restclient/v2023_06_01_preview/operations/_workspaces_operations.py
 azure/ai/ml/_schema/__init__.py
 azure/ai/ml/_schema/identity.py
 azure/ai/ml/_schema/job_resource_configuration.py
 azure/ai/ml/_schema/queue_settings.py
 azure/ai/ml/_schema/resource_configuration.py
 azure/ai/ml/_schema/spark_resource_configuration.py
 azure/ai/ml/_schema/_data/__init__.py
@@ -1204,14 +1312,15 @@
 azure/ai/ml/_telemetry/__init__.py
 azure/ai/ml/_telemetry/_customtraceback.py
 azure/ai/ml/_telemetry/activity.py
 azure/ai/ml/_telemetry/logging_handler.py
 azure/ai/ml/_utils/__init__.py
 azure/ai/ml/_utils/_appinsights_utils.py
 azure/ai/ml/_utils/_arm_id_utils.py
+azure/ai/ml/_utils/_artifact_utils.py
 azure/ai/ml/_utils/_asset_utils.py
 azure/ai/ml/_utils/_azureml_polling.py
 azure/ai/ml/_utils/_cache_utils.py
 azure/ai/ml/_utils/_data_utils.py
 azure/ai/ml/_utils/_endpoint_utils.py
 azure/ai/ml/_utils/_experimental.py
 azure/ai/ml/_utils/_feature_store_utils.py
@@ -1357,15 +1466,14 @@
 azure/ai/ml/entities/_builders/pipeline.py
 azure/ai/ml/entities/_builders/spark.py
 azure/ai/ml/entities/_builders/spark_func.py
 azure/ai/ml/entities/_builders/subcomponents.py
 azure/ai/ml/entities/_builders/sweep.py
 azure/ai/ml/entities/_component/__init__.py
 azure/ai/ml/entities/_component/_additional_includes.py
-azure/ai/ml/entities/_component/_artifact_cache.py
 azure/ai/ml/entities/_component/automl_component.py
 azure/ai/ml/entities/_component/code.py
 azure/ai/ml/entities/_component/command_component.py
 azure/ai/ml/entities/_component/component.py
 azure/ai/ml/entities/_component/component_factory.py
 azure/ai/ml/entities/_component/datatransfer_component.py
 azure/ai/ml/entities/_component/import_component.py
@@ -1637,14 +1745,16 @@
 azure_ai_ml.egg-info/dependency_links.txt
 azure_ai_ml.egg-info/not-zip-safe
 azure_ai_ml.egg-info/requires.txt
 azure_ai_ml.egg-info/top_level.txt
 samples/README.md
 samples/ml_samples_authentication_sovereign_cloud.py
 samples/ml_samples_cloud_configurations.py
+samples/ml_samples_command_configurations.py
+samples/ml_samples_spark_configurations.py
 samples/ml_samples_sweep_configurations.py
 tests/conftest.py
 tests/automl_job/__init__.py
 tests/automl_job/conftest.py
 tests/automl_job/jsonl_converter.py
 tests/automl_job/e2etests/__init__.py
 tests/automl_job/e2etests/test_automl_image_classification.py
@@ -1706,14 +1816,15 @@
 tests/command_job/unittests/test_command_job_schema.py
 tests/component/__init__.py
 tests/component/_util.py
 tests/component/e2etests/__init__.py
 tests/component/e2etests/test_component.py
 tests/component/e2etests/test_component_hash.py
 tests/component/e2etests/test_component_validate.py
+tests/component/e2etests/test_component_without_mock.py
 tests/component/unittests/__init__.py
 tests/component/unittests/test_automl_component.py
 tests/component/unittests/test_command_component_entity.py
 tests/component/unittests/test_component_operations.py
 tests/component/unittests/test_component_operations_registry.py
 tests/component/unittests/test_component_schema.py
 tests/component/unittests/test_component_validate.py
@@ -1941,14 +2052,16 @@
 tests/test_configs/deployments/endpoint_scoring/do_nothing.py
 tests/test_configs/deployments/endpoint_scoring/main.py
 tests/test_configs/deployments/mnist/code/digit_identification.py
 tests/test_configs/deployments/model-1/onlinescoring/score.py
 tests/test_configs/deployments/model-2/onlinescoring/score.py
 tests/test_configs/deployments/model-3/score.py
 tests/test_configs/deployments/model-4/onlinescoring/cloud_score.py
+tests/test_configs/deployments/model-5/onlinescoring/score.py
+tests/test_configs/deployments/model-5/onlinescoring/score_managedidentity.py
 tests/test_configs/dsl_pipeline/automl_job_in_pipeline/pipeline.py
 tests/test_configs/dsl_pipeline/basic_component/pipeline.py
 tests/test_configs/dsl_pipeline/basic_component/src/hello.py
 tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/pipeline.py
 tests/test_configs/dsl_pipeline/basic_component_with_component_in_folder/components/src/hello.py
 tests/test_configs/dsl_pipeline/basic_pipeline/pipeline.py
 tests/test_configs/dsl_pipeline/basic_pipeline/componentA_src/hello.py
```

## Comparing `azure-ai-ml-1.8.0/samples/README.md` & `azure-ai-ml-1.9.0/samples/README.md`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/samples/ml_samples_sweep_configurations.py` & `azure-ai-ml-1.9.0/samples/ml_samples_sweep_configurations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/samples/ml_samples_authentication_sovereign_cloud.py` & `azure-ai-ml-1.9.0/samples/ml_samples_authentication_sovereign_cloud.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/samples/ml_samples_cloud_configurations.py` & `azure-ai-ml-1.9.0/samples/ml_samples_cloud_configurations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/__init__.py` & `azure-ai-ml-1.9.0/azure/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,31 +11,31 @@
 
 from ._ml_client import MLClient
 from ._utils._logger_utils import initialize_logger_info
 from ._version import VERSION
 from .entities._builders.command_func import command
 from .entities._builders.spark_func import spark
 from .entities._credentials import AmlTokenConfiguration, ManagedIdentityConfiguration, UserIdentityConfiguration
-from .entities._job.distribution import MpiDistribution, PyTorchDistribution, TensorFlowDistribution, RayDistribution
+from .entities._job.distribution import MpiDistribution, PyTorchDistribution, RayDistribution, TensorFlowDistribution
 from .entities._load_functions import (
     load_batch_deployment,
     load_batch_endpoint,
     load_component,
     load_compute,
     load_data,
     load_datastore,
     load_environment,
     load_job,
     load_model,
+    load_model_package,
     load_online_deployment,
     load_online_endpoint,
     load_registry,
     load_workspace,
     load_workspace_connection,
-    load_model_package,
 )
 
 module_logger = logging.getLogger(__name__)
 initialize_logger_info(module_logger, terminator="\n")
 
 __all__ = [
     "MLClient",
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_exception_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_exception_helper.py`

 * *Files 0% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 
 
 def _find_deepest_dictionary(data):
     """
     Find deepest dictionary in nested dictionary.
     Used here to get nested error message. Can't be in utils.py due to circular import.
     """
-    if not any([isinstance(data.get(key), dict) for key in data]):
+    if not any(isinstance(data.get(key), dict) for key in data):
         return data
     for key in data:
         if isinstance(data.get(key), dict):
             return _find_deepest_dictionary(data.get(key))
 
 
 def get_entity_type(error: Union[SchemaValidationError, ValidationException]) -> Tuple[str, str]:
@@ -45,15 +45,15 @@
             entity_type = ErrorTarget.DATA
         elif "ModelSchema" in error_name:
             entity_type = ErrorTarget.MODEL
         elif "EnvironmentSchema" in error_name:
             entity_type = ErrorTarget.ENVIRONMENT
         elif "CodeAssetSchema" in error_name:
             entity_type = ErrorTarget.CODE
-        elif any([x in error_name for x in DATASTORE_SCHEMA_TYPES]):
+        elif any(x in error_name for x in DATASTORE_SCHEMA_TYPES):
             entity_type = ErrorTarget.DATASTORE
         elif "BaseJobSchema" in error_name:
             entity_type = ErrorTarget.JOB
         elif "CommandSchema" in error_name:
             entity_type = ErrorTarget.COMMAND_JOB
         elif "CommandJobSchema" in error_name:
             entity_type = ErrorTarget.COMMAND_JOB
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_scope_dependent_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_scope_dependent_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_ml_client.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_ml_client.py`

 * *Files 0% similar despite different names*

```diff
@@ -839,15 +839,15 @@
     def _get_workspace_info(cls, found_path: Optional[str]) -> Tuple[str, str, str]:
         with open(found_path) as config_file:
             config = json.load(config_file)
 
         # Checking the keys in the config.json file to check for required parameters.
         scope = config.get("Scope")
         if not scope:
-            if not all([k in config.keys() for k in ("subscription_id", "resource_group", "workspace_name")]):
+            if not all(k in config.keys() for k in ("subscription_id", "resource_group", "workspace_name")):
                 msg = (
                     "The config file found in: {} does not seem to contain the required "
                     "parameters. Please make sure it contains your subscription_id, "
                     "resource_group and workspace_name."
                 )
                 raise ValidationException(
                     message=msg.format(found_path),
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_azure_environments.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_azure_environments.py`

 * *Files 1% similar despite different names*

```diff
@@ -70,16 +70,16 @@
         return _environments[cloud]
     arm_url = os.environ.get(ArmConstants.METADATA_URL_ENV_NAME, ArmConstants.DEFAULT_URL)
     arm_clouds = _get_clouds_by_metadata_url(arm_url)
     try:
         new_cloud = arm_clouds[cloud]
         _environments.update(new_cloud)
         return new_cloud
-    except KeyError:
-        raise Exception('Unknown cloud environment "{0}".'.format(cloud))
+    except KeyError as e:
+        raise Exception('Unknown cloud environment "{0}".'.format(cloud)) from e
 
 
 def _get_default_cloud_name():
     """Return AzureCloud as the default cloud."""
     return os.getenv(AZUREML_CLOUD_ENV_NAME, AzureEnvironments.ENV_DEFAULT)
 
 
@@ -102,16 +102,16 @@
     """Sets the current cloud.
 
     :param cloud: cloud name
     """
     if cloud is not None:
         try:
             _get_cloud(cloud)
-        except Exception:
-            raise Exception('Unknown cloud environment supplied: "{0}".'.format(cloud))
+        except Exception as e:
+            raise Exception('Unknown cloud environment supplied: "{0}".'.format(cloud)) from e
     else:
         cloud = _get_default_cloud_name()
     os.environ[AZUREML_CLOUD_ENV_NAME] = cloud
 
 
 def _get_base_url_from_metadata(cloud_name: Optional[str] = None, is_local_mfe: bool = False):
     """Retrieve the base url for a cloud from the metadata in SDK.
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/exceptions.py` & `azure-ai-ml-1.9.0/azure/ai/ml/exceptions.py`

 * *Files 1% similar despite different names*

```diff
@@ -815,7 +815,19 @@
                 "'code' is installed and accessible from PATH environment variable. "
                 "See https://code.visualstudio.com/docs/editor/command-line#_common-questions.\n"
             ),
             target=ErrorTarget.LOCAL_ENDPOINT,
             no_personal_data_message="Could not start VSCode instance.",
             error_category=error_category,
         )
+
+
+class LocalDeploymentGPUNotAvailable(MlException):
+    """Exception raised when local_enable_gpu is set and Nvidia GPU is not available."""
+
+    def __init__(self, error_category=ErrorCategory.USER_ERROR, msg=None):
+        super().__init__(
+            message=msg,
+            target=ErrorTarget.LOCAL_ENDPOINT,
+            no_personal_data_message=msg,
+            error_category=error_category,
+        )
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_helper.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_deployment_executor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_deployment_executor.py`

 * *Files 0% similar despite different names*

```diff
@@ -184,15 +184,15 @@
             if (
                 properties.provisioning_state
                 and (not self._lock or self._lock == target_resource.resource_name)
                 and target_resource.resource_name not in self._printed_set
             ):
                 status_in_resource_dict = self._resources_being_deployed[target_resource.resource_name][1]
                 module_logger.debug(
-                    ("\n LOCK STATUS :  %s,  " "Status in the resources dict : %s ,  " "Already in printed set: %s\n"),
+                    ("\n LOCK STATUS :  %s,  Status in the resources dict : %s ,  Already in printed set: %s\n"),
                     self._lock,
                     status_in_resource_dict,
                     self._printed_set,
                 )
                 module_logger.debug("Locking with the deployment : %s\n\n", target_resource.resource_name)
                 self._lock = target_resource.resource_name
                 provisioning_state = properties.provisioning_state
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_base.json` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_base.json`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/online_deployment.json` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/online_deployment.json`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_param.json` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/workspace_param.json`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/online_endpoint.json` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/online_endpoint.json`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/update_online_endpoint.json` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/update_online_endpoint.json`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_arm_deployments/arm_templates/environment_version.json` & `azure-ai-ml-1.9.0/azure/ai/ml/_arm_deployments/arm_templates/environment_version.json`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_package_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_package_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,22 +8,23 @@
 import hashlib
 import json
 import logging
 import os
 import random
 import re
 import string
+import tempfile
 import time
 import warnings
 from collections import OrderedDict
-from contextlib import contextmanager
+from contextlib import contextmanager, nullcontext
 from datetime import timedelta
 from functools import singledispatch, wraps
 from os import PathLike
-from pathlib import PosixPath, PureWindowsPath
+from pathlib import Path, PosixPath, PureWindowsPath
 from typing import IO, Any, AnyStr, Callable, Dict, List, Optional, Tuple, Union
 from urllib.parse import urlparse
 from uuid import UUID
 
 import isodate
 import pydash
 import yaml
@@ -165,15 +166,15 @@
     Returns:
         str: the Response text
     """
     if not timeout:
         timeout_params = {}
     else:
         connect_timeout, read_timeout = timeout if isinstance(timeout, tuple) else (timeout, timeout)
-        timeout_params = dict(read_timeout=read_timeout, connection_timeout=connect_timeout)
+        timeout_params = {"read_timeout": read_timeout, "connection_timeout": connect_timeout}
 
     response = requests_pipeline.get(source_uri, **timeout_params)
     # Match old behavior from execution service's status API.
     if response.status_code == 404:
         return ""
 
     # _raise_request_error(response, "Retrieving content from " + uri)
@@ -193,23 +194,23 @@
 
     # These imports can't be placed in at top file level because it will cause a circular import in
     # exceptions.py via _get_mfe_url_override
 
     try:
         with open(file_path, "r") as f:
             cfg = f.read()
-    except OSError:  # FileNotFoundError introduced in Python 3
+    except OSError as e:  # FileNotFoundError introduced in Python 3
         msg = "No such file or directory: {}"
         raise ValidationException(
             message=msg.format(file_path),
             no_personal_data_message=msg.format("[file_path]"),
             error_category=ErrorCategory.USER_ERROR,
             target=ErrorTarget.GENERAL,
             error_type=ValidationErrorType.FILE_OR_FOLDER_NOT_FOUND,
-        )
+        ) from e
     return cfg
 
 
 def load_json(file_path: Optional[Union[str, os.PathLike]]) -> Dict:
     """Load a local json file.
 
     :param file_path: The relative or absolute path to the local file.
@@ -222,23 +223,23 @@
 
     # These imports can't be placed in at top file level because it will cause a circular import in
     # exceptions.py via _get_mfe_url_override
 
     try:
         with open(file_path, "r") as f:
             cfg = json.load(f)
-    except OSError:  # FileNotFoundError introduced in Python 3
+    except OSError as e:  # FileNotFoundError introduced in Python 3
         msg = "No such file or directory: {}"
         raise ValidationException(
             message=msg.format(file_path),
             no_personal_data_message=msg.format("[file_path]"),
             error_category=ErrorCategory.USER_ERROR,
             target=ErrorTarget.GENERAL,
             error_type=ValidationErrorType.FILE_OR_FOLDER_NOT_FOUND,
-        )
+        ) from e
     return cfg
 
 
 def load_yaml(source: Optional[Union[AnyStr, PathLike, IO]]) -> Dict:
     # null check - just return an empty dict.
     # Certain CLI commands rely on this behavior to produce a resource
     # via CLI, which is then populated through CLArgs.
@@ -255,63 +256,52 @@
 
     # These imports can't be placed in at top file level because it will cause a circular import in
     # exceptions.py via _get_mfe_url_override
 
     if source is None:
         return {}
 
-    # pylint: disable=redefined-builtin
-    input = None  # type: IOBase
-    must_open_file = False
-    try:  # check source type by duck-typing it as an IOBase
-        readable = source.readable()
-        if not readable:  # source is misformatted stream or file
+    if isinstance(source, (str, os.PathLike)):
+        try:
+            cm = open(source, "r")
+        except OSError as e:
+            msg = "No such file or directory: {}"
+            raise ValidationException(
+                message=msg.format(source),
+                no_personal_data_message=msg.format("[file_path]"),
+                error_category=ErrorCategory.USER_ERROR,
+                target=ErrorTarget.GENERAL,
+                error_type=ValidationErrorType.FILE_OR_FOLDER_NOT_FOUND,
+            ) from e
+    else:
+        # source is a subclass of IO
+        if not source.readable():
             msg = "File Permissions Error: The already-open \n\n inputted file is not readable."
             raise ValidationException(
                 message=msg,
                 no_personal_data_message="File Permissions error",
                 error_category=ErrorCategory.USER_ERROR,
                 target=ErrorTarget.GENERAL,
                 error_type=ValidationErrorType.INVALID_VALUE,
             )
-        # source is an already-open stream or file, we can read() from it directly.
-        input = source
-    except AttributeError:
-        # source has no writable() function, assume it's a string or file path.
-        must_open_file = True
 
-    if must_open_file:  # If supplied a file path, open it.
+        cm = nullcontext(enter_result=source)
+
+    with cm as f:
         try:
-            input = open(source, "r")
-        except OSError:  # FileNotFoundError introduced in Python 3
-            msg = "No such file or directory: {}"
+            return yaml.safe_load(f)
+        except yaml.YAMLError as e:
+            msg = f"Error while parsing yaml file: {source} \n\n {str(e)}"
             raise ValidationException(
-                message=msg.format(source),
-                no_personal_data_message=msg.format("[file_path]"),
+                message=msg,
+                no_personal_data_message="Error while parsing yaml file",
                 error_category=ErrorCategory.USER_ERROR,
                 target=ErrorTarget.GENERAL,
-                error_type=ValidationErrorType.FILE_OR_FOLDER_NOT_FOUND,
-            )
-    # input should now be an readable file or stream. Parse it.
-    cfg = {}
-    try:
-        cfg = yaml.safe_load(input)
-    except yaml.YAMLError as e:
-        msg = f"Error while parsing yaml file: {source} \n\n {str(e)}"
-        raise ValidationException(
-            message=msg,
-            no_personal_data_message="Error while parsing yaml file",
-            error_category=ErrorCategory.USER_ERROR,
-            target=ErrorTarget.GENERAL,
-            error_type=ValidationErrorType.CANNOT_PARSE,
-        )
-    finally:
-        if must_open_file:
-            input.close()
-    return cfg
+                error_type=ValidationErrorType.CANNOT_PARSE,
+            ) from e
 
 
 def dump_yaml(*args, **kwargs):
     """A thin wrapper over yaml.dump which forces `OrderedDict`s to be serialized as mappings.
 
     Otherwise behaves identically to yaml.dump
     """
@@ -365,63 +355,51 @@
                 message=msg,
                 no_personal_data_message="No dump destination Provided",
                 error_category=ErrorCategory.USER_ERROR,
                 target=ErrorTarget.GENERAL,
                 error_type=ValidationErrorType.MISSING_FIELD,
             )
 
-    # Check inputs
-    output = None  # type: IOBase
-    must_open_file = False
-    try:  # check dest type by duck-typing it as an IOBase
-        writable = dest.writable()
-        if not writable:  # dest is misformatted stream or file
+    if isinstance(dest, (str, os.PathLike)):
+        try:
+            cm = open(dest, "w")
+        except OSError as e:  # FileNotFoundError introduced in Python 3
+            msg = "No such file or directory: {}"
+            raise ValidationException(
+                message=msg.format(dest),
+                no_personal_data_message=msg.format("[file_path]"),
+                error_category=ErrorCategory.USER_ERROR,
+                target=ErrorTarget.GENERAL,
+                error_type=ValidationErrorType.FILE_OR_FOLDER_NOT_FOUND,
+            ) from e
+    else:
+        # dest is a subclass of IO
+        if not dest.writable():  # dest is misformatted stream or file
             msg = "File Permissions Error: The already-open \n\n inputted file is not writable."
             raise ValidationException(
                 message=msg,
                 no_personal_data_message="File Permissions error",
                 error_category=ErrorCategory.USER_ERROR,
                 target=ErrorTarget.GENERAL,
                 error_type=ValidationErrorType.CANNOT_PARSE,
             )
-        # dest is an already-open stream or file, we can write() to it directly.
-        output = dest
-    except AttributeError:
-        # dest has no writable() function, assume it's a string or file path.
-        must_open_file = True
+        cm = nullcontext(enter_result=dest)
 
-    if must_open_file:  # If supplied a file path, open it.
+    with cm as f:
         try:
-            output = open(dest, "w")
-        except OSError:  # FileNotFoundError introduced in Python 3
-            msg = "No such file or directory: {}"
+            dump_yaml(data_dict, f, default_flow_style=default_flow_style)
+        except yaml.YAMLError as e:
+            msg = f"Error while parsing yaml file \n\n {str(e)}"
             raise ValidationException(
-                message=msg.format(dest),
-                no_personal_data_message=msg.format("[file_path]"),
+                message=msg,
+                no_personal_data_message="Error while parsing yaml file",
                 error_category=ErrorCategory.USER_ERROR,
                 target=ErrorTarget.GENERAL,
-                error_type=ValidationErrorType.FILE_OR_FOLDER_NOT_FOUND,
-            )
-
-    # Once we have an open file pointer through either method, dump.
-    try:
-        dump_yaml(data_dict, output, default_flow_style=default_flow_style)
-    except yaml.YAMLError as e:
-        msg = f"Error while parsing yaml file \n\n {str(e)}"
-        raise ValidationException(
-            message=msg,
-            no_personal_data_message="Error while parsing yaml file",
-            error_category=ErrorCategory.USER_ERROR,
-            target=ErrorTarget.GENERAL,
-            error_type=ValidationErrorType.CANNOT_PARSE,
-        )
-    finally:
-        # close the file only if we opened it as part of this function.
-        if must_open_file:
-            output.close()
+                error_type=ValidationErrorType.CANNOT_PARSE,
+            ) from e
 
 
 def dict_eq(dict1: Dict[str, Any], dict2: Dict[str, Any]) -> bool:
     if not dict1 and not dict2:
         return True
     return dict1 == dict2
 
@@ -633,15 +611,15 @@
     if identity:
         if identity.type.lower() in ("system_assigned", "none"):
             identity = ManagedServiceIdentity(type="SystemAssigned")
         else:
             if identity.user_assigned_identities:
                 if isinstance(identity.user_assigned_identities, dict):  # if the identity is already in right format
                     return identity
-                ids = dict()
+                ids = {}
                 for id in identity.user_assigned_identities:  # pylint: disable=redefined-builtin
                     ids[id["resource_id"]] = {}
                 identity.user_assigned_identities = ids
                 identity.type = snake_to_camel(identity.type)
     else:
         identity = ManagedServiceIdentity(type="SystemAssigned")
     return identity
@@ -897,18 +875,18 @@
 
 class DockerProxy:
     def __getattribute__(self, name: str) -> Any:
         try:
             import docker  # pylint: disable=import-error
 
             return getattr(docker, name)
-        except ModuleNotFoundError:
+        except ModuleNotFoundError as e:
             raise Exception(
                 "Please install docker in the current python environment with `pip install docker` and try again."
-            )
+            ) from e
 
 
 def get_all_enum_values_iter(enum_type):
     """Get all values of an enum type."""
     for key in dir(enum_type):
         if not key.startswith("_"):
             yield getattr(enum_type, key)
@@ -998,7 +976,18 @@
     :param validate_func: Validation function. It takes two parameters: the root node and the dot key parts.
     If None, no validation will be performed.
     :type validate_func: Optional[Callable[[List[str], Dict[str, Any]], bool]]
     :return: List of valid dot keys.
     """
     left_reversed_parts = dot_key_wildcard.split(".")[::-1]
     return _get_valid_dot_keys_with_wildcard_impl(left_reversed_parts, root, validate_func=validate_func)
+
+
+def get_base_directory_for_cache() -> Path:
+    return Path(tempfile.gettempdir()).joinpath("azure-ai-ml")
+
+
+def get_versioned_base_directory_for_cache() -> Path:
+    # import here to avoid circular import
+    from azure.ai.ml._version import VERSION
+
+    return get_base_directory_for_cache().joinpath(VERSION)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_cache_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_cache_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,33 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import hashlib
 import logging
 import os.path
-import tempfile
 import threading
 import time
 from collections import defaultdict
 from concurrent.futures import ThreadPoolExecutor
 from dataclasses import dataclass
 from pathlib import Path
 from typing import Callable, Dict, List, Optional, Union
 
 from azure.ai.ml._utils._asset_utils import get_object_hash
 from azure.ai.ml._utils.utils import (
+    get_versioned_base_directory_for_cache,
     is_concurrent_component_registration_enabled,
     is_on_disk_cache_enabled,
     is_private_preview_enabled,
     write_to_shared_file,
 )
 from azure.ai.ml.constants._common import AZUREML_COMPONENT_REGISTRATION_MAX_WORKERS, AzureMLResourceType
 from azure.ai.ml.entities import Component
 from azure.ai.ml.entities._builders import BaseNode
+from azure.ai.ml.entities._component.code import ComponentCodeMixin
 
 logger = logging.getLogger(__name__)
 
 _ANONYMOUS_HASH_PREFIX = "anonymous-component-"
 _YAML_SOURCE_PREFIX = "yaml-source-"
 _CODE_INVOLVED_PREFIX = "code-involved-"
 EXPIRE_TIME_IN_SECONDS = 60 * 60 * 24 * 7  # 7 days
@@ -90,44 +91,27 @@
           }
           Its in-memory hash will be `hash_b`, which will be a cache miss.
     """
 
     def __init__(
         self,
         resolver: Callable[[Union[Component, str]], str],
-        subscription_id: Optional[str],
-        resource_group_name: Optional[str],
-        workspace_name: Optional[str],
-        registry_name: Optional[str],
+        client_key: str,
     ):
         self._resolver = resolver
         self._cache: Dict[str, _CacheContent] = {}
         self._nodes_to_resolve: List[BaseNode] = []
 
-        self._client_hash = self._get_client_hash(subscription_id, resource_group_name, workspace_name, registry_name)
+        hash_obj = hashlib.sha256()
+        hash_obj.update(client_key.encode("utf-8"))
+        self._client_hash = hash_obj.hexdigest()
         # the same client share 1 lock
         self._lock = _node_resolution_lock[self._client_hash]
 
     @staticmethod
-    def _get_client_hash(
-        subscription_id: Optional[str],
-        resource_group_name: Optional[str],
-        workspace_name: Optional[str],
-        registry_name: Optional[str],
-    ) -> str:
-        """Get a hash for used client.
-
-        Works for both workspace client and registry client.
-        """
-        object_hash = hashlib.sha256()
-        for s in [subscription_id, resource_group_name, workspace_name, registry_name]:
-            object_hash.update(str(s).encode("utf-8"))
-        return object_hash.hexdigest()
-
-    @staticmethod
     def _get_component_registration_max_workers():
         """Get the max workers for component registration.
 
         Before Python 3.8, the default max_worker is the number of processors multiplied by 5.
         It may send a large number of the uploading snapshot requests that will occur remote refuses requests.
         In order to avoid retrying the upload requests, max_worker will use the default value in Python 3.8,
         min(32, os.cpu_count + 4).
@@ -186,46 +170,43 @@
         if not isinstance(component, Component):
             # this shouldn't happen; handle it in case invalid call is made outside this class
             raise ValueError(f"Component {component} is not a Component object.")
 
         # TODO: calculate hash without resolving additional includes (copy code to temp folder)
         # note that it's still thread-safe with current implementation, as only read operations are
         # done on the original code folder
-        with component._resolve_local_code() as code:  # pylint: disable=protected-access
-            if code is None or code._is_remote:  # pylint: disable=protected-access
-                return in_memory_hash
+        if not (
+            isinstance(component, ComponentCodeMixin)
+            and component._with_local_code()  # pylint: disable=protected-access
+        ):
+            return in_memory_hash
 
+        with component._build_code() as code:  # pylint: disable=protected-access
             if hasattr(code, "_upload_hash"):
                 content_hash = code._upload_hash  # pylint: disable=protected-access
             else:
-                path = code.path if os.path.isabs(code.path) else os.path.join(code.base_path, code.path)
-                if os.path.exists(path):
-                    content_hash = get_object_hash(path)
+                code_path = code.path if os.path.isabs(code.path) else os.path.join(code.base_path, code.path)
+                if os.path.exists(code_path):
+                    content_hash = get_object_hash(code_path)
                 else:
                     # this will be gated by schema validation, so it shouldn't happen except for mock tests
                     return in_memory_hash
 
             object_hash = hashlib.sha256()
             object_hash.update(in_memory_hash.encode("utf-8"))
 
             object_hash.update(content_hash.encode("utf-8"))
             return _CODE_INVOLVED_PREFIX + object_hash.hexdigest()
 
     @property
     def _on_disk_cache_dir(self) -> Path:
         """Get the base path for on disk cache."""
-        from azure.ai.ml._version import VERSION
-
-        return Path(tempfile.gettempdir()).joinpath(
-            ".azureml",
-            "azure-ai-ml",
-            VERSION,
-            "cache",
-            self._client_hash,
+        return get_versioned_base_directory_for_cache().joinpath(
             "components",
+            self._client_hash,
         )
 
     def _get_on_disk_cache_path(self, on_disk_hash: str) -> Path:
         """Get the on disk cache path for a component."""
         return self._on_disk_cache_dir.joinpath(on_disk_hash)
 
     def _load_from_on_disk_cache(self, on_disk_hash: str) -> Optional[str]:
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_azureml_polling.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_azureml_polling.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_preflight_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_preflight_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_html_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_html_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 # ---------------------------------------------------------
 
 import logging
 from collections import OrderedDict
 from datetime import datetime, timedelta
 from html import escape
 
-import six
 
 SUPPORTED_VALUE_TYPE_TUPLE = (int, float, str, datetime, timedelta)
 TABLE_FMT = '<table style="width:100%">{0}</table>'
 ROW_FMT = "<tr>{0}</tr>"
 HEADER_FMT = "<th>{0}</th>"
 DATA_FMT = "<td>{0}</td>"
 # target="_blank" opens in new tab, rel="noopener" is for perf + security
@@ -42,15 +41,15 @@
     def values_to_data_row(values):
         cells = [to_html(value) for value in values]
         return get_data_row_string(cells)
 
     if all(is_collection):
         # Cases 2 and 4
         length = len(list(ordered_obj.values)[0])
-        if any([len(v) != length for v in ordered_obj.values()]):
+        if any(len(v) != length for v in ordered_obj.values()):
             # Case 4
             logging.warning("Uneven column lengths in table conversion")
             all_rows.append(values_to_data_row(ordered_obj.values()))
 
         else:
             # Case 2 - sad transpose
             for i in range(length):
@@ -95,15 +94,15 @@
 
     converted_value = converter(object_to_convert)
     return converted_value
 
 
 def is_string_link(string):
     # type: (str) -> bool
-    return isinstance(string, six.text_type) and string.strip().lower().startswith("http")
+    return isinstance(string, str) and string.strip().lower().startswith("http")
 
 
 def make_link(link_string, link_text=None):
     # type: (str) -> str
     if not link_text:  # Actually want truthy string
         link_text = "Link"
     return LINK_FMT.format(escape(link_string), link_text)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_http_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_http_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -142,38 +142,31 @@
         """
         cls = self.__class__
         return cls(config=self._config, transport=kwargs.pop("transport", self._transport), **kwargs)
 
     @_request_function
     def delete(self) -> None:
         """Sends a DELETE request."""
-        ...
 
     @_request_function
     def get(self) -> None:
         """Sends a GET request."""
-        ...
 
     @_request_function
     def head(self) -> None:
         """Sends a HEAD request."""
-        ...
 
     @_request_function
     def options(self) -> None:
         """Sends a OPTIONS request."""
-        ...
 
     @_request_function
     def patch(self) -> None:
         """Sends a PATCH request."""
-        ...
 
     @_request_function
     def post(self) -> None:
         """Sends a POST request."""
-        ...
 
     @_request_function
     def put(self) -> None:
         """Sends a PUT request."""
-        ...
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_experimental.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_experimental.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_registry_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_registry_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -100,15 +100,15 @@
         res = service_client.temporary_data_references.create_or_get_temporary_data_reference(
             name=name,
             version=version,
             resource_group_name=resource_group,
             registry_name=registry,
             body=body,
         )
-        sas_uri = res.blob_reference_for_consumption.credential.sas_uri
+        sas_uri = res.blob_reference_for_consumption.credential.additional_properties["sasUri"]
     except HttpResponseError as e:
         # "Asset already exists" exception is thrown from service with error code 409, that we need to ignore
         if e.status_code == 409:
             module_logger.debug("Skipping file upload, reason:  %s", str(e.reason))
         else:
             raise e
     return sas_uri
@@ -166,18 +166,18 @@
     body = BlobReferenceSASRequestDto(
         asset_id=REGISTRY_ASSET_ID.format(reg_name, asset_type, asset_name, asset_version),
         blob_uri=uri,
     )
     sas_uri = service_client.data_references.get_blob_reference_sas(
         name=asset_name, version=asset_version, resource_group_name=rg_name, registry_name=reg_name, body=body
     )
-    if sas_uri.blob_reference_for_consumption.credential["credentialType"] == "NoCredentials":
+    if sas_uri.blob_reference_for_consumption.credential.credential_type == "no_credentials":
         return sas_uri.blob_reference_for_consumption.blob_uri, "NoCredentials"
 
-    return sas_uri.blob_reference_for_consumption.credential["sasUri"], "SAS"
+    return sas_uri.blob_reference_for_consumption.credential.additional_properties["sasUri"], "SAS"
 
 
 def get_registry_client(credential, registry_name, **kwargs):
     base_url = _get_registry_discovery_endpoint_from_metadata(_get_default_cloud_name())
     kwargs.pop("base_url", None)
     service_client_registry_discovery_client = ServiceClientRegistryDiscovery(
         credential=credential, base_url=base_url, **kwargs
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_pathspec.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_pathspec.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/azure_resource_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/azure_resource_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,25 +16,25 @@
     # If a subscription list is passed in, use it. Otherwise, get all subscriptions
     subsList = []
     if subscription_list is not None:
         subsList = subscription_list
     else:
         try:
             from azure.mgmt.resource import SubscriptionClient  # pylint: disable=import-error
-        except ImportError:
-            raise ImportError("azure-mgmt-resource is required to get all accessible subscriptions")
+        except ImportError as e:
+            raise ImportError("azure-mgmt-resource is required to get all accessible subscriptions") from e
 
         subsClient = SubscriptionClient(credential)
         for sub in subsClient.subscriptions.list():
             subsList.append(sub.as_dict().get("subscription_id"))
 
     try:
         import azure.mgmt.resourcegraph as arg  # pylint: disable=import-error
-    except ImportError:
-        raise ImportError("azure-mgmt-resourcegraph is required query resources from subscriptions")
+    except ImportError as e:
+        raise ImportError("azure-mgmt-resourcegraph is required query resources from subscriptions") from e
 
     # Create Azure Resource Graph client and set options
     argClient = arg.ResourceGraphClient(credential)
     argQueryOptions = arg.models.QueryRequestOptions(result_format="objectArray")
 
     # Create query
     argQuery = arg.models.QueryRequest(subscriptions=subsList, query=strQuery, options=argQueryOptions)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_data_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_data_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_logger_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_logger_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_storage_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_storage_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -182,18 +182,18 @@
 
 
 def get_ds_name_and_path_prefix(asset_uri: str, registry_name: Optional[str] = None) -> Tuple[str, str]:
     if registry_name:
         try:
             split_paths = re.findall(STORAGE_URI_REGEX, asset_uri)
             path_prefix = split_paths[0][3]
-        except Exception:
-            raise Exception("Registry asset URI could not be parsed.")
+        except Exception as e:
+            raise Exception("Registry asset URI could not be parsed.") from e
         ds_name = None
     else:
         try:
             ds_name = asset_uri.split("paths")[0].split("/")[-2]
             path_prefix = asset_uri.split("paths")[1][1:]
-        except Exception:
-            raise Exception("Workspace asset URI could not be parsed.")
+        except Exception as e:
+            raise Exception("Workspace asset URI could not be parsed.") from e
 
     return ds_name, path_prefix
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_appinsights_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_appinsights_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_arm_id_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_arm_id_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_func_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_func_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_feature_store_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_feature_store_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_asset_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_asset_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -738,15 +738,15 @@
                 resource_group_name=resource_group_name,
                 workspace_name=workspace_name,
                 **kwargs,
             )
         )
         version = container.properties.latest_version
 
-    except ResourceNotFoundError:
+    except ResourceNotFoundError as e:
         message = (
             f"Asset {asset_name} does not exist in registry {registry_name}."
             if registry_name
             else f"Asset {asset_name} does not exist in workspace {workspace_name}."
         )
         no_personal_data_message = (
             "Asset {asset_name} does not exist in registry {registry_name}."
@@ -755,15 +755,15 @@
         )
         raise ValidationException(
             message=message,
             no_personal_data_message=no_personal_data_message,
             target=ErrorTarget.ASSET,
             error_category=ErrorCategory.USER_ERROR,
             error_type=ValidationErrorType.RESOURCE_NOT_FOUND,
-        )
+        ) from e
     return version
 
 
 def _get_latest(
     asset_name: str,
     version_operation: Any,
     resource_group_name: str,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_endpoint_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_endpoint_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -111,17 +111,17 @@
 
     if response.status_code not in [200, 201]:
         # We need to check for an empty response body or catch the exception raised.
         # It is possible the server responded with a 204 No Content response, and json parsing fails.
         if response.status_code != 204:
             try:
                 r_json = response.json()
-            except ValueError:
+            except ValueError as e:
                 # exception is not in the json format
-                raise Exception(response.content.decode("utf-8"))
+                raise Exception(response.content.decode("utf-8")) from e
         failure_msg = r_json.get("error", {}).get("message", response)
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
         }
         map_error(status_code=response.status_code, response=response, error_map=error_map)
@@ -199,13 +199,13 @@
                         ErrorTarget.BATCH_DEPLOYMENT
                         if isinstance(deployment, BatchDeployment)
                         else ErrorTarget.ONLINE_DEPLOYMENT
                     ),
                     no_personal_data_message=np_msg,
                     error_category=ErrorCategory.USER_ERROR,
                     error_type=ValidationErrorType.CANNOT_PARSE,
-                )
+                ) from err
     except OSError as err:
         raise MlException(
             message=f"Failed to open scoring script {err.filename}.",
             no_personal_data_message="Failed to open scoring script.",
-        )
+        ) from err
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_workspace_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_workspace_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -31,15 +31,15 @@
     return _BaseJob(
         name=properties.additional_properties["runId"],
         display_name=annotations.additional_properties["displayName"],
         description=annotations.additional_properties["description"] or "",
         tags=annotations.tags,
         properties=properties.additional_properties["userProperties"],
         experiment_name=properties.additional_properties["experimentName"],
-        services=dict(),
+        services={},
         status=annotations.additional_properties["status"],
         creation_context=creation_context,
         compute=properties.additional_properties["compute"]["armId"]
         if "compute" in properties.additional_properties
         else None,
     )
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_index_service_apis.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_index_service_apis.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_index_service_apis.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_index_service_apis.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/_index_entities_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/aio/operations/_index_entities_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/_index_entities_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_virtual_cluster_utils/_restclient/index_service_apis/operations/_index_entities_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_parallel_for.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_parallel_for.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_pipeline_decorator.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_pipeline_decorator.py`

 * *Files 0% similar despite different names*

```diff
@@ -203,15 +203,15 @@
                 # on_init/on_finalize is not supported for pipeline component
                 if job_settings.get("on_init") is not None or job_settings.get("on_finalize") is not None:
                     raise UserErrorException("On_init/on_finalize is not supported for pipeline component.")
                 # Build pipeline node instead of pipeline job if inside dsl.
                 built_pipeline = Pipeline(_from_component_func=True, **common_init_args)
                 if job_settings:
                     module_logger.warning(
-                        ("Job settings %s on pipeline function %r are ignored " "when using inside PipelineJob."),
+                        ("Job settings %s on pipeline function %r are ignored when using inside PipelineJob."),
                         job_settings,
                         func.__name__,
                     )
             else:
                 built_pipeline = PipelineJob(
                     jobs=pipeline_component.jobs,
                     compute=compute,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_condition.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_condition.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_load_import.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_load_import.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_fl_scatter_gather_node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_fl_scatter_gather_node.py`

 * *Files 0% similar despite different names*

```diff
@@ -13,20 +13,20 @@
 from azure.ai.ml._utils._experimental import experimental
 
 
 def _check_for_import(package_name):
     try:
         # pylint: disable=unused-import
         importlib.import_module(package_name)
-    except ImportError:
+    except ImportError as e:
         raise ImportError(
             "The DSL FL Node has an additional requirement above the rest of the "
             + "AML SDK repo in that the mldesigner package is required. Please run `pip install mldesigner` "
             + "and try again."
-        )
+        ) from e
 
 
 @experimental
 def fl_scatter_gather(
     *,
     silo_configs: List[FederatedLearningSilo],
     silo_component: Union[PipelineJob, CommandComponent],
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_pipeline_component_builder.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_pipeline_component_builder.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_group_decorator.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_group_decorator.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_component_func.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_component_func.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_dynamic.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_dynamic.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_overrides_definition.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_overrides_definition.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_do_while.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_do_while.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/dsl/_mldesigner/_constants.py` & `azure-ai-ml-1.9.0/azure/ai/ml/dsl/_mldesigner/_constants.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_registry.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_registry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_monitoring.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_monitoring.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_common.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_common.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_workspace.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_workspace.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/sweep.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/sweep.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/pipeline.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,14 +12,15 @@
     CONTINUE_RUN_ON_FAILED_OPTIONAL_INPUT = "continue_run_on_failed_optional_input"
     DATASTORE_REST = "Datastore"
     ENVIRONMENT = "environment"
     CODE = "code"
     REUSED_FLAG_FIELD = "azureml.isreused"
     REUSED_FLAG_TRUE = "true"
     REUSED_JOB_ID = "azureml.reusedrunid"
+    PIPELINE_JOB_TYPE = "azureml.pipelinejob"
 
 
 class ValidationErrorCode:
     PARAMETER_TYPE_UNKNOWN = "ParameterTypeUnknown"
 
 
 # Methods in Python dictionary, when used as IO name, will actually get function rather than IO object,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/automl.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/automl.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/constants/_job/job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/constants/_job/job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/automl/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/automl/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_image.py` & `azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_image.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_nlp.py` & `azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_nlp.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/automl/_automl_tabular.py` & `azure-ai-ml-1.9.0/azure/ai/ml/automl/_automl_tabular.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_logging/chained_identity.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_logging/chained_identity.py`

 * *Files 6% similar despite different names*

```diff
@@ -31,15 +31,17 @@
         # and pick up the stack trace as a reasonable approximation
         self._identity = self.__class__.__name__ if _ident is None else _ident
         parent = logging.getLogger("azureml") if _parent_logger is None else _parent_logger
         self._logger = parent.getChild(self._identity)
         try:
             super(ChainedIdentity, self).__init__(**kwargs)
         except TypeError as type_error:
-            raise TypeError("{}. Found key word arguments: {}.".format(",".join(type_error.args), kwargs.keys()))
+            raise TypeError(
+                "{}. Found key word arguments: {}.".format(",".join(type_error.args), kwargs.keys())
+            ) from type_error
 
     @property
     def identity(self) -> str:
         return self._identity
 
     def _log_context(self, context_name: str) -> Any:
         return LogScope(_ident=context_name, _parent_logger=self._logger)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_logging/debug_mode.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_logging/debug_mode.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 import os
 import sys
 import time
 import traceback
 from collections import namedtuple
 from typing import List, Optional
 
-import six.moves.http_client as httpclient
+import http.client
 
 LOG_FILE = os.path.abspath("azureml.log")
 LOG_FORMAT = "%(asctime)s|%(name)s|%(levelname)s|%(message)s"
 INTERESTING_NAMESPACES = ["azureml", "msrest.http_logger", "urllib2", "azure"]
 
 module_logger = logging.getLogger(__name__)
 separator = "\n==================\n"
@@ -38,15 +38,15 @@
                 }
             )
 
     return main_stack
 
 
 def connection_info(gc_objects: list) -> List[ConnectionInfo]:
-    connections = [obj for obj in gc_objects if isinstance(obj, httpclient.HTTPConnection)]
+    connections = [obj for obj in gc_objects if isinstance(obj, http.client.HTTPConnection)]
     return [ConnectionInfo(host=c.host, port=c.port, hasSocket=(c.sock is not None)) for c in connections]
 
 
 # pylint: disable=client-incorrect-naming-convention
 class diagnostic_log(object):
     """Directs debug logs to a specified file.
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/docker_client.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/docker_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -59,15 +59,15 @@
         :raises: azure.ai.ml._local_endpoints.errors.DockerEngineNotAvailableError
         """
         if self._lazy_client is None:
             try:
                 self._lazy_client = docker.from_env()
             except docker.errors.DockerException as e:
                 if "Error while fetching server API version" in str(e):
-                    raise DockerEngineNotAvailableError()
+                    raise DockerEngineNotAvailableError() from e
                 raise
         return self._lazy_client
 
     def create_endpoint(
         self,
         endpoint_name: str,
         endpoint_metadata: str,
@@ -107,14 +107,15 @@
         conda_source_path: str,
         conda_yaml_contents: str,
         volumes: dict,
         environment: dict,
         azureml_port: int,
         local_endpoint_mode: LocalEndpointMode,
         prebuilt_image_name: Optional[str] = None,
+        local_enable_gpu: Optional[bool] = False,
     ) -> None:
         """Builds and runs an image from provided image context.
 
         :param endpoint_name: name of local endpoint
         :type endpoint_name: str
         :param deployment_name: name of local deployment
         :type deployment_name: str
@@ -136,14 +137,16 @@
         :type environment: dict
         :param azureml_port: Port exposed in Docker image for AzureML service.
         :type azureml_port: int
         :param local_endpoint_mode: Mode for how to create the local user container.
         :type local_endpoint_mode: LocalEndpointMode
         :param prebuilt_image_name: Name of pre-built image from customer if using BYOC flow.
         :type prebuilt_image_name: str
+        :param local_enable_gpu: enable local container to access gpu
+        :type local_enable_gpu: bool
         """
         # Prepare image
         if prebuilt_image_name is None:
             image_name = _get_image_name(endpoint_name, deployment_name)
             module_logger.debug("Building local image '%s'\n", image_name)
             module_logger.debug("Build directory: '%s'\n", build_directory)
             module_logger.debug("Dockerfile path: '%s'\n", dockerfile_path)
@@ -159,24 +162,24 @@
             image_name = prebuilt_image_name
             try:
                 self._client.images.get(image_name)
             except docker.errors.ImageNotFound:
                 module_logger.info("\nDid not find image '%s' locally. Pulling from registry.\n", image_name)
                 try:
                     self._client.images.pull(image_name)
-                except docker.errors.NotFound:
+                except docker.errors.NotFound as e:
                     raise InvalidLocalEndpointError(
                         message=(
                             f"Could not find image '{image_name}' locally or in registry. "
                             "Please check your image name."
                         ),
                         no_personal_data_message=(
                             "Could not find image locally or in registry. Please check your image name."
                         ),
-                    )
+                    ) from e
 
         module_logger.info("\nStarting up endpoint")
         # Delete container if exists
         self.delete(endpoint_name=endpoint_name, verify_exists=False)
 
         labels = get_container_labels(
             endpoint_name=endpoint_name,
@@ -185,23 +188,25 @@
             deployment_metadata=deployment_metadata,
             azureml_port=azureml_port,
         )
         module_logger.debug("Setting labels: '%s'\n", labels)
         module_logger.debug("Mounting volumes: '%s'\n", volumes)
         module_logger.debug("Setting environment variables: '%s'\n", environment)
         container_name = _get_container_name(endpoint_name, deployment_name)
+        device_requests = [docker.types.DeviceRequest(count=-1, capabilities=[["gpu"]])] if local_enable_gpu else None
         container = self._client.containers.create(
             image_name,
             name=container_name,
             labels=labels,
             volumes=self._reformat_volumes(volumes),
             environment=environment,
             detach=True,
             tty=True,
             publish_all_ports=True,
+            device_requests=device_requests,
         )
         if local_endpoint_mode == LocalEndpointMode.VSCodeDevContainer:
             try:
                 devcontainer_path = self._vscode_client.create_dev_container_json(
                     azureml_container=container,
                     endpoint_name=endpoint_name,
                     deployment_name=deployment_name,
@@ -405,19 +410,19 @@
                         raise LocalEndpointImageBuildError(status["stream"])
                     module_logger.info(status["stream"])
 
                 if "error" in status:
                     module_logger.info(status["error"])
                     raise LocalEndpointImageBuildError(status["error"])
         except docker.errors.APIError as e:
-            raise LocalEndpointImageBuildError(e)
+            raise LocalEndpointImageBuildError(e) from e
         except Exception as e:
             if isinstance(e, LocalEndpointImageBuildError):
                 raise
-            raise LocalEndpointImageBuildError(e)
+            raise LocalEndpointImageBuildError(e) from e
 
     def _reformat_volumes(self, volumes_dict: dict) -> list:  # pylint: disable=no-self-use
         """Returns a list of volumes to pass to docker.
 
         :param volumes_dict: custom formatted dict of volumes to mount. We expect the keys to be unique.
         Example: {
             "codesrc:codedest": {
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/dockerfile_instructions.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/dockerfile_instructions.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/endpoint_stub.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/endpoint_stub.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/azureml_image_context.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/azureml_image_context.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/mdc_config_resolver.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/mdc_config_resolver.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/dockerfile_resolver.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/dockerfile_resolver.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/environment_validator.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/environment_validator.py`

 * *Files 2% similar despite different names*

```diff
@@ -32,19 +32,23 @@
         dockerfile_contents, inference_config) - Either base_image or build_directory should be None.
     :type return: Iterable[str]
     :raises: azure.ai.ml._local_endpoints.errors.RequiredLocalArtifactsNotFoundError
     :raises: azure.ai.ml._local_endpoints.errors.CloudArtifactsNotSupportedError
     """
     # Validate environment for local endpoint
     if _environment_contains_cloud_artifacts(deployment=deployment):
-        name, version = parse_name_version(deployment.environment)
-        label = None
-        if not version:
-            name, label = parse_name_label(deployment.environment)
-        environment_asset = environment_operations.get(name=name, version=version, label=label)
+        if isinstance(deployment.environment, Environment):
+            environment_asset = deployment.environment
+        else:
+            name, version = parse_name_version(deployment.environment)
+            label = None
+            if not version:
+                name, label = parse_name_label(deployment.environment)
+            environment_asset = environment_operations.get(name=name, version=version, label=label)
+
         if not _cloud_environment_is_valid(environment=environment_asset):
             msg = (
                 "Cloud environment must have environment.image "
                 "or the environment.build.path set to work for local endpoints."
                 " Note: Curated environments are not supported for local deployments."
             )
             raise ValidationException(
@@ -79,15 +83,15 @@
     :type return: Iterable[str]
     """
     if environment_asset.build and environment_asset.build.path and is_url(environment_asset.build.path):
         environment_build_directory = download_artifact_from_storage_url(
             blob_url=environment_asset.build.path,
             destination=download_path,
             datastore_operation=environment_operations._datastore_operation,
-            datastore_name=None,
+            datastore_name="workspaceartifactstore",
         )
         dockerfile_path = Path(environment_build_directory, environment_asset.build.dockerfile_path)
         dockerfile_contents = dockerfile_path.read_text()
         return (
             None,
             None,
             None,
@@ -156,8 +160,8 @@
 def _cloud_environment_is_valid(environment: Environment):
     return isinstance(environment, Environment) and (
         environment.image or (environment.build and environment.build.path)
     )
 
 
 def _environment_contains_cloud_artifacts(deployment: OnlineDeployment):
-    return isinstance(deployment.environment, str)
+    return isinstance(deployment.environment, str) or deployment.environment.id is not None
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/model_validator.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/model_validator.py`

 * *Files 2% similar despite different names*

```diff
@@ -55,20 +55,25 @@
 
 def _local_model_is_valid(deployment: OnlineDeployment):
     return deployment.model and isinstance(deployment.model, Model) and deployment.model.path
 
 
 def _model_contains_cloud_artifacts(deployment: OnlineDeployment):
     # If the deployment.model is a string, then it is the cloud model name or full arm ID
-    return isinstance(deployment.model, str)
+    return isinstance(deployment.model, str) or deployment.model.id is not None
 
 
 def _get_cloud_model_artifacts(model_operations: ModelOperations, model: str, download_path: str) -> str:
-    name, version = parse_prefixed_name_version(model)
-    model_asset = model_operations.get(name=name, version=version)
+    if isinstance(model, Model):
+        name = model.name
+        version = model._version
+        model_asset = model
+    else:
+        name, version = parse_prefixed_name_version(model)
+        model_asset = model_operations.get(name=name, version=version)
     model_uri_path = AzureMLDatastorePathUri(model_asset.path)
     path = Path(model_uri_path.path)
     starts_with = path if path.is_dir() else path.parent
     return (
         name,
         version,
         download_artifact(
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/validators/code_validator.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/validators/code_validator.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/wsl_utility.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/wsl_utility.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/utilities/commandline_utility.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/utilities/commandline_utility.py`

 * *Files 7% similar despite different names*

```diff
@@ -61,22 +61,22 @@
         time_taken = time.time() - start_time
         if not do_not_print:
             _print_command_results(True, time_taken, output)
 
         if return_json:
             try:
                 return json.loads(exclude_warnings(output))
-            except Exception:
+            except Exception as e:
                 msg = "Expected JSON, instead got: \n{}\n"
                 raise MlException(
                     message=msg.format(output),
                     no_personal_data_message=msg.format("[something else]"),
                     target=ErrorTarget.LOCAL_ENDPOINT,
                     error_category=ErrorCategory.SYSTEM_ERROR,
-                )
+                ) from e
         else:
             return output
     except subprocess.CalledProcessError as e:
         time_taken = time.time() - start_time
         output = e.output.decode(encoding="UTF-8")
         if not do_not_print:
             _print_command_results(False, time_taken, output)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/vscode_client.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/vscode_client.py`

 * *Files 0% similar despite different names*

```diff
@@ -41,13 +41,13 @@
             "--folder-uri",
             f"vscode-remote://dev-container+{hex_encoded_devcontainer_path}{app_path}",
         ]
         try:
             run_cli_command(command)
         except Exception as e:
             output = e.output.decode(encoding="UTF-8")  # pylint: disable=no-member
-            raise VSCodeCommandNotFound(output)
+            raise VSCodeCommandNotFound(output) from e
 
 
 def _encode_hex(path: str):
     vscode_path = re.sub("\\s+", "", path)  # pylint: disable=specify-parameter-names-in-call
     return binascii.hexlify(vscode_path.encode()).decode("ascii")
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_resolver.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_resolver.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_properties.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_local_endpoints/vscode_debug/devcontainer_properties.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/_AzureMLSparkOnBehalfOfCredential.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/_AzureMLSparkOnBehalfOfCredential.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,42 +21,44 @@
         return None
 
     def get_unavailable_message(self) -> str:
         return "AzureML Spark On Behalf of credentials not available in this environment"
 
 
 def _get_client_args(**kwargs) -> Optional[dict]:
-    from pyspark.sql import SparkSession  # cspell:disable-line # pylint: disable=import-error
-
-    try:
-        spark = SparkSession.builder.getOrCreate()
-    except Exception:
-        raise Exception("Fail to get spark session, please check if spark environment is set up.")
-
-    spark_conf = spark.sparkContext.getConf()
-    spark_conf_vars = {
-        "AZUREML_SYNAPSE_CLUSTER_IDENTIFIER": "spark.synapse.clusteridentifier",
-        "AZUREML_SYNAPSE_TOKEN_SERVICE_ENDPOINT": "spark.tokenServiceEndpoint",
-    }
-    for env_key, conf_key in spark_conf_vars.items():
-        value = spark_conf.get(conf_key)
-        if value:
-            os.environ[env_key] = value
-
     # Override default settings if provided via arguments
     if len(kwargs) > 0:
         env_key_from_kwargs = [
             "AZUREML_SYNAPSE_CLUSTER_IDENTIFIER",
             "AZUREML_SYNAPSE_TOKEN_SERVICE_ENDPOINT",
             "AZUREML_RUN_ID",
             "AZUREML_RUN_TOKEN_EXPIRY",
         ]
         for env_key in env_key_from_kwargs:
-            if env_key in kwargs:
+            if env_key in kwargs.keys():
                 os.environ[env_key] = kwargs[env_key]
+            else:
+                raise Exception("Unable to initialize AzureMLHoboSparkOBOCredential due to invalid arguments")
+    else:
+        from pyspark.sql import SparkSession  # cspell:disable-line # pylint: disable=import-error
+
+        try:
+            spark = SparkSession.builder.getOrCreate()
+        except Exception as e:
+            raise Exception("Fail to get spark session, please check if spark environment is set up.") from e
+
+        spark_conf = spark.sparkContext.getConf()
+        spark_conf_vars = {
+            "AZUREML_SYNAPSE_CLUSTER_IDENTIFIER": "spark.synapse.clusteridentifier",
+            "AZUREML_SYNAPSE_TOKEN_SERVICE_ENDPOINT": "spark.tokenServiceEndpoint",
+        }
+        for env_key, conf_key in spark_conf_vars.items():
+            value = spark_conf.get(conf_key)
+            if value:
+                os.environ[env_key] = value
 
     token_service_endpoint = os.environ.get("AZUREML_SYNAPSE_TOKEN_SERVICE_ENDPOINT")
     obo_access_token = os.environ.get("AZUREML_OBO_CANARY_TOKEN")
     obo_endpoint = os.environ.get("AZUREML_OBO_USER_TOKEN_FOR_SPARK_RETRIEVAL_API", "getuseraccesstokenforspark")
     subscription_id = os.environ.get("AZUREML_ARM_SUBSCRIPTION")
     resource_group = os.environ.get("AZUREML_ARM_RESOURCEGROUP")
     workspace_name = os.environ.get("AZUREML_ARM_WORKSPACE_NAME")
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_credentials/aml_on_behalf_of.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_credentials/aml_on_behalf_of.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_credentials/aml_on_behalf_of.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_credentials/aml_on_behalf_of.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/managed_identity_base.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/managed_identity_base.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/managed_identity_client.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/managed_identity_client.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_aio/_internal/get_token_mixin.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_aio/_internal/get_token_mixin.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/managed_identity_base.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/managed_identity_base.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/pipeline.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/pipeline.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/managed_identity_client.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/managed_identity_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,28 +3,24 @@
 # ---------------------------------------------------------
 
 import abc
 import time
 from typing import TYPE_CHECKING
 
 import isodate
-import six
 from msal import TokenCache
 
 from azure.core.credentials import AccessToken
 from azure.core.exceptions import ClientAuthenticationError, DecodeError
 from azure.core.pipeline.policies import ContentDecodePolicy
 
 from .._internal import _scopes_to_resource
 from .._internal.pipeline import build_pipeline
 
-try:
-    ABC = abc.ABC
-except AttributeError:  # Python 2.7, abc exists, but not ABC
-    ABC = abc.ABCMeta("ABC", (object,), {"__slots__": ()})  # type: ignore
+ABC = abc.ABC
 
 if TYPE_CHECKING:
     # pylint:disable=ungrouped-imports
     from typing import Union
 
     from azure.core.pipeline import PipelineResponse
     from azure.core.pipeline.policies import HTTPPolicy, SansIOHTTPPolicy
@@ -52,18 +48,15 @@
                     response.http_response.text(), mime_type="application/json"
                 )
             except DecodeError as ex:
                 if response.http_response.content_type.startswith("application/json"):
                     message = "Failed to deserialize JSON from response"
                 else:
                     message = 'Unexpected content type "{}"'.format(response.http_response.content_type)
-                six.raise_from(
-                    ClientAuthenticationError(message=message, response=response.http_response),
-                    ex,
-                )
+                raise ClientAuthenticationError(message=message, response=response.http_response) from ex
 
         if not content:
             raise ClientAuthenticationError(message="No token received.", response=response.http_response)
 
         if not ("access_token" in content or "token" in content) or not (
             "expires_in" in content or "expires_on" in content or "expiresOn" in content
         ):
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/identity/_internal/get_token_mixin.py` & `azure-ai-ml-1.9.0/azure/ai/ml/identity/_internal/get_token_mixin.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/_setup.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/_setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -54,15 +54,14 @@
         create_instance_func=lambda: node_cls.__new__(node_cls),
         load_from_rest_object_func=node_cls._from_rest_object,
         nested_schema=NestedField(schema_cls, unknown=INCLUDE),
     )
 
 
 def enable_internal_components_in_pipeline(*, force=False):
-    global _registered  # pylint: disable=global-statement
     if _registered and not force:
         return  # already registered
 
     _enable_internal_components()
     for _type in NodeType.all_values():
         # if we do not register node class for all node types, the only difference will be the type of created node
         # instance (Ae365exepool => InternalBaseNode). Not sure if this is acceptable.
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/_utils/_yaml_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/_utils/_yaml_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/command.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/command.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/environment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/environment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/input_output.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/input_output.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/_schema/node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/_schema/node.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/parallel.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/parallel.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/command.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/command.py`

 * *Files 1% similar despite different names*

```diff
@@ -89,18 +89,18 @@
         from .._schema.command import CommandSchema
 
         return CommandSchema(context=context)
 
     def _to_rest_object(self, **kwargs) -> dict:
         rest_obj = super()._to_rest_object(**kwargs)
         rest_obj.update(
-            dict(
-                limits=get_rest_dict_for_node_attrs(self.limits, clear_empty_value=True),
-                resources=get_rest_dict_for_node_attrs(self.resources, clear_empty_value=True),
-            )
+            {
+                "limits": get_rest_dict_for_node_attrs(self.limits, clear_empty_value=True),
+                "resources": get_rest_dict_for_node_attrs(self.resources, clear_empty_value=True),
+            }
         )
         return rest_obj
 
     @classmethod
     def _from_rest_object_to_init_params(cls, obj):
         obj = InternalBaseNode._from_rest_object_to_init_params(obj)
 
@@ -160,12 +160,12 @@
     def _picked_fields_from_dict_to_rest_object(cls) -> List[str]:
         return Command._picked_fields_from_dict_to_rest_object() + ["distribution"]
 
     def _to_rest_object(self, **kwargs) -> dict:
         rest_obj = super()._to_rest_object(**kwargs)
         distribution = self.distribution._to_rest_object() if self.distribution else None  # pylint: disable=no-member
         rest_obj.update(
-            dict(
-                distribution=get_rest_dict_for_node_attrs(distribution),
-            )
+            {
+                "distribution": get_rest_dict_for_node_attrs(distribution),
+            }
         )
         return rest_obj
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/code.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/code.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/spark.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/spark.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/scope.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/scope.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_merkle_tree.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_merkle_tree.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/environment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/environment.py`

 * *Files 2% similar despite different names*

```diff
@@ -83,15 +83,19 @@
         ):
             validation_result.append_error(
                 yaml_path=f"docker.{self.BUILD}.{self.DOCKERFILE}",
                 message=f"Dockerfile not exists: {dockerfile_file}",
             )
         return validation_result
 
-    def _validate(self, base_path: str, skip_path_validation: bool = False) -> MutableValidationResult:
+    def validate(self, base_path: str, skip_path_validation: bool = False) -> MutableValidationResult:
+        """Validate the environment section.
+
+        This is a public method but won't be exposed to user given InternalEnvironment is an internal class.
+        """
         validation_result = _ValidationResultBuilder.success()
         if self.os is not None and self.os not in {"Linux", "Windows", "linux", "windows"}:
             validation_result.append_error(
                 yaml_path="os",
                 message=f"Only support 'Linux' and 'Windows', but got {self.os!r}",
             )
         validation_result.merge_with(self._validate_conda_section(base_path, skip_path_validation))
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/component.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,41 +2,45 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 # pylint: disable=protected-access, redefined-builtin
 # disable redefined-builtin to use id/type as argument name
 from contextlib import contextmanager
 from os import PathLike
 from pathlib import Path
-from typing import Dict, Optional, Union
+from typing import Dict, List, Optional, Union
 from uuid import UUID
 
+import yaml
 from marshmallow import Schema
 
 from ... import Input, Output
 from ..._restclient.v2022_10_01.models import ComponentVersion, ComponentVersionProperties
 from ..._schema import PathAwareSchema
 from ..._utils._arm_id_utils import parse_name_label
 from ..._utils._asset_utils import IgnoreFile
 from ...entities import Component
 from ...entities._assets import Code
+from ...entities._component._additional_includes import AdditionalIncludesMixin
 from ...entities._component.code import ComponentIgnoreFile
 from ...entities._job.distribution import DistributionConfiguration
 from ...entities._system_data import SystemData
 from ...entities._util import convert_ordered_dict_to_dict
 from ...entities._validation import MutableValidationResult
 from .._schema.component import InternalComponentSchema
-from ._additional_includes import ADDITIONAL_INCLUDES_SUFFIX, InternalAdditionalIncludes
 from ._input_outputs import InternalInput, InternalOutput
 from ._merkle_tree import create_merkletree
 from .code import InternalCode
 from .environment import InternalEnvironment
 from .node import InternalBaseNode
 
+_ADDITIONAL_INCLUDES_CONFIG_KEY = "additional_includes"
+_ADDITIONAL_INCLUDES_SUFFIX = ".additional_includes"
 
-class InternalComponent(Component):
+
+class InternalComponent(Component, AdditionalIncludesMixin):
     # pylint: disable=too-many-instance-attributes, too-many-locals
     """Base class for internal component version, used to define an internal component. Recommended to create instance
     with component_factory.
 
     :param name: Name of the resource.
     :type name: str
     :param version: Version of the resource.
@@ -95,20 +99,20 @@
         parallel: Optional[Dict] = None,
         starlite: Optional[Dict] = None,
         ae365exepool: Optional[Dict] = None,
         launcher: Optional[Dict] = None,
         datatransfer: Optional[Dict] = None,
         **kwargs,
     ):
-        type, self._type_label = parse_name_label(type)
+        _type, self._type_label = parse_name_label(type)
         super().__init__(
             name=name,
             version=version,
             id=id,
-            type=type,
+            type=_type,
             description=description,
             tags=tags,
             properties=properties,
             display_name=display_name,
             is_deterministic=is_deterministic,
             inputs=inputs,
             outputs=outputs,
@@ -121,16 +125,14 @@
         self._yaml_str = yaml_str
         self._other_parameter = kwargs
 
         self.successful_return_code = successful_return_code
         self.code = code
         self.environment = InternalEnvironment(**environment) if isinstance(environment, dict) else environment
         self.environment_variables = environment_variables
-        self.__additional_includes = None
-        self.__ignore_file = None
         # TODO: remove these to keep it a general component class
         self.command = command
         self.scope = scope
         self.hemera = hemera
         self.hdinsight = hdinsight
         self.parallel = parallel
         self.starlite = starlite
@@ -144,48 +146,104 @@
         for name, port in io_dict.items():
             if is_input:
                 component_io[name] = InternalInput._from_base(port)
             else:
                 component_io[name] = InternalOutput._from_base(port)
         return component_io
 
+    # region AdditionalIncludesMixin
+
+    @classmethod
+    def _read_additional_include_configs(cls, yaml_path) -> List:
+        """Read additional include configs from the additional includes file.
+        The name of the file is the same as the component spec file, with a suffix of ".additional_includes".
+        It can be either a yaml file or a text file:
+        1. If it is a yaml file, yaml format of additional_includes looks like below:
+        ```
+        additional_includes:
+         - your/local/path
+         - type: artifact
+           organization: devops_organization
+           project: devops_project
+           feed: artifacts_feed_name
+           name: universal_package_name
+           version: package_version
+           scope: scope_type
+        ```
+        2. If it is a text file, each line is a path to include. Note that artifact config is not supported
+        in this format.
+        """
+        additional_includes_config_path = yaml_path.with_suffix(_ADDITIONAL_INCLUDES_SUFFIX)
+        if additional_includes_config_path.is_file():
+            with open(additional_includes_config_path) as f:
+                file_content = f.read()
+                try:
+                    configs = yaml.safe_load(file_content)
+                    if isinstance(configs, dict):
+                        return configs.get(_ADDITIONAL_INCLUDES_CONFIG_KEY, [])
+                except Exception:  # pylint: disable=broad-except
+                    # TODO: check if we should catch yaml.YamlError instead here
+                    pass
+                return [line.strip() for line in file_content.splitlines(keepends=False) if len(line.strip()) > 0]
+        return []
+
+    @classmethod
+    def _get_additional_includes_field_name(cls) -> str:
+        # additional includes for internal components are configured by a file, which is not a field in the yaml
+        # return '*' as diagnostics yaml paths and override _get_all_additional_includes_configs.
+        return "*"
+
+    def _get_all_additional_includes_configs(self) -> List:
+        # internal components must have a source path
+        return self._read_additional_include_configs(Path(self._source_path))
+
+    def _get_base_path_for_code(self) -> Path:
+        # internal components must have a source path
+        return Path(self._source_path).parent
+
+    def _get_origin_code_value(self) -> Union[str, PathLike, None]:
+        return self.code or Path(".").as_posix()
+
+    # endregion
+
     @property
     def _additional_includes(self):
-        if self.__additional_includes is None:
-            # use property as `self._source_path` is set after __init__ now
-            # `self._source_path` is not None when enter this function
-            self.__additional_includes = InternalAdditionalIncludes(
-                code_path=self.code,
-                yaml_path=self._source_path,
-            )
-        return self.__additional_includes
+        """This property is kept for compatibility with old mldesigner sdk."""
+        obj = self._generate_additional_includes_obj()
+        from azure.ai.ml._internal.entities._additional_includes import InternalAdditionalIncludes
 
+        obj.__class__ = InternalAdditionalIncludes
+        return obj
+
+    # region SchemaValidatableMixin
     @classmethod
     def _create_schema_for_validation(cls, context) -> Union[PathAwareSchema, Schema]:
         return InternalComponentSchema(context=context)
 
     def _customized_validate(self) -> MutableValidationResult:
         validation_result = super(InternalComponent, self)._customized_validate()
-        # if the code is not local path, no need for additional includes
-        code = Path(self.code) if self.code is not None else Path(self._source_path).parent
-        if code.exists() and self._additional_includes.with_includes:
-            validation_result.merge_with(self._additional_includes._validate())
-            # resolving additional includes & update self._base_path can be dangerous,
-            # so we just skip path validation if additional_includes is used
-            # note that there will still be runtime error in submission or execution
-            skip_path_validation = True
-        else:
-            skip_path_validation = False
+        skip_path_validation = not self._append_diagnostics_and_check_if_origin_code_reliable_for_local_path_validation(
+            validation_result
+        )
+        # resolving additional includes & update self._base_path can be dangerous,
+        # so we just skip path validation if additional includes is provided.
+        # note that there will still be client-side error on job submission (after code is resolved)
+        # if paths in environment are invalid
         if isinstance(self.environment, InternalEnvironment):
             validation_result.merge_with(
-                self.environment._validate(self._base_path, skip_path_validation=skip_path_validation),
+                self.environment.validate(
+                    self._base_path,
+                    skip_path_validation=skip_path_validation,
+                ),
                 field_name="environment",
             )
         return validation_result
 
+    # endregion
+
     @classmethod
     def _from_rest_object_to_init_params(cls, obj: ComponentVersion) -> Dict:
         # put it here as distribution is shared by some components, e.g. command
         distribution = obj.properties.component_spec.pop("distribution", None)
         init_kwargs = super()._from_rest_object_to_init_params(obj)
         if distribution:
             init_kwargs["distribution"] = DistributionConfiguration._from_rest_object(distribution)
@@ -222,66 +280,49 @@
         :return: The snapshot id of a component in ml-components with code_path as its working directory.
         """
         curr_root = create_merkletree(code_path, ignore_file.is_file_excluded)
         snapshot_id = str(UUID(curr_root.hexdigest_hash[::4]))
         return snapshot_id
 
     @contextmanager
-    def _resolve_local_code(self) -> Optional[Code]:
-        """Try to create a Code object pointing to local code and yield it.
-
-        If there is no local code to upload, yield None. Otherwise, yield a Code object pointing to the code.
+    def _try_build_local_code(self) -> Optional[Code]:
+        """Build final code when origin code is a local code.
+        Will merge code path with additional includes into a temp folder if additional includes is specified.
+        For internal components, file dependencies in environment will be resolved based on the final code.
         """
-        # an internal component always has a default local code of its base path
-        # otherwise, if there is no local code, yield super()._resolve_local_code() and return early
-        if self.code is not None:
-            with super()._resolve_local_code() as code:
-                if not isinstance(code, Code) or code._is_remote:
-                    yield code
-                    return
-
-        # This is forbidden by schema CodeFields for now so won't happen.
-        if isinstance(self.code, Code):
-            yield code
-            return
-
-        def get_additional_include_file_name():
-            if self._source_path is not None:
-                return Path(self._source_path).with_suffix(ADDITIONAL_INCLUDES_SUFFIX).name
-            return None
-
-        self._additional_includes.resolve()
-
-        # file dependency in code will be read during internal environment resolution
-        # for example, docker file of the environment may be in additional includes
-        # and it will be read then insert to the environment object during resolution
-        # so we need to resolve environment based on the temporary code path
-        if isinstance(self.environment, InternalEnvironment):
-            self.environment.resolve(self._additional_includes.code)
-        # use absolute path in case temp folder & work dir are in different drive
-        tmp_code_dir = self._additional_includes.code.absolute()
-        rebased_ignore_file = ComponentIgnoreFile(
-            tmp_code_dir,
-            additional_includes_file_name=get_additional_include_file_name(),
-        )
-        # Use the snapshot id in ml-components as code name to enable anonymous
-        # component reuse from ml-component runs.
-        # calculate snapshot id here instead of inside InternalCode to ensure that
-        # snapshot id is calculated based on the resolved code path
-        yield InternalCode(
-            name=self._get_snapshot_id(
-                # use absolute path in case temp folder & work dir are in different drive
-                self._additional_includes.code.absolute(),
-                # this ignore-file should be rebased to the resolved code path
-                rebased_ignore_file,
-            ),
-            version="1",
-            base_path=self._base_path,
-            path=tmp_code_dir,
-            is_anonymous=True,
-            ignore_file=rebased_ignore_file,
-        )
-
-        self._additional_includes.cleanup()
+        # origin code value of internal component will never be None. check _get_origin_code_value for details
+        with self._generate_additional_includes_obj().merge_local_code_and_additional_includes() as tmp_code_dir:
+            # use absolute path in case temp folder & work dir are in different drive
+            tmp_code_dir = tmp_code_dir.absolute()
+
+            # file dependency in code will be read during internal environment resolution
+            # for example, docker file of the environment may be in additional includes;
+            # and it will be read then insert to the environment object during resolution.
+            # so we need to resolve environment based on the temporary code path
+            if isinstance(self.environment, InternalEnvironment):
+                self.environment.resolve(base_path=tmp_code_dir)
+
+            # additional includes config file itself should be ignored
+            rebased_ignore_file = ComponentIgnoreFile(
+                tmp_code_dir,
+                additional_includes_file_name=Path(self._source_path).with_suffix(_ADDITIONAL_INCLUDES_SUFFIX).name,
+            )
+            # Use the snapshot id in ml-components as code name to enable anonymous
+            # component reuse from ml-component runs.
+            # calculate snapshot id here instead of inside InternalCode to ensure that
+            # snapshot id is calculated based on the built code path
+            yield InternalCode(
+                name=self._get_snapshot_id(
+                    # use absolute path in case temp folder & work dir are in different drive
+                    tmp_code_dir,
+                    # this ignore-file should be rebased to the built code path
+                    rebased_ignore_file,
+                ),
+                version="1",
+                base_path=self._base_path,
+                path=tmp_code_dir,
+                is_anonymous=True,
+                ignore_file=rebased_ignore_file,
+            )
 
     def __call__(self, *args, **kwargs) -> InternalBaseNode:  # pylint: disable=useless-super-delegation
         return super(InternalComponent, self).__call__(*args, **kwargs)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/_input_outputs.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/_input_outputs.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/node.py`

 * *Files 1% similar despite different names*

```diff
@@ -120,18 +120,18 @@
                 del base_dict[key]
         for key in ["computeId"]:
             if key in base_dict and base_dict[key] is None:
                 del base_dict[key]
 
         base_dict.update(
             convert_ordered_dict_to_dict(
-                dict(
-                    componentId=self._get_component_id(),
-                    type=self.type,
-                )
+                {
+                    "componentId": self._get_component_id(),
+                    "type": self.type,
+                }
             )
         )
         return base_dict
 
 
 class DataTransfer(InternalBaseNode):
     def __init__(self, **kwargs):
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/itp_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/itp_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/ai_super_computer_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/ai_super_computer_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_internal/entities/runsettings/target_selector.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_internal/entities/runsettings/target_selector.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/identity.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/identity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/queue_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/queue_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/resource_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/resource_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/spark_resource_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/spark_resource_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job_resource_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job_resource_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_notification/notification_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_notification/notification_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/signals.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/signals.py`

 * *Files 1% similar despite different names*

```diff
@@ -187,14 +187,15 @@
 
 class CustomMonitoringSignalSchema(metaclass=PatchedSchemaMeta):
     type = StringTransformedEnum(allowed_values=MonitorSignalType.CUSTOM, required=True)
     component_id = ArmVersionedStr(azureml_type=AzureMLResourceType.COMPONENT)
     metric_thresholds = fields.List(NestedField(CustomMonitoringMetricThresholdSchema))
     input_datasets = fields.Dict(keys=fields.Str(), values=NestedField(MonitorInputDataSchema))
     alert_notification = fields.Bool()
+    data_window_size = fields.Int()
 
     @pre_dump
     def predump(self, data, **kwargs):
         from azure.ai.ml.entities._monitoring.signals import CustomMonitoringSignal
 
         if not isinstance(data, CustomMonitoringSignal):
             raise ValidationError("Cannot dump non-CustomMonitoringSignal object into CustomMonitoringSignal")
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/thresholds.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/thresholds.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/input_data.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/input_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/monitor_definition.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/monitor_definition.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/target.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/target.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/monitoring/alert_notification.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/monitoring/alert_notification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/trigger.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/trigger.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/create_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/create_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/schedule/schedule.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/schedule/schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/utils.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
-
+import copy
 import logging
 import re
 from collections import OrderedDict
 from typing import Any, Dict, Optional
 
 from marshmallow.exceptions import ValidationError
 
@@ -57,7 +57,25 @@
     if (
         "code_configuration" in data
         and data["code_configuration"].code
         and isinstance(data["code_configuration"].code, str)
         and data["code_configuration"].code.startswith(startswith)
     ):
         raise ValidationError(f"Registry reference for code_configuration.code is not supported for {caller}")
+
+
+def _resolve_group_inputs_for_component(component, **kwargs):  # pylint: disable=unused-argument
+    # Try resolve object's inputs & outputs and return a resolved new object
+    from azure.ai.ml.entities._inputs_outputs import GroupInput
+
+    result = copy.copy(component)
+
+    flatten_inputs = {}
+    for key, val in result.inputs.items():
+        if isinstance(val, GroupInput):
+            flatten_inputs.update(val.flatten(group_parameter_name=key))
+            continue
+        flatten_inputs[key] = val
+
+    # Flatten group inputs
+    result._inputs = flatten_inputs  # pylint: disable=protected-access
+    return result
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_utils/data_binding_expression.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_utils/data_binding_expression.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/feature_store_entity_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/feature_store_entity_schema.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,21 +1,26 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 
-from marshmallow import fields, validate
+from marshmallow import fields, post_dump, validate
 
 from azure.ai.ml._schema import NestedField
 from azure.ai.ml._schema.core.schema import YamlFileSchema
 
 from .data_column_schema import DataColumnSchema
 
 
 class FeatureStoreEntitySchema(YamlFileSchema):
     name = fields.Str(required=True, allow_none=False)
     version = fields.Str(required=True, allow_none=False)
+    latest_version = fields.Str(dump_only=True)
     index_columns = fields.List(NestedField(DataColumnSchema), required=True, allow_none=False)
     stage = fields.Str(validate=validate.OneOf(["Development", "Production", "Archived"]), dump_default="Development")
     description = fields.Str()
     tags = fields.Dict(keys=fields.Str(), values=fields.Str())
     properties = fields.Dict(keys=fields.Str(), values=fields.Str())
+
+    @post_dump
+    def remove_empty_values(self, data, **kwargs):  # pylint: disable=unused-argument
+        return {key: value for key, value in data.items() if value}
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store_entity/data_column_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store_entity/data_column_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/forecasting_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/forecasting_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/automl_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/automl_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/featurization_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/featurization_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/automl_vertical.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/automl_vertical.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/training_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/training_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_fixed_parameters.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_fixed_parameters.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical_limit_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical_limit_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_parameter_subspace.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_parameter_subspace.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_ner.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_ner.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification_multilabel.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/text_classification_multilabel.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_vertical.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_sweep_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/nlp_vertical/nlp_sweep_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/classification.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/classification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/forecasting.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/forecasting.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical_limit_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical_limit_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/regression.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/regression.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/table_vertical/table_vertical.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_vertical.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_vertical.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_classification.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_classification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_sweep_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_sweep_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_limit_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_limit_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_model_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_model_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_model_distribution_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_model_distribution_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/automl/image_vertical/image_object_detection.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/automl/image_vertical/image_object_detection.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/code_configuration_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/code_configuration_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/compute_binding.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/compute_binding.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_pipeline_component_deployment_configurations_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_pipeline_component_deployment_configurations_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/run_settings_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/run_settings_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/job_definition_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/job_definition_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/batch_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/pipeline_component_batch_deployment_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/pipeline_component_batch_deployment_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/batch/model_batch_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/scale_settings_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/scale_settings_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/request_logging_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/request_logging_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/liveness_probe.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/liveness_probe.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/deployment_collection_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/deployment_collection_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/oversize_data_config_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/oversize_data_config_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/event_hub_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/event_hub_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/data_collector_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/data_collector_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/resource_settings_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/resource_settings_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/payload_response_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/payload_response_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/data_asset_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/data_asset_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/request_settings_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/request_settings_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/resource_requirements_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/resource_requirements_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_deployment/online/online_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_deployment/online/online_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/intellectual_property.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/intellectual_property.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/fields.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/fields.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,41 +4,28 @@
 
 # pylint: disable=unused-argument,no-self-use,protected-access
 
 import copy
 import logging
 import os
 import re
+import traceback
 import typing
 from abc import abstractmethod
 from pathlib import Path
 from typing import List, Optional
 
 from marshmallow import RAISE, fields
 from marshmallow.exceptions import ValidationError
 from marshmallow.fields import _T, Field, Nested
-from marshmallow.utils import (
-    FieldInstanceResolutionError,
-    from_iso_datetime,
-    resolve_field_instance,
-)
+from marshmallow.utils import FieldInstanceResolutionError, from_iso_datetime, resolve_field_instance
 
-from ..._utils._arm_id_utils import (
-    AMLVersionedArmId,
-    is_ARM_id_for_resource,
-    parse_name_label,
-    parse_name_version,
-)
+from ..._utils._arm_id_utils import AMLVersionedArmId, is_ARM_id_for_resource, parse_name_label, parse_name_version
 from ..._utils._experimental import _is_warning_cached
-from ..._utils.utils import (
-    is_data_binding_expression,
-    is_valid_node_name,
-    load_file,
-    load_yaml,
-)
+from ..._utils.utils import is_data_binding_expression, is_valid_node_name, load_file, load_yaml
 from ...constants._common import (
     ARM_ID_PREFIX,
     AZUREML_RESOURCE_PROVIDER,
     BASE_PATH_CONTEXT_KEY,
     CONDA_FILE,
     DOCKER_FILE_NAME,
     EXPERIMENTAL_FIELD_MESSAGE,
@@ -47,17 +34,15 @@
     INTERNAL_REGISTRY_URI_FORMAT,
     LOCAL_COMPUTE_TARGET,
     LOCAL_PATH,
     REGISTRY_URI_FORMAT,
     RESOURCE_ID_FORMAT,
     AzureMLResourceType,
 )
-from ...entities._job.pipeline._attr_dict import (
-    try_get_non_arbitrary_attr_for_potential_attr_dict,
-)
+from ...entities._job.pipeline._attr_dict import try_get_non_arbitrary_attr_for_potential_attr_dict
 from ...exceptions import ValidationException
 from ..core.schema import PathAwareSchema
 
 module_logger = logging.getLogger(__name__)
 
 
 class StringTransformedEnum(Field):
@@ -138,16 +123,16 @@
                 result = base_path / result
 
             # for non-path string like "azureml:/xxx", OSError can be raised in either
             # resolve() or is_dir() or is_file()
             result = result.resolve()
             if (self._allow_dir and result.is_dir()) or (self._allow_file and result.is_file()):
                 return result
-        except OSError:
-            raise self.make_error("invalid_path")
+        except OSError as e:
+            raise self.make_error("invalid_path") from e
         raise self.make_error("path_not_exist", path=result.as_posix(), allow_type=self.allowed_path_type)
 
     @property
     def allowed_path_type(self) -> str:
         if self._allow_dir and self._allow_file:
             return "directory or file"
         if self._allow_dir:
@@ -253,16 +238,16 @@
             return None
         self._validate(value)
         return super(DateTimeStr, self)._serialize(value, attr, obj, **kwargs)
 
     def _validate(self, value):
         try:
             from_iso_datetime(value)
-        except Exception:
-            raise ValidationError(f"Not a valid ISO8601-formatted datetime string: {value}")
+        except Exception as e:
+            raise ValidationError(f"Not a valid ISO8601-formatted datetime string: {value}") from e
 
 
 class ArmStr(Field):
     def __init__(self, **kwargs):
         self.azureml_type = kwargs.pop("azureml_type", None)
         self.pattern = kwargs.pop("pattern", r"^azureml:.+")
         super().__init__(**kwargs)
@@ -331,15 +316,15 @@
             raise ValidationError(message=msg.format(attr))
 
         try:
             name, label = parse_name_label(arm_id)
         except ValidationException as e:
             # Schema will try to deserialize the value with all possible Schema & catch ValidationError
             # So raise ValidationError instead of ValidationException
-            raise ValidationError(e.message)
+            raise ValidationError(e.message) from e
 
         version = None
         if not label:
             name, version = parse_name_version(arm_id)
 
         if not (label or version):
             if self.allow_default_version:
@@ -436,15 +421,15 @@
             # add the validation and make sure union_fields must be subclasses or instances of
             # marshmallow.base.FieldABC
             self._union_fields = [resolve_field_instance(cls_or_instance) for cls_or_instance in union_fields]
             # TODO: make serialization/de-serialization work in the same way as json schema when is_strict is True
             self.is_strict = is_strict  # S\When True, combine fields with oneOf instead of anyOf at schema generation
         except FieldInstanceResolutionError as error:
             raise ValueError(
-                'Elements of "union_fields" must be subclasses or ' "instances of marshmallow.base.FieldABC."
+                'Elements of "union_fields" must be subclasses or instances of marshmallow.base.FieldABC.'
             ) from error
 
     @property
     def union_fields(self):
         return iter(self._union_fields)
 
     def insert_union_field(self, field):
@@ -480,16 +465,26 @@
     def _deserialize(self, value, attr, data, **kwargs):
         errors = []
         for schema in self._union_fields:
             try:
                 return schema.deserialize(value, attr, data, **kwargs)
             except ValidationError as e:
                 errors.append(e.normalized_messages())
-            except (ValidationException, FileNotFoundError, TypeError) as e:
+            except ValidationException as e:
+                # ValidationException is explicitly raised in project code so usually easy to locate with error message
                 errors.append([str(e)])
+            except (FileNotFoundError, TypeError) as e:
+                # FileNotFoundError and TypeError can be raised in system code, so we need to add more information
+                # TODO: consider if it's possible to handle those errors in their directly relative
+                #  code instead of in UnionField
+                trace = traceback.format_exc().splitlines()
+                if len(trace) >= 3:
+                    errors.append([f"{trace[-1]} from {trace[-3]} {trace[-2]}"])
+                else:
+                    errors.append([f"{e.__class__.__name__}: {e}"])
             finally:
                 # Revert base path to original path when job schema fail to deserialize job. For example, when load
                 # parallel job with component file reference starting with FILE prefix, maybe first CommandSchema will
                 # load component yaml according to AnonymousCommandComponentSchema, and YamlFileSchema will update base
                 # path. When CommandSchema fail to load, then Parallelschema will load component yaml according to
                 # AnonymousParallelComponentSchema, but base path now is incorrect, and will raise path not found error
                 # when load component yaml file.
@@ -677,16 +672,16 @@
     )
 
 
 def DistributionField(**kwargs):
     from azure.ai.ml._schema.job.distribution import (
         MPIDistributionSchema,
         PyTorchDistributionSchema,
-        TensorFlowDistributionSchema,
         RayDistributionSchema,
+        TensorFlowDistributionSchema,
     )
 
     return UnionField(
         [
             NestedField(PyTorchDistributionSchema, **kwargs),
             NestedField(TensorFlowDistributionSchema, **kwargs),
             NestedField(MPIDistributionSchema, **kwargs),
@@ -777,15 +772,15 @@
     def __init__(self, experimental_field: fields.Field, **kwargs):
         super().__init__(**kwargs)
         try:
             self._experimental_field = resolve_field_instance(experimental_field)
             self.required = experimental_field.required
         except FieldInstanceResolutionError as error:
             raise ValueError(
-                '"experimental_field" must be subclasses or ' "instances of marshmallow.base.FieldABC."
+                '"experimental_field" must be subclasses or instances of marshmallow.base.FieldABC.'
             ) from error
 
     @property
     def experimental_field(self):
         return self._experimental_field
 
     # This sets the parent for the schema and also handles nesting.
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/auto_delete_setting.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/auto_delete_setting.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/schema_meta.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/schema_meta.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/core/resource.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/core/resource.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/_on_prem_credentials.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/_on_prem_credentials.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/_on_prem.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/_on_prem.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/adls_gen1.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/adls_gen1.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/credentials.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/credentials.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_datastore/azure_storage.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_datastore/azure_storage.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint_defaults.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/batch/batch_endpoint_defaults.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_endpoint/online/online_endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_endpoint/online/online_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/identity.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/identity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/networking.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/networking.py`

 * *Files 20% similar despite different names*

```diff
@@ -3,135 +3,190 @@
 # ---------------------------------------------------------
 
 # pylint: disable=unused-argument,no-self-use,no-else-return
 
 from marshmallow import fields, EXCLUDE
 from marshmallow.decorators import post_load, pre_dump
 from azure.ai.ml._schema.core.schema_meta import PatchedSchemaMeta
-from azure.ai.ml._schema.core.fields import StringTransformedEnum
-from azure.ai.ml._schema.core.fields import NestedField
+from azure.ai.ml._schema.core.fields import StringTransformedEnum, NestedField, UnionField
 from azure.ai.ml.entities._workspace.networking import (
     ManagedNetwork,
     FqdnDestination,
     ServiceTagDestination,
     PrivateEndpointDestination,
 )
-from azure.ai.ml.constants._workspace import IsolationMode, OutboundRuleCategory, OutboundRuleType
+from azure.ai.ml.constants._workspace import IsolationMode, OutboundRuleCategory
 from azure.ai.ml._utils.utils import camel_to_snake, _snake_to_camel
 
 from azure.ai.ml._utils._experimental import experimental
 
 
 @experimental
-class DestinationSchema(metaclass=PatchedSchemaMeta):
-    service_resource_id = fields.Str()
-    subresource_target = fields.Str()
-    spark_enabled = fields.Bool()
-    service_tag = fields.Str()
-    protocol = fields.Str()
-    port_ranges = fields.Str()
+class ManagedNetworkStatusSchema(metaclass=PatchedSchemaMeta):
+    spark_ready = fields.Bool(dump_only=True)
+    status = fields.Str(dump_only=True)
 
 
 @experimental
-class ManagedNetworkStatusSchema(metaclass=PatchedSchemaMeta):
-    spark_ready = fields.Bool()
-    status = fields.Str()
+class FqdnOutboundRuleSchema(metaclass=PatchedSchemaMeta):
+    name = fields.Str(required=True)
+    type = fields.Constant("fqdn")
+    destination = fields.Str(required=True)
+    category = StringTransformedEnum(
+        allowed_values=[
+            OutboundRuleCategory.REQUIRED,
+            OutboundRuleCategory.RECOMMENDED,
+            OutboundRuleCategory.USER_DEFINED,
+        ],
+        casing_transform=camel_to_snake,
+        metadata={"description": "outbound rule category."},
+        dump_only=True,
+    )
+    status = fields.Str(dump_only=True)
+
+    @post_load
+    def createdestobject(self, data, **kwargs):
+        dest = data.get("destination")
+        category = data.get("category", OutboundRuleCategory.USER_DEFINED)
+        name = data.get("name")
+        status = data.get("status", None)
+        return FqdnDestination(name=name, destination=dest, category=_snake_to_camel(category), status=status)
+
+
+@experimental
+class ServiceTagDestinationSchema(metaclass=PatchedSchemaMeta):
+    service_tag = fields.Str(required=True)
+    protocol = fields.Str(required=True)
+    port_ranges = fields.Str(required=True)
 
 
 @experimental
-class OutboundRuleSchema(metaclass=PatchedSchemaMeta):
+class ServiceTagOutboundRuleSchema(metaclass=PatchedSchemaMeta):
     name = fields.Str(required=True)
-    type = StringTransformedEnum(
-        allowed_values=[OutboundRuleType.FQDN, OutboundRuleType.PRIVATE_ENDPOINT, OutboundRuleType.SERVICE_TAG],
+    type = fields.Constant("service_tag")
+    destination = NestedField(ServiceTagDestinationSchema, required=True)
+    category = StringTransformedEnum(
+        allowed_values=[
+            OutboundRuleCategory.REQUIRED,
+            OutboundRuleCategory.RECOMMENDED,
+            OutboundRuleCategory.USER_DEFINED,
+        ],
         casing_transform=camel_to_snake,
-        metadata={"description": "outbound rule type."},
+        metadata={"description": "outbound rule category."},
+        dump_only=True,
     )
-    destination = fields.Raw(required=True)
+    status = fields.Str(dump_only=True)
+
+    @pre_dump
+    def predump(self, data, **kwargs):
+        data.destination = self.service_tag_dest2dict(data.service_tag, data.protocol, data.port_ranges)
+        return data
+
+    @post_load
+    def createdestobject(self, data, **kwargs):
+        dest = data.get("destination")
+        category = data.get("category", OutboundRuleCategory.USER_DEFINED)
+        name = data.get("name")
+        status = data.get("status", None)
+        return ServiceTagDestination(
+            name=name,
+            service_tag=dest["service_tag"],
+            protocol=dest["protocol"],
+            port_ranges=dest["port_ranges"],
+            category=_snake_to_camel(category),
+            status=status,
+        )
+
+    def service_tag_dest2dict(self, service_tag, protocol, port_ranges):
+        service_tag_dest = {}
+        service_tag_dest["service_tag"] = service_tag
+        service_tag_dest["protocol"] = protocol
+        service_tag_dest["port_ranges"] = port_ranges
+        return service_tag_dest
+
+
+@experimental
+class PrivateEndpointDestinationSchema(metaclass=PatchedSchemaMeta):
+    service_resource_id = fields.Str(required=True)
+    subresource_target = fields.Str(required=True)
+    spark_enabled = fields.Bool(required=True)
+
+
+@experimental
+class PrivateEndpointOutboundRuleSchema(metaclass=PatchedSchemaMeta):
+    name = fields.Str(required=True)
+    type = fields.Constant("private_endpoint")
+    destination = NestedField(PrivateEndpointDestinationSchema, required=True)
     category = StringTransformedEnum(
         allowed_values=[
             OutboundRuleCategory.REQUIRED,
             OutboundRuleCategory.RECOMMENDED,
             OutboundRuleCategory.USER_DEFINED,
         ],
         casing_transform=camel_to_snake,
         metadata={"description": "outbound rule category."},
+        dump_only=True,
     )
     status = fields.Str(dump_only=True)
 
     @pre_dump
     def predump(self, data, **kwargs):
-        if data and isinstance(data, FqdnDestination):
-            data.destination = self.fqdn_dest2dict(data.destination)
-        if data and isinstance(data, PrivateEndpointDestination):
-            data.destination = self.pe_dest2dict(data.service_resource_id, data.subresource_target, data.spark_enabled)
-        if data and isinstance(data, ServiceTagDestination):
-            data.destination = self.service_tag_dest2dict(data.service_tag, data.protocol, data.port_ranges)
+        data.destination = self.pe_dest2dict(data.service_resource_id, data.subresource_target, data.spark_enabled)
         return data
 
     @post_load
     def createdestobject(self, data, **kwargs):
-        dest = data.get("destination", False)
+        dest = data.get("destination")
         category = data.get("category", OutboundRuleCategory.USER_DEFINED)
-        name = data.get("name", None)
+        name = data.get("name")
         status = data.get("status", None)
-        if dest:
-            if isinstance(dest, str):
-                return FqdnDestination(name=name, destination=dest, category=_snake_to_camel(category), status=status)
-            else:
-                if dest.get("subresource_target", False):
-                    return PrivateEndpointDestination(
-                        name=name,
-                        service_resource_id=dest["service_resource_id"],
-                        subresource_target=dest["subresource_target"],
-                        spark_enabled=dest["spark_enabled"],
-                        category=_snake_to_camel(category),
-                        status=status,
-                    )
-            return ServiceTagDestination(
-                name=name,
-                service_tag=dest["service_tag"],
-                protocol=dest["protocol"],
-                port_ranges=dest["port_ranges"],
-                category=_snake_to_camel(category),
-                status=status,
-            )
-
-    def fqdn_dest2dict(self, fqdndest):
-        res = fqdndest
-        return res
+        return PrivateEndpointDestination(
+            name=name,
+            service_resource_id=dest["service_resource_id"],
+            subresource_target=dest["subresource_target"],
+            spark_enabled=dest["spark_enabled"],
+            category=_snake_to_camel(category),
+            status=status,
+        )
 
     def pe_dest2dict(self, service_resource_id, subresource_target, spark_enabled):
         pedest = {}
         pedest["service_resource_id"] = service_resource_id
         pedest["subresource_target"] = subresource_target
         pedest["spark_enabled"] = spark_enabled
         return pedest
 
-    def service_tag_dest2dict(self, service_tag, protocol, port_ranges):
-        service_tag_dest = {}
-        service_tag_dest["service_tag"] = service_tag
-        service_tag_dest["protocol"] = protocol
-        service_tag_dest["port_ranges"] = port_ranges
-        return service_tag_dest
-
 
 @experimental
 class ManagedNetworkSchema(metaclass=PatchedSchemaMeta):
     isolation_mode = StringTransformedEnum(
         allowed_values=[
             IsolationMode.DISABLED,
             IsolationMode.ALLOW_INTERNET_OUTBOUND,
             IsolationMode.ALLOW_ONLY_APPROVED_OUTBOUND,
         ],
         casing_transform=camel_to_snake,
         metadata={"description": "isolation mode for the workspace managed network."},
     )
-    outbound_rules = fields.List(NestedField(OutboundRuleSchema, allow_none=False, unknown=EXCLUDE), allow_none=True)
-    network_id = fields.Str(required=False)
-    status = NestedField(ManagedNetworkStatusSchema, dump_only=True)
+    outbound_rules = fields.List(
+        UnionField(
+            [
+                NestedField(PrivateEndpointOutboundRuleSchema, allow_none=False, unknown=EXCLUDE),
+                NestedField(ServiceTagOutboundRuleSchema, allow_none=False, unknown=EXCLUDE),
+                NestedField(
+                    FqdnOutboundRuleSchema, allow_none=False, unknown=EXCLUDE
+                ),  # this needs to be last since otherwise union field with match destination as a string
+            ],
+            allow_none=False,
+            is_strict=True,
+        ),
+        allow_none=True,
+    )
+    network_id = fields.Str(required=False, dump_only=True)
+    status = NestedField(ManagedNetworkStatusSchema, allow_none=False, unknown=EXCLUDE)
 
     @post_load
     def make(self, data, **kwargs):
         outbound_rules = data.get("outbound_rules", False)
         if outbound_rules:
             return ManagedNetwork(_snake_to_camel(data["isolation_mode"]), outbound_rules)
         else:
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/workspace.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/workspace.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/private_endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/private_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/endpoint_connection.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/endpoint_connection.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/customer_managed_key.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/customer_managed_key.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/workspace_connection.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/workspace_connection.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/workspace/connections/credentials.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/workspace/connections/credentials.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_termination.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_termination.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_fields_provider.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_fields_provider.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_objective.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_objective.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/sweep_sampling_algorithm.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/sweep_sampling_algorithm.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/parameterized_sweep.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/parameterized_sweep.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/choice.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/choice.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/randint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/randint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/normal.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/normal.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_sweep/search_space/uniform.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_sweep/search_space/uniform.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_spark_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_spark_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/automl_node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/automl_node.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_import_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_import_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/control_flow_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/control_flow_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_command_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_command_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_datatransfer_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_datatransfer_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_job_io.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_job_io.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/condition_node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/condition_node.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/component_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/component_job.py`

 * *Files 1% similar despite different names*

```diff
@@ -201,15 +201,15 @@
         # parse inputs/outputs
         data = parse_inputs_outputs(data)
         try:
             command_node = command(**data)
         except ValidationException as e:
             # It may raise ValidationError during initialization, command._validate_io e.g. raise ValidationError
             # instead in marshmallow function, so it won't break SchemaValidatable._schema_validate
-            raise ValidationError(e.message)
+            raise ValidationError(e.message) from e
         return command_node
 
     @pre_dump
     def resolve_inputs_outputs(self, job, **kwargs):
         return _resolve_inputs_outputs(job)
 
 
@@ -367,15 +367,15 @@
         # parse inputs/outputs
         data = parse_inputs_outputs(data)
         try:
             spark_node = spark(**data)
         except ValidationException as e:
             # It may raise ValidationError during initialization, command._validate_io e.g. raise ValidationError
             # instead in marshmallow function, so it won't break SchemaValidatable._schema_validate
-            raise ValidationError(e.message)
+            raise ValidationError(e.message) from e
         return spark_node
 
     @pre_dump
     def resolve_inputs_outputs(self, job, **kwargs):
         return _resolve_inputs_outputs(job)
 
 
@@ -410,15 +410,15 @@
         # parse inputs/outputs
         data = parse_inputs_outputs(data)
         try:
             data_transfer_node = copy_data(**data)
         except ValidationException as e:
             # It may raise ValidationError during initialization, data_transfer._validate_io e.g. raise ValidationError
             # instead in marshmallow function, so it won't break SchemaValidatable._schema_validate
-            raise ValidationError(e.message)
+            raise ValidationError(e.message) from e
         return data_transfer_node
 
     @pre_dump
     def resolve_inputs_outputs(self, job, **kwargs):
         return _resolve_inputs_outputs(job)
 
 
@@ -461,15 +461,15 @@
         # parse inputs/outputs
         data = parse_inputs_outputs(data)
         try:
             data_transfer_node = import_data(**data)
         except ValidationException as e:
             # It may raise ValidationError during initialization, data_transfer._validate_io e.g. raise ValidationError
             # instead in marshmallow function, so it won't break SchemaValidatable._schema_validate
-            raise ValidationError(e.message)
+            raise ValidationError(e.message) from e
         return data_transfer_node
 
     @pre_dump
     def resolve_inputs_outputs(self, job, **kwargs):
         return _resolve_inputs_outputs(job)
 
 
@@ -512,13 +512,13 @@
         # parse inputs/outputs
         data = parse_inputs_outputs(data)
         try:
             data_transfer_node = export_data(**data)
         except ValidationException as e:
             # It may raise ValidationError during initialization, data_transfer._validate_io e.g. raise ValidationError
             # instead in marshmallow function, so it won't break SchemaValidatable._schema_validate
-            raise ValidationError(e.message)
+            raise ValidationError(e.message) from e
         return data_transfer_node
 
     @pre_dump
     def resolve_inputs_outputs(self, job, **kwargs):
         return _resolve_inputs_outputs(job)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_parallel_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_parallel_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/pipeline/pipeline_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/pipeline/pipeline_component.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
-import copy
 from copy import deepcopy
 
 import yaml
 from marshmallow import INCLUDE, fields, post_load, pre_dump
 
+from azure.ai.ml._schema._utils.utils import _resolve_group_inputs_for_component
 from azure.ai.ml._schema.assets.asset import AnonymousAssetSchema
 from azure.ai.ml._schema.component.component import ComponentSchema
 from azure.ai.ml._schema.component.input_output import OutputPortSchema, PrimitiveOutputSchema
 from azure.ai.ml._schema.core.fields import (
     ArmVersionedStr,
     FileRefField,
     NestedField,
@@ -22,42 +22,42 @@
     TypeSensitiveUnionField,
     UnionField,
 )
 from azure.ai.ml._schema.pipeline.automl_node import AutoMLNodeSchema
 from azure.ai.ml._schema.pipeline.component_job import (
     BaseNodeSchema,
     CommandSchema,
+    DataTransferCopySchema,
+    DataTransferExportSchema,
+    DataTransferImportSchema,
     ImportSchema,
     ParallelSchema,
     SparkSchema,
     SweepSchema,
-    DataTransferCopySchema,
-    DataTransferImportSchema,
-    DataTransferExportSchema,
     _resolve_inputs_outputs,
 )
 from azure.ai.ml._schema.pipeline.condition_node import ConditionNodeSchema
 from azure.ai.ml._schema.pipeline.control_flow_job import DoWhileSchema, ParallelForSchema
 from azure.ai.ml._schema.pipeline.pipeline_command_job import PipelineCommandJobSchema
-from azure.ai.ml._schema.pipeline.pipeline_import_job import PipelineImportJobSchema
-from azure.ai.ml._schema.pipeline.pipeline_parallel_job import PipelineParallelJobSchema
-from azure.ai.ml._schema.pipeline.pipeline_spark_job import PipelineSparkJobSchema
 from azure.ai.ml._schema.pipeline.pipeline_datatransfer_job import (
     PipelineDataTransferCopyJobSchema,
-    PipelineDataTransferImportJobSchema,
     PipelineDataTransferExportJobSchema,
+    PipelineDataTransferImportJobSchema,
 )
+from azure.ai.ml._schema.pipeline.pipeline_import_job import PipelineImportJobSchema
+from azure.ai.ml._schema.pipeline.pipeline_parallel_job import PipelineParallelJobSchema
+from azure.ai.ml._schema.pipeline.pipeline_spark_job import PipelineSparkJobSchema
 from azure.ai.ml._utils.utils import is_private_preview_enabled
 from azure.ai.ml.constants._common import BASE_PATH_CONTEXT_KEY, AzureMLResourceType
 from azure.ai.ml.constants._component import (
-    NodeType,
+    CONTROL_FLOW_TYPES,
     ComponentSource,
     ControlFlowType,
-    CONTROL_FLOW_TYPES,
     DataTransferTaskType,
+    NodeType,
 )
 
 
 class NodeNameStr(PipelineNodeNameStr):
     def _get_field_name(self) -> str:
         return "Pipeline node"
 
@@ -122,19 +122,19 @@
     )
     return pipeline_job_field
 
 
 def _post_load_pipeline_jobs(context, data: dict) -> dict:
     """Silently convert Job in pipeline jobs to node."""
     from azure.ai.ml.entities._builders import parse_inputs_outputs
+    from azure.ai.ml.entities._builders.condition_node import ConditionNode
     from azure.ai.ml.entities._builders.do_while import DoWhile
     from azure.ai.ml.entities._builders.parallel_for import ParallelFor
     from azure.ai.ml.entities._job.automl.automl_job import AutoMLJob
     from azure.ai.ml.entities._job.pipeline._component_translatable import ComponentTranslatableMixin
-    from azure.ai.ml.entities._builders.condition_node import ConditionNode
 
     # parse inputs/outputs
     data = parse_inputs_outputs(data)
     # convert JobNode to Component here
     jobs = data.get("jobs", {})
 
     for key, job_instance in jobs.items():
@@ -179,22 +179,14 @@
                 job_instance._source = job_instance.component._source
             jobs[key] = job_instance
         # update job instance name to key
         job_instance.name = key
     return data
 
 
-def _resolve_pipeline_component_inputs(component, **kwargs):  # pylint: disable=unused-argument
-    # Try resolve object's inputs & outputs and return a resolved new object
-    result = copy.copy(component)
-    # Flatten group inputs
-    result._inputs = component._get_flattened_inputs()
-    return result
-
-
 class PipelineComponentSchema(ComponentSchema):
     type = StringTransformedEnum(allowed_values=[NodeType.PIPELINE])
     jobs = PipelineJobsField()
 
     # primitive output is only supported for command component & pipeline component
     outputs = fields.Dict(
         keys=fields.Str(),
@@ -202,18 +194,14 @@
             [
                 NestedField(PrimitiveOutputSchema, unknown=INCLUDE),
                 NestedField(OutputPortSchema),
             ]
         ),
     )
 
-    @pre_dump
-    def resolve_pipeline_component_inputs(self, component, **kwargs):  # pylint: disable=unused-argument, no-self-use
-        return _resolve_pipeline_component_inputs(component, **kwargs)
-
     @post_load
     def make(self, data, **kwargs):  # pylint: disable=unused-argument
         return _post_load_pipeline_jobs(self.context, data)
 
 
 class RestPipelineComponentSchema(PipelineComponentSchema):
     """When component load from rest, won't validate on name since there might
@@ -253,15 +241,15 @@
 
         Call AnonymousPipelineComponent schema to serialize. This
         function is overwrite because we need Pipeline can be dumped.
         """
         # Update base_path to parent path of component file.
         component_schema_context = deepcopy(self.context)
         # pylint: disable=no-member
-        value = _resolve_pipeline_component_inputs(value)
+        value = _resolve_group_inputs_for_component(value)
         return _AnonymousPipelineComponentSchema(context=component_schema_context)._serialize(value, **kwargs)
 
     def _deserialize(self, value, attr, data, **kwargs):
         # Get component info from component yaml file.
         data = super()._deserialize(value, attr, data, **kwargs)
         component_dict = yaml.safe_load(data)
         source_path = self.context[BASE_PATH_CONTEXT_KEY] / value
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/import_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/import_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/identity.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/identity.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/services.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/services.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/base_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/base_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parallel_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parallel_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_output_fields_provider.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_output_fields_provider.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_port.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_port.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_spark.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_spark.py`

 * *Files 4% similar despite different names*

```diff
@@ -94,34 +94,42 @@
         no_duplicates("files", value)
 
     @validates("archives")
     def no_duplicate_archives(self, value):
         no_duplicates("archives", value)
 
     @pre_load
-    def deserialize_field_names(self, data, **kwargs):
+    def map_conf_field_names(self, data, **kwargs):
+        """Map the field names in the conf dictionary.
+        This function must be called after YamlFileSchema.load_from_file.
+        Given marshmallow executes the pre_load functions in the alphabetical order (marshmallow\\schema.py:L166,
+        functions will be checked in alphabetical order when inject to cls._hooks), we must make sure the function
+        name is alphabetically after "load_from_file".
+        """
+        # TODO: it's dangerous to depend on an alphabetical order, we'd better move related logic out of Schema.
         conf = data["conf"] if "conf" in data else None
         if conf is not None:
             for field_key, dict_key in CONF_KEY_MAP.items():
                 value = conf.get(dict_key, None)
                 if dict_key in conf and value is not None:
                     del conf[dict_key]
                     conf[field_key] = value
             data["conf"] = conf
         return data
 
     @post_dump(pass_original=True)
     def serialize_field_names(self, data: Dict[str, Any], original_data: Dict[str, Any], **kwargs):
         conf = data["conf"] if "conf" in data else {}
-        if conf is not None or original_data.conf is not None:
+        if original_data.conf is not None and conf is not None:
             for field_name, value in original_data.conf.items():
                 if field_name not in conf:
                     if isinstance(value, str) and value.isdigit():
                         value = int(value)
                     conf[field_name] = value
+        if conf is not None:
             for field_name, dict_name in CONF_KEY_MAP.items():
                 val = conf.get(field_name, None)
                 if field_name in conf and val is not None:
                     if isinstance(val, str) and val.isdigit():
                         val = int(val)
                     del conf[field_name]
                     conf[dict_name] = val
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_command.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_command.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/job_output.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/job_output.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/spark_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/spark_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/input_output_entry.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/input_output_entry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/parameterized_parallel.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/parameterized_parallel.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/creation_context.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/creation_context.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/command_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/command_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/data_transfer_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/data_transfer_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/distribution.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/distribution.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/job/job_limits.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/job/job_limits.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/aml_compute_node_info.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/aml_compute_node_info.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/usage.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/usage.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/kubernetes_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/kubernetes_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/aml_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/aml_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/synapsespark_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/synapsespark_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/custom_applications.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/custom_applications.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/schedule.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/setup_scripts.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/setup_scripts.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/vm_size.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/vm_size.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/compute_instance.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/compute_instance.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/compute/virtual_machine_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/compute/virtual_machine_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/model.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/model.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/data.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/artifact.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/artifact.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/workspace_asset_reference.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/workspace_asset_reference.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/federated_learning_silo.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/federated_learning_silo.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/code_asset.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/code_asset.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/environment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/environment.py`

 * *Files 1% similar despite different names*

```diff
@@ -124,15 +124,15 @@
         from azure.ai.ml.entities._assets import Environment
 
         try:
             obj = Environment(base_path=self.context[BASE_PATH_CONTEXT_KEY], **data)
         except FileNotFoundError as e:
             # Environment.__init__() will raise FileNotFoundError if build.path is not found when trying to calculate
             # the hash for anonymous. Raise ValidationError instead to collect all errors in schema validation.
-            raise ValidationError("Environment file not found: {}".format(e))
+            raise ValidationError("Environment file not found: {}".format(e)) from e
         return obj
 
 
 class EnvironmentSchema(_BaseEnvironmentSchema):
     name = fields.Str(required=True)
     version = VersionField()
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/asset.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/asset.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/route.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/route.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/base_environment_source.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/base_environment_source.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_package_input.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_package_input.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/model_package.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/model_package.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/inference_server.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/inference_server.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/assets/package/online_inference_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/assets/package/online_inference_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/parallel_task.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/parallel_task.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/parallel_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/parallel_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/spark_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/spark_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/data_transfer_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/data_transfer_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/import_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/import_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/automl_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/automl_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/resource.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/resource.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/input_output.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/input_output.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/command_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/command_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/component/component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/component/component.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,25 +1,26 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
-from marshmallow import fields, post_dump, pre_load, pre_dump
+from marshmallow import fields, post_dump, pre_dump, pre_load
 
 from azure.ai.ml._schema.component.input_output import InputPortSchema, OutputPortSchema, ParameterSchema
 from azure.ai.ml._schema.core.fields import (
     ArmVersionedStr,
     ExperimentalField,
     NestedField,
     PythonFuncNameStr,
     UnionField,
 )
 from azure.ai.ml._schema.core.intellectual_property import IntellectualPropertySchema
-from azure.ai.ml.constants._common import AzureMLResourceType
 from azure.ai.ml._utils.utils import is_private_preview_enabled
+from azure.ai.ml.constants._common import AzureMLResourceType
 
+from .._utils.utils import _resolve_group_inputs_for_component
 from ..assets.asset import AssetSchema
 from ..core.fields import RegistryStr
 
 
 class ComponentNameStr(PythonFuncNameStr):
     def _get_field_name(self):
         return "Component"
@@ -84,7 +85,11 @@
                 input_type = input_value.get("type", None)
                 if isinstance(input_type, str) and input_type.lower() == "float":
                     # Convert number to string to avoid precision issue
                     for key in ["default", "min", "max"]:
                         if input_value.get(key, None) is not None:
                             input_value[key] = str(input_value[key])
         return data
+
+    @pre_dump
+    def flatten_group_inputs(self, data, **kwargs):  # pylint: disable=unused-argument, no-self-use
+        return _resolve_group_inputs_for_component(data)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/featureset_spec_metadata_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/featureset_spec_metadata_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/timestamp_column_metadata_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/timestamp_column_metadata_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/delay_metadata_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/delay_metadata_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/source_metadata_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/source_metadata_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/featureset_spec_properties_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/featureset_spec_properties_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_set_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_set_schema.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,24 +1,29 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=unused-argument,no-self-use
 
-from marshmallow import fields, validate
+from marshmallow import fields, post_dump, validate
 
 from azure.ai.ml._schema import NestedField
 from azure.ai.ml._schema.core.schema import YamlFileSchema
 
 from .feature_set_specification_schema import FeatureSetSpecificationSchema
 from .materialization_settings_schema import MaterializationSettingsSchema
 
 
 class FeatureSetSchema(YamlFileSchema):
     name = fields.Str(required=True, allow_none=False)
     version = fields.Str(required=True, allow_none=False)
+    latest_version = fields.Str(dump_only=True)
     specification = NestedField(FeatureSetSpecificationSchema, required=True, allow_none=False)
     entities = fields.List(fields.Str, required=True, allow_none=False)
     stage = fields.Str(validate=validate.OneOf(["Development", "Production", "Archived"]), dump_default="Development")
     description = fields.Str()
     tags = fields.Dict(keys=fields.Str(), values=fields.Str())
     materialization_settings = NestedField(MaterializationSettingsSchema)
+
+    @post_dump
+    def remove_empty_values(self, data, **kwargs):  # pylint: disable=unused-argument
+        return {key: value for key, value in data.items() if value}
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_transformation_code_metadata_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_transformation_code_metadata_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/feature_set_specification_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/feature_set_specification_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_set/materialization_settings_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_set/materialization_settings_schema.py`

 * *Files 11% similar despite different names*

```diff
@@ -23,15 +23,15 @@
 
 
 class MaterializationSettingsSchema(metaclass=PatchedSchemaMeta):
     schedule = NestedField(RecurrenceTriggerSchema)
     notification = NestedField(NotificationSchema)
     resource = NestedField(MaterializationComputeResourceSchema)
     spark_configuration = fields.Dict()
-    offline_enabled = fields.Boolean(required=True, allow_none=False)
-    online_enabled = fields.Boolean(required=True, allow_none=False)
+    offline_enabled = fields.Boolean()
+    online_enabled = fields.Boolean()
 
     @post_load
     def make(self, data, **kwargs):
         from azure.ai.ml.entities._feature_set.materialization_settings import MaterializationSettings
 
         return MaterializationSettings(**data)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/registry.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/registry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/registry_region_arm_details.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/registry_region_arm_details.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/system_created_storage_account.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/system_created_storage_account.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/util.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/util.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/registry/system_created_acr_account.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/registry/system_created_acr_account.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/feature_store_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/feature_store_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/materialization_store_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/materialization_store_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_feature_store/compute_runtime_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_feature_store/compute_runtime_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/mltable_metadata_path_schemas.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/mltable_metadata_path_schemas.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data/mltable_metadata_schema.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data/mltable_metadata_schema.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/data_import.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/data_import.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_schema/_data_import/schedule.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_schema/_data_import/schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/logging_handler.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/logging_handler.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/activity.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/activity.py`

 * *Files 0% similar despite different names*

```diff
@@ -162,19 +162,19 @@
     :type activity_name: str
     :param activity_type: One of PUBLICAPI, INTERNALCALL, or CLIENTPROXY which represent an incoming API call,
         an internal (function) call, or an outgoing API call. If not specified, INTERNALCALL is used.
     :type activity_type: str
     :param custom_dimensions: The custom properties of the activity.
     :type custom_dimensions: dict
     """
-    activity_info = dict(
-        activity_id=str(uuid.uuid4()),
-        activity_name=activity_name,
-        activity_type=activity_type,
-    )
+    activity_info = {
+        "activity_id": str(uuid.uuid4()),
+        "activity_name": activity_name,
+        "activity_type": activity_type,
+    }
     custom_dimensions = custom_dimensions or {}
     custom_dimensions.update({"client_request_id": str(uuid4())})
     activity_info.update(custom_dimensions)
 
     start_time = datetime.utcnow()
     completion_status = ActivityCompletionStatus.SUCCESS
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_telemetry/_customtraceback.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_telemetry/_customtraceback.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_credentials.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_credentials.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_validation.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_validation.py`

 * *Files 0% similar despite different names*

```diff
@@ -13,15 +13,14 @@
 from pathlib import Path
 from typing import List, Optional
 
 import msrest
 import pydash
 import strictyaml
 from marshmallow import Schema, ValidationError
-from strictyaml.ruamel.scanner import ScannerError
 
 from .._schema import PathAwareSchema
 from .._vendor.azure_resources.models import Deployment, DeploymentProperties, DeploymentValidateResult, ErrorResponse
 from ..constants._common import BASE_PATH_CONTEXT_KEY, OperationStatus
 from ..entities._job.pipeline._attr_dict import try_get_non_arbitrary_attr_for_potential_attr_dict
 from ..entities._util import convert_ordered_dict_to_dict, decorate_validation_error
 from ..exceptions import ErrorCategory, ErrorTarget, ValidationException
@@ -255,15 +254,15 @@
         :rtype: MutableValidationResult
         """
         # pylint: disable=logging-not-lazy
         if raise_error is False:
             return self
 
         if self._warnings:
-            module_logger.info("Warnings: %s" % str(self._warnings))
+            module_logger.warning("Warnings: %s" % str(self._warnings))
 
         if not self.passed:
             message = (
                 decorate_validation_error(
                     schema=schema.__class__,
                     pretty_error=self.__repr__(),
                     additional_message=additional_message,
@@ -381,15 +380,15 @@
                 json.dumps(e.messages, indent=4),
             )
             raise ValidationException(
                 message=msg,
                 no_personal_data_message=str(e),
                 target=cls._get_validation_error_target(),
                 error_category=ErrorCategory.USER_ERROR,
-            )
+            ) from e
 
     @classmethod
     def _create_schema_for_validation(cls, context) -> PathAwareSchema:
         """Create a schema of the resource with specific context. Should be overridden by subclass.
 
         return: The schema of the resource.
         return type: PathAwareSchema. PathAwareSchema will add marshmallow.Schema as super class on runtime.
@@ -628,15 +627,15 @@
 
         return self._resolve_recursively(attrs, Path(source_path))
 
     def _resolve_recursively(self, attrs: List[str], source_path: Path):
         with open(source_path, encoding="utf-8") as f:
             try:
                 loaded_yaml = strictyaml.load(f.read())
-            except (ScannerError, strictyaml.exceptions.StrictYAMLError) as e:
+            except Exception as e:  # pylint: disable=broad-except
                 msg = "Can't load source file %s as a strict yaml:\n%s" % (source_path, str(e))
                 module_logger.debug(msg)
                 return None, None
 
         while attrs:
             attr = attrs[-1]
             if loaded_yaml.is_mapping() and attr in loaded_yaml:
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_load_functions.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_load_functions.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_mixins.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_mixins.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_validate_funcs.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_validate_funcs.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_system_data.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_system_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_util.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_util.py`

 * *Files 0% similar despite different names*

```diff
@@ -132,23 +132,23 @@
     for override in params_override:
         if CommonYamlFields.TYPE in override:
             return override[CommonYamlFields.TYPE]
     return None
 
 
 def is_compute_in_override(params_override: Optional[list] = None) -> bool:
-    return any([EndpointYamlFields.COMPUTE in param for param in params_override])
+    return any(EndpointYamlFields.COMPUTE in param for param in params_override)
 
 
 def load_from_dict(schema: Any, data: Dict, context: Dict, additional_message: str = "", **kwargs):
     try:
         return schema(context=context).load(data, **kwargs)
     except ValidationError as e:
         pretty_error = json.dumps(e.normalized_messages(), indent=2)
-        raise ValidationError(decorate_validation_error(schema, pretty_error, additional_message))
+        raise ValidationError(decorate_validation_error(schema, pretty_error, additional_message)) from e
 
 
 def decorate_validation_error(schema: Any, pretty_error: str, additional_message: str = "") -> str:
     ref_doc_link_error_msg = REF_DOC_ERROR_MESSAGE_MAP.get(schema, "")
     if ref_doc_link_error_msg:
         additional_message += f"\n{ref_doc_link_error_msg}"
     additional_message += (
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_resource.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_resource.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_notification/notification.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_notification/notification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/feature_store_entity.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/feature_store_entity.py`

 * *Files 1% similar despite different names*

```diff
@@ -58,15 +58,15 @@
         super().__init__(
             name=name,
             version=version,
             description=description,
             tags=tags,
             **kwargs,
         )
-        if stage not in ["Development", "Production", "Archived"]:
+        if stage and stage not in ["Development", "Production", "Archived"]:
             msg = f"Stage must be Development, Production, or Archived, found {stage}"
             raise ValidationException(
                 message=msg,
                 no_personal_data_message=msg,
                 error_type=ValidationErrorType.INVALID_VALUE,
                 target=ErrorTarget.FEATURE_STORE_ENTITY,
                 error_category=ErrorCategory.USER_ERROR,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/data_column.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/data_column.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store_entity/data_column_type.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store_entity/data_column_type.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/registry.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/registry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/registry_support_classes.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/registry_support_classes.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_registry/util.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_registry/util.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/signals.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/signals.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
 
-from typing import Dict, List, Union
+from typing import Dict, List, Optional, Union
 
 from typing_extensions import Literal
 
 from azure.ai.ml.entities._mixins import RestTranslatableMixin
 from azure.ai.ml._restclient.v2023_04_01_preview.models import (
     MonitoringSignalBase as RestMonitoringSignalBase,
     DataDriftMonitoringSignal as RestMonitoringDataDriftSignal,
@@ -538,55 +538,64 @@
             if not obj.mode or (obj.mode and obj.mode == MonitoringNotificationMode.DISABLED)
             else MonitoringNotificationMode.ENABLED,
         )
 
 
 @experimental
 class CustomMonitoringSignal(RestTranslatableMixin):
-    """Feature attribution drift signal
+    """Custom signal
 
     :ivar type: The type of the signal
     :vartype type: str
     :param input_datasets: Diction of input datasets for monitoring.
         Key is the component input port name, value is the data asset.
     :type input_datasets: Dict[str, ~azure.ai.ml.entities.MonitorInputData]
     :param metric_thresholds :A list of metrics to calculate and their
         associated thresholds
     :type metric_thresholds: List[~azure.ai.ml.entities.CustomMonitoringMetricThreshold]
     :param alert_enabled: The current notification mode for this signal
     :type alert_enabled: bool
     :param component_id: ARM ID of the component resource used to
         calculate the custom metrics.
     :type component_id: str
+    :param data_window_size: The number of days a single monitor looks back
+        over the target
+    :type data_window_size: int
     """
 
     def __init__(
         self,
         *,
         input_datasets: Dict[str, MonitorInputData] = None,
         metric_thresholds: List[CustomMonitoringMetricThreshold],
         component_id: str,
         alert_enabled: bool = True,
+        data_window_size: Optional[int] = None,
     ):
         self.type = MonitorSignalType.CUSTOM
         self.input_datasets = input_datasets
         self.metric_thresholds = metric_thresholds
         self.component_id = component_id
         self.alert_enabled = alert_enabled
+        self.data_window_size = data_window_size
 
     def _to_rest_object(self, **kwargs) -> RestCustomMonitoringSignal:  # pylint:disable=unused-argument
+        default_data_window_size = kwargs.get("default_data_window_size")
         return RestCustomMonitoringSignal(
             component_id=self.component_id,
             metric_thresholds=[threshold._to_rest_object() for threshold in self.metric_thresholds],
             input_assets={
                 input_name: input_value._to_rest_object() for input_name, input_value in self.input_datasets.items()
             }
             if self.input_datasets
             else None,
             mode=MonitoringNotificationMode.ENABLED if self.alert_enabled else MonitoringNotificationMode.DISABLED,
+            lookback_period=to_iso_duration_format_days(self.data_window_size)
+            if self.data_window_size
+            else default_data_window_size,
         )
 
     @classmethod
     def _from_rest_object(cls, obj: RestCustomMonitoringSignal) -> "CustomMonitoringSignal":
         return cls(
             input_datasets={
                 input_name: MonitorInputData._from_rest_object(input_value)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/thresholds.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/thresholds.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/schedule.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/input_data.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/input_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/target.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/target.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_monitoring/alert_notification.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_monitoring/alert_notification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/compute.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
 
-from abc import abstractclassmethod
+from abc import abstractmethod
 from os import PathLike
 from pathlib import Path
 from typing import IO, AnyStr, Dict, Optional, Union
 
 from azure.ai.ml._restclient.v2022_10_01_preview.models import ComputeResource
 from azure.ai.ml._schema.compute.compute import ComputeSchema
 from azure.ai.ml._utils.utils import dump_yaml_to_file
@@ -121,15 +121,16 @@
         compute_type = obj.properties.compute_type.lower() if obj.properties.compute_type else None
 
         class_type = mapping.get(compute_type, None)
         if class_type:
             return class_type._load_from_rest(obj)
         return UnsupportedCompute._load_from_rest(obj)
 
-    @abstractclassmethod
+    @classmethod
+    @abstractmethod
     def _load_from_rest(cls, rest_obj: ComputeResource) -> "Compute":
         pass
 
     def _set_full_subnet_name(self, subscription_id: str, rg: str) -> None:
         pass
 
     def dump(self, dest: Union[str, PathLike, IO[AnyStr]], **kwargs) -> None:
@@ -190,15 +191,16 @@
         raise ValidationException(
             message=msg,
             target=ErrorTarget.COMPUTE,
             no_personal_data_message=msg,
             error_category=ErrorCategory.USER_ERROR,
         )
 
-    @abstractclassmethod
+    @classmethod
+    @abstractmethod
     def _load_from_dict(cls, data: Dict, context: Dict, **kwargs) -> "Compute":
         pass
 
 
 class NetworkSettings:
     def __init__(
         self,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_vm_size.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_vm_size.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/unsupported_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/unsupported_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/kubernetes_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/kubernetes_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/aml_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/aml_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/synapsespark_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/synapsespark_compute.py`

 * *Files 20% similar despite different names*

```diff
@@ -15,32 +15,42 @@
 from azure.ai.ml.constants._compute import ComputeType
 from azure.ai.ml.entities import Compute
 from azure.ai.ml.entities._credentials import IdentityConfiguration
 from azure.ai.ml.entities._util import load_from_dict
 
 
 class AutoScaleSettings:
-    """Auto scale settings for synapse spark compute."""
+    """Auto-scale settings for Synapse Spark compute.
+
+    :param min_node_count: The minimum compute node count.
+    :type min_node_count: int
+    :param max_node_count: The maximum compute node count.
+    :type max_node_count: int
+    :param enabled: Specifies if auto-scale is enabled.
+    :type enabled: bool
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+
+            :start-after: [START synapse_spark_compute_configuration]
+            :end-before: [END synapse_spark_compute_configuration]
+            :language: python
+            :dedent: 8
+            :caption: Configuring AutoScaleSettings on SynapseSparkCompute.
+    """
 
     def __init__(
         self,
         *,
         min_node_count: Optional[int] = None,
         max_node_count: Optional[int] = None,
         enabled: Optional[bool] = None,
-    ):
-        """Auto scale settings for synapse spark compute.
-
-        :param min_node_count: Min node count
-        :type min_node_count: int
-        :param max_node_count: Max node count
-        :type max_node_count: int
-        :param auto_scale_enabled:  Auto scale enabled
-        :type auto_scale_enabled: bool
-        """
+    ) -> None:
         self.min_node_count = min_node_count
         self.max_node_count = max_node_count
         self.auto_scale_enabled = enabled
 
     def _to_auto_scale_settings(self) -> AutoScaleProperties:
         return AutoScaleProperties(
             min_node_count=self.min_node_count,
@@ -54,24 +64,33 @@
             min_node_count=autoscaleprops.min_node_count,
             max_node_count=autoscaleprops.max_node_count,
             enabled=autoscaleprops.enabled,
         )
 
 
 class AutoPauseSettings:
-    """Auto pause settings for synapse spark compute."""
+    """Auto pause settings for Synapse Spark compute.
 
-    def __init__(self, *, delay_in_minutes: Optional[int] = None, enabled: Optional[bool] = None):
-        """Auto pause settings for synapse spark compute.
+    :param delay_in_minutes: The time delay in minutes before pausing cluster.
+    :type delay_in_minutes: int
+    :param enabled:  Specifies if auto-pause is enabled.
+    :type enabled: bool
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START synapse_spark_compute_configuration]
+            :end-before: [END synapse_spark_compute_configuration]
+            :language: python
+            :dedent: 8
+            :caption: Configuring AutoPauseSettings on SynapseSparkCompute.
+    """
 
-        :param delay_in_minutes: ideal time delay in minutes before pause cluster
-        :type delay_in_minutes: int
-        :param auto_scale_enabled:  Auto pause enabled
-        :type auto_scale_enabled: bool
-        """
+    def __init__(self, *, delay_in_minutes: Optional[int] = None, enabled: Optional[bool] = None) -> None:
         self.delay_in_minutes = delay_in_minutes
         self.auto_pause_enabled = enabled
 
     def _to_auto_pause_settings(self) -> AutoPauseProperties:
         return AutoPauseProperties(
             delay_in_minutes=self.delay_in_minutes,
             auto_pause_enabled=self.auto_pause_enabled,
@@ -85,43 +104,65 @@
         )
 
 
 @experimental
 class SynapseSparkCompute(Compute):
     """SynapseSpark Compute resource.
 
-    :param name: Name of the compute
+    :param name: The name of the compute.
     :type name: str
-    :param location: The resource location, defaults to None
-    :type location: Optional[str], optional
-    :param description: Description of the resource.
-    :type description: Optional[str], optional
-    :param resource_id: ARM resource id of the underlying compute, defaults to None
-    :type resource_id: Optional[str], optional
-    :param tags: A set of tags. Contains resource tags defined as key/value pairs.
-    :type tags: Optional[dict[str, str]]
-    :param identity:  The identity configuration, identities that are associated with the compute cluster.
-    :type identity: IdentityConfiguration, optional
+    :param description: The description of the resource.
+    :type description: str
+    :param tags: The set of resource tags defined as key/value pairs.
+    :type tags: Dict[str, str]
+    :param node_count: The number of nodes in the compute.
+    :type node_count: int
+    :param node_family: The node family of the compute.
+    :type node_family: str
+    :param node_size: The size of the node.
+    :type node_size: str
+    :param spark_version: The version of Spark to use.
+    :type spark_version: str
+    :param identity: The configuration of identities that are associated with the compute cluster.
+    :type identity: ~azure.ai.ml.entities.IdentityConfiguration
+    :param scale_settings: The scale settings for the compute.
+    :type scale_settings: ~azure.ai.ml.entities.AutoScaleSettings
+    :param auto_pause_settings: The auto pause settings for the compute.
+    :type auto_pause_settings: ~azure.ai.ml.entities.AutoPauseSettings
+    :param location: The resource location.
+    :type location: str
+    :param resource_id: The ARM resource ID of the underlying compute.
+    :type resource_id: str
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START synapse_spark_compute_configuration]
+            :end-before: [END synapse_spark_compute_configuration]
+            :language: python
+            :dedent: 8
+            :caption: Creating Synapse Spark compute.
     """
 
     def __init__(
         self,
         *,
         name: str,
         description: Optional[str] = None,
-        tags: Optional[dict] = None,
+        tags: Optional[Dict[str, str]] = None,
         node_count: Optional[int] = None,
         node_family: Optional[str] = None,
         node_size: Optional[str] = None,
         spark_version: Optional[str] = None,
         identity: Optional[IdentityConfiguration] = None,
         scale_settings: Optional[AutoScaleSettings] = None,
         auto_pause_settings: Optional[AutoPauseSettings] = None,
         **kwargs,
-    ):
+    ) -> None:
         kwargs[TYPE] = ComputeType.SYNAPSESPARK
         super().__init__(name=name, description=description, location=kwargs.pop("location", None), tags=tags, **kwargs)
         self.identity = identity
         self.node_count = node_count
         self.node_family = node_family
         self.node_size = node_size
         self.spark_version = spark_version
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_schedule.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_aml_compute_node_info.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_aml_compute_node_info.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_image_metadata.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_image_metadata.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_usage.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_usage.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_custom_applications.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_custom_applications.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/compute_instance.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/compute_instance.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/virtual_machine_compute.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/virtual_machine_compute.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_compute/_setup_scripts.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_compute/_setup_scripts.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/model_batch_deployment_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/model_batch_deployment_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/batch_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/batch_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/container_resource_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/container_resource_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/payload_response.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/payload_response.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/request_logging.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/request_logging.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/data_collector.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/data_collector.py`

 * *Files 2% similar despite different names*

```diff
@@ -48,14 +48,15 @@
     def _to_dict(self) -> Dict:
         # pylint: disable=no-member
         return DataCollectorSchema(context={BASE_PATH_CONTEXT_KEY: "./"}).dump(self)
 
     @classmethod
     def _from_rest_object(cls, rest_obj: RestDataCollector) -> "DataCollector":
         collections = dict()
+        sampling_rate = None
         for k, v in rest_obj.collections.items():
             sampling_rate = v.sampling_rate
             collections[k] = DeploymentCollection._from_rest_object(v)
             delattr(collections[k], "sampling_rate")
 
         return DataCollector(
             collections=collections,
@@ -67,19 +68,20 @@
         )
 
     def _to_dict(self) -> Dict:
         # pylint: disable=no-member
         return DataCollectorSchema(context={BASE_PATH_CONTEXT_KEY: "./"}).dump(self)
 
     def _to_rest_object(self) -> RestDataCollector:
+        rest_collections = dict()
         for collection in self.collections.values():
             collection.sampling_rate = self.sampling_rate
         delattr(self, "sampling_rate")
         if self.request_logging:
             self.request_logging = self.request_logging._to_rest_object()
         if self.collections:
-            rest_collections = dict()
+            rest_collections = {}
             for k, v in self.collections.items():
                 rest_collections[k] = v._to_rest_object()
         return RestDataCollector(
             collections=rest_collections, rolling_rate=self.rolling_rate, request_logging=self.request_logging
         )
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment_collection.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment_collection.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/resource_requirements_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/resource_requirements_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/run_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/run_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/pipeline_component_batch_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/pipeline_component_batch_deployment.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 from os import PathLike
 from pathlib import Path
-from typing import Any, Dict, Optional, Union
+from typing import Dict, Optional, Union
 
 from azure.ai.ml.entities._component.component import Component
 from azure.ai.ml._schema._deployment.batch.pipeline_component_batch_deployment_schema import (
     PipelineComponentBatchDeploymentSchema,
 )  # pylint: disable=line-too-long
 from azure.ai.ml.entities import Deployment, PipelineComponent
 from azure.ai.ml._utils._experimental import experimental
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/event_hub.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/event_hub.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/deployment_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/deployment_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/batch_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/batch_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/code_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/code_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/data_asset.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/data_asset.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
-from typing import Any, Dict, Optional
+from typing import Dict, Optional
 
 from azure.ai.ml._schema._deployment.online.data_asset_schema import DataAssetSchema
 from azure.ai.ml._utils._experimental import experimental
 from azure.ai.ml.constants._common import BASE_PATH_CONTEXT_KEY
 
 
 @experimental
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/model_batch_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/model_batch_deployment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/online_deployment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/online_deployment.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 # pylint: disable=protected-access,no-member,arguments-renamed,unidiomatic-typecheck
 
 import logging
 import os
 import typing
 from abc import abstractmethod
 from pathlib import Path
-from typing import Any, Dict, Optional, Union
+from typing import Dict, Optional, Union
 
 from azure.ai.ml._restclient.v2023_04_01_preview.models import CodeConfiguration as RestCodeConfiguration
 from azure.ai.ml._restclient.v2023_04_01_preview.models import EndpointComputeType
 from azure.ai.ml._restclient.v2023_04_01_preview.models import (
     KubernetesOnlineDeployment as RestKubernetesOnlineDeployment,
 )
 from azure.ai.ml._restclient.v2023_04_01_preview.models import ManagedOnlineDeployment as RestManagedOnlineDeployment
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/oversize_data_config.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/oversize_data_config.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/scale_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/scale_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_deployment/job_definition.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_deployment/job_definition.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_on_prem_credentials.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_on_prem_credentials.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/datastore.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/datastore.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access,redefined-builtin,arguments-renamed
 
-from abc import ABC, abstractclassmethod, abstractmethod
+from abc import ABC, abstractmethod
 from os import PathLike
 from pathlib import Path
 from typing import IO, Any, AnyStr, Dict, Optional, Union
 
 from azure.ai.ml._restclient.v2022_10_01.models import Datastore as DatastoreData, DatastoreType
 from azure.ai.ml._utils.utils import camel_to_snake, dump_yaml_to_file
 from azure.ai.ml.constants._common import BASE_PATH_CONTEXT_KEY, PARAMS_OVERRIDE_KEY, CommonYamlFields
@@ -170,15 +170,16 @@
             message=msg,
             error_type=ValidationErrorType.INVALID_VALUE,
             target=ErrorTarget.DATASTORE,
             no_personal_data_message=msg,
             error_category=ErrorCategory.SYSTEM_ERROR,
         )
 
-    @abstractclassmethod
+    @classmethod
+    @abstractmethod
     def _load_from_dict(cls, data: Dict, context: Dict, additional_message: str, **kwargs) -> "Datastore":
         pass
 
     def __eq__(self, other) -> bool:
         return self.name == other.name and self.type == other.type and self.credentials == other.credentials
 
     def __ne__(self, other) -> bool:
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/_on_prem.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/_on_prem.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/adls_gen1.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/adls_gen1.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_datastore/azure_storage.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_datastore/azure_storage.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/batch_endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/batch_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/online_endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/online_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_endpoint/_endpoint_helpers.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_endpoint/_endpoint_helpers.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,22 +19,22 @@
 from .._component.component import Component
 from .._component.parallel_component import ParallelComponent
 from .._inputs_outputs import Input, Output
 from .._job.job_resource_configuration import JobResourceConfiguration
 from .._job.parallel.parallel_job import ParallelJob
 from .._job.parallel.parallel_task import ParallelTask
 from .._job.parallel.retry_settings import RetrySettings
-from .._job.pipeline._io import NodeOutput
+from .._job.pipeline._io import NodeOutput, NodeWithGroupInputMixin
 from .._util import convert_ordered_dict_to_dict, get_rest_dict_for_node_attrs, validate_attribute_type
 from .base_node import BaseNode
 
 module_logger = logging.getLogger(__name__)
 
 
-class Parallel(BaseNode):
+class Parallel(BaseNode, NodeWithGroupInputMixin):
     """Base class for parallel node, used for parallel component version consumption.
 
     You should not instantiate this class directly. Instead, you should
     create from builder function: parallel.
 
     :param component: Id or instance of the parallel component/job to be run for the step
     :type component: parallelComponent
@@ -137,24 +137,24 @@
             """Convert str to int."""  # pylint: disable=pointless-string-statement
             pattern = re.compile(r"^\d+([kKmMgG][bB])*$")
             if not pattern.match(mini_batch_size):
                 raise ValueError(r"Parameter mini_batch_size must follow regex rule ^\d+([kKmMgG][bB])*$")
 
             try:
                 mini_batch_size = int(mini_batch_size)
-            except ValueError:
+            except ValueError as e:
                 unit = mini_batch_size[-2:].lower()
                 if unit == "kb":
                     mini_batch_size = int(mini_batch_size[0:-2]) * 1024
                 elif unit == "mb":
                     mini_batch_size = int(mini_batch_size[0:-2]) * 1024 * 1024
                 elif unit == "gb":
                     mini_batch_size = int(mini_batch_size[0:-2]) * 1024 * 1024 * 1024
                 else:
-                    raise ValueError("mini_batch_size unit must be kb, mb or gb")
+                    raise ValueError("mini_batch_size unit must be kb, mb or gb") from e
 
         self.mini_batch_size = mini_batch_size
         self.partition_keys = partition_keys
         self.input_data = input_data
         self._retry_settings = retry_settings
         self.logging_level = logging_level
         self.max_concurrency_per_instance = max_concurrency_per_instance
@@ -319,24 +319,24 @@
             "input_data",
         ]
 
     def _to_rest_object(self, **kwargs) -> dict:
         rest_obj = super(Parallel, self)._to_rest_object(**kwargs)
         rest_obj.update(
             convert_ordered_dict_to_dict(
-                dict(
-                    componentId=self._get_component_id(),
-                    retry_settings=get_rest_dict_for_node_attrs(self.retry_settings),
-                    logging_level=self.logging_level,
-                    mini_batch_size=self.mini_batch_size,
-                    partition_keys=json.dumps(self.partition_keys)
+                {
+                    "componentId": self._get_component_id(),
+                    "retry_settings": get_rest_dict_for_node_attrs(self.retry_settings),
+                    "logging_level": self.logging_level,
+                    "mini_batch_size": self.mini_batch_size,
+                    "partition_keys": json.dumps(self.partition_keys)
                     if self.partition_keys is not None
                     else self.partition_keys,
-                    resources=get_rest_dict_for_node_attrs(self.resources),
-                )
+                    "resources": get_rest_dict_for_node_attrs(self.resources),
+                }
             )
         )
         return rest_obj
 
     @classmethod
     def _from_rest_object_to_init_params(cls, obj: dict) -> Dict:
         obj = super()._from_rest_object_to_init_params(obj)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/sweep.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/sweep.py`

 * *Files 2% similar despite different names*

```diff
@@ -224,18 +224,18 @@
 
         # hack: only early termination policy does not follow yaml schema now, should be removed after server-side made
         # the change
         if "early_termination" in rest_obj:
             rest_obj["early_termination"] = self.early_termination._to_rest_object().as_dict()
 
         rest_obj.update(
-            dict(
-                type=self.type,
-                trial=self._get_trial_component_rest_obj(),
-            )
+            {
+                "type": self.type,
+                "trial": self._get_trial_component_rest_obj(),
+            }
         )
         return rest_obj
 
     @classmethod
     def _from_rest_object_to_init_params(cls, obj: dict) -> Dict:
         obj = super()._from_rest_object_to_init_params(obj)
 
@@ -263,15 +263,15 @@
 
     def _get_trial_component_rest_obj(self):
         # trial component to rest object is different from usual component
         trial_component_id = self._get_component_id()
         if trial_component_id is None:
             return None
         if isinstance(trial_component_id, str):
-            return dict(componentId=trial_component_id)
+            return {"componentId": trial_component_id}
         if isinstance(trial_component_id, CommandComponent):
             return trial_component_id._to_rest_object()
         raise UserErrorException(f"invalid trial in sweep node {self.name}: {str(self.trial)}")
 
     def _to_job(self) -> SweepJob:
         command = self.trial.command
         for key, _ in self.search_space.items():
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/command.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/command.py`

 * *Files 16% similar despite different names*

```diff
@@ -19,15 +19,14 @@
 from azure.ai.ml._schema.job.command_job import CommandJobSchema
 from azure.ai.ml._schema.job.identity import AMLTokenIdentitySchema, ManagedIdentitySchema, UserIdentitySchema
 from azure.ai.ml._schema.job.services import JobServiceSchema
 from azure.ai.ml.constants._common import BASE_PATH_CONTEXT_KEY, LOCAL_COMPUTE_PROPERTY, LOCAL_COMPUTE_TARGET
 from azure.ai.ml.constants._component import ComponentSource, NodeType
 from azure.ai.ml.entities._assets import Environment
 from azure.ai.ml.entities._component.command_component import CommandComponent
-from azure.ai.ml.entities._component.component import Component
 from azure.ai.ml.entities._credentials import (
     AmlTokenConfiguration,
     ManagedIdentityConfiguration,
     UserIdentityConfiguration,
     _BaseJobIdentityConfiguration,
 )
 from azure.ai.ml.entities._inputs_outputs import Input, Output
@@ -72,74 +71,93 @@
 from ..._schema import PathAwareSchema
 from ..._schema.job.distribution import (
     MPIDistributionSchema,
     PyTorchDistributionSchema,
     RayDistributionSchema,
     TensorFlowDistributionSchema,
 )
+from .._job.pipeline._io import NodeWithGroupInputMixin
 from .._util import (
     convert_ordered_dict_to_dict,
     from_rest_dict_to_dummy_rest_object,
     get_rest_dict_for_node_attrs,
     load_from_dict,
     validate_attribute_type,
 )
 from .base_node import BaseNode
 from .sweep import Sweep
 
 module_logger = logging.getLogger(__name__)
 
 
-class Command(BaseNode):
+class Command(BaseNode, NodeWithGroupInputMixin):
     """Base class for command node, used for command component version consumption.
 
     You should not instantiate this class directly. Instead, you should
-    create from builder function: command.
+    create it using the builder function: command().
 
-    :param component: Id or instance of the command component/job to be run for the step
-    :type component: CommandComponent
-    :param inputs: Inputs to the command.
-    :type inputs: Dict[str, Union[Input, SweepDistribution, str, bool, int, float, Enum, dict]]
-    :param outputs: Mapping of output data bindings used in the job.
-    :type outputs: Dict[str, Union[str, Output, dict]]
-    :param name: Name of the command.
+    :param name: The name of the command.
     :type name: str
-    :param description: Description of the command.
+    :param description: The description of the command.
     :type description: str
     :param tags: Tag dictionary. Tags can be added, removed, and updated.
     :type tags: dict[str, str]
     :param properties: The job property dictionary.
     :type properties: dict[str, str]
-    :param display_name: Display name of the job.
+    :param display_name: The display name of the job.
     :type display_name: str
-    :param experiment_name:  Name of the experiment the job will be created under,
-        if None is provided, default will be set to current directory name.
+    :param experiment_name: The name of the experiment the job will be created under. Defaults to current directory
+        name.
     :type experiment_name: str
-    :param command: Command to be executed in training.
+    :param command: The command to be executed during job.
     :type command: str
-    :param compute: The compute target the job runs on.
-    :type compute: str
-    :param resources: Compute Resource configuration for the command.
-    :type resources: Union[Dict, ~azure.ai.ml.entities.JobResourceConfiguration]
-    :param code: A local path or http:, https:, azureml: url pointing to a remote location.
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url pointing
+        to a remote location.
     :type code: str
-    :param distribution: Distribution configuration for distributed training.
-    :type distribution: Union[Dict, PyTorchDistribution, MpiDistribution, TensorFlowDistribution, RayDistribution]
-    :param environment: Environment that training job will run in.
-    :type environment: Union[Environment, str]
-    :param limits: Command Job limit.
+    :param component: The ID or instance of the command component or job to be run for the step.
+    :type component: Union[str, ~azure.ai.ml.entities.CommandComponent]
+    :param compute: The compute target the job will run on.
+    :type compute: str
+    :param inputs: A mapping of input names to input data sources used in the job.
+    :type inputs: dict[str, Union[
+        ~azure.ai.ml.Input,
+        str,
+        bool,
+        int,
+        float,
+        Enum,
+        ]
+    ]
+    :param outputs: A mapping of output names to output data sources used in the job.
+    :type outputs: dict[str, Union[str, ~azure.ai.ml.Output]]
+    :param limits: The limits for the command component or job.
     :type limits: ~azure.ai.ml.entities.CommandJobLimits
-    :param identity: Identity that training job will use while running on compute.
-    :type identity: Union[ManagedIdentity, AmlToken, UserIdentity]
-    :param services: Interactive services for the node. This is an experimental parameter, and may change at any time.
-        Please see https://aka.ms/azuremlexperimental for more information.
-    :type services:
-        Dict[str, Union[JobService, JupyterLabJobService, SshJobService, TensorBoardJobService, VsCodeJobService]]
+    :param identity: The identity that the command job will use while running on compute.
+    :type identity: Union[
+        dict[str, str],
+        ~azure.ai.ml.entities.ManagedIdentityConfiguration,
+        ~azure.ai.ml.entities.AmlTokenConfiguration,
+        ~azure.ai.ml.entities.UserIdentityConfiguration]
+    :param distribution: The configuration for distributed jobs.
+    :type distribution: Union[dict, ~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+    :param environment: The environment that the job will run in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param environment_variables:  A dictionary of environment variable names and values.
+        These environment variables are set on the process where the user script is being executed.
+    :type environment_variables: dict[str, str]
+    :param resources: The compute resource configuration for the command.
+    :type resources: ~azure.ai.ml.entities.JobResourceConfiguration
+    :param services: The interactive services for the node. This is an experimental parameter, and may change at any
+        time. Please see https://aka.ms/azuremlexperimental for more information.
+    :type services: dict[str, Union[~azure.ai.ml.entities.JobService, ~azure.ai.ml.entities.JupyterLabJobService,
+        ~azure.ai.ml.entities.SshJobService, ~azure.ai.ml.entities.TensorBoardJobService,
+        ~azure.ai.ml.entities.VsCodeJobService]]
     :param queue_settings: Queue settings for the job.
-    :type queue_settings: QueueSettings
+    :type queue_settings: ~azure.ai.ml.entities.QueueSettings
     :raises ~azure.ai.ml.exceptions.ValidationException: Raised if Command cannot be successfully validated.
         Details will be provided in the error message.
     """
 
     # pylint: disable=too-many-instance-attributes
     def __init__(
         self,
@@ -171,15 +189,15 @@
         environment_variables: Optional[Dict] = None,
         resources: Optional[JobResourceConfiguration] = None,
         services: Optional[
             Dict[str, Union[JobService, JupyterLabJobService, SshJobService, TensorBoardJobService, VsCodeJobService]]
         ] = None,
         queue_settings: Optional[QueueSettings] = None,
         **kwargs,
-    ):
+    ) -> None:
         # validate init params are valid type
         validate_attribute_type(attrs_to_check=locals(), attr_type_map=self._attr_type_map())
 
         # resolve normal dict to dict[str, JobService]
         services = _resolve_job_services(services)
         kwargs.pop("type", None)
         self._parameters = kwargs.pop("parameters", {})
@@ -223,134 +241,225 @@
 
     @classmethod
     def _get_supported_outputs_types(cls):
         return str, Output
 
     @property
     def parameters(self) -> Dict[str, str]:
-        """MLFlow parameters.
+        """MLFlow parameters to be logged during the job.
 
-        :return: MLFlow parameters logged in job.
-        :rtype: Dict[str, str]
+        :rtype: dict[str, str]
         """
         return self._parameters
 
     @property
     def distribution(
         self,
     ) -> Union[PyTorchDistribution, MpiDistribution, TensorFlowDistribution, RayDistribution]:
+        """The configuration for the distributed command component or job.
+
+        :rtype: Union[~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+        """
         return self._distribution
 
     @distribution.setter
     def distribution(
         self,
         value: Union[Dict, PyTorchDistribution, TensorFlowDistribution, MpiDistribution, RayDistribution],
-    ):
+    ) -> None:
+        """Sets the configuration for the distributed command component or job.
+
+        :param value: The configuration for distributed jobs.
+        :type value: Union[dict, ~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+        """
         if isinstance(value, dict):
             dist_schema = UnionField(
                 [
                     NestedField(PyTorchDistributionSchema, unknown=INCLUDE),
                     NestedField(TensorFlowDistributionSchema, unknown=INCLUDE),
                     NestedField(MPIDistributionSchema, unknown=INCLUDE),
                     ExperimentalField(NestedField(RayDistributionSchema, unknown=INCLUDE)),
                 ]
             )
             value = dist_schema._deserialize(value=value, attr=None, data=None)
         self._distribution = value
 
     @property
     def resources(self) -> JobResourceConfiguration:
+        """The compute resource configuration for the command component or job.
+
+        :rtype: ~azure.ai.ml.entities.JobResourceConfiguration
+        """
         return self._resources
 
     @resources.setter
-    def resources(self, value: Union[Dict, JobResourceConfiguration]):
+    def resources(self, value: Union[Dict, JobResourceConfiguration]) -> None:
+        """Sets the compute resource configuration for the command component or job.
+
+        :param value: The compute resource configuration for the command component or job.
+        :type value: Union[dict, ~azure.ai.ml.entities.JobResourceConfiguration]
+        """
         if isinstance(value, dict):
             value = JobResourceConfiguration(**value)
         self._resources = value
 
     @property
     def queue_settings(self) -> QueueSettings:
+        """The queue settings for the command component or job.
+
+        :rtype: ~azure.ai.ml.entities.QueueSettings
+        """
         return self._queue_settings
 
     @queue_settings.setter
-    def queue_settings(self, value: Union[Dict, QueueSettings]):
+    def queue_settings(self, value: Union[Dict, QueueSettings]) -> None:
+        """Sets the queue settings for the command component or job.
+
+        :param value: The queue settings for the command component or job.
+        :type value: Union[dict, ~azure.ai.ml.entities.QueueSettings]
+        """
         if isinstance(value, dict):
             value = QueueSettings(**value)
         self._queue_settings = value
 
     @property
     def identity(
         self,
     ) -> Optional[Union[ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration]]:
-        """Configuration of the hyperparameter identity."""
+        """The identity that the job will use while running on compute.
+
+        :rtype: Union[~azure.ai.ml.ManagedIdentityConfiguration, ~azure.ai.ml.AmlTokenConfiguration,
+        ~azure.ai.ml.UserIdentityConfiguration]
+        """
         return self._identity
 
     @identity.setter
     def identity(
         self,
         value: Union[
             Dict[str, str], ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration, None
         ],
-    ):
+    ) -> None:
+        """Sets the identity that the job will use while running on compute.
+
+        :param value: The identity that the job will use while running on compute.
+        :type value: Union[dict[str, str], ~azure.ai.ml.ManagedIdentityConfiguration,
+        ~azure.ai.ml.AmlTokenConfiguration, ~azure.ai.ml.UserIdentityConfiguration]
+        """
         if isinstance(value, dict):
             identity_schema = UnionField(
                 [
                     NestedField(ManagedIdentitySchema, unknown=INCLUDE),
                     NestedField(AMLTokenIdentitySchema, unknown=INCLUDE),
                     NestedField(UserIdentitySchema, unknown=INCLUDE),
                 ]
             )
             value = identity_schema._deserialize(value=value, attr=None, data=None)
         self._identity = value
 
     @property
-    def services(self) -> Dict:
+    def services(
+        self,
+    ) -> Dict[str, Union[JobService, JupyterLabJobService, SshJobService, TensorBoardJobService, VsCodeJobService]]:
+        """The interactive services for the node.
+
+        This is an experimental parameter, and may change at any time.
+        Please see https://aka.ms/azuremlexperimental for more information.
+
+        :rtype: dict[str, Union[~azure.ai.ml.entities.JobService, ~azure.ai.ml.entities.JupyterLabJobService,
+            ~azure.ai.ml.entities.SshJobService, ~azure.ai.ml.entities.TensorBoardJobService,
+            ~azure.ai.ml.entities.VsCodeJobService]]
+        """
         return self._services
 
     @services.setter
-    def services(self, value: Dict):
+    def services(
+        self,
+        value: Dict[
+            str, Union[JobService, JupyterLabJobService, SshJobService, TensorBoardJobService, VsCodeJobService]
+        ],
+    ) -> None:
+        """Sets the interactive services for the node.
+
+        This is an experimental parameter, and may change at any time.
+        Please see https://aka.ms/azuremlexperimental for more information.
+
+        :param value: The interactive services for the node.
+        :type value: dict[str, Union[~azure.ai.ml.entities.JobService, ~azure.ai.ml.entities.JupyterLabJobService,
+            ~azure.ai.ml.entities.SshJobService, ~azure.ai.ml.entities.TensorBoardJobService,
+            ~azure.ai.ml.entities.VsCodeJobService]]
+        """
         self._services = _resolve_job_services(value)
 
     @property
     def component(self) -> Union[str, CommandComponent]:
+        """The ID or instance of the command component or job to be run for the step.
+
+        :rtype: Union[str, ~azure.ai.ml.entities.CommandComponent]
+        """
         return self._component
 
     @property
     def command(self) -> Optional[str]:
+        """Sets the command to be executed.
+
+        :rtype: str
+        """
         # the same as code
-        return self.component.command if hasattr(self.component, "command") else None
+        if not isinstance(self.component, CommandComponent):
+            return None
+        return self.component.command
 
     @command.setter
     def command(self, value: str) -> None:
-        if isinstance(self.component, Component):
+        """The command to be executed.
+
+        :param value: The command to be executed.
+        :type value: str
+        """
+        if isinstance(self.component, CommandComponent):
             self.component.command = value
         else:
             msg = "Can't set command property for a registered component {}. Tried to set it to {}."
             raise ValidationException(
                 message=msg.format(self.component, value),
                 no_personal_data_message=msg,
                 target=ErrorTarget.COMMAND_JOB,
                 error_category=ErrorCategory.USER_ERROR,
                 error_type=ValidationErrorType.INVALID_VALUE,
             )
 
     @property
     def code(self) -> Optional[Union[str, PathLike]]:
+        """The source code to run the job.
+
+        :rtype: Union[str, os.PathLike]
+        """
         # BaseNode is an _AttrDict to allow dynamic attributes, so that lower version of SDK can work with attributes
         # added in higher version of SDK.
         # self.code will be treated as an Arbitrary attribute if it raises AttributeError in getting
         # (when self.component doesn't have attribute code, self.component = 'azureml:xxx:1' e.g.
         # you may check _AttrDict._is_arbitrary_attr for detailed logic for Arbitrary judgement),
         # then its value will be set to _AttrDict and be deserialized as {"shape": {}} instead of None,
         # which is invalid in schema validation.
-        return self.component.code if hasattr(self.component, "code") else None
+        if not isinstance(self.component, CommandComponent):
+            return None
+        return self.component.code
 
     @code.setter
     def code(self, value: str) -> None:
-        if isinstance(self.component, Component):
+        """Sets the source code to run the job.
+
+        :param value: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url
+            pointing to a remote location.
+        :type value: str
+        """
+        if isinstance(self.component, CommandComponent):
             self.component.code = value
         else:
             msg = "Can't set code property for a registered component {}"
             raise ValidationException(
                 message=msg.format(self.component),
                 no_personal_data_message=msg,
                 target=ErrorTarget.COMMAND_JOB,
@@ -364,16 +473,45 @@
         instance_type: Optional[Union[str, List[str]]] = None,
         instance_count: Optional[int] = None,
         locations: Optional[List[str]] = None,
         properties: Optional[Dict] = None,
         docker_args: Optional[str] = None,
         shm_size: Optional[str] = None,
         **kwargs,  # pylint: disable=unused-argument
-    ):
-        """Set resources for Command."""
+    ) -> None:
+        """Set resources for Command.
+
+        :param instance_type: The type of compute instance to run the job on. If not specified, the job will run on
+            the default compute target.
+        :type instance_type: Union[str, list[str]]
+        :param instance_count: The number of instances to run the job on. If not specified, the job will run on a
+            single instance.
+        :type instance_count: int
+        :param locations: The list of locations where the job will run. If not specified, the job will run on the
+            default compute target.
+        :type locations: list[str]
+        :param properties: The properties of the job.
+        :type properties: dict
+        :param docker_args: The Docker arguments for the job.
+        :type docker_args: str
+        :param shm_size: The size of the docker container's shared memory block. This should be in the
+            format of (number)(unit) where the number has to be greater than 0 and the unit can be one of
+            b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).
+        :type shm_size: str
+
+        .. admonition:: Example:
+            :class: tip
+
+            .. literalinclude:: ../samples/ml_samples_command_configurations.py
+                :start-after: [START command_set_resources]
+                :end-before: [END command_set_resources]
+                :language: python
+                :dedent: 8
+                :caption: Setting resources on a Command.
+        """
         if self.resources is None:
             self.resources = JobResourceConfiguration()
 
         if locations is not None:
             self.resources.locations = locations
         if instance_type is not None:
             self.resources.instance_type = instance_type
@@ -383,30 +521,55 @@
             self.resources.properties = properties
         if docker_args is not None:
             self.resources.docker_args = docker_args
         if shm_size is not None:
             self.resources.shm_size = shm_size
 
         # Save the resources to internal component as well, otherwise calling sweep() will loose the settings
-        if isinstance(self.component, Component):
+        if isinstance(self.component, CommandComponent):
             self.component.resources = self.resources
 
-    def set_limits(self, *, timeout: int, **kwargs):  # pylint: disable=unused-argument
-        """Set limits for Command."""
+    def set_limits(self, *, timeout: int, **kwargs) -> None:  # pylint: disable=unused-argument
+        """Set limits for Command.
+
+        :param timeout: The timeout for the job in seconds.
+        :type timeout: int
+
+        .. admonition:: Example:
+            :class: tip
+
+            .. literalinclude:: ../samples/ml_samples_command_configurations.py
+                :start-after: [START command_set_limits]
+                :end-before: [END command_set_limits]
+                :language: python
+                :dedent: 8
+                :caption: Setting a timeout limit of 10 seconds on a Command.
+        """
         if isinstance(self.limits, CommandJobLimits):
             self.limits.timeout = timeout
         else:
             self.limits = CommandJobLimits(timeout=timeout)
 
-    def set_queue_settings(self, *, job_tier: Optional[str] = None, priority: Optional[str] = None):
+    def set_queue_settings(self, *, job_tier: Optional[str] = None, priority: Optional[str] = None) -> None:
         """Set QueueSettings for the job.
-        :param job_tier: determines the job tier.
+
+        :param job_tier: The job tier. Accepted values are "Spot", "Basic", "Standard", or "Premium".
         :type job_tier: str
-        :param priority: controls the priority on the compute.
+        :param priority:  The priority of the job on the compute. Defaults to "Medium".
         :type priority: str
+
+        .. admonition:: Example:
+            :class: tip
+
+            .. literalinclude:: ../samples/ml_samples_command_configurations.py
+                :start-after: [START command_set_queue_settings]
+                :end-before: [END command_set_queue_settings]
+                :language: python
+                :dedent: 8
+                :caption: Configuring queue settings on a Command.
         """
         if isinstance(self.queue_settings, QueueSettings):
             self.queue_settings.job_tier = job_tier
             self.queue_settings.priority = priority
         else:
             self.queue_settings = QueueSettings(job_tier=job_tier, priority=priority)
 
@@ -463,15 +626,15 @@
         :type timeout: int
         :param trial_timeout: The Sweep Job trial timeout value in seconds.
         :type trial_timeout: int
         :param early_termination_policy: The early termination policy of the sweep node. Acceptable
         values are "bandit", "median_stopping", or "truncation_selection".
         :type early_termination_policy: Union[~azure.ai.ml.sweep.BanditPolicy,
         ~azure.ai.ml.sweep.TruncationSelectionPolicy, ~azure.ai.ml.sweep.MedianStoppingPolicy, str]
-        :param identity: The identity that the training job will use while running on compute.
+        :param identity: The identity that the job will use while running on compute.
         :type identity: Union[
             ~azure.ai.ml.ManagedIdentityConfiguration,
             ~azure.ai.ml.AmlTokenConfiguration,
             ~azure.ai.ml.UserIdentityConfiguration]
         :param queue_settings: The queue settings for the job.
         :type queue_settings: ~azure.ai.ml.entities.QueueSettings
         :param job_tier: **Experimental** The job tier. Accepted values are "Spot", "Basic",
@@ -701,15 +864,15 @@
     def _create_schema_for_validation(cls, context) -> Union[PathAwareSchema, Schema]:
         from azure.ai.ml._schema.pipeline import CommandSchema
 
         return CommandSchema(context=context)
 
     def __call__(self, *args, **kwargs) -> "Command":
         """Call Command as a function will return a new instance each time."""
-        if isinstance(self._component, Component):
+        if isinstance(self._component, CommandComponent):
             # call this to validate inputs
             node = self._component(*args, **kwargs)
             # merge inputs
             for name, original_input in self.inputs.items():
                 if name not in kwargs.keys():
                     # use setattr here to make sure owner of input won't change
                     setattr(node.inputs, name, original_input._data)
@@ -735,16 +898,16 @@
             node.resources = copy.deepcopy(self.resources)
             node.queue_settings = copy.deepcopy(self.queue_settings)
             node.services = copy.deepcopy(self.services)
             node.identity = copy.deepcopy(self.identity)
             return node
         msg = "Command can be called as a function only when referenced component is {}, currently got {}."
         raise ValidationException(
-            message=msg.format(type(Component), self._component),
-            no_personal_data_message=msg.format(type(Component), "self._component"),
+            message=msg.format(type(CommandComponent), self._component),
+            no_personal_data_message=msg.format(type(CommandComponent), "self._component"),
             target=ErrorTarget.COMMAND_JOB,
             error_type=ValidationErrorType.INVALID_VALUE,
         )
 
 
 def _resolve_job_services(
     services: dict,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/do_while.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/do_while.py`

 * *Files 2% similar despite different names*

```diff
@@ -218,20 +218,20 @@
             # Check condition exists in dowhile body.
             validation_result.merge_with(
                 self._validate_port(self.condition, self.body.outputs, port_type="output", yaml_path="condition")
             )
             if validation_result.passed:
                 # Check condition is a control output.
                 condition_name = self.condition if isinstance(self.condition, str) else self.condition._port_name
-                if not self.body._outputs[condition_name].is_control:
+                if not self.body._outputs[condition_name]._is_control_or_primitive_type:
                     validation_result.append_error(
                         yaml_path="condition",
                         message=(
-                            f"{condition_name} is not a control output. "
-                            "The condition of dowhile must be the control output of the body."
+                            f"{condition_name} is not a control output and is not primitive type. "
+                            "The condition of dowhile must be the control output or primitive type of the body."
                         ),
                     )
         return validation_result.try_raise(self._get_validation_error_target(), raise_error=raise_error)
 
     def _validate_do_while_limit(self, raise_error=True):
         validation_result = self._create_empty_validation_result()
         if not self.limits or self.limits.max_iteration_count is None:
@@ -262,15 +262,15 @@
             for output, inputs in self.mapping.items():
                 # pylint: disable=protected-access
                 output_name = output if isinstance(output, str) else output._port_name
                 validate_results = self._validate_port(
                     output, self.body.outputs, port_type="output", yaml_path="mapping"
                 )
                 if validate_results.passed:
-                    is_control_output = self.body._outputs[output_name].is_control
+                    is_control_output = self.body._outputs[output_name]._is_control_or_primitive_type
                     inputs = inputs if isinstance(inputs, list) else [inputs]
                     for item in inputs:
                         input_validate_results = self._validate_port(
                             item, self.body.inputs, port_type="input", yaml_path="mapping"
                         )
                         validation_result.merge_with(input_validate_results)
                         # pylint: disable=protected-access
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/pipeline.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -165,17 +165,17 @@
             validation_result.merge_with(self.component._customized_validate())
         return validation_result
 
     def _to_rest_object(self, **kwargs) -> dict:
         rest_obj = super()._to_rest_object(**kwargs)
         rest_obj.update(
             convert_ordered_dict_to_dict(
-                dict(
-                    componentId=self._get_component_id(),
-                )
+                {
+                    "componentId": self._get_component_id(),
+                }
             )
         )
         return rest_obj
 
     def _build_inputs(self):
         inputs = super(Pipeline, self)._build_inputs()
         built_inputs = {}
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/spark.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/spark.py`

 * *Files 4% similar despite different names*

```diff
@@ -61,64 +61,76 @@
 module_logger = logging.getLogger(__name__)
 
 
 class Spark(BaseNode, SparkJobEntryMixin):
     """Base class for spark node, used for spark component version consumption.
 
     You should not instantiate this class directly. Instead, you should
-    create from builder function: spark.
+    create it from the builder function: spark.
 
-    :param component: Id or instance of the spark component/job to be run for the step
-    :type component: SparkComponent
-    :param entry: File or class entry point.
-    :type entry: dict[str, str]
-    :param py_files: List of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
-    :type py_files: Optional[typing.List[str]]
-    :param jars: List of jars to include on the driver and executor classpaths.
-    :type jars: Optional[typing.List[str]]
-    :param files: List of files to be placed in the working directory of each executor.
-    :type files: Optional[typing.List[str]]
-    :param archives: List of archives to be extracted into the working directory of each executor.
-    :type archives: Optional[typing.List[str]]
-    :param identity: Identity that spark job will use while running on compute.
+    :param component: The ID or instance of the Spark component or job to be run during the step.
+    :type component: Union[str, ~azure.ai.ml.entities.SparkComponent]
+    :param identity: The identity that the Spark job will use while running on compute.
     :type identity: Union[
-        Dict,
-        ManagedIdentityConfiguration,
-        AmlTokenConfiguration,
-        UserIdentityConfiguration]
-    :param driver_cores: Number of cores to use for the driver process, only in cluster mode.
+        Dict[str, str],
+        ~azure.ai.ml.entities.ManagedIdentityConfiguration,
+        ~azure.ai.ml.entities.AmlTokenConfiguration,
+        ~azure.ai.ml.entities.UserIdentityConfiguration]
+    :param driver_cores: The number of cores to use for the driver process, only in cluster mode.
     :type driver_cores: int
-    :param driver_memory: Amount of memory to use for the driver process.
+    :param driver_memory: The amount of memory to use for the driver process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type driver_memory: str
     :param executor_cores: The number of cores to use on each executor.
     :type executor_cores: int
-    :param executor_memory: Amount of memory to use per executor process, in the same format as JVM memory strings with
-        a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).
+    :param executor_memory: The amount of memory to use per executor process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type executor_memory: str
-    :param executor_instances: Initial number of executors.
+    :param executor_instances: The initial number of executors.
     :type executor_instances: int
-    :param dynamic_allocation_enabled: Whether to use dynamic resource allocation, which scales the number of executors
-        registered with this application up and down based on the workload.
+    :param dynamic_allocation_enabled: Whether to use dynamic resource allocation, which scales the number of
+        executors registered with this application up and down based on the workload.
     :type dynamic_allocation_enabled: bool
-    :param dynamic_allocation_min_executors: Lower bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_min_executors: The lower bound for the number of executors if dynamic allocation
+        is enabled.
     :type dynamic_allocation_min_executors: int
-    :param dynamic_allocation_max_executors: Upper bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_max_executors: The upper bound for the number of executors if dynamic allocation
+        is enabled.
     :type dynamic_allocation_max_executors: int
-    :param conf: A dict with pre-defined spark configurations key and values.
-    :type conf: dict
-    :param inputs: Mapping of inputs data bindings used in the job.
-    :type inputs: dict
-    :param outputs: Mapping of outputs data bindings used in the job.
-    :type outputs: dict
-    :param args: Arguments for the job.
+    :param conf: A dictionary with pre-defined Spark configurations key and values.
+    :type conf: Dict[str, str]
+    :param inputs: A mapping of input names to input data sources used in the job.
+    :type inputs: Dict[str, Union[
+        ~azure.ai.ml.entities._job.pipeline._io.NodeOutput,
+        ~azure.ai.ml.Input,
+        str,
+        bool,
+        int,
+        float,
+        Enum,
+        ]
+    ]
+    :param outputs: A mapping of output names to output data sources used in the job.
+    :type outputs: Dict[str, Union[str, ~azure.ai.ml.Output]]
+    :param args: The arguments for the job.
     :type args: str
     :param compute: The compute resource the job runs on.
     :type compute: str
-    :param resources: Compute Resource configuration for the job.
-    :type resources: Union[Dict, SparkResourceConfiguration]
+    :param resources: The compute resource configuration for the job.
+    :type resources: Union[Dict, ~azure.ai.ml.entities.SparkResourceConfiguration]
+    :param entry: The file or class entry point.
+    :type entry: Dict[str, str]
+    :param py_files: The list of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
+    :type py_files: List[str]
+    :param jars: The list of .JAR files to include on the driver and executor classpaths.
+    :type jars: List[str]
+    :param files: The list of files to be placed in the working directory of each executor.
+    :type files: List[str]
+    :param archives: The list of archives to be extracted into the working directory of each executor.
+    :type archives: List[str]
     """
 
     def __init__(
         self,
         *,
         component: Union[str, SparkComponent],
         identity: Optional[
@@ -154,15 +166,15 @@
         entry: Union[Dict[str, str], SparkJobEntry, None] = None,
         py_files: Optional[List[str]] = None,
         jars: Optional[List[str]] = None,
         files: Optional[List[str]] = None,
         archives: Optional[List[str]] = None,
         args: Optional[str] = None,
         **kwargs,
-    ):
+    ) -> None:
         # validate init params are valid type
         validate_attribute_type(attrs_to_check=locals(), attr_type_map=self._attr_type_map())
         kwargs.pop("type", None)
 
         BaseNode.__init__(
             self, type=NodeType.SPARK, inputs=inputs, outputs=outputs, component=component, compute=compute, **kwargs
         )
@@ -224,67 +236,97 @@
 
     @classmethod
     def _get_supported_outputs_types(cls):
         return str, Output
 
     @property
     def component(self) -> Union[str, SparkComponent]:
+        """The ID or instance of the Spark component or job to be run during the step.
+
+        :rtype: ~azure.ai.ml.entities.SparkComponent
+        """
         return self._component
 
     @property
     def resources(self) -> Optional[SparkResourceConfiguration]:
-        """Compute Resource configuration for the job."""
+        """The compute resource configuration for the job.
 
+        :rtype: ~azure.ai.ml.entities.SparkResourceConfiguration
+        """
         return self._resources
 
     @resources.setter
     def resources(self, value: Union[Dict[str, str], SparkResourceConfiguration, None]):
+        """Sets the compute resource configuration for the job.
+
+        :param value: The compute resource configuration for the job.
+        :type value: Union[Dict[str, str], ~azure.ai.ml.entities.SparkResourceConfiguration]
+        """
         if isinstance(value, dict):
             value = SparkResourceConfiguration(**value)
         self._resources = value
 
     @property
     def identity(
         self,
     ) -> Optional[Union[ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration]]:
-        """Identity that spark job will use while running on compute."""
+        """The identity that the Spark job will use while running on compute.
+
+        :rtype: Union[~azure.ai.ml.entities.ManagedIdentityConfiguration, ~azure.ai.ml.entities.AmlTokenConfiguration,
+            ~azure.ai.ml.entities.UserIdentityConfiguration]
+        """
         # If there is no identity from CLI/SDK input: for jobs running on synapse compute (MLCompute Clusters), the
         # managed identity is the default; for jobs running on clusterless, the user identity should be the default,
         # otherwise use user input identity.
         if self._identity is None:
             if self.compute is not None:
                 return ManagedIdentityConfiguration()
             if self.resources is not None:
                 return UserIdentityConfiguration()
         return self._identity
 
     @identity.setter
     def identity(
         self,
-        value: Union[
-            Dict[str, str], ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration, None
-        ],
+        value: Union[Dict[str, str], ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration],
     ):
+        """Sets the identity that the Spark job will use while running on compute.
+
+        :param value: The identity that the Spark job will use while running on compute.
+        :type value: Union[Dict[str, str], ~azure.ai.ml.entities.ManagedIdentityConfiguration,
+            ~azure.ai.ml.entities.AmlTokenConfiguration, ~azure.ai.ml.entities.UserIdentityConfiguration]
+        """
         if isinstance(value, dict):
             identify_schema = UnionField(
                 [
                     NestedField(ManagedIdentitySchema, unknown=INCLUDE),
                     NestedField(AMLTokenIdentitySchema, unknown=INCLUDE),
                     NestedField(UserIdentitySchema, unknown=INCLUDE),
                 ]
             )
             value = identify_schema._deserialize(value=value, attr=None, data=None)
         self._identity = value
 
     @property
     def code(self) -> Optional[Union[str, PathLike]]:
-        return self.component.code if hasattr(self.component, "code") else None
+        """The local or remote path pointing at source code.
+
+        :rtype: Union[str, PathLike]
+        """
+        if isinstance(self.component, Component):
+            return self.component.code
+        return None
 
     @code.setter
     def code(self, value: str) -> None:
+        """Sets the source code to be used for the job.
+
+        :param value: The local or remote path pointing at source code.
+        :type value: Union[str, PathLike]
+        """
         if isinstance(self.component, Component):
             self.component.code = value
         else:
             msg = "Can't set code property for a registered component {}"
             raise ValidationException(
                 message=msg.format(self.component),
                 no_personal_data_message=msg.format(self.component),
@@ -432,20 +474,20 @@
             "args",
         ]
 
     def _to_rest_object(self, **kwargs) -> dict:
         rest_obj = super()._to_rest_object(**kwargs)
         rest_obj.update(
             convert_ordered_dict_to_dict(
-                dict(
-                    componentId=self._get_component_id(),
-                    identity=get_rest_dict_for_node_attrs(self.identity),
-                    resources=get_rest_dict_for_node_attrs(self.resources),
-                    entry=get_rest_dict_for_node_attrs(self.entry),
-                )
+                {
+                    "componentId": self._get_component_id(),
+                    "identity": get_rest_dict_for_node_attrs(self.identity),
+                    "resources": get_rest_dict_for_node_attrs(self.resources),
+                    "entry": get_rest_dict_for_node_attrs(self.entry),
+                }
             )
         )
         return rest_obj
 
     def _build_inputs(self):
         inputs = super(Spark, self)._build_inputs()
         built_inputs = {}
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel_func.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel_func.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/fl_scatter_gather.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/fl_scatter_gather.py`

 * *Files 0% similar despite different names*

```diff
@@ -788,9 +788,9 @@
     @classmethod
     def _create_schema_for_validation(cls, context) -> PathAwareSchema:
         return FLScatterGatherSchema(context=context)
 
     def _to_rest_object(self, **kwargs) -> dict:  # pylint: disable=unused-argument
         """Convert self to a rest object for remote call."""
         rest_node = super(FLScatterGather, self)._to_rest_object(**kwargs)
-        rest_node.update(dict(outputs=self._to_rest_outputs()))
+        rest_node.update({"outputs": self._to_rest_outputs()})
         return convert_ordered_dict_to_dict(rest_node)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/import_node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/import_node.py`

 * *Files 0% similar despite different names*

```diff
@@ -112,17 +112,17 @@
     def _picked_fields_from_dict_to_rest_object(cls) -> List[str]:
         return []
 
     def _to_rest_object(self, **kwargs) -> dict:
         rest_obj = super()._to_rest_object(**kwargs)
         rest_obj.update(
             convert_ordered_dict_to_dict(
-                dict(
-                    componentId=self._get_component_id(),
-                )
+                {
+                    "componentId": self._get_component_id(),
+                }
             )
         )
         return rest_obj
 
     @classmethod
     def _load_from_dict(cls, data: Dict, context: Dict, additional_message: str, **kwargs) -> "Import":
         from .import_func import import_job
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/import_func.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/import_func.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/base_node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/base_node.py`

 * *Files 5% similar despite different names*

```diff
@@ -16,21 +16,22 @@
 from azure.ai.ml.constants._component import NodeType
 from azure.ai.ml.entities import Data, Model
 from azure.ai.ml.entities._component.component import Component
 from azure.ai.ml.entities._inputs_outputs import Input, Output
 from azure.ai.ml.entities._job._input_output_helpers import build_input_output
 from azure.ai.ml.entities._job.job import Job
 from azure.ai.ml.entities._job.pipeline._attr_dict import _AttrDict
-from azure.ai.ml.entities._job.pipeline._io import NodeOutput, PipelineInput, PipelineNodeIOMixin
+from azure.ai.ml.entities._job.pipeline._io import NodeOutput, PipelineInput
+from azure.ai.ml.entities._job.pipeline._io.mixin import NodeWithGroupInputMixin
 from azure.ai.ml.entities._job.pipeline._pipeline_expression import PipelineExpression
 from azure.ai.ml.entities._job.sweep.search_space import SweepDistribution
 from azure.ai.ml.entities._mixins import YamlTranslatableMixin
 from azure.ai.ml.entities._util import convert_ordered_dict_to_dict, resolve_pipeline_parameters
 from azure.ai.ml.entities._validation import MutableValidationResult, SchemaValidatableMixin
-from azure.ai.ml.exceptions import ErrorTarget, ValidationErrorType, ValidationException
+from azure.ai.ml.exceptions import ErrorTarget
 
 module_logger = logging.getLogger(__name__)
 
 
 def parse_inputs_outputs(data):
     if "inputs" in data:
         data["inputs"] = {key: build_input_output(val) for key, val in data["inputs"].items()}
@@ -56,15 +57,15 @@
             _add_component_to_current_definition_builder(automl_job)
         return automl_job
 
     return wrapper
 
 
 # pylint: disable=too-many-instance-attributes
-class BaseNode(Job, PipelineNodeIOMixin, YamlTranslatableMixin, _AttrDict, SchemaValidatableMixin):
+class BaseNode(Job, YamlTranslatableMixin, _AttrDict, SchemaValidatableMixin, NodeWithGroupInputMixin):
     """Base class for node in pipeline, used for component version consumption. Can't be instantiated directly.
 
     You should not instantiate this class directly. Instead, you should
     create from a builder function.
 
     :param type: Type of pipeline node
     :type type: str
@@ -142,35 +143,31 @@
             **kwargs,
         )
         self.comment = comment
 
         # initialize io
         inputs = resolve_pipeline_parameters(inputs)
         inputs, outputs = inputs or {}, outputs or {}
-        self._parse_io(inputs, Input)
-        self._validate_io(inputs, self._get_supported_inputs_types())
-        self._parse_io(outputs, Output)
-        self._validate_io(outputs, self._get_supported_outputs_types())
         # parse empty dict to None so we won't pass default mode, type to backend
         # add `isinstance` to avoid converting to expression
         for k, v in inputs.items():
             if isinstance(v, dict) and v == {}:
                 inputs[k] = None
 
         # TODO: get rid of self._job_inputs, self._job_outputs once we have unified Input
         self._job_inputs, self._job_outputs = inputs, outputs
         if isinstance(component, Component):
             # Build the inputs from component input definition and given inputs, unfilled inputs will be None
-            self._inputs = self._build_inputs_dict(component.inputs, inputs or {})
+            self._inputs = self._build_inputs_dict(inputs or {}, input_definition_dict=component.inputs)
             # Build the outputs from component output definition and given outputs, unfilled outputs will be None
-            self._outputs = self._build_outputs_dict(component.outputs, outputs or {})
+            self._outputs = self._build_outputs_dict(outputs or {}, output_definition_dict=component.outputs)
         else:
             # Build inputs/outputs dict without meta when definition not available
-            self._inputs = self._build_inputs_dict_without_meta(inputs or {})
-            self._outputs = self._build_outputs_dict_without_meta(outputs or {})
+            self._inputs = self._build_inputs_dict(inputs or {})
+            self._outputs = self._build_outputs_dict(outputs or {})
 
         self._component = component
         self._referenced_control_flow_node_instance_id = None
         self.kwargs = kwargs
 
         # Generate an id for every instance
         self._instance_id = str(uuid.uuid4())
@@ -217,55 +214,18 @@
             bool,
             int,
             float,
             Enum,
             PipelineExpression,
         )
 
-    @classmethod
-    def _get_supported_outputs_types(cls):
-        # supported output types for node input
-        return None
-
     @property
     def _skip_required_compute_missing_validation(self):
         return False
 
-    @classmethod
-    def _validate_io(cls, io_dict: dict, allowed_types: Optional[tuple]):
-        if allowed_types is None:
-            return
-        for key, value in io_dict.items():
-            if value is None or isinstance(value, allowed_types):
-                pass
-            else:
-                msg = "Expecting {} for input/output {}, got {} instead."
-                raise ValidationException(
-                    message=msg.format(allowed_types, key, type(value)),
-                    no_personal_data_message=msg.format(allowed_types, "[key]", type(value)),
-                    target=ErrorTarget.PIPELINE,
-                    error_type=ValidationErrorType.INVALID_VALUE,
-                )
-
-    @classmethod
-    def _parse_io(cls, io_dict: dict, parse_cls):
-        for key, value in io_dict.items():
-            # output mode of last node should not affect input mode of next node
-            if isinstance(value, NodeOutput):
-                # value = copy.deepcopy(value)
-                value = value._deepcopy()  # Decoupled input and output
-                io_dict[key] = value
-                value.mode = None
-            elif type(value) == dict:  # pylint: disable=unidiomatic-typecheck
-                # Use type comparison instead of is_instance to skip _GroupAttrDict
-                # when loading from yaml io will be a dict,
-                # like {'job_data_path': '${{parent.inputs.pipeline_job_data_path}}'}
-                # parse dict to allowed type
-                io_dict[key] = parse_cls(**value)
-
     def _initializing(self) -> bool:
         # use this to indicate ongoing init process so all attributes set during init process won't be set as
         # arbitrary attribute in _AttrDict
         # TODO: replace this hack
         return self._init
 
     def _set_base_path(self, base_path):
@@ -446,15 +406,15 @@
                 _source=self._source,
                 # add all arbitrary attributes to support setting unknown attributes
                 **self._get_attrs(),
             )
         )
         # only add comment in REST object when it is set
         if self.comment is not None:
-            rest_obj.update(dict(comment=self.comment))
+            rest_obj.update({"comment": self.comment})
 
         return convert_ordered_dict_to_dict(rest_obj)
 
     @property
     def inputs(self) -> Dict[str, Union[Input, str, bool, int, float]]:
         return self._inputs
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/data_transfer_func.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/data_transfer_func.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/command_func.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/command_func.py`

 * *Files 8% similar despite different names*

```diff
@@ -16,16 +16,16 @@
     ManagedIdentityConfiguration,
     UserIdentityConfiguration,
 )
 from azure.ai.ml.entities._inputs_outputs import Input, Output
 from azure.ai.ml.entities._job.distribution import (
     MpiDistribution,
     PyTorchDistribution,
-    TensorFlowDistribution,
     RayDistribution,
+    TensorFlowDistribution,
 )
 from azure.ai.ml.entities._job.job_service import (
     JobService,
     JupyterLabJobService,
     SshJobService,
     TensorBoardJobService,
     VsCodeJobService,
@@ -141,85 +141,104 @@
     services: Optional[
         Dict[str, Union[JobService, JupyterLabJobService, SshJobService, TensorBoardJobService, VsCodeJobService]]
     ] = None,
     job_tier: Optional[str] = None,
     priority: Optional[str] = None,
     **kwargs,
 ) -> Command:
-    """Create a Command object which can be used inside dsl.pipeline as a function and can also be created as a
-    standalone command job.
+    """Creates a Command object which can be used inside a dsl.pipeline function or used as a standalone Command job.
 
-    :param name: Name of the command job or component created
+    :param name: The name of the Command job or component.
     :type name: str
-    :param description: a friendly description of the command
+    :param description: The description of the Command.
     :type description: str
-    :param tags: Tags to be attached to this command
-    :type tags: Dict
-    :param properties: The asset property dictionary.
+    :param tags: Tag dictionary. Tags can be added, removed, and updated.
+    :type tags: dict[str, str]
+    :param properties: The job property dictionary.
     :type properties: dict[str, str]
-    :param display_name: a friendly name
+    :param display_name: The display name of the job.
     :type display_name: str
-    :param experiment_name:  Name of the experiment the job will be created under,
-        if None is provided, default will be set to current directory name. Will be ignored as a pipeline step.
-    :type experiment_name: str
-    :param command: the command string that will be run
+    :param command: The command to be executed.
     :type command: str
-    :param environment: the environment to use for this command
-    :type environment: Union[str, azure.ai.ml.entities.Environment]
-    :param environment_variables: environment variables to set on the compute before this command is executed
-    :type environment_variables: dict
-    :param distribution: the distribution mode to use for this command
-    :type distribution:
-        Union[Dict,
-              azure.ai.ml.MpiDistribution,
-              azure.ai.ml.TensorFlowDistribution,
-              azure.ai.ml.PyTorchDistribution,
-              azure.ai.ml.RayDistribution]
-    :param compute: the name of the compute where the command job is executed(
-        will not be used if the command is used as a component/function)
+    :param experiment_name: The name of the experiment the job will be created under. Defaults to current directory
+        name.
+    :type experiment_name: str
+    :param environment: The environment that the job will run in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param environment_variables:  A dictionary of environment variable names and values.
+        These environment variables are set on the process where user script is being executed.
+    :type environment_variables: dict[str, str]
+    :param distribution: The configuration for distributed jobs.
+    :type distribution: Union[dict, ~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+    :param compute: The compute target the job will run on.
     :type compute: str
-    :param inputs: a dict of inputs used by this command.
-    :type inputs: Dict
-    :param outputs: the outputs of this command
-    :type outputs: Dict
-    :param instance_count: Optional number of instances or nodes used by the compute target. Defaults to 1.
-    :vartype instance_count: int
-    :param instance_type: Optional type of VM used as supported by the compute target.
-    :vartype instance_type: str
-    :param locations: Optional list of locations where the job can run.
-    :vartype locations: List[str]
+    :param inputs: A mapping of input names to input data sources used in the job.
+    :type inputs: dict[str, Union[
+        ~azure.ai.ml.Input,
+        str,
+        bool,
+        int,
+        float,
+        Enum,
+        ]
+    ]
+    :param outputs: A mapping of output names to output data sources used in the job.
+    :type outputs: dict[str, Union[str, ~azure.ai.ml.Output]]
+    :param instance_count: The number of instances or nodes to be used by the compute target. Defaults to 1.
+    :type instance_count: int
+    :param instance_type: The type of VM to be used by the compute target.
+    :type instance_type: str
+    :param locations: The list of locations where the job will run.
+    :type locations: list[str]
     :param docker_args: Extra arguments to pass to the Docker run command. This would override any
      parameters that have already been set by the system, or in this section. This parameter is only
      supported for Azure ML compute types.
-    :vartype docker_args: str
-    :param shm_size: Size of the docker container's shared memory block. This should be in the
-     format of (number)(unit) where number as to be greater than 0 and the unit can be one of
+    :type docker_args: str
+    :param shm_size: The size of the Docker container's shared memory block. This should be in the
+     format of (number)(unit) where the number has to be greater than 0 and the unit can be one of
      b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).
-    :vartype shm_size: str
-    :param timeout: The number in seconds, after which the job will be cancelled.
-    :vartype timeout: int
-    :param code: the code folder to run -- typically a local folder that will be uploaded as the job is submitted
+    :type shm_size: str
+    :param timeout: The number, in seconds, after which the job will be cancelled.
+    :type timeout: int
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url
+        pointing to a remote location.
     :type code: Union[str, os.PathLike]
-    :param identity: Identity that training job will use while running on compute.
+    :param identity: The identity that the command job will use while running on compute.
     :type identity: Union[
-        azure.ai.ml.ManagedIdentityConfiguration,
-        azure.ai.ml.AmlTokenConfiguration]
-    :param is_deterministic: Specify whether the command will return same output given same input.
-        If a command (component) is deterministic, when use it as a node/step in a pipeline,
-        it will reuse results from a previous submitted job in current workspace which has same inputs and settings.
-        In this case, this step will not use any compute resource.
-        Default to be True, specify is_deterministic=False if you would like to avoid such reuse behavior.
+        ~azure.ai.ml.entities.ManagedIdentityConfiguration,
+        ~azure.ai.ml.entities.AmlTokenConfiguration,
+        ~azure.ai.ml.entities.UserIdentityConfiguration]
+    :param is_deterministic: Specifies whether the Command will return the same output given the same input.
+        Defaults to True.
+        When True, if a Command Component is deterministic and has been run before in the current workspace
+        with the same input and settings, it will reuse results from a previously submitted job when used as a
+        node or step in a pipeline. In that scenario, no compute resources will be used.
     :type is_deterministic: bool
-    :param services: Interactive services for the node. This is an experimental parameter, and may change at any time.
-        Please see https://aka.ms/azuremlexperimental for more information.
-    :type services: Dict[str, JobService]
-    :param job_tier: **Experimental** determines the job tier.
+    :param services: The interactive services for the node. This is an experimental parameter, and may change at
+        any time. Please see https://aka.ms/azuremlexperimental for more information.
+    :type services: dict[str, Union[~azure.ai.ml.entities.JobService, ~azure.ai.ml.entities.JupyterLabJobService,
+        ~azure.ai.ml.entities.SshJobService, ~azure.ai.ml.entities.TensorBoardJobService,
+        ~azure.ai.ml.entities.VsCodeJobService]]
+    :param job_tier: The job tier. Accepted values are "Spot", "Basic", "Standard", or "Premium".
     :type job_tier: str
-    :param priority: **Experimental** controls the priority on the compute.
+    :param priority: The priority of the job on the compute. Defaults to "Medium".
     :type priority: str
+    :return: A Command object.
+    :rtype: ~azure.ai.ml.entities.Command
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_command_configurations.py
+            :start-after: [START command_function]
+            :end-before: [END command_function]
+            :language: python
+            :dedent: 8
+            :caption: Creating a Command Job using the command() builder method.
     """
     # pylint: disable=too-many-locals
     inputs = inputs or {}
     outputs = outputs or {}
     component_inputs, job_inputs = _parse_inputs_outputs(inputs, parse_func=_parse_input)
     # job inputs can not be None
     job_inputs = {k: v for k, v in job_inputs.items() if v is not None}
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/control_flow_node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/control_flow_node.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/spark_func.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/spark_func.py`

 * *Files 14% similar despite different names*

```diff
@@ -104,73 +104,110 @@
     inputs: Optional[Dict] = None,
     outputs: Optional[Dict] = None,
     args: Optional[str] = None,
     compute: Optional[str] = None,
     resources: Optional[Union[Dict, SparkResourceConfiguration]] = None,
     **kwargs,
 ) -> Spark:
-    """Create a Spark object which can be used inside dsl.pipeline as a function and
-    can also be created as a standalone spark job.
+    """Creates a Spark object which can be used inside a dsl.pipeline function or used as a standalone Spark job.
 
-    :param experiment_name:  Name of the experiment the job will be created under.
+    :param experiment_name:  The name of the experiment the job will be created under.
     :type experiment_name: str
     :param name: The name of the job.
     :type name: str
-    :param display_name: Display name of the job.
+    :param display_name: The job display name.
     :type display_name: str
-    :param description: Description of the job.
+    :param description: The description of the job.
     :type description: str
-    :param tags: Tag dictionary. Tags can be added, removed, and updated.
+    :param tags: The dictionary of tags for the job. Tags can be added, removed, and updated.
     :type tags: dict[str, str]
-    :param code: The source code to run the job.
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url pointing
+        to a remote location.
     :type code: Union[str, os.PathLike]
-    :param entry: File or class entry point.
-    :type entry: dict[str, str]
-    :param py_files: List of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
-    :type py_files: Optional[typing.List[str]]
-    :param jars: List of jars to include on the driver and executor classpaths.
-    :type jars: Optional[typing.List[str]]
-    :param files: List of files to be placed in the working directory of each executor.
-    :type files: Optional[typing.List[str]]
-    :param archives: List of archives to be extracted into the working directory of each executor.
-    :type archives: Optional[typing.List[str]]
-    :param identity: Identity that spark job will use while running on compute.
-    :type identity: Union[Dict, ManagedIdentity, AmlToken, UserIdentity]
-    :param driver_cores: Number of cores to use for the driver process, only in cluster mode.
+    :param entry: The file or class entry point.
+    :type entry: Union[dict[str, str], ~azure.ai.ml.entities.SparkJobEntry]
+    :param py_files: The list of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
+    :type py_files: list[str]
+    :param jars: The list of .JAR files to include on the driver and executor classpaths.
+    :type jars: list[str]
+    :param files: The list of files to be placed in the working directory of each executor.
+    :type files: list[str]
+    :param archives: The list of archives to be extracted into the working directory of each executor.
+    :type archives: list[str]
+    :param identity: The identity that the Spark job will use while running on compute.
+    :type identity: Union[
+        dict[str, str],
+        ~azure.ai.ml.entities.ManagedIdentityConfiguration,
+        ~azure.ai.ml.entities.AmlTokenConfiguration,
+        ~azure.ai.ml.entities.UserIdentityConfiguration]
+    :param driver_cores: The number of cores to use for the driver process, only in cluster mode.
     :type driver_cores: int
-    :param driver_memory: Amount of memory to use for the driver process.
+    :param driver_memory: The amount of memory to use for the driver process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type driver_memory: str
     :param executor_cores: The number of cores to use on each executor.
     :type executor_cores: int
-    :param executor_memory: Amount of memory to use per executor process, in the same format as JVM memory strings with
-        a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).
+    :param executor_memory: The amount of memory to use per executor process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type executor_memory: str
-    :param executor_instances: Initial number of executors.
+    :param executor_instances: The initial number of executors.
     :type executor_instances: int
     :param dynamic_allocation_enabled: Whether to use dynamic resource allocation, which scales the number of executors
         registered with this application up and down based on the workload.
     :type dynamic_allocation_enabled: bool
-    :param dynamic_allocation_min_executors: Lower bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_min_executors: The lower bound for the number of executors if dynamic allocation is
+        enabled.
     :type dynamic_allocation_min_executors: int
-    :param dynamic_allocation_max_executors: Upper bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_max_executors: The upper bound for the number of executors if dynamic allocation is
+        enabled.
     :type dynamic_allocation_max_executors: int
-    :param conf: A dict with pre-defined spark configurations key and values.
-    :type conf: dict
-    :param environment: Azure ML environment to run the job in.
-    :type environment: Union[str, azure.ai.ml.entities.Environment]
-    :param inputs: Mapping of inputs data bindings used in the job.
-    :type inputs: dict
-    :param outputs: Mapping of outputs data bindings used in the job.
-    :type outputs: dict
-    :param args: Arguments for the job.
+    :param conf: A dictionary with pre-defined Spark configurations key and values.
+    :type conf: dict[str, str]
+    :param environment: The Azure ML environment to run the job in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param inputs: A mapping of input names to input data used in the job.
+    :type inputs: dict[str, ~azure.ai.ml.Input]
+    :param outputs: A mapping of output names to output data used in the job.
+    :type outputs: dict[str, ~azure.ai.ml.Output]
+    :param args: The arguments for the job.
     :type args: str
     :param compute: The compute resource the job runs on.
     :type compute: str
-    :param resources: Compute Resource configuration for the job.
-    :type resources: Union[Dict, SparkResourceConfiguration]
+    :param resources: The compute resource configuration for the job.
+    :type resources: Union[dict, ~azure.ai.ml.entities.SparkResourceConfiguration]
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START spark_function_configuration_1]
+            :end-before: [END spark_function_configuration_1]
+            :language: python
+            :dedent: 8
+            :caption: Configuring a SparkJob.
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START spark_function_configuration_2]
+            :end-before: [END spark_function_configuration_2]
+            :language: python
+            :dedent: 8
+            :caption: Configuring a SparkJob.
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START spark_dsl_pipeline]
+            :end-before: [END spark_dsl_pipeline]
+            :language: python
+            :dedent: 8
+            :caption: Building a Spark pipeline using the DSL pipeline decorator
     """
 
     inputs = inputs or {}
     outputs = outputs or {}
     component_inputs, job_inputs = _parse_inputs_outputs(inputs, parse_func=_parse_input)
     # job inputs can not be None
     job_inputs = {k: v for k, v in job_inputs.items() if v is not None}
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/parallel_for.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/parallel_for.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import json
 import os
 from typing import Dict, Union
 
-from azure.ai.ml import Output, Input
+from azure.ai.ml import Input, Output
 from azure.ai.ml._schema import PathAwareSchema
 from azure.ai.ml._schema.pipeline.control_flow_job import ParallelForSchema
 from azure.ai.ml._utils.utils import is_data_binding_expression
 from azure.ai.ml.constants import AssetTypes
 from azure.ai.ml.constants._component import ComponentParameterTypes, ControlFlowType
 from azure.ai.ml.entities import Component
 from azure.ai.ml.entities._builders import BaseNode
@@ -71,19 +71,19 @@
 
         actual_outputs = kwargs.get("outputs", {})
         # parallel for node shares output meta with body
         try:
             outputs = self.body._component.outputs
             # transform body outputs to aggregate types when available
             self._outputs = self._build_outputs_dict(
-                output_definition_dict=self._convert_output_meta(outputs), outputs=actual_outputs
+                outputs=actual_outputs, output_definition_dict=self._convert_output_meta(outputs)
             )
         except AttributeError:
             # when body output not available, create default output builder without meta
-            self._outputs = self._build_outputs_dict_without_meta(outputs=actual_outputs)
+            self._outputs = self._build_outputs_dict(outputs=actual_outputs)
 
         self._items = items
 
         self.max_concurrency = max_concurrency
 
     @property
     def outputs(self) -> Dict[str, Union[str, Output]]:
@@ -148,15 +148,15 @@
         return rest_items
 
     def _to_rest_object(self, **kwargs) -> dict:  # pylint: disable=unused-argument
         """Convert self to a rest object for remote call."""
         rest_node = super(ParallelFor, self)._to_rest_object(**kwargs)
         # convert items to rest object
         rest_items = self._to_rest_items(items=self.items)
-        rest_node.update(dict(items=rest_items, outputs=self._to_rest_outputs()))
+        rest_node.update({"items": rest_items, "outputs": self._to_rest_outputs()})
         return convert_ordered_dict_to_dict(rest_node)
 
     @classmethod
     def _from_rest_item(cls, rest_item):
         """Convert rest item to item."""
         primitive_inputs, asset_inputs = {}, {}
         for key, val in rest_item.items():
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/condition_node.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/condition_node.py`

 * *Files 4% similar despite different names*

```diff
@@ -71,19 +71,19 @@
             )
 
         # Check if output is a control output.
         # pylint: disable=protected-access
         if isinstance(self.condition, InputOutputBase) and self.condition._meta is not None:
             # pylint: disable=protected-access
             output_definition = self.condition._meta
-            if output_definition is not None and not output_definition.is_control:
+            if output_definition is not None and not output_definition._is_control_or_primitive_type:
                 validation_result.append_error(
                     yaml_path="condition",
-                    message=f"'condition' of dsl.condition node must have 'is_control' field "
-                    f"with value 'True', got {output_definition.is_control}",
+                    message=f"'condition' of dsl.condition node must have 'is_control' field or is primitive type "
+                    f"with value 'True', got {output_definition._is_control_or_primitive_type}",
                 )
 
         # check if condition is valid binding
         if isinstance(self.condition, str) and not is_data_binding_expression(
             self.condition, ["parent"], is_singular=False
         ):
             error_tail = "for example, ${{parent.jobs.xxx.outputs.output}}"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/data_transfer.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/data_transfer.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_builders/subcomponents.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_builders/subcomponents.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/import_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/import_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job_entry_mixin.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job_entry_mixin.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_service.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_service.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/base_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/base_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/service_instance.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/service_instance.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
 
 import json
 import logging
 import traceback
-from abc import abstractclassmethod, abstractmethod
+from abc import abstractmethod
 from collections import OrderedDict
 from os import PathLike
 from pathlib import Path
 from typing import IO, AnyStr, Dict, Optional, Type, Union
 
 from azure.ai.ml._restclient.runhistory.models import Run
 from azure.ai.ml._restclient.v2023_04_01_preview.models import JobBase, JobService
@@ -314,24 +314,25 @@
             module_logger.info(
                 "Exception: %s.\n%s\nUnable to parse the job resource: %s.\n", ex, traceback.format_exc(), error_message
             )
             raise JobParsingError(
                 message=str(ex),
                 no_personal_data_message=f"Unable to parse a job resource of type:{type(obj).__name__}",
                 error_category=ErrorCategory.SYSTEM_ERROR,
-            )
+            ) from ex
         else:
             msg = f"Unsupported job type {obj.properties.job_type}"
             raise JobException(
                 message=msg,
                 no_personal_data_message=msg,
                 target=ErrorTarget.JOB,
                 error_category=ErrorCategory.SYSTEM_ERROR,
             )
 
     def _get_telemetry_values(self):  # pylint: disable=arguments-differ
         telemetry_values = {"type": self.type}
         return telemetry_values
 
-    @abstractclassmethod
+    @classmethod
+    @abstractmethod
     def _load_from_dict(cls, data: Dict, context: Dict, additional_message: str, **kwargs) -> "Job":
         pass
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/input_port.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/input_port.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/_studio_url_from_job_id.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/_studio_url_from_job_id.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parameterized_spark.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parameterized_spark.py`

 * *Files 21% similar despite different names*

```diff
@@ -10,36 +10,40 @@
 
 from .._job.spark_job_entry_mixin import SparkJobEntryMixin
 
 DUMMY_IMAGE = "conda/miniconda3"
 
 
 class ParameterizedSpark(SparkJobEntryMixin):
-    """Spark component that contains supporting parameters.
+    """
+    This class should not be instantiated directly. Instead, use the child class ~azure.ai.ml.entities.SparkComponent.
+
+    Spark component that contains supporting parameters.
 
-    :param code: The source code to run the job.
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url pointing
+        to a remote location.
     :type code: str
-    :param entry: Entry.
-    :type entry: str
-    :param py_files: List of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
+    :param entry: The file or class entry point.
+    :type entry: dict[str, str]
+    :param py_files: The list of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
     :type py_files: list[str]
-    :param jars: List of jars to include on the driver and executor classpaths.
+    :param jars: The list of .JAR files to include on the driver and executor classpaths.
     :type jars: list[str]
-    :param files: List of files to be placed in the working directory of each executor.
+    :param files: The list of files to be placed in the working directory of each executor.
     :type files: list[str]
-    :param archives: List of archives to be extracted into the working directory of each executor.
+    :param archives: The list of archives to be extracted into the working directory of each executor.
     :type archives: list[str]
-    :param conf: A dict with pre-defined spark configurations key and values.
-    :type conf: dict
-    :param environment: Azure ML environment to run the job in.
-    :type environment: Union[str, azure.ai.ml.entities.Environment]
-    :param args: Arguments for the job.
+    :param conf: A dictionary with pre-defined Spark configurations key and values.
+    :type conf: dict[str, str]
+    :param environment: The Azure ML environment to run the job in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param args: The arguments for the job.
     :type args: str
     :param kwargs: A dictionary of additional configuration parameters.
-    :type kwargs: dict
+    :type kwargs: dict[str, Any]
     """
 
     def __init__(
         self,
         code: Union[str, os.PathLike] = ".",
         entry: Union[Dict[str, str], SparkJobEntry, None] = None,
         py_files: Optional[List[str]] = None,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/compute_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/compute_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parameterized_command.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parameterized_command.py`

 * *Files 23% similar despite different names*

```diff
@@ -13,47 +13,58 @@
 from azure.ai.ml._schema.core.fields import ExperimentalField
 from azure.ai.ml.entities._assets import Environment
 
 from ..._schema import NestedField, UnionField
 from ..._schema.job.distribution import (
     MPIDistributionSchema,
     PyTorchDistributionSchema,
-    TensorFlowDistributionSchema,
     RayDistributionSchema,
+    TensorFlowDistributionSchema,
 )
 from .distribution import (
     DistributionConfiguration,
     MpiDistribution,
     PyTorchDistribution,
-    TensorFlowDistribution,
     RayDistribution,
+    TensorFlowDistribution,
 )
 from .job_resource_configuration import JobResourceConfiguration
 from .queue_settings import QueueSettings
 
 module_logger = logging.getLogger(__name__)
 
 # no reference found. leave it for future use.
 INPUT_BINDING_PREFIX = "AZURE_ML_INPUT_"
 OLD_INPUT_BINDING_PREFIX = "AZURE_ML_INPUT"
 
 
 class ParameterizedCommand:
-    """Command component that contains the training command and supporting parameters for the command.
+    """This class should not be instantiated directly. Instead, use the child class
+    ~azure.ai.ml.entities.CommandComponent.
+
+    Command component version that contains the command and supporting parameters for a Command component
+    or job.
 
-    :param command: Command to be executed in training.
+    :param command: The command to be executed.
     :type command: str
-    :param code: A local or remote path pointing at source code.
+    :param resources: The compute resource configuration for the command.
+    :type resources: Union[dict, ~azure.ai.ml.entities.JobResourceConfiguration]
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url pointing
+        to a remote location.
     :type code: str
-    :param distribution: Distribution configuration for distributed training.
-    :type distribution: Union[Dict, PyTorchDistribution, MpiDistribution, TensorFlowDistribution]
-    :param environment: Environment that training job will run in.
-    :type environment: Union[Environment, str]
-    :param resources: Compute Resource configuration for the job.
-    :type resources: Union[Dict, ~azure.ai.ml.entities.JobResourceConfiguration]
+    :param environment_variables: A dictionary of environment variable names and values.
+        These environment variables are set on the process where user script is being executed.
+    :type environment_variables: dict[str, str]
+    :param distribution: The distribution configuration for distributed jobs.
+    :type distribution: Union[dict, ~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+    :param environment: The environment that the job will run in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param queue_settings: The queue settings for the job.
+    :type queue_settings: ~azure.ai.ml.entities.QueueSettings
     :param kwargs: A dictionary of additional configuration parameters.
     :type kwargs: dict
     """
 
     def __init__(
         self,
         command: str = "",
@@ -67,16 +78,16 @@
                 TensorFlowDistribution,
                 PyTorchDistribution,
                 RayDistribution,
             ]
         ] = None,
         environment: Optional[Union[Environment, str]] = None,
         queue_settings: Optional[QueueSettings] = None,
-        **kwargs,
-    ):
+        **kwargs: Dict,
+    ) -> None:
         super().__init__(**kwargs)
         self.command = command
         self.code = code
         self.environment_variables = dict(environment_variables) if environment_variables else {}
         self.environment = environment
         self.distribution: Union[
             MpiDistribution,
@@ -87,36 +98,56 @@
         self.resources = resources
         self.queue_settings = queue_settings
 
     @property
     def distribution(
         self,
     ) -> Union[MpiDistribution, TensorFlowDistribution, PyTorchDistribution, RayDistribution]:
+        """The configuration for the distributed command component or job.
+
+        :rtype: Union[~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+        """
         return self._distribution
 
     @distribution.setter
-    def distribution(self, value):
+    def distribution(self, value: Union[dict, PyTorchDistribution, MpiDistribution]) -> None:
+        """Sets the configuration for the distributed command component or job.
+
+        :param value: The distribution configuration for distributed jobs.
+        :type value: Union[dict, ~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+        """
         if isinstance(value, dict):
             dist_schema = UnionField(
                 [
                     NestedField(PyTorchDistributionSchema, unknown=INCLUDE),
                     NestedField(TensorFlowDistributionSchema, unknown=INCLUDE),
                     NestedField(MPIDistributionSchema, unknown=INCLUDE),
                     ExperimentalField(NestedField(RayDistributionSchema, unknown=INCLUDE)),
                 ]
             )
             value = dist_schema._deserialize(value=value, attr=None, data=None)
         self._distribution = value
 
     @property
     def resources(self) -> JobResourceConfiguration:
+        """The compute resource configuration for the command component or job.
+
+        :rtype: ~azure.ai.ml.entities.JobResourceConfiguration
+        """
         return self._resources
 
     @resources.setter
-    def resources(self, value):
+    def resources(self, value: Union[dict, JobResourceConfiguration]) -> None:
+        """Sets the compute resource configuration for the command component or job.
+
+        :param value: The compute resource configuration for the command component or job.
+        :type value: Union[dict, ~azure.ai.ml.entities.JobResourceConfiguration]
+        """
         if isinstance(value, dict):
             value = JobResourceConfiguration(**value)
         self._resources = value
 
     @classmethod
     def _load_from_sweep_job(cls, sweep_job: SweepJob) -> "ParameterizedCommand":
         parameterized_command = cls(
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_name_generator.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_name_generator.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/queue_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/queue_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/resource_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/resource_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job.py`

 * *Files 10% similar despite different names*

```diff
@@ -42,81 +42,90 @@
 from .spark_job_entry_mixin import SparkJobEntryMixin
 from .spark_resource_configuration import SparkResourceConfiguration
 
 module_logger = logging.getLogger(__name__)
 
 
 class SparkJob(Job, ParameterizedSpark, JobIOMixin, SparkJobEntryMixin):
-    """Create a standalone spark job.
+    """A standalone Spark job.
 
-    :param experiment_name:  Name of the experiment the job will be created under.
-    :type experiment_name: str
-    :param name: The name of the job.
-    :type name: str
-    :param display_name: Display name of the job.
-    :type display_name: str
-    :param description: Description of the job.
-    :type description: str
-    :param tags: Tag dictionary. Tags can be added, removed, and updated.
-    :type tags: dict[str, str]
-    :param code: The source code to run the job.
-    :type code: Union[str, os.PathLike]
-    :param entry: File or class entry point.
-    :type entry: dict[str, str]
-    :param py_files: List of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
-    :type py_files: Optional[typing.List[str]]
-    :param jars: List of jars to include on the driver and executor classpaths.
-    :type jars: Optional[typing.List[str]]
-    :param files: List of files to be placed in the working directory of each executor.
-    :type files: Optional[typing.List[str]]
-    :param archives: List of archives to be extracted into the working directory of each executor.
-    :type archives: Optional[typing.List[str]]
-    :param identity: Identity that spark job will use while running on compute.
-    :type identity: Union[
-        azure.ai.ml.ManagedIdentityConfiguration,
-        azure.ai.ml.AmlTokenConfiguration,
-        azure.ai.ml.UserIdentityConfiguration]
-    :param driver_cores: Number of cores to use for the driver process, only in cluster mode.
+    :param driver_cores: The number of cores to use for the driver process, only in cluster mode.
     :type driver_cores: int
-    :param driver_memory: Amount of memory to use for the driver process.
+    :param driver_memory: The amount of memory to use for the driver process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type driver_memory: str
     :param executor_cores: The number of cores to use on each executor.
     :type executor_cores: int
-    :param executor_memory: Amount of memory to use per executor process, in the same format as JVM memory strings with
-        a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).
+    :param executor_memory: The amount of memory to use per executor process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type executor_memory: str
-    :param executor_instances: Initial number of executors.
+    :param executor_instances: The initial number of executors.
     :type executor_instances: int
     :param dynamic_allocation_enabled: Whether to use dynamic resource allocation, which scales the number of executors
         registered with this application up and down based on the workload.
     :type dynamic_allocation_enabled: bool
-    :param dynamic_allocation_min_executors: Lower bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_min_executors: The lower bound for the number of executors if dynamic allocation is
+        enabled.
     :type dynamic_allocation_min_executors: int
-    :param dynamic_allocation_max_executors: Upper bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_max_executors: The upper bound for the number of executors if dynamic allocation is
+        enabled.
     :type dynamic_allocation_max_executors: int
-    :param conf: A dict with pre-defined spark configurations key and values.
-    :type conf: dict
-    :param environment: Azure ML environment to run the job in.
-    :type environment: Union[str, azure.ai.ml.entities.Environment]
-    :param inputs: Mapping of inputs data bindings used in the job.
-    :type inputs: dict
-    :param outputs: Mapping of outputs data bindings used in the job.
-    :type outputs: dict
-    :param args: Arguments for the job.
-    :type args: str
+    :param inputs: The mapping of input data bindings used in the job.
+    :type inputs: dict[str, ~azure.ai.ml.Input]
+    :param outputs: The mapping of output data bindings used in the job.
+    :type outputs: dict[str, ~azure.ai.ml.Output]
     :param compute: The compute resource the job runs on.
     :type compute: str
-    :param identity: Identity that spark job will use while running on compute.
+    :param identity: The identity that the Spark job will use while running on compute.
     :type identity: Union[
-        Dict,
-        ManagedIdentityConfiguration,
-        AmlTokenConfiguration,
-        UserIdentityConfiguration]
-    :param resources: Compute Resource configuration for the job.
-    :type resources: Union[Dict, SparkResourceConfiguration]
+        dict[str, str],
+        ~azure.ai.ml.ManagedIdentityConfiguration,
+        ~azure.ai.ml.AmlTokenConfiguration,
+        ~azure.ai.ml.UserIdentityConfiguration]
+    :param resources: The compute resource configuration for the job.
+    :type resources: Union[dict, ~azure.ai.ml.entities.SparkResourceConfiguration]
+    :param experiment_name: The name of the experiment the job will be created under.
+    :type experiment_name: str
+    :param name: The name of the job.
+    :type name: str
+    :param display_name: The job display name.
+    :type display_name: str
+    :param description: The job description.
+    :type description: str
+    :param tags: The tag dictionary. Tags can be added, removed, and updated.
+    :type tags: dict[str, str]
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url pointing
+        to a remote location.
+    :type code: Union[str, os.PathLike]
+    :param entry: The file or class entry point.
+    :type entry: dict[str, str]
+    :param py_files: The list of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
+    :type py_files: list[str]
+    :param jars: The list of .JAR files to include on the driver and executor classpaths.
+    :type jars: list[str]
+    :param files: The list of files to be placed in the working directory of each executor.
+    :type files: list[str]
+    :param archives: The list of archives to be extracted into the working directory of each executor.
+    :type archives: list[str]
+    :param conf: A dictionary with pre-defined Spark configurations key and values.
+    :type conf: dict[str, str]
+    :param environment: The Azure ML environment to run the job in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param args: The arguments for the job.
+    :type args: str
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START spark_job_configuration]
+            :end-before: [END spark_job_configuration]
+            :language: python
+            :dedent: 8
+            :caption: Configuring a SparkJob.
     """
 
     def __init__(
         self,
         *,
         driver_cores: Optional[int] = None,
         driver_memory: Optional[str] = None,
@@ -128,17 +137,17 @@
         dynamic_allocation_max_executors: Optional[int] = None,
         inputs: Optional[Dict] = None,
         outputs: Optional[Dict] = None,
         compute: Optional[str] = None,
         identity: Optional[
             Union[Dict[str, str], ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration]
         ] = None,
-        resources: Union[Dict, SparkResourceConfiguration, None] = None,
+        resources: Optional[Union[Dict, SparkResourceConfiguration]] = None,
         **kwargs,
-    ):
+    ) -> None:
         kwargs[TYPE] = JobType.SPARK
 
         super().__init__(**kwargs)
         self.conf = self.conf or {}
         self.properties = self.properties or {}
         self.driver_cores = driver_cores
         self.driver_memory = driver_memory
@@ -154,35 +163,55 @@
         self.resources = resources
         self.identity = identity
         if self.executor_instances is None and str(self.dynamic_allocation_enabled).lower() == "true":
             self.executor_instances = self.dynamic_allocation_min_executors
 
     @property
     def resources(self) -> Optional[SparkResourceConfiguration]:
+        """The compute resource configuration for the job.
+
+        :rtype: ~azure.ai.ml.entities.SparkResourceConfiguration
+        """
         return self._resources
 
     @resources.setter
     def resources(self, value: Union[Dict[str, str], SparkResourceConfiguration, None]):
+        """Sets the compute resource configuration for the job.
+
+        :param value: The compute resource configuration for the job.
+        :type value: Union[dict, ~azure.ai.ml.entities.SparkResourceConfiguration]
+        """
         if isinstance(value, dict):
             value = SparkResourceConfiguration(**value)
         self._resources = value
 
     @property
     def identity(
         self,
     ) -> Optional[Union[ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration]]:
+        """The identity that the Spark job will use while running on compute.
+
+        :rtype: Union[~azure.ai.ml.ManagedIdentityConfiguration, ~azure.ai.ml.AmlTokenConfiguration,
+            ~azure.ai.ml.UserIdentityConfiguration]
+        """
         return self._identity
 
     @identity.setter
     def identity(
         self,
         value: Union[
             Dict[str, str], ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration, None
         ],
     ):
+        """Sets the identity that the Spark job will use while running on compute.
+
+        :param value: The identity that the Spark job will use while running on compute.
+        :type value: Union[dict[str, str], ~azure.ai.ml.ManagedIdentityConfiguration,
+            ~azure.ai.ml.AmlTokenConfiguration, ~azure.ai.ml.UserIdentityConfiguration]
+        """
         if isinstance(value, dict):
             identify_schema = UnionField(
                 [
                     NestedField(ManagedIdentitySchema, unknown=INCLUDE),
                     NestedField(AMLTokenIdentitySchema, unknown=INCLUDE),
                     NestedField(UserIdentitySchema, unknown=INCLUDE),
                 ]
@@ -190,15 +219,21 @@
             value = identify_schema._deserialize(value=value, attr=None, data=None)
         self._identity = value
 
     def _to_dict(self) -> Dict:
         # pylint: disable=no-member
         return SparkJobSchema(context={BASE_PATH_CONTEXT_KEY: "./"}).dump(self)
 
-    def filter_conf_fields(self):
+    def filter_conf_fields(self) -> Dict[str, str]:
+        """Filters out the fields of the conf attribute that are not among the Spark configuration fields
+        listed in ~azure.ai.ml._schema.job.parameterized_spark.CONF_KEY_MAP and returns them in their own dictionary.
+
+        :return: A dictionary of the conf fields that are not Spark configuration fields.
+        :rtype: dict[str, str]
+        """
         if self.conf is None:
             return {}
         data_conf = {}
         for conf_key, conf_val in self.conf.items():
             if not conf_key in CONF_KEY_MAP:
                 data_conf[conf_key] = conf_val
         return data_conf
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/input_output_entry.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/input_output_entry.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/to_rest_functions.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/to_rest_functions.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/_input_output_helpers.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/_input_output_helpers.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_job_entry.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_job_entry.py`

 * *Files 26% similar despite different names*

```diff
@@ -7,28 +7,41 @@
 
 from azure.ai.ml._restclient.v2023_04_01_preview.models import SparkJobEntry as RestSparkJobEntry
 from azure.ai.ml._restclient.v2023_04_01_preview.models import SparkJobPythonEntry, SparkJobScalaEntry
 from azure.ai.ml.entities._mixins import RestTranslatableMixin
 
 
 class SparkJobEntryType:
+    """Type of Spark job entry. Possibilities are Python file entry or Scala class entry."""
+
     SPARK_JOB_FILE_ENTRY = "SparkJobPythonEntry"
     SPARK_JOB_CLASS_ENTRY = "SparkJobScalaEntry"
 
 
 class SparkJobEntry(RestTranslatableMixin):
-    """Entry for spark job.
+    """Entry for Spark job.
 
-    :param entry_type: Can be python or scala entry.
-    :type entry_type: SparkJobEntryType
-    :param entry: File or class entry point.
+    :param entry: The file or class entry point.
     :type entry: str
+    :param type: The entry type. Accepted values are SparkJobEntryType.SPARK_JOB_FILE_ENTRY or
+        SparkJobEntryType.SPARK_JOB_CLASS_ENTRY. Defaults to SparkJobEntryType.SPARK_JOB_FILE_ENTRY.
+    :type type: ~azure.ai.ml.entities.SparkJobEntryType
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START spark_component_definition]
+            :end-before: [END spark_component_definition]
+            :language: python
+            :dedent: 8
+            :caption: Creating SparkComponent.
     """
 
-    def __init__(self, *, entry: str, type: str = SparkJobEntryType.SPARK_JOB_FILE_ENTRY):
+    def __init__(self, *, entry: str, type: str = SparkJobEntryType.SPARK_JOB_FILE_ENTRY) -> None:
         self.entry_type = type
         self.entry = entry
 
     @classmethod
     def _from_rest_object(cls, obj: Union[SparkJobPythonEntry, SparkJobScalaEntry]) -> Optional["SparkJobEntry"]:
         if obj is None:
             return
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/command_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/command_job.py`

 * *Files 4% similar despite different names*

```diff
@@ -27,16 +27,16 @@
     from_rest_inputs_to_dataset_literal,
     to_rest_data_outputs,
     to_rest_dataset_literal_inputs,
     validate_inputs_for_command,
 )
 from azure.ai.ml.entities._job.distribution import DistributionConfiguration
 from azure.ai.ml.entities._job.job_service import (
-    JobServiceBase,
     JobService,
+    JobServiceBase,
     JupyterLabJobService,
     SshJobService,
     TensorBoardJobService,
     VsCodeJobService,
 )
 from azure.ai.ml.entities._system_data import SystemData
 from azure.ai.ml.entities._util import load_from_dict
@@ -51,74 +51,84 @@
 
 module_logger = logging.getLogger(__name__)
 
 
 class CommandJob(Job, ParameterizedCommand, JobIOMixin):
     """Command job.
 
-    :param name: Name of the job.
+    :param name: The name of the job.
     :type name: str
-    :param description: Description of the job.
+    :param description: The job description.
     :type description: str
     :param tags: Tag dictionary. Tags can be added, removed, and updated.
     :type tags: dict[str, str]
-    :param display_name: Display name of the job.
+    :param display_name: The job display name.
     :type display_name: str
-    :param properties: The asset property dictionary.
+    :param properties: A dictionary of properties for the job.
     :type properties: dict[str, str]
-    :param experiment_name:  Name of the experiment the job will be created under.
-        If None is provided, default will be set to current directory name.
+    :param experiment_name: The name of the experiment that the job will be created under. Defaults to current
+        directory name.
     :type experiment_name: str
-    :param services: Information on services associated with the job, readonly.
-    :type services: dict[str, JobService]
-    :param inputs: Inputs to the command.
-    :type inputs: dict[str, Union[azure.ai.ml.Input, str, bool, int, float]]
+    :param services: Read-only information on services associated with the job.
+    :type services: dict[str, ~azure.ai.ml.entities.JobService]
+    :param inputs: Mapping of output data bindings used in the command.
+    :type inputs: dict[str, Union[~azure.ai.ml.Input, str, bool, int, float]]
     :param outputs: Mapping of output data bindings used in the job.
-    :type outputs: dict[str, azure.ai.ml.Output]
-    :param command: Command to be executed in training.
+    :type outputs: dict[str, ~azure.ai.ml.Output]
+    :param command: The command to be executed.
     :type command: str
     :param compute: The compute target the job runs on.
     :type compute: str
-    :param resources: Compute Resource configuration for the job.
+    :param resources: The compute resource configuration for the job.
     :type resources: ~azure.ai.ml.entities.ResourceConfiguration
-    :param code: A local path or http:, https:, azureml: url pointing to a remote location.
+    :param code: A local path or "http:", "https:", or "azureml:" url pointing to a remote location.
     :type code: str
-    :param distribution: Distribution configuration for distributed training.
+    :param distribution: The distribution configuration for distributed jobs.
     :type distribution: Union[
-        azure.ai.ml.PyTorchDistribution,
-        azure.ai.ml.MpiDistribution,
-        azure.ai.ml.TensorFlowDistribution,
-        azure.ai.ml.RayDistribution]
-    :param environment: Environment that training job will run in.
-    :type environment: Union[azure.ai.ml.entities.Environment, str]
-    :param identity: Identity that training job will use while running on compute.
+        ~azure.ai.ml.PyTorchDistribution,
+        ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution,
+        ~azure.ai.ml.RayDistribution]
+    :param environment: The environment that the job will run in.
+    :type environment: Union[~azure.ai.ml.entities.Environment, str]
+    :param identity: The identity that the job will use while running on compute.
     :type identity: Union[
-        azure.ai.ml.ManagedIdentityConfiguration,
-        azure.ai.ml.AmlTokenConfiguration,
-        azure.ai.ml.UserIdentityConfiguration]
-    :param limits: Command Job limit.
+        ~azure.ai.ml.ManagedIdentityConfiguration,
+        ~azure.ai.ml.AmlTokenConfiguration,
+        ~azure.ai.ml.UserIdentityConfiguration]
+    :param limits: The limits for the job.
     :type limits: ~azure.ai.ml.entities.CommandJobLimits
     :param kwargs: A dictionary of additional configuration parameters.
-    :type kwargs: dict
+    :type kwargs: dict[str, Any]
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_command_configurations.py
+            :start-after: [START command_job_definition]
+            :end-before: [END command_job_definition]
+            :language: python
+            :dedent: 8
+            :caption: Configuring a CommandJob.
     """
 
     def __init__(
         self,
         *,
         inputs: Optional[Dict[str, Union[Input, str, bool, int, float]]] = None,
-        outputs: Optional[Dict[str, Union[Output]]] = None,
+        outputs: Optional[Dict[str, Output]] = None,
         limits: Optional[CommandJobLimits] = None,
         identity: Optional[
             Union[ManagedIdentityConfiguration, AmlTokenConfiguration, UserIdentityConfiguration]
         ] = None,
         services: Optional[
             Dict[str, Union[JobService, JupyterLabJobService, SshJobService, TensorBoardJobService, VsCodeJobService]]
         ] = None,
         **kwargs,
-    ):
+    ) -> None:
         kwargs[TYPE] = JobType.COMMAND
         self._parameters = kwargs.pop("parameters", {})
 
         super().__init__(**kwargs)
 
         self.outputs = outputs
         self.inputs = inputs
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_io_mixin.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_io_mixin.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_resource_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_resource_configuration.py`

 * *Files 16% similar despite different names*

```diff
@@ -8,23 +8,41 @@
     SparkResourceConfiguration as RestSparkResourceConfiguration,
 )
 from azure.ai.ml.entities._mixins import DictMixin, RestTranslatableMixin
 from azure.ai.ml.exceptions import ErrorCategory, ErrorTarget, ValidationException
 
 
 class SparkResourceConfiguration(RestTranslatableMixin, DictMixin):
+    """Compute resource configuration for Spark component or job.
+
+    :param instance_type: The type of VM to be used by the compute target.
+    :type instance_type: str
+    :param runtime_version: The Spark runtime version.
+    :type runtime_version: str
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START spark_resource_configuration]
+            :end-before: [END spark_resource_configuration]
+            :language: python
+            :dedent: 8
+            :caption: Configuring a SparkJob with SparkResourceConfiguration.
+    """
+
     instance_type_list = [
         "standard_e4s_v3",
         "standard_e8s_v3",
         "standard_e16s_v3",
         "standard_e32s_v3",
         "standard_e64s_v3",
     ]
 
-    def __init__(self, *, instance_type: Optional[str] = None, runtime_version: Optional[str] = None):
+    def __init__(self, *, instance_type: Optional[str] = None, runtime_version: Optional[str] = None) -> None:
         self.instance_type = instance_type
         self.runtime_version = runtime_version
 
     def _to_rest_object(self) -> RestSparkResourceConfiguration:
         return RestSparkResourceConfiguration(instance_type=self.instance_type, runtime_version=self.runtime_version)
 
     @classmethod
@@ -66,16 +84,16 @@
                     error_category=ErrorCategory.USER_ERROR,
                 )
         elif isinstance(self.runtime_version, str):
             runtime_arr = self.runtime_version.split(".")
             try:
                 for runtime in runtime_arr:
                     int(runtime)
-            except ValueError:
-                raise ValueError("runtime_version should only contain numbers")
+            except ValueError as e:
+                raise ValueError("runtime_version should only contain numbers") from e
             if len(runtime_arr) <= 1:
                 msg = "runtime version should be either 3.2 or 3.3"
                 raise ValidationException(
                     message=msg,
                     no_personal_data_message=msg,
                     target=ErrorTarget.SPARK_JOB,
                     error_category=ErrorCategory.USER_ERROR,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_resource_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_resource_configuration.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,17 +2,15 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 import json
 import logging
 from typing import Any, Dict, List, Optional
 
-from azure.ai.ml._restclient.v2023_04_01_preview.models import (
-    JobResourceConfiguration as RestJobResourceConfiguration,
-)
+from azure.ai.ml._restclient.v2023_04_01_preview.models import JobResourceConfiguration as RestJobResourceConfiguration
 from azure.ai.ml.constants._job.job import JobComputePropertyFields
 from azure.ai.ml.entities._mixins import DictMixin, RestTranslatableMixin
 from azure.ai.ml.entities._util import convert_ordered_dict_to_dict
 
 module_logger = logging.getLogger(__name__)
 
 
@@ -84,61 +82,83 @@
         # recursively convert Ordered Dict to dictionary
         return convert_ordered_dict_to_dict(result)
 
 
 class JobResourceConfiguration(RestTranslatableMixin, DictMixin):
     """Class for job resource, inherited and extended functionalities from ResourceConfiguration.
 
-    :param instance_count: Optional number of instances or nodes used by the compute target.
+    :param locations: A list of locations where the job can run.
+    :type locations: list[str]
+    :param instance_count: The number of instances or nodes used by the compute target.
     :type instance_count: int
-    :param locations: Optional list of locations where the job can run.
-    :vartype locations: List[str]
-    :param instance_type: Optional type of VM used as supported by the compute target.
+    :param instance_type: The type of VM to be used, as supported by the compute target.
     :type instance_type: str
-    :param max_instance_count: Optional maximum number of instances or nodes used by the compute target.
-    :type max_instance_count: int
-    :param properties: Additional properties bag.
-    :type properties: Dict[str, Any]
+    :param properties: A dictionary of properties for the job.
+    :type properties: dict[str, Any]
     :param docker_args: Extra arguments to pass to the Docker run command. This would override any
      parameters that have already been set by the system, or in this section. This parameter is only
      supported for Azure ML compute types.
     :type docker_args: str
-    :param shm_size: Size of the docker container's shared memory block. This should be in the
-     format of (number)(unit) where number as to be greater than 0 and the unit can be one of
+    :param shm_size: The size of the docker container's shared memory block. This should be in the
+     format of (number)(unit) where the number has to be greater than 0 and the unit can be one of
      b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).
     :type shm_size: str
+    :param max_instance_count: The maximum number of instances or nodes used by the compute target.
+    :type max_instance_count: int
+    :param kwargs: A dictionary of additional configuration parameters.
+    :type kwargs: dict[str, Any]
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_command_configurations.py
+            :start-after: [START command_job_resource_configuration]
+            :end-before: [END command_job_resource_configuration]
+            :language: python
+            :dedent: 8
+            :caption: Configuring a CommandJob with a JobResourceConfiguration.
     """
 
     def __init__(
         self,
         *,
         locations: Optional[List[str]] = None,
         instance_count: Optional[int] = None,
         instance_type: Optional[str] = None,
         properties: Optional[Dict[str, Any]] = None,
         docker_args: Optional[str] = None,
         shm_size: Optional[str] = None,
         max_instance_count: Optional[int] = None,
-        **kwargs
-    ):  # pylint: disable=unused-argument
+        **kwargs  # pylint: disable=unused-argument
+    ) -> None:
         self.locations = locations
         self.instance_count = instance_count
         self.instance_type = instance_type
         self.shm_size = shm_size
         self.max_instance_count = max_instance_count
         self.docker_args = docker_args
         self._properties = None
         self.properties = properties
 
     @property
     def properties(self) -> Properties:
+        """The properties of the job.
+
+        :rtype: ~azure.ai.ml.entities._job.job_resource_configuration.Properties
+        """
         return self._properties
 
     @properties.setter
     def properties(self, properties: Dict[str, Any]):
+        """Sets the properties of the job.
+
+        :param properties: A dictionary of properties for the job.
+        :type properties: Dict[str, Any]
+        :raises TypeError: Raised if properties is not a dictionary type.
+        """
         if properties is None:
             self._properties = Properties()
         elif isinstance(properties, dict):
             self._properties = Properties(**properties)
         else:
             raise TypeError("properties must be a dict.")
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/distribution.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/distribution.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/job_limits.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/job_limits.py`

 * *Files 10% similar despite different names*

```diff
@@ -12,36 +12,51 @@
 from azure.ai.ml.constants import JobType
 from azure.ai.ml.entities._mixins import RestTranslatableMixin
 
 module_logger = logging.getLogger(__name__)
 
 
 class JobLimits(RestTranslatableMixin, ABC):
+    """Base class for Job limits.
+
+    This class should not be instantiated directly. Instead, one of its child classes should be used.
+
+    :param type: The job type.
+    :type type: ~azure.ai.ml.constants.JobType
+    """
+
     def __init__(
         self,
-    ):
+    ) -> None:
         self.type = None
 
     def __eq__(self, other) -> bool:
         if not isinstance(other, JobLimits):
             return NotImplemented
         return self._to_rest_object() == other._to_rest_object()
 
 
 class CommandJobLimits(JobLimits):
-    """Command Job limit class.
-
-    Variables are only populated by the server, and will be ignored when sending a request.
+    """Limits for Command Jobs.
 
-    :param timeout: The max run duration in seconds, after which the job will be cancelled.
-     Only supports duration with precision as low as Seconds.
+    :param timeout: The maximum run duration, in seconds, after which the job will be cancelled.
     :type timeout: int
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_command_configurations.py
+            :start-after: [START command_job_definition]
+            :end-before: [END command_job_definition]
+            :language: python
+            :dedent: 8
+            :caption: Configuring a CommandJob with CommandJobLimits.
     """
 
-    def __init__(self, *, timeout: Union[int, str, None] = None):
+    def __init__(self, *, timeout: Union[int, str, None] = None) -> None:
         super().__init__()
         self.type = JobType.COMMAND
         self.timeout = timeout
 
     def _to_rest_object(self) -> RestCommandJobLimits:
         if is_data_binding_expression(self.timeout):
             return RestCommandJobLimits(timeout=self.timeout)
@@ -58,26 +73,23 @@
                 return cls(timeout=timeout_value)
             # if response timeout is a normal iso date string
             obj = RestCommandJobLimits.from_dict(obj)
         return cls(timeout=from_iso_duration_format(obj.timeout))
 
 
 class SweepJobLimits(JobLimits):
-    """Sweep Job limit class.
+    """Limits for Sweep Jobs.
 
-    Variables are only populated by the server, and will be ignored when sending a request.
-
-    :param max_concurrent_trials: Sweep Job max concurrent trials.
+    :param max_concurrent_trials: The maximum number of concurrent trials for the Sweep Job.
     :type max_concurrent_trials: int
-    :param max_total_trials: Sweep Job max total trials.
+    :param max_total_trials: The maximum number of total trials for the Sweep Job.
     :type max_total_trials: int
-    :param timeout: The max run duration in seconds , after which the job will be cancelled.
-     Only supports duration with precision as low as Seconds.
+    :param timeout: The maximum run duration, in seconds, after which the job will be cancelled.
     :type timeout: int
-    :param trial_timeout: Sweep Job Trial timeout value in seconds.
+    :param trial_timeout: The timeout value, in seconds, for each Sweep Job trial.
     :type trial_timeout: int
 
     .. admonition:: Example:
         :class: tip
 
         .. literalinclude:: ../samples/ml_samples_sweep_configurations.py
             :start-after: [START configure_sweep_job_bayesian_sampling_algorithm]
@@ -91,47 +103,53 @@
         self,
         *,
         max_concurrent_trials: Optional[int] = None,
         max_total_trials: Optional[int] = None,
         timeout: Optional[int] = None,
         trial_timeout: Optional[int] = None,
     ) -> None:
-        """Sweep Job limit class.
-
-        :param max_concurrent_trials: Sweep Job max concurrent trials.
-        :type max_concurrent_trials: int
-        :param max_total_trials: Sweep Job max total trials.
-        :type max_total_trials: int
-        :param timeout: The max run duration in seconds , after which the job will be cancelled.
-        Only supports duration with precision as low as Seconds.
-        :type timeout: int
-        :param trial_timeout: Sweep Job Trial timeout value in seconds.
-        :type trial_timeout: int
-        """
         super().__init__()
         self.type = JobType.SWEEP
         self.max_concurrent_trials = max_concurrent_trials
         self.max_total_trials = max_total_trials
         self._timeout = _get_floored_timeout(timeout)
         self._trial_timeout = _get_floored_timeout(trial_timeout)
 
     @property
     def timeout(self) -> int:
+        """The maximum run duration, in seconds, after which the job will be cancelled.
+
+        :rtype: int
+        """
         return self._timeout
 
     @timeout.setter
     def timeout(self, value: int) -> None:
+        """Sets the maximum run duration.
+
+        :param value: The maximum run duration, in seconds, after which the job will be cancelled.
+        :type value: int
+        """
         self._timeout = _get_floored_timeout(value)
 
     @property
     def trial_timeout(self) -> int:
+        """The timeout value, in seconds, for each Sweep Job trial.
+
+        :rtype: int
+        """
         return self._trial_timeout
 
     @trial_timeout.setter
     def trial_timeout(self, value: int) -> None:
+        """Sets the timeout value for each Sweep Job trial.
+
+        :param value: The timeout value, in seconds, for each Sweep Job trial.
+        :type value: int
+        """
         self._trial_timeout = _get_floored_timeout(value)
 
     def _to_rest_object(self) -> RestSweepJobLimits:
         return RestSweepJobLimits(
             max_concurrent_trials=self.max_concurrent_trials,
             max_total_trials=self.max_total_trials,
             timeout=to_iso_duration_format(self.timeout),
@@ -156,16 +174,14 @@
     # If duration is non-0 and less than 60, set to 60.
     return value if not value or value > 60 else 60
 
 
 class DoWhileJobLimits(JobLimits):
     """DoWhile Job limit class.
 
-    Variables are only populated by the server, and will be ignored when sending a request.
-
     :param max_iteration_count:
     :type max_iteration_count: int
     """
 
     def __init__(
         self,
         *,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/spark_helpers.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/spark_helpers.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/search_space_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/search_space_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/automl_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/automl_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/featurization_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/featurization_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/automl_vertical.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/automl_vertical.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/stack_ensemble_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/stack_ensemble_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/training_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/training_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/automl_tabular.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/automl_tabular.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/classification_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/classification_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/limit_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/limit_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/regression_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/regression_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/featurization_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/featurization_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/tabular/forecasting_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_fixed_parameters.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_fixed_parameters.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_search_space.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_search_space.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_limit_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_limit_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_featurization_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_featurization_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_multilabel_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_classification_multilabel_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/text_ner_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/text_ner_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/nlp_sweep_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/nlp_sweep_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/nlp/automl_nlp_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/nlp/automl_nlp_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image_classification_base.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image_classification_base.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_search_space.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_search_space.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image_object_detection_base.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image_object_detection_base.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_instance_segmentation_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_instance_segmentation_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/automl_image.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/automl_image.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_sweep_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_sweep_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_limit_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_limit_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_classification_multilabel_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_classification_multilabel_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_model_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_model_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_search_space.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_search_space.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/automl/image/image_object_detection_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parallel_task.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parallel_task.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/run_function.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/run_function.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parallel_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parallel_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/parameterized_parallel.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/parameterized_parallel.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/parallel/retry_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/parallel/retry_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/pipeline_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/pipeline_job.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,44 +29,44 @@
 from azure.ai.ml.entities._builders.condition_node import ConditionNode
 from azure.ai.ml.entities._builders.control_flow_node import LoopNode
 from azure.ai.ml.entities._builders.import_node import Import
 from azure.ai.ml.entities._builders.parallel import Parallel
 from azure.ai.ml.entities._builders.pipeline import Pipeline
 from azure.ai.ml.entities._component.component import Component
 from azure.ai.ml.entities._component.pipeline_component import PipelineComponent
-from azure.ai.ml.entities._inputs_outputs.group_input import GroupInput
 
 # from azure.ai.ml.entities._job.identity import AmlToken, Identity, ManagedIdentity, UserIdentity
 from azure.ai.ml.entities._credentials import (
     AmlTokenConfiguration,
     ManagedIdentityConfiguration,
     UserIdentityConfiguration,
     _BaseJobIdentityConfiguration,
 )
 from azure.ai.ml.entities._inputs_outputs import Input, Output
+from azure.ai.ml.entities._inputs_outputs.group_input import GroupInput
 from azure.ai.ml.entities._job._input_output_helpers import (
     from_rest_data_outputs,
     from_rest_inputs_to_dataset_literal,
     to_rest_data_outputs,
     to_rest_dataset_literal_inputs,
 )
 from azure.ai.ml.entities._job.import_job import ImportJob
 from azure.ai.ml.entities._job.job import Job
 from azure.ai.ml.entities._job.job_service import JobServiceBase
-from azure.ai.ml.entities._job.pipeline._io import PipelineInput, PipelineIOMixin
+from azure.ai.ml.entities._job.pipeline._io import PipelineInput, PipelineJobIOMixin
 from azure.ai.ml.entities._job.pipeline.pipeline_job_settings import PipelineJobSettings
 from azure.ai.ml.entities._mixins import YamlTranslatableMixin
 from azure.ai.ml.entities._system_data import SystemData
 from azure.ai.ml.entities._validation import MutableValidationResult, SchemaValidatableMixin
 from azure.ai.ml.exceptions import ErrorTarget, UserErrorException
 
 module_logger = logging.getLogger(__name__)
 
 
-class PipelineJob(Job, YamlTranslatableMixin, PipelineIOMixin, SchemaValidatableMixin):
+class PipelineJob(Job, YamlTranslatableMixin, PipelineJobIOMixin, SchemaValidatableMixin):
     """Pipeline job.
 
     You should not instantiate this class directly. Instead, you should
     use @pipeline decorator to create a PipelineJob
 
     :param component: Pipeline component version. The field is mutual exclusive with 'jobs'.
     :type component: Union[str, PipelineComponent]
@@ -121,21 +121,21 @@
     ):
         # initialize io
         inputs, outputs = inputs or {}, outputs or {}
         if isinstance(component, PipelineComponent) and component._source in [
             ComponentSource.DSL,
             ComponentSource.YAML_COMPONENT,
         ]:
-            self._inputs = self._build_inputs_dict(component.inputs, inputs)
+            self._inputs = self._build_inputs_dict(inputs, input_definition_dict=component.inputs)
             # for pipeline component created pipeline jobs,
             # it's output should have same value with the component outputs
             self._outputs = self._build_pipeline_outputs_dict(component.outputs)
         else:
             # Build inputs/outputs dict without meta when definition not available
-            self._inputs = self._build_inputs_dict_without_meta(inputs)
+            self._inputs = self._build_inputs_dict(inputs)
             # for node created pipeline jobs,
             # it's output should have same value with the given outputs
             self._outputs = self._build_pipeline_outputs_dict(outputs=outputs)
         source = kwargs.pop("_source", ComponentSource.CLASS)
         if component is None:
             component = PipelineComponent(
                 jobs=jobs,
@@ -534,21 +534,21 @@
         settings_dict = transform_dict_keys(properties.settings, camel_to_snake) if properties.settings else None
         settings_sdk = PipelineJobSettings(**settings_dict) if settings_dict else PipelineJobSettings()
         # Create component or use component id
         if getattr(properties, "component_id", None):
             component = properties.component_id
         else:
             component = PipelineComponent._load_from_rest_pipeline_job(
-                dict(
-                    inputs=from_rest_inputs,
-                    outputs=from_rest_outputs,
-                    display_name=properties.display_name,
-                    description=properties.description,
-                    jobs=sub_nodes,
-                )
+                {
+                    "inputs": from_rest_inputs,
+                    "outputs": from_rest_outputs,
+                    "display_name": properties.display_name,
+                    "description": properties.description,
+                    "jobs": sub_nodes,
+                }
             )
 
         job = PipelineJob(
             component=component,
             inputs=from_rest_inputs,
             outputs=from_rest_outputs,
             name=obj.name,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_pipeline_job_helpers.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_pipeline_job_helpers.py`

 * *Files 1% similar despite different names*

```diff
@@ -42,15 +42,15 @@
     ]
     for io_name, io_value in io.items():
         if isinstance(io_value, (Input, Output)) and isinstance(io_value.path, str):
             mode = io_value.mode
             path = io_value.path
             name = io_value.name if hasattr(io_value, "name") else None
             version = io_value.version if hasattr(io_value, "version") else None
-            if any([re.match(item, path) for item in io_binding_regex_list]):
+            if any(re.match(item, path) for item in io_binding_regex_list):
                 # Yaml syntax requires using ${{}} to enclose inputs and outputs bindings
                 # io_bindings[io_name] = io_value
                 io_bindings.update({io_name: {"value": path}})
                 # add mode to literal value for binding input
                 if mode:
                     if isinstance(io_value, Input):
                         io_bindings[io_name].update({"mode": INPUT_MOUNT_MAPPING_TO_REST[mode]})
@@ -62,15 +62,15 @@
                         io_bindings[io_name].update({"name": name})
                     if version:
                         io_bindings[io_name].update({"version": version})
                 if isinstance(io_value, Output) and io_value.name is not None:
                     # when the output should be registered,
                     # we add io_value to dataset_literal_io for further to_rest_data_outputs
                     dataset_literal_io[io_name] = io_value
-            elif any([re.match(item, path) for item in legacy_io_binding_regex_list]):
+            elif any(re.match(item, path) for item in legacy_io_binding_regex_list):
                 new_format = path.replace("{{", "{{parent.")
                 msg = "{} has changed to {}, please change to use new format."
                 raise ValidationException(
                     message=msg.format(path, new_format),
                     no_personal_data_message=msg.format("[io_value]", "[io_value_new_format]"),
                     target=ErrorTarget.PIPELINE,
                     error_category=ErrorCategory.USER_ERROR,
@@ -108,15 +108,15 @@
             normalize_job_input_output_type(val)
 
             # Add casting as sometimes we got value like 1(int)
             io_value = str(val.get("value", ""))
             io_mode = val.get("mode", None)
             io_name = val.get("name", None)
             io_version = val.get("version", None)
-            if any([re.match(item, io_value) for item in io_binding_regex_list]):
+            if any(re.match(item, io_value) for item in io_binding_regex_list):
                 io_bindings.update({key: {"path": io_value}})
                 # add mode to literal value for binding input
                 if io_mode:
                     # deal with dirty mode data submitted before
                     if io_mode in DIRTY_MODE_MAPPING:
                         io_mode = DIRTY_MODE_MAPPING[io_mode]
                         val["mode"] = io_mode
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_load_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_load_component.py`

 * *Files 1% similar despite different names*

```diff
@@ -282,15 +282,15 @@
             _type = "_".join([NodeType.DATA_TRANSFER, component_entity.task])
             if component_entity.task == DataTransferTaskType.IMPORT_DATA:
                 return pipeline_node_factory.load_from_dict(
                     data=dict(component=component_entity, **kwargs, _from_component_func=True),
                     _type=_type,
                 )
         return pipeline_node_factory.load_from_dict(
-            data=dict(component=component_entity, inputs=kwargs, _from_component_func=True),
+            data={"component": component_entity, "inputs": kwargs, "_from_component_func": True},
             _type=_type,
         )
 
     return to_component_func(component_entity, create_component_func)
 
 
 pipeline_node_factory = _PipelineNodeFactory()
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_pipeline_expression.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_pipeline_expression.py`

 * *Files 2% similar despite different names*

```diff
@@ -45,15 +45,15 @@
     for attr in PipelineExpressionOperator.__dict__
     if not attr.startswith("__")
 }
 
 
 def _enumerate_operation_combination() -> Dict[str, Union[str, Exception]]:
     """Enumerate, leverage `eval` to validate operation and get its result type."""
-    res = dict()
+    res = {}
     primitive_types_values = {
         NONE_PARAMETER_TYPE: repr(None),
         ComponentParameterTypes.BOOLEAN: repr(True),
         ComponentParameterTypes.INTEGER: repr(1),
         ComponentParameterTypes.NUMBER: repr(1.0),
         ComponentParameterTypes.STRING: repr("1"),
     }
@@ -256,15 +256,15 @@
     def __str__(self) -> str:
         return self._to_data_binding()
 
     def _data_binding(self) -> str:
         return self._to_data_binding()
 
     def _to_infix(self) -> str:
-        stack = list()
+        stack = []
         for token in self._postfix:
             if token not in _SUPPORTED_OPERATORS:
                 stack.append(token)
                 continue
             operand2, operand1 = stack.pop(), stack.pop()
             stack.append(f"({operand1} {token} {operand2})")
         return stack.pop()
@@ -312,28 +312,33 @@
                     _name = _get_or_create_input_name(_name, _pipeline_input, _expression_inputs)
                 else:
                     _expression_inputs.pop(_name)
                     _new_name = f"{_seen_input.value._owner.component.name}__{_seen_input.value._port_name}"
                     _postfix = _update_postfix(_postfix, _name, _new_name)
                     _expression_inputs[_new_name] = ExpressionInput(_new_name, _seen_input.type, _seen_input)
             _postfix.append(_name)
+
+            param_input = pipeline_inputs
+            for group_name in _pipeline_input._group_names:
+                param_input = param_input[group_name].values
             _expression_inputs[_name] = ExpressionInput(
-                _name, pipeline_inputs[_pipeline_input._port_name].type, _pipeline_input
+                _name, param_input[_pipeline_input._port_name].type, _pipeline_input
             )
             return _postfix, _expression_inputs
 
         def _handle_component_output(
             _component_output: NodeOutput,
             _postfix: List[str],
             _expression_inputs: Dict[str, ExpressionInput],
         ) -> Tuple[List[str], dict]:
-            if not _component_output._meta.is_control:
+            if not _component_output._meta._is_control_or_primitive_type:
                 error_message = (
                     f"Component output {_component_output._port_name} in expression must have "
-                    f'"is_control" field with value {True!r}, got {_component_output._meta.is_control!r}'
+                    f'"is_control" field or is a primitive type with value {True!r}, '
+                    f"got {_component_output._meta._is_control_or_primitive_type!r}"
                 )
                 raise UserErrorException(message=error_message, no_personal_data_message=error_message)
             _name = _component_output._port_name
             _has_prefix = False
             # "output" is the default output name for command component, add component's name as prefix
             if _name == "output":
                 _name = f"{_component_output._owner.component.name}__output"
@@ -383,15 +388,15 @@
             raise UserErrorException(message=error_message, no_personal_data_message=error_message)
 
         # get all pipeline input types from builder stack
         # TODO: check if there is pipeline input we cannot know its type (missing in `PipelineComponentBuilder.inputs`)?
         from azure.ai.ml.dsl._pipeline_component_builder import _definition_builder_stack
 
         pipeline_inputs = _definition_builder_stack.top().inputs
-        postfix, inputs = list(), dict()
+        postfix, inputs = [], {}
         postfix, inputs = PipelineExpression._handle_operand(operand1, postfix, inputs, pipeline_inputs)
         postfix, inputs = PipelineExpression._handle_operand(operand2, postfix, inputs, pipeline_inputs)
         postfix.append(operator)
         return PipelineExpression(postfix, inputs)
 
     @property
     def _string_concatenation(self) -> bool:
@@ -416,15 +421,15 @@
         if not self._string_concatenation:
             error_message = (
                 "Only string concatenation expression is supported to convert to data binding, "
                 f"current expression is '{self.expression}'."
             )
             raise UserErrorException(message=error_message, no_personal_data_message=error_message)
 
-        stack = list()
+        stack = []
         for token in self._postfix:
             if token != PipelineExpressionOperator.ADD:
                 if token in self._inputs:
                     stack.append(self._inputs[token].value._data_binding())
                 else:
                     stack.append(eval(token))  # pylint: disable=eval-used # nosec
                 continue
@@ -483,15 +488,15 @@
         primitive_type = type(eval(operand))  # pylint: disable=eval-used # nosec
         return IOConstants.PRIMITIVE_TYPE_2_STR.get(primitive_type, NONE_PARAMETER_TYPE)
 
     @property
     def _component_code(self) -> str:
         def _generate_function_code_lines() -> Tuple[List[str], str]:
             """Return lines of code and return type."""
-            _inter_id, _code, _stack, _line_recorder = 0, list(), list(), dict()
+            _inter_id, _code, _stack, _line_recorder = 0, [], [], {}
             for _token in self._postfix:
                 if _token not in _SUPPORTED_OPERATORS:
                     _type = self._get_operand_type(_token)
                     _stack.append((_token, _type))
                     continue
                 _operand2, _type2 = _stack.pop()
                 _operand1, _type1 = _stack.pop()
@@ -546,15 +551,15 @@
 
         def _generate_yaml_file(_path: Path) -> None:
             _data_folder = Path(__file__).parent / "data"
             # update YAML content from template and dump
             with open(_data_folder / "expression_component_template.yml", "r") as _f:
                 _data = load_yaml(_f)
             _data["display_name"] = f"Expression: {self.expression}"
-            _data["inputs"] = dict()
+            _data["inputs"] = {}
             _data["outputs"]["output"]["type"] = self._result_type
             _command_inputs_items = []
             for _name in sorted(self._inputs):
                 _type = self._inputs[_name].type
                 _data["inputs"][_name] = {"type": _type}
                 _command_inputs_items.append(_name + '="${{inputs.' + _name + '}}"')
             _command_inputs_string = " ".join(_command_inputs_items)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/pipeline_job_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/pipeline_job_settings.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_attr_dict.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_attr_dict.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_component_translatable.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_component_translatable.py`

 * *Files 0% similar despite different names*

```diff
@@ -121,22 +121,22 @@
                         source_type = _source._data.type
                     else:
                         #  otherwise _input_job's input/output is bound to pipeline input/output, we continue
                         #  infer the type according to _source._data. Will return corresponding pipeline
                         #  input/output type because we didn't get the component.
                         source_type, _ = cls._find_source_input_output_type(_source._data, pipeline_job_dict)
                 return source_type, source_mode
-            except AttributeError:
+            except AttributeError as e:
                 msg = "Failed to get referenced component type {}."
                 raise JobException(
                     message=msg.format(_input_regex),
                     no_personal_data_message=msg.format("[_input_regex]"),
                     target=ErrorTarget.PIPELINE,
                     error_category=ErrorCategory.USER_ERROR,
-                )
+                ) from e
         if isinstance(_input_job, (CommandJob, ParallelJob)):
             # If source has not parsed to Command yet, infer type
             _source = get(_input_job, f"{_io_type}.{_name}")
             if isinstance(_source, str):
                 source_type, _ = cls._find_source_input_output_type(_source, pipeline_job_dict)
                 return source_type, source_mode
             return getattr(_source, "type", AssetTypes.URI_FOLDER), source_mode
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/attr_dict.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/attr_dict.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/base.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -202,14 +202,22 @@
                           azure.ai.ml.Output]
         """
         # pipeline level inputs won't pass mode to bound node level inputs
         if isinstance(original_data, PipelineInput):
             return None
         return data.mode if data is not None and hasattr(data, "mode") else kwargs.pop("mode", None)
 
+    @property
+    def _is_primitive_type(self):
+        return self.type in IOConstants.PRIMITIVE_STR_2_TYPE
+
+    @property
+    def _is_control_or_primitive_type(self):
+        return getattr(self, "is_control", None) or getattr(self, "_is_primitive_type", None)
+
 
 class NodeInput(InputOutputBase):
     """Define one input of a Component."""
 
     def __init__(
         self,
         port_name: str,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/pipeline/_io/mixin.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/pipeline/_io/mixin.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 import copy
-from typing import Dict, Union
+from typing import Dict, Optional, Union
 
 from azure.ai.ml._restclient.v2023_04_01_preview.models import JobInput as RestJobInput
 from azure.ai.ml._restclient.v2023_04_01_preview.models import JobOutput as RestJobOutput
 from azure.ai.ml.constants._component import ComponentJobConstants
 from azure.ai.ml.entities._inputs_outputs import GroupInput, Input, Output
 from azure.ai.ml.entities._util import copy_output_setting
-from azure.ai.ml.exceptions import ErrorTarget, ValidationException
+from azure.ai.ml.exceptions import ErrorTarget, ValidationErrorType, ValidationException
 
 from ..._input_output_helpers import (
     from_rest_data_outputs,
     from_rest_inputs_to_dataset_literal,
     to_rest_data_outputs,
     to_rest_dataset_literal_inputs,
 )
@@ -23,92 +23,126 @@
 from .base import NodeInput, NodeOutput, PipelineInput, PipelineOutput
 
 
 class NodeIOMixin:
     """Provides ability to wrap node inputs/outputs and build data bindings
     dynamically."""
 
+    @classmethod
+    def _get_supported_inputs_types(cls):
+        return None
+
+    @classmethod
+    def _get_supported_outputs_types(cls):
+        return None
+
+    @classmethod
+    def _validate_io(cls, value: dict, allowed_types: Optional[tuple], *, key: str = None):
+        if allowed_types is None:
+            return
+
+        if value is None or isinstance(value, allowed_types):
+            pass
+        else:
+            msg = "Expecting {} for input/output {}, got {} instead."
+            raise ValidationException(
+                message=msg.format(allowed_types, key, type(value)),
+                no_personal_data_message=msg.format(allowed_types, "[key]", type(value)),
+                target=ErrorTarget.PIPELINE,
+                error_type=ValidationErrorType.INVALID_VALUE,
+            )
+
     def _build_input(self, name, meta: Input, data) -> NodeInput:
+        # output mode of last node should not affect input mode of next node
+        if isinstance(data, NodeOutput):
+            # Decoupled input and output
+            # value = copy.deepcopy(value)
+            data = data._deepcopy()  # pylint: disable=protected-access
+            data.mode = None
+        elif isinstance(data, dict):
+            # Use type comparison instead of is_instance to skip _GroupAttrDict
+            # when loading from yaml io will be a dict,
+            # like {'job_data_path': '${{parent.inputs.pipeline_job_data_path}}'}
+            # parse dict to allowed type
+            data = Input(**data)
+
+        # parameter group can be of custom type, so we don't check it here
+        if meta is not None and not isinstance(meta, GroupInput):
+            self._validate_io(data, self._get_supported_inputs_types(), key=name)
         return NodeInput(port_name=name, meta=meta, data=data, owner=self)
 
     def _build_output(self, name, meta: Output, data) -> NodeOutput:
+        if isinstance(data, dict):
+            data = Output(**data)
+
+        self._validate_io(data, self._get_supported_outputs_types(), key=name)
         # For un-configured outputs, settings it to None, so we won't pass extra fields(eg: default mode)
         return NodeOutput(port_name=name, meta=meta, data=data, owner=self)
 
     def _get_default_input_val(self, val):  # pylint: disable=unused-argument, no-self-use
         # use None value as data placeholder for unfilled inputs.
         # server side will fill the default value
         return None
 
     def _build_inputs_dict(
         self,
-        input_definition_dict: dict,
         inputs: Dict[str, Union[Input, str, bool, int, float]],
+        *,
+        input_definition_dict: dict = None,
     ) -> InputsAttrDict:
         """Build an input attribute dict so user can get/set inputs by
         accessing attribute, eg: node1.inputs.xxx.
 
-        :param input_definition_dict: Static input definition dict.
         :param inputs: Provided kwargs when parameterizing component func.
+        :param input_definition_dict: Static input definition dict. If not provided, will build inputs without meta.
         :return: Built dynamic input attribute dict.
         """
-        # TODO: validate inputs.keys() in input_definitions.keys()
-        input_dict = {}
-        for key, val in input_definition_dict.items():
-            if key in inputs.keys():
-                # If input is set through component functions' kwargs, create an input object with real value.
-                data = inputs[key]
-            else:
-                data = self._get_default_input_val(val)  # pylint: disable=assignment-from-none
+        if input_definition_dict is not None:
+            # TODO: validate inputs.keys() in input_definitions.keys()
+            input_dict = {}
+            for key, val in input_definition_dict.items():
+                if key in inputs.keys():
+                    # If input is set through component functions' kwargs, create an input object with real value.
+                    data = inputs[key]
+                else:
+                    data = self._get_default_input_val(val)  # pylint: disable=assignment-from-none
 
-            val = self._build_input(name=key, meta=val, data=data)
-            input_dict[key] = val
+                val = self._build_input(name=key, meta=val, data=data)
+                input_dict[key] = val
+        else:
+            input_dict = {key: self._build_input(name=key, meta=None, data=val) for key, val in inputs.items()}
         return InputsAttrDict(input_dict)
 
-    def _build_outputs_dict(self, output_definition_dict: dict, outputs: Dict[str, Output]) -> OutputsAttrDict:
+    def _build_outputs_dict(
+        self, outputs: Dict[str, Output], *, output_definition_dict: dict = None, none_data=False
+    ) -> OutputsAttrDict:
         """Build an output attribute dict so user can get/set outputs by
         accessing attribute, eg: node1.outputs.xxx.
 
-        :param output_definition_dict: Static output definition dict.
-        :return: Built dynamic output attribute dict.
-        """
-        # TODO: check if we need another way to mark a un-configured output instead of just set None.
-        # Create None as data placeholder for all outputs.
-        output_dict = {}
-        for key, val in output_definition_dict.items():
-            if key in outputs.keys():
-                # If output has given value, create an output object with real value.
-                val = self._build_output(name=key, meta=val, data=outputs[key])
-            else:
-                val = self._build_output(name=key, meta=val, data=None)
-            output_dict[key] = val
-        return OutputsAttrDict(output_dict)
-
-    def _build_inputs_dict_without_meta(self, inputs: Dict[str, Union[Input, str, bool, int, float]]) -> InputsAttrDict:
-        """Build an input attribute dict without input definition metadata, so user can get/set inputs by
-        accessing attribute, eg: node1.inputs.xxx.
-
-        :param inputs: Static input definition dict.
-        :return: Built dynamic input attribute dict.
-        """
-        input_dict = {key: self._build_input(name=key, meta=None, data=val) for key, val in inputs.items()}
-        return InputsAttrDict(input_dict)
-
-    def _build_outputs_dict_without_meta(self, outputs: Dict[str, Output], none_data=False) -> OutputsAttrDict:
-        """Build an output attribute dict without output definition metadata, so user can get/set outputs by
-        accessing attribute, eg: node1.outputs.xxx.
-
-        :param outputs: Static output definition dict.
-        :param none_data: Set data to None if True.
-        :return: Built dynamic output attribute dict.
-        """
-        output_dict = {}
-        for key, val in outputs.items():
-            output_val = self._build_output(name=key, meta=None, data=val if not none_data else None)
-            output_dict[key] = output_val
+        : param outputs: Provided kwargs when parameterizing component func.
+        : param output_definition_dict: Static output definition dict.
+        : param none_data: If True, will set output data to None.
+        : return: Built dynamic output attribute dict.
+        """
+        if output_definition_dict is not None:
+            # TODO: check if we need another way to mark a un-configured output instead of just set None.
+            # Create None as data placeholder for all outputs.
+            output_dict = {}
+            for key, val in output_definition_dict.items():
+                if key in outputs.keys():
+                    # If output has given value, create an output object with real value.
+                    val = self._build_output(name=key, meta=val, data=outputs[key])
+                else:
+                    val = self._build_output(name=key, meta=val, data=None)
+                output_dict[key] = val
+        else:
+            output_dict = {}
+            for key, val in outputs.items():
+                output_val = self._build_output(name=key, meta=None, data=val if not none_data else None)
+                output_dict[key] = output_val
         return OutputsAttrDict(output_dict)
 
     def _build_inputs(self) -> Dict[str, Union[Input, str, bool, int, float]]:
         """Build inputs of this component to a dict dict which maps output to
         actual value.
 
         The built input dict will have same input format as other jobs, eg:
@@ -251,16 +285,43 @@
             original_output = self.outputs[name]
             # for configured output with meta, "correct" the output type to file to avoid the uri_folder default value
             if original_output and original_output.type:
                 if original_output.type in ["AnyFile", "uri_file"]:
                     rest_output["job_output_type"] = "uri_file"
 
 
-class PipelineNodeIOMixin(NodeIOMixin):
-    """This class provide build_inputs_dict for Pipeline and PipelineJob to support ParameterGroup."""
+def _flatten_dict(dictionary, parent_key="", separator="."):
+    items = []
+    for key, value in dictionary.items():
+        new_key = parent_key + separator + key if parent_key else key
+        if isinstance(value, dict):
+            items.extend(_flatten_dict(value, new_key, separator=separator).items())
+        else:
+            items.append((new_key, value))
+    return dict(items)
+
+
+def flatten_dict(dct, _type, *, allow_dict_fields=None):
+    """Flatten inputs/input_definitions dict for inputs dict build."""
+    _result = {}
+    for key, val in dct.items():
+        # to support passing dict value as parameter group
+        if allow_dict_fields and key in allow_dict_fields and isinstance(val, dict):
+            _result.update(_flatten_dict(val, parent_key=key))
+            continue
+        val = GroupInput.custom_class_value_to_attr_dict(val)
+        if isinstance(val, _type):
+            _result.update(val.flatten(group_parameter_name=key))
+            continue
+        _result[key] = val
+    return _result
+
+
+class NodeWithGroupInputMixin(NodeIOMixin):
+    """This class provide build_inputs_dict for a node to use ParameterGroup as an input."""
 
     def _validate_group_input_type(  # pylint: disable=no-self-use
         self,
         input_definition_dict: dict,
         inputs: Dict[str, Union[Input, str, bool, int, float]],
     ):
         """Raise error when group input receive a value not group type."""
@@ -270,78 +331,89 @@
         non_group_msg = "'%s' is defined as a parameter but got a parameter group as input."
         for key, val in inputs.items():
             definition = input_definition_dict.get(key)
             val = GroupInput.custom_class_value_to_attr_dict(val)
             if val is None:
                 continue
             # 1. inputs.group = 'a string'
-            if isinstance(definition, GroupInput) and not isinstance(val, _GroupAttrDict):
+            if isinstance(definition, GroupInput) and not isinstance(val, (_GroupAttrDict, dict)):
                 raise ValidationException(
                     message=group_msg % (key, val, type(val)),
                     no_personal_data_message=group_msg % ("[key]", "[val]", "[type(val)]"),
                     target=ErrorTarget.PIPELINE,
+                    type=ValidationErrorType.INVALID_VALUE,
                 )
             # 2. inputs.str_param = group
             if not isinstance(definition, GroupInput) and isinstance(val, _GroupAttrDict):
                 raise ValidationException(
                     message=non_group_msg % key,
                     no_personal_data_message=non_group_msg % "[key]",
                     target=ErrorTarget.PIPELINE,
+                    type=ValidationErrorType.INVALID_VALUE,
                 )
 
     def _build_inputs_dict(
         self,
-        input_definition_dict: dict,
         inputs: Dict[str, Union[Input, str, bool, int, float]],
+        *,
+        input_definition_dict: dict = None,
     ) -> InputsAttrDict:
         """Build an input attribute dict so user can get/set inputs by
         accessing attribute, eg: node1.inputs.xxx.
 
         :param input_definition_dict: Input definition dict from component entity.
         :param inputs: Provided kwargs when parameterizing component func.
         :return: Built input attribute dict.
         """
 
-        def flatten_dict(dct, _type):
-            """Flatten inputs/input_definitions dict for inputs dict build."""
-            _result = {}
-            for key, val in dct.items():
-                val = GroupInput.custom_class_value_to_attr_dict(val)
-                if isinstance(val, _type):
-                    _result.update(val.flatten(group_parameter_name=key))
-                    continue
-                _result[key] = val
-            return _result
-
-        # Validate group mismatch
-        self._validate_group_input_type(input_definition_dict, inputs)
-        # Flatten all GroupInput(definition) and GroupAttrDict.
-        flattened_inputs = flatten_dict(inputs, _GroupAttrDict)
-        flattened_definition_dict = flatten_dict(input_definition_dict, GroupInput)
-        # Build: zip all flattened parameter with definition
-        inputs = super()._build_inputs_dict(flattened_definition_dict, flattened_inputs)
-        return InputsAttrDict(GroupInput.restore_flattened_inputs(inputs))
+        # TODO: should we support group input when there is no local input definition?
+        if input_definition_dict is not None:
+            # Validate group mismatch
+            self._validate_group_input_type(input_definition_dict, inputs)
+
+            allow_dict_fields = [key for key, val in input_definition_dict.items() if isinstance(val, GroupInput)]
+            # Flatten all GroupInput(definition) and GroupAttrDict.
+            flattened_inputs = flatten_dict(inputs, _GroupAttrDict, allow_dict_fields=allow_dict_fields)
+            flattened_definition_dict = flatten_dict(input_definition_dict, GroupInput)
+            # Build: zip all flattened parameter with definition
+            inputs = super()._build_inputs_dict(flattened_inputs, input_definition_dict=flattened_definition_dict)
+            return InputsAttrDict(GroupInput.restore_flattened_inputs(inputs))
+        return super()._build_inputs_dict(inputs)
 
 
-class PipelineIOMixin(PipelineNodeIOMixin):
-    """Provides ability to wrap pipeline inputs/outputs and build data bindings
+class PipelineJobIOMixin(NodeWithGroupInputMixin):
+    """Provides ability to wrap pipeline job inputs/outputs and build data bindings
     dynamically."""
 
     def _build_input(self, name, meta: Input, data) -> "PipelineInput":
         return PipelineInput(name=name, meta=meta, data=data, owner=self)
 
     def _build_output(self, name, meta: Output, data) -> "PipelineOutput":
         # TODO: settings data to None for un-configured outputs so we won't passing extra fields(eg: default mode)
         result = PipelineOutput(port_name=name, meta=meta, data=data, owner=self)
         return result
 
-    def _build_inputs_dict_without_meta(self, inputs: Dict[str, Union[Input, str, bool, int, float]]) -> InputsAttrDict:
-        input_dict = {key: self._build_input(name=key, meta=None, data=val) for key, val in inputs.items()}
-        input_dict = GroupInput.restore_flattened_inputs(input_dict)
-        return InputsAttrDict(input_dict)
+    def _build_inputs_dict(
+        self,
+        inputs: Dict[str, Union[Input, str, bool, int, float]],
+        *,
+        input_definition_dict: dict = None,
+    ) -> InputsAttrDict:
+        """Build an input attribute dict so user can get/set inputs by
+        accessing attribute, eg: node1.inputs.xxx.
+
+        :param input_definition_dict: Input definition dict from component entity.
+        :param inputs: Provided kwargs when parameterizing component func.
+        :return: Built input attribute dict.
+        """
+        input_dict = super()._build_inputs_dict(inputs, input_definition_dict=input_definition_dict)
+        # TODO: should we do this when input_definition_dict is not None?
+        if input_definition_dict is None:
+            return InputsAttrDict(GroupInput.restore_flattened_inputs(input_dict))
+        return input_dict
 
     def _build_output_for_pipeline(self, name, data) -> "PipelineOutput":
         """Build an output object for pipeline and copy settings from source output.
 
         :param name: Output name.
         :param meta: Output metadata.
         :param data: Output data.
@@ -410,8 +482,8 @@
     """Wrap outputs of automl node and build data bindings dynamically."""
 
     def __init__(self, **kwargs):
         # add a inputs field to align with other nodes
         self.inputs = {}
         super(AutoMLNodeIOMixin, self).__init__(**kwargs)
         if getattr(self, "outputs", None):
-            self._outputs = self._build_outputs_dict_without_meta(self.outputs or {})
+            self._outputs = self._build_outputs_dict(self.outputs or {})
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/data_transfer/data_transfer_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/data_transfer/data_transfer_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/sampling_algorithm.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/sampling_algorithm.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/search_space.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/search_space.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/sweep_job.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/sweep_job.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/early_termination_policy.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/early_termination_policy.py`

 * *Files 3% similar despite different names*

```diff
@@ -71,18 +71,18 @@
             :dedent: 8
             :caption: Configuring BanditPolicy early termination of a hyperparameter sweep on a Command job.
     """
 
     def __init__(
         self,
         *,
-        delay_evaluation: Optional[int] = 0,
-        evaluation_interval: Optional[int] = 0,
-        slack_amount: Optional[float] = 0,
-        slack_factor: Optional[float] = 0,
+        delay_evaluation: int = 0,
+        evaluation_interval: int = 0,
+        slack_amount: float = 0,
+        slack_factor: float = 0,
     ) -> None:
         """Defines an early termination policy based on slack criteria and a frequency and delay interval
         for evaluation.
 
         :param delay_evaluation: Number of intervals by which to delay the first evaluation. Defaults to 0.
         :type delay_evaluation: int
         :param evaluation_interval: Interval (number of runs) between policy evaluations. Defaults to 0.
@@ -133,16 +133,16 @@
             :dedent: 8
             :caption: Configuring an early termination policy for a hyperparameter sweep job using MedianStoppingPolicy
     """
 
     def __init__(
         self,
         *,
-        delay_evaluation: Optional[int] = 0,
-        evaluation_interval: Optional[int] = 1,
+        delay_evaluation: int = 0,
+        evaluation_interval: int = 1,
     ) -> None:
         """Defines an early termination policy based on a running average of the primary metric of all runs.
 
         :param delay_evaluation: Number of intervals by which to delay the first evaluation. Defaults to 0.
         :type delay_evaluation: int
         :param evaluation_interval: Interval (number of runs) between policy evaluations. Defaults to 1.
         :type evaluation_interval: int
@@ -184,17 +184,17 @@
             :caption: Configuring an early termination policy for a hyperparameter sweep job
             using TruncationStoppingPolicy
     """
 
     def __init__(
         self,
         *,
-        delay_evaluation: Optional[int] = 0,
-        evaluation_interval: Optional[int] = 0,
-        truncation_percentage: Optional[int] = 0,
+        delay_evaluation: int = 0,
+        evaluation_interval: int = 0,
+        truncation_percentage: int = 0,
     ) -> None:
         """Defines an early termination policy that cancels a given percentage of runs at each evaluation interval.
 
         :param delay_evaluation: Number of intervals by which to delay the first evaluation.
         :type delay_evaluation: int
         :param evaluation_interval: Interval (number of runs) between policy evaluations.
         :type evaluation_interval: int
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/objective.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/objective.py`

 * *Files 5% similar despite different names*

```diff
@@ -26,18 +26,18 @@
             :dedent: 8
             :caption: Assigning an objective to a SweepJob
     """
 
     def __init__(self, goal: str, primary_metric: Optional[str] = None) -> None:
         """Optimization objective.
 
-        :param goal: Required. Defines supported metric goals for hyperparameter tuning. Acceptable values
-        are: "minimize", "maximize".
+        :param goal: Defines supported metric goals for hyperparameter tuning. Acceptable values
+            are: "minimize" or "maximize".
         :type goal: str
-        :param primary_metric: Required. The name of the metric to optimize.
+        :param primary_metric: The name of the metric to optimize.
         :type primary_metric: str
         """
         self.goal = goal.lower()
         self.primary_metric = primary_metric
 
     def _to_rest_object(self) -> RestObjective:
         return RestObjective(
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_job/sweep/parameterized_sweep.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_job/sweep/parameterized_sweep.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,14 +10,16 @@
 from enum import Enum as PyEnum
 from enum import EnumMeta
 from inspect import Parameter, getmro, signature
 
 from azure.ai.ml.constants._component import IOConstants
 from azure.ai.ml.exceptions import UserErrorException
 
+SUPPORTED_RETURN_TYPES_PRIMITIVE = list(IOConstants.PRIMITIVE_TYPE_2_STR.keys())
+
 
 def is_group(obj):
     """Return True if obj is a group or an instance of a parameter group class."""
     return hasattr(obj, IOConstants.GROUP_ATTR_NAME)
 
 
 def _get_annotation_by_value(val):
@@ -242,25 +244,27 @@
     """This function will translate IOBase from mldesigner package to azure.ml.entities.Input/Output.
 
     This function depend on `mldesigner._input_output._IOBase._to_io_entity_args_dict` to translate Input/Output
     instance annotations to IO entities.
     This function depend on class names of `mldesigner._input_output` to translate Input/Output class annotations
     to IO entities.
     """
+    from typing_extensions import Annotated, get_args, get_origin
+
     from azure.ai.ml import Input, Output
 
     from .enum_input import EnumInput
 
     mldesigner_pkg = "mldesigner"
     param_name = "_Param"
     return_annotation_key = "return"
 
     def _is_primitive_type(io: type):
         """Return true if type is subclass of mldesigner._input_output._Param"""
-        return any([io.__module__.startswith(mldesigner_pkg) and item.__name__ == param_name for item in getmro(io)])
+        return any(io.__module__.startswith(mldesigner_pkg) and item.__name__ == param_name for item in getmro(io))
 
     def _is_input_or_output_type(io: type, type_str: str):
         """Return true if type name contains type_str"""
         if isinstance(io, type) and io.__module__.startswith(mldesigner_pkg):
             if type_str in io.__name__:
                 return True
         return False
@@ -291,14 +295,34 @@
                         io = (
                             Output(**io._to_io_entity_args_dict())
                             if key == return_annotation_key
                             else Input(**io._to_io_entity_args_dict())
                         )
             except BaseException as e:
                 raise UserErrorException(f"Failed to parse {io} to azure-ai-ml Input/Output: {str(e)}") from e
+                # Handle Annotated annotation
+        elif get_origin(io) is Annotated:
+            hint_type, arg, *hint_args = get_args(io)  # pylint: disable=unused-variable
+            if hint_type in SUPPORTED_RETURN_TYPES_PRIMITIVE:
+                if not _is_input_or_output_type(type(arg), "Meta"):
+                    raise UserErrorException(
+                        f"Annotated Metadata class only support "
+                        f"mldesigner._input_output.Meta, "
+                        f"it is {type(arg)} now."
+                    )
+                if arg.type is not None and arg.type != hint_type:
+                    raise UserErrorException(
+                        f"Meta class type {arg.type} should be same as Annotated type: " f"{hint_type}"
+                    )
+                arg.type = hint_type
+                io = (
+                    Output(**arg._to_io_entity_args_dict())
+                    if key == return_annotation_key
+                    else Input(**arg._to_io_entity_args_dict())
+                )
         result[key] = io
     return result
 
 
 def _remove_empty_values(data, ignore_keys=None):
     if not isinstance(data, dict):
         return data
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/__init__.py`

 * *Ordering differences only*

 * *Files 1% similar despite different names*

```diff
@@ -51,19 +51,19 @@
             },
             outputs={"my_model": Output(type="mlflow_model")},
         )
         node = my_command()
 """
 
 from .enum_input import EnumInput
+from .external_data import Database, FileSystem
 from .group_input import GroupInput
 from .input import Input
 from .output import Output
 from .utils import _get_param_with_standard_annotation, is_group
-from .external_data import Database, FileSystem
 
 __all__ = [
     "Input",
     "Output",
     "EnumInput",
     "GroupInput",
     "is_group",
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/group_input.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/group_input.py`

 * *Files 8% similar despite different names*

```diff
@@ -31,14 +31,24 @@
 
     @classmethod
     def _is_group_attr_dict(cls, obj):
         from .._job.pipeline._io import _GroupAttrDict
 
         return isinstance(obj, _GroupAttrDict)
 
+    def __getattr__(self, item):
+        """Allow get value from values by __get_attr__."""
+        try:
+            return super().__getattr__(item)
+        except AttributeError:
+            # TODO: why values is not a dict in some cases?
+            if isinstance(self.values, dict) and item in self.values:
+                return self.values[item]
+            raise
+
     def _create_default(self):
         from .._job.pipeline._io import PipelineInput
 
         default_dict = {}
         # Note: no top-level group names at this time.
         for k, v in self.values.items():
             # skip create default for outputs or port inputs
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/external_data.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/external_data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/input.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/input.py`

 * *Files 1% similar despite different names*

```diff
@@ -52,14 +52,15 @@
     :param description: Description of the input
     :type description: str
     :raises ~azure.ai.ml.exceptions.ValidationException: Raised if Input cannot be successfully validated.
         Details will be provided in the error message.
     """
 
     _EMPTY = Parameter.empty
+    _IO_KEYS = ["path", "type", "mode", "description", "default", "min", "max", "enum", "optional", "datastore"]
 
     @overload
     def __init__(
         self,
         *,
         type: Literal["uri_folder"] = "uri_folder",
         path: Optional[str] = None,
@@ -275,26 +276,26 @@
 
     def _is_enum(self):
         """returns true if the input is enum."""
         return self.type == ComponentParameterTypes.STRING and self.enum
 
     def _to_dict(self):
         """Convert the Input object to a dict."""
-        keys = ["path", "type", "mode", "description", "default", "min", "max", "enum", "optional", "datastore"]
+        keys = self._IO_KEYS
         result = {key: getattr(self, key) for key in keys}
         return _remove_empty_values(result)
 
     def _parse(self, val):
         """Parse value passed from command line.
 
         :param val: The input value
         :return: The parsed value.
         """
         if self.type == "integer":
-            return int(val)
+            return int(float(val))  # backend returns 10.0for integer parse it to float before int
         if self.type == "number":
             return float(val)
         if self.type == "boolean":
             lower_val = str(val).lower()
             if lower_val not in {"true", "false"}:
                 msg = "Boolean parameter '{}' only accept True/False, got {}."
                 raise ValidationException(
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/enum_input.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/enum_input.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/base.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/base.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
-
 from azure.ai.ml._schema.component.input_output import SUPPORTED_PARAM_TYPES
 from azure.ai.ml.entities._mixins import DictMixin, RestTranslatableMixin
 
 
 class _InputOutputBase(DictMixin, RestTranslatableMixin):
     def __init__(
         self,
@@ -21,7 +20,11 @@
         :type type: str
         """
         self.type = type
 
     def _is_literal(self) -> bool:
         """Returns True if this input is literal input."""
         return self.type in SUPPORTED_PARAM_TYPES
+
+    @property
+    def _is_control_or_primitive_type(self):
+        return getattr(self, "is_control", None) or getattr(self, "_is_primitive_type", None)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_inputs_outputs/output.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_inputs_outputs/output.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,16 +6,16 @@
 import re
 from typing import Dict, overload
 
 from typing_extensions import Literal
 
 from azure.ai.ml.constants import AssetTypes
 from azure.ai.ml.constants._component import IOConstants
-from azure.ai.ml.exceptions import UserErrorException
 from azure.ai.ml.entities._assets.intellectual_property import IntellectualProperty
+from azure.ai.ml.exceptions import UserErrorException
 
 from .base import _InputOutputBase
 from .utils import _remove_empty_values
 
 
 class Output(_InputOutputBase):
     """Define an output of a Component or Job.
@@ -35,14 +35,16 @@
     :param name: The name used to register output as data or model asset. Name can be set without setting version.
     :type name: str
     :param version: The version used to register output as data or model asset.
         Version can be set only when name is set.
     :type version: str
     """
 
+    _IO_KEYS = ["name", "version", "path", "type", "mode", "description", "is_control", "early_available"]
+
     @overload
     def __init__(self, type: Literal["uri_folder"] = "uri_folder", path=None, mode=None, description=None):
         """Define a uri_folder output.
 
         :param type: The type of the data output. Possible values include:
                             'uri_folder', 'uri_file', 'mltable', 'mlflow_model', 'custom_model', and user-defined types.
         :type type: str
@@ -113,15 +115,15 @@
 
     def _get_hint(self, new_line_style=False):
         comment_str = self.description.replace('"', '\\"') if self.description else self.type
         return '"""%s"""' % comment_str if comment_str and new_line_style else comment_str
 
     def _to_dict(self):
         """Convert the Output object to a dict."""
-        keys = ["name", "version", "path", "type", "mode", "description", "is_control", "early_available"]
+        keys = self._IO_KEYS
         result = {key: getattr(self, key) for key in keys}
         return _remove_empty_values(result)
 
     def _to_rest_object(self) -> Dict:
         # this is for component rest object when using Output as component outputs, as for job output usage,
         # rest object is generated by extracting Output's properties, see details in to_rest_data_outputs()
         return self._to_dict()
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/networking.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/networking.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/workspace.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/workspace.py`

 * *Files 1% similar despite different names*

```diff
@@ -95,14 +95,15 @@
         :type managed_network: ManagedNetwork
         :param enable_data_isolation: A flag to determine if workspace has data isolation enabled.
             The flag can only be set at the creation phase, it can't be updated.
         :type enable_data_isolation: bool
         :param kwargs: A dictionary of additional configuration parameters.
         :type kwargs: dict
         """
+        self.print_as_yaml = True
         self._discovery_url = kwargs.pop("discovery_url", None)
         self._mlflow_tracking_uri = kwargs.pop("mlflow_tracking_uri", None)
         self._kind = kwargs.pop("kind", "default")
         self._feature_store_settings: Optional[FeatureStoreSettings] = kwargs.pop("feature_store_settings", None)
         super().__init__(name=name, description=description, tags=tags, **kwargs)
 
         self.display_name = display_name
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/workspace_keys.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/workspace_keys.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/private_endpoint.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/private_endpoint.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/diagnose.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/diagnose.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/compute_runtime.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/compute_runtime.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/feature_store_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/feature_store_settings.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
 
-from typing import Optional, Any
+from typing import Optional
 
 from azure.ai.ml._restclient.v2023_04_01_preview.models import FeatureStoreSettings as RestFeatureStoreSettings
 from azure.ai.ml.entities._mixins import RestTranslatableMixin
 from azure.ai.ml._utils._experimental import experimental
 from .compute_runtime import ComputeRuntime
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/customer_managed_key.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/customer_managed_key.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/workspace_connection.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/workspace_connection.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_workspace/connections/credentials.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_workspace/connections/credentials.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_specification.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_specification.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_materialization_metadata.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_materialization_metadata.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/featureset_spec_metadata.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/featureset_spec_metadata.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_settings.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_settings.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,41 +11,51 @@
 from azure.ai.ml.entities._mixins import RestTranslatableMixin
 from azure.ai.ml.entities._notification.notification import Notification
 from azure.ai.ml.entities._schedule.trigger import RecurrenceTrigger
 
 
 @experimental
 class MaterializationSettings(RestTranslatableMixin):
+    """Defines materialization settings.
+
+    :param schedule: The schedule details.
+    :type schedule: ~azure.ai.ml.entities.RecurrenceTrigger
+    :param offline_enabled: Specifies if offline store is enabled.
+    :type offline_enabled: bool
+    :param online_enabled: Specifies if online store is enabled.
+    :type online_enabled: bool
+    :param notification: The notification details.
+    :type notification: ~azure.ai.ml.entities.Notification
+    :param resource: The compute resource settings.
+    :type resource: ~azure.ai.ml.entities.MaterializationComputeResource
+    :param spark_configuration: The spark compute settings.
+    :type spark_configuration: Dict[str, str]
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START materialization_setting_configuration]
+            :end-before: [END materialization_setting_configuration]
+            :language: python
+            :dedent: 8
+            :caption: Configuring MaterializationSettings.
+    """
+
     def __init__(
         self,
         *,
         schedule: Optional[RecurrenceTrigger] = None,
         offline_enabled: Optional[bool] = None,
         online_enabled: Optional[bool] = None,
         notification: Optional[Notification] = None,
         resource: Optional[MaterializationComputeResource] = None,
         spark_configuration: Optional[Dict[str, str]] = None,
         **kwargs  # pylint: disable=unused-argument
-    ):
-        """MaterializationSettings.
-
-        :param schedule: Specifies the schedule details.
-        :type schedule: ~azure.ai.ml.entities.RecurrenceTrigger
-        :param offline_enabled: Specifies if offline store is enabled.
-        :type offline_enabled: bool
-        :param online_enabled: Specifies if online store is enabled.
-        :type online_enabled: bool
-        :param notification: Specifies the notification details.
-        :type notification: ~azure.ai.ml.entities.Notification
-        :param resource: Specifies the compute resource settings.
-        :type resource: ~azure.ai.ml.entities.MaterializationComputeResource
-        :param spark_configuration: Specifies the spark compute settings.
-        :type spark_configuration: dict[str, str]
-        """
-
+    ) -> None:
         self.schedule = schedule
         self.offline_enabled = offline_enabled
         self.online_enabled = online_enabled
         self.notification = notification
         self.resource = resource
         self.spark_configuration = spark_configuration
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/materialization_compute_resource.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/materialization_compute_resource.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature_set_backfill_metadata.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature_set_backfill_metadata.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/source_metadata.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/source_metadata.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_set/feature.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_set/feature.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/_constants.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/_constants.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/feature_store.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/feature_store.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,34 +4,32 @@
 
 # pylint: disable=too-many-instance-attributes,protected-access
 
 
 from os import PathLike
 from pathlib import Path
 from typing import Dict, Optional, Union
-from marshmallow import ValidationError
 
 from azure.ai.ml._restclient.v2023_04_01_preview.models import Workspace as RestWorkspace
-
 from azure.ai.ml._schema._feature_store.feature_store_schema import FeatureStoreSchema
-from azure.ai.ml.entities._workspace.feature_store_settings import FeatureStoreSettings
-from azure.ai.ml.entities._workspace.compute_runtime import ComputeRuntime
-from azure.ai.ml.entities import Workspace, CustomerManagedKey
-from azure.ai.ml.entities._util import load_from_dict
-from azure.ai.ml.entities._credentials import IdentityConfiguration, ManagedIdentityConfiguration
 from azure.ai.ml._utils._experimental import experimental
 from azure.ai.ml.constants._common import BASE_PATH_CONTEXT_KEY, PARAMS_OVERRIDE_KEY
+from azure.ai.ml.entities import CustomerManagedKey, Workspace
+from azure.ai.ml.entities._credentials import IdentityConfiguration, ManagedIdentityConfiguration
+from azure.ai.ml.entities._util import load_from_dict
+from azure.ai.ml.entities._workspace.compute_runtime import ComputeRuntime
+from azure.ai.ml.entities._workspace.feature_store_settings import FeatureStoreSettings
 
-from .materialization_store import MaterializationStore
 from ._constants import (
-    OFFLINE_STORE_CONNECTION_NAME,
-    ONLINE_STORE_CONNECTION_NAME,
     DEFAULT_SPARK_RUNTIME_VERSION,
     FEATURE_STORE_KIND,
+    OFFLINE_STORE_CONNECTION_NAME,
+    ONLINE_STORE_CONNECTION_NAME,
 )
+from .materialization_store import MaterializationStore
 
 
 @experimental
 class FeatureStore(Workspace):
     def __init__(
         self,
         *,
@@ -110,20 +108,14 @@
         :type identity: IdentityConfiguration
         :param primary_user_assigned_identity: The workspace's primary user assigned identity
         :type primary_user_assigned_identity: str
         :param kwargs: A dictionary of additional configuration parameters.
         :type kwargs: dict
         """
 
-        if offline_store and not materialization_identity:
-            raise ValidationError("materialization_identity is required to setup offline store")
-
-        if online_store and not materialization_identity:
-            raise ValidationError("materialization_identity is required to setup online store")
-
         feature_store_settings = FeatureStoreSettings(
             compute_runtime=compute_runtime
             if compute_runtime
             else ComputeRuntime(spark_runtime_version=DEFAULT_SPARK_RUNTIME_VERSION),
             offline_store_connection_name=(
                 OFFLINE_STORE_CONNECTION_NAME if materialization_identity and offline_store else None
             ),
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_feature_store/materialization_store.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_feature_store/materialization_store.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_data/mltable_metadata.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_data/mltable_metadata.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/_additional_includes.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/_additional_includes.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,156 +1,154 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
+import json
 import os
 import shutil
 import tempfile
 import zipfile
+from collections import defaultdict
 from concurrent.futures import ThreadPoolExecutor
+from contextlib import contextmanager
 from multiprocessing import cpu_count
 from pathlib import Path
-from typing import Union, List
-import yaml
+from typing import Dict, List, Optional, Tuple, Union
 
-from azure.ai.ml.entities._validation import MutableValidationResult, _ValidationResultBuilder
 from azure.ai.ml.constants._common import AzureDevopsArtifactsType
+from azure.ai.ml.entities._validation import MutableValidationResult, _ValidationResultBuilder
 
-from .code import ComponentIgnoreFile
-from ._artifact_cache import ArtifactCache
+from ..._utils._artifact_utils import ArtifactCache
+from ..._utils._asset_utils import IgnoreFile, traverse_directory
 from ..._utils.utils import is_concurrent_component_registration_enabled, is_private_preview_enabled
-from ..._utils._asset_utils import traverse_directory, IgnoreFile
 from ...entities._util import _general_copy
-
+from .._assets import Code
+from .code import ComponentCodeMixin, ComponentIgnoreFile
 
 PLACEHOLDER_FILE_NAME = "_placeholder_spec.yaml"
-ADDITIONAL_INCLUDES_KEY = "additional_includes"
-ADDITIONAL_INCLUDES_SUFFIX = ".additional_includes"
 
 
 class AdditionalIncludes:
-    def __init__(self, code_path: Union[None, str], yaml_path: str, additional_includes: List[Union[str, dict]] = None):
-        self._yaml_path = yaml_path
-        self._code_path = code_path
-        self._additional_includes = additional_includes if additional_includes else []
-
-        self._tmp_code_path = None
-        self._includes = None
-        # artifact validation is done on loading now, so need a private variable to store the result
-        self._artifact_validate_result = None
-
-    @property
-    def additional_includes(self):
-        return self._additional_includes
-
-    @property
-    def code_path(self) -> Union[None, Path]:
-        if self._code_path is not None:
-            return (self.yaml_path.parent / self._code_path).resolve()
-        return self._code_path
+    def __init__(
+        self,
+        *,
+        origin_code_value: Union[None, str],
+        base_path: Path,
+        configs: List[Union[str, dict]] = None,
+    ):
+        self._base_path = base_path
+        self._origin_code_value = origin_code_value
+        self._origin_configs = configs
 
     @property
-    def code(self):
-        return self._tmp_code_path if self._tmp_code_path else self.code_path
+    def origin_configs(self):
+        """The origin additional include configs.
+        Artifact additional include configs haven't been resolved in this property.
+        """
+        return self._origin_configs or []
 
     @property
-    def yaml_path(self) -> Path:
-        if self._yaml_path is None:
-            # if yaml path is not specified, take working directory as root folder and use a not created temp file name
-            return Path.cwd() / PLACEHOLDER_FILE_NAME
-        return Path(self._yaml_path)
+    def resolved_code_path(self) -> Union[None, Path]:
+        """The resolved origin code path based on base path, if code path is not specified, return None.
+        We shouldn't change this property name given it's referenced in mldesigner.
+        """
+        if self._origin_code_value is None:
+            return None
+        if os.path.isabs(self._origin_code_value):
+            return Path(self._origin_code_value)
+        return (self.base_path / self._origin_code_value).resolve()
 
     @property
     def base_path(self) -> Path:
-        return self.yaml_path.parent
-
-    @property
-    def yaml_name(self) -> str:
-        return self.yaml_path.name
+        """Base path for origin code path and additional include configs."""
+        return self._base_path
 
     @property
     def with_includes(self):
-        return len(self.includes) != 0 or not self.artifact_validate_result.passed
-
-    @property
-    def is_artifact_includes(self):
-        try:
-            return any(
-                map(
-                    lambda x: isinstance(x, dict) and x.get("type", None) == AzureDevopsArtifactsType.ARTIFACT,
-                    self.additional_includes,
-                )
-            )
-        except Exception:  # pylint: disable=broad-except
-            return False
-
-    @property
-    def includes(self):
-        if self._includes is None:
-            if self.is_artifact_includes:
-                self._includes = self._load_artifact_additional_includes()
-            else:
-                self._includes = self.additional_includes if self.additional_includes else []
-        return self._includes
-
-    @property
-    def artifact_validate_result(self):
-        if not self.is_artifact_includes:
-            return _ValidationResultBuilder.success()
-        if self._artifact_validate_result is None:
-            # artifact validation is done on loading now, so trigger it here
-            self._load_artifact_additional_includes()
-        return self._artifact_validate_result
-
-    @classmethod
-    def merge_local_path_to_additional_includes(cls, local_path, config_info, conflict_files):
-        file_name = Path(local_path).name
-        conflicts = conflict_files.get(file_name, set())
-        conflicts.add(config_info)
-        conflict_files[file_name] = conflicts
+        """Whether the additional include configs have been provided."""
+        return len(self.origin_configs) != 0
 
     @classmethod
     def _get_artifacts_by_config(cls, artifact_config):
-        artifact_cache = ArtifactCache()
-        if any(item not in artifact_config for item in ["feed", "name", "version"]):
-            raise RuntimeError("Feed, name and version are required for artifacts config.")
-        return artifact_cache.get(
+        # config key existence has been validated in _validate_additional_include_config
+        return ArtifactCache().get(
             organization=artifact_config.get("organization", None),
             project=artifact_config.get("project", None),
             feed=artifact_config["feed"],
             name=artifact_config["name"],
             version=artifact_config["version"],
             scope=artifact_config.get("scope", "organization"),
             resolve=True,
         )
 
-    def _resolve_additional_include_config(self, additional_include_config):
-        result = []
+    def _validate_additional_include_config(self, additional_include_config):
+        validation_result = _ValidationResultBuilder.success()
         if (
             isinstance(additional_include_config, dict)
             and additional_include_config.get("type") == AzureDevopsArtifactsType.ARTIFACT
         ):
-            try:
-                # Get the artifacts package from devops to the local
-                artifact_path = self._get_artifacts_by_config(additional_include_config)
-                for item in os.listdir(artifact_path):
-                    config_info = (
-                        f"{additional_include_config['name']}:{additional_include_config['version']} in "
-                        f"{additional_include_config['feed']}"
+            # for artifact additional include, we validate the required fields in config but won't validate the
+            # artifact content to avoid downloading it in validation stage
+            # note that runtime error will be thrown when loading the artifact
+            for item in ["feed", "name", "version"]:
+                if item not in additional_include_config:
+                    # TODO: add yaml path after we support list index in yaml path
+                    validation_result.append_error(
+                        "{} are required for artifacts config but got {}.".format(
+                            item, json.dumps(additional_include_config)
+                        )
                     )
-                    result.append((os.path.join(artifact_path, item), config_info))
-            except Exception as e:  # pylint: disable=broad-except
-                self.artifact_validate_result.append_error(message=e.args[0])
         elif isinstance(additional_include_config, str):
-            result.append((additional_include_config, additional_include_config))
+            validation_result.merge_with(self._validate_local_additional_include_config(additional_include_config))
         else:
-            self.artifact_validate_result.append_error(
+            validation_result.append_error(
                 message=f"Unexpected format in additional_includes, {additional_include_config}"
             )
+        return validation_result
+
+    @classmethod
+    def _resolve_artifact_additional_include_config(cls, artifact_additional_include_config) -> List[Tuple[str, str]]:
+        """Resolve an artifact additional include config into a list of (local_path, config_info) tuples.
+        Configured artifact will be downloaded to local path first; the config_info will be in below format:
+        %name%:%version% in %feed%
+        """
+        result = []
+        # Note that we don't validate the artifact config here, since it has already been validated in
+        # _validate_additional_include_config
+        artifact_path = cls._get_artifacts_by_config(artifact_additional_include_config)
+        for item in os.listdir(artifact_path):
+            config_info = (
+                f"{artifact_additional_include_config['name']}:{artifact_additional_include_config['version']} in "
+                f"{artifact_additional_include_config['feed']}"
+            )
+            result.append((os.path.join(artifact_path, item), config_info))
         return result
 
+    def _resolve_artifact_additional_include_configs(self, artifact_additional_includes_configs: List[Dict[str, str]]):
+        additional_include_info_tuples = []
+        # Unlike component registration, artifact downloading is a pure download progress; so we can use
+        # more threads to speed up the downloading process.
+        # We use 5 threads per CPU core plus 5 extra threads, and the max number of threads is 64.
+        num_threads = min(64, (int(cpu_count()) * 5) + 5)
+        if (
+            len(artifact_additional_includes_configs) > 1
+            and is_concurrent_component_registration_enabled()
+            and is_private_preview_enabled()
+        ):
+            with ThreadPoolExecutor(max_workers=num_threads) as executor:
+                all_artifact_pairs = executor.map(
+                    self._resolve_artifact_additional_include_config, artifact_additional_includes_configs
+                )
+        else:
+            all_artifact_pairs = list(
+                map(self._resolve_artifact_additional_include_config, artifact_additional_includes_configs)
+            )
+        for artifact_pairs in all_artifact_pairs:
+            additional_include_info_tuples.extend(artifact_pairs)
+        return additional_include_info_tuples
+
     @staticmethod
     def _copy(src: Path, dst: Path, *, ignore_file=None) -> None:
         if ignore_file and ignore_file.is_file_excluded(src):
             return
         if not src.exists():
             raise ValueError(f"Path {src} does not exist.")
         if src.is_file():
@@ -192,220 +190,254 @@
         zip_file = dst_path / zip_additional_include.name
         with zipfile.ZipFile(zip_file, "w") as zf:
             zf.write(folder_to_zip, os.path.relpath(folder_to_zip, folder_to_zip.parent))  # write root in zip
             for root, _, files in os.walk(folder_to_zip, followlinks=True):
                 for path, _ in traverse_directory(root, files, str(folder_to_zip), "", ignore_file=ignore_file):
                     zf.write(path, os.path.relpath(path, folder_to_zip.parent))
 
-    def cleanup(self) -> None:
-        """Clean up potential tmp folder generated during resolve as it can be
-        very disk consuming."""
-        if not self._tmp_code_path:
-            return
-        if Path(self._tmp_code_path).is_dir():
-            shutil.rmtree(self._tmp_code_path)
-        self._tmp_code_path = None  # point code path back to real path
-
-    def _load_artifact_additional_includes(self):
+    def _get_resolved_additional_include_configs(self) -> List[str]:
         """
-        Load the additional includes by yaml format.
+        Resolve additional include configs to a list of local_paths and return it.
 
-        Addition includes is a list of include files, such as local paths and Azure Devops Artifacts.
-        Yaml format of additional_includes likes below:
+        Addition includes is a list of include files, including local paths and Azure Devops Artifacts.
+        Yaml format of additional_includes looks like below:
             additional_includes:
              - your/local/path
              - type: artifact
                organization: devops_organization
                project: devops_project
                feed: artifacts_feed_name
                name: universal_package_name
                version: package_version
                scope: scope_type
-        If will get the artifacts package from devops to the local, and merge them with the local path into
-        additional include list. If there are files conflict in the artifacts, user error will be raised.
+        The artifacts package will be downloaded from devops to the local in this function and transferred to
+        the local paths of downloaded artifacts;
+        The local paths will be returned directly.
+        If there are conflicts among artifacts, runtime error will be raised. Note that we won't check the
+        conflicts between artifacts and local paths and conflicts among local paths. Reasons are:
+        1. There can be ignore_file in local paths, which makes it hard to check the conflict and may lead to breaking
+        changes;
+        2. Conflicts among artifacts are more likely to happen, since user may refer to 2 artifacts of the same name
+        but with different version & feed.
+        3. According to current design, folders in local paths will be merged; while artifact conflicts can be
+        identified by folder name conflicts and are not allowed.
 
         :return additional_includes: Path list of additional_includes
         :rtype additional_includes: List[str]
         """
-        self._artifact_validate_result = _ValidationResultBuilder.success()
-        additional_includes, conflict_files = [], {}
+        additional_include_configs_in_local_path = []
 
-        # Load the artifacts config from additional_includes
-        # pylint: disable=no-member
-        if self.additional_includes:
-            additional_includes_configs = self.additional_includes
-        elif (
-            hasattr(self, "additional_includes_file_path")
-            and self.additional_includes_file_path.exists()
-            and self.additional_includes_file_path.suffix == ADDITIONAL_INCLUDES_SUFFIX
-            and self.additional_includes_file_path.is_file()
-        ):
-            with open(self.additional_includes_file_path) as f:
-                additional_includes_configs = yaml.safe_load(f)
-                additional_includes_configs = additional_includes_configs.get(ADDITIONAL_INCLUDES_KEY, [])
-        else:
-            return additional_includes
+        artifact_additional_include_configs = []
+        for additional_include_config in self.origin_configs:
+            if isinstance(additional_include_config, str):
+                # add local additional include configs directly
+                additional_include_configs_in_local_path.append(additional_include_config)
+            else:
+                # artifact additional include config will be downloaded and resolved to a local path later
+                # note that there is no more validation for artifact additional include config here, since it has
+                # already been validated in _validate_additional_include_config
+                artifact_additional_include_configs.append(additional_include_config)
 
-        # Unlike component registration, artifact downloading is a pure download progress; so we can use
-        # more threads to speed up the downloading process.
-        # We use 5 threads per CPU core plus 5 extra threads, and the max number of threads is 64.
-        num_threads = min(64, (int(cpu_count()) * 5) + 5)
-        if (
-            len(additional_includes_configs) > 1
-            and is_concurrent_component_registration_enabled()
-            and is_private_preview_enabled()
-        ):
-            with ThreadPoolExecutor(max_workers=num_threads) as executor:
-                for result in executor.map(self._resolve_additional_include_config, additional_includes_configs):
-                    for local_path, config_info in result:
-                        additional_includes.append(local_path)
-                        self.merge_local_path_to_additional_includes(
-                            local_path=local_path, config_info=config_info, conflict_files=conflict_files
-                        )
-        else:
-            for result in map(self._resolve_additional_include_config, additional_includes_configs):
-                for local_path, config_info in result:
-                    additional_includes.append(local_path)
-                    self.merge_local_path_to_additional_includes(
-                        local_path=local_path, config_info=config_info, conflict_files=conflict_files
-                    )
+        artifact_additional_include_info_tuples = self._resolve_artifact_additional_include_configs(
+            artifact_additional_include_configs
+        )
+        additional_include_configs_in_local_path.extend(
+            local_path for local_path, _ in artifact_additional_include_info_tuples
+        )
+
+        # check file conflicts among artifact package
+        # given this is not in validate stage, we will raise error if there are conflict files
+        conflict_files = defaultdict(set)
+        for local_path, config_info in artifact_additional_include_info_tuples:
+            file_name = Path(local_path).name
+            conflict_files[file_name].add(config_info)
 
-        # Check the file conflict in local path and artifact package.
         conflict_files = {k: v for k, v in conflict_files.items() if len(v) > 1}
         if conflict_files:
-            self.artifact_validate_result.append_error(
-                message=f"There are conflict files in additional include: {conflict_files}"
-            )
-        return additional_includes
+            raise RuntimeError(f"There are conflict files in additional include: {conflict_files}")
+
+        return additional_include_configs_in_local_path
 
-    def _validate(self) -> MutableValidationResult:
+    def _validate_local_additional_include_config(self, local_path: str, config_info: str = None):
+        """Validate local additional include config.
+
+        Note that we will check the file conflicts between each local additional includes and origin code, but
+        won't check the file conflicts among local additional includes fo now.
+        """
         validation_result = _ValidationResultBuilder.success()
-        validation_result.merge_with(self.artifact_validate_result)
-        if not self.with_includes:
+        include_path = self.base_path / local_path
+        # if additional include has not supported characters, resolve will fail and raise OSError
+        try:
+            src_path = include_path.resolve()
+        except OSError:
+            # no need to include potential yaml file name in error message as it will be covered by
+            # validation message construction.
+            error_msg = (
+                f"Failed to resolve additional include " f"{config_info or local_path} " f"based on {self.base_path}."
+            )
+            validation_result.append_error(message=error_msg)
             return validation_result
-        for additional_include in self.includes:
-            include_path = self.base_path / additional_include
-            # if additional include has not supported characters, resolve will fail and raise OSError
-            try:
-                src_path = include_path.resolve()
-            except OSError:
-                error_msg = f"Failed to resolve additional include {additional_include} for {self.yaml_name}."
-                validation_result.append_error(message=error_msg)
-                continue
 
-            if not src_path.exists() and not self._is_folder_to_compress(src_path):
-                error_msg = f"Unable to find additional include {additional_include} for {self.yaml_name}."
-                validation_result.append_error(message=error_msg)
-                continue
+        if not src_path.exists() and not self._is_folder_to_compress(src_path):
+            error_msg = f"Unable to find additional include {config_info or local_path}"
+            validation_result.append_error(message=error_msg)
+            return validation_result
 
-            if len(src_path.parents) == 0:
-                error_msg = f"Root directory is not supported for additional includes for {self.yaml_name}."
-                validation_result.append_error(message=error_msg)
-                continue
+        if len(src_path.parents) == 0:
+            error_msg = "Root directory is not supported for additional includes."
+            validation_result.append_error(message=error_msg)
+            return validation_result
 
-            dst_path = Path(self.code_path) / src_path.name if self.code_path else None
-            if dst_path:
-                if dst_path.is_symlink():
-                    # if destination path is symbolic link, check if it points to the same file/folder as source path
-                    if dst_path.resolve() != src_path.resolve():
-                        error_msg = (
-                            f"A symbolic link already exists for additional include {additional_include} "
-                            f"for {self.yaml_name}."
-                        )
-                        validation_result.append_error(message=error_msg)
-                        continue
-                elif dst_path.exists():
-                    error_msg = (
-                        f"A file already exists for additional include {additional_include} for " f"{self.yaml_name}."
-                    )
+        dst_path = Path(self.resolved_code_path) / src_path.name if self.resolved_code_path else None
+        if dst_path:
+            if dst_path.is_symlink():
+                # if destination path is symbolic link, check if it points to the same file/folder as source path
+                if dst_path.resolve() != src_path.resolve():
+                    error_msg = f"A symbolic link already exists for additional include {config_info or local_path}."
                     validation_result.append_error(message=error_msg)
+                    return validation_result
+            elif dst_path.exists():
+                error_msg = f"A file already exists for additional include {config_info or local_path}."
+                validation_result.append_error(message=error_msg)
         return validation_result
 
-    def _resolve_code(self, tmp_folder_path):
-        """Resolve code when additional includes is specified.
-
-        create a tmp folder and copy all files under real code path to it.
-        """
+    def validate(self) -> MutableValidationResult:
+        validation_result = _ValidationResultBuilder.success()
+        for additional_include_config in self.origin_configs:
+            validation_result.merge_with(self._validate_additional_include_config(additional_include_config))
+        return validation_result
 
+    def _copy_origin_code(self, target_path):
+        """Copy origin code to target path."""
         # code can be either file or folder, as additional includes exists, need to copy to temporary folder
-        # pylint: disable=no-member
-        if self.code_path:
-            if Path(self.code_path).is_file():
-                # use a dummy ignore file to save base path
-                root_ignore_file = ComponentIgnoreFile(
-                    Path(self.code_path).parent,
-                    skip_ignore_file=True,
-                    additional_includes_file_name=self.additional_includes_file_path.name
-                    if hasattr(self, "additional_includes_file_path")
-                    else None,
-                )
-                self._copy(
-                    Path(self.code_path), tmp_folder_path / Path(self.code_path).name, ignore_file=root_ignore_file
-                )
-            else:
-                # current implementation of ignore file is based on absolute path, so it cannot be shared
-                root_ignore_file = ComponentIgnoreFile(
-                    self.code_path,
-                    additional_includes_file_name=self.additional_includes_file_path.name
-                    if hasattr(self, "additional_includes_file_path")
-                    else None,
-                )
-                self._copy(self.code_path, tmp_folder_path, ignore_file=root_ignore_file)
-        else:
+        if self.resolved_code_path is None:
+            # if additional include configs exist but no origin code path, return a dummy ignore file
+            return ComponentIgnoreFile(
+                self.base_path,
+            )
+
+        if Path(self.resolved_code_path).is_file():
+            # use a dummy ignore file to save base path
             root_ignore_file = ComponentIgnoreFile(
-                self.yaml_path.parent,
+                Path(self.resolved_code_path).parent,
+                skip_ignore_file=True,
             )
+            self._copy(
+                Path(self.resolved_code_path),
+                target_path / Path(self.resolved_code_path).name,
+                ignore_file=root_ignore_file,
+            )
+        else:
+            # current implementation of ignore file is based on absolute path, so it cannot be shared
+            root_ignore_file = ComponentIgnoreFile(self.resolved_code_path)
+            self._copy(self.resolved_code_path, target_path, ignore_file=root_ignore_file)
         return root_ignore_file
 
-    def resolve(self) -> None:
-        """Resolve code and potential additional includes.
-
-        If no additional includes is specified, just return and use
-        original real code path; otherwise, create a tmp folder and copy
-        all files under real code path and additional includes to it.
+    @contextmanager
+    def merge_local_code_and_additional_includes(self) -> Path:
+        """Merge code and potential additional includes into a temp folder and return the absolute path of it.
+        If no additional includes is specified, just return absolute path of original code path;
+        If no original code path is specified, just return None.
         """
         if not self.with_includes:
+            if self.resolved_code_path is None:
+                yield None
+            else:
+                yield self.resolved_code_path.absolute()
             return
 
         tmp_folder_path = Path(tempfile.mkdtemp())
-        root_ignore_file = self._resolve_code(tmp_folder_path)
+        root_ignore_file = self._copy_origin_code(tmp_folder_path)
 
         # resolve additional includes
         base_path = self.base_path
         # additional includes from artifact will be downloaded to a temp local path on calling
         # self.includes, so no need to add specific logic for artifact
 
         # TODO: skip ignored files defined in code when copying additional includes
         # copy additional includes disregarding ignore files as current ignore file implementation
         # is based on absolute path, which is not suitable for additional includes
-        for additional_include in self.includes:
-            src_path = Path(additional_include)
+        for additional_include_local_path in self._get_resolved_additional_include_configs():
+            src_path = Path(additional_include_local_path)
             if not src_path.is_absolute():
-                src_path = (base_path / additional_include).resolve()
+                src_path = (base_path / additional_include_local_path).resolve()
             dst_path = (tmp_folder_path / src_path.name).resolve()
 
             root_ignore_file.rebase(src_path.parent)
             if self._is_folder_to_compress(src_path):
                 self._resolve_folder_to_compress(
-                    additional_include,
+                    additional_include_local_path,
                     Path(tmp_folder_path),
                     # actual src path is without .zip suffix
                     ignore_file=root_ignore_file.merge(src_path.parent / src_path.stem),
                 )
                 # early continue as the folder is compressed as a zip file
                 continue
 
-            if not src_path.exists():
-                raise ValueError(f"Unable to find additional include {additional_include} for {self.yaml_name}.")
-
+            # no need to check if src_path exists as it is already validated
             if src_path.is_file():
                 self._copy(src_path, dst_path, ignore_file=root_ignore_file)
-            if src_path.is_dir():
+            elif src_path.is_dir():
                 self._copy(
                     src_path,
                     dst_path,
                     # root ignore file on parent + ignore file on src_path
                     ignore_file=root_ignore_file.merge(src_path),
                 )
+            else:
+                raise ValueError(f"Unable to find additional include {additional_include_local_path}.")
+
+        yield tmp_folder_path.absolute()
 
-        self._tmp_code_path = tmp_folder_path  # point code path to tmp folder
+        # clean up tmp folder as it can be very disk space consuming
+        shutil.rmtree(tmp_folder_path, ignore_errors=True)
         return
+
+
+class AdditionalIncludesMixin(ComponentCodeMixin):
+    @classmethod
+    def _get_additional_includes_field_name(cls) -> str:
+        """Get the field name for additional includes."""
+        return "additional_includes"
+
+    def _get_all_additional_includes_configs(self) -> List:
+        """Get all additional include configs."""
+        return getattr(self, self._get_additional_includes_field_name(), [])
+
+    def _append_diagnostics_and_check_if_origin_code_reliable_for_local_path_validation(
+        self, base_validation_result: MutableValidationResult = None
+    ) -> bool:
+        is_reliable = super()._append_diagnostics_and_check_if_origin_code_reliable_for_local_path_validation(
+            base_validation_result
+        )
+        additional_includes_obj = self._generate_additional_includes_obj()
+        base_validation_result.merge_with(
+            additional_includes_obj.validate(), field_name=self._get_additional_includes_field_name()
+        )
+        # if additional includes is specified, origin code will be merged with additional includes into a temp folder
+        # before registered as a code asset, so origin code value is not reliable for local path validation
+        if additional_includes_obj.with_includes:
+            return False
+        return is_reliable
+
+    def _generate_additional_includes_obj(self):
+        return AdditionalIncludes(
+            base_path=self._get_base_path_for_code(),
+            configs=self._get_all_additional_includes_configs(),
+            origin_code_value=self._get_origin_code_value(),
+        )
+
+    @contextmanager
+    def _try_build_local_code(self) -> Optional[Code]:
+        """Build final code when origin code is a local code.
+        Will merge code path with additional includes into a temp folder if additional includes is specified.
+        """
+        # will try to merge code and additional includes even if code is None
+        with self._generate_additional_includes_obj().merge_local_code_and_additional_includes() as tmp_code_dir:
+            if tmp_code_dir is None:
+                yield None
+            else:
+                yield Code(
+                    base_path=self._get_base_path_for_code(),
+                    path=tmp_code_dir,
+                    ignore_file=ComponentIgnoreFile(tmp_code_dir),
+                )
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/parallel_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/parallel_component.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,18 +17,22 @@
 from azure.ai.ml.entities._job.parallel.parallel_task import ParallelTask
 from azure.ai.ml.entities._job.parallel.parameterized_parallel import ParameterizedParallel
 from azure.ai.ml.entities._job.parallel.retry_settings import RetrySettings
 from azure.ai.ml.exceptions import ErrorCategory, ErrorTarget, ValidationException
 
 from ..._schema import PathAwareSchema
 from .._util import validate_attribute_type
+from .._validation import MutableValidationResult
+from .code import ComponentCodeMixin
 from .component import Component
 
 
-class ParallelComponent(Component, ParameterizedParallel):  # pylint: disable=too-many-instance-attributes
+class ParallelComponent(
+    Component, ParameterizedParallel, ComponentCodeMixin
+):  # pylint: disable=too-many-instance-attributes
     """Parallel component version, used to define a parallel component.
 
     :param name: Name of the component.
     :type name: str
     :param version: Version of the component.
     :type version: str
     :param description: Description of the component.
@@ -75,15 +79,15 @@
     :type instance_count: int
     :param is_deterministic: Whether the parallel component is deterministic.
     :type is_deterministic: bool
     :raises ~azure.ai.ml.exceptions.ValidationException: Raised if ParallelComponent cannot be successfully validated.
         Details will be provided in the error message.
     """
 
-    def __init__(
+    def __init__(  # pylint: disable=too-many-locals
         self,
         *,
         name: Optional[str] = None,
         version: Optional[str] = None,
         description: Optional[str] = None,
         tags: Optional[Dict[str, Any]] = None,
         display_name: Optional[str] = None,
@@ -150,24 +154,24 @@
             # Convert str to int.
             pattern = re.compile(r"^\d+([kKmMgG][bB])*$")
             if not pattern.match(self.mini_batch_size):
                 raise ValueError(r"Parameter mini_batch_size must follow regex rule ^\d+([kKmMgG][bB])*$")
 
             try:
                 self.mini_batch_size = int(self.mini_batch_size)
-            except ValueError:
+            except ValueError as e:
                 unit = self.mini_batch_size[-2:].lower()
                 if unit == "kb":
                     self.mini_batch_size = int(self.mini_batch_size[0:-2]) * 1024
                 elif unit == "mb":
                     self.mini_batch_size = int(self.mini_batch_size[0:-2]) * 1024 * 1024
                 elif unit == "gb":
                     self.mini_batch_size = int(self.mini_batch_size[0:-2]) * 1024 * 1024 * 1024
                 else:
-                    raise ValueError("mini_batch_size unit must be kb, mb or gb")
+                    raise ValueError("mini_batch_size unit must be kb, mb or gb") from e
 
     @property
     def instance_count(self) -> int:
         """Return value of promoted property resources.instance_count.
 
         :return: Value of resources.instance_count.
         :rtype: Optional[int]
@@ -217,14 +221,19 @@
         if not value:
             return
         if not self.task:
             self.task = ParallelTask(environment=value)
         else:
             self.task.environment = value
 
+    def _customized_validate(self) -> MutableValidationResult:
+        validation_result = super()._customized_validate()
+        self._append_diagnostics_and_check_if_origin_code_reliable_for_local_path_validation(validation_result)
+        return validation_result
+
     @classmethod
     def _attr_type_map(cls) -> dict:
         return {
             "retry_settings": (dict, RetrySettings),
             "task": (dict, ParallelTask),
             "logging_level": str,
             "max_concurrency_per_instance": int,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/component_factory.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/component_factory.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/datatransfer_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/datatransfer_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/spark_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/spark_component.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,79 +1,105 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import os
-from pathlib import Path
 from typing import Dict, List, Optional, Union
 
 from marshmallow import Schema
 
 from azure.ai.ml._schema.component.spark_component import SparkComponentSchema
 from azure.ai.ml.constants._common import COMPONENT_TYPE
 from azure.ai.ml.constants._component import NodeType
 from azure.ai.ml.constants._job.job import RestSparkConfKey
 from azure.ai.ml.entities._assets import Environment
 from azure.ai.ml.entities._job.parameterized_spark import ParameterizedSpark
 
 from ..._schema import PathAwareSchema
 from .._job.spark_job_entry_mixin import SparkJobEntry, SparkJobEntryMixin
 from .._util import convert_ordered_dict_to_dict, validate_attribute_type
+from .._validation import MutableValidationResult
+from .code import ComponentCodeMixin
 from .component import Component
 
 
-class SparkComponent(Component, ParameterizedSpark, SparkJobEntryMixin):  # pylint: disable=too-many-instance-attributes
-    """Spark component version, used to define a spark component.
+class SparkComponent(
+    Component, ParameterizedSpark, SparkJobEntryMixin, ComponentCodeMixin
+):  # pylint: disable=too-many-instance-attributes
+    """Spark component version, used to define a Spark Component or Job.
 
-    :param code: The source code to run the job.
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url pointing
+        to a remote location. Defaults to ".".
     :type code: Union[str, os.PathLike]
-    :param entry: File or class entry point.
-    :type entry: dict[str, str]
-    :param py_files: List of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
-    :type py_files: Optional[typing.List[str]]
-    :param jars: List of jars to include on the driver and executor classpaths.
-    :type jars: Optional[typing.List[str]]
-    :param files: List of files to be placed in the working directory of each executor.
-    :type files: Optional[typing.List[str]]
-    :param archives: List of archives to be extracted into the working directory of each executor.
-    :type archives: Optional[typing.List[str]]
-    :param driver_cores: Number of cores to use for the driver process, only in cluster mode.
+    :param entry: The file or class entry point.
+    :type entry: Union[dict[str, str], ~azure.ai.ml.entities.SparkJobEntry]
+    :param py_files: The list of .zip, .egg or .py files to place on the PYTHONPATH for Python apps.
+    :type py_files: list[str]
+    :param jars: The list of .JAR files to include on the driver and executor classpaths.
+    :type jars: list[str]
+    :param files: The list of files to be placed in the working directory of each executor.
+    :type files: list[str]
+    :param archives: The list of archives to be extracted into the working directory of each executor.
+    :type archives: list[str]
+    :param driver_cores: The number of cores to use for the driver process, only in cluster mode.
     :type driver_cores: int
-    :param driver_memory: Amount of memory to use for the driver process.
+    :param driver_memory: The amount of memory to use for the driver process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type driver_memory: str
     :param executor_cores: The number of cores to use on each executor.
     :type executor_cores: int
-    :param executor_memory: Amount of memory to use per executor process, in the same format as JVM memory strings with
-        a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).
+    :param executor_memory: The amount of memory to use per executor process, formatted as strings with a size unit
+        suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").
     :type executor_memory: str
-    :param executor_instances: Initial number of executors.
+    :param executor_instances: The initial number of executors.
     :type executor_instances: int
     :param dynamic_allocation_enabled: Whether to use dynamic resource allocation, which scales the number of executors
-        registered with this application up and down based on the workload.
+        registered with this application up and down based on the workload. Defaults to False.
     :type dynamic_allocation_enabled: bool
-    :param dynamic_allocation_min_executors: Lower bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_min_executors: The lower bound for the number of executors if dynamic allocation is
+        enabled.
     :type dynamic_allocation_min_executors: int
-    :param dynamic_allocation_max_executors: Upper bound for the number of executors if dynamic allocation is enabled.
+    :param dynamic_allocation_max_executors: The upper bound for the number of executors if dynamic allocation is
+        enabled.
     :type dynamic_allocation_max_executors: int
-    :param conf: A dict with pre-defined spark configurations key and values.
-    :type conf: dict
-    :param environment: Azure ML environment to run the job in.
-    :type environment: Union[str, azure.ai.ml.entities.Environment]
-    :param inputs: Mapping of inputs data bindings used in the job.
-    :type inputs: dict
-    :param outputs: Mapping of outputs data bindings used in the job.
-    :type outputs: dict
-    :param args: Arguments for the job.
+    :param conf: A dictionary with pre-defined Spark configurations key and values.
+    :type conf: dict[str, str]
+    :param environment: The Azure ML environment to run the job in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param inputs: A mapping of input names to input data sources used in the job.
+    :type inputs: dict[str, Union[
+        ~azure.ai.ml.entities._job.pipeline._io.NodeOutput,
+        ~azure.ai.ml.Input,
+        str,
+        bool,
+        int,
+        float,
+        Enum,
+        ]
+    ]
+    :param outputs: A mapping of output names to output data sources used in the job.
+    :type outputs: dict[str, Union[str, ~azure.ai.ml.Output]]
+    :param args: The arguments for the job.
     :type args: str
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_spark_configurations.py
+            :start-after: [START spark_component_definition]
+            :end-before: [END spark_component_definition]
+            :language: python
+            :dedent: 8
+            :caption: Creating SparkComponent.
     """
 
     def __init__(
         self,
         *,
         code: Union[str, os.PathLike] = ".",
-        entry: Union[Dict[str, str], SparkJobEntry, None] = None,
+        entry: Optional[Union[Dict[str, str], SparkJobEntry]] = None,
         py_files: Optional[List[str]] = None,
         jars: Optional[List[str]] = None,
         files: Optional[List[str]] = None,
         archives: Optional[List[str]] = None,
         driver_cores: Optional[int] = None,
         driver_memory: Optional[str] = None,
         executor_cores: Optional[int] = None,
@@ -84,30 +110,27 @@
         dynamic_allocation_max_executors: Optional[int] = None,
         conf: Optional[Dict[str, str]] = None,
         environment: Optional[Union[str, Environment]] = None,
         inputs: Optional[Dict] = None,
         outputs: Optional[Dict] = None,
         args: Optional[str] = None,
         **kwargs,
-    ):
+    ) -> None:
         # validate init params are valid type
         validate_attribute_type(attrs_to_check=locals(), attr_type_map=self._attr_type_map())
 
         kwargs[COMPONENT_TYPE] = NodeType.SPARK
-        # Set default base path
-        if "base_path" not in kwargs:
-            kwargs["base_path"] = Path(".")
 
         super().__init__(
             inputs=inputs,
             outputs=outputs,
             **kwargs,
         )
 
-        self.code = code
+        self.code: Union[str, os.PathLike] = code
         self.entry = entry
         self.py_files = py_files
         self.jars = jars
         self.files = files
         self.archives = archives
         self.conf = conf
         self.environment = environment
@@ -139,14 +162,19 @@
     @classmethod
     def _attr_type_map(cls) -> dict:
         return {
             "environment": (str, Environment),
             "code": (str, os.PathLike),
         }
 
+    def _customized_validate(self) -> MutableValidationResult:
+        validation_result = super()._customized_validate()
+        self._append_diagnostics_and_check_if_origin_code_reliable_for_local_path_validation(validation_result)
+        return validation_result
+
     def _to_dict(self) -> Dict:
         """Dump the spark component content into a dictionary."""
         return convert_ordered_dict_to_dict({**self._other_parameter, **super(SparkComponent, self)._to_dict()})
 
     def _get_environment_id(self) -> Union[str, None]:
         # Return environment id of environment
         # handle case when environment is defined inline
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/import_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/import_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/automl_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/automl_component.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/_artifact_cache.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_utils/_artifact_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,28 +13,29 @@
 from collections import defaultdict
 from io import BytesIO
 from pathlib import Path
 from threading import Lock
 
 import requests
 
+from .utils import get_base_directory_for_cache
+
 _logger = logging.getLogger(__name__)
 
 
 class ArtifactCache:
     """Disk cache of azure artifact packages.
 
     The key of the cache is path of artifact packages in local, like this
     azure-ai-ml/components/additional_includes/artifacts/{organization}/{project}/{feed}/{package_name}/{version}.
     The value is the files/folders in this cache folder.
     """
 
-    DEFAULT_DISK_CACHE_DIRECTORY = os.path.join(
-        tempfile.gettempdir(),
-        "azure-ai-ml",
+    # artifact cache is shared across SDK versions and across workspaces/registries
+    DEFAULT_DISK_CACHE_DIRECTORY = get_base_directory_for_cache().joinpath(
         "components",
         "additional_includes",
         "artifacts",
     )
     POSTFIX_CHECKSUM = "checksum"
     _instance_lock = Lock()
     _instance = None
@@ -47,22 +48,21 @@
                     cls._instance = object.__new__(cls)
                     cls.check_artifact_extension()
         return cls._instance
 
     @staticmethod
     def check_artifact_extension():
         # check az extension azure-devops installed. Install it if not installed.
-        process = subprocess.Popen(
-            "az artifacts --help --yes",
-            shell=True,  # nosec B602
-            stdout=subprocess.PIPE,
-            stderr=subprocess.PIPE,
+        result = subprocess.run(
+            [shutil.which("az"), "artifacts", "--help", "--yes"],
+            capture_output=True,
+            check=False,
         )
-        process.communicate()
-        if process.returncode != 0:
+
+        if result.returncode != 0:
             raise RuntimeError(
                 "Auto-installation failed. Please install azure-devops "
                 "extension by 'az extension add --name azure-devops'."
             )
 
     def __init__(self, cache_directory=None):
         self._cache_directory = cache_directory or self.DEFAULT_DISK_CACHE_DIRECTORY
@@ -97,28 +97,28 @@
         """Get organization and project from git remote url. For example, the git remote url is
         "https://organization.visualstudio.com/xxx/project_name/_git/repositry_name" or
         "https://dev.azure.com/{organization}/project".
 
         :return organization_url, project: organization_url, project
         :rtype organization_url, project: str, str
         """
-        process = subprocess.Popen(
-            "git config --get remote.origin.url",
-            stdout=subprocess.PIPE,
-            stderr=subprocess.PIPE,
+        result = subprocess.run(
+            [shutil.which("git"), "config", "--get", "remote.origin.url"],
+            capture_output=True,
             encoding="utf-8",
-            shell=True,  # nosec B602
+            check=False,
         )
-        outs, errs = process.communicate()
-        if process.returncode != 0:
+
+        if result.returncode != 0:
             # When organization and project cannot be retrieved from the origin url.
             raise RuntimeError(
-                f"Get the git origin url failed, you must be in a local Git directory, " f"error message: {errs}"
+                f"Get the git origin url failed, you must be in a local Git directory, "
+                f"error message: {result.stderr}"
             )
-        origin_url = outs.strip()
+        origin_url = result.stdout.strip()
 
         # Organization URL has two format, https://dev.azure.com/{organization} and
         # https://{organization}.visualstudio.com
         # https://docs.microsoft.com/en-us/azure/devops/extend/develop/work-with-urls?view=azure-devops&tabs=http
         if "dev.azure.com" in origin_url:
             regex = r"^https:\/\/\w*@?dev\.azure\.com\/(\w*)\/(\w*)"
             results = re.findall(regex, origin_url)
@@ -191,28 +191,29 @@
         while retries <= max_retries:
             try:
                 self._redirect_artifacts_tool_path(organization)
             except Exception as e:  # pylint: disable=broad-except
                 _logger.warning("Redirect artifacts tool path failed, details: %s", e)
 
             retries += 1
-            process = subprocess.Popen(
+            result = subprocess.run(
                 download_cmd,
-                stdout=subprocess.PIPE,
-                stderr=subprocess.PIPE,
-                shell=True,  # nosec B602
+                capture_output=True,
                 encoding="utf-8",
+                check=False,
             )
-            outputs, errs = process.communicate()
-            if process.returncode != 0:
-                error_msg = f"Download package {name}:{version} from the feed {feed} failed {retries} times: {errs}"
+
+            if result.returncode != 0:
+                error_msg = (
+                    f"Download package {name}:{version} from the feed {feed} failed {retries} times: {result.stderr}"
+                )
                 if retries < max_retries:
                     _logger.warning(error_msg)
                 else:
-                    error_msg = error_msg + f"\nDownload artifact debug info: {outputs}"
+                    error_msg = error_msg + f"\nDownload artifact debug info: {result.stdout}"
                     raise RuntimeError(error_msg)
             else:
                 return
 
     def _check_artifacts(self, artifact_package_path):
         """Check the artifact folder is legal.
 
@@ -293,41 +294,53 @@
         :param version: Version of the package.
         :param scope: Scope of the feed: 'project' if the feed was created in a project, and 'organization' otherwise.
         :param organization: Azure DevOps organization URL.
         :param project: Name or ID of the project.
         :return artifact_package_path: Cache path of the artifact package
         """
         tempdir = tempfile.mktemp()  # nosec B306
-        download_cmd = (
-            f"az artifacts universal download --feed {feed} --name {name} --version {version} "
-            f"--scope {scope} --path {tempdir}"
-        )
+        download_cmd = [
+            shutil.which("az"),
+            "artifacts",
+            "universal",
+            "download",
+            "--feed",
+            feed,
+            "--name",
+            name,
+            "--version",
+            version,
+            "--scope",
+            scope,
+            "--path",
+            tempdir,
+        ]
         if organization:
-            download_cmd = download_cmd + f" --org {organization}"
+            download_cmd.extend(["--org", organization])
         if project:
-            download_cmd = download_cmd + f" --project {project}"
+            download_cmd.extend(["--project", project])
         _logger.info("Start downloading artifacts %s:%s from %s.", name, version, feed)
-        process = subprocess.Popen(
+        result = subprocess.run(
             download_cmd,
-            stdout=subprocess.PIPE,
-            stderr=subprocess.PIPE,
-            shell=True,  # nosec B602
+            capture_output=True,
             encoding="utf-8",
+            check=False,
         )
-        # Avoid deadlock when setting stdout/stderr to PIPE.
-        _, errs = process.communicate()
-        if process.returncode != 0:
+
+        if result.returncode != 0:
             artifacts_tool_not_find_error_pattern = "No such file or directory: .*artifacttool"
-            if re.findall(artifacts_tool_not_find_error_pattern, errs):
+            if re.findall(artifacts_tool_not_find_error_pattern, result.stderr):
                 # When download artifacts tool failed retry download artifacts command
-                _logger.warning("Download package %s:%s from the feed %s failed: %s", name, version, feed, errs)
-                download_cmd = download_cmd + "--debug"
+                _logger.warning(
+                    "Download package %s:%s from the feed %s failed: %s", name, version, feed, result.stderr
+                )
+                download_cmd.append("--debug")
                 self._download_artifacts(download_cmd, organization, name, version, feed)
             else:
-                raise RuntimeError(f"Download package {name}:{version} from the feed {feed} failed: {errs}")
+                raise RuntimeError(f"Download package {name}:{version} from the feed {feed} failed: {result.stderr}")
         try:
             # Copy artifact package from temp folder to the cache path.
             if not all([organization, project]):
                 org_val, project_val = self.get_organization_project_by_git()
                 organization = organization or org_val
                 project = project or project_val
             artifact_package_path = (
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/command_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/command_component.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,84 +1,101 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import os
-from pathlib import Path
-from typing import Dict, Optional, Union, List
-from contextlib import contextmanager
+from typing import Dict, List, Optional, Union
 
 from marshmallow import Schema
 
 from azure.ai.ml._schema.component.command_component import CommandComponentSchema
 from azure.ai.ml.constants._common import COMPONENT_TYPE
 from azure.ai.ml.constants._component import NodeType
 from azure.ai.ml.entities._assets import Environment
 from azure.ai.ml.entities._job.distribution import (
     DistributionConfiguration,
     MpiDistribution,
     PyTorchDistribution,
-    TensorFlowDistribution,
     RayDistribution,
+    TensorFlowDistribution,
 )
 from azure.ai.ml.entities._job.job_resource_configuration import JobResourceConfiguration
 from azure.ai.ml.entities._job.parameterized_command import ParameterizedCommand
 from azure.ai.ml.exceptions import ErrorCategory, ErrorTarget, ValidationException
 
-from .code import ComponentIgnoreFile
-from ._additional_includes import AdditionalIncludes
-
-from ...entities._assets import Code
 from ..._restclient.v2022_10_01.models import ComponentVersion
 from ..._schema import PathAwareSchema
 from ..._utils.utils import get_all_data_binding_expressions, parse_args_description_from_docstring
 from .._util import convert_ordered_dict_to_dict, validate_attribute_type
 from .._validation import MutableValidationResult
+from ._additional_includes import AdditionalIncludesMixin
 from .component import Component
 
 # pylint: disable=protected-access
 
 
-class CommandComponent(Component, ParameterizedCommand):
-    """Command component version, used to define a command component.
+class CommandComponent(Component, ParameterizedCommand, AdditionalIncludesMixin):
+    """Command component version, used to define a Command Component or Job.
 
-    :param name: Name of the component.
+    :param name: The name of the Command job or component.
     :type name: str
-    :param version: Version of the component.
+    :param version: The version of the Command job or component.
     :type version: str
-    :param description: Description of the component.
+    :param description: The description of the component.
     :type description: str
     :param tags: Tag dictionary. Tags can be added, removed, and updated.
     :type tags: dict
-    :param display_name: Display name of the component.
+    :param display_name: The display name of the component.
     :type display_name: str
-    :param command: Command to be executed in component.
+    :param command: The command to be executed.
     :type command: str
-    :param code: Code file or folder that will be uploaded to the cloud for component execution.
+    :param code: The source code to run the job. Can be a local path or "http:", "https:", or "azureml:" url pointing
+        to a remote location.
     :type code: str
-    :param environment: Environment that component will run in.
-    :type environment: Union[Environment, str]
-    :param distribution: Distribution configuration for distributed training.
-    :type distribution: Union[dict, PyTorchDistribution, MpiDistribution, TensorFlowDistribution, RayDistribution]
-    :param resources: Compute Resource configuration for the component.
-    :type resources: Union[dict, ~azure.ai.ml.entities.JobResourceConfiguration]
-    :param inputs: Inputs of the component.
-    :type inputs: dict
-    :param outputs: Outputs of the component.
-    :type outputs: dict
-    :param instance_count: promoted property from resources.instance_count
+    :param environment: The environment that the job will run in.
+    :type environment: Union[str, ~azure.ai.ml.entities.Environment]
+    :param distribution: The configuration for distributed jobs.
+    :type distribution: Union[~azure.ai.ml.PyTorchDistribution, ~azure.ai.ml.MpiDistribution,
+        ~azure.ai.ml.TensorFlowDistribution, ~azure.ai.ml.RayDistribution]
+    :param resources: The compute resource configuration for the command.
+    :type resources: ~azure.ai.ml.entities.JobResourceConfiguration
+    :param inputs: A mapping of input names to input data sources used in the job.
+    :type inputs: dict[str, Union[
+        ~azure.ai.ml.Input,
+        str,
+        bool,
+        int,
+        float,
+        Enum,
+        ]
+    ]
+    :param outputs: A mapping of output names to output data sources used in the job.
+    :type outputs: dict[str, Union[str, ~azure.ai.ml.Output]]
+    :param instance_count: The number of instances or nodes to be used by the compute target. Defaults to 1.
     :type instance_count: int
-    :param is_deterministic: Whether the command component is deterministic.
+    :param is_deterministic: Specifies whether the Command will return the same output given the same input.
+        Defaults to True. When True, if a Command (component) is deterministic and has been run before in the
+        current workspace with the same input and settings, it will reuse results from a previous submitted job
+        when used as a node or step in a pipeline. In that scenario, no compute resources will be used.
     :type is_deterministic: bool
     :param additional_includes: A list of shared additional files to be included in the component.
-    :type additional_includes: list
-    :param properties: Properties of the component. Contents inside will pass through to backend as a dictionary.
-    :type properties: dict
-
+    :type additional_includes: list[str]
+    :param properties: The job property dictionary.
+    :type properties: dict[str, str]
     :raises ~azure.ai.ml.exceptions.ValidationException: Raised if CommandComponent cannot be successfully validated.
         Details will be provided in the error message.
+
+    .. admonition:: Example:
+        :class: tip
+
+        .. literalinclude:: ../samples/ml_samples_command_configurations.py
+            :start-after: [START command_component_definition]
+            :end-before: [END command_component_definition]
+            :language: python
+            :dedent: 8
+            :caption: Creating a CommandComponent.
     """
 
     def __init__(
         self,
         *,
         name: Optional[str] = None,
         version: Optional[str] = None,
@@ -95,22 +112,19 @@
         inputs: Optional[Dict] = None,
         outputs: Optional[Dict] = None,
         instance_count: Optional[int] = None,  # promoted property from resources.instance_count
         is_deterministic: bool = True,
         additional_includes: Optional[List] = None,
         properties: Optional[Dict] = None,
         **kwargs,
-    ):
+    ) -> None:
         # validate init params are valid type
         validate_attribute_type(attrs_to_check=locals(), attr_type_map=self._attr_type_map())
 
         kwargs[COMPONENT_TYPE] = NodeType.COMMAND
-        # Set default base path
-        if "base_path" not in kwargs:
-            kwargs["base_path"] = Path(".")
 
         # Component backend doesn't support environment_variables yet,
         # this is to support the case of CommandComponent being the trial of
         # a SweepJob, where environment_variables is stored as part of trial
         environment_variables = kwargs.pop("environment_variables", None)
         super().__init__(
             name=name,
@@ -141,41 +155,41 @@
                 message=msg,
                 target=ErrorTarget.COMPONENT,
                 no_personal_data_message=msg,
                 error_category=ErrorCategory.USER_ERROR,
             )
         self.instance_count = instance_count
         self.additional_includes = additional_includes or []
-        self.__additional_includes_obj = None
 
-    @property
-    def _additional_includes_obj(self):
-        if (
-            self.__additional_includes_obj is None
-            and self.additional_includes
-            and isinstance(self.additional_includes, list)
-        ):
-            # use property as `self._source_path` is set after __init__ now
-            # `self._source_path` is not None when enter this function
-            self.__additional_includes_obj = AdditionalIncludes(
-                code_path=self.code, yaml_path=self._source_path, additional_includes=self.additional_includes
-            )
-        return self.__additional_includes_obj
+    # region AdditionalIncludesMixin
+    def _get_origin_code_value(self) -> Union[str, os.PathLike, None]:
+        if self.code is not None and isinstance(self.code, str):
+            # directly return code given it will be validated in self._validate_additional_includes
+            return self.code
+
+        # self.code won't be a Code object, or it will fail schema validation according to CodeFields
+        return None
+
+    # endregion
 
     @property
     def instance_count(self) -> int:
-        """Return value of promoted property resources.instance_count.
+        """The number of instances or nodes to be used by the compute target.
 
-        :return: Value of resources.instance_count.
-        :rtype: Optional[int]
+        :rtype: int
         """
         return self.resources.instance_count if self.resources else None
 
     @instance_count.setter
-    def instance_count(self, value: int):
+    def instance_count(self, value: int) -> None:
+        """Sets the number of instances or nodes to be used by the compute target.
+
+        :param value: The number of instances of nodes to be used by the compute target. Defaults to 1.
+        :type instance_count: int
+        """
         if not value:
             return
         if not self.resources:
             self.resources = JobResourceConfiguration(instance_count=value)
         else:
             self.resources.instance_count = value
 
@@ -204,22 +218,22 @@
     def _get_environment_id(self) -> Union[str, None]:
         # Return environment id of environment
         # handle case when environment is defined inline
         if isinstance(self.environment, Environment):
             return self.environment.id
         return self.environment
 
+    # region SchemaValidatableMixin
     @classmethod
     def _create_schema_for_validation(cls, context) -> Union[PathAwareSchema, Schema]:
         return CommandComponentSchema(context=context)
 
     def _customized_validate(self):
         validation_result = super(CommandComponent, self)._customized_validate()
-        if self._additional_includes_obj and self._additional_includes_obj.with_includes:
-            validation_result.merge_with(self._additional_includes_obj._validate())
+        self._append_diagnostics_and_check_if_origin_code_reliable_for_local_path_validation(validation_result)
         validation_result.merge_with(self._validate_command())
         validation_result.merge_with(self._validate_early_available_output())
         return validation_result
 
     def _validate_command(self) -> MutableValidationResult:
         validation_result = self._create_empty_validation_result()
         # command
@@ -235,16 +249,19 @@
                     message="Invalid data binding expression: {}".format(", ".join(invalid_expressions)),
                 )
         return validation_result
 
     def _validate_early_available_output(self) -> MutableValidationResult:
         validation_result = self._create_empty_validation_result()
         for name, output in self.outputs.items():
-            if output.early_available is True and output.is_control is not True:
-                msg = f"Early available output {name!r} requires is_control as True, got {output.is_control!r}."
+            if output.early_available is True and output._is_control_or_primitive_type is not True:
+                msg = (
+                    f"Early available output {name!r} requires is_control as True or output is primitive type, "
+                    f"got {output._is_control_or_primitive_type!r}."
+                )
                 validation_result.append_error(message=msg, yaml_path=f"outputs.{name}")
         return validation_result
 
     def _is_valid_data_binding_expression(self, data_binding_expression: str) -> bool:
         current_obj = self
         for item in data_binding_expression.split("."):
             if hasattr(current_obj, item):
@@ -252,59 +269,18 @@
             else:
                 try:
                     current_obj = current_obj[item]
                 except Exception:  # pylint: disable=broad-except
                     return False
         return True
 
+    # endregion
+
     @classmethod
     def _parse_args_description_from_docstring(cls, docstring):
         return parse_args_description_from_docstring(docstring)
 
     def __str__(self):
         try:
             return self._to_yaml()
         except BaseException:  # pylint: disable=broad-except
             return super(CommandComponent, self).__str__()
-
-    @contextmanager
-    def _resolve_local_code(self) -> Optional[Code]:
-        """Try to create a Code object pointing to local code and yield it.
-
-        If there is no local code to upload, yield None. Otherwise, yield a Code object pointing to the code.
-        """
-        # if there is no local code, yield super()._resolve_local_code() and return early
-        if self.code is not None:
-            with super()._resolve_local_code() as code:
-                if not isinstance(code, Code) or code._is_remote:
-                    yield code
-                    return
-
-        # This is forbidden by schema CodeFields for now so won't happen.
-        if isinstance(self.code, Code):
-            yield code
-            return
-
-        if self._additional_includes_obj is not None:
-            self._additional_includes_obj.resolve()
-
-            # use absolute path in case temp folder & work dir are in different drive
-            tmp_code_dir = (
-                self._additional_includes_obj.code.absolute()
-                if self._additional_includes_obj.code
-                else self._additional_includes_obj.yaml_path.absolute()
-            )
-            rebased_ignore_file = ComponentIgnoreFile(
-                tmp_code_dir,
-            )
-
-            yield Code(
-                base_path=self._base_path,
-                path=tmp_code_dir,
-                ignore_file=rebased_ignore_file,
-            )
-
-            self._additional_includes_obj.cleanup()
-        elif self.code is not None:
-            yield code
-        else:
-            yield None
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/component.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,48 +1,44 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import re
 import uuid
-from contextlib import contextmanager
 from os import PathLike
 from pathlib import Path
 from typing import IO, AnyStr, Dict, Optional, Tuple, Union
 
 from marshmallow import INCLUDE
 
 from ..._restclient.v2022_10_01.models import (
     ComponentContainer,
     ComponentContainerProperties,
     ComponentVersion,
     ComponentVersionProperties,
 )
 from ..._schema import PathAwareSchema
 from ..._schema.component import ComponentSchema
-from ..._utils._arm_id_utils import is_ARM_id_for_resource, is_registry_id_for_resource
-from ..._utils.utils import dump_yaml_to_file, hash_dict, is_private_preview_enabled
+from ..._utils.utils import dump_yaml_to_file, hash_dict
 from ...constants._common import (
     ANONYMOUS_COMPONENT_NAME,
     BASE_PATH_CONTEXT_KEY,
     PARAMS_OVERRIDE_KEY,
     REGISTRY_URI_FORMAT,
     SOURCE_PATH_CONTEXT_KEY,
-    AzureMLResourceType,
     CommonYamlFields,
 )
 from ...constants._component import ComponentSource, IOConstants, NodeType
-from ...entities._assets import Code
 from ...entities._assets.asset import Asset
 from ...entities._inputs_outputs import Input, Output
 from ...entities._mixins import TelemetryMixin, YamlTranslatableMixin
 from ...entities._system_data import SystemData
 from ...entities._util import find_type_in_override
 from ...entities._validation import MutableValidationResult, RemoteValidatableMixin, SchemaValidatableMixin
 from ...exceptions import ErrorCategory, ErrorTarget, ValidationException
-from .code import ComponentIgnoreFile
+from .._inputs_outputs import GroupInput
 
 # pylint: disable=protected-access, redefined-builtin
 # disable redefined-builtin to use id/type as argument name
 
 
 COMPONENT_PLACEHOLDER = "COMPONENT_PLACEHOLDER"
 
@@ -283,14 +279,18 @@
     def _build_io(cls, io_dict: Union[Dict, Input, Output], is_input: bool):
         component_io = {}
         for name, port in io_dict.items():
             if is_input:
                 component_io[name] = port if isinstance(port, Input) else Input(**port)
             else:
                 component_io[name] = port if isinstance(port, Output) else Output(**port)
+
+        if is_input:
+            # Restore flattened parameters to group
+            return GroupInput.restore_flattened_inputs(component_io)
         return component_io
 
     @classmethod
     def _create_schema_for_validation(cls, context) -> PathAwareSchema:
         return ComponentSchema(context=context)
 
     @classmethod
@@ -405,37 +405,41 @@
             _input["type"] = Input._map_from_rest_type(_input["type"])
         outputs = rest_component_version.component_spec.pop("outputs", {})
 
         origin_name = rest_component_version.component_spec[CommonYamlFields.NAME]
         rest_component_version.component_spec[CommonYamlFields.NAME] = ANONYMOUS_COMPONENT_NAME
         init_kwargs = cls._load_with_schema(rest_component_version.component_spec, unknown=INCLUDE)
         init_kwargs.update(
-            dict(
-                id=obj.id,
-                is_anonymous=rest_component_version.is_anonymous,
-                creation_context=obj.system_data,
-                inputs=inputs,
-                outputs=outputs,
-                name=origin_name,
-            )
+            {
+                "id": obj.id,
+                "is_anonymous": rest_component_version.is_anonymous,
+                "creation_context": obj.system_data,
+                "inputs": inputs,
+                "outputs": outputs,
+                "name": origin_name,
+            }
         )
 
         # remove empty values, because some property only works for specific component, eg: distribution for command
         # note that there is an issue that environment == {} will always be true, so use isinstance here
         return {k: v for k, v in init_kwargs.items() if v is not None and not (isinstance(v, dict) and not v)}
 
     def _get_anonymous_hash(self) -> str:
         """Return the name of anonymous component.
 
         same anonymous component(same code and interface) will have same name.
         """
-        component_interface_dict = self._to_dict()
         # omit version since anonymous component's version is random guid
         # omit name since name doesn't impact component's uniqueness
-        return hash_dict(component_interface_dict, keys_to_omit=["name", "id", "version"])
+        return self._get_component_hash(keys_to_omit=["name", "id", "version"])
+
+    def _get_component_hash(self, keys_to_omit=None) -> str:
+        """Return the hash of component."""
+        component_interface_dict = self._to_dict()
+        return hash_dict(component_interface_dict, keys_to_omit=keys_to_omit)
 
     @classmethod
     def _get_resource_type(cls) -> str:
         return "Microsoft.MachineLearningServices/workspaces/components/versions"
 
     def _get_resource_name_version(self) -> Tuple[str, str]:
         if not self.version and not self._auto_increment_version:
@@ -452,29 +456,15 @@
         try:
             return super()._validate(raise_error)
         finally:
             self.name = origin_name
 
     def _customized_validate(self) -> MutableValidationResult:
         validation_result = super(Component, self)._customized_validate()
-        # If private features are enable and component has code value of type str we need to check
-        # that it is a valid git path case. Otherwise we should throw a ValidationError
-        # saying that the code value is not valid
-        # pylint: disable=no-member
-        if (
-            hasattr(self, "code")
-            and self.code is not None
-            and isinstance(self.code, str)
-            and self.code.startswith("git+")
-            and not is_private_preview_enabled()
-        ):
-            validation_result.append_error(
-                message="Not a valid code value: git paths are not supported.",
-                yaml_path="code",
-            )
+
         # validate inputs names
         validation_result.merge_with(self._validate_io_names(self.inputs, raise_error=False))
         validation_result.merge_with(self._validate_io_names(self.outputs, raise_error=False))
 
         return validation_result
 
     def _get_anonymous_component_name_version(self):
@@ -506,22 +496,23 @@
             # hack while full pass through supported is worked on for IPP fields
             component.pop("intellectual_property")
             component["intellectualProperty"] = self._intellectual_property._to_rest_object().serialize()
         properties = ComponentVersionProperties(
             component_spec=component,
             description=self.description,
             is_anonymous=self._is_anonymous,
-            properties=self.properties,
+            properties=dict(self.properties) if self.properties else {},
             tags=self.tags,
         )
         result = ComponentVersion(properties=properties)
         if self._is_anonymous:
             result.name = ANONYMOUS_COMPONENT_NAME
         else:
             result.name = self.name
+            result.properties.properties["client_component_hash"] = self._get_component_hash(keys_to_omit=["version"])
         return result
 
     def _to_dict(self) -> Dict:
         """Dump the command component content into a dictionary."""
 
         # Replace the name of $schema to schema.
         component_schema_dict = self._dump_for_validation()
@@ -552,39 +543,7 @@
             raise ValidationException(
                 message=msg,
                 target=ErrorTarget.COMPONENT,
                 no_personal_data_message=msg,
                 error_category=ErrorCategory.USER_ERROR,
             )
         return self._func(*args, **kwargs)  # pylint: disable=not-callable
-
-    @contextmanager
-    def _resolve_local_code(self) -> Optional[Code]:
-        """Try to create a Code object pointing to local code and yield it.
-
-        If there is no local code to upload, yield None. Otherwise, yield a Code object pointing to the code.
-        """
-        if not hasattr(self, "code"):
-            yield None
-            return
-
-        code = getattr(self, "code")
-
-        if is_ARM_id_for_resource(code, AzureMLResourceType.CODE) or is_registry_id_for_resource(code):
-            # arm id can be passed directly
-            yield None
-        elif isinstance(code, Code):
-            # Code object & registry id need to be resolved into arm id
-            # note that:
-            # 1. Code & CodeOperation are not public for now
-            # 2. AnonymousCodeSchema is not supported in Component for now
-            # So isinstance(component.code, Code) will always be false, or an exception will be raised
-            # in validation stage.
-            yield code
-        elif isinstance(code, str) and code.startswith("git+"):
-            # git also need to be resolved into arm id
-            yield Code(path=code, is_remote=True)
-        elif code is None:
-            # server-side will handle how to run component without a code.
-            yield None
-        else:
-            yield Code(base_path=self._base_path, path=code, ignore_file=ComponentIgnoreFile(code))
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_component/pipeline_component.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_component/pipeline_component.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,22 +12,22 @@
 from typing import Dict, Optional, Tuple, Union
 
 from marshmallow import Schema
 
 from azure.ai.ml._restclient.v2022_10_01.models import ComponentVersion, ComponentVersionProperties
 from azure.ai.ml._schema import PathAwareSchema
 from azure.ai.ml._schema.pipeline.pipeline_component import PipelineComponentSchema
-from azure.ai.ml._utils.utils import is_data_binding_expression, hash_dict
-from azure.ai.ml.constants._common import COMPONENT_TYPE, ARM_ID_PREFIX, ASSET_ARM_ID_REGEX_FORMAT
+from azure.ai.ml._utils.utils import hash_dict, is_data_binding_expression
+from azure.ai.ml.constants._common import ARM_ID_PREFIX, ASSET_ARM_ID_REGEX_FORMAT, COMPONENT_TYPE
 from azure.ai.ml.constants._component import ComponentSource, NodeType
 from azure.ai.ml.constants._job.pipeline import ValidationErrorCode
 from azure.ai.ml.entities._builders import BaseNode, Command
 from azure.ai.ml.entities._builders.control_flow_node import ControlFlowNode, LoopNode
 from azure.ai.ml.entities._component.component import Component
-from azure.ai.ml.entities._inputs_outputs import GroupInput, Input, Output
+from azure.ai.ml.entities._inputs_outputs import GroupInput, Input
 from azure.ai.ml.entities._job.automl.automl_job import AutoMLJob
 from azure.ai.ml.entities._job.pipeline._attr_dict import (
     has_attr_safe,
     try_get_non_arbitrary_attr_for_potential_attr_dict,
 )
 from azure.ai.ml.entities._job.pipeline._pipeline_expression import PipelineExpression
 from azure.ai.ml.entities._validation import MutableValidationResult
@@ -282,22 +282,14 @@
         return dict(Counter(job_types)), dict(Counter(job_sources))
 
     @property
     def jobs(self) -> Dict[str, BaseNode]:
         """Return a dictionary from component variable name to component object."""
         return self._jobs
 
-    @classmethod
-    def _build_io(cls, io_dict: Union[Dict, Input, Output], is_input: bool):
-        component_io = super()._build_io(io_dict, is_input)
-        if is_input:
-            # Restore flattened parameters to group
-            component_io = GroupInput.restore_flattened_inputs(component_io)
-        return component_io
-
     def _get_anonymous_hash(self) -> str:
         """Get anonymous hash for pipeline component."""
         # ideally we should always use rest object to generate hash as it's the same as
         # what we send to server-side, but changing the hash function will break reuse of
         # existing components except for command component (hash result is the same for
         # command component), so we just use rest object to generate hash for pipeline component,
         # which doesn't have reuse issue.
@@ -313,23 +305,14 @@
                 "id",
                 # omit version since it will be set to this hash later
                 "version",
             ],
         )
         return hash_value
 
-    def _get_flattened_inputs(self):
-        _result = {}
-        for key, val in self.inputs.items():
-            if isinstance(val, GroupInput):
-                _result.update(val.flatten(group_parameter_name=key))
-                continue
-            _result[key] = val
-        return _result
-
     @classmethod
     def _load_from_rest_pipeline_job(cls, data: Dict):
         # TODO: refine this?
         # Set type as None here to avoid schema validation failed
         definition_inputs = {p: {"type": None} for p in data.get("inputs", {}).keys()}
         definition_outputs = {p: {"type": None} for p in data.get("outputs", {}).keys()}
         return PipelineComponent(
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/trigger.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/trigger.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_schedule/schedule.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_schedule/schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/data_import.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/data_import.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_data_import/schedule.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_data_import/schedule.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/intellectual_property.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/intellectual_property.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/auto_delete_setting.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/auto_delete_setting.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/workspace_asset_reference.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/workspace_asset_reference.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/federated_learning_silo.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/federated_learning_silo.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/environment.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/environment.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/asset.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/asset.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/model.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/model.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/code.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/code.py`

 * *Files 2% similar despite different names*

```diff
@@ -48,15 +48,14 @@
         description: Optional[str] = None,
         tags: Optional[Dict] = None,
         properties: Optional[Dict] = None,
         path: Optional[Union[str, PathLike]] = None,
         ignore_file: Optional[IgnoreFile] = None,
         **kwargs,
     ):
-        self._is_remote = kwargs.pop("is_remote", False)
         super().__init__(
             name=name,
             version=version,
             description=description,
             tags=tags,
             properties=properties,
             path=path,
@@ -112,15 +111,15 @@
             properties["hash_version"] = get_content_hash_version()
         code_version = CodeVersionDetails(code_uri=self.path, is_anonymous=self._is_anonymous, properties=properties)
         code_version_resource = CodeVersionData(properties=code_version)
 
         return code_version_resource
 
     def _update_path(self, asset_artifact: ArtifactStorageInfo) -> None:
-        """Updates an an artifact with the remote path of a local upload."""
+        """Update an artifact with the remote path of a local upload."""
         if asset_artifact.is_file:
             # Code paths cannot be pointers to single files. It must be a pointer to a container
             # Skipping the setter to avoid being resolved as a local path
             self._path = asset_artifact.subdir_path  # pylint: disable=attribute-defined-outside-init
         else:
             self._path = asset_artifact.full_storage_path  # pylint: disable=attribute-defined-outside-init
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/data.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/data.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/artifact.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/artifact.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/feature_set.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/feature_set.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
             name=name,
             version=version,
             description=description,
             tags=tags,
             path=specification.path,
             **kwargs,
         )
-        if stage not in ["Development", "Production", "Archived"]:
+        if stage and stage not in ["Development", "Production", "Archived"]:
             msg = f"Stage must be Development, Production, or Archived, found {stage}"
             raise ValidationException(
                 message=msg,
                 no_personal_data_message=msg,
                 error_type=ValidationErrorType.INVALID_VALUE,
                 target=ErrorTarget.FEATURE_SET,
                 error_category=ErrorCategory.USER_ERROR,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/base_environment_source.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/base_environment_source.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_package.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/model_package.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/entities/_assets/_artifacts/_package/inferencing_server.py` & `azure-ai-ml-1.9.0/azure/ai/ml/entities/_assets/_artifacts/_package/inferencing_server.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_artifact_utilities.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_artifact_utilities.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_constants.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_constants.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_gen2_storage_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_gen2_storage_helper.py`

 * *Files 1% similar despite different names*

```diff
@@ -157,15 +157,15 @@
                     "Storage Blob Data Reader and Storage Blob Data Contributor roles."
                 )
                 raise ValidationException(
                     message=msg,
                     no_personal_data_message=msg,
                     target=ErrorTarget.ARTIFACT,
                     error_category=ErrorCategory.USER_ERROR,
-                )
+                ) from e
             raise e
 
     def _set_confirmation_metadata(self, name: str, version: str) -> None:
         self.directory_client.set_metadata(_build_metadata_dict(name, version))
 
     def download(self, starts_with: str, destination: str = Path.home()) -> None:
         """Downloads all items inside a specified filesystem directory with the
@@ -204,15 +204,15 @@
             msg = "Saving output with prefix {} was unsuccessful. exception={}"
             raise MlException(
                 message=msg.format(starts_with, e),
                 no_personal_data_message=msg.format("[starts_with]", "[exception]"),
                 target=ErrorTarget.ARTIFACT,
                 error_category=ErrorCategory.USER_ERROR,
                 error=e,
-            )
+            ) from e
 
     def list(self, starts_with: str) -> List[str]:
         """Lists all file names in the specified filesystem with the prefix
         `starts_with`"""
         return [f.get("name") for f in self.file_system_client.get_paths(path=starts_with)]
 
     def exists(self, path: str) -> bool:
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_blob_storage_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_blob_storage_helper.py`

 * *Files 0% similar despite different names*

```diff
@@ -188,15 +188,15 @@
                     "and Storage Blob Data Contributor roles."
                 )
                 raise ValidationException(
                     message=msg,
                     no_personal_data_message=msg,
                     target=ErrorTarget.ARTIFACT,
                     error_category=ErrorCategory.USER_ERROR,
-                )
+                ) from e
             raise e
 
     def _set_confirmation_metadata(self, name: str, version: str) -> None:
         blob_client = self.container_client.get_blob_client(blob=self.indicator_file)
         metadata_dict = _build_metadata_dict(name, version)
         blob_client.set_blob_metadata(metadata_dict)
 
@@ -244,15 +244,15 @@
             msg = "Saving blob with prefix {} was unsuccessful. exception={}"
             raise MlException(
                 message=msg.format(starts_with, e),
                 no_personal_data_message=msg.format("[starts_with]", "[exception]"),
                 target=ErrorTarget.ARTIFACT,
                 error_category=ErrorCategory.USER_ERROR,
                 error=e,
-            )
+            ) from e
 
     def list(self, starts_with: str) -> List[str]:
         """Lists all blob names in the specified container.
 
         :param starts_with: Indicates the blob name starts with to search.
         :return: the list of blob paths in container
         """
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_artifacts/_fileshare_storage_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_artifacts/_fileshare_storage_helper.py`

 * *Files 1% similar despite different names*

```diff
@@ -340,15 +340,15 @@
             with open(local_path, "wb") as file_data:
                 file_data.write(file_content.readall())
 
         for f in folders:
             sub_client = client.get_subdirectory_client(f["name"])
             destination = "/".join((destination, f["name"]))
             recursive_download(sub_client, destination=destination, max_concurrency=max_concurrency)
-    except Exception:
+    except Exception as e:
         msg = f"Saving fileshare directory with prefix {starts_with} was unsuccessful."
         raise MlException(
             message=msg.format(starts_with),
             no_personal_data_message=msg.format("[prefix]"),
             target=ErrorTarget.ARTIFACT,
             error_category=ErrorCategory.SYSTEM_ERROR,
-        )
+        ) from e
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/data_transfer/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/data_transfer/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/sweep/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/sweep/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 17% similar despite different names*

```diff
@@ -3,66 +3,65 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class AllocationState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class AllocationState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Allocation state of the compute. Possible values are: steady - Indicates that the compute is
     not resizing. There are no changes to the number of compute nodes in the compute in progress. A
     compute enters this state when it is created and when no operations are being performed on the
     compute to change the number of compute nodes. resizing - Indicates that the compute is
     resizing; that is, compute nodes are being added to or removed from the compute.
     """
 
     STEADY = "Steady"
     RESIZING = "Resizing"
 
-class AllowRecoverSoftDeletedWorkspace(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class AllowRecoverSoftDeletedWorkspace(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Allow a soft deleted workspace to be recovered
     """
 
     TRUE = "True"
     FALSE = "False"
 
-class ApplicationSharingPolicy(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ApplicationSharingPolicy(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Policy for sharing applications on this compute instance among users of parent workspace. If
     Personal, only the creator can access applications on this compute instance. When Shared, any
     workspace user can access applications on this instance depending on his/her assigned role.
     """
 
     PERSONAL = "Personal"
     SHARED = "Shared"
 
-class BillingCurrency(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class BillingCurrency(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Three lettered code specifying the currency of the VM price. Example: USD
     """
 
     USD = "USD"
 
-class ClusterPurpose(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ClusterPurpose(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Intended usage of the cluster
     """
 
     FAST_PROD = "FastProd"
     DENSE_PROD = "DenseProd"
     DEV_TEST = "DevTest"
 
-class ComputeInstanceAuthorizationType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputeInstanceAuthorizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The Compute Instance Authorization type. Available values are personal (default).
     """
 
     PERSONAL = "personal"
 
-class ComputeInstanceState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputeInstanceState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Current state of an ComputeInstance.
     """
 
     CREATING = "Creating"
     CREATE_FAILED = "CreateFailed"
     DELETING = "Deleting"
     RUNNING = "Running"
@@ -74,322 +73,322 @@
     STOPPED = "Stopped"
     STOPPING = "Stopping"
     USER_SETTING_UP = "UserSettingUp"
     USER_SETUP_FAILED = "UserSetupFailed"
     UNKNOWN = "Unknown"
     UNUSABLE = "Unusable"
 
-class ComputePowerAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputePowerAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The compute power action.
     """
 
     START = "Start"
     STOP = "Stop"
 
-class ComputeType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of compute
     """
 
     AKS = "AKS"
     KUBERNETES = "Kubernetes"
     AML_COMPUTE = "AmlCompute"
     COMPUTE_INSTANCE = "ComputeInstance"
     DATA_FACTORY = "DataFactory"
     VIRTUAL_MACHINE = "VirtualMachine"
     HD_INSIGHT = "HDInsight"
     DATABRICKS = "Databricks"
     DATA_LAKE_ANALYTICS = "DataLakeAnalytics"
     SYNAPSE_SPARK = "SynapseSpark"
 
-class ConnectionAuthType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ConnectionAuthType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Authentication type of the connection target
     """
 
     PAT = "PAT"
     MANAGED_IDENTITY = "ManagedIdentity"
     USERNAME_PASSWORD = "UsernamePassword"
     NONE = "None"
     SAS = "SAS"
     SERVICE_PRINCIPAL = "ServicePrincipal"
 
-class ConnectionCategory(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ConnectionCategory(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Category of the connection
     """
 
     PYTHON_FEED = "PythonFeed"
     CONTAINER_REGISTRY = "ContainerRegistry"
     GIT = "Git"
     FEATURE_STORE = "FeatureStore"
 
-class CreatedByType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class CreatedByType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of identity that created the resource.
     """
 
     USER = "User"
     APPLICATION = "Application"
     MANAGED_IDENTITY = "ManagedIdentity"
     KEY = "Key"
 
-class DaysOfWeek(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DaysOfWeek(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     SUNDAY = "Sunday"
     MONDAY = "Monday"
     TUESDAY = "Tuesday"
     WEDNESDAY = "Wednesday"
     THURSDAY = "Thursday"
     FRIDAY = "Friday"
     SATURDAY = "Saturday"
 
-class DiagnoseResultLevel(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DiagnoseResultLevel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Level of workspace setup error
     """
 
     WARNING = "Warning"
     ERROR = "Error"
     INFORMATION = "Information"
 
-class EncryptionStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EncryptionStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Indicates whether or not the encryption is enabled for the workspace.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class LoadBalancerType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class LoadBalancerType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Load Balancer Type
     """
 
     PUBLIC_IP = "PublicIp"
     INTERNAL_LOAD_BALANCER = "InternalLoadBalancer"
 
-class NodeState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class NodeState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of the compute node. Values are idle, running, preparing, unusable, leaving and
     preempted.
     """
 
     IDLE = "idle"
     RUNNING = "running"
     PREPARING = "preparing"
     UNUSABLE = "unusable"
     LEAVING = "leaving"
     PREEMPTED = "preempted"
 
-class OperationName(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OperationName(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Name of the last operation.
     """
 
     CREATE = "Create"
     START = "Start"
     STOP = "Stop"
     RESTART = "Restart"
     REIMAGE = "Reimage"
     DELETE = "Delete"
 
-class OperationStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OperationStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Operation status.
     """
 
     IN_PROGRESS = "InProgress"
     SUCCEEDED = "Succeeded"
     CREATE_FAILED = "CreateFailed"
     START_FAILED = "StartFailed"
     STOP_FAILED = "StopFailed"
     RESTART_FAILED = "RestartFailed"
     REIMAGE_FAILED = "ReimageFailed"
     DELETE_FAILED = "DeleteFailed"
 
-class OsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Compute OS Type
     """
 
     LINUX = "Linux"
     WINDOWS = "Windows"
 
-class PrivateEndpointConnectionProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class PrivateEndpointConnectionProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The current provisioning state.
     """
 
     SUCCEEDED = "Succeeded"
     CREATING = "Creating"
     DELETING = "Deleting"
     FAILED = "Failed"
 
-class PrivateEndpointServiceConnectionStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class PrivateEndpointServiceConnectionStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The private endpoint connection status.
     """
 
     PENDING = "Pending"
     APPROVED = "Approved"
     REJECTED = "Rejected"
     DISCONNECTED = "Disconnected"
     TIMEOUT = "Timeout"
 
-class ProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The current deployment state of workspace resource. The provisioningState is to indicate states
     for resource provisioning.
     """
 
     UNKNOWN = "Unknown"
     UPDATING = "Updating"
     CREATING = "Creating"
     DELETING = "Deleting"
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
     CANCELED = "Canceled"
 
-class ProvisioningStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ProvisioningStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The current deployment state of schedule.
     """
 
     COMPLETED = "Completed"
     PROVISIONING = "Provisioning"
     FAILED = "Failed"
 
-class PublicNetworkAccess(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class PublicNetworkAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Whether requests from Public Network are allowed.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class QuotaUnit(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class QuotaUnit(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """An enum describing the unit of quota measurement.
     """
 
     COUNT = "Count"
 
-class RecurrenceFrequency(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RecurrenceFrequency(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The recurrence frequency.
     """
 
     NOT_SPECIFIED = "NotSpecified"
     SECOND = "Second"
     MINUTE = "Minute"
     HOUR = "Hour"
     DAY = "Day"
     WEEK = "Week"
     MONTH = "Month"
     YEAR = "Year"
 
-class RemoteLoginPortPublicAccess(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RemoteLoginPortPublicAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh
     port is closed on all nodes of the cluster. Enabled - Indicates that the public ssh port is
     open on all nodes of the cluster. NotSpecified - Indicates that the public ssh port is closed
     on all nodes of the cluster if VNet is defined, else is open all public nodes. It can be
     default only during cluster creation time, after creation it will be either enabled or
     disabled.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
     NOT_SPECIFIED = "NotSpecified"
 
-class ResourceIdentityType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ResourceIdentityType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The identity type.
     """
 
     SYSTEM_ASSIGNED = "SystemAssigned"
     SYSTEM_ASSIGNED_USER_ASSIGNED = "SystemAssigned,UserAssigned"
     USER_ASSIGNED = "UserAssigned"
     NONE = "None"
 
-class ScheduleStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScheduleStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The schedule status.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class ScheduleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScheduleType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The schedule type.
     """
 
     COMPUTE_START_STOP = "ComputeStartStop"
 
-class SoftDeleteEnabled(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SoftDeleteEnabled(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """create a workspace with soft delete capability
     """
 
     TRUE = "True"
     FALSE = "False"
 
-class SshPublicAccess(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SshPublicAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh
     port is closed on this instance. Enabled - Indicates that the public ssh port is open and
     accessible according to the VNet/subnet policy if applicable.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class SslConfigurationStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SslConfigurationStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enable or disable ssl for scoring
     """
 
     DISABLED = "Disabled"
     ENABLED = "Enabled"
     AUTO = "Auto"
 
-class Status(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Status(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Status of update workspace quota.
     """
 
     UNDEFINED = "Undefined"
     SUCCESS = "Success"
     FAILURE = "Failure"
     INVALID_QUOTA_BELOW_CLUSTER_MINIMUM = "InvalidQuotaBelowClusterMinimum"
     INVALID_QUOTA_EXCEEDS_SUBSCRIPTION_LIMIT = "InvalidQuotaExceedsSubscriptionLimit"
     INVALID_VM_FAMILY_NAME = "InvalidVMFamilyName"
     OPERATION_NOT_SUPPORTED_FOR_SKU = "OperationNotSupportedForSku"
     OPERATION_NOT_ENABLED_FOR_REGION = "OperationNotEnabledForRegion"
 
-class TriggerType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class TriggerType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The schedule trigger type.
     """
 
     RECURRENCE = "Recurrence"
     CRON = "Cron"
 
-class UnderlyingResourceAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class UnderlyingResourceAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     DELETE = "Delete"
     DETACH = "Detach"
 
-class UnitOfMeasure(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class UnitOfMeasure(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The unit of time measurement for the specified VM price. Example: OneHour
     """
 
     ONE_HOUR = "OneHour"
 
-class UsageUnit(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class UsageUnit(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """An enum describing the unit of usage measurement.
     """
 
     COUNT = "Count"
 
-class ValueFormat(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ValueFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """format for the workspace connection value
     """
 
     JSON = "JSON"
 
-class VMPriceOSType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class VMPriceOSType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Operating system type used by the VM.
     """
 
     LINUX = "Linux"
     WINDOWS = "Windows"
 
-class VmPriority(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class VmPriority(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Virtual Machine priority
     """
 
     DEDICATED = "Dedicated"
     LOW_PRIORITY = "LowPriority"
 
-class VMTier(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class VMTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of the VM.
     """
 
     STANDARD = "Standard"
     LOW_PRIORITY = "LowPriority"
     SPOT = "Spot"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_models_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_models_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_extensive_model_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_extensive_model_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_migration_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_migration_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_assets_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/operations/_assets_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 25% similar despite different names*

```diff
@@ -3,19 +3,18 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class ComputeEnvironmentType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputeEnvironmentType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     ACS = "ACS"
     FPGA = "FPGA"
     ACI = "ACI"
     AKS = "AKS"
     AMLCOMPUTE = "AMLCOMPUTE"
     IOT = "IOT"
@@ -24,41 +23,41 @@
     MIRSINGLEMODEL = "MIRSINGLEMODEL"
     MIRAMLCOMPUTE = "MIRAMLCOMPUTE"
     MIRGA = "MIRGA"
     AMLARC = "AMLARC"
     BATCHAMLCOMPUTE = "BATCHAMLCOMPUTE"
     UNKNOWN = "UNKNOWN"
 
-class DeploymentType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DeploymentType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     GRPC_REALTIME_ENDPOINT = "GRPCRealtimeEndpoint"
     HTTP_REALTIME_ENDPOINT = "HttpRealtimeEndpoint"
     BATCH = "Batch"
 
-class EntityKind(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EntityKind(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     INVALID = "Invalid"
     LINEAGE_ROOT = "LineageRoot"
     VERSIONED = "Versioned"
     UNVERSIONED = "Unversioned"
 
-class ListViewType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ListViewType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     ACTIVE_ONLY = "ActiveOnly"
     ARCHIVED_ONLY = "ArchivedOnly"
     ALL = "All"
 
-class ModelFormatEnum(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ModelFormatEnum(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     CUSTOM = "CUSTOM"
     MLFLOW = "MLFLOW"
     TRITON = "TRITON"
     PRESETS = "PRESETS"
 
-class ModelSchemaDataType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ModelSchemaDataType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     UNDEFINED = "undefined"
     BOOL = "bool"
     UINT8 = "uint8"
     UINT16 = "uint16"
     UINT32 = "uint32"
     UINT64 = "uint64"
@@ -70,21 +69,21 @@
     FLOAT32 = "float32"
     FLOAT64 = "float64"
     BFLOAT16 = "bfloat16"
     COMPLEX64 = "complex64"
     COMPLEX128 = "complex128"
     STRING = "string"
 
-class OrderString(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OrderString(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     CREATED_AT_DESC = "CreatedAtDesc"
     CREATED_AT_ASC = "CreatedAtAsc"
     UPDATED_AT_DESC = "UpdatedAtDesc"
     UPDATED_AT_ASC = "UpdatedAtAsc"
 
-class WebServiceState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class WebServiceState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     TRANSITIONING = "Transitioning"
     HEALTHY = "Healthy"
     UNHEALTHY = "Unhealthy"
     FAILED = "Failed"
     UNSCHEDULABLE = "Unschedulable"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_models_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_models_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_extensive_model_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_extensive_model_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_migration_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_migration_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/model_dataplane/operations/_assets_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/operations/_assets_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_provisions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_provisions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featureset_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_settings_rule_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_managed_network_settings_rule_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_featurestore_entity_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 2% similar despite different names*

```diff
@@ -166,16 +166,14 @@
 
     #: Calculates the accuracy of the model predictions.
     ACCURACY = "Accuracy"
     #: Calculates the precision of the model predictions.
     PRECISION = "Precision"
     #: Calculates the recall of the model predictions.
     RECALL = "Recall"
-    #: Calculates the F1 score of the model predictions.
-    F1_SCORE = "F1Score"
 
 class ClassificationModels(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Enum for all classification models supported by AutoML.
     """
 
     #: Logistic regression is a fundamental classification technique.
     #: It belongs to the group of linear classifiers and is somewhat similar to polynomial and linear
@@ -342,31 +340,37 @@
     PAT = "PAT"
     MANAGED_IDENTITY = "ManagedIdentity"
     USERNAME_PASSWORD = "UsernamePassword"
     NONE = "None"
     SAS = "SAS"
     SERVICE_PRINCIPAL = "ServicePrincipal"
     ACCESS_KEY = "AccessKey"
+    API_KEY = "ApiKey"
+    CUSTOM_KEYS = "CustomKeys"
 
 class ConnectionCategory(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Category of the connection
     """
 
     PYTHON_FEED = "PythonFeed"
     CONTAINER_REGISTRY = "ContainerRegistry"
     GIT = "Git"
-    FEATURE_STORE = "FeatureStore"
     S3 = "S3"
     SNOWFLAKE = "Snowflake"
     AZURE_SQL_DB = "AzureSqlDb"
     AZURE_SYNAPSE_ANALYTICS = "AzureSynapseAnalytics"
     AZURE_MY_SQL_DB = "AzureMySqlDb"
     AZURE_POSTGRES_DB = "AzurePostgresDb"
-    AZURE_DATA_LAKE_GEN2 = "AzureDataLakeGen2"
+    ADLS_GEN2 = "ADLSGen2"
     REDIS = "Redis"
+    API_KEY = "ApiKey"
+    AZURE_OPEN_AI = "AzureOpenAI"
+    COGNITIVE_SEARCH = "CognitiveSearch"
+    COGNITIVE_SERVICE = "CognitiveService"
+    CUSTOM_KEYS = "CustomKeys"
 
 class ContainerType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """The type of container to retrieve logs from.
     """
 
     #: The container used to download models and score script.
     STORAGE_INITIALIZER = "StorageInitializer"
@@ -516,14 +520,15 @@
     """Connection status of the service consumer with the service provider
     """
 
     APPROVED = "Approved"
     PENDING = "Pending"
     REJECTED = "Rejected"
     DISCONNECTED = "Disconnected"
+    TIMEOUT = "Timeout"
 
 class EnvironmentType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Environment type is either user created or curated by Azure ML service
     """
 
     CURATED = "Curated"
     USER_CREATED = "UserCreated"
@@ -683,14 +688,36 @@
     #: The R2 score is one of the performance evaluation measures for forecasting-based machine
     #: learning models.
     R2_SCORE = "R2Score"
     #: The Normalized Mean Absolute Error (NMAE) is a validation metric to compare the Mean Absolute
     #: Error (MAE) of (time) series with different scales.
     NORMALIZED_MEAN_ABSOLUTE_ERROR = "NormalizedMeanAbsoluteError"
 
+class GenerationSafetyQualityMetric(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    """Generation safety quality metric enum.
+    """
+
+    ACCEPTABLE_GROUNDEDNESS_SCORE_PER_INSTANCE = "AcceptableGroundednessScorePerInstance"
+    AGGREGATED_GROUNDEDNESS_PASS_RATE = "AggregatedGroundednessPassRate"
+    ACCEPTABLE_COHERENCE_SCORE_PER_INSTANCE = "AcceptableCoherenceScorePerInstance"
+    AGGREGATED_COHERENCE_PASS_RATE = "AggregatedCoherencePassRate"
+    ACCEPTABLE_FLUENCY_SCORE_PER_INSTANCE = "AcceptableFluencyScorePerInstance"
+    AGGREGATED_FLUENCY_PASS_RATE = "AggregatedFluencyPassRate"
+    ACCEPTABLE_SIMILARITY_SCORE_PER_INSTANCE = "AcceptableSimilarityScorePerInstance"
+    AGGREGATED_SIMILARITY_PASS_RATE = "AggregatedSimilarityPassRate"
+    ACCEPTABLE_RELEVANCE_SCORE_PER_INSTANCE = "AcceptableRelevanceScorePerInstance"
+    AGGREGATED_RELEVANCE_PASS_RATE = "AggregatedRelevancePassRate"
+
+class GenerationTokenStatisticsMetric(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    """Generation token statistics metric enum.
+    """
+
+    TOTAL_TOKEN_COUNT = "TotalTokenCount"
+    TOTAL_TOKEN_COUNT_PER_GROUP = "TotalTokenCountPerGroup"
+
 class Goal(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Defines supported metric goals for hyperparameter tuning
     """
 
     MINIMIZE = "Minimize"
     MAXIMIZE = "Maximize"
 
@@ -846,14 +873,15 @@
     #: The job is in a scheduled state. Job is not in any active state.
     SCHEDULED = "Scheduled"
 
 class JobTier(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Enum to determine the job tier.
     """
 
+    NULL = "Null"
     SPOT = "Spot"
     BASIC = "Basic"
     STANDARD = "Standard"
     PREMIUM = "Premium"
 
 class JobType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Enum to determine the type of job.
@@ -987,14 +1015,38 @@
     #: Medium size.
     MEDIUM = "Medium"
     #: Large size.
     LARGE = "Large"
     #: Extra large size.
     EXTRA_LARGE = "ExtraLarge"
 
+class ModelTaskType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    """Model task type enum.
+    """
+
+    CLASSIFICATION = "Classification"
+    REGRESSION = "Regression"
+    QUESTION_ANSWERING = "QuestionAnswering"
+
+class MonitorComputeIdentityType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    """Monitor compute identity type enum.
+    """
+
+    #: Authenticates through user's AML token.
+    AML_TOKEN = "AmlToken"
+    #: Authenticates through a user-provided managed identity.
+    MANAGED_IDENTITY = "ManagedIdentity"
+
+class MonitorComputeType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    """Monitor compute type enum.
+    """
+
+    #: Serverless Spark compute.
+    SERVERLESS_SPARK = "ServerlessSpark"
+
 class MonitoringAlertNotificationType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
 
     #: Settings for Azure Monitor based alerting.
     AZURE_MONITOR = "AzureMonitor"
     #: Settings for AML email notifications.
     EMAIL = "Email"
 
@@ -1010,28 +1062,24 @@
     #: Includes all features.
     ALL_FEATURES = "AllFeatures"
     #: Only includes the top contributing features, measured by feature attribution.
     TOP_N_BY_ATTRIBUTION = "TopNByAttribution"
     #: Includes a user-defined subset of features.
     FEATURE_SUBSET = "FeatureSubset"
 
-class MonitoringInputDataContext(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class MonitoringInputDataType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    """Monitoring input data type enum.
+    """
 
-    #: A dataset containing the feature input to the model.
-    MODEL_INPUTS = "ModelInputs"
-    #: A dataset containing the inferred results of the model.
-    MODEL_OUTPUTS = "ModelOutputs"
-    #: A dataset containing the data used for training the model.
-    TRAINING = "Training"
-    #: A dataset leveraged to test the model.
-    TEST = "Test"
-    #: A dataset leveraged for model validation.
-    VALIDATION = "Validation"
-    #: A dataset containing the ground truth data.
-    GROUND_TRUTH = "GroundTruth"
+    #: An input data with a fixed window size.
+    STATIC = "Static"
+    #: An input data which trailing relatively to the monitor's current run.
+    TRAILING = "Trailing"
+    #: An input data with tabular format which doesn't require preprocessing.
+    FIXED = "Fixed"
 
 class MonitoringModelType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
 
     #: A model trained for classification tasks.
     CLASSIFICATION = "Classification"
     #: A model trained for regressions tasks.
     REGRESSION = "Regression"
@@ -1056,14 +1104,18 @@
     #: Tracks feature importance change in production, comparing against feature importance at
     #: training time.
     FEATURE_ATTRIBUTION_DRIFT = "FeatureAttributionDrift"
     #: Tracks a custom signal provided by users.
     CUSTOM = "Custom"
     #: Tracks model performance based on ground truth data.
     MODEL_PERFORMANCE = "ModelPerformance"
+    #: Tracks the safety and quality of generated content.
+    GENERATION_SAFETY_QUALITY = "GenerationSafetyQuality"
+    #: Tracks the token usage of generative endpoints.
+    GENERATION_TOKEN_STATISTICS = "GenerationTokenStatistics"
 
 class MountAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Mount Action.
     """
 
     MOUNT = "Mount"
     UNMOUNT = "Unmount"
@@ -1256,15 +1308,15 @@
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
 
 class PackageInputDeliveryMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Mounting type of the model or the inputs
     """
 
-    READ_ONLY_MOUNT = "ReadOnlyMount"
+    COPY = "Copy"
     DOWNLOAD = "Download"
 
 class PackageInputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Type of the inputs.
     """
 
     URI_FILE = "UriFile"
@@ -1288,24 +1340,14 @@
     """
 
     SUCCEEDED = "Succeeded"
     CREATING = "Creating"
     DELETING = "Deleting"
     FAILED = "Failed"
 
-class PrivateEndpointServiceConnectionStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """The private endpoint connection status.
-    """
-
-    PENDING = "Pending"
-    APPROVED = "Approved"
-    REJECTED = "Rejected"
-    DISCONNECTED = "Disconnected"
-    TIMEOUT = "Timeout"
-
 class ProtectionLevel(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Protection level associated with the Intellectual Property.
     """
 
     #: All means Intellectual Property is fully protected.
     ALL = "All"
     #: None means it is not an Intellectual Property.
@@ -1316,42 +1358,34 @@
     """
 
     TCP = "tcp"
     UDP = "udp"
     HTTP = "http"
 
 class ProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """The current deployment state of workspace resource. The provisioningState is to indicate states
-    for resource provisioning.
+    """The provision state of the cluster. Valid values are Unknown, Updating, Provisioning,
+    Succeeded, and Failed.
     """
 
     UNKNOWN = "Unknown"
     UPDATING = "Updating"
     CREATING = "Creating"
     DELETING = "Deleting"
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
     CANCELED = "Canceled"
-    SOFT_DELETED = "SoftDeleted"
 
 class ProvisioningStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """The current deployment state of schedule.
     """
 
     COMPLETED = "Completed"
     PROVISIONING = "Provisioning"
     FAILED = "Failed"
 
-class PublicNetworkAccess(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Whether requests from Public Network are allowed.
-    """
-
-    ENABLED = "Enabled"
-    DISABLED = "Disabled"
-
 class PublicNetworkAccessType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Enum to determine whether PublicNetworkAccess is Enabled or Disabled.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
@@ -1477,24 +1511,31 @@
 
     YEAR = "Year"
     MONTH = "Month"
     DAY = "Day"
     HOUR = "Hour"
     MINUTE = "Minute"
 
+class RuleAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    """The action enum for networking rule.
+    """
+
+    ALLOW = "Allow"
+    DENY = "Deny"
+
 class RuleCategory(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Category of a managed network Outbound Rule of a machine learning workspace.
     """
 
     REQUIRED = "Required"
     RECOMMENDED = "Recommended"
     USER_DEFINED = "UserDefined"
 
 class RuleStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Status of a managed network Outbound Rule of a machine learning workspace.
+    """Type of a managed network Outbound Rule of a machine learning workspace.
     """
 
     INACTIVE = "Inactive"
     ACTIVE = "Active"
 
 class RuleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Type of a managed network Outbound Rule of a machine learning workspace.
@@ -1838,20 +1879,14 @@
     #: Coco metric.
     COCO = "Coco"
     #: Voc metric.
     VOC = "Voc"
     #: CocoVoc metric.
     COCO_VOC = "CocoVoc"
 
-class ValueFormat(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """format for the workspace connection value
-    """
-
-    JSON = "JSON"
-
 class VMPriceOSType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
     """Operating system type used by the VM.
     """
 
     LINUX = "Linux"
     WINDOWS = "Windows"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_provisions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_provisions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featureset_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_settings_rule_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_managed_network_settings_rule_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_featurestore_entity_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_azure_machine_learning_workspaces.py`

 * *Files 9% similar despite different names*

```diff
@@ -5,32 +5,37 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from copy import deepcopy
 from typing import TYPE_CHECKING
 
-from msrest import Deserializer, Serializer
-
 from azure.mgmt.core import ARMPipelineClient
+from msrest import Deserializer, Serializer
 
 from . import models
 from ._configuration import AzureMachineLearningWorkspacesConfiguration
-from .operations import CodeContainersOperations, CodeVersionsOperations, ComponentContainersOperations, ComponentVersionsOperations, DataContainersOperations, DataReferencesOperations, DataVersionsOperations, EnvironmentContainersOperations, EnvironmentVersionsOperations, ModelContainersOperations, ModelVersionsOperations, ResourceManagementAssetReferenceOperations, TemporaryDataReferencesOperations
+from .operations import BatchDeploymentsOperations, BatchEndpointsOperations, CodeContainersOperations, CodeVersionsOperations, ComponentContainersOperations, ComponentVersionsOperations, DataContainersOperations, DataVersionsOperations, DatastoresOperations, EnvironmentContainersOperations, EnvironmentVersionsOperations, JobsOperations, ModelContainersOperations, ModelVersionsOperations, OnlineDeploymentsOperations, OnlineEndpointsOperations
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any
+    from typing import Any, Optional
 
     from azure.core.credentials import TokenCredential
     from azure.core.rest import HttpRequest, HttpResponse
 
-class AzureMachineLearningWorkspaces(object):    # pylint: disable=too-many-instance-attributes
+class AzureMachineLearningWorkspaces(object):
     """AzureMachineLearningWorkspaces.
 
+    :ivar batch_endpoints: BatchEndpointsOperations operations
+    :vartype batch_endpoints:
+     azure.mgmt.machinelearningservices.operations.BatchEndpointsOperations
+    :ivar batch_deployments: BatchDeploymentsOperations operations
+    :vartype batch_deployments:
+     azure.mgmt.machinelearningservices.operations.BatchDeploymentsOperations
     :ivar code_containers: CodeContainersOperations operations
     :vartype code_containers:
      azure.mgmt.machinelearningservices.operations.CodeContainersOperations
     :ivar code_versions: CodeVersionsOperations operations
     :vartype code_versions: azure.mgmt.machinelearningservices.operations.CodeVersionsOperations
     :ivar component_containers: ComponentContainersOperations operations
     :vartype component_containers:
@@ -39,44 +44,41 @@
     :vartype component_versions:
      azure.mgmt.machinelearningservices.operations.ComponentVersionsOperations
     :ivar data_containers: DataContainersOperations operations
     :vartype data_containers:
      azure.mgmt.machinelearningservices.operations.DataContainersOperations
     :ivar data_versions: DataVersionsOperations operations
     :vartype data_versions: azure.mgmt.machinelearningservices.operations.DataVersionsOperations
-    :ivar data_references: DataReferencesOperations operations
-    :vartype data_references:
-     azure.mgmt.machinelearningservices.operations.DataReferencesOperations
+    :ivar datastores: DatastoresOperations operations
+    :vartype datastores: azure.mgmt.machinelearningservices.operations.DatastoresOperations
     :ivar environment_containers: EnvironmentContainersOperations operations
     :vartype environment_containers:
      azure.mgmt.machinelearningservices.operations.EnvironmentContainersOperations
     :ivar environment_versions: EnvironmentVersionsOperations operations
     :vartype environment_versions:
      azure.mgmt.machinelearningservices.operations.EnvironmentVersionsOperations
-    :ivar resource_management_asset_reference: ResourceManagementAssetReferenceOperations
-     operations
-    :vartype resource_management_asset_reference:
-     azure.mgmt.machinelearningservices.operations.ResourceManagementAssetReferenceOperations
+    :ivar jobs: JobsOperations operations
+    :vartype jobs: azure.mgmt.machinelearningservices.operations.JobsOperations
     :ivar model_containers: ModelContainersOperations operations
     :vartype model_containers:
      azure.mgmt.machinelearningservices.operations.ModelContainersOperations
     :ivar model_versions: ModelVersionsOperations operations
     :vartype model_versions: azure.mgmt.machinelearningservices.operations.ModelVersionsOperations
-    :ivar temporary_data_references: TemporaryDataReferencesOperations operations
-    :vartype temporary_data_references:
-     azure.mgmt.machinelearningservices.operations.TemporaryDataReferencesOperations
+    :ivar online_endpoints: OnlineEndpointsOperations operations
+    :vartype online_endpoints:
+     azure.mgmt.machinelearningservices.operations.OnlineEndpointsOperations
+    :ivar online_deployments: OnlineDeploymentsOperations operations
+    :vartype online_deployments:
+     azure.mgmt.machinelearningservices.operations.OnlineDeploymentsOperations
     :param credential: Credential needed for the client to connect to Azure.
     :type credential: ~azure.core.credentials.TokenCredential
     :param subscription_id: The ID of the target subscription.
     :type subscription_id: str
     :param base_url: Service URL. Default value is 'https://management.azure.com'.
     :type base_url: str
-    :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
-     that overriding this default value may result in unsupported behavior.
-    :paramtype api_version: str
     :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
      Retry-After header is present.
     """
 
     def __init__(
         self,
         credential,  # type: "TokenCredential"
@@ -88,27 +90,30 @@
         self._config = AzureMachineLearningWorkspacesConfiguration(credential=credential, subscription_id=subscription_id, **kwargs)
         self._client = ARMPipelineClient(base_url=base_url, config=self._config, **kwargs)
 
         client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
         self._serialize = Serializer(client_models)
         self._deserialize = Deserializer(client_models)
         self._serialize.client_side_validation = False
+        self.batch_endpoints = BatchEndpointsOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.batch_deployments = BatchDeploymentsOperations(self._client, self._config, self._serialize, self._deserialize)
         self.code_containers = CodeContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.code_versions = CodeVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
         self.component_containers = ComponentContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.component_versions = ComponentVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
         self.data_containers = DataContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.data_versions = DataVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.data_references = DataReferencesOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.datastores = DatastoresOperations(self._client, self._config, self._serialize, self._deserialize)
         self.environment_containers = EnvironmentContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.environment_versions = EnvironmentVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.resource_management_asset_reference = ResourceManagementAssetReferenceOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.jobs = JobsOperations(self._client, self._config, self._serialize, self._deserialize)
         self.model_containers = ModelContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.model_versions = ModelVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.temporary_data_references = TemporaryDataReferencesOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.online_endpoints = OnlineEndpointsOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.online_deployments = OnlineDeploymentsOperations(self._client, self._config, self._serialize, self._deserialize)
 
 
     def _send_request(
         self,
         request,  # type: HttpRequest
         **kwargs  # type: Any
     ):
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_configuration.py`

 * *Files 0% similar despite different names*

```diff
@@ -27,28 +27,28 @@
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
     :param credential: Credential needed for the client to connect to Azure.
     :type credential: ~azure.core.credentials.TokenCredential
     :param subscription_id: The ID of the target subscription.
     :type subscription_id: str
-    :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+    :keyword api_version: Api Version. The default value is "2020-09-01-dataplanepreview". Note
      that overriding this default value may result in unsupported behavior.
     :paramtype api_version: str
     """
 
     def __init__(
         self,
         credential,  # type: "TokenCredential"
         subscription_id,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
         super(AzureMachineLearningWorkspacesConfiguration, self).__init__(**kwargs)
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop('api_version', "2020-09-01-dataplanepreview")  # type: str
 
         if credential is None:
             raise ValueError("Parameter 'credential' must not be None.")
         if subscription_id is None:
             raise ValueError("Parameter 'subscription_id' must not be None.")
 
         self.credential = credential
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py`

 * *Files 6% similar despite different names*

```diff
@@ -3,30 +3,44 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from copy import deepcopy
-from typing import Any, Awaitable, TYPE_CHECKING
-
-from msrest import Deserializer, Serializer
+from typing import Any, Awaitable, Optional, TYPE_CHECKING
 
 from azure.core.rest import AsyncHttpResponse, HttpRequest
 from azure.mgmt.core import AsyncARMPipelineClient
+from msrest import Deserializer, Serializer
 
 from .. import models
 from ._configuration import AzureMachineLearningWorkspacesConfiguration
-from .operations import CodeContainersOperations, CodeVersionsOperations, ComponentContainersOperations, ComponentVersionsOperations, DataContainersOperations, DataReferencesOperations, DataVersionsOperations, EnvironmentContainersOperations, EnvironmentVersionsOperations, ModelContainersOperations, ModelVersionsOperations, ResourceManagementAssetReferenceOperations, TemporaryDataReferencesOperations
+from .operations import (
+    CodeContainersOperations,
+    CodeVersionsOperations,
+    ComponentContainersOperations,
+    ComponentVersionsOperations,
+    DataContainersOperations,
+    DataReferencesOperations,
+    DataVersionsOperations,
+    EnvironmentContainersOperations,
+    EnvironmentVersionsOperations,
+    ModelContainersOperations,
+    ModelVersionsOperations,
+    ResourceManagementAssetReferenceOperations,
+    TemporaryDataReferencesOperations,
+)
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
     from azure.core.credentials_async import AsyncTokenCredential
 
-class AzureMachineLearningWorkspaces:    # pylint: disable=too-many-instance-attributes
+
+class AzureMachineLearningWorkspaces:
     """AzureMachineLearningWorkspaces.
 
     :ivar code_containers: CodeContainersOperations operations
     :vartype code_containers:
      azure.mgmt.machinelearningservices.aio.operations.CodeContainersOperations
     :ivar code_versions: CodeVersionsOperations operations
     :vartype code_versions:
@@ -81,41 +95,52 @@
     def __init__(
         self,
         credential: "AsyncTokenCredential",
         subscription_id: str,
         base_url: str = "https://management.azure.com",
         **kwargs: Any
     ) -> None:
-        self._config = AzureMachineLearningWorkspacesConfiguration(credential=credential, subscription_id=subscription_id, **kwargs)
+        self._config = AzureMachineLearningWorkspacesConfiguration(
+            credential=credential, subscription_id=subscription_id, **kwargs
+        )
         self._client = AsyncARMPipelineClient(base_url=base_url, config=self._config, **kwargs)
 
         client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
         self._serialize = Serializer(client_models)
         self._deserialize = Deserializer(client_models)
         self._serialize.client_side_validation = False
         self.code_containers = CodeContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.code_versions = CodeVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.component_containers = ComponentContainersOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.component_versions = ComponentVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.component_containers = ComponentContainersOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.component_versions = ComponentVersionsOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
         self.data_containers = DataContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.data_versions = DataVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
         self.data_references = DataReferencesOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.environment_containers = EnvironmentContainersOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.environment_versions = EnvironmentVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.resource_management_asset_reference = ResourceManagementAssetReferenceOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.model_containers = ModelContainersOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.environment_containers = EnvironmentContainersOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.environment_versions = EnvironmentVersionsOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.resource_management_asset_reference = ResourceManagementAssetReferenceOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.model_containers = ModelContainersOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
         self.model_versions = ModelVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.temporary_data_references = TemporaryDataReferencesOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.temporary_data_references = TemporaryDataReferencesOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
 
-
-    def _send_request(
-        self,
-        request: HttpRequest,
-        **kwargs: Any
-    ) -> Awaitable[AsyncHttpResponse]:
+    def _send_request(self, request: HttpRequest, **kwargs: Any) -> Awaitable[AsyncHttpResponse]:
         """Runs the network request through the client's chained policies.
 
         >>> from azure.core.rest import HttpRequest
         >>> request = HttpRequest("GET", "https://www.example.org/")
         <HttpRequest [GET], url: 'https://www.example.org/'>
         >>> response = await client._send_request(request)
         <AsyncHttpResponse: 200 OK>
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,27 +25,27 @@
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
     :param credential: Credential needed for the client to connect to Azure.
     :type credential: ~azure.core.credentials_async.AsyncTokenCredential
     :param subscription_id: The ID of the target subscription.
     :type subscription_id: str
-    :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
-     that overriding this default value may result in unsupported behavior.
+    :keyword api_version: Api Version. The default value is "2022-10-01-preview". Note that
+     overriding this default value may result in unsupported behavior.
     :paramtype api_version: str
     """
 
     def __init__(
         self,
         credential: "AsyncTokenCredential",
         subscription_id: str,
         **kwargs: Any
     ) -> None:
         super(AzureMachineLearningWorkspacesConfiguration, self).__init__(**kwargs)
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop('api_version', "2022-10-01-preview")  # type: str
 
         if credential is None:
             raise ValueError("Parameter 'credential' must not be None.")
         if subscription_id is None:
             raise ValueError("Parameter 'subscription_id' must not be None.")
 
         self.credential = credential
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_containers_operations.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,32 +1,46 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._data_containers_operations import build_create_or_update_request, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._data_containers_operations import (
+    build_create_or_update_request,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class DataContainersOperations:
     """DataContainersOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -62,45 +76,47 @@
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
         :param list_view_type:
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either DataContainerResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.DataContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
@@ -117,224 +133,189 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> None:
+    async def delete(self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any) -> None:
         """Delete container.
 
         Delete container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> "_models.DataContainerData":
         """Get container.
 
         Get container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: DataContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.DataContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('DataContainerData', pipeline_response)
+        deserialized = self._deserialize("DataContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def create_or_update(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        body: "_models.DataContainerData",
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, body: "_models.DataContainerData", **kwargs: Any
     ) -> "_models.DataContainerData":
         """Create or update container.
 
         Create or update container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.DataContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: DataContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.DataContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'DataContainerData')
+        _json = self._serialize.body(body, "DataContainerData")
 
         request = build_create_or_update_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('DataContainerData', pipeline_response)
+        deserialized = self._deserialize("DataContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_containers_operations.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,32 +1,46 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._code_containers_operations import build_create_or_update_request, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._code_containers_operations import (
+    build_create_or_update_request,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class CodeContainersOperations:
     """CodeContainersOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -43,60 +57,58 @@
         self._client = client
         self._serialize = serializer
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
-        self,
-        resource_group_name: str,
-        registry_name: str,
-        skiptoken: Optional[str] = None,
-        **kwargs: Any
+        self, resource_group_name: str, registry_name: str, skiptoken: Optional[str] = None, **kwargs: Any
     ) -> AsyncIterable["_models.CodeContainerResourceArmPaginatedResult"]:
         """List containers.
 
         List containers.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either CodeContainerResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.CodeContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     template_url=next_link,
@@ -112,224 +124,189 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> None:
+    async def delete(self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any) -> None:
         """Delete container.
 
         Delete container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> "_models.CodeContainerData":
         """Get container.
 
         Get container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: CodeContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('CodeContainerData', pipeline_response)
+        deserialized = self._deserialize("CodeContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def create_or_update(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        body: "_models.CodeContainerData",
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, body: "_models.CodeContainerData", **kwargs: Any
     ) -> "_models.CodeContainerData":
         """Create or update container.
 
         Create or update container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.CodeContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: CodeContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'CodeContainerData')
+        _json = self._serialize.body(body, "CodeContainerData")
 
         request = build_create_or_update_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('CodeContainerData', pipeline_response)
+        deserialized = self._deserialize("CodeContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_versions_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,48 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._environment_versions_operations import build_create_or_update_request_initial, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._environment_versions_operations import (
+    build_create_or_update_request_initial,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class EnvironmentVersionsOperations:
     """EnvironmentVersionsOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -76,49 +90,51 @@
         :type top: int
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
         :param stage:
         :type stage: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either EnvironmentVersionResourceArmPaginatedResult or
          the result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.EnvironmentVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
                     stage=stage,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
@@ -139,227 +155,195 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+    async def delete(
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> None:
         """Delete version.
 
         Delete version.
 
         :param name: Container name.
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> "_models.EnvironmentVersionData":
         """Get version.
 
         Get version.
 
         :param name: Container name. This is case-sensitive.
         :type name: str
         :param version: Version identifier. This is case-sensitive.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: EnvironmentVersionData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentVersionData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('EnvironmentVersionData', pipeline_response)
+        deserialized = self._deserialize("EnvironmentVersionData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
 
-
-    async def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    async def _create_or_update_initial(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
         body: "_models.EnvironmentVersionData",
         **kwargs: Any
     ) -> None:
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'EnvironmentVersionData')
+        _json = self._serialize.body(body, "EnvironmentVersionData")
 
         request = build_create_or_update_request_initial(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
-    async def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    async def begin_create_or_update(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
         body: "_models.EnvironmentVersionData",
         **kwargs: Any
@@ -374,60 +358,63 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Version entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of AsyncLROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.AsyncLROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
                 name=name,
                 version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-
-        if polling is True: polling_method = AsyncARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = AsyncNoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_resource_management_asset_reference_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_resource_management_asset_reference_operations.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,32 +1,41 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, Callable, Dict, Optional, TypeVar, Union
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+import functools
+from typing import Any, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
+
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
 from ...operations._resource_management_asset_reference_operations import build_import_method_request_initial
-T = TypeVar('T')
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class ResourceManagementAssetReferenceOperations:
     """ResourceManagementAssetReferenceOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -48,65 +57,57 @@
     async def _import_method_initial(
         self,
         resource_group_name: str,
         registry_name: str,
         body: "_models.ResourceManagementAssetReferenceData",
         **kwargs: Any
     ) -> Optional[Any]:
-        cls = kwargs.pop('cls', None)  # type: ClsType[Optional[Any]]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[Optional[Any]]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ResourceManagementAssetReferenceData')
+        _json = self._serialize.body(body, "ResourceManagementAssetReferenceData")
 
         request = build_import_method_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._import_method_initial.metadata['url'],
+            template_url=self._import_method_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         deserialized = None
         response_headers = {}
         if response.status_code == 200:
-            deserialized = self._deserialize('object', pipeline_response)
+            deserialized = self._deserialize("object", pipeline_response)
 
         if response.status_code == 202:
-            response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-            response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-            
+            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _import_method_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
-
+    _import_method_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
 
     @distributed_trace_async
     async def begin_import_method(
         self,
         resource_group_name: str,
         registry_name: str,
         body: "_models.ResourceManagementAssetReferenceData",
@@ -127,61 +128,64 @@
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Import request contains the source asset reference value and destination version
          value.
         :type body: ~azure.mgmt.machinelearningservices.models.ResourceManagementAssetReferenceData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of AsyncLROPoller that returns either any or the result of cls(response)
         :rtype: ~azure.core.polling.AsyncLROPoller[any]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[Any]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[Any]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._import_method_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             response = pipeline_response.http_response
-            deserialized = self._deserialize('object', pipeline_response)
+            deserialized = self._deserialize("object", pipeline_response)
             if cls:
                 return cls(pipeline_response, deserialized, {})
             return deserialized
 
-
-        if polling is True: polling_method = AsyncARMPolling(lro_delay, lro_options={'final-state-via': 'location'}, **kwargs)
-        elif polling is False: polling_method = AsyncNoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_import_method.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
+    begin_import_method.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_versions_operations.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,36 +1,50 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._component_versions_operations import build_create_or_update_request_initial, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._code_versions_operations import (
+    build_create_or_update_request_initial,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
-class ComponentVersionsOperations:
-    """ComponentVersionsOperations async operations.
+
+class CodeVersionsOperations:
+    """CodeVersionsOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -53,15 +67,15 @@
         name: str,
         resource_group_name: str,
         registry_name: str,
         order_by: Optional[str] = None,
         top: Optional[int] = None,
         skiptoken: Optional[str] = None,
         **kwargs: Any
-    ) -> AsyncIterable["_models.ComponentVersionResourceArmPaginatedResult"]:
+    ) -> AsyncIterable["_models.CodeVersionResourceArmPaginatedResult"]:
         """List versions.
 
         List versions.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
@@ -70,47 +84,49 @@
         :type registry_name: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either ComponentVersionResourceArmPaginatedResult or the
+        :return: An iterator like instance of either CodeVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
-         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.ComponentVersionResourceArmPaginatedResult]
+         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.CodeVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skiptoken=skiptoken,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
@@ -120,242 +136,210 @@
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         async def extract_data(pipeline_response):
-            deserialized = self._deserialize("ComponentVersionResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("CodeVersionResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+    async def delete(
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> None:
         """Delete version.
 
         Delete version.
 
         :param name: Container name.
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> "_models.ComponentVersionData":
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
+    ) -> "_models.CodeVersionData":
         """Get version.
 
         Get version.
 
         :param name: Container name.
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ComponentVersionData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentVersionData
+        :return: CodeVersionData, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersionData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersionData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ComponentVersionData', pipeline_response)
+        deserialized = self._deserialize("CodeVersionData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
 
-
-    async def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    async def _create_or_update_initial(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
-        body: "_models.ComponentVersionData",
+        body: "_models.CodeVersionData",
         **kwargs: Any
     ) -> None:
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ComponentVersionData')
+        _json = self._serialize.body(body, "CodeVersionData")
 
         request = build_create_or_update_request_initial(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
-    async def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    async def begin_create_or_update(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
-        body: "_models.ComponentVersionData",
+        body: "_models.CodeVersionData",
         **kwargs: Any
     ) -> AsyncLROPoller[None]:
         """Create or update version.
 
         Create or update version.
 
         :param name: Container name.
@@ -363,61 +347,64 @@
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ComponentVersionData
+        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersionData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of AsyncLROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.AsyncLROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
                 name=name,
                 version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-
-        if polling is True: polling_method = AsyncARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = AsyncNoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_environment_containers_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,46 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._environment_containers_operations import build_create_or_update_request, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._environment_containers_operations import (
+    build_create_or_update_request,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class EnvironmentContainersOperations:
     """EnvironmentContainersOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -62,45 +76,47 @@
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either EnvironmentContainerResourceArmPaginatedResult or
          the result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.EnvironmentContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
@@ -117,159 +133,133 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> None:
+    async def delete(self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any) -> None:
         """Delete container.
 
         Delete container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> "_models.EnvironmentContainerData":
         """Get container.
 
         Get container.
 
         :param name: Container name. This is case-sensitive.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: EnvironmentContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('EnvironmentContainerData', pipeline_response)
+        deserialized = self._deserialize("EnvironmentContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def create_or_update(
         self,
         name: str,
         resource_group_name: str,
         registry_name: str,
@@ -284,57 +274,53 @@
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: EnvironmentContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'EnvironmentContainerData')
+        _json = self._serialize.body(body, "EnvironmentContainerData")
 
         request = build_create_or_update_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('EnvironmentContainerData', pipeline_response)
+        deserialized = self._deserialize("EnvironmentContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_references_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_references_operations.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,30 +1,39 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, Callable, Dict, Optional, TypeVar
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+import functools
+from typing import Any, Callable, Dict, Generic, Optional, TypeVar
+import warnings
+
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 
 from ... import models as _models
 from ..._vendor import _convert_request
 from ...operations._data_references_operations import build_get_blob_reference_sas_request
-T = TypeVar('T')
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class DataReferencesOperations:
     """DataReferencesOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -61,58 +70,54 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body:
         :type body: ~azure.mgmt.machinelearningservices.models.BlobReferenceSASRequestDto
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: BlobReferenceSASResponseDto, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.BlobReferenceSASResponseDto
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.BlobReferenceSASResponseDto"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.BlobReferenceSASResponseDto"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'BlobReferenceSASRequestDto')
+        _json = self._serialize.body(body, "BlobReferenceSASRequestDto")
 
         request = build_get_blob_reference_sas_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.get_blob_reference_sas.metadata['url'],
+            template_url=self.get_blob_reference_sas.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('BlobReferenceSASResponseDto', pipeline_response)
+        deserialized = self._deserialize("BlobReferenceSASResponseDto", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get_blob_reference_sas.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/datarefs/{name}/versions/{version}"}  # type: ignore
-
+    get_blob_reference_sas.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/datarefs/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_containers_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,48 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._model_containers_operations import build_create_or_update_request_initial, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._model_containers_operations import (
+    build_create_or_update_request_initial,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class ModelContainersOperations:
     """ModelContainersOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -64,45 +78,47 @@
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either ModelContainerResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.ModelContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
@@ -119,292 +135,260 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> None:
+    async def delete(self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any) -> None:
         """Delete container.
 
         Delete container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> "_models.ModelContainerData":
         """Get container.
 
         Get container.
 
         :param name: Container name. This is case-sensitive.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: ModelContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.ModelContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ModelContainerData', pipeline_response)
+        deserialized = self._deserialize("ModelContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
 
     async def _create_or_update_initial(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        body: "_models.ModelContainerData",
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, body: "_models.ModelContainerData", **kwargs: Any
     ) -> "_models.ModelContainerData":
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ModelContainerData')
+        _json = self._serialize.body(body, "ModelContainerData")
 
         request = build_create_or_update_request_initial(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Azure-AsyncOperation']=self._deserialize('str', response.headers.get('Azure-AsyncOperation'))
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Azure-AsyncOperation"] = self._deserialize(
+            "str", response.headers.get("Azure-AsyncOperation")
+        )
 
-        deserialized = self._deserialize('ModelContainerData', pipeline_response)
+        deserialized = self._deserialize("ModelContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def begin_create_or_update(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        body: "_models.ModelContainerData",
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, body: "_models.ModelContainerData", **kwargs: Any
     ) -> AsyncLROPoller["_models.ModelContainerData"]:
         """Create or update model container.
 
         Create or update model container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.ModelContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of AsyncLROPoller that returns either ModelContainerData or the result of
          cls(response)
         :rtype:
          ~azure.core.polling.AsyncLROPoller[~azure.mgmt.machinelearningservices.models.ModelContainerData]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerData"]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelContainerData"]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
                 name=name,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             response_headers = {}
             response = pipeline_response.http_response
-            response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-            response_headers['Azure-AsyncOperation']=self._deserialize('str', response.headers.get('Azure-AsyncOperation'))
-            
-            deserialized = self._deserialize('ModelContainerData', pipeline_response)
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Azure-AsyncOperation"] = self._deserialize(
+                "str", response.headers.get("Azure-AsyncOperation")
+            )
+
+            deserialized = self._deserialize("ModelContainerData", pipeline_response)
             if cls:
                 return cls(pipeline_response, deserialized, response_headers)
             return deserialized
 
-
-        if polling is True: polling_method = AsyncARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = AsyncNoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_containers_operations.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,32 +1,46 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._component_containers_operations import build_create_or_update_request, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._component_containers_operations import (
+    build_create_or_update_request,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class ComponentContainersOperations:
     """ComponentContainersOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -43,60 +57,58 @@
         self._client = client
         self._serialize = serializer
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
-        self,
-        resource_group_name: str,
-        registry_name: str,
-        skiptoken: Optional[str] = None,
-        **kwargs: Any
+        self, resource_group_name: str, registry_name: str, skiptoken: Optional[str] = None, **kwargs: Any
     ) -> AsyncIterable["_models.ComponentContainerResourceArmPaginatedResult"]:
         """List containers.
 
         List containers.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either ComponentContainerResourceArmPaginatedResult or
          the result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.ComponentContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     template_url=next_link,
@@ -112,159 +124,133 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> None:
+    async def delete(self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any) -> None:
         """Delete container.
 
         Delete container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+        self, name: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> "_models.ComponentContainerData":
         """Get container.
 
         Get container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: ComponentContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ComponentContainerData', pipeline_response)
+        deserialized = self._deserialize("ComponentContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
 
     @distributed_trace_async
     async def create_or_update(
         self,
         name: str,
         resource_group_name: str,
         registry_name: str,
@@ -279,57 +265,53 @@
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.ComponentContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: ComponentContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ComponentContainerData')
+        _json = self._serialize.body(body, "ComponentContainerData")
 
         request = build_create_or_update_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ComponentContainerData', pipeline_response)
+        deserialized = self._deserialize("ComponentContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_temporary_data_references_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_temporary_data_references_operations.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,30 +1,39 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, Callable, Dict, Optional, TypeVar
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+import functools
+from typing import Any, Callable, Dict, Generic, Optional, TypeVar
+import warnings
+
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 
 from ... import models as _models
 from ..._vendor import _convert_request
 from ...operations._temporary_data_references_operations import build_create_or_get_temporary_data_reference_request
-T = TypeVar('T')
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class TemporaryDataReferencesOperations:
     """TemporaryDataReferencesOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -61,58 +70,54 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body:
         :type body: ~azure.mgmt.machinelearningservices.models.TemporaryDataReferenceRequestDto
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: TemporaryDataReferenceResponseDto, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.TemporaryDataReferenceResponseDto
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.TemporaryDataReferenceResponseDto"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.TemporaryDataReferenceResponseDto"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'TemporaryDataReferenceRequestDto')
+        _json = self._serialize.body(body, "TemporaryDataReferenceRequestDto")
 
         request = build_create_or_get_temporary_data_reference_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_get_temporary_data_reference.metadata['url'],
+            template_url=self.create_or_get_temporary_data_reference.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('TemporaryDataReferenceResponseDto', pipeline_response)
+        deserialized = self._deserialize("TemporaryDataReferenceResponseDto", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_get_temporary_data_reference.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/tempdatarefs/{name}/versions/{version}"}  # type: ignore
-
+    create_or_get_temporary_data_reference.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/tempdatarefs/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_data_versions_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,48 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._data_versions_operations import build_create_or_update_request_initial, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._data_versions_operations import (
+    build_create_or_update_request_initial,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class DataVersionsOperations:
     """DataVersionsOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
@@ -80,49 +94,51 @@
         :type skiptoken: str
         :param tags: Comma-separated list of tag names (and optionally values). Example:
          tag1,tag2=value2.
         :type tags: str
         :param list_view_type: [ListViewType.ActiveOnly, ListViewType.ArchivedOnly,
          ListViewType.All]View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either DataVersionBaseResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.DataVersionBaseResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataVersionBaseResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skiptoken=skiptoken,
                     tags=tags,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
@@ -143,227 +159,195 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+    async def delete(
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> None:
         """Delete version.
 
         Delete version.
 
         :param name: Container name.
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> "_models.DataVersionBaseData":
         """Get version.
 
         Get version.
 
         :param name: Container name.
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: DataVersionBaseData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataVersionBaseData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
+        deserialized = self._deserialize("DataVersionBaseData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
 
-
-    async def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    async def _create_or_update_initial(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
         body: "_models.DataVersionBaseData",
         **kwargs: Any
     ) -> None:
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'DataVersionBaseData')
+        _json = self._serialize.body(body, "DataVersionBaseData")
 
         request = build_create_or_update_request_initial(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
-    async def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    async def begin_create_or_update(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
         body: "_models.DataVersionBaseData",
         **kwargs: Any
@@ -378,60 +362,63 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Version entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of AsyncLROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.AsyncLROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
                 name=name,
                 version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-
-        if polling is True: polling_method = AsyncARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = AsyncNoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_component_versions_operations.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,36 +1,50 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
+import functools
+from typing import Any, AsyncIterable, Callable, Dict, Generic, Optional, TypeVar, Union
+import warnings
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._code_versions_operations import build_create_or_update_request_initial, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._component_versions_operations import (
+    build_create_or_update_request_initial,
+    build_delete_request,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
-class CodeVersionsOperations:
-    """CodeVersionsOperations async operations.
+
+class ComponentVersionsOperations:
+    """ComponentVersionsOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -53,15 +67,15 @@
         name: str,
         resource_group_name: str,
         registry_name: str,
         order_by: Optional[str] = None,
         top: Optional[int] = None,
         skiptoken: Optional[str] = None,
         **kwargs: Any
-    ) -> AsyncIterable["_models.CodeVersionResourceArmPaginatedResult"]:
+    ) -> AsyncIterable["_models.ComponentVersionResourceArmPaginatedResult"]:
         """List versions.
 
         List versions.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
@@ -70,47 +84,49 @@
         :type registry_name: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either CodeVersionResourceArmPaginatedResult or the
+        :return: An iterator like instance of either ComponentVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
-         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.CodeVersionResourceArmPaginatedResult]
+         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.ComponentVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skiptoken=skiptoken,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
@@ -120,242 +136,210 @@
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         async def extract_data(pipeline_response):
-            deserialized = self._deserialize("CodeVersionResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("ComponentVersionResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions"}  # type: ignore
 
     @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+    async def delete(
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
     ) -> None:
         """Delete version.
 
         Delete version.
 
         :param name: Container name.
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> "_models.CodeVersionData":
+        self, name: str, version: str, resource_group_name: str, registry_name: str, **kwargs: Any
+    ) -> "_models.ComponentVersionData":
         """Get version.
 
         Get version.
 
         :param name: Container name.
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: CodeVersionData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersionData
+        :return: ComponentVersionData, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentVersionData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentVersionData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('CodeVersionData', pipeline_response)
+        deserialized = self._deserialize("ComponentVersionData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
 
-
-    async def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    async def _create_or_update_initial(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
-        body: "_models.CodeVersionData",
+        body: "_models.ComponentVersionData",
         **kwargs: Any
     ) -> None:
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'CodeVersionData')
+        _json = self._serialize.body(body, "ComponentVersionData")
 
         request = build_create_or_update_request_initial(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
-    async def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    async def begin_create_or_update(
         self,
         name: str,
         version: str,
         resource_group_name: str,
         registry_name: str,
-        body: "_models.CodeVersionData",
+        body: "_models.ComponentVersionData",
         **kwargs: Any
     ) -> AsyncLROPoller[None]:
         """Create or update version.
 
         Create or update version.
 
         :param name: Container name.
@@ -363,61 +347,64 @@
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersionData
+        :type body: ~azure.mgmt.machinelearningservices.models.ComponentVersionData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of AsyncLROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.AsyncLROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
                 name=name,
                 version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-
-        if polling is True: polling_method = AsyncARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = AsyncNoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_versions_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,32 +5,45 @@
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._model_versions_operations import build_create_or_update_request_initial, build_delete_request, build_get_request, build_list_request
-T = TypeVar('T')
+from ...operations._registry_model_versions_operations import (
+    build_create_or_update_request_initial,
+    build_delete_request_initial,
+    build_get_request,
+    build_list_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
-class ModelVersionsOperations:
-    """ModelVersionsOperations async operations.
+
+class RegistryModelVersionsOperations:
+    """RegistryModelVersionsOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -46,39 +59,39 @@
         self._serialize = serializer
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
         self,
-        name: str,
         resource_group_name: str,
         registry_name: str,
-        skiptoken: Optional[str] = None,
+        model_name: str,
+        skip: Optional[str] = None,
         order_by: Optional[str] = None,
         top: Optional[int] = None,
         version: Optional[str] = None,
         description: Optional[str] = None,
         tags: Optional[str] = None,
         properties: Optional[str] = None,
         list_view_type: Optional[Union[str, "_models.ListViewType"]] = None,
         **kwargs: Any
     ) -> AsyncIterable["_models.ModelVersionResourceArmPaginatedResult"]:
         """List versions.
 
         List versions.
 
-        :param name: Container name. This is case-sensitive.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param skiptoken: Continuation token for pagination.
-        :type skiptoken: str
+        :param model_name: Container name. This is case-sensitive.
+        :type model_name: str
+        :param skip: Continuation token for pagination.
+        :type skip: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
         :param version: Version identifier.
         :type version: str
         :param description: Model description.
@@ -94,52 +107,51 @@
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either ModelVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.ModelVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
-                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
+                    model_name=model_name,
                     api_version=api_version,
-                    skiptoken=skiptoken,
+                    skip=skip,
                     order_by=order_by,
                     top=top,
                     version=version,
                     description=description,
                     tags=tags,
                     properties=properties,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
-                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
+                    model_name=model_name,
                     api_version=api_version,
-                    skiptoken=skiptoken,
+                    skip=skip,
                     order_by=order_by,
                     top=top,
                     version=version,
                     description=description,
                     tags=tags,
                     properties=properties,
                     list_view_type=list_view_type,
@@ -157,294 +169,332 @@
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
+                request, stream=False, **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return AsyncItemPaged(get_next, extract_data)
 
-        return AsyncItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions"}  # type: ignore
 
-    @distributed_trace_async
-    async def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
+    async def _delete_initial(  # pylint: disable=inconsistent-return-statements
+        self, resource_group_name: str, registry_name: str, model_name: str, version: str, **kwargs: Any
     ) -> None:
-        """Delete version.
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        Delete version.
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        :param name: Container name.
-        :type name: str
-        :param version: Version identifier.
-        :type version: str
-        :param resource_group_name: The name of the resource group. The name is case insensitive.
-        :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
-        :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
-        """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
-        
-        request = build_delete_request(
-            name=name,
-            version=version,
+        request = build_delete_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            model_name=model_name,
+            version=version,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self._delete_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 204]:
+        if response.status_code not in [200, 202, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
-            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
+            raise HttpResponseError(response=response, error_format=ARMErrorFormat)
+
+        response_headers = {}
+        if response.status_code == 202:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
-            return cls(pipeline_response, None, {})
+            return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
+    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
+    @distributed_trace_async
+    async def begin_delete(  # pylint: disable=inconsistent-return-statements
+        self, resource_group_name: str, registry_name: str, model_name: str, version: str, **kwargs: Any
+    ) -> AsyncLROPoller[None]:
+        """Delete version.
+
+        Delete version.
+
+        :param resource_group_name: The name of the resource group. The name is case insensitive.
+        :type resource_group_name: str
+        :param registry_name: Name of Azure Machine Learning registry.
+        :type registry_name: str
+        :param model_name: Container name.
+        :type model_name: str
+        :param version: Version identifier.
+        :type version: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
+        :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
+         this operation to not poll, or pass in your own initialized polling object for a personal
+         polling strategy.
+        :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
+        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
+         Retry-After header is present.
+        :return: An instance of AsyncLROPoller that returns either None or the result of cls(response)
+        :rtype: ~azure.core.polling.AsyncLROPoller[None]
+        :raises: ~azure.core.exceptions.HttpResponseError
+        """
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        polling = kwargs.pop("polling", True)  # type: Union[bool, AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        if cont_token is None:
+            raw_result = await self._delete_initial(
+                resource_group_name=resource_group_name,
+                registry_name=registry_name,
+                model_name=model_name,
+                version=version,
+                api_version=api_version,
+                cls=lambda x, y, z: x,
+                **kwargs
+            )
+        kwargs.pop("error_map", None)
+
+        def get_long_running_output(pipeline_response):
+            if cls:
+                return cls(pipeline_response, None, {})
+
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
+        if cont_token:
+            return AsyncLROPoller.from_continuation_token(
+                polling_method=polling_method,
+                continuation_token=cont_token,
+                client=self._client,
+                deserialization_callback=get_long_running_output,
+            )
+        return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
+
+    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self,
-        name: str,
-        version: str,
-        resource_group_name: str,
-        registry_name: str,
-        **kwargs: Any
-    ) -> "_models.ModelVersionData":
+        self, resource_group_name: str, registry_name: str, model_name: str, version: str, **kwargs: Any
+    ) -> "_models.ModelVersion":
         """Get version.
 
         Get version.
 
-        :param name: Container name. This is case-sensitive.
-        :type name: str
-        :param version: Version identifier. This is case-sensitive.
-        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param model_name: Container name. This is case-sensitive.
+        :type model_name: str
+        :param version: Version identifier. This is case-sensitive.
+        :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ModelVersionData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ModelVersionData
+        :return: ModelVersion, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ModelVersion
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        
         request = build_get_request(
-            name=name,
-            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            model_name=model_name,
+            version=version,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ModelVersionData', pipeline_response)
+        deserialized = self._deserialize("ModelVersion", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
-    async def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    async def _create_or_update_initial(
         self,
-        name: str,
-        version: str,
         resource_group_name: str,
         registry_name: str,
-        body: "_models.ModelVersionData",
+        model_name: str,
+        version: str,
+        body: "_models.ModelVersion",
         **kwargs: Any
-    ) -> None:
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+    ) -> "_models.ModelVersion":
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ModelVersionData')
+        _json = self._serialize.body(body, "ModelVersion")
 
         request = build_create_or_update_request_initial(
-            name=name,
-            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            model_name=model_name,
+            version=version,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
+        if response.status_code == 200:
+            deserialized = self._deserialize("ModelVersion", pipeline_response)
 
+        if response.status_code == 201:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Azure-AsyncOperation"] = self._deserialize(
+                "str", response.headers.get("Azure-AsyncOperation")
+            )
+
+            deserialized = self._deserialize("ModelVersion", pipeline_response)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
+        return deserialized
 
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
-    async def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    async def begin_create_or_update(
         self,
-        name: str,
-        version: str,
         resource_group_name: str,
         registry_name: str,
-        body: "_models.ModelVersionData",
+        model_name: str,
+        version: str,
+        body: "_models.ModelVersion",
         **kwargs: Any
-    ) -> AsyncLROPoller[None]:
+    ) -> AsyncLROPoller["_models.ModelVersion"]:
         """Create or update version.
 
         Create or update version.
 
-        :param name: Container name.
-        :type name: str
-        :param version: Version identifier.
-        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param model_name: Container name.
+        :type model_name: str
+        :param version: Version identifier.
+        :type version: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ModelVersionData
+        :type body: ~azure.mgmt.machinelearningservices.models.ModelVersion
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of AsyncLROPoller that returns either None or the result of cls(response)
-        :rtype: ~azure.core.polling.AsyncLROPoller[None]
+        :return: An instance of AsyncLROPoller that returns either ModelVersion or the result of
+         cls(response)
+        :rtype:
+         ~azure.core.polling.AsyncLROPoller[~azure.mgmt.machinelearningservices.models.ModelVersion]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, AsyncPollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
-                name=name,
-                version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
+                model_name=model_name,
+                version=version,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
+            response = pipeline_response.http_response
+            deserialized = self._deserialize("ModelVersion", pipeline_response)
             if cls:
-                return cls(pipeline_response, None, {})
-
+                return cls(pipeline_response, deserialized, {})
+            return deserialized
 
-        if polling is True: polling_method = AsyncARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = AsyncNoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = AsyncARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
+        elif polling is False:
+            polling_method = AsyncNoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
         return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models.py`

 * *Files 18% similar despite different names*

```diff
@@ -21,31 +21,33 @@
     :ivar credentials_type: Required. Credential type used to authentication with storage.Constant
      filled by server. Possible values include: "AccountKey", "Certificate", "None", "Sas",
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     """
 
     _validation = {
-        'credentials_type': {'required': True},
+        "credentials_type": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
     }
 
     _subtype_map = {
-        'credentials_type': {'AccountKey': 'AccountKeyDatastoreCredentials', 'Certificate': 'CertificateDatastoreCredentials', 'None': 'NoneDatastoreCredentials', 'Sas': 'SasDatastoreCredentials', 'ServicePrincipal': 'ServicePrincipalDatastoreCredentials'}
+        "credentials_type": {
+            "AccountKey": "AccountKeyDatastoreCredentials",
+            "Certificate": "CertificateDatastoreCredentials",
+            "None": "NoneDatastoreCredentials",
+            "Sas": "SasDatastoreCredentials",
+            "ServicePrincipal": "ServicePrincipalDatastoreCredentials",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(DatastoreCredentials, self).__init__(**kwargs)
         self.credentials_type = None  # type: Optional[str]
 
 
 class AccountKeyDatastoreCredentials(DatastoreCredentials):
     """Account key datastore credentials configuration.
 
@@ -56,34 +58,31 @@
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     :ivar secrets: Required. Storage account secrets.
     :vartype secrets: ~azure.mgmt.machinelearningservices.models.AccountKeyDatastoreSecrets
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'secrets': {'required': True},
+        "credentials_type": {"required": True},
+        "secrets": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'AccountKeyDatastoreSecrets'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "secrets": {"key": "secrets", "type": "AccountKeyDatastoreSecrets"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword secrets: Required. Storage account secrets.
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.AccountKeyDatastoreSecrets
         """
         super(AccountKeyDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'AccountKey'  # type: str
-        self.secrets = kwargs['secrets']
+        self.credentials_type = "AccountKey"  # type: str
+        self.secrets = kwargs["secrets"]
 
 
 class DatastoreSecrets(msrest.serialization.Model):
     """Base definition for datastore secrets.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: AccountKeyDatastoreSecrets, CertificateDatastoreSecrets, SasDatastoreSecrets, ServicePrincipalDatastoreSecrets.
@@ -93,31 +92,32 @@
     :ivar secrets_type: Required. Credential type used to authentication with storage.Constant
      filled by server. Possible values include: "AccountKey", "Certificate", "Sas",
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
     }
 
     _subtype_map = {
-        'secrets_type': {'AccountKey': 'AccountKeyDatastoreSecrets', 'Certificate': 'CertificateDatastoreSecrets', 'Sas': 'SasDatastoreSecrets', 'ServicePrincipal': 'ServicePrincipalDatastoreSecrets'}
+        "secrets_type": {
+            "AccountKey": "AccountKeyDatastoreSecrets",
+            "Certificate": "CertificateDatastoreSecrets",
+            "Sas": "SasDatastoreSecrets",
+            "ServicePrincipal": "ServicePrincipalDatastoreSecrets",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(DatastoreSecrets, self).__init__(**kwargs)
         self.secrets_type = None  # type: Optional[str]
 
 
 class AccountKeyDatastoreSecrets(DatastoreSecrets):
     """Datastore account key secrets.
 
@@ -128,33 +128,30 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar key: Storage account key.
     :vartype key: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'key': {'key': 'key', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "key": {"key": "key", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword key: Storage account key.
         :paramtype key: str
         """
         super(AccountKeyDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'AccountKey'  # type: str
-        self.key = kwargs.get('key', None)
+        self.secrets_type = "AccountKey"  # type: str
+        self.key = kwargs.get("key", None)
 
 
 class AcrDetail(msrest.serialization.Model):
     """AcrDetail.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -169,49 +166,46 @@
     :ivar resource_group_name:
     :vartype resource_group_name: str
     :ivar subscription_id:
     :vartype subscription_id: str
     """
 
     _validation = {
-        'arm_scope': {'readonly': True},
+        "arm_scope": {"readonly": True},
     }
 
     _attribute_map = {
-        'acr_address': {'key': 'acrAddress', 'type': 'str'},
-        'acr_name': {'key': 'acrName', 'type': 'str'},
-        'acr_region': {'key': 'acrRegion', 'type': 'str'},
-        'arm_scope': {'key': 'armScope', 'type': 'str'},
-        'resource_group_name': {'key': 'resourceGroupName', 'type': 'str'},
-        'subscription_id': {'key': 'subscriptionId', 'type': 'str'},
+        "acr_address": {"key": "acrAddress", "type": "str"},
+        "acr_name": {"key": "acrName", "type": "str"},
+        "acr_region": {"key": "acrRegion", "type": "str"},
+        "arm_scope": {"key": "armScope", "type": "str"},
+        "resource_group_name": {"key": "resourceGroupName", "type": "str"},
+        "subscription_id": {"key": "subscriptionId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword acr_address:
         :paramtype acr_address: str
         :keyword acr_name:
         :paramtype acr_name: str
         :keyword acr_region:
         :paramtype acr_region: str
         :keyword resource_group_name:
         :paramtype resource_group_name: str
         :keyword subscription_id:
         :paramtype subscription_id: str
         """
         super(AcrDetail, self).__init__(**kwargs)
-        self.acr_address = kwargs.get('acr_address', None)
-        self.acr_name = kwargs.get('acr_name', None)
-        self.acr_region = kwargs.get('acr_region', None)
+        self.acr_address = kwargs.get("acr_address", None)
+        self.acr_name = kwargs.get("acr_name", None)
+        self.acr_region = kwargs.get("acr_region", None)
         self.arm_scope = None
-        self.resource_group_name = kwargs.get('resource_group_name', None)
-        self.subscription_id = kwargs.get('subscription_id', None)
+        self.resource_group_name = kwargs.get("resource_group_name", None)
+        self.subscription_id = kwargs.get("subscription_id", None)
 
 
 class IdentityConfiguration(msrest.serialization.Model):
     """Base definition for identity configuration.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: AmlToken, ManagedIdentity.
@@ -221,31 +215,25 @@
     :ivar identity_type: Required. Specifies the type of identity framework.Constant filled by
      server. Possible values include: "Managed", "AMLToken".
     :vartype identity_type: str or
      ~azure.mgmt.machinelearningservices.models.IdentityConfigurationType
     """
 
     _validation = {
-        'identity_type': {'required': True},
+        "identity_type": {"required": True},
     }
 
     _attribute_map = {
-        'identity_type': {'key': 'identityType', 'type': 'str'},
+        "identity_type": {"key": "identityType", "type": "str"},
     }
 
-    _subtype_map = {
-        'identity_type': {'AMLToken': 'AmlToken', 'Managed': 'ManagedIdentity'}
-    }
+    _subtype_map = {"identity_type": {"AMLToken": "AmlToken", "Managed": "ManagedIdentity"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(IdentityConfiguration, self).__init__(**kwargs)
         self.identity_type = None  # type: Optional[str]
 
 
 class AmlToken(IdentityConfiguration):
     """AML Token identity configuration.
 
@@ -254,129 +242,57 @@
     :ivar identity_type: Required. Specifies the type of identity framework.Constant filled by
      server. Possible values include: "Managed", "AMLToken".
     :vartype identity_type: str or
      ~azure.mgmt.machinelearningservices.models.IdentityConfigurationType
     """
 
     _validation = {
-        'identity_type': {'required': True},
+        "identity_type": {"required": True},
     }
 
     _attribute_map = {
-        'identity_type': {'key': 'identityType', 'type': 'str'},
+        "identity_type": {"key": "identityType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(AmlToken, self).__init__(**kwargs)
-        self.identity_type = 'AMLToken'  # type: str
-
-
-class DataReferenceCredentialDto(msrest.serialization.Model):
-    """DataReferenceCredentialDto.
-
-    You probably want to use the sub-classes and not this class directly. Known
-    sub-classes are: DockerCredentialDto, ManagedIdentityCredentialDto, AnonymousAccessCredentialDto, SASCredentialDto.
-
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
-    """
-
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
-    _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-    }
-
-    _subtype_map = {
-        'credential_type': {'DockerCredentials': 'DockerCredentialDto', 'ManagedIdentity': 'ManagedIdentityCredentialDto', 'NoCredentials': 'AnonymousAccessCredentialDto', 'SAS': 'SASCredentialDto'}
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
-        super(DataReferenceCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'DataReferenceCredentialDto'  # type: str
-
-
-class AnonymousAccessCredentialDto(DataReferenceCredentialDto):
-    """AnonymousAccessCredentialDto.
-
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
-    """
-
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
-    _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
-        super(AnonymousAccessCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'NoCredentials'  # type: str
+        self.identity_type = "AMLToken"  # type: str
 
 
 class ResourceBase(msrest.serialization.Model):
     """ResourceBase.
 
     :ivar description: The asset description text.
     :vartype description: str
     :ivar properties: The asset property dictionary.
     :vartype properties: dict[str, str]
     :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
     :vartype tags: dict[str, str]
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         """
         super(ResourceBase, self).__init__(**kwargs)
-        self.description = kwargs.get('description', None)
-        self.properties = kwargs.get('properties', None)
-        self.tags = kwargs.get('tags', None)
+        self.description = kwargs.get("description", None)
+        self.properties = kwargs.get("properties", None)
+        self.tags = kwargs.get("tags", None)
 
 
 class AssetBase(ResourceBase):
     """AssetBase.
 
     :ivar description: The asset description text.
     :vartype description: str
@@ -387,40 +303,37 @@
     :ivar is_anonymous: If the name version are system generated (anonymous registration).
     :vartype is_anonymous: bool
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_anonymous: If the name version are system generated (anonymous registration).
         :paramtype is_anonymous: bool
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         """
         super(AssetBase, self).__init__(**kwargs)
-        self.is_anonymous = kwargs.get('is_anonymous', False)
-        self.is_archived = kwargs.get('is_archived', False)
+        self.is_anonymous = kwargs.get("is_anonymous", False)
+        self.is_archived = kwargs.get("is_archived", False)
 
 
 class AssetContainer(ResourceBase):
     """AssetContainer.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -435,43 +348,40 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         """
         super(AssetContainer, self).__init__(**kwargs)
-        self.is_archived = kwargs.get('is_archived', False)
+        self.is_archived = kwargs.get("is_archived", False)
         self.latest_version = None
         self.next_version = None
 
 
 class AssetReferenceBase(msrest.serialization.Model):
     """Base definition for asset references.
 
@@ -482,31 +392,31 @@
 
     :ivar reference_type: Required. Specifies the type of asset reference.Constant filled by
      server. Possible values include: "Id", "DataPath", "OutputPath".
     :vartype reference_type: str or ~azure.mgmt.machinelearningservices.models.ReferenceType
     """
 
     _validation = {
-        'reference_type': {'required': True},
+        "reference_type": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
     }
 
     _subtype_map = {
-        'reference_type': {'DataPath': 'DataPathAssetReference', 'Id': 'IdAssetReference', 'OutputPath': 'OutputPathAssetReference'}
+        "reference_type": {
+            "DataPath": "DataPathAssetReference",
+            "Id": "IdAssetReference",
+            "OutputPath": "OutputPathAssetReference",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(AssetReferenceBase, self).__init__(**kwargs)
         self.reference_type = None  # type: Optional[str]
 
 
 class Datastore(ResourceBase):
     """Base definition for datastore contents configuration.
 
@@ -530,49 +440,51 @@
     :vartype datastore_type: str or ~azure.mgmt.machinelearningservices.models.DatastoreType
     :ivar is_default: Readonly property to indicate if datastore is the workspace default
      datastore.
     :vartype is_default: bool
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
     }
 
     _subtype_map = {
-        'datastore_type': {'AzureBlob': 'AzureBlobDatastore', 'AzureDataLakeGen1': 'AzureDataLakeGen1Datastore', 'AzureDataLakeGen2': 'AzureDataLakeGen2Datastore', 'AzureFile': 'AzureFileDatastore'}
+        "datastore_type": {
+            "AzureBlob": "AzureBlobDatastore",
+            "AzureDataLakeGen1": "AzureDataLakeGen1Datastore",
+            "AzureDataLakeGen2": "AzureDataLakeGen2Datastore",
+            "AzureFile": "AzureFileDatastore",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword credentials: Required. Account credentials.
         :paramtype credentials: ~azure.mgmt.machinelearningservices.models.DatastoreCredentials
         """
         super(Datastore, self).__init__(**kwargs)
-        self.credentials = kwargs['credentials']
-        self.datastore_type = 'Datastore'  # type: str
+        self.credentials = kwargs["credentials"]
+        self.datastore_type = "Datastore"  # type: str
         self.is_default = None
 
 
 class AzureBlobDatastore(Datastore):
     """Azure Blob datastore configuration.
 
     Variables are only populated by the server, and will be ignored when sending a request.
@@ -605,37 +517,34 @@
      service data access to customer's storage. Possible values include: "None",
      "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'account_name': {'key': 'accountName', 'type': 'str'},
-        'container_name': {'key': 'containerName', 'type': 'str'},
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'protocol': {'key': 'protocol', 'type': 'str'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "account_name": {"key": "accountName", "type": "str"},
+        "container_name": {"key": "containerName", "type": "str"},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "protocol": {"key": "protocol", "type": "str"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -652,20 +561,20 @@
         :keyword service_data_access_auth_identity: Indicates which identity to use to authenticate
          service data access to customer's storage. Possible values include: "None",
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         """
         super(AzureBlobDatastore, self).__init__(**kwargs)
-        self.datastore_type = 'AzureBlob'  # type: str
-        self.account_name = kwargs.get('account_name', None)
-        self.container_name = kwargs.get('container_name', None)
-        self.endpoint = kwargs.get('endpoint', None)
-        self.protocol = kwargs.get('protocol', None)
-        self.service_data_access_auth_identity = kwargs.get('service_data_access_auth_identity', None)
+        self.datastore_type = "AzureBlob"  # type: str
+        self.account_name = kwargs.get("account_name", None)
+        self.container_name = kwargs.get("container_name", None)
+        self.endpoint = kwargs.get("endpoint", None)
+        self.protocol = kwargs.get("protocol", None)
+        self.service_data_access_auth_identity = kwargs.get("service_data_access_auth_identity", None)
 
 
 class AzureDataLakeGen1Datastore(Datastore):
     """Azure Data Lake Gen1 datastore configuration.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -691,35 +600,32 @@
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     :ivar store_name: Required. Azure Data Lake store name.
     :vartype store_name: str
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
-        'store_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
+        "store_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
-        'store_name': {'key': 'storeName', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
+        "store_name": {"key": "storeName", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -730,17 +636,17 @@
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         :keyword store_name: Required. Azure Data Lake store name.
         :paramtype store_name: str
         """
         super(AzureDataLakeGen1Datastore, self).__init__(**kwargs)
-        self.datastore_type = 'AzureDataLakeGen1'  # type: str
-        self.service_data_access_auth_identity = kwargs.get('service_data_access_auth_identity', None)
-        self.store_name = kwargs['store_name']
+        self.datastore_type = "AzureDataLakeGen1"  # type: str
+        self.service_data_access_auth_identity = kwargs.get("service_data_access_auth_identity", None)
+        self.store_name = kwargs["store_name"]
 
 
 class AzureDataLakeGen2Datastore(Datastore):
     """Azure Data Lake Gen2 datastore configuration.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -772,39 +678,36 @@
      service data access to customer's storage. Possible values include: "None",
      "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
-        'account_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'filesystem': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
+        "account_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "filesystem": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'account_name': {'key': 'accountName', 'type': 'str'},
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'filesystem': {'key': 'filesystem', 'type': 'str'},
-        'protocol': {'key': 'protocol', 'type': 'str'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "account_name": {"key": "accountName", "type": "str"},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "filesystem": {"key": "filesystem", "type": "str"},
+        "protocol": {"key": "protocol", "type": "str"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -821,20 +724,20 @@
         :keyword service_data_access_auth_identity: Indicates which identity to use to authenticate
          service data access to customer's storage. Possible values include: "None",
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         """
         super(AzureDataLakeGen2Datastore, self).__init__(**kwargs)
-        self.datastore_type = 'AzureDataLakeGen2'  # type: str
-        self.account_name = kwargs['account_name']
-        self.endpoint = kwargs.get('endpoint', None)
-        self.filesystem = kwargs['filesystem']
-        self.protocol = kwargs.get('protocol', None)
-        self.service_data_access_auth_identity = kwargs.get('service_data_access_auth_identity', None)
+        self.datastore_type = "AzureDataLakeGen2"  # type: str
+        self.account_name = kwargs["account_name"]
+        self.endpoint = kwargs.get("endpoint", None)
+        self.filesystem = kwargs["filesystem"]
+        self.protocol = kwargs.get("protocol", None)
+        self.service_data_access_auth_identity = kwargs.get("service_data_access_auth_identity", None)
 
 
 class AzureFileDatastore(Datastore):
     """Azure File datastore configuration.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -866,39 +769,36 @@
      service data access to customer's storage. Possible values include: "None",
      "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
-        'account_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'file_share_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
+        "account_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "file_share_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'account_name': {'key': 'accountName', 'type': 'str'},
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'file_share_name': {'key': 'fileShareName', 'type': 'str'},
-        'protocol': {'key': 'protocol', 'type': 'str'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "account_name": {"key": "accountName", "type": "str"},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "file_share_name": {"key": "fileShareName", "type": "str"},
+        "protocol": {"key": "protocol", "type": "str"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -915,20 +815,118 @@
         :keyword service_data_access_auth_identity: Indicates which identity to use to authenticate
          service data access to customer's storage. Possible values include: "None",
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         """
         super(AzureFileDatastore, self).__init__(**kwargs)
-        self.datastore_type = 'AzureFile'  # type: str
-        self.account_name = kwargs['account_name']
-        self.endpoint = kwargs.get('endpoint', None)
-        self.file_share_name = kwargs['file_share_name']
-        self.protocol = kwargs.get('protocol', None)
-        self.service_data_access_auth_identity = kwargs.get('service_data_access_auth_identity', None)
+        self.datastore_type = "AzureFile"  # type: str
+        self.account_name = kwargs["account_name"]
+        self.endpoint = kwargs.get("endpoint", None)
+        self.file_share_name = kwargs["file_share_name"]
+        self.protocol = kwargs.get("protocol", None)
+        self.service_data_access_auth_identity = kwargs.get("service_data_access_auth_identity", None)
+
+
+class InferencingServer(msrest.serialization.Model):
+    """InferencingServer.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: AzureMLBatchInferencingServer, AzureMLOnlineInferencingServer, CustomInferencingServer, TritonInferencingServer.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+    }
+
+    _subtype_map = {
+        "server_type": {
+            "AzureMLBatch": "AzureMLBatchInferencingServer",
+            "AzureMLOnline": "AzureMLOnlineInferencingServer",
+            "Custom": "CustomInferencingServer",
+            "Triton": "TritonInferencingServer",
+        }
+    }
+
+    def __init__(self, **kwargs):
+        """ """
+        super(InferencingServer, self).__init__(**kwargs)
+        self.server_type = None  # type: Optional[str]
+
+
+class AzureMLBatchInferencingServer(InferencingServer):
+    """Azure ML batch inferencing server configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar code_configuration: Code configuration for AML batch inferencing server.
+    :vartype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "code_configuration": {"key": "codeConfiguration", "type": "CodeConfiguration"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword code_configuration: Code configuration for AML batch inferencing server.
+        :paramtype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+        """
+        super(AzureMLBatchInferencingServer, self).__init__(**kwargs)
+        self.server_type = "AzureMLBatch"  # type: str
+        self.code_configuration = kwargs.get("code_configuration", None)
+
+
+class AzureMLOnlineInferencingServer(InferencingServer):
+    """Azure ML online inferencing configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar code_configuration: Code configuration for AML inferencing server.
+    :vartype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "code_configuration": {"key": "codeConfiguration", "type": "CodeConfiguration"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword code_configuration: Code configuration for AML inferencing server.
+        :paramtype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+        """
+        super(AzureMLOnlineInferencingServer, self).__init__(**kwargs)
+        self.server_type = "AzureMLOnline"  # type: str
+        self.code_configuration = kwargs.get("code_configuration", None)
 
 
 class EarlyTerminationPolicy(msrest.serialization.Model):
     """Early termination policies enable canceling poor-performing runs before they complete.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: BanditPolicy, MedianStoppingPolicy, TruncationSelectionPolicy.
@@ -942,40 +940,41 @@
     :ivar policy_type: Required. Name of policy configuration.Constant filled by server. Possible
      values include: "Bandit", "MedianStopping", "TruncationSelection".
     :vartype policy_type: str or
      ~azure.mgmt.machinelearningservices.models.EarlyTerminationPolicyType
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
     }
 
     _subtype_map = {
-        'policy_type': {'Bandit': 'BanditPolicy', 'MedianStopping': 'MedianStoppingPolicy', 'TruncationSelection': 'TruncationSelectionPolicy'}
+        "policy_type": {
+            "Bandit": "BanditPolicy",
+            "MedianStopping": "MedianStoppingPolicy",
+            "TruncationSelection": "TruncationSelectionPolicy",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword delay_evaluation: Number of intervals by which to delay the first evaluation.
         :paramtype delay_evaluation: int
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         """
         super(EarlyTerminationPolicy, self).__init__(**kwargs)
-        self.delay_evaluation = kwargs.get('delay_evaluation', 0)
-        self.evaluation_interval = kwargs.get('evaluation_interval', 0)
+        self.delay_evaluation = kwargs.get("delay_evaluation", 0)
+        self.evaluation_interval = kwargs.get("evaluation_interval", 0)
         self.policy_type = None  # type: Optional[str]
 
 
 class BanditPolicy(EarlyTerminationPolicy):
     """Defines an early termination policy based on slack criteria, and a frequency and delay interval for evaluation.
 
     All required parameters must be populated in order to send to Azure.
@@ -991,43 +990,103 @@
     :ivar slack_amount: Absolute distance allowed from the best performing run.
     :vartype slack_amount: float
     :ivar slack_factor: Ratio of the allowed distance from the best performing run.
     :vartype slack_factor: float
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
-        'slack_amount': {'key': 'slackAmount', 'type': 'float'},
-        'slack_factor': {'key': 'slackFactor', 'type': 'float'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
+        "slack_amount": {"key": "slackAmount", "type": "float"},
+        "slack_factor": {"key": "slackFactor", "type": "float"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword delay_evaluation: Number of intervals by which to delay the first evaluation.
         :paramtype delay_evaluation: int
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         :keyword slack_amount: Absolute distance allowed from the best performing run.
         :paramtype slack_amount: float
         :keyword slack_factor: Ratio of the allowed distance from the best performing run.
         :paramtype slack_factor: float
         """
         super(BanditPolicy, self).__init__(**kwargs)
-        self.policy_type = 'Bandit'  # type: str
-        self.slack_amount = kwargs.get('slack_amount', 0)
-        self.slack_factor = kwargs.get('slack_factor', 0)
+        self.policy_type = "Bandit"  # type: str
+        self.slack_amount = kwargs.get("slack_amount", 0)
+        self.slack_factor = kwargs.get("slack_factor", 0)
+
+
+class BaseEnvironmentSource(msrest.serialization.Model):
+    """BaseEnvironmentSource.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: BaseEnvironmentId.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar base_environment_source_type: Required. Base environment type.Constant filled by server.
+     Possible values include: "EnvironmentAsset".
+    :vartype base_environment_source_type: str or
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSourceType
+    """
+
+    _validation = {
+        "base_environment_source_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "base_environment_source_type": {"key": "baseEnvironmentSourceType", "type": "str"},
+    }
+
+    _subtype_map = {"base_environment_source_type": {"EnvironmentAsset": "BaseEnvironmentId"}}
+
+    def __init__(self, **kwargs):
+        """ """
+        super(BaseEnvironmentSource, self).__init__(**kwargs)
+        self.base_environment_source_type = None  # type: Optional[str]
+
+
+class BaseEnvironmentId(BaseEnvironmentSource):
+    """Base environment type.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar base_environment_source_type: Required. Base environment type.Constant filled by server.
+     Possible values include: "EnvironmentAsset".
+    :vartype base_environment_source_type: str or
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSourceType
+    :ivar resource_id: Required. Resource id accepting ArmId or AzureMlId.
+    :vartype resource_id: str
+    """
+
+    _validation = {
+        "base_environment_source_type": {"required": True},
+        "resource_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+    }
+
+    _attribute_map = {
+        "base_environment_source_type": {"key": "baseEnvironmentSourceType", "type": "str"},
+        "resource_id": {"key": "resourceId", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword resource_id: Required. Resource id accepting ArmId or AzureMlId.
+        :paramtype resource_id: str
+        """
+        super(BaseEnvironmentId, self).__init__(**kwargs)
+        self.base_environment_source_type = "EnvironmentAsset"  # type: str
+        self.resource_id = kwargs["resource_id"]
 
 
 class Binding(msrest.serialization.Model):
     """Binding Inputs/Outputs to ComponentJob Inputs/Outputs etc.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: BasicBinding.
@@ -1036,31 +1095,25 @@
 
     :ivar binding_type: Required. Type of Binding.Constant filled by server. Possible values
      include: "Basic".
     :vartype binding_type: str or ~azure.mgmt.machinelearningservices.models.BindingType
     """
 
     _validation = {
-        'binding_type': {'required': True},
+        "binding_type": {"required": True},
     }
 
     _attribute_map = {
-        'binding_type': {'key': 'bindingType', 'type': 'str'},
+        "binding_type": {"key": "bindingType", "type": "str"},
     }
 
-    _subtype_map = {
-        'binding_type': {'Basic': 'BasicBinding'}
-    }
+    _subtype_map = {"binding_type": {"Basic": "BasicBinding"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(Binding, self).__init__(**kwargs)
         self.binding_type = None  # type: Optional[str]
 
 
 class BasicBinding(Binding):
     """Basic binding with simple source and destination.
 
@@ -1072,185 +1125,173 @@
     :ivar destination: Destination reference.
     :vartype destination: str
     :ivar source: Source reference.
     :vartype source: str
     """
 
     _validation = {
-        'binding_type': {'required': True},
+        "binding_type": {"required": True},
     }
 
     _attribute_map = {
-        'binding_type': {'key': 'bindingType', 'type': 'str'},
-        'destination': {'key': 'destination', 'type': 'str'},
-        'source': {'key': 'source', 'type': 'str'},
+        "binding_type": {"key": "bindingType", "type": "str"},
+        "destination": {"key": "destination", "type": "str"},
+        "source": {"key": "source", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword destination: Destination reference.
         :paramtype destination: str
         :keyword source: Source reference.
         :paramtype source: str
         """
         super(BasicBinding, self).__init__(**kwargs)
-        self.binding_type = 'Basic'  # type: str
-        self.destination = kwargs.get('destination', None)
-        self.source = kwargs.get('source', None)
+        self.binding_type = "Basic"  # type: str
+        self.destination = kwargs.get("destination", None)
+        self.source = kwargs.get("source", None)
 
 
 class BlobReferenceForConsumptionDto(msrest.serialization.Model):
     """BlobReferenceForConsumptionDto.
 
     :ivar blob_uri: https://blob.windows.core.net/Container/Path.
     :vartype blob_uri: str
     :ivar credential:
     :vartype credential: ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialDto
     :ivar storage_account_arm_id:
     :vartype storage_account_arm_id: str
     """
 
     _attribute_map = {
-        'blob_uri': {'key': 'blobUri', 'type': 'str'},
-        'credential': {'key': 'credential', 'type': 'DataReferenceCredentialDto'},
-        'storage_account_arm_id': {'key': 'storageAccountArmId', 'type': 'str'},
+        "blob_uri": {"key": "blobUri", "type": "str"},
+        "credential": {"key": "credential", "type": "DataReferenceCredentialDto"},
+        "storage_account_arm_id": {"key": "storageAccountArmId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword blob_uri: https://blob.windows.core.net/Container/Path.
         :paramtype blob_uri: str
         :keyword credential:
         :paramtype credential: ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialDto
         :keyword storage_account_arm_id:
         :paramtype storage_account_arm_id: str
         """
         super(BlobReferenceForConsumptionDto, self).__init__(**kwargs)
-        self.blob_uri = kwargs.get('blob_uri', None)
-        self.credential = kwargs.get('credential', None)
-        self.storage_account_arm_id = kwargs.get('storage_account_arm_id', None)
+        self.blob_uri = kwargs.get("blob_uri", None)
+        self.credential = kwargs.get("credential", None)
+        self.storage_account_arm_id = kwargs.get("storage_account_arm_id", None)
 
 
 class BlobReferenceSASRequestDto(msrest.serialization.Model):
     """BlobReferenceSASRequestDto.
 
     :ivar asset_id:
     :vartype asset_id: str
     :ivar blob_uri:
     :vartype blob_uri: str
     """
 
     _attribute_map = {
-        'asset_id': {'key': 'assetId', 'type': 'str'},
-        'blob_uri': {'key': 'blobUri', 'type': 'str'},
+        "asset_id": {"key": "assetId", "type": "str"},
+        "blob_uri": {"key": "blobUri", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword asset_id:
         :paramtype asset_id: str
         :keyword blob_uri:
         :paramtype blob_uri: str
         """
         super(BlobReferenceSASRequestDto, self).__init__(**kwargs)
-        self.asset_id = kwargs.get('asset_id', None)
-        self.blob_uri = kwargs.get('blob_uri', None)
+        self.asset_id = kwargs.get("asset_id", None)
+        self.blob_uri = kwargs.get("blob_uri", None)
 
 
 class BlobReferenceSASResponseDto(msrest.serialization.Model):
     """BlobReferenceSASResponseDto.
 
     :ivar blob_reference_for_consumption:
     :vartype blob_reference_for_consumption:
      ~azure.mgmt.machinelearningservices.models.BlobReferenceForConsumptionDto
     """
 
     _attribute_map = {
-        'blob_reference_for_consumption': {'key': 'blobReferenceForConsumption', 'type': 'BlobReferenceForConsumptionDto'},
+        "blob_reference_for_consumption": {
+            "key": "blobReferenceForConsumption",
+            "type": "BlobReferenceForConsumptionDto",
+        },
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword blob_reference_for_consumption:
         :paramtype blob_reference_for_consumption:
          ~azure.mgmt.machinelearningservices.models.BlobReferenceForConsumptionDto
         """
         super(BlobReferenceSASResponseDto, self).__init__(**kwargs)
-        self.blob_reference_for_consumption = kwargs.get('blob_reference_for_consumption', None)
+        self.blob_reference_for_consumption = kwargs.get("blob_reference_for_consumption", None)
 
 
 class BuildContext(msrest.serialization.Model):
     """Configuration settings for Docker build context.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar context_uri: Required. URI of the Docker build context used to build the image. Supports
      blob URIs on environment creation and may return blob or Git URIs.
-    
-    
+
+
      .. raw:: html
-    
+
         <seealso
      href="https://docs.docker.com/engine/reference/commandline/build/#extended-description" />.
     :vartype context_uri: str
     :ivar dockerfile_path: Path to the Dockerfile in the build context.
-    
-    
+
+
      .. raw:: html
-    
+
         <seealso href="https://docs.docker.com/engine/reference/builder/" />.
     :vartype dockerfile_path: str
     """
 
     _validation = {
-        'context_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "context_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'context_uri': {'key': 'contextUri', 'type': 'str'},
-        'dockerfile_path': {'key': 'dockerfilePath', 'type': 'str'},
+        "context_uri": {"key": "contextUri", "type": "str"},
+        "dockerfile_path": {"key": "dockerfilePath", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword context_uri: Required. URI of the Docker build context used to build the image.
          Supports blob URIs on environment creation and may return blob or Git URIs.
-        
-        
+
+
          .. raw:: html
-        
+
             <seealso
          href="https://docs.docker.com/engine/reference/commandline/build/#extended-description" />.
         :paramtype context_uri: str
         :keyword dockerfile_path: Path to the Dockerfile in the build context.
-        
-        
+
+
          .. raw:: html
-        
+
             <seealso href="https://docs.docker.com/engine/reference/builder/" />.
         :paramtype dockerfile_path: str
         """
         super(BuildContext, self).__init__(**kwargs)
-        self.context_uri = kwargs['context_uri']
-        self.dockerfile_path = kwargs.get('dockerfile_path', "Dockerfile")
+        self.context_uri = kwargs["context_uri"]
+        self.dockerfile_path = kwargs.get("dockerfile_path", "Dockerfile")
 
 
 class CertificateDatastoreCredentials(DatastoreCredentials):
     """Certificate datastore credentials configuration.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -1269,35 +1310,32 @@
     :ivar tenant_id: Required. ID of the tenant to which the service principal belongs.
     :vartype tenant_id: str
     :ivar thumbprint: Required. Thumbprint of the certificate used for authentication.
     :vartype thumbprint: str
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'client_id': {'required': True},
-        'secrets': {'required': True},
-        'tenant_id': {'required': True},
-        'thumbprint': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials_type": {"required": True},
+        "client_id": {"required": True},
+        "secrets": {"required": True},
+        "tenant_id": {"required": True},
+        "thumbprint": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'authority_url': {'key': 'authorityUrl', 'type': 'str'},
-        'client_id': {'key': 'clientId', 'type': 'str'},
-        'resource_url': {'key': 'resourceUrl', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'CertificateDatastoreSecrets'},
-        'tenant_id': {'key': 'tenantId', 'type': 'str'},
-        'thumbprint': {'key': 'thumbprint', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "authority_url": {"key": "authorityUrl", "type": "str"},
+        "client_id": {"key": "clientId", "type": "str"},
+        "resource_url": {"key": "resourceUrl", "type": "str"},
+        "secrets": {"key": "secrets", "type": "CertificateDatastoreSecrets"},
+        "tenant_id": {"key": "tenantId", "type": "str"},
+        "thumbprint": {"key": "thumbprint", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword authority_url: Authority URL used for authentication.
         :paramtype authority_url: str
         :keyword client_id: Required. Service principal client ID.
         :paramtype client_id: str
         :keyword resource_url: Resource the service principal has access to.
         :paramtype resource_url: str
@@ -1305,21 +1343,21 @@
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.CertificateDatastoreSecrets
         :keyword tenant_id: Required. ID of the tenant to which the service principal belongs.
         :paramtype tenant_id: str
         :keyword thumbprint: Required. Thumbprint of the certificate used for authentication.
         :paramtype thumbprint: str
         """
         super(CertificateDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'Certificate'  # type: str
-        self.authority_url = kwargs.get('authority_url', None)
-        self.client_id = kwargs['client_id']
-        self.resource_url = kwargs.get('resource_url', None)
-        self.secrets = kwargs['secrets']
-        self.tenant_id = kwargs['tenant_id']
-        self.thumbprint = kwargs['thumbprint']
+        self.credentials_type = "Certificate"  # type: str
+        self.authority_url = kwargs.get("authority_url", None)
+        self.client_id = kwargs["client_id"]
+        self.resource_url = kwargs.get("resource_url", None)
+        self.secrets = kwargs["secrets"]
+        self.tenant_id = kwargs["tenant_id"]
+        self.thumbprint = kwargs["thumbprint"]
 
 
 class CertificateDatastoreSecrets(DatastoreSecrets):
     """Datastore certificate secrets.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -1328,33 +1366,62 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar certificate: Service principal certificate.
     :vartype certificate: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'certificate': {'key': 'certificate', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "certificate": {"key": "certificate", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword certificate: Service principal certificate.
         :paramtype certificate: str
         """
         super(CertificateDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'Certificate'  # type: str
-        self.certificate = kwargs.get('certificate', None)
+        self.secrets_type = "Certificate"  # type: str
+        self.certificate = kwargs.get("certificate", None)
+
+
+class CodeConfiguration(msrest.serialization.Model):
+    """Configuration for a scoring code asset.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar code_id: ARM resource ID of the code asset.
+    :vartype code_id: str
+    :ivar scoring_script: Required. The script to execute on startup. eg. "score.py".
+    :vartype scoring_script: str
+    """
+
+    _validation = {
+        "scoring_script": {"required": True, "min_length": 1, "pattern": r"[a-zA-Z0-9_]"},
+    }
+
+    _attribute_map = {
+        "code_id": {"key": "codeId", "type": "str"},
+        "scoring_script": {"key": "scoringScript", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword code_id: ARM resource ID of the code asset.
+        :paramtype code_id: str
+        :keyword scoring_script: Required. The script to execute on startup. eg. "score.py".
+        :paramtype scoring_script: str
+        """
+        super(CodeConfiguration, self).__init__(**kwargs)
+        self.code_id = kwargs.get("code_id", None)
+        self.scoring_script = kwargs["scoring_script"]
 
 
 class Resource(msrest.serialization.Model):
     """Common fields that are returned in the response for all Azure Resource Manager resources.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -1368,33 +1435,29 @@
     :vartype type: str
     :ivar system_data: Azure Resource Manager metadata containing createdBy and modifiedBy
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(Resource, self).__init__(**kwargs)
         self.id = None
         self.name = None
         self.type = None
         self.system_data = None
 
 
@@ -1417,39 +1480,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.CodeContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'CodeContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "CodeContainerDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.CodeContainerDetails
         """
         super(CodeContainerData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class CodeContainerDetails(AssetContainer):
     """Container for code asset versions.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -1464,31 +1524,28 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -1505,32 +1562,29 @@
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type CodeContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.CodeContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[CodeContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[CodeContainerData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of CodeContainer objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type CodeContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.CodeContainerData]
         """
         super(CodeContainerResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class CodeVersionData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -1548,39 +1602,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.CodeVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'CodeVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "CodeVersionDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.CodeVersionDetails
         """
         super(CodeVersionData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class CodeVersionDetails(AssetBase):
     """Code asset version details.
 
     :ivar description: The asset description text.
     :vartype description: str
@@ -1593,26 +1644,23 @@
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     :ivar code_uri: Uri where code is located.
     :vartype code_uri: str
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'code_uri': {'key': 'codeUri', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "code_uri": {"key": "codeUri", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -1620,46 +1668,43 @@
         :paramtype is_anonymous: bool
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword code_uri: Uri where code is located.
         :paramtype code_uri: str
         """
         super(CodeVersionDetails, self).__init__(**kwargs)
-        self.code_uri = kwargs.get('code_uri', None)
+        self.code_uri = kwargs.get("code_uri", None)
 
 
 class CodeVersionResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of CodeVersion entities.
 
     :ivar next_link: The link to the next page of CodeVersion objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type CodeVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.CodeVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[CodeVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[CodeVersionData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of CodeVersion objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type CodeVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.CodeVersionData]
         """
         super(CodeVersionResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class JobBase(ResourceBase):
     """Base definition for a job.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: Job, CommandJob, PipelineJob, SweepJob.
@@ -1694,41 +1739,38 @@
     :ivar status: Status of the job. Possible values include: "NotStarted", "Starting",
      "Provisioning", "Preparing", "Queued", "Running", "Finalizing", "CancelRequested", "Completed",
      "Failed", "Canceled", "NotResponding", "Paused", "Unknown".
     :vartype status: str or ~azure.mgmt.machinelearningservices.models.JobStatus
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
     }
 
     _subtype_map = {
-        'job_type': {'Base': 'Job', 'Command': 'CommandJob', 'Pipeline': 'PipelineJob', 'Sweep': 'SweepJob'}
+        "job_type": {"Base": "Job", "Command": "CommandJob", "Pipeline": "PipelineJob", "Sweep": "SweepJob"}
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -1742,21 +1784,21 @@
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword services: List of JobEndpoints.
          For local jobs, a job endpoint will have an endpoint value of FileStreamObject.
         :paramtype services: dict[str, ~azure.mgmt.machinelearningservices.models.JobService]
         """
         super(JobBase, self).__init__(**kwargs)
-        self.compute_id = kwargs.get('compute_id', None)
-        self.display_name = kwargs.get('display_name', None)
-        self.experiment_name = kwargs.get('experiment_name', "Default")
-        self.is_archived = kwargs.get('is_archived', False)
-        self.job_type = 'JobBase'  # type: str
+        self.compute_id = kwargs.get("compute_id", None)
+        self.display_name = kwargs.get("display_name", None)
+        self.experiment_name = kwargs.get("experiment_name", "Default")
+        self.is_archived = kwargs.get("is_archived", False)
+        self.job_type = "JobBase"  # type: str
         self.parent_job_name = None
-        self.services = kwargs.get('services', None)
+        self.services = kwargs.get("services", None)
         self.status = None
 
 
 class CommandJob(JobBase):
     """Command job definition.
 
     Variables are only populated by the server, and will be ignored when sending a request.
@@ -1815,51 +1857,48 @@
     :ivar parameters: Input parameters.
     :vartype parameters: any
     :ivar resources: Compute Resource configuration for the job.
     :vartype resources: ~azure.mgmt.machinelearningservices.models.ResourceConfiguration
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
-        'command': {'required': True, 'min_length': 1, 'pattern': r'[a-zA-Z0-9_]'},
-        'environment_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'parameters': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
+        "command": {"required": True, "min_length": 1, "pattern": r"[a-zA-Z0-9_]"},
+        "environment_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "parameters": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
-        'code_id': {'key': 'codeId', 'type': 'str'},
-        'command': {'key': 'command', 'type': 'str'},
-        'distribution': {'key': 'distribution', 'type': 'DistributionConfiguration'},
-        'environment_id': {'key': 'environmentId', 'type': 'str'},
-        'environment_variables': {'key': 'environmentVariables', 'type': '{str}'},
-        'identity': {'key': 'identity', 'type': 'IdentityConfiguration'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'limits': {'key': 'limits', 'type': 'CommandJobLimits'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'parameters': {'key': 'parameters', 'type': 'object'},
-        'resources': {'key': 'resources', 'type': 'ResourceConfiguration'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
+        "code_id": {"key": "codeId", "type": "str"},
+        "command": {"key": "command", "type": "str"},
+        "distribution": {"key": "distribution", "type": "DistributionConfiguration"},
+        "environment_id": {"key": "environmentId", "type": "str"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "identity": {"key": "identity", "type": "IdentityConfiguration"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "limits": {"key": "limits", "type": "CommandJobLimits"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "parameters": {"key": "parameters", "type": "object"},
+        "resources": {"key": "resources", "type": "ResourceConfiguration"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -1898,26 +1937,26 @@
         :paramtype limits: ~azure.mgmt.machinelearningservices.models.CommandJobLimits
         :keyword outputs: Mapping of output data bindings used in the job.
         :paramtype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
         :keyword resources: Compute Resource configuration for the job.
         :paramtype resources: ~azure.mgmt.machinelearningservices.models.ResourceConfiguration
         """
         super(CommandJob, self).__init__(**kwargs)
-        self.job_type = 'Command'  # type: str
-        self.code_id = kwargs.get('code_id', None)
-        self.command = kwargs['command']
-        self.distribution = kwargs.get('distribution', None)
-        self.environment_id = kwargs['environment_id']
-        self.environment_variables = kwargs.get('environment_variables', None)
-        self.identity = kwargs.get('identity', None)
-        self.inputs = kwargs.get('inputs', None)
-        self.limits = kwargs.get('limits', None)
-        self.outputs = kwargs.get('outputs', None)
+        self.job_type = "Command"  # type: str
+        self.code_id = kwargs.get("code_id", None)
+        self.command = kwargs["command"]
+        self.distribution = kwargs.get("distribution", None)
+        self.environment_id = kwargs["environment_id"]
+        self.environment_variables = kwargs.get("environment_variables", None)
+        self.identity = kwargs.get("identity", None)
+        self.inputs = kwargs.get("inputs", None)
+        self.limits = kwargs.get("limits", None)
+        self.outputs = kwargs.get("outputs", None)
         self.parameters = None
-        self.resources = kwargs.get('resources', None)
+        self.resources = kwargs.get("resources", None)
 
 
 class JobLimits(msrest.serialization.Model):
     """JobLimits.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: CommandJobLimits, SweepJobLimits.
@@ -1929,38 +1968,33 @@
     :vartype job_limits_type: str or ~azure.mgmt.machinelearningservices.models.JobLimitsType
     :ivar timeout: The max run duration in ISO 8601 format, after which the job will be cancelled.
      Only supports duration with precision as low as Seconds.
     :vartype timeout: ~datetime.timedelta
     """
 
     _validation = {
-        'job_limits_type': {'required': True},
+        "job_limits_type": {"required": True},
     }
 
     _attribute_map = {
-        'job_limits_type': {'key': 'jobLimitsType', 'type': 'str'},
-        'timeout': {'key': 'timeout', 'type': 'duration'},
+        "job_limits_type": {"key": "jobLimitsType", "type": "str"},
+        "timeout": {"key": "timeout", "type": "duration"},
     }
 
-    _subtype_map = {
-        'job_limits_type': {'Command': 'CommandJobLimits', 'Sweep': 'SweepJobLimits'}
-    }
+    _subtype_map = {"job_limits_type": {"Command": "CommandJobLimits", "Sweep": "SweepJobLimits"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword timeout: The max run duration in ISO 8601 format, after which the job will be
          cancelled. Only supports duration with precision as low as Seconds.
         :paramtype timeout: ~datetime.timedelta
         """
         super(JobLimits, self).__init__(**kwargs)
         self.job_limits_type = None  # type: Optional[str]
-        self.timeout = kwargs.get('timeout', None)
+        self.timeout = kwargs.get("timeout", None)
 
 
 class CommandJobLimits(JobLimits):
     """Command Job limit class.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -1969,33 +2003,30 @@
     :vartype job_limits_type: str or ~azure.mgmt.machinelearningservices.models.JobLimitsType
     :ivar timeout: The max run duration in ISO 8601 format, after which the job will be cancelled.
      Only supports duration with precision as low as Seconds.
     :vartype timeout: ~datetime.timedelta
     """
 
     _validation = {
-        'job_limits_type': {'required': True},
+        "job_limits_type": {"required": True},
     }
 
     _attribute_map = {
-        'job_limits_type': {'key': 'jobLimitsType', 'type': 'str'},
-        'timeout': {'key': 'timeout', 'type': 'duration'},
+        "job_limits_type": {"key": "jobLimitsType", "type": "str"},
+        "timeout": {"key": "timeout", "type": "duration"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword timeout: The max run duration in ISO 8601 format, after which the job will be
          cancelled. Only supports duration with precision as low as Seconds.
         :paramtype timeout: ~datetime.timedelta
         """
         super(CommandJobLimits, self).__init__(**kwargs)
-        self.job_limits_type = 'Command'  # type: str
+        self.job_limits_type = "Command"  # type: str
 
 
 class ComponentContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2013,83 +2044,77 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ComponentContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ComponentContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ComponentContainerDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ComponentContainerDetails
         """
         super(ComponentContainerData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class ComponentContainerDetails(AssetContainer):
     """Component container definition.
 
 
-.. raw:: html
+    .. raw:: html
 
-   <see href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command" />.
+       <see href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command" />.
 
-    Variables are only populated by the server, and will be ignored when sending a request.
+        Variables are only populated by the server, and will be ignored when sending a request.
 
-    :ivar description: The asset description text.
-    :vartype description: str
-    :ivar properties: The asset property dictionary.
-    :vartype properties: dict[str, str]
-    :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
-    :vartype tags: dict[str, str]
-    :ivar is_archived: Is the asset archived?.
-    :vartype is_archived: bool
-    :ivar latest_version: The latest version inside this container.
-    :vartype latest_version: str
-    :ivar next_version: The next auto incremental version.
-    :vartype next_version: str
+        :ivar description: The asset description text.
+        :vartype description: str
+        :ivar properties: The asset property dictionary.
+        :vartype properties: dict[str, str]
+        :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+        :vartype tags: dict[str, str]
+        :ivar is_archived: Is the asset archived?.
+        :vartype is_archived: bool
+        :ivar latest_version: The latest version inside this container.
+        :vartype latest_version: str
+        :ivar next_version: The next auto incremental version.
+        :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -2106,32 +2131,29 @@
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ComponentContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ComponentContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ComponentContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ComponentContainerData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of ComponentContainer objects. If null, there are
          no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ComponentContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ComponentContainerData]
         """
         super(ComponentContainerResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class ComponentJob(msrest.serialization.Model):
     """Definition of a ComponentJob.
 
     :ivar component_id: Reference to component artifact.
     :vartype component_id: str
@@ -2142,43 +2164,40 @@
     :ivar outputs: Data output set for job.
     :vartype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
     :ivar overrides: Override component default settings.
     :vartype overrides: any
     """
 
     _attribute_map = {
-        'component_id': {'key': 'componentId', 'type': 'str'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'overrides': {'key': 'overrides', 'type': 'object'},
+        "component_id": {"key": "componentId", "type": "str"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "overrides": {"key": "overrides", "type": "object"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword component_id: Reference to component artifact.
         :paramtype component_id: str
         :keyword compute_id: ARM resource ID of the compute resource.
         :paramtype compute_id: str
         :keyword inputs: Data input set for job.
         :paramtype inputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobInput]
         :keyword outputs: Data output set for job.
         :paramtype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
         :keyword overrides: Override component default settings.
         :paramtype overrides: any
         """
         super(ComponentJob, self).__init__(**kwargs)
-        self.component_id = kwargs.get('component_id', None)
-        self.compute_id = kwargs.get('compute_id', None)
-        self.inputs = kwargs.get('inputs', None)
-        self.outputs = kwargs.get('outputs', None)
-        self.overrides = kwargs.get('overrides', None)
+        self.component_id = kwargs.get("component_id", None)
+        self.compute_id = kwargs.get("compute_id", None)
+        self.inputs = kwargs.get("inputs", None)
+        self.outputs = kwargs.get("outputs", None)
+        self.overrides = kwargs.get("overrides", None)
 
 
 class ComponentVersionData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2196,39 +2215,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ComponentVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ComponentVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ComponentVersionDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ComponentVersionDetails
         """
         super(ComponentVersionData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class ComponentVersionDetails(AssetBase):
     """Definition of a component version: defines resources that span component types.
 
     :ivar description: The asset description text.
     :vartype description: str
@@ -2237,91 +2253,118 @@
     :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
     :vartype tags: dict[str, str]
     :ivar is_anonymous: If the name version are system generated (anonymous registration).
     :vartype is_anonymous: bool
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     :ivar component_spec: Defines Component definition details.
-    
-    
+
+
      .. raw:: html
-    
+
         <see
      href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command"
      />.
     :vartype component_spec: any
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'component_spec': {'key': 'componentSpec', 'type': 'object'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "component_spec": {"key": "componentSpec", "type": "object"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_anonymous: If the name version are system generated (anonymous registration).
         :paramtype is_anonymous: bool
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword component_spec: Defines Component definition details.
-        
-        
+
+
          .. raw:: html
-        
+
             <see
          href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command"
          />.
         :paramtype component_spec: any
         """
         super(ComponentVersionDetails, self).__init__(**kwargs)
-        self.component_spec = kwargs.get('component_spec', None)
+        self.component_spec = kwargs.get("component_spec", None)
 
 
 class ComponentVersionResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of ComponentVersion entities.
 
     :ivar next_link: The link to the next page of ComponentVersion objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ComponentVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ComponentVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ComponentVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ComponentVersionData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of ComponentVersion objects. If null, there are
          no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ComponentVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ComponentVersionData]
         """
         super(ComponentVersionResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
+
+
+class CustomInferencingServer(InferencingServer):
+    """Custom inference server configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar inference_configuration: Inference configuration for custom inferencing.
+    :vartype inference_configuration:
+     ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "inference_configuration": {"key": "inferenceConfiguration", "type": "OnlineInferenceConfiguration"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword inference_configuration: Inference configuration for custom inferencing.
+        :paramtype inference_configuration:
+         ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+        """
+        super(CustomInferencingServer, self).__init__(**kwargs)
+        self.server_type = "Custom"  # type: str
+        self.inference_configuration = kwargs.get("inference_configuration", None)
 
 
 class DataContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2339,39 +2382,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.DataContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'DataContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "DataContainerDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.DataContainerDetails
         """
         super(DataContainerData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class DataContainerDetails(AssetContainer):
     """Container for data asset versions.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2391,79 +2431,73 @@
     :vartype next_version: str
     :ivar data_type: Required. Specifies the type of data. Possible values include: "uri_file",
      "uri_folder", "mltable".
     :vartype data_type: str or ~azure.mgmt.machinelearningservices.models.DataType
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
-        'data_type': {'required': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
+        "data_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
+        "data_type": {"key": "dataType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword data_type: Required. Specifies the type of data. Possible values include: "uri_file",
          "uri_folder", "mltable".
         :paramtype data_type: str or ~azure.mgmt.machinelearningservices.models.DataType
         """
         super(DataContainerDetails, self).__init__(**kwargs)
-        self.data_type = kwargs['data_type']
+        self.data_type = kwargs["data_type"]
 
 
 class DataContainerResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of DataContainer entities.
 
     :ivar next_link: The link to the next page of DataContainer objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type DataContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.DataContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[DataContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[DataContainerData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of DataContainer objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type DataContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.DataContainerData]
         """
         super(DataContainerResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class DataPathAssetReference(AssetReferenceBase):
     """Reference to an asset via its path in a datastore.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -2473,37 +2507,64 @@
     :ivar datastore_id: ARM resource ID of the datastore where the asset is located.
     :vartype datastore_id: str
     :ivar path: The path of the file/directory in the datastore.
     :vartype path: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
+        "reference_type": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'datastore_id': {'key': 'datastoreId', 'type': 'str'},
-        'path': {'key': 'path', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "datastore_id": {"key": "datastoreId", "type": "str"},
+        "path": {"key": "path", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword datastore_id: ARM resource ID of the datastore where the asset is located.
         :paramtype datastore_id: str
         :keyword path: The path of the file/directory in the datastore.
         :paramtype path: str
         """
         super(DataPathAssetReference, self).__init__(**kwargs)
-        self.reference_type = 'DataPath'  # type: str
-        self.datastore_id = kwargs.get('datastore_id', None)
-        self.path = kwargs.get('path', None)
+        self.reference_type = "DataPath"  # type: str
+        self.datastore_id = kwargs.get("datastore_id", None)
+        self.path = kwargs.get("path", None)
+
+
+class DataReferenceCredentialDto(msrest.serialization.Model):
+    """DataReferenceCredentialDto.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: .
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
+     "DockerCredentials", "ManagedIdentity", "NoCredentials".
+    :vartype credential_type: str or
+     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
+    """
+
+    _validation = {
+        "credential_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "credential_type": {"key": "credentialType", "type": "str"},
+    }
+
+    _subtype_map = {"credential_type": {}}
+
+    def __init__(self, **kwargs):
+        """ """
+        super(DataReferenceCredentialDto, self).__init__(**kwargs)
+        self.credential_type = "SAS"  # type: str
 
 
 class DataVersionBaseData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2521,39 +2582,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.DataVersionBaseDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'DataVersionBaseDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "DataVersionBaseDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.DataVersionBaseDetails
         """
         super(DataVersionBaseData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class DataVersionBaseDetails(AssetBase):
     """Data version base definition.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: MLTableData, UriFileDataVersion, UriFolderDataVersion.
@@ -2578,37 +2636,34 @@
     :vartype data_uri: str
     :ivar intellectual_property: Intellectual Property details. Used if data is an Intellectual
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
     }
 
     _subtype_map = {
-        'data_type': {'mltable': 'MLTableData', 'uri_file': 'UriFileDataVersion', 'uri_folder': 'UriFolderDataVersion'}
+        "data_type": {"mltable": "MLTableData", "uri_file": "UriFileDataVersion", "uri_folder": "UriFolderDataVersion"}
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -2621,48 +2676,45 @@
         :paramtype data_uri: str
         :keyword intellectual_property: Intellectual Property details. Used if data is an Intellectual
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         """
         super(DataVersionBaseDetails, self).__init__(**kwargs)
-        self.data_type = 'DataVersionBaseDetails'  # type: str
-        self.data_uri = kwargs['data_uri']
-        self.intellectual_property = kwargs.get('intellectual_property', None)
+        self.data_type = "DataVersionBaseDetails"  # type: str
+        self.data_uri = kwargs["data_uri"]
+        self.intellectual_property = kwargs.get("intellectual_property", None)
 
 
 class DataVersionBaseResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of DataVersionBase entities.
 
     :ivar next_link: The link to the next page of DataVersionBase objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type DataVersionBase.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.DataVersionBaseData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[DataVersionBaseData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[DataVersionBaseData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of DataVersionBase objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type DataVersionBase.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.DataVersionBaseData]
         """
         super(DataVersionBaseResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class DistributionConfiguration(msrest.serialization.Model):
     """Base definition for job distribution configuration.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: Mpi, PyTorch, TensorFlow.
@@ -2671,74 +2723,53 @@
 
     :ivar distribution_type: Required. Specifies the type of distribution framework.Constant filled
      by server. Possible values include: "PyTorch", "TensorFlow", "Mpi".
     :vartype distribution_type: str or ~azure.mgmt.machinelearningservices.models.DistributionType
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
     }
 
-    _subtype_map = {
-        'distribution_type': {'Mpi': 'Mpi', 'PyTorch': 'PyTorch', 'TensorFlow': 'TensorFlow'}
-    }
+    _subtype_map = {"distribution_type": {"Mpi": "Mpi", "PyTorch": "PyTorch", "TensorFlow": "TensorFlow"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(DistributionConfiguration, self).__init__(**kwargs)
         self.distribution_type = None  # type: Optional[str]
 
 
-class DockerCredentialDto(DataReferenceCredentialDto):
+class DockerCredentialDto(msrest.serialization.Model):
     """DockerCredentialDto.
 
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
     :ivar password:
     :vartype password: str
     :ivar user_name:
     :vartype user_name: str
     """
 
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
     _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-        'password': {'key': 'password', 'type': 'str'},
-        'user_name': {'key': 'userName', 'type': 'str'},
+        "password": {"key": "password", "type": "str"},
+        "user_name": {"key": "userName", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword password:
         :paramtype password: str
         :keyword user_name:
         :paramtype user_name: str
         """
         super(DockerCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'DockerCredentials'  # type: str
-        self.password = kwargs.get('password', None)
-        self.user_name = kwargs.get('user_name', None)
+        self.password = kwargs.get("password", None)
+        self.user_name = kwargs.get("user_name", None)
 
 
 class EnvironmentContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2756,39 +2787,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'EnvironmentContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "EnvironmentContainerDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerDetails
         """
         super(EnvironmentContainerData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class EnvironmentContainerDetails(AssetContainer):
     """Container for environment specification versions.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2803,31 +2831,28 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -2844,32 +2869,29 @@
      no additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type EnvironmentContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[EnvironmentContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[EnvironmentContainerData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of EnvironmentContainer objects. If null, there
          are no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type EnvironmentContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentContainerData]
         """
         super(EnvironmentContainerResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class EnvironmentVersionData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2887,39 +2909,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'EnvironmentVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "EnvironmentVersionDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionDetails
         """
         super(EnvironmentVersionData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class EnvironmentVersionDetails(AssetBase):
     """Environment version details.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2933,37 +2952,37 @@
     :vartype is_anonymous: bool
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     :ivar build: Configuration settings for Docker build context.
     :vartype build: ~azure.mgmt.machinelearningservices.models.BuildContext
     :ivar conda_file: Standard configuration file used by Conda that lets you install any kind of
      package, including Python, R, and C/C++ packages.
-    
-    
+
+
      .. raw:: html
-    
+
         <see
      href="https://repo2docker.readthedocs.io/en/latest/config_files.html#environment-yml-install-a-conda-environment"
      />.
     :vartype conda_file: str
     :ivar environment_type: Environment type is either user managed or curated by the Azure ML
      service
-    
-    
+
+
      .. raw:: html
-    
+
         <see
      href="https://docs.microsoft.com/en-us/azure/machine-learning/resource-curated-environments"
      />. Possible values include: "Curated", "UserCreated".
     :vartype environment_type: str or ~azure.mgmt.machinelearningservices.models.EnvironmentType
     :ivar image: Name of the image that will be used for the environment.
-    
-    
+
+
      .. raw:: html
-    
+
         <seealso
      href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-custom-docker-image#use-a-custom-base-image"
      />.
     :vartype image: str
     :ivar inference_config: Defines configuration specific to inference.
     :vartype inference_config:
      ~azure.mgmt.machinelearningservices.models.InferenceContainerProperties
@@ -2973,37 +2992,34 @@
     :ivar os_type: The OS type of the environment. Possible values include: "Linux", "Windows".
     :vartype os_type: str or ~azure.mgmt.machinelearningservices.models.OperatingSystemType
     :ivar stage: Stage in the environment lifecycle assigned to this environment.
     :vartype stage: str
     """
 
     _validation = {
-        'environment_type': {'readonly': True},
+        "environment_type": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'build': {'key': 'build', 'type': 'BuildContext'},
-        'conda_file': {'key': 'condaFile', 'type': 'str'},
-        'environment_type': {'key': 'environmentType', 'type': 'str'},
-        'image': {'key': 'image', 'type': 'str'},
-        'inference_config': {'key': 'inferenceConfig', 'type': 'InferenceContainerProperties'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
-        'os_type': {'key': 'osType', 'type': 'str'},
-        'stage': {'key': 'stage', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "build": {"key": "build", "type": "BuildContext"},
+        "conda_file": {"key": "condaFile", "type": "str"},
+        "environment_type": {"key": "environmentType", "type": "str"},
+        "image": {"key": "image", "type": "str"},
+        "inference_config": {"key": "inferenceConfig", "type": "InferenceContainerProperties"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
+        "os_type": {"key": "osType", "type": "str"},
+        "stage": {"key": "stage", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -3011,27 +3027,27 @@
         :paramtype is_anonymous: bool
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword build: Configuration settings for Docker build context.
         :paramtype build: ~azure.mgmt.machinelearningservices.models.BuildContext
         :keyword conda_file: Standard configuration file used by Conda that lets you install any kind
          of package, including Python, R, and C/C++ packages.
-        
-        
+
+
          .. raw:: html
-        
+
             <see
          href="https://repo2docker.readthedocs.io/en/latest/config_files.html#environment-yml-install-a-conda-environment"
          />.
         :paramtype conda_file: str
         :keyword image: Name of the image that will be used for the environment.
-        
-        
+
+
          .. raw:: html
-        
+
             <seealso
          href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-custom-docker-image#use-a-custom-base-image"
          />.
         :paramtype image: str
         :keyword inference_config: Defines configuration specific to inference.
         :paramtype inference_config:
          ~azure.mgmt.machinelearningservices.models.InferenceContainerProperties
@@ -3041,82 +3057,75 @@
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         :keyword os_type: The OS type of the environment. Possible values include: "Linux", "Windows".
         :paramtype os_type: str or ~azure.mgmt.machinelearningservices.models.OperatingSystemType
         :keyword stage: Stage in the environment lifecycle assigned to this environment.
         :paramtype stage: str
         """
         super(EnvironmentVersionDetails, self).__init__(**kwargs)
-        self.build = kwargs.get('build', None)
-        self.conda_file = kwargs.get('conda_file', None)
+        self.build = kwargs.get("build", None)
+        self.conda_file = kwargs.get("conda_file", None)
         self.environment_type = None
-        self.image = kwargs.get('image', None)
-        self.inference_config = kwargs.get('inference_config', None)
-        self.intellectual_property = kwargs.get('intellectual_property', None)
-        self.os_type = kwargs.get('os_type', None)
-        self.stage = kwargs.get('stage', None)
+        self.image = kwargs.get("image", None)
+        self.inference_config = kwargs.get("inference_config", None)
+        self.intellectual_property = kwargs.get("intellectual_property", None)
+        self.os_type = kwargs.get("os_type", None)
+        self.stage = kwargs.get("stage", None)
 
 
 class EnvironmentVersionResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of EnvironmentVersion entities.
 
     :ivar next_link: The link to the next page of EnvironmentVersion objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type EnvironmentVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[EnvironmentVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[EnvironmentVersionData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of EnvironmentVersion objects. If null, there are
          no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type EnvironmentVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentVersionData]
         """
         super(EnvironmentVersionResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class ErrorAdditionalInfo(msrest.serialization.Model):
     """The resource management error additional info.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     :ivar type: The additional info type.
     :vartype type: str
     :ivar info: The additional info.
     :vartype info: any
     """
 
     _validation = {
-        'type': {'readonly': True},
-        'info': {'readonly': True},
+        "type": {"readonly": True},
+        "info": {"readonly": True},
     }
 
     _attribute_map = {
-        'type': {'key': 'type', 'type': 'str'},
-        'info': {'key': 'info', 'type': 'object'},
+        "type": {"key": "type", "type": "str"},
+        "info": {"key": "info", "type": "object"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(ErrorAdditionalInfo, self).__init__(**kwargs)
         self.type = None
         self.info = None
 
 
 class ErrorDetail(msrest.serialization.Model):
     """The error detail.
@@ -3132,35 +3141,31 @@
     :ivar details: The error details.
     :vartype details: list[~azure.mgmt.machinelearningservices.models.ErrorDetail]
     :ivar additional_info: The error additional info.
     :vartype additional_info: list[~azure.mgmt.machinelearningservices.models.ErrorAdditionalInfo]
     """
 
     _validation = {
-        'code': {'readonly': True},
-        'message': {'readonly': True},
-        'target': {'readonly': True},
-        'details': {'readonly': True},
-        'additional_info': {'readonly': True},
+        "code": {"readonly": True},
+        "message": {"readonly": True},
+        "target": {"readonly": True},
+        "details": {"readonly": True},
+        "additional_info": {"readonly": True},
     }
 
     _attribute_map = {
-        'code': {'key': 'code', 'type': 'str'},
-        'message': {'key': 'message', 'type': 'str'},
-        'target': {'key': 'target', 'type': 'str'},
-        'details': {'key': 'details', 'type': '[ErrorDetail]'},
-        'additional_info': {'key': 'additionalInfo', 'type': '[ErrorAdditionalInfo]'},
+        "code": {"key": "code", "type": "str"},
+        "message": {"key": "message", "type": "str"},
+        "target": {"key": "target", "type": "str"},
+        "details": {"key": "details", "type": "[ErrorDetail]"},
+        "additional_info": {"key": "additionalInfo", "type": "[ErrorAdditionalInfo]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(ErrorDetail, self).__init__(**kwargs)
         self.code = None
         self.message = None
         self.target = None
         self.details = None
         self.additional_info = None
 
@@ -3169,50 +3174,44 @@
     """Common error response for all Azure Resource Manager APIs to return error details for failed operations. (This also follows the OData error response format.).
 
     :ivar error: The error object.
     :vartype error: ~azure.mgmt.machinelearningservices.models.ErrorDetail
     """
 
     _attribute_map = {
-        'error': {'key': 'error', 'type': 'ErrorDetail'},
+        "error": {"key": "error", "type": "ErrorDetail"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword error: The error object.
         :paramtype error: ~azure.mgmt.machinelearningservices.models.ErrorDetail
         """
         super(ErrorResponse, self).__init__(**kwargs)
-        self.error = kwargs.get('error', None)
+        self.error = kwargs.get("error", None)
 
 
 class FlavorData(msrest.serialization.Model):
     """FlavorData.
 
     :ivar data: Model flavor-specific data.
     :vartype data: dict[str, str]
     """
 
     _attribute_map = {
-        'data': {'key': 'data', 'type': '{str}'},
+        "data": {"key": "data", "type": "{str}"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword data: Model flavor-specific data.
         :paramtype data: dict[str, str]
         """
         super(FlavorData, self).__init__(**kwargs)
-        self.data = kwargs.get('data', None)
+        self.data = kwargs.get("data", None)
 
 
 class IdAssetReference(AssetReferenceBase):
     """Reference to an asset via its ARM resource ID.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -3220,34 +3219,31 @@
      server. Possible values include: "Id", "DataPath", "OutputPath".
     :vartype reference_type: str or ~azure.mgmt.machinelearningservices.models.ReferenceType
     :ivar asset_id: Required. ARM resource ID of the asset.
     :vartype asset_id: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
-        'asset_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "reference_type": {"required": True},
+        "asset_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'asset_id': {'key': 'assetId', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "asset_id": {"key": "assetId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword asset_id: Required. ARM resource ID of the asset.
         :paramtype asset_id: str
         """
         super(IdAssetReference, self).__init__(**kwargs)
-        self.reference_type = 'Id'  # type: str
-        self.asset_id = kwargs['asset_id']
+        self.reference_type = "Id"  # type: str
+        self.asset_id = kwargs["asset_id"]
 
 
 class ImageReferenceForConsumptionDto(msrest.serialization.Model):
     """ImageReferenceForConsumptionDto.
 
     :ivar acr_details:
     :vartype acr_details: ~azure.mgmt.machinelearningservices.models.AcrDetail
@@ -3256,39 +3252,36 @@
     :ivar image_name:
     :vartype image_name: str
     :ivar image_registry_reference:
     :vartype image_registry_reference: str
     """
 
     _attribute_map = {
-        'acr_details': {'key': 'acrDetails', 'type': 'AcrDetail'},
-        'credential': {'key': 'credential', 'type': 'DataReferenceCredentialDto'},
-        'image_name': {'key': 'imageName', 'type': 'str'},
-        'image_registry_reference': {'key': 'imageRegistryReference', 'type': 'str'},
+        "acr_details": {"key": "acrDetails", "type": "AcrDetail"},
+        "credential": {"key": "credential", "type": "DataReferenceCredentialDto"},
+        "image_name": {"key": "imageName", "type": "str"},
+        "image_registry_reference": {"key": "imageRegistryReference", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword acr_details:
         :paramtype acr_details: ~azure.mgmt.machinelearningservices.models.AcrDetail
         :keyword credential:
         :paramtype credential: ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialDto
         :keyword image_name:
         :paramtype image_name: str
         :keyword image_registry_reference:
         :paramtype image_registry_reference: str
         """
         super(ImageReferenceForConsumptionDto, self).__init__(**kwargs)
-        self.acr_details = kwargs.get('acr_details', None)
-        self.credential = kwargs.get('credential', None)
-        self.image_name = kwargs.get('image_name', None)
-        self.image_registry_reference = kwargs.get('image_registry_reference', None)
+        self.acr_details = kwargs.get("acr_details", None)
+        self.credential = kwargs.get("credential", None)
+        self.image_name = kwargs.get("image_name", None)
+        self.image_registry_reference = kwargs.get("image_registry_reference", None)
 
 
 class InferenceContainerProperties(msrest.serialization.Model):
     """InferenceContainerProperties.
 
     :ivar liveness_route: The route to check the liveness of the inference server container.
     :vartype liveness_route: ~azure.mgmt.machinelearningservices.models.Route
@@ -3296,36 +3289,33 @@
     :vartype readiness_route: ~azure.mgmt.machinelearningservices.models.Route
     :ivar scoring_route: The port to send the scoring requests to, within the inference server
      container.
     :vartype scoring_route: ~azure.mgmt.machinelearningservices.models.Route
     """
 
     _attribute_map = {
-        'liveness_route': {'key': 'livenessRoute', 'type': 'Route'},
-        'readiness_route': {'key': 'readinessRoute', 'type': 'Route'},
-        'scoring_route': {'key': 'scoringRoute', 'type': 'Route'},
+        "liveness_route": {"key": "livenessRoute", "type": "Route"},
+        "readiness_route": {"key": "readinessRoute", "type": "Route"},
+        "scoring_route": {"key": "scoringRoute", "type": "Route"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword liveness_route: The route to check the liveness of the inference server container.
         :paramtype liveness_route: ~azure.mgmt.machinelearningservices.models.Route
         :keyword readiness_route: The route to check the readiness of the inference server container.
         :paramtype readiness_route: ~azure.mgmt.machinelearningservices.models.Route
         :keyword scoring_route: The port to send the scoring requests to, within the inference server
          container.
         :paramtype scoring_route: ~azure.mgmt.machinelearningservices.models.Route
         """
         super(InferenceContainerProperties, self).__init__(**kwargs)
-        self.liveness_route = kwargs.get('liveness_route', None)
-        self.readiness_route = kwargs.get('readiness_route', None)
-        self.scoring_route = kwargs.get('scoring_route', None)
+        self.liveness_route = kwargs.get("liveness_route", None)
+        self.readiness_route = kwargs.get("readiness_route", None)
+        self.scoring_route = kwargs.get("scoring_route", None)
 
 
 class IntellectualProperty(msrest.serialization.Model):
     """Intellectual Property details for a resource.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -3334,37 +3324,34 @@
     :vartype protection_level: str or ~azure.mgmt.machinelearningservices.models.ProtectionLevel
     :ivar publisher: Required. Publisher of the Intellectual Property. Must be the same as Registry
      publisher name.
     :vartype publisher: str
     """
 
     _validation = {
-        'publisher': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "publisher": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'protection_level': {'key': 'protectionLevel', 'type': 'str'},
-        'publisher': {'key': 'publisher', 'type': 'str'},
+        "protection_level": {"key": "protectionLevel", "type": "str"},
+        "publisher": {"key": "publisher", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword protection_level: Protection level of the Intellectual Property. Possible values
          include: "All", "None".
         :paramtype protection_level: str or ~azure.mgmt.machinelearningservices.models.ProtectionLevel
         :keyword publisher: Required. Publisher of the Intellectual Property. Must be the same as
          Registry publisher name.
         :paramtype publisher: str
         """
         super(IntellectualProperty, self).__init__(**kwargs)
-        self.protection_level = kwargs.get('protection_level', None)
-        self.publisher = kwargs['publisher']
+        self.protection_level = kwargs.get("protection_level", None)
+        self.publisher = kwargs["publisher"]
 
 
 class Job(JobBase):
     """Basic Job class with all job base properties.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -3396,37 +3383,34 @@
     :ivar status: Status of the job. Possible values include: "NotStarted", "Starting",
      "Provisioning", "Preparing", "Queued", "Running", "Finalizing", "CancelRequested", "Completed",
      "Failed", "Canceled", "NotResponding", "Paused", "Unknown".
     :vartype status: str or ~azure.mgmt.machinelearningservices.models.JobStatus
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -3440,15 +3424,15 @@
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword services: List of JobEndpoints.
          For local jobs, a job endpoint will have an endpoint value of FileStreamObject.
         :paramtype services: dict[str, ~azure.mgmt.machinelearningservices.models.JobService]
         """
         super(Job, self).__init__(**kwargs)
-        self.job_type = 'Base'  # type: str
+        self.job_type = "Base"  # type: str
 
 
 class JobInput(msrest.serialization.Model):
     """Command job definition.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: JobInputDataset, JobInputLiteral, JobInputUri.
@@ -3459,36 +3443,33 @@
     :vartype description: str
     :ivar job_input_type: Required. Specifies the type of job.Constant filled by server. Possible
      values include: "Dataset", "Uri", "Literal".
     :vartype job_input_type: str or ~azure.mgmt.machinelearningservices.models.JobInputType
     """
 
     _validation = {
-        'job_input_type': {'required': True},
+        "job_input_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
     }
 
     _subtype_map = {
-        'job_input_type': {'Dataset': 'JobInputDataset', 'Literal': 'JobInputLiteral', 'Uri': 'JobInputUri'}
+        "job_input_type": {"Dataset": "JobInputDataset", "Literal": "JobInputLiteral", "Uri": "JobInputUri"}
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: Description for the input.
         :paramtype description: str
         """
         super(JobInput, self).__init__(**kwargs)
-        self.description = kwargs.get('description', None)
+        self.description = kwargs.get("description", None)
         self.job_input_type = None  # type: Optional[str]
 
 
 class JobInputDataset(JobInput):
     """InputDataset type.
 
     All required parameters must be populated in order to send to Azure.
@@ -3502,42 +3483,39 @@
     :vartype dataset_id: str
     :ivar mode: Dataset Delivery Mode. Possible values include: "ReadOnlyMount", "ReadWriteMount",
      "Download".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
     """
 
     _validation = {
-        'job_input_type': {'required': True},
-        'dataset_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "job_input_type": {"required": True},
+        "dataset_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
-        'dataset_id': {'key': 'datasetId', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
+        "dataset_id": {"key": "datasetId", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: Description for the input.
         :paramtype description: str
         :keyword dataset_id: Required. Dataset ARM Id for the input.
         :paramtype dataset_id: str
         :keyword mode: Dataset Delivery Mode. Possible values include: "ReadOnlyMount",
          "ReadWriteMount", "Download".
         :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
         """
         super(JobInputDataset, self).__init__(**kwargs)
-        self.job_input_type = 'Dataset'  # type: str
-        self.dataset_id = kwargs['dataset_id']
-        self.mode = kwargs.get('mode', None)
+        self.job_input_type = "Dataset"  # type: str
+        self.dataset_id = kwargs["dataset_id"]
+        self.mode = kwargs.get("mode", None)
 
 
 class JobInputLiteral(JobInput):
     """Literal input type.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -3547,36 +3525,33 @@
      values include: "Dataset", "Uri", "Literal".
     :vartype job_input_type: str or ~azure.mgmt.machinelearningservices.models.JobInputType
     :ivar value: Literal value for the input.
     :vartype value: str
     """
 
     _validation = {
-        'job_input_type': {'required': True},
+        "job_input_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
-        'value': {'key': 'value', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
+        "value": {"key": "value", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: Description for the input.
         :paramtype description: str
         :keyword value: Literal value for the input.
         :paramtype value: str
         """
         super(JobInputLiteral, self).__init__(**kwargs)
-        self.job_input_type = 'Literal'  # type: str
-        self.value = kwargs.get('value', None)
+        self.job_input_type = "Literal"  # type: str
+        self.value = kwargs.get("value", None)
 
 
 class JobInputUri(JobInput):
     """Input uri type.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -3589,42 +3564,39 @@
      "ReadWriteMount", "Download".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
     :ivar uri: Required. Uri path.
     :vartype uri: ~azure.mgmt.machinelearningservices.models.UriReference
     """
 
     _validation = {
-        'job_input_type': {'required': True},
-        'uri': {'required': True},
+        "job_input_type": {"required": True},
+        "uri": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
-        'uri': {'key': 'uri', 'type': 'UriReference'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
+        "uri": {"key": "uri", "type": "UriReference"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: Description for the input.
         :paramtype description: str
         :keyword mode: Input Uri Delivery Mode. Possible values include: "ReadOnlyMount",
          "ReadWriteMount", "Download".
         :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
         :keyword uri: Required. Uri path.
         :paramtype uri: ~azure.mgmt.machinelearningservices.models.UriReference
         """
         super(JobInputUri, self).__init__(**kwargs)
-        self.job_input_type = 'Uri'  # type: str
-        self.mode = kwargs.get('mode', None)
-        self.uri = kwargs['uri']
+        self.job_input_type = "Uri"  # type: str
+        self.mode = kwargs.get("mode", None)
+        self.uri = kwargs["uri"]
 
 
 class JobOutput(msrest.serialization.Model):
     """Job output definition container information on where to find job output/logs.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: JobOutputDataset, JobOutputUri.
@@ -3635,36 +3607,31 @@
     :vartype description: str
     :ivar job_output_type: Required. Specifies the type of job.Constant filled by server. Possible
      values include: "Uri", "Dataset".
     :vartype job_output_type: str or ~azure.mgmt.machinelearningservices.models.JobOutputType
     """
 
     _validation = {
-        'job_output_type': {'required': True},
+        "job_output_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_output_type': {'key': 'jobOutputType', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_output_type": {"key": "jobOutputType", "type": "str"},
     }
 
-    _subtype_map = {
-        'job_output_type': {'Dataset': 'JobOutputDataset', 'Uri': 'JobOutputUri'}
-    }
+    _subtype_map = {"job_output_type": {"Dataset": "JobOutputDataset", "Uri": "JobOutputUri"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: Description for the output.
         :paramtype description: str
         """
         super(JobOutput, self).__init__(**kwargs)
-        self.description = kwargs.get('description', None)
+        self.description = kwargs.get("description", None)
         self.job_output_type = None  # type: Optional[str]
 
 
 class JobOutputDataset(JobOutput):
     """Dataset output.
 
     All required parameters must be populated in order to send to Azure.
@@ -3675,36 +3642,33 @@
      values include: "Uri", "Dataset".
     :vartype job_output_type: str or ~azure.mgmt.machinelearningservices.models.JobOutputType
     :ivar mode: Output Delivery Mode. Possible values include: "ReadWriteMount", "Upload".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.OutputDataDeliveryMode
     """
 
     _validation = {
-        'job_output_type': {'required': True},
+        "job_output_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_output_type': {'key': 'jobOutputType', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_output_type": {"key": "jobOutputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: Description for the output.
         :paramtype description: str
         :keyword mode: Output Delivery Mode. Possible values include: "ReadWriteMount", "Upload".
         :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.OutputDataDeliveryMode
         """
         super(JobOutputDataset, self).__init__(**kwargs)
-        self.job_output_type = 'Dataset'  # type: str
-        self.mode = kwargs.get('mode', None)
+        self.job_output_type = "Dataset"  # type: str
+        self.mode = kwargs.get("mode", None)
 
 
 class JobOutputUri(JobOutput):
     """Uri output.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -3718,36 +3682,33 @@
     :ivar mode: Output Delivery Mode. Possible values include: "ReadWriteMount", "Upload".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.OutputDataDeliveryMode
     :ivar uri: Uri path.
     :vartype uri: ~azure.mgmt.machinelearningservices.models.UriReference
     """
 
     _validation = {
-        'job_output_type': {'required': True},
-        'mode': {'readonly': True},
-        'uri': {'readonly': True},
+        "job_output_type": {"required": True},
+        "mode": {"readonly": True},
+        "uri": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_output_type': {'key': 'jobOutputType', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
-        'uri': {'key': 'uri', 'type': 'UriReference'},
+        "description": {"key": "description", "type": "str"},
+        "job_output_type": {"key": "jobOutputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
+        "uri": {"key": "uri", "type": "UriReference"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: Description for the output.
         :paramtype description: str
         """
         super(JobOutputUri, self).__init__(**kwargs)
-        self.job_output_type = 'Uri'  # type: str
+        self.job_output_type = "Uri"  # type: str
         self.mode = None
         self.uri = None
 
 
 class JobService(msrest.serialization.Model):
     """Job endpoint definition.
 
@@ -3764,47 +3725,44 @@
     :ivar properties: Additional properties to set on the endpoint.
     :vartype properties: dict[str, str]
     :ivar status: Status of endpoint.
     :vartype status: str
     """
 
     _validation = {
-        'error_message': {'readonly': True},
-        'status': {'readonly': True},
+        "error_message": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'error_message': {'key': 'errorMessage', 'type': 'str'},
-        'job_service_type': {'key': 'jobServiceType', 'type': 'str'},
-        'port': {'key': 'port', 'type': 'int'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'status': {'key': 'status', 'type': 'str'},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "error_message": {"key": "errorMessage", "type": "str"},
+        "job_service_type": {"key": "jobServiceType", "type": "str"},
+        "port": {"key": "port", "type": "int"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "status": {"key": "status", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword endpoint: Url for endpoint.
         :paramtype endpoint: str
         :keyword job_service_type: Endpoint type.
         :paramtype job_service_type: str
         :keyword port: Port for endpoint.
         :paramtype port: int
         :keyword properties: Additional properties to set on the endpoint.
         :paramtype properties: dict[str, str]
         """
         super(JobService, self).__init__(**kwargs)
-        self.endpoint = kwargs.get('endpoint', None)
+        self.endpoint = kwargs.get("endpoint", None)
         self.error_message = None
-        self.job_service_type = kwargs.get('job_service_type', None)
-        self.port = kwargs.get('port', None)
-        self.properties = kwargs.get('properties', None)
+        self.job_service_type = kwargs.get("job_service_type", None)
+        self.port = kwargs.get("port", None)
+        self.properties = kwargs.get("properties", None)
         self.status = None
 
 
 class ManagedIdentity(IdentityConfiguration):
     """Managed identity configuration.
 
     All required parameters must be populated in order to send to Azure.
@@ -3821,55 +3779,46 @@
     :vartype object_id: str
     :ivar resource_id: Specifies a user-assigned identity by ARM resource ID. For system-assigned,
      do not set this field.
     :vartype resource_id: str
     """
 
     _validation = {
-        'identity_type': {'required': True},
+        "identity_type": {"required": True},
     }
 
     _attribute_map = {
-        'identity_type': {'key': 'identityType', 'type': 'str'},
-        'client_id': {'key': 'clientId', 'type': 'str'},
-        'object_id': {'key': 'objectId', 'type': 'str'},
-        'resource_id': {'key': 'resourceId', 'type': 'str'},
+        "identity_type": {"key": "identityType", "type": "str"},
+        "client_id": {"key": "clientId", "type": "str"},
+        "object_id": {"key": "objectId", "type": "str"},
+        "resource_id": {"key": "resourceId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword client_id: Specifies a user-assigned identity by client ID. For system-assigned, do
          not set this field.
         :paramtype client_id: str
         :keyword object_id: Specifies a user-assigned identity by object ID. For system-assigned, do
          not set this field.
         :paramtype object_id: str
         :keyword resource_id: Specifies a user-assigned identity by ARM resource ID. For
          system-assigned, do not set this field.
         :paramtype resource_id: str
         """
         super(ManagedIdentity, self).__init__(**kwargs)
-        self.identity_type = 'Managed'  # type: str
-        self.client_id = kwargs.get('client_id', None)
-        self.object_id = kwargs.get('object_id', None)
-        self.resource_id = kwargs.get('resource_id', None)
+        self.identity_type = "Managed"  # type: str
+        self.client_id = kwargs.get("client_id", None)
+        self.object_id = kwargs.get("object_id", None)
+        self.resource_id = kwargs.get("resource_id", None)
 
 
-class ManagedIdentityCredentialDto(DataReferenceCredentialDto):
+class ManagedIdentityCredentialDto(msrest.serialization.Model):
     """ManagedIdentityCredentialDto.
 
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
     :ivar managed_identity_type:
     :vartype managed_identity_type: str
     :ivar user_managed_identity_client_id: ClientId for the UAMI. For ManagedIdentityType =
      SystemManaged, this field is null.
     :vartype user_managed_identity_client_id: str
     :ivar user_managed_identity_principal_id: PrincipalId for the UAMI. For ManagedIdentityType =
      SystemManaged, this field is null.
@@ -3878,31 +3827,23 @@
      SystemManaged, this field is null.
     :vartype user_managed_identity_resource_id: str
     :ivar user_managed_identity_tenant_id: TenantId for the UAMI. For ManagedIdentityType =
      SystemManaged, this field is null.
     :vartype user_managed_identity_tenant_id: str
     """
 
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
     _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-        'managed_identity_type': {'key': 'managedIdentityType', 'type': 'str'},
-        'user_managed_identity_client_id': {'key': 'userManagedIdentityClientId', 'type': 'str'},
-        'user_managed_identity_principal_id': {'key': 'userManagedIdentityPrincipalId', 'type': 'str'},
-        'user_managed_identity_resource_id': {'key': 'userManagedIdentityResourceId', 'type': 'str'},
-        'user_managed_identity_tenant_id': {'key': 'userManagedIdentityTenantId', 'type': 'str'},
+        "managed_identity_type": {"key": "managedIdentityType", "type": "str"},
+        "user_managed_identity_client_id": {"key": "userManagedIdentityClientId", "type": "str"},
+        "user_managed_identity_principal_id": {"key": "userManagedIdentityPrincipalId", "type": "str"},
+        "user_managed_identity_resource_id": {"key": "userManagedIdentityResourceId", "type": "str"},
+        "user_managed_identity_tenant_id": {"key": "userManagedIdentityTenantId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword managed_identity_type:
         :paramtype managed_identity_type: str
         :keyword user_managed_identity_client_id: ClientId for the UAMI. For ManagedIdentityType =
          SystemManaged, this field is null.
         :paramtype user_managed_identity_client_id: str
         :keyword user_managed_identity_principal_id: PrincipalId for the UAMI. For ManagedIdentityType
@@ -3912,20 +3853,19 @@
          = SystemManaged, this field is null.
         :paramtype user_managed_identity_resource_id: str
         :keyword user_managed_identity_tenant_id: TenantId for the UAMI. For ManagedIdentityType =
          SystemManaged, this field is null.
         :paramtype user_managed_identity_tenant_id: str
         """
         super(ManagedIdentityCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'ManagedIdentity'  # type: str
-        self.managed_identity_type = kwargs.get('managed_identity_type', None)
-        self.user_managed_identity_client_id = kwargs.get('user_managed_identity_client_id', None)
-        self.user_managed_identity_principal_id = kwargs.get('user_managed_identity_principal_id', None)
-        self.user_managed_identity_resource_id = kwargs.get('user_managed_identity_resource_id', None)
-        self.user_managed_identity_tenant_id = kwargs.get('user_managed_identity_tenant_id', None)
+        self.managed_identity_type = kwargs.get("managed_identity_type", None)
+        self.user_managed_identity_client_id = kwargs.get("user_managed_identity_client_id", None)
+        self.user_managed_identity_principal_id = kwargs.get("user_managed_identity_principal_id", None)
+        self.user_managed_identity_resource_id = kwargs.get("user_managed_identity_resource_id", None)
+        self.user_managed_identity_tenant_id = kwargs.get("user_managed_identity_tenant_id", None)
 
 
 class MedianStoppingPolicy(EarlyTerminationPolicy):
     """Defines an early termination policy based on running averages of the primary metric of all runs.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -3936,35 +3876,32 @@
     :ivar policy_type: Required. Name of policy configuration.Constant filled by server. Possible
      values include: "Bandit", "MedianStopping", "TruncationSelection".
     :vartype policy_type: str or
      ~azure.mgmt.machinelearningservices.models.EarlyTerminationPolicyType
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword delay_evaluation: Number of intervals by which to delay the first evaluation.
         :paramtype delay_evaluation: int
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         """
         super(MedianStoppingPolicy, self).__init__(**kwargs)
-        self.policy_type = 'MedianStopping'  # type: str
+        self.policy_type = "MedianStopping"  # type: str
 
 
 class MLTableData(DataVersionBaseDetails):
     """MLTable data definition.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -3988,34 +3925,31 @@
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     :ivar referenced_uris: Uris referenced in the MLTable definition (required for lineage).
     :vartype referenced_uris: list[str]
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
-        'referenced_uris': {'key': 'referencedUris', 'type': '[str]'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
+        "referenced_uris": {"key": "referencedUris", "type": "[str]"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -4030,16 +3964,42 @@
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         :keyword referenced_uris: Uris referenced in the MLTable definition (required for lineage).
         :paramtype referenced_uris: list[str]
         """
         super(MLTableData, self).__init__(**kwargs)
-        self.data_type = 'mltable'  # type: str
-        self.referenced_uris = kwargs.get('referenced_uris', None)
+        self.data_type = "mltable"  # type: str
+        self.referenced_uris = kwargs.get("referenced_uris", None)
+
+
+class ModelConfiguration(msrest.serialization.Model):
+    """Model configuration options.
+
+    :ivar mode: Input delivery mode for the model. Possible values include: "Copy", "Download".
+    :vartype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+    :ivar mount_path: Relative mounting path of the model in the target image.
+    :vartype mount_path: str
+    """
+
+    _attribute_map = {
+        "mode": {"key": "mode", "type": "str"},
+        "mount_path": {"key": "mountPath", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword mode: Input delivery mode for the model. Possible values include: "Copy", "Download".
+        :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+        :keyword mount_path: Relative mounting path of the model in the target image.
+        :paramtype mount_path: str
+        """
+        super(ModelConfiguration, self).__init__(**kwargs)
+        self.mode = kwargs.get("mode", None)
+        self.mount_path = kwargs.get("mount_path", None)
 
 
 class ModelContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -4057,39 +4017,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ModelContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ModelContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ModelContainerDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ModelContainerDetails
         """
         super(ModelContainerData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class ModelContainerDetails(AssetContainer):
     """ModelContainerDetails.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -4104,31 +4061,28 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -4145,32 +4099,76 @@
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ModelContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ModelContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ModelContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ModelContainerData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of ModelContainer objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ModelContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ModelContainerData]
         """
         super(ModelContainerResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
+
+
+class ModelPackageInput(msrest.serialization.Model):
+    """Model package input options.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_type: Required. Type of the input included in the target image. Possible values
+     include: "UriFile", "UriFolder".
+    :vartype input_type: str or ~azure.mgmt.machinelearningservices.models.PackageInputType
+    :ivar mode: Input delivery mode of the input. Possible values include: "Copy", "Download".
+    :vartype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+    :ivar mount_path: Relative mount path of the input in the target image.
+    :vartype mount_path: str
+    :ivar path: Required. Location of the input.
+    :vartype path: ~azure.mgmt.machinelearningservices.models.PackageInputPathBase
+    """
+
+    _validation = {
+        "input_type": {"required": True},
+        "path": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_type": {"key": "inputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
+        "mount_path": {"key": "mountPath", "type": "str"},
+        "path": {"key": "path", "type": "PackageInputPathBase"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword input_type: Required. Type of the input included in the target image. Possible values
+         include: "UriFile", "UriFolder".
+        :paramtype input_type: str or ~azure.mgmt.machinelearningservices.models.PackageInputType
+        :keyword mode: Input delivery mode of the input. Possible values include: "Copy", "Download".
+        :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+        :keyword mount_path: Relative mount path of the input in the target image.
+        :paramtype mount_path: str
+        :keyword path: Required. Location of the input.
+        :paramtype path: ~azure.mgmt.machinelearningservices.models.PackageInputPathBase
+        """
+        super(ModelPackageInput, self).__init__(**kwargs)
+        self.input_type = kwargs["input_type"]
+        self.mode = kwargs.get("mode", None)
+        self.mount_path = kwargs.get("mount_path", None)
+        self.path = kwargs["path"]
 
 
 class ModelVersionData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -4188,39 +4186,36 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ModelVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ModelVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ModelVersionDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ModelVersionDetails
         """
         super(ModelVersionData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class ModelVersionDetails(AssetBase):
     """Model asset version details.
 
     :ivar description: The asset description text.
     :vartype description: str
@@ -4244,31 +4239,28 @@
     :ivar model_uri: The URI path to the model contents.
     :vartype model_uri: str
     :ivar origin_asset_id: AssetId of origin model.
     :vartype origin_asset_id: str
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'flavors': {'key': 'flavors', 'type': '{FlavorData}'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
-        'job_name': {'key': 'jobName', 'type': 'str'},
-        'model_type': {'key': 'modelType', 'type': 'str'},
-        'model_uri': {'key': 'modelUri', 'type': 'str'},
-        'origin_asset_id': {'key': 'originAssetId', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "flavors": {"key": "flavors", "type": "{FlavorData}"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
+        "job_name": {"key": "jobName", "type": "str"},
+        "model_type": {"key": "modelType", "type": "str"},
+        "model_uri": {"key": "modelUri", "type": "str"},
+        "origin_asset_id": {"key": "originAssetId", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -4288,51 +4280,48 @@
         :paramtype model_type: str
         :keyword model_uri: The URI path to the model contents.
         :paramtype model_uri: str
         :keyword origin_asset_id: AssetId of origin model.
         :paramtype origin_asset_id: str
         """
         super(ModelVersionDetails, self).__init__(**kwargs)
-        self.flavors = kwargs.get('flavors', None)
-        self.intellectual_property = kwargs.get('intellectual_property', None)
-        self.job_name = kwargs.get('job_name', None)
-        self.model_type = kwargs.get('model_type', None)
-        self.model_uri = kwargs.get('model_uri', None)
-        self.origin_asset_id = kwargs.get('origin_asset_id', None)
+        self.flavors = kwargs.get("flavors", None)
+        self.intellectual_property = kwargs.get("intellectual_property", None)
+        self.job_name = kwargs.get("job_name", None)
+        self.model_type = kwargs.get("model_type", None)
+        self.model_uri = kwargs.get("model_uri", None)
+        self.origin_asset_id = kwargs.get("origin_asset_id", None)
 
 
 class ModelVersionResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of ModelVersion entities.
 
     :ivar next_link: The link to the next page of ModelVersion objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ModelVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ModelVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ModelVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ModelVersionData]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword next_link: The link to the next page of ModelVersion objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ModelVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ModelVersionData]
         """
         super(ModelVersionResourceArmPaginatedResult, self).__init__(**kwargs)
-        self.next_link = kwargs.get('next_link', None)
-        self.value = kwargs.get('value', None)
+        self.next_link = kwargs.get("next_link", None)
+        self.value = kwargs.get("value", None)
 
 
 class Mpi(DistributionConfiguration):
     """MPI distribution configuration.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4340,62 +4329,55 @@
      by server. Possible values include: "PyTorch", "TensorFlow", "Mpi".
     :vartype distribution_type: str or ~azure.mgmt.machinelearningservices.models.DistributionType
     :ivar process_count_per_instance: Number of processes per MPI node.
     :vartype process_count_per_instance: int
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
-        'process_count_per_instance': {'key': 'processCountPerInstance', 'type': 'int'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
+        "process_count_per_instance": {"key": "processCountPerInstance", "type": "int"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword process_count_per_instance: Number of processes per MPI node.
         :paramtype process_count_per_instance: int
         """
         super(Mpi, self).__init__(**kwargs)
-        self.distribution_type = 'Mpi'  # type: str
-        self.process_count_per_instance = kwargs.get('process_count_per_instance', None)
+        self.distribution_type = "Mpi"  # type: str
+        self.process_count_per_instance = kwargs.get("process_count_per_instance", None)
 
 
 class NoneDatastoreCredentials(DatastoreCredentials):
     """Empty/none datastore credentials.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar credentials_type: Required. Credential type used to authentication with storage.Constant
      filled by server. Possible values include: "AccountKey", "Certificate", "None", "Sas",
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     """
 
     _validation = {
-        'credentials_type': {'required': True},
+        "credentials_type": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(NoneDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'None'  # type: str
+        self.credentials_type = "None"  # type: str
 
 
 class Objective(msrest.serialization.Model):
     """Optimization objective.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4403,37 +4385,80 @@
      include: "Minimize", "Maximize".
     :vartype goal: str or ~azure.mgmt.machinelearningservices.models.Goal
     :ivar primary_metric: Required. Name of the metric to optimize.
     :vartype primary_metric: str
     """
 
     _validation = {
-        'goal': {'required': True},
-        'primary_metric': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "goal": {"required": True},
+        "primary_metric": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'goal': {'key': 'goal', 'type': 'str'},
-        'primary_metric': {'key': 'primaryMetric', 'type': 'str'},
+        "goal": {"key": "goal", "type": "str"},
+        "primary_metric": {"key": "primaryMetric", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword goal: Required. Defines supported metric goals for hyperparameter tuning. Possible
          values include: "Minimize", "Maximize".
         :paramtype goal: str or ~azure.mgmt.machinelearningservices.models.Goal
         :keyword primary_metric: Required. Name of the metric to optimize.
         :paramtype primary_metric: str
         """
         super(Objective, self).__init__(**kwargs)
-        self.goal = kwargs['goal']
-        self.primary_metric = kwargs['primary_metric']
+        self.goal = kwargs["goal"]
+        self.primary_metric = kwargs["primary_metric"]
+
+
+class OnlineInferenceConfiguration(msrest.serialization.Model):
+    """Online inference configuration options.
+
+    :ivar configurations: Additional configurations.
+    :vartype configurations: dict[str, str]
+    :ivar entry_script: Entry script or command to invoke.
+    :vartype entry_script: str
+    :ivar liveness_route: The route to check the liveness of the inference server container.
+    :vartype liveness_route: ~azure.mgmt.machinelearningservices.models.Route
+    :ivar readiness_route: The route to check the readiness of the inference server container.
+    :vartype readiness_route: ~azure.mgmt.machinelearningservices.models.Route
+    :ivar scoring_route: The port to send the scoring requests to, within the inference server
+     container.
+    :vartype scoring_route: ~azure.mgmt.machinelearningservices.models.Route
+    """
+
+    _attribute_map = {
+        "configurations": {"key": "configurations", "type": "{str}"},
+        "entry_script": {"key": "entryScript", "type": "str"},
+        "liveness_route": {"key": "livenessRoute", "type": "Route"},
+        "readiness_route": {"key": "readinessRoute", "type": "Route"},
+        "scoring_route": {"key": "scoringRoute", "type": "Route"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword configurations: Additional configurations.
+        :paramtype configurations: dict[str, str]
+        :keyword entry_script: Entry script or command to invoke.
+        :paramtype entry_script: str
+        :keyword liveness_route: The route to check the liveness of the inference server container.
+        :paramtype liveness_route: ~azure.mgmt.machinelearningservices.models.Route
+        :keyword readiness_route: The route to check the readiness of the inference server container.
+        :paramtype readiness_route: ~azure.mgmt.machinelearningservices.models.Route
+        :keyword scoring_route: The port to send the scoring requests to, within the inference server
+         container.
+        :paramtype scoring_route: ~azure.mgmt.machinelearningservices.models.Route
+        """
+        super(OnlineInferenceConfiguration, self).__init__(**kwargs)
+        self.configurations = kwargs.get("configurations", None)
+        self.entry_script = kwargs.get("entry_script", None)
+        self.liveness_route = kwargs.get("liveness_route", None)
+        self.readiness_route = kwargs.get("readiness_route", None)
+        self.scoring_route = kwargs.get("scoring_route", None)
 
 
 class OutputPathAssetReference(AssetReferenceBase):
     """Reference to an asset via its path in a job output.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4443,37 +4468,330 @@
     :ivar job_id: ARM resource ID of the job.
     :vartype job_id: str
     :ivar path: The path of the file/directory in the job output.
     :vartype path: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
+        "reference_type": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'job_id': {'key': 'jobId', 'type': 'str'},
-        'path': {'key': 'path', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "job_id": {"key": "jobId", "type": "str"},
+        "path": {"key": "path", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword job_id: ARM resource ID of the job.
         :paramtype job_id: str
         :keyword path: The path of the file/directory in the job output.
         :paramtype path: str
         """
         super(OutputPathAssetReference, self).__init__(**kwargs)
-        self.reference_type = 'OutputPath'  # type: str
-        self.job_id = kwargs.get('job_id', None)
-        self.path = kwargs.get('path', None)
+        self.reference_type = "OutputPath"  # type: str
+        self.job_id = kwargs.get("job_id", None)
+        self.path = kwargs.get("path", None)
+
+
+class PackageInputPathBase(msrest.serialization.Model):
+    """PackageInputPathBase.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: PackageInputPathId, PackageInputPathVersion, PackageInputPathUrl.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+    }
+
+    _subtype_map = {
+        "input_path_type": {
+            "PathId": "PackageInputPathId",
+            "PathVersion": "PackageInputPathVersion",
+            "Url": "PackageInputPathUrl",
+        }
+    }
+
+    def __init__(self, **kwargs):
+        """ """
+        super(PackageInputPathBase, self).__init__(**kwargs)
+        self.input_path_type = None  # type: Optional[str]
+
+
+class PackageInputPathId(PackageInputPathBase):
+    """Package input path specified with a resource id.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    :ivar resource_id: Input resource id.
+    :vartype resource_id: str
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+        "resource_id": {"key": "resourceId", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword resource_id: Input resource id.
+        :paramtype resource_id: str
+        """
+        super(PackageInputPathId, self).__init__(**kwargs)
+        self.input_path_type = "PathId"  # type: str
+        self.resource_id = kwargs.get("resource_id", None)
+
+
+class PackageInputPathUrl(PackageInputPathBase):
+    """Package input path specified as an url.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    :ivar url: Input path url.
+    :vartype url: str
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+        "url": {"key": "url", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword url: Input path url.
+        :paramtype url: str
+        """
+        super(PackageInputPathUrl, self).__init__(**kwargs)
+        self.input_path_type = "Url"  # type: str
+        self.url = kwargs.get("url", None)
+
+
+class PackageInputPathVersion(PackageInputPathBase):
+    """Package input path specified with name and version.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    :ivar resource_name: Input resource name.
+    :vartype resource_name: str
+    :ivar resource_version: Input resource version.
+    :vartype resource_version: str
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+        "resource_name": {"key": "resourceName", "type": "str"},
+        "resource_version": {"key": "resourceVersion", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword resource_name: Input resource name.
+        :paramtype resource_name: str
+        :keyword resource_version: Input resource version.
+        :paramtype resource_version: str
+        """
+        super(PackageInputPathVersion, self).__init__(**kwargs)
+        self.input_path_type = "PathVersion"  # type: str
+        self.resource_name = kwargs.get("resource_name", None)
+        self.resource_version = kwargs.get("resource_version", None)
+
+
+class PackageRequest(msrest.serialization.Model):
+    """Model package operation request properties.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar base_environment_source: Base environment to start with.
+    :vartype base_environment_source:
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSource
+    :ivar environment_variables: Collection of environment variables.
+    :vartype environment_variables: dict[str, str]
+    :ivar inferencing_server: Required. Inferencing server configurations.
+    :vartype inferencing_server: ~azure.mgmt.machinelearningservices.models.InferencingServer
+    :ivar inputs: Collection of inputs.
+    :vartype inputs: list[~azure.mgmt.machinelearningservices.models.ModelPackageInput]
+    :ivar model_configuration: Model configuration including the mount mode.
+    :vartype model_configuration: ~azure.mgmt.machinelearningservices.models.ModelConfiguration
+    :ivar properties: Properties dictionary.
+    :vartype properties: dict[str, str]
+    :ivar sku_architecture_type: The sku architecture type.
+    :vartype sku_architecture_type: str
+    :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+    :vartype tags: dict[str, str]
+    :ivar target_environment_id: Required. Arm ID of the target environment to be created by
+     package operation.
+    :vartype target_environment_id: str
+    """
+
+    _validation = {
+        "inferencing_server": {"required": True},
+        "target_environment_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+    }
+
+    _attribute_map = {
+        "base_environment_source": {"key": "baseEnvironmentSource", "type": "BaseEnvironmentSource"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "inferencing_server": {"key": "inferencingServer", "type": "InferencingServer"},
+        "inputs": {"key": "inputs", "type": "[ModelPackageInput]"},
+        "model_configuration": {"key": "modelConfiguration", "type": "ModelConfiguration"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "sku_architecture_type": {"key": "skuArchitectureType", "type": "str"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "target_environment_id": {"key": "targetEnvironmentId", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword base_environment_source: Base environment to start with.
+        :paramtype base_environment_source:
+         ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSource
+        :keyword environment_variables: Collection of environment variables.
+        :paramtype environment_variables: dict[str, str]
+        :keyword inferencing_server: Required. Inferencing server configurations.
+        :paramtype inferencing_server: ~azure.mgmt.machinelearningservices.models.InferencingServer
+        :keyword inputs: Collection of inputs.
+        :paramtype inputs: list[~azure.mgmt.machinelearningservices.models.ModelPackageInput]
+        :keyword model_configuration: Model configuration including the mount mode.
+        :paramtype model_configuration: ~azure.mgmt.machinelearningservices.models.ModelConfiguration
+        :keyword properties: Properties dictionary.
+        :paramtype properties: dict[str, str]
+        :keyword sku_architecture_type: The sku architecture type.
+        :paramtype sku_architecture_type: str
+        :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+        :paramtype tags: dict[str, str]
+        :keyword target_environment_id: Required. Arm ID of the target environment to be created by
+         package operation.
+        :paramtype target_environment_id: str
+        """
+        super(PackageRequest, self).__init__(**kwargs)
+        self.base_environment_source = kwargs.get("base_environment_source", None)
+        self.environment_variables = kwargs.get("environment_variables", None)
+        self.inferencing_server = kwargs["inferencing_server"]
+        self.inputs = kwargs.get("inputs", None)
+        self.model_configuration = kwargs.get("model_configuration", None)
+        self.properties = kwargs.get("properties", None)
+        self.sku_architecture_type = kwargs.get("sku_architecture_type", None)
+        self.tags = kwargs.get("tags", None)
+        self.target_environment_id = kwargs["target_environment_id"]
+
+
+class PackageResponse(msrest.serialization.Model):
+    """Package response returned after async package operation completes successfully.
+
+    Variables are only populated by the server, and will be ignored when sending a request.
+
+    :ivar base_environment_source: Base environment to start with.
+    :vartype base_environment_source:
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSource
+    :ivar build_id: Build id of the image build operation.
+    :vartype build_id: str
+    :ivar build_state: Build state of the image build operation. Possible values include:
+     "NotStarted", "Running", "Succeeded", "Failed".
+    :vartype build_state: str or ~azure.mgmt.machinelearningservices.models.PackageBuildState
+    :ivar environment_variables: Collection of environment variables.
+    :vartype environment_variables: dict[str, str]
+    :ivar inferencing_server: Inferencing server configurations.
+    :vartype inferencing_server: ~azure.mgmt.machinelearningservices.models.InferencingServer
+    :ivar inputs: Collection of inputs.
+    :vartype inputs: list[~azure.mgmt.machinelearningservices.models.ModelPackageInput]
+    :ivar log_url: Log url of the image build operation.
+    :vartype log_url: str
+    :ivar model_configuration: Model configuration including the mount mode.
+    :vartype model_configuration: ~azure.mgmt.machinelearningservices.models.ModelConfiguration
+    :ivar properties: Properties dictionary.
+    :vartype properties: dict[str, str]
+    :ivar sku_architecture_type: The sku architecture type.
+    :vartype sku_architecture_type: str
+    :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+    :vartype tags: dict[str, str]
+    :ivar target_environment_id: Asset ID of the target environment created by package operation.
+    :vartype target_environment_id: str
+    """
+
+    _validation = {
+        "base_environment_source": {"readonly": True},
+        "build_id": {"readonly": True},
+        "build_state": {"readonly": True},
+        "environment_variables": {"readonly": True},
+        "inferencing_server": {"readonly": True},
+        "inputs": {"readonly": True},
+        "log_url": {"readonly": True},
+        "model_configuration": {"readonly": True},
+        "tags": {"readonly": True},
+        "target_environment_id": {"readonly": True},
+    }
+
+    _attribute_map = {
+        "base_environment_source": {"key": "baseEnvironmentSource", "type": "BaseEnvironmentSource"},
+        "build_id": {"key": "buildId", "type": "str"},
+        "build_state": {"key": "buildState", "type": "str"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "inferencing_server": {"key": "inferencingServer", "type": "InferencingServer"},
+        "inputs": {"key": "inputs", "type": "[ModelPackageInput]"},
+        "log_url": {"key": "logUrl", "type": "str"},
+        "model_configuration": {"key": "modelConfiguration", "type": "ModelConfiguration"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "sku_architecture_type": {"key": "skuArchitectureType", "type": "str"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "target_environment_id": {"key": "targetEnvironmentId", "type": "str"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword properties: Properties dictionary.
+        :paramtype properties: dict[str, str]
+        :keyword sku_architecture_type: The sku architecture type.
+        :paramtype sku_architecture_type: str
+        """
+        super(PackageResponse, self).__init__(**kwargs)
+        self.base_environment_source = None
+        self.build_id = None
+        self.build_state = None
+        self.environment_variables = None
+        self.inferencing_server = None
+        self.inputs = None
+        self.log_url = None
+        self.model_configuration = None
+        self.properties = kwargs.get("properties", None)
+        self.sku_architecture_type = kwargs.get("sku_architecture_type", None)
+        self.tags = None
+        self.target_environment_id = None
 
 
 class PipelineJob(JobBase):
     """Pipeline Job definition: defines generic to MFE attributes.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -4515,42 +4833,39 @@
     :ivar outputs: Data output set for jobs.
     :vartype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
     :ivar settings: Pipeline settings, for things like ContinueRunOnStepFailure etc.
     :vartype settings: any
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
-        'bindings': {'key': 'bindings', 'type': '[Binding]'},
-        'component_jobs': {'key': 'componentJobs', 'type': '{ComponentJob}'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'settings': {'key': 'settings', 'type': 'object'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
+        "bindings": {"key": "bindings", "type": "[Binding]"},
+        "component_jobs": {"key": "componentJobs", "type": "{ComponentJob}"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "settings": {"key": "settings", "type": "object"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -4574,20 +4889,20 @@
         :paramtype inputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobInput]
         :keyword outputs: Data output set for jobs.
         :paramtype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
         :keyword settings: Pipeline settings, for things like ContinueRunOnStepFailure etc.
         :paramtype settings: any
         """
         super(PipelineJob, self).__init__(**kwargs)
-        self.job_type = 'Pipeline'  # type: str
-        self.bindings = kwargs.get('bindings', None)
-        self.component_jobs = kwargs.get('component_jobs', None)
-        self.inputs = kwargs.get('inputs', None)
-        self.outputs = kwargs.get('outputs', None)
-        self.settings = kwargs.get('settings', None)
+        self.job_type = "Pipeline"  # type: str
+        self.bindings = kwargs.get("bindings", None)
+        self.component_jobs = kwargs.get("component_jobs", None)
+        self.inputs = kwargs.get("inputs", None)
+        self.outputs = kwargs.get("outputs", None)
+        self.settings = kwargs.get("settings", None)
 
 
 class PyTorch(DistributionConfiguration):
     """PyTorch distribution configuration.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4595,68 +4910,62 @@
      by server. Possible values include: "PyTorch", "TensorFlow", "Mpi".
     :vartype distribution_type: str or ~azure.mgmt.machinelearningservices.models.DistributionType
     :ivar process_count_per_instance: Number of processes per node.
     :vartype process_count_per_instance: int
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
-        'process_count_per_instance': {'key': 'processCountPerInstance', 'type': 'int'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
+        "process_count_per_instance": {"key": "processCountPerInstance", "type": "int"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword process_count_per_instance: Number of processes per node.
         :paramtype process_count_per_instance: int
         """
         super(PyTorch, self).__init__(**kwargs)
-        self.distribution_type = 'PyTorch'  # type: str
-        self.process_count_per_instance = kwargs.get('process_count_per_instance', None)
+        self.distribution_type = "PyTorch"  # type: str
+        self.process_count_per_instance = kwargs.get("process_count_per_instance", None)
 
 
 class ResourceConfiguration(msrest.serialization.Model):
     """ResourceConfiguration.
 
     :ivar instance_count: Optional number of instances or nodes used by the compute target.
     :vartype instance_count: int
     :ivar instance_type: Optional type of VM used as supported by the compute target.
     :vartype instance_type: str
     :ivar properties: Additional properties bag.
     :vartype properties: dict[str, any]
     """
 
     _attribute_map = {
-        'instance_count': {'key': 'instanceCount', 'type': 'int'},
-        'instance_type': {'key': 'instanceType', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{object}'},
+        "instance_count": {"key": "instanceCount", "type": "int"},
+        "instance_type": {"key": "instanceType", "type": "str"},
+        "properties": {"key": "properties", "type": "{object}"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword instance_count: Optional number of instances or nodes used by the compute target.
         :paramtype instance_count: int
         :keyword instance_type: Optional type of VM used as supported by the compute target.
         :paramtype instance_type: str
         :keyword properties: Additional properties bag.
         :paramtype properties: dict[str, any]
         """
         super(ResourceConfiguration, self).__init__(**kwargs)
-        self.instance_count = kwargs.get('instance_count', 1)
-        self.instance_type = kwargs.get('instance_type', None)
-        self.properties = kwargs.get('properties', None)
+        self.instance_count = kwargs.get("instance_count", 1)
+        self.instance_type = kwargs.get("instance_type", None)
+        self.properties = kwargs.get("properties", None)
 
 
 class ResourceManagementAssetReferenceData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -4675,40 +4984,37 @@
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties:
      ~azure.mgmt.machinelearningservices.models.ResourceManagementAssetReferenceDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ResourceManagementAssetReferenceDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ResourceManagementAssetReferenceDetails"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties:
          ~azure.mgmt.machinelearningservices.models.ResourceManagementAssetReferenceDetails
         """
         super(ResourceManagementAssetReferenceData, self).__init__(**kwargs)
-        self.properties = kwargs['properties']
+        self.properties = kwargs["properties"]
 
 
 class ResourceManagementAssetReferenceDetails(AssetReferenceBase):
     """Resource Management asset reference.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4720,113 +5026,92 @@
     :ivar destination_version: Destination asset version for import.
     :vartype destination_version: str
     :ivar source_asset_id: Required. ARM resource ID of the source asset.
     :vartype source_asset_id: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
-        'source_asset_id': {'required': True},
+        "reference_type": {"required": True},
+        "source_asset_id": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'destination_name': {'key': 'destinationName', 'type': 'str'},
-        'destination_version': {'key': 'destinationVersion', 'type': 'str'},
-        'source_asset_id': {'key': 'sourceAssetId', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "destination_name": {"key": "destinationName", "type": "str"},
+        "destination_version": {"key": "destinationVersion", "type": "str"},
+        "source_asset_id": {"key": "sourceAssetId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword destination_name: Destination asset name for import.
         :paramtype destination_name: str
         :keyword destination_version: Destination asset version for import.
         :paramtype destination_version: str
         :keyword source_asset_id: Required. ARM resource ID of the source asset.
         :paramtype source_asset_id: str
         """
         super(ResourceManagementAssetReferenceDetails, self).__init__(**kwargs)
-        self.reference_type = 'Id'  # type: str
-        self.destination_name = kwargs.get('destination_name', None)
-        self.destination_version = kwargs.get('destination_version', None)
-        self.source_asset_id = kwargs['source_asset_id']
+        self.reference_type = "Id"  # type: str
+        self.destination_name = kwargs.get("destination_name", None)
+        self.destination_version = kwargs.get("destination_version", None)
+        self.source_asset_id = kwargs["source_asset_id"]
 
 
 class Route(msrest.serialization.Model):
     """Route.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar path: Required. The path for the route.
     :vartype path: str
     :ivar port: Required. The port for the route.
     :vartype port: int
     """
 
     _validation = {
-        'path': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'port': {'required': True},
+        "path": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "port": {"required": True},
     }
 
     _attribute_map = {
-        'path': {'key': 'path', 'type': 'str'},
-        'port': {'key': 'port', 'type': 'int'},
+        "path": {"key": "path", "type": "str"},
+        "port": {"key": "port", "type": "int"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword path: Required. The path for the route.
         :paramtype path: str
         :keyword port: Required. The port for the route.
         :paramtype port: int
         """
         super(Route, self).__init__(**kwargs)
-        self.path = kwargs['path']
-        self.port = kwargs['port']
+        self.path = kwargs["path"]
+        self.port = kwargs["port"]
 
 
-class SASCredentialDto(DataReferenceCredentialDto):
+class SASCredentialDto(msrest.serialization.Model):
     """SASCredentialDto.
 
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
     :ivar sas_uri: Full SAS Uri, including the storage, container/blob path and SAS token.
     :vartype sas_uri: str
     """
 
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
     _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-        'sas_uri': {'key': 'sasUri', 'type': 'str'},
+        "sas_uri": {"key": "sasUri", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword sas_uri: Full SAS Uri, including the storage, container/blob path and SAS token.
         :paramtype sas_uri: str
         """
         super(SASCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'SAS'  # type: str
-        self.sas_uri = kwargs.get('sas_uri', None)
+        self.sas_uri = kwargs.get("sas_uri", None)
 
 
 class SasDatastoreCredentials(DatastoreCredentials):
     """SAS datastore credentials configuration.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4835,34 +5120,31 @@
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     :ivar secrets: Required. Storage container secrets.
     :vartype secrets: ~azure.mgmt.machinelearningservices.models.SasDatastoreSecrets
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'secrets': {'required': True},
+        "credentials_type": {"required": True},
+        "secrets": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'SasDatastoreSecrets'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "secrets": {"key": "secrets", "type": "SasDatastoreSecrets"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword secrets: Required. Storage container secrets.
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.SasDatastoreSecrets
         """
         super(SasDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'Sas'  # type: str
-        self.secrets = kwargs['secrets']
+        self.credentials_type = "Sas"  # type: str
+        self.secrets = kwargs["secrets"]
 
 
 class SasDatastoreSecrets(DatastoreSecrets):
     """Datastore SAS secrets.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4871,33 +5153,30 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar sas_token: Storage container SAS token.
     :vartype sas_token: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'sas_token': {'key': 'sasToken', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "sas_token": {"key": "sasToken", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword sas_token: Storage container SAS token.
         :paramtype sas_token: str
         """
         super(SasDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'Sas'  # type: str
-        self.sas_token = kwargs.get('sas_token', None)
+        self.secrets_type = "Sas"  # type: str
+        self.sas_token = kwargs.get("sas_token", None)
 
 
 class ServicePrincipalDatastoreCredentials(DatastoreCredentials):
     """Service Principal datastore credentials configuration.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4914,52 +5193,49 @@
     :ivar secrets: Required. Service principal secrets.
     :vartype secrets: ~azure.mgmt.machinelearningservices.models.ServicePrincipalDatastoreSecrets
     :ivar tenant_id: Required. ID of the tenant to which the service principal belongs.
     :vartype tenant_id: str
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'client_id': {'required': True},
-        'secrets': {'required': True},
-        'tenant_id': {'required': True},
+        "credentials_type": {"required": True},
+        "client_id": {"required": True},
+        "secrets": {"required": True},
+        "tenant_id": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'authority_url': {'key': 'authorityUrl', 'type': 'str'},
-        'client_id': {'key': 'clientId', 'type': 'str'},
-        'resource_url': {'key': 'resourceUrl', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'ServicePrincipalDatastoreSecrets'},
-        'tenant_id': {'key': 'tenantId', 'type': 'str'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "authority_url": {"key": "authorityUrl", "type": "str"},
+        "client_id": {"key": "clientId", "type": "str"},
+        "resource_url": {"key": "resourceUrl", "type": "str"},
+        "secrets": {"key": "secrets", "type": "ServicePrincipalDatastoreSecrets"},
+        "tenant_id": {"key": "tenantId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword authority_url: Authority URL used for authentication.
         :paramtype authority_url: str
         :keyword client_id: Required. Service principal client ID.
         :paramtype client_id: str
         :keyword resource_url: Resource the service principal has access to.
         :paramtype resource_url: str
         :keyword secrets: Required. Service principal secrets.
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.ServicePrincipalDatastoreSecrets
         :keyword tenant_id: Required. ID of the tenant to which the service principal belongs.
         :paramtype tenant_id: str
         """
         super(ServicePrincipalDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'ServicePrincipal'  # type: str
-        self.authority_url = kwargs.get('authority_url', None)
-        self.client_id = kwargs['client_id']
-        self.resource_url = kwargs.get('resource_url', None)
-        self.secrets = kwargs['secrets']
-        self.tenant_id = kwargs['tenant_id']
+        self.credentials_type = "ServicePrincipal"  # type: str
+        self.authority_url = kwargs.get("authority_url", None)
+        self.client_id = kwargs["client_id"]
+        self.resource_url = kwargs.get("resource_url", None)
+        self.secrets = kwargs["secrets"]
+        self.tenant_id = kwargs["tenant_id"]
 
 
 class ServicePrincipalDatastoreSecrets(DatastoreSecrets):
     """Datastore Service Principal secrets.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4968,33 +5244,30 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar client_secret: Service principal secret.
     :vartype client_secret: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'client_secret': {'key': 'clientSecret', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "client_secret": {"key": "clientSecret", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword client_secret: Service principal secret.
         :paramtype client_secret: str
         """
         super(ServicePrincipalDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'ServicePrincipal'  # type: str
-        self.client_secret = kwargs.get('client_secret', None)
+        self.secrets_type = "ServicePrincipal"  # type: str
+        self.client_secret = kwargs.get("client_secret", None)
 
 
 class SweepJob(JobBase):
     """Sweep job definition.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -5050,50 +5323,47 @@
      dictionary key is the name of the parameter.
     :vartype search_space: any
     :ivar trial: Required. Trial component definition.
     :vartype trial: ~azure.mgmt.machinelearningservices.models.TrialComponent
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
-        'objective': {'required': True},
-        'sampling_algorithm': {'required': True},
-        'search_space': {'required': True},
-        'trial': {'required': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
+        "objective": {"required": True},
+        "sampling_algorithm": {"required": True},
+        "search_space": {"required": True},
+        "trial": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
-        'early_termination': {'key': 'earlyTermination', 'type': 'EarlyTerminationPolicy'},
-        'identity': {'key': 'identity', 'type': 'IdentityConfiguration'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'limits': {'key': 'limits', 'type': 'SweepJobLimits'},
-        'objective': {'key': 'objective', 'type': 'Objective'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'sampling_algorithm': {'key': 'samplingAlgorithm', 'type': 'str'},
-        'search_space': {'key': 'searchSpace', 'type': 'object'},
-        'trial': {'key': 'trial', 'type': 'TrialComponent'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
+        "early_termination": {"key": "earlyTermination", "type": "EarlyTerminationPolicy"},
+        "identity": {"key": "identity", "type": "IdentityConfiguration"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "limits": {"key": "limits", "type": "SweepJobLimits"},
+        "objective": {"key": "objective", "type": "Objective"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "sampling_algorithm": {"key": "samplingAlgorithm", "type": "str"},
+        "search_space": {"key": "searchSpace", "type": "object"},
+        "trial": {"key": "trial", "type": "TrialComponent"},
+    }
+
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -5131,24 +5401,24 @@
         :keyword search_space: Required. A dictionary containing each parameter and its distribution.
          The dictionary key is the name of the parameter.
         :paramtype search_space: any
         :keyword trial: Required. Trial component definition.
         :paramtype trial: ~azure.mgmt.machinelearningservices.models.TrialComponent
         """
         super(SweepJob, self).__init__(**kwargs)
-        self.job_type = 'Sweep'  # type: str
-        self.early_termination = kwargs.get('early_termination', None)
-        self.identity = kwargs.get('identity', None)
-        self.inputs = kwargs.get('inputs', None)
-        self.limits = kwargs.get('limits', None)
-        self.objective = kwargs['objective']
-        self.outputs = kwargs.get('outputs', None)
-        self.sampling_algorithm = kwargs['sampling_algorithm']
-        self.search_space = kwargs['search_space']
-        self.trial = kwargs['trial']
+        self.job_type = "Sweep"  # type: str
+        self.early_termination = kwargs.get("early_termination", None)
+        self.identity = kwargs.get("identity", None)
+        self.inputs = kwargs.get("inputs", None)
+        self.limits = kwargs.get("limits", None)
+        self.objective = kwargs["objective"]
+        self.outputs = kwargs.get("outputs", None)
+        self.sampling_algorithm = kwargs["sampling_algorithm"]
+        self.search_space = kwargs["search_space"]
+        self.trial = kwargs["trial"]
 
 
 class SweepJobLimits(JobLimits):
     """Sweep Job limit class.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -5163,45 +5433,42 @@
     :ivar max_total_trials: Sweep Job max total trials.
     :vartype max_total_trials: int
     :ivar trial_timeout: Sweep Job Trial timeout value.
     :vartype trial_timeout: ~datetime.timedelta
     """
 
     _validation = {
-        'job_limits_type': {'required': True},
+        "job_limits_type": {"required": True},
     }
 
     _attribute_map = {
-        'job_limits_type': {'key': 'jobLimitsType', 'type': 'str'},
-        'timeout': {'key': 'timeout', 'type': 'duration'},
-        'max_concurrent_trials': {'key': 'maxConcurrentTrials', 'type': 'int'},
-        'max_total_trials': {'key': 'maxTotalTrials', 'type': 'int'},
-        'trial_timeout': {'key': 'trialTimeout', 'type': 'duration'},
+        "job_limits_type": {"key": "jobLimitsType", "type": "str"},
+        "timeout": {"key": "timeout", "type": "duration"},
+        "max_concurrent_trials": {"key": "maxConcurrentTrials", "type": "int"},
+        "max_total_trials": {"key": "maxTotalTrials", "type": "int"},
+        "trial_timeout": {"key": "trialTimeout", "type": "duration"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword timeout: The max run duration in ISO 8601 format, after which the job will be
          cancelled. Only supports duration with precision as low as Seconds.
         :paramtype timeout: ~datetime.timedelta
         :keyword max_concurrent_trials: Sweep Job max concurrent trials.
         :paramtype max_concurrent_trials: int
         :keyword max_total_trials: Sweep Job max total trials.
         :paramtype max_total_trials: int
         :keyword trial_timeout: Sweep Job Trial timeout value.
         :paramtype trial_timeout: ~datetime.timedelta
         """
         super(SweepJobLimits, self).__init__(**kwargs)
-        self.job_limits_type = 'Sweep'  # type: str
-        self.max_concurrent_trials = kwargs.get('max_concurrent_trials', None)
-        self.max_total_trials = kwargs.get('max_total_trials', None)
-        self.trial_timeout = kwargs.get('trial_timeout', None)
+        self.job_limits_type = "Sweep"  # type: str
+        self.max_concurrent_trials = kwargs.get("max_concurrent_trials", None)
+        self.max_total_trials = kwargs.get("max_total_trials", None)
+        self.trial_timeout = kwargs.get("trial_timeout", None)
 
 
 class SystemData(msrest.serialization.Model):
     """Metadata pertaining to creation and last modification of the resource.
 
     :ivar created_by: The identity that created the resource.
     :vartype created_by: str
@@ -5216,26 +5483,23 @@
      values include: "User", "Application", "ManagedIdentity", "Key".
     :vartype last_modified_by_type: str or ~azure.mgmt.machinelearningservices.models.CreatedByType
     :ivar last_modified_at: The timestamp of resource last modification (UTC).
     :vartype last_modified_at: ~datetime.datetime
     """
 
     _attribute_map = {
-        'created_by': {'key': 'createdBy', 'type': 'str'},
-        'created_by_type': {'key': 'createdByType', 'type': 'str'},
-        'created_at': {'key': 'createdAt', 'type': 'iso-8601'},
-        'last_modified_by': {'key': 'lastModifiedBy', 'type': 'str'},
-        'last_modified_by_type': {'key': 'lastModifiedByType', 'type': 'str'},
-        'last_modified_at': {'key': 'lastModifiedAt', 'type': 'iso-8601'},
+        "created_by": {"key": "createdBy", "type": "str"},
+        "created_by_type": {"key": "createdByType", "type": "str"},
+        "created_at": {"key": "createdAt", "type": "iso-8601"},
+        "last_modified_by": {"key": "lastModifiedBy", "type": "str"},
+        "last_modified_by_type": {"key": "lastModifiedByType", "type": "str"},
+        "last_modified_at": {"key": "lastModifiedAt", "type": "iso-8601"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword created_by: The identity that created the resource.
         :paramtype created_by: str
         :keyword created_by_type: The type of identity that created the resource. Possible values
          include: "User", "Application", "ManagedIdentity", "Key".
         :paramtype created_by_type: str or ~azure.mgmt.machinelearningservices.models.CreatedByType
         :keyword created_at: The timestamp of resource creation (UTC).
@@ -5246,20 +5510,20 @@
          values include: "User", "Application", "ManagedIdentity", "Key".
         :paramtype last_modified_by_type: str or
          ~azure.mgmt.machinelearningservices.models.CreatedByType
         :keyword last_modified_at: The timestamp of resource last modification (UTC).
         :paramtype last_modified_at: ~datetime.datetime
         """
         super(SystemData, self).__init__(**kwargs)
-        self.created_by = kwargs.get('created_by', None)
-        self.created_by_type = kwargs.get('created_by_type', None)
-        self.created_at = kwargs.get('created_at', None)
-        self.last_modified_by = kwargs.get('last_modified_by', None)
-        self.last_modified_by_type = kwargs.get('last_modified_by_type', None)
-        self.last_modified_at = kwargs.get('last_modified_at', None)
+        self.created_by = kwargs.get("created_by", None)
+        self.created_by_type = kwargs.get("created_by_type", None)
+        self.created_at = kwargs.get("created_at", None)
+        self.last_modified_by = kwargs.get("last_modified_by", None)
+        self.last_modified_by_type = kwargs.get("last_modified_by_type", None)
+        self.last_modified_at = kwargs.get("last_modified_at", None)
 
 
 class TemporaryDataReferenceRequestDto(msrest.serialization.Model):
     """TemporaryDataReferenceRequestDto.
 
     :ivar asset_id:
     :vartype asset_id: str
@@ -5267,37 +5531,34 @@
      used.
     :vartype temporary_data_reference_id: str
     :ivar temporary_data_reference_type: Either TemporaryBlobReference or TemporaryImageReference.
     :vartype temporary_data_reference_type: str
     """
 
     _attribute_map = {
-        'asset_id': {'key': 'assetId', 'type': 'str'},
-        'temporary_data_reference_id': {'key': 'temporaryDataReferenceId', 'type': 'str'},
-        'temporary_data_reference_type': {'key': 'temporaryDataReferenceType', 'type': 'str'},
+        "asset_id": {"key": "assetId", "type": "str"},
+        "temporary_data_reference_id": {"key": "temporaryDataReferenceId", "type": "str"},
+        "temporary_data_reference_type": {"key": "temporaryDataReferenceType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword asset_id:
         :paramtype asset_id: str
         :keyword temporary_data_reference_id: If TemporaryDataReferenceId = null then random guid will
          be used.
         :paramtype temporary_data_reference_id: str
         :keyword temporary_data_reference_type: Either TemporaryBlobReference or
          TemporaryImageReference.
         :paramtype temporary_data_reference_type: str
         """
         super(TemporaryDataReferenceRequestDto, self).__init__(**kwargs)
-        self.asset_id = kwargs.get('asset_id', None)
-        self.temporary_data_reference_id = kwargs.get('temporary_data_reference_id', None)
-        self.temporary_data_reference_type = kwargs.get('temporary_data_reference_type', None)
+        self.asset_id = kwargs.get("asset_id", None)
+        self.temporary_data_reference_id = kwargs.get("temporary_data_reference_id", None)
+        self.temporary_data_reference_type = kwargs.get("temporary_data_reference_type", None)
 
 
 class TemporaryDataReferenceResponseDto(msrest.serialization.Model):
     """TemporaryDataReferenceResponseDto.
 
     :ivar blob_reference_for_consumption: Container level read, write, list SAS.
     :vartype blob_reference_for_consumption:
@@ -5308,41 +5569,44 @@
     :ivar temporary_data_reference_id:
     :vartype temporary_data_reference_id: str
     :ivar temporary_data_reference_type:
     :vartype temporary_data_reference_type: str
     """
 
     _attribute_map = {
-        'blob_reference_for_consumption': {'key': 'blobReferenceForConsumption', 'type': 'BlobReferenceForConsumptionDto'},
-        'image_reference_for_consumption': {'key': 'imageReferenceForConsumption', 'type': 'ImageReferenceForConsumptionDto'},
-        'temporary_data_reference_id': {'key': 'temporaryDataReferenceId', 'type': 'str'},
-        'temporary_data_reference_type': {'key': 'temporaryDataReferenceType', 'type': 'str'},
+        "blob_reference_for_consumption": {
+            "key": "blobReferenceForConsumption",
+            "type": "BlobReferenceForConsumptionDto",
+        },
+        "image_reference_for_consumption": {
+            "key": "imageReferenceForConsumption",
+            "type": "ImageReferenceForConsumptionDto",
+        },
+        "temporary_data_reference_id": {"key": "temporaryDataReferenceId", "type": "str"},
+        "temporary_data_reference_type": {"key": "temporaryDataReferenceType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword blob_reference_for_consumption: Container level read, write, list SAS.
         :paramtype blob_reference_for_consumption:
          ~azure.mgmt.machinelearningservices.models.BlobReferenceForConsumptionDto
         :keyword image_reference_for_consumption:
         :paramtype image_reference_for_consumption:
          ~azure.mgmt.machinelearningservices.models.ImageReferenceForConsumptionDto
         :keyword temporary_data_reference_id:
         :paramtype temporary_data_reference_id: str
         :keyword temporary_data_reference_type:
         :paramtype temporary_data_reference_type: str
         """
         super(TemporaryDataReferenceResponseDto, self).__init__(**kwargs)
-        self.blob_reference_for_consumption = kwargs.get('blob_reference_for_consumption', None)
-        self.image_reference_for_consumption = kwargs.get('image_reference_for_consumption', None)
-        self.temporary_data_reference_id = kwargs.get('temporary_data_reference_id', None)
-        self.temporary_data_reference_type = kwargs.get('temporary_data_reference_type', None)
+        self.blob_reference_for_consumption = kwargs.get("blob_reference_for_consumption", None)
+        self.image_reference_for_consumption = kwargs.get("image_reference_for_consumption", None)
+        self.temporary_data_reference_id = kwargs.get("temporary_data_reference_id", None)
+        self.temporary_data_reference_type = kwargs.get("temporary_data_reference_type", None)
 
 
 class TensorFlow(DistributionConfiguration):
     """TensorFlow distribution configuration.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -5352,37 +5616,34 @@
     :ivar parameter_server_count: Number of parameter server tasks.
     :vartype parameter_server_count: int
     :ivar worker_count: Number of workers. If not specified, will default to the instance count.
     :vartype worker_count: int
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
-        'parameter_server_count': {'key': 'parameterServerCount', 'type': 'int'},
-        'worker_count': {'key': 'workerCount', 'type': 'int'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
+        "parameter_server_count": {"key": "parameterServerCount", "type": "int"},
+        "worker_count": {"key": "workerCount", "type": "int"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword parameter_server_count: Number of parameter server tasks.
         :paramtype parameter_server_count: int
         :keyword worker_count: Number of workers. If not specified, will default to the instance count.
         :paramtype worker_count: int
         """
         super(TensorFlow, self).__init__(**kwargs)
-        self.distribution_type = 'TensorFlow'  # type: str
-        self.parameter_server_count = kwargs.get('parameter_server_count', 0)
-        self.worker_count = kwargs.get('worker_count', None)
+        self.distribution_type = "TensorFlow"  # type: str
+        self.parameter_server_count = kwargs.get("parameter_server_count", 0)
+        self.worker_count = kwargs.get("worker_count", None)
 
 
 class TrialComponent(msrest.serialization.Model):
     """Trial component definition.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -5399,31 +5660,28 @@
     :ivar environment_variables: Environment variables included in the job.
     :vartype environment_variables: dict[str, str]
     :ivar resources: Compute Resource configuration for the job.
     :vartype resources: ~azure.mgmt.machinelearningservices.models.ResourceConfiguration
     """
 
     _validation = {
-        'command': {'required': True, 'min_length': 1, 'pattern': r'[a-zA-Z0-9_]'},
-        'environment_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "command": {"required": True, "min_length": 1, "pattern": r"[a-zA-Z0-9_]"},
+        "environment_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'code_id': {'key': 'codeId', 'type': 'str'},
-        'command': {'key': 'command', 'type': 'str'},
-        'distribution': {'key': 'distribution', 'type': 'DistributionConfiguration'},
-        'environment_id': {'key': 'environmentId', 'type': 'str'},
-        'environment_variables': {'key': 'environmentVariables', 'type': '{str}'},
-        'resources': {'key': 'resources', 'type': 'ResourceConfiguration'},
+        "code_id": {"key": "codeId", "type": "str"},
+        "command": {"key": "command", "type": "str"},
+        "distribution": {"key": "distribution", "type": "DistributionConfiguration"},
+        "environment_id": {"key": "environmentId", "type": "str"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "resources": {"key": "resources", "type": "ResourceConfiguration"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword code_id: ARM resource ID of the code asset.
         :paramtype code_id: str
         :keyword command: Required. The command to execute on startup of the job. eg. "python
          train.py".
         :paramtype command: str
         :keyword distribution: Distribution configuration of the job. If set, this should be one of
@@ -5434,20 +5692,53 @@
         :paramtype environment_id: str
         :keyword environment_variables: Environment variables included in the job.
         :paramtype environment_variables: dict[str, str]
         :keyword resources: Compute Resource configuration for the job.
         :paramtype resources: ~azure.mgmt.machinelearningservices.models.ResourceConfiguration
         """
         super(TrialComponent, self).__init__(**kwargs)
-        self.code_id = kwargs.get('code_id', None)
-        self.command = kwargs['command']
-        self.distribution = kwargs.get('distribution', None)
-        self.environment_id = kwargs['environment_id']
-        self.environment_variables = kwargs.get('environment_variables', None)
-        self.resources = kwargs.get('resources', None)
+        self.code_id = kwargs.get("code_id", None)
+        self.command = kwargs["command"]
+        self.distribution = kwargs.get("distribution", None)
+        self.environment_id = kwargs["environment_id"]
+        self.environment_variables = kwargs.get("environment_variables", None)
+        self.resources = kwargs.get("resources", None)
+
+
+class TritonInferencingServer(InferencingServer):
+    """Triton inferencing server configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar inference_configuration: Inference configuration for Triton.
+    :vartype inference_configuration:
+     ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "inference_configuration": {"key": "inferenceConfiguration", "type": "OnlineInferenceConfiguration"},
+    }
+
+    def __init__(self, **kwargs):
+        """
+        :keyword inference_configuration: Inference configuration for Triton.
+        :paramtype inference_configuration:
+         ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+        """
+        super(TritonInferencingServer, self).__init__(**kwargs)
+        self.server_type = "Triton"  # type: str
+        self.inference_configuration = kwargs.get("inference_configuration", None)
 
 
 class TruncationSelectionPolicy(EarlyTerminationPolicy):
     """Defines an early termination policy that cancels a given percentage of runs at each evaluation interval.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -5460,39 +5751,36 @@
     :vartype policy_type: str or
      ~azure.mgmt.machinelearningservices.models.EarlyTerminationPolicyType
     :ivar truncation_percentage: The percentage of runs to cancel at each evaluation interval.
     :vartype truncation_percentage: int
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
-        'truncation_percentage': {'key': 'truncationPercentage', 'type': 'int'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
+        "truncation_percentage": {"key": "truncationPercentage", "type": "int"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword delay_evaluation: Number of intervals by which to delay the first evaluation.
         :paramtype delay_evaluation: int
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         :keyword truncation_percentage: The percentage of runs to cancel at each evaluation interval.
         :paramtype truncation_percentage: int
         """
         super(TruncationSelectionPolicy, self).__init__(**kwargs)
-        self.policy_type = 'TruncationSelection'  # type: str
-        self.truncation_percentage = kwargs.get('truncation_percentage', 0)
+        self.policy_type = "TruncationSelection"  # type: str
+        self.truncation_percentage = kwargs.get("truncation_percentage", 0)
 
 
 class UriFileDataVersion(DataVersionBaseDetails):
     """uri-file data version entity.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -5514,33 +5802,30 @@
     :vartype data_uri: str
     :ivar intellectual_property: Intellectual Property details. Used if data is an Intellectual
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -5553,15 +5838,15 @@
         :paramtype data_uri: str
         :keyword intellectual_property: Intellectual Property details. Used if data is an Intellectual
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         """
         super(UriFileDataVersion, self).__init__(**kwargs)
-        self.data_type = 'uri_file'  # type: str
+        self.data_type = "uri_file"  # type: str
 
 
 class UriFolderDataVersion(DataVersionBaseDetails):
     """uri-folder data version entity.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -5583,33 +5868,30 @@
     :vartype data_uri: str
     :ivar intellectual_property: Intellectual Property details. Used if data is an Intellectual
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword description: The asset description text.
         :paramtype description: str
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
@@ -5622,37 +5904,34 @@
         :paramtype data_uri: str
         :keyword intellectual_property: Intellectual Property details. Used if data is an Intellectual
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         """
         super(UriFolderDataVersion, self).__init__(**kwargs)
-        self.data_type = 'uri_folder'  # type: str
+        self.data_type = "uri_folder"  # type: str
 
 
 class UriReference(msrest.serialization.Model):
     """TODO - UriReference.
 
     :ivar file: Single file uri path.
     :vartype file: str
     :ivar folder: Folder uri path.
     :vartype folder: str
     """
 
     _attribute_map = {
-        'file': {'key': 'file', 'type': 'str'},
-        'folder': {'key': 'folder', 'type': 'str'},
+        "file": {"key": "file", "type": "str"},
+        "folder": {"key": "folder", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, **kwargs):
         """
         :keyword file: Single file uri path.
         :paramtype file: str
         :keyword folder: Folder uri path.
         :paramtype folder: str
         """
         super(UriReference, self).__init__(**kwargs)
-        self.file = kwargs.get('file', None)
-        self.folder = kwargs.get('folder', None)
+        self.file = kwargs.get("file", None)
+        self.folder = kwargs.get("folder", None)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/models/_models_py3.py`

 * *Files 14% similar despite different names*

```diff
@@ -26,31 +26,33 @@
     :ivar credentials_type: Required. Credential type used to authentication with storage.Constant
      filled by server. Possible values include: "AccountKey", "Certificate", "None", "Sas",
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     """
 
     _validation = {
-        'credentials_type': {'required': True},
+        "credentials_type": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
     }
 
     _subtype_map = {
-        'credentials_type': {'AccountKey': 'AccountKeyDatastoreCredentials', 'Certificate': 'CertificateDatastoreCredentials', 'None': 'NoneDatastoreCredentials', 'Sas': 'SasDatastoreCredentials', 'ServicePrincipal': 'ServicePrincipalDatastoreCredentials'}
+        "credentials_type": {
+            "AccountKey": "AccountKeyDatastoreCredentials",
+            "Certificate": "CertificateDatastoreCredentials",
+            "None": "NoneDatastoreCredentials",
+            "Sas": "SasDatastoreCredentials",
+            "ServicePrincipal": "ServicePrincipalDatastoreCredentials",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(DatastoreCredentials, self).__init__(**kwargs)
         self.credentials_type = None  # type: Optional[str]
 
 
 class AccountKeyDatastoreCredentials(DatastoreCredentials):
     """Account key datastore credentials configuration.
 
@@ -61,35 +63,30 @@
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     :ivar secrets: Required. Storage account secrets.
     :vartype secrets: ~azure.mgmt.machinelearningservices.models.AccountKeyDatastoreSecrets
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'secrets': {'required': True},
+        "credentials_type": {"required": True},
+        "secrets": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'AccountKeyDatastoreSecrets'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "secrets": {"key": "secrets", "type": "AccountKeyDatastoreSecrets"},
     }
 
-    def __init__(
-        self,
-        *,
-        secrets: "AccountKeyDatastoreSecrets",
-        **kwargs
-    ):
+    def __init__(self, *, secrets: "AccountKeyDatastoreSecrets", **kwargs):
         """
         :keyword secrets: Required. Storage account secrets.
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.AccountKeyDatastoreSecrets
         """
         super(AccountKeyDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'AccountKey'  # type: str
+        self.credentials_type = "AccountKey"  # type: str
         self.secrets = secrets
 
 
 class DatastoreSecrets(msrest.serialization.Model):
     """Base definition for datastore secrets.
 
     You probably want to use the sub-classes and not this class directly. Known
@@ -100,31 +97,32 @@
     :ivar secrets_type: Required. Credential type used to authentication with storage.Constant
      filled by server. Possible values include: "AccountKey", "Certificate", "Sas",
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
     }
 
     _subtype_map = {
-        'secrets_type': {'AccountKey': 'AccountKeyDatastoreSecrets', 'Certificate': 'CertificateDatastoreSecrets', 'Sas': 'SasDatastoreSecrets', 'ServicePrincipal': 'ServicePrincipalDatastoreSecrets'}
+        "secrets_type": {
+            "AccountKey": "AccountKeyDatastoreSecrets",
+            "Certificate": "CertificateDatastoreSecrets",
+            "Sas": "SasDatastoreSecrets",
+            "ServicePrincipal": "ServicePrincipalDatastoreSecrets",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(DatastoreSecrets, self).__init__(**kwargs)
         self.secrets_type = None  # type: Optional[str]
 
 
 class AccountKeyDatastoreSecrets(DatastoreSecrets):
     """Datastore account key secrets.
 
@@ -135,34 +133,29 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar key: Storage account key.
     :vartype key: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'key': {'key': 'key', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "key": {"key": "key", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        key: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, key: Optional[str] = None, **kwargs):
         """
         :keyword key: Storage account key.
         :paramtype key: str
         """
         super(AccountKeyDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'AccountKey'  # type: str
+        self.secrets_type = "AccountKey"  # type: str
         self.key = key
 
 
 class AcrDetail(msrest.serialization.Model):
     """AcrDetail.
 
     Variables are only populated by the server, and will be ignored when sending a request.
@@ -178,24 +171,24 @@
     :ivar resource_group_name:
     :vartype resource_group_name: str
     :ivar subscription_id:
     :vartype subscription_id: str
     """
 
     _validation = {
-        'arm_scope': {'readonly': True},
+        "arm_scope": {"readonly": True},
     }
 
     _attribute_map = {
-        'acr_address': {'key': 'acrAddress', 'type': 'str'},
-        'acr_name': {'key': 'acrName', 'type': 'str'},
-        'acr_region': {'key': 'acrRegion', 'type': 'str'},
-        'arm_scope': {'key': 'armScope', 'type': 'str'},
-        'resource_group_name': {'key': 'resourceGroupName', 'type': 'str'},
-        'subscription_id': {'key': 'subscriptionId', 'type': 'str'},
+        "acr_address": {"key": "acrAddress", "type": "str"},
+        "acr_name": {"key": "acrName", "type": "str"},
+        "acr_region": {"key": "acrRegion", "type": "str"},
+        "arm_scope": {"key": "armScope", "type": "str"},
+        "resource_group_name": {"key": "resourceGroupName", "type": "str"},
+        "subscription_id": {"key": "subscriptionId", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         acr_address: Optional[str] = None,
         acr_name: Optional[str] = None,
@@ -236,31 +229,25 @@
     :ivar identity_type: Required. Specifies the type of identity framework.Constant filled by
      server. Possible values include: "Managed", "AMLToken".
     :vartype identity_type: str or
      ~azure.mgmt.machinelearningservices.models.IdentityConfigurationType
     """
 
     _validation = {
-        'identity_type': {'required': True},
+        "identity_type": {"required": True},
     }
 
     _attribute_map = {
-        'identity_type': {'key': 'identityType', 'type': 'str'},
+        "identity_type": {"key": "identityType", "type": "str"},
     }
 
-    _subtype_map = {
-        'identity_type': {'AMLToken': 'AmlToken', 'Managed': 'ManagedIdentity'}
-    }
+    _subtype_map = {"identity_type": {"AMLToken": "AmlToken", "Managed": "ManagedIdentity"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(IdentityConfiguration, self).__init__(**kwargs)
         self.identity_type = None  # type: Optional[str]
 
 
 class AmlToken(IdentityConfiguration):
     """AML Token identity configuration.
 
@@ -269,111 +256,42 @@
     :ivar identity_type: Required. Specifies the type of identity framework.Constant filled by
      server. Possible values include: "Managed", "AMLToken".
     :vartype identity_type: str or
      ~azure.mgmt.machinelearningservices.models.IdentityConfigurationType
     """
 
     _validation = {
-        'identity_type': {'required': True},
+        "identity_type": {"required": True},
     }
 
     _attribute_map = {
-        'identity_type': {'key': 'identityType', 'type': 'str'},
+        "identity_type": {"key": "identityType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(AmlToken, self).__init__(**kwargs)
-        self.identity_type = 'AMLToken'  # type: str
-
-
-class DataReferenceCredentialDto(msrest.serialization.Model):
-    """DataReferenceCredentialDto.
-
-    You probably want to use the sub-classes and not this class directly. Known
-    sub-classes are: DockerCredentialDto, ManagedIdentityCredentialDto, AnonymousAccessCredentialDto, SASCredentialDto.
-
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
-    """
-
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
-    _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-    }
-
-    _subtype_map = {
-        'credential_type': {'DockerCredentials': 'DockerCredentialDto', 'ManagedIdentity': 'ManagedIdentityCredentialDto', 'NoCredentials': 'AnonymousAccessCredentialDto', 'SAS': 'SASCredentialDto'}
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
-        super(DataReferenceCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'DataReferenceCredentialDto'  # type: str
-
-
-class AnonymousAccessCredentialDto(DataReferenceCredentialDto):
-    """AnonymousAccessCredentialDto.
-
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
-    """
-
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
-    _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-    }
-
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
-        super(AnonymousAccessCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'NoCredentials'  # type: str
+        self.identity_type = "AMLToken"  # type: str
 
 
 class ResourceBase(msrest.serialization.Model):
     """ResourceBase.
 
     :ivar description: The asset description text.
     :vartype description: str
     :ivar properties: The asset property dictionary.
     :vartype properties: dict[str, str]
     :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
     :vartype tags: dict[str, str]
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -406,19 +324,19 @@
     :ivar is_anonymous: If the name version are system generated (anonymous registration).
     :vartype is_anonymous: bool
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -460,25 +378,25 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -512,31 +430,31 @@
 
     :ivar reference_type: Required. Specifies the type of asset reference.Constant filled by
      server. Possible values include: "Id", "DataPath", "OutputPath".
     :vartype reference_type: str or ~azure.mgmt.machinelearningservices.models.ReferenceType
     """
 
     _validation = {
-        'reference_type': {'required': True},
+        "reference_type": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
     }
 
     _subtype_map = {
-        'reference_type': {'DataPath': 'DataPathAssetReference', 'Id': 'IdAssetReference', 'OutputPath': 'OutputPathAssetReference'}
+        "reference_type": {
+            "DataPath": "DataPathAssetReference",
+            "Id": "IdAssetReference",
+            "OutputPath": "OutputPathAssetReference",
+        }
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(AssetReferenceBase, self).__init__(**kwargs)
         self.reference_type = None  # type: Optional[str]
 
 
 class Datastore(ResourceBase):
     """Base definition for datastore contents configuration.
 
@@ -560,30 +478,35 @@
     :vartype datastore_type: str or ~azure.mgmt.machinelearningservices.models.DatastoreType
     :ivar is_default: Readonly property to indicate if datastore is the workspace default
      datastore.
     :vartype is_default: bool
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
     }
 
     _subtype_map = {
-        'datastore_type': {'AzureBlob': 'AzureBlobDatastore', 'AzureDataLakeGen1': 'AzureDataLakeGen1Datastore', 'AzureDataLakeGen2': 'AzureDataLakeGen2Datastore', 'AzureFile': 'AzureFileDatastore'}
+        "datastore_type": {
+            "AzureBlob": "AzureBlobDatastore",
+            "AzureDataLakeGen1": "AzureDataLakeGen1Datastore",
+            "AzureDataLakeGen2": "AzureDataLakeGen2Datastore",
+            "AzureFile": "AzureFileDatastore",
+        }
     }
 
     def __init__(
         self,
         *,
         credentials: "DatastoreCredentials",
         description: Optional[str] = None,
@@ -599,15 +522,15 @@
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword credentials: Required. Account credentials.
         :paramtype credentials: ~azure.mgmt.machinelearningservices.models.DatastoreCredentials
         """
         super(Datastore, self).__init__(description=description, properties=properties, tags=tags, **kwargs)
         self.credentials = credentials
-        self.datastore_type = 'Datastore'  # type: str
+        self.datastore_type = "Datastore"  # type: str
         self.is_default = None
 
 
 class AzureBlobDatastore(Datastore):
     """Azure Blob datastore configuration.
 
     Variables are only populated by the server, and will be ignored when sending a request.
@@ -640,31 +563,31 @@
      service data access to customer's storage. Possible values include: "None",
      "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'account_name': {'key': 'accountName', 'type': 'str'},
-        'container_name': {'key': 'containerName', 'type': 'str'},
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'protocol': {'key': 'protocol', 'type': 'str'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "account_name": {"key": "accountName", "type": "str"},
+        "container_name": {"key": "containerName", "type": "str"},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "protocol": {"key": "protocol", "type": "str"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         credentials: "DatastoreCredentials",
         description: Optional[str] = None,
@@ -696,16 +619,18 @@
         :paramtype protocol: str
         :keyword service_data_access_auth_identity: Indicates which identity to use to authenticate
          service data access to customer's storage. Possible values include: "None",
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         """
-        super(AzureBlobDatastore, self).__init__(description=description, properties=properties, tags=tags, credentials=credentials, **kwargs)
-        self.datastore_type = 'AzureBlob'  # type: str
+        super(AzureBlobDatastore, self).__init__(
+            description=description, properties=properties, tags=tags, credentials=credentials, **kwargs
+        )
+        self.datastore_type = "AzureBlob"  # type: str
         self.account_name = account_name
         self.container_name = container_name
         self.endpoint = endpoint
         self.protocol = protocol
         self.service_data_access_auth_identity = service_data_access_auth_identity
 
 
@@ -736,29 +661,29 @@
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     :ivar store_name: Required. Azure Data Lake store name.
     :vartype store_name: str
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
-        'store_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
+        "store_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
-        'store_name': {'key': 'storeName', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
+        "store_name": {"key": "storeName", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         credentials: "DatastoreCredentials",
         store_name: str,
@@ -781,16 +706,18 @@
          service data access to customer's storage. Possible values include: "None",
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         :keyword store_name: Required. Azure Data Lake store name.
         :paramtype store_name: str
         """
-        super(AzureDataLakeGen1Datastore, self).__init__(description=description, properties=properties, tags=tags, credentials=credentials, **kwargs)
-        self.datastore_type = 'AzureDataLakeGen1'  # type: str
+        super(AzureDataLakeGen1Datastore, self).__init__(
+            description=description, properties=properties, tags=tags, credentials=credentials, **kwargs
+        )
+        self.datastore_type = "AzureDataLakeGen1"  # type: str
         self.service_data_access_auth_identity = service_data_access_auth_identity
         self.store_name = store_name
 
 
 class AzureDataLakeGen2Datastore(Datastore):
     """Azure Data Lake Gen2 datastore configuration.
 
@@ -824,33 +751,33 @@
      service data access to customer's storage. Possible values include: "None",
      "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
-        'account_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'filesystem': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
+        "account_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "filesystem": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'account_name': {'key': 'accountName', 'type': 'str'},
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'filesystem': {'key': 'filesystem', 'type': 'str'},
-        'protocol': {'key': 'protocol', 'type': 'str'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "account_name": {"key": "accountName", "type": "str"},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "filesystem": {"key": "filesystem", "type": "str"},
+        "protocol": {"key": "protocol", "type": "str"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         credentials: "DatastoreCredentials",
         account_name: str,
@@ -882,16 +809,18 @@
         :paramtype protocol: str
         :keyword service_data_access_auth_identity: Indicates which identity to use to authenticate
          service data access to customer's storage. Possible values include: "None",
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         """
-        super(AzureDataLakeGen2Datastore, self).__init__(description=description, properties=properties, tags=tags, credentials=credentials, **kwargs)
-        self.datastore_type = 'AzureDataLakeGen2'  # type: str
+        super(AzureDataLakeGen2Datastore, self).__init__(
+            description=description, properties=properties, tags=tags, credentials=credentials, **kwargs
+        )
+        self.datastore_type = "AzureDataLakeGen2"  # type: str
         self.account_name = account_name
         self.endpoint = endpoint
         self.filesystem = filesystem
         self.protocol = protocol
         self.service_data_access_auth_identity = service_data_access_auth_identity
 
 
@@ -928,33 +857,33 @@
      service data access to customer's storage. Possible values include: "None",
      "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
     :vartype service_data_access_auth_identity: str or
      ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
     """
 
     _validation = {
-        'credentials': {'required': True},
-        'datastore_type': {'required': True},
-        'is_default': {'readonly': True},
-        'account_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'file_share_name': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials": {"required": True},
+        "datastore_type": {"required": True},
+        "is_default": {"readonly": True},
+        "account_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "file_share_name": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'credentials': {'key': 'credentials', 'type': 'DatastoreCredentials'},
-        'datastore_type': {'key': 'datastoreType', 'type': 'str'},
-        'is_default': {'key': 'isDefault', 'type': 'bool'},
-        'account_name': {'key': 'accountName', 'type': 'str'},
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'file_share_name': {'key': 'fileShareName', 'type': 'str'},
-        'protocol': {'key': 'protocol', 'type': 'str'},
-        'service_data_access_auth_identity': {'key': 'serviceDataAccessAuthIdentity', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "credentials": {"key": "credentials", "type": "DatastoreCredentials"},
+        "datastore_type": {"key": "datastoreType", "type": "str"},
+        "is_default": {"key": "isDefault", "type": "bool"},
+        "account_name": {"key": "accountName", "type": "str"},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "file_share_name": {"key": "fileShareName", "type": "str"},
+        "protocol": {"key": "protocol", "type": "str"},
+        "service_data_access_auth_identity": {"key": "serviceDataAccessAuthIdentity", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         credentials: "DatastoreCredentials",
         account_name: str,
@@ -986,23 +915,123 @@
         :paramtype protocol: str
         :keyword service_data_access_auth_identity: Indicates which identity to use to authenticate
          service data access to customer's storage. Possible values include: "None",
          "WorkspaceSystemAssignedIdentity", "WorkspaceUserAssignedIdentity".
         :paramtype service_data_access_auth_identity: str or
          ~azure.mgmt.machinelearningservices.models.ServiceDataAccessAuthIdentity
         """
-        super(AzureFileDatastore, self).__init__(description=description, properties=properties, tags=tags, credentials=credentials, **kwargs)
-        self.datastore_type = 'AzureFile'  # type: str
+        super(AzureFileDatastore, self).__init__(
+            description=description, properties=properties, tags=tags, credentials=credentials, **kwargs
+        )
+        self.datastore_type = "AzureFile"  # type: str
         self.account_name = account_name
         self.endpoint = endpoint
         self.file_share_name = file_share_name
         self.protocol = protocol
         self.service_data_access_auth_identity = service_data_access_auth_identity
 
 
+class InferencingServer(msrest.serialization.Model):
+    """InferencingServer.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: AzureMLBatchInferencingServer, AzureMLOnlineInferencingServer, CustomInferencingServer, TritonInferencingServer.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+    }
+
+    _subtype_map = {
+        "server_type": {
+            "AzureMLBatch": "AzureMLBatchInferencingServer",
+            "AzureMLOnline": "AzureMLOnlineInferencingServer",
+            "Custom": "CustomInferencingServer",
+            "Triton": "TritonInferencingServer",
+        }
+    }
+
+    def __init__(self, **kwargs):
+        """ """
+        super(InferencingServer, self).__init__(**kwargs)
+        self.server_type = None  # type: Optional[str]
+
+
+class AzureMLBatchInferencingServer(InferencingServer):
+    """Azure ML batch inferencing server configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar code_configuration: Code configuration for AML batch inferencing server.
+    :vartype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "code_configuration": {"key": "codeConfiguration", "type": "CodeConfiguration"},
+    }
+
+    def __init__(self, *, code_configuration: Optional["CodeConfiguration"] = None, **kwargs):
+        """
+        :keyword code_configuration: Code configuration for AML batch inferencing server.
+        :paramtype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+        """
+        super(AzureMLBatchInferencingServer, self).__init__(**kwargs)
+        self.server_type = "AzureMLBatch"  # type: str
+        self.code_configuration = code_configuration
+
+
+class AzureMLOnlineInferencingServer(InferencingServer):
+    """Azure ML online inferencing configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar code_configuration: Code configuration for AML inferencing server.
+    :vartype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "code_configuration": {"key": "codeConfiguration", "type": "CodeConfiguration"},
+    }
+
+    def __init__(self, *, code_configuration: Optional["CodeConfiguration"] = None, **kwargs):
+        """
+        :keyword code_configuration: Code configuration for AML inferencing server.
+        :paramtype code_configuration: ~azure.mgmt.machinelearningservices.models.CodeConfiguration
+        """
+        super(AzureMLOnlineInferencingServer, self).__init__(**kwargs)
+        self.server_type = "AzureMLOnline"  # type: str
+        self.code_configuration = code_configuration
+
+
 class EarlyTerminationPolicy(msrest.serialization.Model):
     """Early termination policies enable canceling poor-performing runs before they complete.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: BanditPolicy, MedianStoppingPolicy, TruncationSelectionPolicy.
 
     All required parameters must be populated in order to send to Azure.
@@ -1014,34 +1043,32 @@
     :ivar policy_type: Required. Name of policy configuration.Constant filled by server. Possible
      values include: "Bandit", "MedianStopping", "TruncationSelection".
     :vartype policy_type: str or
      ~azure.mgmt.machinelearningservices.models.EarlyTerminationPolicyType
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
     }
 
     _subtype_map = {
-        'policy_type': {'Bandit': 'BanditPolicy', 'MedianStopping': 'MedianStoppingPolicy', 'TruncationSelection': 'TruncationSelectionPolicy'}
+        "policy_type": {
+            "Bandit": "BanditPolicy",
+            "MedianStopping": "MedianStoppingPolicy",
+            "TruncationSelection": "TruncationSelectionPolicy",
+        }
     }
 
-    def __init__(
-        self,
-        *,
-        delay_evaluation: Optional[int] = 0,
-        evaluation_interval: Optional[int] = 0,
-        **kwargs
-    ):
+    def __init__(self, *, delay_evaluation: Optional[int] = 0, evaluation_interval: Optional[int] = 0, **kwargs):
         """
         :keyword delay_evaluation: Number of intervals by which to delay the first evaluation.
         :paramtype delay_evaluation: int
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         """
         super(EarlyTerminationPolicy, self).__init__(**kwargs)
@@ -1066,23 +1093,23 @@
     :ivar slack_amount: Absolute distance allowed from the best performing run.
     :vartype slack_amount: float
     :ivar slack_factor: Ratio of the allowed distance from the best performing run.
     :vartype slack_factor: float
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
-        'slack_amount': {'key': 'slackAmount', 'type': 'float'},
-        'slack_factor': {'key': 'slackFactor', 'type': 'float'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
+        "slack_amount": {"key": "slackAmount", "type": "float"},
+        "slack_factor": {"key": "slackFactor", "type": "float"},
     }
 
     def __init__(
         self,
         *,
         delay_evaluation: Optional[int] = 0,
         evaluation_interval: Optional[int] = 0,
@@ -1096,51 +1123,110 @@
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         :keyword slack_amount: Absolute distance allowed from the best performing run.
         :paramtype slack_amount: float
         :keyword slack_factor: Ratio of the allowed distance from the best performing run.
         :paramtype slack_factor: float
         """
-        super(BanditPolicy, self).__init__(delay_evaluation=delay_evaluation, evaluation_interval=evaluation_interval, **kwargs)
-        self.policy_type = 'Bandit'  # type: str
+        super(BanditPolicy, self).__init__(
+            delay_evaluation=delay_evaluation, evaluation_interval=evaluation_interval, **kwargs
+        )
+        self.policy_type = "Bandit"  # type: str
         self.slack_amount = slack_amount
         self.slack_factor = slack_factor
 
 
+class BaseEnvironmentSource(msrest.serialization.Model):
+    """BaseEnvironmentSource.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: BaseEnvironmentId.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar base_environment_source_type: Required. Base environment type.Constant filled by server.
+     Possible values include: "EnvironmentAsset".
+    :vartype base_environment_source_type: str or
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSourceType
+    """
+
+    _validation = {
+        "base_environment_source_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "base_environment_source_type": {"key": "baseEnvironmentSourceType", "type": "str"},
+    }
+
+    _subtype_map = {"base_environment_source_type": {"EnvironmentAsset": "BaseEnvironmentId"}}
+
+    def __init__(self, **kwargs):
+        """ """
+        super(BaseEnvironmentSource, self).__init__(**kwargs)
+        self.base_environment_source_type = None  # type: Optional[str]
+
+
+class BaseEnvironmentId(BaseEnvironmentSource):
+    """Base environment type.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar base_environment_source_type: Required. Base environment type.Constant filled by server.
+     Possible values include: "EnvironmentAsset".
+    :vartype base_environment_source_type: str or
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSourceType
+    :ivar resource_id: Required. Resource id accepting ArmId or AzureMlId.
+    :vartype resource_id: str
+    """
+
+    _validation = {
+        "base_environment_source_type": {"required": True},
+        "resource_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+    }
+
+    _attribute_map = {
+        "base_environment_source_type": {"key": "baseEnvironmentSourceType", "type": "str"},
+        "resource_id": {"key": "resourceId", "type": "str"},
+    }
+
+    def __init__(self, *, resource_id: str, **kwargs):
+        """
+        :keyword resource_id: Required. Resource id accepting ArmId or AzureMlId.
+        :paramtype resource_id: str
+        """
+        super(BaseEnvironmentId, self).__init__(**kwargs)
+        self.base_environment_source_type = "EnvironmentAsset"  # type: str
+        self.resource_id = resource_id
+
+
 class Binding(msrest.serialization.Model):
     """Binding Inputs/Outputs to ComponentJob Inputs/Outputs etc.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: BasicBinding.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar binding_type: Required. Type of Binding.Constant filled by server. Possible values
      include: "Basic".
     :vartype binding_type: str or ~azure.mgmt.machinelearningservices.models.BindingType
     """
 
     _validation = {
-        'binding_type': {'required': True},
+        "binding_type": {"required": True},
     }
 
     _attribute_map = {
-        'binding_type': {'key': 'bindingType', 'type': 'str'},
+        "binding_type": {"key": "bindingType", "type": "str"},
     }
 
-    _subtype_map = {
-        'binding_type': {'Basic': 'BasicBinding'}
-    }
+    _subtype_map = {"binding_type": {"Basic": "BasicBinding"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(Binding, self).__init__(**kwargs)
         self.binding_type = None  # type: Optional[str]
 
 
 class BasicBinding(Binding):
     """Basic binding with simple source and destination.
 
@@ -1152,38 +1238,32 @@
     :ivar destination: Destination reference.
     :vartype destination: str
     :ivar source: Source reference.
     :vartype source: str
     """
 
     _validation = {
-        'binding_type': {'required': True},
+        "binding_type": {"required": True},
     }
 
     _attribute_map = {
-        'binding_type': {'key': 'bindingType', 'type': 'str'},
-        'destination': {'key': 'destination', 'type': 'str'},
-        'source': {'key': 'source', 'type': 'str'},
+        "binding_type": {"key": "bindingType", "type": "str"},
+        "destination": {"key": "destination", "type": "str"},
+        "source": {"key": "source", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        destination: Optional[str] = None,
-        source: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, destination: Optional[str] = None, source: Optional[str] = None, **kwargs):
         """
         :keyword destination: Destination reference.
         :paramtype destination: str
         :keyword source: Source reference.
         :paramtype source: str
         """
         super(BasicBinding, self).__init__(**kwargs)
-        self.binding_type = 'Basic'  # type: str
+        self.binding_type = "Basic"  # type: str
         self.destination = destination
         self.source = source
 
 
 class BlobReferenceForConsumptionDto(msrest.serialization.Model):
     """BlobReferenceForConsumptionDto.
 
@@ -1192,17 +1272,17 @@
     :ivar credential:
     :vartype credential: ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialDto
     :ivar storage_account_arm_id:
     :vartype storage_account_arm_id: str
     """
 
     _attribute_map = {
-        'blob_uri': {'key': 'blobUri', 'type': 'str'},
-        'credential': {'key': 'credential', 'type': 'DataReferenceCredentialDto'},
-        'storage_account_arm_id': {'key': 'storageAccountArmId', 'type': 'str'},
+        "blob_uri": {"key": "blobUri", "type": "str"},
+        "credential": {"key": "credential", "type": "DataReferenceCredentialDto"},
+        "storage_account_arm_id": {"key": "storageAccountArmId", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         blob_uri: Optional[str] = None,
         credential: Optional["DataReferenceCredentialDto"] = None,
@@ -1229,25 +1309,19 @@
     :ivar asset_id:
     :vartype asset_id: str
     :ivar blob_uri:
     :vartype blob_uri: str
     """
 
     _attribute_map = {
-        'asset_id': {'key': 'assetId', 'type': 'str'},
-        'blob_uri': {'key': 'blobUri', 'type': 'str'},
+        "asset_id": {"key": "assetId", "type": "str"},
+        "blob_uri": {"key": "blobUri", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        asset_id: Optional[str] = None,
-        blob_uri: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, asset_id: Optional[str] = None, blob_uri: Optional[str] = None, **kwargs):
         """
         :keyword asset_id:
         :paramtype asset_id: str
         :keyword blob_uri:
         :paramtype blob_uri: str
         """
         super(BlobReferenceSASRequestDto, self).__init__(**kwargs)
@@ -1260,23 +1334,21 @@
 
     :ivar blob_reference_for_consumption:
     :vartype blob_reference_for_consumption:
      ~azure.mgmt.machinelearningservices.models.BlobReferenceForConsumptionDto
     """
 
     _attribute_map = {
-        'blob_reference_for_consumption': {'key': 'blobReferenceForConsumption', 'type': 'BlobReferenceForConsumptionDto'},
+        "blob_reference_for_consumption": {
+            "key": "blobReferenceForConsumption",
+            "type": "BlobReferenceForConsumptionDto",
+        },
     }
 
-    def __init__(
-        self,
-        *,
-        blob_reference_for_consumption: Optional["BlobReferenceForConsumptionDto"] = None,
-        **kwargs
-    ):
+    def __init__(self, *, blob_reference_for_consumption: Optional["BlobReferenceForConsumptionDto"] = None, **kwargs):
         """
         :keyword blob_reference_for_consumption:
         :paramtype blob_reference_for_consumption:
          ~azure.mgmt.machinelearningservices.models.BlobReferenceForConsumptionDto
         """
         super(BlobReferenceSASResponseDto, self).__init__(**kwargs)
         self.blob_reference_for_consumption = blob_reference_for_consumption
@@ -1285,61 +1357,55 @@
 class BuildContext(msrest.serialization.Model):
     """Configuration settings for Docker build context.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar context_uri: Required. URI of the Docker build context used to build the image. Supports
      blob URIs on environment creation and may return blob or Git URIs.
-    
-    
+
+
      .. raw:: html
-    
+
         <seealso
      href="https://docs.docker.com/engine/reference/commandline/build/#extended-description" />.
     :vartype context_uri: str
     :ivar dockerfile_path: Path to the Dockerfile in the build context.
-    
-    
+
+
      .. raw:: html
-    
+
         <seealso href="https://docs.docker.com/engine/reference/builder/" />.
     :vartype dockerfile_path: str
     """
 
     _validation = {
-        'context_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "context_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'context_uri': {'key': 'contextUri', 'type': 'str'},
-        'dockerfile_path': {'key': 'dockerfilePath', 'type': 'str'},
+        "context_uri": {"key": "contextUri", "type": "str"},
+        "dockerfile_path": {"key": "dockerfilePath", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        context_uri: str,
-        dockerfile_path: Optional[str] = "Dockerfile",
-        **kwargs
-    ):
+    def __init__(self, *, context_uri: str, dockerfile_path: Optional[str] = "Dockerfile", **kwargs):
         """
         :keyword context_uri: Required. URI of the Docker build context used to build the image.
          Supports blob URIs on environment creation and may return blob or Git URIs.
-        
-        
+
+
          .. raw:: html
-        
+
             <seealso
          href="https://docs.docker.com/engine/reference/commandline/build/#extended-description" />.
         :paramtype context_uri: str
         :keyword dockerfile_path: Path to the Dockerfile in the build context.
-        
-        
+
+
          .. raw:: html
-        
+
             <seealso href="https://docs.docker.com/engine/reference/builder/" />.
         :paramtype dockerfile_path: str
         """
         super(BuildContext, self).__init__(**kwargs)
         self.context_uri = context_uri
         self.dockerfile_path = dockerfile_path
 
@@ -1364,29 +1430,29 @@
     :ivar tenant_id: Required. ID of the tenant to which the service principal belongs.
     :vartype tenant_id: str
     :ivar thumbprint: Required. Thumbprint of the certificate used for authentication.
     :vartype thumbprint: str
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'client_id': {'required': True},
-        'secrets': {'required': True},
-        'tenant_id': {'required': True},
-        'thumbprint': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "credentials_type": {"required": True},
+        "client_id": {"required": True},
+        "secrets": {"required": True},
+        "tenant_id": {"required": True},
+        "thumbprint": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'authority_url': {'key': 'authorityUrl', 'type': 'str'},
-        'client_id': {'key': 'clientId', 'type': 'str'},
-        'resource_url': {'key': 'resourceUrl', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'CertificateDatastoreSecrets'},
-        'tenant_id': {'key': 'tenantId', 'type': 'str'},
-        'thumbprint': {'key': 'thumbprint', 'type': 'str'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "authority_url": {"key": "authorityUrl", "type": "str"},
+        "client_id": {"key": "clientId", "type": "str"},
+        "resource_url": {"key": "resourceUrl", "type": "str"},
+        "secrets": {"key": "secrets", "type": "CertificateDatastoreSecrets"},
+        "tenant_id": {"key": "tenantId", "type": "str"},
+        "thumbprint": {"key": "thumbprint", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         client_id: str,
         secrets: "CertificateDatastoreSecrets",
@@ -1407,15 +1473,15 @@
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.CertificateDatastoreSecrets
         :keyword tenant_id: Required. ID of the tenant to which the service principal belongs.
         :paramtype tenant_id: str
         :keyword thumbprint: Required. Thumbprint of the certificate used for authentication.
         :paramtype thumbprint: str
         """
         super(CertificateDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'Certificate'  # type: str
+        self.credentials_type = "Certificate"  # type: str
         self.authority_url = authority_url
         self.client_id = client_id
         self.resource_url = resource_url
         self.secrets = secrets
         self.tenant_id = tenant_id
         self.thumbprint = thumbprint
 
@@ -1430,37 +1496,64 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar certificate: Service principal certificate.
     :vartype certificate: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'certificate': {'key': 'certificate', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "certificate": {"key": "certificate", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        certificate: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, certificate: Optional[str] = None, **kwargs):
         """
         :keyword certificate: Service principal certificate.
         :paramtype certificate: str
         """
         super(CertificateDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'Certificate'  # type: str
+        self.secrets_type = "Certificate"  # type: str
         self.certificate = certificate
 
 
+class CodeConfiguration(msrest.serialization.Model):
+    """Configuration for a scoring code asset.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar code_id: ARM resource ID of the code asset.
+    :vartype code_id: str
+    :ivar scoring_script: Required. The script to execute on startup. eg. "score.py".
+    :vartype scoring_script: str
+    """
+
+    _validation = {
+        "scoring_script": {"required": True, "min_length": 1, "pattern": r"[a-zA-Z0-9_]"},
+    }
+
+    _attribute_map = {
+        "code_id": {"key": "codeId", "type": "str"},
+        "scoring_script": {"key": "scoringScript", "type": "str"},
+    }
+
+    def __init__(self, *, scoring_script: str, code_id: Optional[str] = None, **kwargs):
+        """
+        :keyword code_id: ARM resource ID of the code asset.
+        :paramtype code_id: str
+        :keyword scoring_script: Required. The script to execute on startup. eg. "score.py".
+        :paramtype scoring_script: str
+        """
+        super(CodeConfiguration, self).__init__(**kwargs)
+        self.code_id = code_id
+        self.scoring_script = scoring_script
+
+
 class Resource(msrest.serialization.Model):
     """Common fields that are returned in the response for all Azure Resource Manager resources.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     :ivar id: Fully qualified resource ID for the resource. Ex -
      /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}.
@@ -1472,33 +1565,29 @@
     :vartype type: str
     :ivar system_data: Azure Resource Manager metadata containing createdBy and modifiedBy
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(Resource, self).__init__(**kwargs)
         self.id = None
         self.name = None
         self.type = None
         self.system_data = None
 
 
@@ -1521,35 +1610,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.CodeContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'CodeContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "CodeContainerDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "CodeContainerDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "CodeContainerDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.CodeContainerDetails
         """
         super(CodeContainerData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -1570,25 +1654,25 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -1602,39 +1686,35 @@
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         """
-        super(CodeContainerDetails, self).__init__(description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs)
+        super(CodeContainerDetails, self).__init__(
+            description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs
+        )
 
 
 class CodeContainerResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of CodeContainer entities.
 
     :ivar next_link: The link to the next page of CodeContainer objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type CodeContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.CodeContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[CodeContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[CodeContainerData]"},
     }
 
-    def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["CodeContainerData"]] = None,
-        **kwargs
-    ):
+    def __init__(self, *, next_link: Optional[str] = None, value: Optional[List["CodeContainerData"]] = None, **kwargs):
         """
         :keyword next_link: The link to the next page of CodeContainer objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type CodeContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.CodeContainerData]
         """
@@ -1662,35 +1742,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.CodeVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'CodeVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "CodeVersionDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "CodeVersionDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "CodeVersionDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.CodeVersionDetails
         """
         super(CodeVersionData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -1709,20 +1784,20 @@
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     :ivar code_uri: Uri where code is located.
     :vartype code_uri: str
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'code_uri': {'key': 'codeUri', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "code_uri": {"key": "codeUri", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -1742,40 +1817,41 @@
         :keyword is_anonymous: If the name version are system generated (anonymous registration).
         :paramtype is_anonymous: bool
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword code_uri: Uri where code is located.
         :paramtype code_uri: str
         """
-        super(CodeVersionDetails, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, **kwargs)
+        super(CodeVersionDetails, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            **kwargs
+        )
         self.code_uri = code_uri
 
 
 class CodeVersionResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of CodeVersion entities.
 
     :ivar next_link: The link to the next page of CodeVersion objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type CodeVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.CodeVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[CodeVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[CodeVersionData]"},
     }
 
-    def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["CodeVersionData"]] = None,
-        **kwargs
-    ):
+    def __init__(self, *, next_link: Optional[str] = None, value: Optional[List["CodeVersionData"]] = None, **kwargs):
         """
         :keyword next_link: The link to the next page of CodeVersion objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type CodeVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.CodeVersionData]
         """
@@ -1820,35 +1896,35 @@
     :ivar status: Status of the job. Possible values include: "NotStarted", "Starting",
      "Provisioning", "Preparing", "Queued", "Running", "Finalizing", "CancelRequested", "Completed",
      "Failed", "Canceled", "NotResponding", "Paused", "Unknown".
     :vartype status: str or ~azure.mgmt.machinelearningservices.models.JobStatus
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
     }
 
     _subtype_map = {
-        'job_type': {'Base': 'Job', 'Command': 'CommandJob', 'Pipeline': 'PipelineJob', 'Sweep': 'SweepJob'}
+        "job_type": {"Base": "Job", "Command": "CommandJob", "Pipeline": "PipelineJob", "Sweep": "SweepJob"}
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -1881,15 +1957,15 @@
         :paramtype services: dict[str, ~azure.mgmt.machinelearningservices.models.JobService]
         """
         super(JobBase, self).__init__(description=description, properties=properties, tags=tags, **kwargs)
         self.compute_id = compute_id
         self.display_name = display_name
         self.experiment_name = experiment_name
         self.is_archived = is_archived
-        self.job_type = 'JobBase'  # type: str
+        self.job_type = "JobBase"  # type: str
         self.parent_job_name = None
         self.services = services
         self.status = None
 
 
 class CommandJob(JobBase):
     """Command job definition.
@@ -1950,45 +2026,45 @@
     :ivar parameters: Input parameters.
     :vartype parameters: any
     :ivar resources: Compute Resource configuration for the job.
     :vartype resources: ~azure.mgmt.machinelearningservices.models.ResourceConfiguration
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
-        'command': {'required': True, 'min_length': 1, 'pattern': r'[a-zA-Z0-9_]'},
-        'environment_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'parameters': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
+        "command": {"required": True, "min_length": 1, "pattern": r"[a-zA-Z0-9_]"},
+        "environment_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "parameters": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
-        'code_id': {'key': 'codeId', 'type': 'str'},
-        'command': {'key': 'command', 'type': 'str'},
-        'distribution': {'key': 'distribution', 'type': 'DistributionConfiguration'},
-        'environment_id': {'key': 'environmentId', 'type': 'str'},
-        'environment_variables': {'key': 'environmentVariables', 'type': '{str}'},
-        'identity': {'key': 'identity', 'type': 'IdentityConfiguration'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'limits': {'key': 'limits', 'type': 'CommandJobLimits'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'parameters': {'key': 'parameters', 'type': 'object'},
-        'resources': {'key': 'resources', 'type': 'ResourceConfiguration'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
+        "code_id": {"key": "codeId", "type": "str"},
+        "command": {"key": "command", "type": "str"},
+        "distribution": {"key": "distribution", "type": "DistributionConfiguration"},
+        "environment_id": {"key": "environmentId", "type": "str"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "identity": {"key": "identity", "type": "IdentityConfiguration"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "limits": {"key": "limits", "type": "CommandJobLimits"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "parameters": {"key": "parameters", "type": "object"},
+        "resources": {"key": "resources", "type": "ResourceConfiguration"},
     }
 
     def __init__(
         self,
         *,
         command: str,
         environment_id: str,
@@ -2051,16 +2127,26 @@
         :keyword limits: Command Job limit.
         :paramtype limits: ~azure.mgmt.machinelearningservices.models.CommandJobLimits
         :keyword outputs: Mapping of output data bindings used in the job.
         :paramtype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
         :keyword resources: Compute Resource configuration for the job.
         :paramtype resources: ~azure.mgmt.machinelearningservices.models.ResourceConfiguration
         """
-        super(CommandJob, self).__init__(description=description, properties=properties, tags=tags, compute_id=compute_id, display_name=display_name, experiment_name=experiment_name, is_archived=is_archived, services=services, **kwargs)
-        self.job_type = 'Command'  # type: str
+        super(CommandJob, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            compute_id=compute_id,
+            display_name=display_name,
+            experiment_name=experiment_name,
+            is_archived=is_archived,
+            services=services,
+            **kwargs
+        )
+        self.job_type = "Command"  # type: str
         self.code_id = code_id
         self.command = command
         self.distribution = distribution
         self.environment_id = environment_id
         self.environment_variables = environment_variables
         self.identity = identity
         self.inputs = inputs
@@ -2083,32 +2169,25 @@
     :vartype job_limits_type: str or ~azure.mgmt.machinelearningservices.models.JobLimitsType
     :ivar timeout: The max run duration in ISO 8601 format, after which the job will be cancelled.
      Only supports duration with precision as low as Seconds.
     :vartype timeout: ~datetime.timedelta
     """
 
     _validation = {
-        'job_limits_type': {'required': True},
+        "job_limits_type": {"required": True},
     }
 
     _attribute_map = {
-        'job_limits_type': {'key': 'jobLimitsType', 'type': 'str'},
-        'timeout': {'key': 'timeout', 'type': 'duration'},
+        "job_limits_type": {"key": "jobLimitsType", "type": "str"},
+        "timeout": {"key": "timeout", "type": "duration"},
     }
 
-    _subtype_map = {
-        'job_limits_type': {'Command': 'CommandJobLimits', 'Sweep': 'SweepJobLimits'}
-    }
+    _subtype_map = {"job_limits_type": {"Command": "CommandJobLimits", "Sweep": "SweepJobLimits"}}
 
-    def __init__(
-        self,
-        *,
-        timeout: Optional[datetime.timedelta] = None,
-        **kwargs
-    ):
+    def __init__(self, *, timeout: Optional[datetime.timedelta] = None, **kwargs):
         """
         :keyword timeout: The max run duration in ISO 8601 format, after which the job will be
          cancelled. Only supports duration with precision as low as Seconds.
         :paramtype timeout: ~datetime.timedelta
         """
         super(JobLimits, self).__init__(**kwargs)
         self.job_limits_type = None  # type: Optional[str]
@@ -2125,35 +2204,30 @@
     :vartype job_limits_type: str or ~azure.mgmt.machinelearningservices.models.JobLimitsType
     :ivar timeout: The max run duration in ISO 8601 format, after which the job will be cancelled.
      Only supports duration with precision as low as Seconds.
     :vartype timeout: ~datetime.timedelta
     """
 
     _validation = {
-        'job_limits_type': {'required': True},
+        "job_limits_type": {"required": True},
     }
 
     _attribute_map = {
-        'job_limits_type': {'key': 'jobLimitsType', 'type': 'str'},
-        'timeout': {'key': 'timeout', 'type': 'duration'},
+        "job_limits_type": {"key": "jobLimitsType", "type": "str"},
+        "timeout": {"key": "timeout", "type": "duration"},
     }
 
-    def __init__(
-        self,
-        *,
-        timeout: Optional[datetime.timedelta] = None,
-        **kwargs
-    ):
+    def __init__(self, *, timeout: Optional[datetime.timedelta] = None, **kwargs):
         """
         :keyword timeout: The max run duration in ISO 8601 format, after which the job will be
          cancelled. Only supports duration with precision as low as Seconds.
         :paramtype timeout: ~datetime.timedelta
         """
         super(CommandJobLimits, self).__init__(timeout=timeout, **kwargs)
-        self.job_limits_type = 'Command'  # type: str
+        self.job_limits_type = "Command"  # type: str
 
 
 class ComponentContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
@@ -2171,79 +2245,74 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ComponentContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ComponentContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ComponentContainerDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "ComponentContainerDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "ComponentContainerDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ComponentContainerDetails
         """
         super(ComponentContainerData, self).__init__(**kwargs)
         self.properties = properties
 
 
 class ComponentContainerDetails(AssetContainer):
     """Component container definition.
 
 
-.. raw:: html
+    .. raw:: html
 
-   <see href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command" />.
+       <see href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command" />.
 
-    Variables are only populated by the server, and will be ignored when sending a request.
+        Variables are only populated by the server, and will be ignored when sending a request.
 
-    :ivar description: The asset description text.
-    :vartype description: str
-    :ivar properties: The asset property dictionary.
-    :vartype properties: dict[str, str]
-    :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
-    :vartype tags: dict[str, str]
-    :ivar is_archived: Is the asset archived?.
-    :vartype is_archived: bool
-    :ivar latest_version: The latest version inside this container.
-    :vartype latest_version: str
-    :ivar next_version: The next auto incremental version.
-    :vartype next_version: str
+        :ivar description: The asset description text.
+        :vartype description: str
+        :ivar properties: The asset property dictionary.
+        :vartype properties: dict[str, str]
+        :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+        :vartype tags: dict[str, str]
+        :ivar is_archived: Is the asset archived?.
+        :vartype is_archived: bool
+        :ivar latest_version: The latest version inside this container.
+        :vartype latest_version: str
+        :ivar next_version: The next auto incremental version.
+        :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -2257,38 +2326,36 @@
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         """
-        super(ComponentContainerDetails, self).__init__(description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs)
+        super(ComponentContainerDetails, self).__init__(
+            description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs
+        )
 
 
 class ComponentContainerResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of ComponentContainer entities.
 
     :ivar next_link: The link to the next page of ComponentContainer objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ComponentContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ComponentContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ComponentContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ComponentContainerData]"},
     }
 
     def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["ComponentContainerData"]] = None,
-        **kwargs
+        self, *, next_link: Optional[str] = None, value: Optional[List["ComponentContainerData"]] = None, **kwargs
     ):
         """
         :keyword next_link: The link to the next page of ComponentContainer objects. If null, there are
          no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ComponentContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ComponentContainerData]
@@ -2310,19 +2377,19 @@
     :ivar outputs: Data output set for job.
     :vartype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
     :ivar overrides: Override component default settings.
     :vartype overrides: any
     """
 
     _attribute_map = {
-        'component_id': {'key': 'componentId', 'type': 'str'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'overrides': {'key': 'overrides', 'type': 'object'},
+        "component_id": {"key": "componentId", "type": "str"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "overrides": {"key": "overrides", "type": "object"},
     }
 
     def __init__(
         self,
         *,
         component_id: Optional[str] = None,
         compute_id: Optional[str] = None,
@@ -2370,35 +2437,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ComponentVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ComponentVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ComponentVersionDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "ComponentVersionDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "ComponentVersionDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ComponentVersionDetails
         """
         super(ComponentVersionData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -2413,31 +2475,31 @@
     :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
     :vartype tags: dict[str, str]
     :ivar is_anonymous: If the name version are system generated (anonymous registration).
     :vartype is_anonymous: bool
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     :ivar component_spec: Defines Component definition details.
-    
-    
+
+
      .. raw:: html
-    
+
         <see
      href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command"
      />.
     :vartype component_spec: any
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'component_spec': {'key': 'componentSpec', 'type': 'object'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "component_spec": {"key": "componentSpec", "type": "object"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -2455,61 +2517,97 @@
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_anonymous: If the name version are system generated (anonymous registration).
         :paramtype is_anonymous: bool
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword component_spec: Defines Component definition details.
-        
-        
+
+
          .. raw:: html
-        
+
             <see
          href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command"
          />.
         :paramtype component_spec: any
         """
-        super(ComponentVersionDetails, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, **kwargs)
+        super(ComponentVersionDetails, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            **kwargs
+        )
         self.component_spec = component_spec
 
 
 class ComponentVersionResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of ComponentVersion entities.
 
     :ivar next_link: The link to the next page of ComponentVersion objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ComponentVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ComponentVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ComponentVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ComponentVersionData]"},
     }
 
     def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["ComponentVersionData"]] = None,
-        **kwargs
+        self, *, next_link: Optional[str] = None, value: Optional[List["ComponentVersionData"]] = None, **kwargs
     ):
         """
         :keyword next_link: The link to the next page of ComponentVersion objects. If null, there are
          no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ComponentVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ComponentVersionData]
         """
         super(ComponentVersionResourceArmPaginatedResult, self).__init__(**kwargs)
         self.next_link = next_link
         self.value = value
 
 
+class CustomInferencingServer(InferencingServer):
+    """Custom inference server configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar inference_configuration: Inference configuration for custom inferencing.
+    :vartype inference_configuration:
+     ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "inference_configuration": {"key": "inferenceConfiguration", "type": "OnlineInferenceConfiguration"},
+    }
+
+    def __init__(self, *, inference_configuration: Optional["OnlineInferenceConfiguration"] = None, **kwargs):
+        """
+        :keyword inference_configuration: Inference configuration for custom inferencing.
+        :paramtype inference_configuration:
+         ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+        """
+        super(CustomInferencingServer, self).__init__(**kwargs)
+        self.server_type = "Custom"  # type: str
+        self.inference_configuration = inference_configuration
+
+
 class DataContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -2525,35 +2623,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.DataContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'DataContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "DataContainerDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "DataContainerDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "DataContainerDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.DataContainerDetails
         """
         super(DataContainerData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -2579,27 +2672,27 @@
     :vartype next_version: str
     :ivar data_type: Required. Specifies the type of data. Possible values include: "uri_file",
      "uri_folder", "mltable".
     :vartype data_type: str or ~azure.mgmt.machinelearningservices.models.DataType
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
-        'data_type': {'required': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
+        "data_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
+        "data_type": {"key": "dataType", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         data_type: Union[str, "DataType"],
         description: Optional[str] = None,
@@ -2617,40 +2710,36 @@
         :paramtype tags: dict[str, str]
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword data_type: Required. Specifies the type of data. Possible values include: "uri_file",
          "uri_folder", "mltable".
         :paramtype data_type: str or ~azure.mgmt.machinelearningservices.models.DataType
         """
-        super(DataContainerDetails, self).__init__(description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs)
+        super(DataContainerDetails, self).__init__(
+            description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs
+        )
         self.data_type = data_type
 
 
 class DataContainerResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of DataContainer entities.
 
     :ivar next_link: The link to the next page of DataContainer objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type DataContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.DataContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[DataContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[DataContainerData]"},
     }
 
-    def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["DataContainerData"]] = None,
-        **kwargs
-    ):
+    def __init__(self, *, next_link: Optional[str] = None, value: Optional[List["DataContainerData"]] = None, **kwargs):
         """
         :keyword next_link: The link to the next page of DataContainer objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type DataContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.DataContainerData]
         """
@@ -2670,42 +2759,66 @@
     :ivar datastore_id: ARM resource ID of the datastore where the asset is located.
     :vartype datastore_id: str
     :ivar path: The path of the file/directory in the datastore.
     :vartype path: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
+        "reference_type": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'datastore_id': {'key': 'datastoreId', 'type': 'str'},
-        'path': {'key': 'path', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "datastore_id": {"key": "datastoreId", "type": "str"},
+        "path": {"key": "path", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        datastore_id: Optional[str] = None,
-        path: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, datastore_id: Optional[str] = None, path: Optional[str] = None, **kwargs):
         """
         :keyword datastore_id: ARM resource ID of the datastore where the asset is located.
         :paramtype datastore_id: str
         :keyword path: The path of the file/directory in the datastore.
         :paramtype path: str
         """
         super(DataPathAssetReference, self).__init__(**kwargs)
-        self.reference_type = 'DataPath'  # type: str
+        self.reference_type = "DataPath"  # type: str
         self.datastore_id = datastore_id
         self.path = path
 
 
+class DataReferenceCredentialDto(msrest.serialization.Model):
+    """DataReferenceCredentialDto.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: .
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
+     "DockerCredentials", "ManagedIdentity", "NoCredentials".
+    :vartype credential_type: str or
+     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
+    """
+
+    _validation = {
+        "credential_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "credential_type": {"key": "credentialType", "type": "str"},
+    }
+
+    _subtype_map = {"credential_type": {}}
+
+    def __init__(self, **kwargs):
+        """ """
+        super(DataReferenceCredentialDto, self).__init__(**kwargs)
+        self.credential_type = "SAS"  # type: str
+
+
 class DataVersionBaseData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -2721,35 +2834,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.DataVersionBaseDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'DataVersionBaseDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "DataVersionBaseDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "DataVersionBaseDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "DataVersionBaseDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.DataVersionBaseDetails
         """
         super(DataVersionBaseData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -2780,31 +2888,31 @@
     :vartype data_uri: str
     :ivar intellectual_property: Intellectual Property details. Used if data is an Intellectual
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
     }
 
     _subtype_map = {
-        'data_type': {'mltable': 'MLTableData', 'uri_file': 'UriFileDataVersion', 'uri_folder': 'UriFolderDataVersion'}
+        "data_type": {"mltable": "MLTableData", "uri_file": "UriFileDataVersion", "uri_folder": "UriFolderDataVersion"}
     }
 
     def __init__(
         self,
         *,
         data_uri: str,
         description: Optional[str] = None,
@@ -2830,16 +2938,23 @@
          Microsoft.MachineLearning.ManagementFrontEnd.Contracts.V20211001Dataplane.Assets.DataVersionBase.DataType.
         :paramtype data_uri: str
         :keyword intellectual_property: Intellectual Property details. Used if data is an Intellectual
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         """
-        super(DataVersionBaseDetails, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, **kwargs)
-        self.data_type = 'DataVersionBaseDetails'  # type: str
+        super(DataVersionBaseDetails, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            **kwargs
+        )
+        self.data_type = "DataVersionBaseDetails"  # type: str
         self.data_uri = data_uri
         self.intellectual_property = intellectual_property
 
 
 class DataVersionBaseResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of DataVersionBase entities.
 
@@ -2847,24 +2962,20 @@
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type DataVersionBase.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.DataVersionBaseData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[DataVersionBaseData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[DataVersionBaseData]"},
     }
 
     def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["DataVersionBaseData"]] = None,
-        **kwargs
+        self, *, next_link: Optional[str] = None, value: Optional[List["DataVersionBaseData"]] = None, **kwargs
     ):
         """
         :keyword next_link: The link to the next page of DataVersionBase objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type DataVersionBase.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.DataVersionBaseData]
@@ -2884,75 +2995,51 @@
 
     :ivar distribution_type: Required. Specifies the type of distribution framework.Constant filled
      by server. Possible values include: "PyTorch", "TensorFlow", "Mpi".
     :vartype distribution_type: str or ~azure.mgmt.machinelearningservices.models.DistributionType
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
     }
 
-    _subtype_map = {
-        'distribution_type': {'Mpi': 'Mpi', 'PyTorch': 'PyTorch', 'TensorFlow': 'TensorFlow'}
-    }
+    _subtype_map = {"distribution_type": {"Mpi": "Mpi", "PyTorch": "PyTorch", "TensorFlow": "TensorFlow"}}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(DistributionConfiguration, self).__init__(**kwargs)
         self.distribution_type = None  # type: Optional[str]
 
 
-class DockerCredentialDto(DataReferenceCredentialDto):
+class DockerCredentialDto(msrest.serialization.Model):
     """DockerCredentialDto.
 
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
     :ivar password:
     :vartype password: str
     :ivar user_name:
     :vartype user_name: str
     """
 
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
     _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-        'password': {'key': 'password', 'type': 'str'},
-        'user_name': {'key': 'userName', 'type': 'str'},
+        "password": {"key": "password", "type": "str"},
+        "user_name": {"key": "userName", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        password: Optional[str] = None,
-        user_name: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, password: Optional[str] = None, user_name: Optional[str] = None, **kwargs):
         """
         :keyword password:
         :paramtype password: str
         :keyword user_name:
         :paramtype user_name: str
         """
         super(DockerCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'DockerCredentials'  # type: str
         self.password = password
         self.user_name = user_name
 
 
 class EnvironmentContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
@@ -2972,35 +3059,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'EnvironmentContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "EnvironmentContainerDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "EnvironmentContainerDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "EnvironmentContainerDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerDetails
         """
         super(EnvironmentContainerData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -3021,25 +3103,25 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -3053,38 +3135,36 @@
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         """
-        super(EnvironmentContainerDetails, self).__init__(description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs)
+        super(EnvironmentContainerDetails, self).__init__(
+            description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs
+        )
 
 
 class EnvironmentContainerResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of EnvironmentContainer entities.
 
     :ivar next_link: The link to the next page of EnvironmentContainer objects. If null, there are
      no additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type EnvironmentContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[EnvironmentContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[EnvironmentContainerData]"},
     }
 
     def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["EnvironmentContainerData"]] = None,
-        **kwargs
+        self, *, next_link: Optional[str] = None, value: Optional[List["EnvironmentContainerData"]] = None, **kwargs
     ):
         """
         :keyword next_link: The link to the next page of EnvironmentContainer objects. If null, there
          are no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type EnvironmentContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentContainerData]
@@ -3113,35 +3193,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'EnvironmentVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "EnvironmentVersionDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "EnvironmentVersionDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "EnvironmentVersionDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionDetails
         """
         super(EnvironmentVersionData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -3161,37 +3236,37 @@
     :vartype is_anonymous: bool
     :ivar is_archived: Is the asset archived?.
     :vartype is_archived: bool
     :ivar build: Configuration settings for Docker build context.
     :vartype build: ~azure.mgmt.machinelearningservices.models.BuildContext
     :ivar conda_file: Standard configuration file used by Conda that lets you install any kind of
      package, including Python, R, and C/C++ packages.
-    
-    
+
+
      .. raw:: html
-    
+
         <see
      href="https://repo2docker.readthedocs.io/en/latest/config_files.html#environment-yml-install-a-conda-environment"
      />.
     :vartype conda_file: str
     :ivar environment_type: Environment type is either user managed or curated by the Azure ML
      service
-    
-    
+
+
      .. raw:: html
-    
+
         <see
      href="https://docs.microsoft.com/en-us/azure/machine-learning/resource-curated-environments"
      />. Possible values include: "Curated", "UserCreated".
     :vartype environment_type: str or ~azure.mgmt.machinelearningservices.models.EnvironmentType
     :ivar image: Name of the image that will be used for the environment.
-    
-    
+
+
      .. raw:: html
-    
+
         <seealso
      href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-custom-docker-image#use-a-custom-base-image"
      />.
     :vartype image: str
     :ivar inference_config: Defines configuration specific to inference.
     :vartype inference_config:
      ~azure.mgmt.machinelearningservices.models.InferenceContainerProperties
@@ -3201,31 +3276,31 @@
     :ivar os_type: The OS type of the environment. Possible values include: "Linux", "Windows".
     :vartype os_type: str or ~azure.mgmt.machinelearningservices.models.OperatingSystemType
     :ivar stage: Stage in the environment lifecycle assigned to this environment.
     :vartype stage: str
     """
 
     _validation = {
-        'environment_type': {'readonly': True},
+        "environment_type": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'build': {'key': 'build', 'type': 'BuildContext'},
-        'conda_file': {'key': 'condaFile', 'type': 'str'},
-        'environment_type': {'key': 'environmentType', 'type': 'str'},
-        'image': {'key': 'image', 'type': 'str'},
-        'inference_config': {'key': 'inferenceConfig', 'type': 'InferenceContainerProperties'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
-        'os_type': {'key': 'osType', 'type': 'str'},
-        'stage': {'key': 'stage', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "build": {"key": "build", "type": "BuildContext"},
+        "conda_file": {"key": "condaFile", "type": "str"},
+        "environment_type": {"key": "environmentType", "type": "str"},
+        "image": {"key": "image", "type": "str"},
+        "inference_config": {"key": "inferenceConfig", "type": "InferenceContainerProperties"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
+        "os_type": {"key": "osType", "type": "str"},
+        "stage": {"key": "stage", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -3252,27 +3327,27 @@
         :paramtype is_anonymous: bool
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword build: Configuration settings for Docker build context.
         :paramtype build: ~azure.mgmt.machinelearningservices.models.BuildContext
         :keyword conda_file: Standard configuration file used by Conda that lets you install any kind
          of package, including Python, R, and C/C++ packages.
-        
-        
+
+
          .. raw:: html
-        
+
             <see
          href="https://repo2docker.readthedocs.io/en/latest/config_files.html#environment-yml-install-a-conda-environment"
          />.
         :paramtype conda_file: str
         :keyword image: Name of the image that will be used for the environment.
-        
-        
+
+
          .. raw:: html
-        
+
             <seealso
          href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-custom-docker-image#use-a-custom-base-image"
          />.
         :paramtype image: str
         :keyword inference_config: Defines configuration specific to inference.
         :paramtype inference_config:
          ~azure.mgmt.machinelearningservices.models.InferenceContainerProperties
@@ -3281,15 +3356,22 @@
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         :keyword os_type: The OS type of the environment. Possible values include: "Linux", "Windows".
         :paramtype os_type: str or ~azure.mgmt.machinelearningservices.models.OperatingSystemType
         :keyword stage: Stage in the environment lifecycle assigned to this environment.
         :paramtype stage: str
         """
-        super(EnvironmentVersionDetails, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, **kwargs)
+        super(EnvironmentVersionDetails, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            **kwargs
+        )
         self.build = build
         self.conda_file = conda_file
         self.environment_type = None
         self.image = image
         self.inference_config = inference_config
         self.intellectual_property = intellectual_property
         self.os_type = os_type
@@ -3303,24 +3385,20 @@
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type EnvironmentVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[EnvironmentVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[EnvironmentVersionData]"},
     }
 
     def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["EnvironmentVersionData"]] = None,
-        **kwargs
+        self, *, next_link: Optional[str] = None, value: Optional[List["EnvironmentVersionData"]] = None, **kwargs
     ):
         """
         :keyword next_link: The link to the next page of EnvironmentVersion objects. If null, there are
          no additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type EnvironmentVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.EnvironmentVersionData]
@@ -3338,29 +3416,25 @@
     :ivar type: The additional info type.
     :vartype type: str
     :ivar info: The additional info.
     :vartype info: any
     """
 
     _validation = {
-        'type': {'readonly': True},
-        'info': {'readonly': True},
+        "type": {"readonly": True},
+        "info": {"readonly": True},
     }
 
     _attribute_map = {
-        'type': {'key': 'type', 'type': 'str'},
-        'info': {'key': 'info', 'type': 'object'},
+        "type": {"key": "type", "type": "str"},
+        "info": {"key": "info", "type": "object"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(ErrorAdditionalInfo, self).__init__(**kwargs)
         self.type = None
         self.info = None
 
 
 class ErrorDetail(msrest.serialization.Model):
     """The error detail.
@@ -3376,35 +3450,31 @@
     :ivar details: The error details.
     :vartype details: list[~azure.mgmt.machinelearningservices.models.ErrorDetail]
     :ivar additional_info: The error additional info.
     :vartype additional_info: list[~azure.mgmt.machinelearningservices.models.ErrorAdditionalInfo]
     """
 
     _validation = {
-        'code': {'readonly': True},
-        'message': {'readonly': True},
-        'target': {'readonly': True},
-        'details': {'readonly': True},
-        'additional_info': {'readonly': True},
+        "code": {"readonly": True},
+        "message": {"readonly": True},
+        "target": {"readonly": True},
+        "details": {"readonly": True},
+        "additional_info": {"readonly": True},
     }
 
     _attribute_map = {
-        'code': {'key': 'code', 'type': 'str'},
-        'message': {'key': 'message', 'type': 'str'},
-        'target': {'key': 'target', 'type': 'str'},
-        'details': {'key': 'details', 'type': '[ErrorDetail]'},
-        'additional_info': {'key': 'additionalInfo', 'type': '[ErrorAdditionalInfo]'},
+        "code": {"key": "code", "type": "str"},
+        "message": {"key": "message", "type": "str"},
+        "target": {"key": "target", "type": "str"},
+        "details": {"key": "details", "type": "[ErrorDetail]"},
+        "additional_info": {"key": "additionalInfo", "type": "[ErrorAdditionalInfo]"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(ErrorDetail, self).__init__(**kwargs)
         self.code = None
         self.message = None
         self.target = None
         self.details = None
         self.additional_info = None
 
@@ -3413,23 +3483,18 @@
     """Common error response for all Azure Resource Manager APIs to return error details for failed operations. (This also follows the OData error response format.).
 
     :ivar error: The error object.
     :vartype error: ~azure.mgmt.machinelearningservices.models.ErrorDetail
     """
 
     _attribute_map = {
-        'error': {'key': 'error', 'type': 'ErrorDetail'},
+        "error": {"key": "error", "type": "ErrorDetail"},
     }
 
-    def __init__(
-        self,
-        *,
-        error: Optional["ErrorDetail"] = None,
-        **kwargs
-    ):
+    def __init__(self, *, error: Optional["ErrorDetail"] = None, **kwargs):
         """
         :keyword error: The error object.
         :paramtype error: ~azure.mgmt.machinelearningservices.models.ErrorDetail
         """
         super(ErrorResponse, self).__init__(**kwargs)
         self.error = error
 
@@ -3438,23 +3503,18 @@
     """FlavorData.
 
     :ivar data: Model flavor-specific data.
     :vartype data: dict[str, str]
     """
 
     _attribute_map = {
-        'data': {'key': 'data', 'type': '{str}'},
+        "data": {"key": "data", "type": "{str}"},
     }
 
-    def __init__(
-        self,
-        *,
-        data: Optional[Dict[str, str]] = None,
-        **kwargs
-    ):
+    def __init__(self, *, data: Optional[Dict[str, str]] = None, **kwargs):
         """
         :keyword data: Model flavor-specific data.
         :paramtype data: dict[str, str]
         """
         super(FlavorData, self).__init__(**kwargs)
         self.data = data
 
@@ -3468,35 +3528,30 @@
      server. Possible values include: "Id", "DataPath", "OutputPath".
     :vartype reference_type: str or ~azure.mgmt.machinelearningservices.models.ReferenceType
     :ivar asset_id: Required. ARM resource ID of the asset.
     :vartype asset_id: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
-        'asset_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "reference_type": {"required": True},
+        "asset_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'asset_id': {'key': 'assetId', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "asset_id": {"key": "assetId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        asset_id: str,
-        **kwargs
-    ):
+    def __init__(self, *, asset_id: str, **kwargs):
         """
         :keyword asset_id: Required. ARM resource ID of the asset.
         :paramtype asset_id: str
         """
         super(IdAssetReference, self).__init__(**kwargs)
-        self.reference_type = 'Id'  # type: str
+        self.reference_type = "Id"  # type: str
         self.asset_id = asset_id
 
 
 class ImageReferenceForConsumptionDto(msrest.serialization.Model):
     """ImageReferenceForConsumptionDto.
 
     :ivar acr_details:
@@ -3506,18 +3561,18 @@
     :ivar image_name:
     :vartype image_name: str
     :ivar image_registry_reference:
     :vartype image_registry_reference: str
     """
 
     _attribute_map = {
-        'acr_details': {'key': 'acrDetails', 'type': 'AcrDetail'},
-        'credential': {'key': 'credential', 'type': 'DataReferenceCredentialDto'},
-        'image_name': {'key': 'imageName', 'type': 'str'},
-        'image_registry_reference': {'key': 'imageRegistryReference', 'type': 'str'},
+        "acr_details": {"key": "acrDetails", "type": "AcrDetail"},
+        "credential": {"key": "credential", "type": "DataReferenceCredentialDto"},
+        "image_name": {"key": "imageName", "type": "str"},
+        "image_registry_reference": {"key": "imageRegistryReference", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         acr_details: Optional["AcrDetail"] = None,
         credential: Optional["DataReferenceCredentialDto"] = None,
@@ -3551,17 +3606,17 @@
     :vartype readiness_route: ~azure.mgmt.machinelearningservices.models.Route
     :ivar scoring_route: The port to send the scoring requests to, within the inference server
      container.
     :vartype scoring_route: ~azure.mgmt.machinelearningservices.models.Route
     """
 
     _attribute_map = {
-        'liveness_route': {'key': 'livenessRoute', 'type': 'Route'},
-        'readiness_route': {'key': 'readinessRoute', 'type': 'Route'},
-        'scoring_route': {'key': 'scoringRoute', 'type': 'Route'},
+        "liveness_route": {"key": "livenessRoute", "type": "Route"},
+        "readiness_route": {"key": "readinessRoute", "type": "Route"},
+        "scoring_route": {"key": "scoringRoute", "type": "Route"},
     }
 
     def __init__(
         self,
         *,
         liveness_route: Optional["Route"] = None,
         readiness_route: Optional["Route"] = None,
@@ -3593,29 +3648,23 @@
     :vartype protection_level: str or ~azure.mgmt.machinelearningservices.models.ProtectionLevel
     :ivar publisher: Required. Publisher of the Intellectual Property. Must be the same as Registry
      publisher name.
     :vartype publisher: str
     """
 
     _validation = {
-        'publisher': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "publisher": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'protection_level': {'key': 'protectionLevel', 'type': 'str'},
-        'publisher': {'key': 'publisher', 'type': 'str'},
+        "protection_level": {"key": "protectionLevel", "type": "str"},
+        "publisher": {"key": "publisher", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        publisher: str,
-        protection_level: Optional[Union[str, "ProtectionLevel"]] = None,
-        **kwargs
-    ):
+    def __init__(self, *, publisher: str, protection_level: Optional[Union[str, "ProtectionLevel"]] = None, **kwargs):
         """
         :keyword protection_level: Protection level of the Intellectual Property. Possible values
          include: "All", "None".
         :paramtype protection_level: str or ~azure.mgmt.machinelearningservices.models.ProtectionLevel
         :keyword publisher: Required. Publisher of the Intellectual Property. Must be the same as
          Registry publisher name.
         :paramtype publisher: str
@@ -3658,31 +3707,31 @@
     :ivar status: Status of the job. Possible values include: "NotStarted", "Starting",
      "Provisioning", "Preparing", "Queued", "Running", "Finalizing", "CancelRequested", "Completed",
      "Failed", "Canceled", "NotResponding", "Paused", "Unknown".
     :vartype status: str or ~azure.mgmt.machinelearningservices.models.JobStatus
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -3710,16 +3759,26 @@
         :paramtype experiment_name: str
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         :keyword services: List of JobEndpoints.
          For local jobs, a job endpoint will have an endpoint value of FileStreamObject.
         :paramtype services: dict[str, ~azure.mgmt.machinelearningservices.models.JobService]
         """
-        super(Job, self).__init__(description=description, properties=properties, tags=tags, compute_id=compute_id, display_name=display_name, experiment_name=experiment_name, is_archived=is_archived, services=services, **kwargs)
-        self.job_type = 'Base'  # type: str
+        super(Job, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            compute_id=compute_id,
+            display_name=display_name,
+            experiment_name=experiment_name,
+            is_archived=is_archived,
+            services=services,
+            **kwargs
+        )
+        self.job_type = "Base"  # type: str
 
 
 class JobInput(msrest.serialization.Model):
     """Command job definition.
 
     You probably want to use the sub-classes and not this class directly. Known
     sub-classes are: JobInputDataset, JobInputLiteral, JobInputUri.
@@ -3730,32 +3789,27 @@
     :vartype description: str
     :ivar job_input_type: Required. Specifies the type of job.Constant filled by server. Possible
      values include: "Dataset", "Uri", "Literal".
     :vartype job_input_type: str or ~azure.mgmt.machinelearningservices.models.JobInputType
     """
 
     _validation = {
-        'job_input_type': {'required': True},
+        "job_input_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
     }
 
     _subtype_map = {
-        'job_input_type': {'Dataset': 'JobInputDataset', 'Literal': 'JobInputLiteral', 'Uri': 'JobInputUri'}
+        "job_input_type": {"Dataset": "JobInputDataset", "Literal": "JobInputLiteral", "Uri": "JobInputUri"}
     }
 
-    def __init__(
-        self,
-        *,
-        description: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, description: Optional[str] = None, **kwargs):
         """
         :keyword description: Description for the input.
         :paramtype description: str
         """
         super(JobInput, self).__init__(**kwargs)
         self.description = description
         self.job_input_type = None  # type: Optional[str]
@@ -3775,23 +3829,23 @@
     :vartype dataset_id: str
     :ivar mode: Dataset Delivery Mode. Possible values include: "ReadOnlyMount", "ReadWriteMount",
      "Download".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
     """
 
     _validation = {
-        'job_input_type': {'required': True},
-        'dataset_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "job_input_type": {"required": True},
+        "dataset_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
-        'dataset_id': {'key': 'datasetId', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
+        "dataset_id": {"key": "datasetId", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         dataset_id: str,
         description: Optional[str] = None,
@@ -3804,15 +3858,15 @@
         :keyword dataset_id: Required. Dataset ARM Id for the input.
         :paramtype dataset_id: str
         :keyword mode: Dataset Delivery Mode. Possible values include: "ReadOnlyMount",
          "ReadWriteMount", "Download".
         :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
         """
         super(JobInputDataset, self).__init__(description=description, **kwargs)
-        self.job_input_type = 'Dataset'  # type: str
+        self.job_input_type = "Dataset"  # type: str
         self.dataset_id = dataset_id
         self.mode = mode
 
 
 class JobInputLiteral(JobInput):
     """Literal input type.
 
@@ -3824,38 +3878,32 @@
      values include: "Dataset", "Uri", "Literal".
     :vartype job_input_type: str or ~azure.mgmt.machinelearningservices.models.JobInputType
     :ivar value: Literal value for the input.
     :vartype value: str
     """
 
     _validation = {
-        'job_input_type': {'required': True},
+        "job_input_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
-        'value': {'key': 'value', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
+        "value": {"key": "value", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        description: Optional[str] = None,
-        value: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, description: Optional[str] = None, value: Optional[str] = None, **kwargs):
         """
         :keyword description: Description for the input.
         :paramtype description: str
         :keyword value: Literal value for the input.
         :paramtype value: str
         """
         super(JobInputLiteral, self).__init__(description=description, **kwargs)
-        self.job_input_type = 'Literal'  # type: str
+        self.job_input_type = "Literal"  # type: str
         self.value = value
 
 
 class JobInputUri(JobInput):
     """Input uri type.
 
     All required parameters must be populated in order to send to Azure.
@@ -3869,23 +3917,23 @@
      "ReadWriteMount", "Download".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
     :ivar uri: Required. Uri path.
     :vartype uri: ~azure.mgmt.machinelearningservices.models.UriReference
     """
 
     _validation = {
-        'job_input_type': {'required': True},
-        'uri': {'required': True},
+        "job_input_type": {"required": True},
+        "uri": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_input_type': {'key': 'jobInputType', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
-        'uri': {'key': 'uri', 'type': 'UriReference'},
+        "description": {"key": "description", "type": "str"},
+        "job_input_type": {"key": "jobInputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
+        "uri": {"key": "uri", "type": "UriReference"},
     }
 
     def __init__(
         self,
         *,
         uri: "UriReference",
         description: Optional[str] = None,
@@ -3898,15 +3946,15 @@
         :keyword mode: Input Uri Delivery Mode. Possible values include: "ReadOnlyMount",
          "ReadWriteMount", "Download".
         :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.InputDataDeliveryMode
         :keyword uri: Required. Uri path.
         :paramtype uri: ~azure.mgmt.machinelearningservices.models.UriReference
         """
         super(JobInputUri, self).__init__(description=description, **kwargs)
-        self.job_input_type = 'Uri'  # type: str
+        self.job_input_type = "Uri"  # type: str
         self.mode = mode
         self.uri = uri
 
 
 class JobOutput(msrest.serialization.Model):
     """Job output definition container information on where to find job output/logs.
 
@@ -3919,32 +3967,25 @@
     :vartype description: str
     :ivar job_output_type: Required. Specifies the type of job.Constant filled by server. Possible
      values include: "Uri", "Dataset".
     :vartype job_output_type: str or ~azure.mgmt.machinelearningservices.models.JobOutputType
     """
 
     _validation = {
-        'job_output_type': {'required': True},
+        "job_output_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_output_type': {'key': 'jobOutputType', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_output_type": {"key": "jobOutputType", "type": "str"},
     }
 
-    _subtype_map = {
-        'job_output_type': {'Dataset': 'JobOutputDataset', 'Uri': 'JobOutputUri'}
-    }
+    _subtype_map = {"job_output_type": {"Dataset": "JobOutputDataset", "Uri": "JobOutputUri"}}
 
-    def __init__(
-        self,
-        *,
-        description: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, description: Optional[str] = None, **kwargs):
         """
         :keyword description: Description for the output.
         :paramtype description: str
         """
         super(JobOutput, self).__init__(**kwargs)
         self.description = description
         self.job_output_type = None  # type: Optional[str]
@@ -3961,21 +4002,21 @@
      values include: "Uri", "Dataset".
     :vartype job_output_type: str or ~azure.mgmt.machinelearningservices.models.JobOutputType
     :ivar mode: Output Delivery Mode. Possible values include: "ReadWriteMount", "Upload".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.OutputDataDeliveryMode
     """
 
     _validation = {
-        'job_output_type': {'required': True},
+        "job_output_type": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_output_type': {'key': 'jobOutputType', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "job_output_type": {"key": "jobOutputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         mode: Optional[Union[str, "OutputDataDeliveryMode"]] = None,
@@ -3984,15 +4025,15 @@
         """
         :keyword description: Description for the output.
         :paramtype description: str
         :keyword mode: Output Delivery Mode. Possible values include: "ReadWriteMount", "Upload".
         :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.OutputDataDeliveryMode
         """
         super(JobOutputDataset, self).__init__(description=description, **kwargs)
-        self.job_output_type = 'Dataset'  # type: str
+        self.job_output_type = "Dataset"  # type: str
         self.mode = mode
 
 
 class JobOutputUri(JobOutput):
     """Uri output.
 
     Variables are only populated by the server, and will be ignored when sending a request.
@@ -4007,38 +4048,33 @@
     :ivar mode: Output Delivery Mode. Possible values include: "ReadWriteMount", "Upload".
     :vartype mode: str or ~azure.mgmt.machinelearningservices.models.OutputDataDeliveryMode
     :ivar uri: Uri path.
     :vartype uri: ~azure.mgmt.machinelearningservices.models.UriReference
     """
 
     _validation = {
-        'job_output_type': {'required': True},
-        'mode': {'readonly': True},
-        'uri': {'readonly': True},
+        "job_output_type": {"required": True},
+        "mode": {"readonly": True},
+        "uri": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'job_output_type': {'key': 'jobOutputType', 'type': 'str'},
-        'mode': {'key': 'mode', 'type': 'str'},
-        'uri': {'key': 'uri', 'type': 'UriReference'},
+        "description": {"key": "description", "type": "str"},
+        "job_output_type": {"key": "jobOutputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
+        "uri": {"key": "uri", "type": "UriReference"},
     }
 
-    def __init__(
-        self,
-        *,
-        description: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, description: Optional[str] = None, **kwargs):
         """
         :keyword description: Description for the output.
         :paramtype description: str
         """
         super(JobOutputUri, self).__init__(description=description, **kwargs)
-        self.job_output_type = 'Uri'  # type: str
+        self.job_output_type = "Uri"  # type: str
         self.mode = None
         self.uri = None
 
 
 class JobService(msrest.serialization.Model):
     """Job endpoint definition.
 
@@ -4055,25 +4091,25 @@
     :ivar properties: Additional properties to set on the endpoint.
     :vartype properties: dict[str, str]
     :ivar status: Status of endpoint.
     :vartype status: str
     """
 
     _validation = {
-        'error_message': {'readonly': True},
-        'status': {'readonly': True},
+        "error_message": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'endpoint': {'key': 'endpoint', 'type': 'str'},
-        'error_message': {'key': 'errorMessage', 'type': 'str'},
-        'job_service_type': {'key': 'jobServiceType', 'type': 'str'},
-        'port': {'key': 'port', 'type': 'int'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'status': {'key': 'status', 'type': 'str'},
+        "endpoint": {"key": "endpoint", "type": "str"},
+        "error_message": {"key": "errorMessage", "type": "str"},
+        "job_service_type": {"key": "jobServiceType", "type": "str"},
+        "port": {"key": "port", "type": "int"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "status": {"key": "status", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         endpoint: Optional[str] = None,
         job_service_type: Optional[str] = None,
@@ -4117,22 +4153,22 @@
     :vartype object_id: str
     :ivar resource_id: Specifies a user-assigned identity by ARM resource ID. For system-assigned,
      do not set this field.
     :vartype resource_id: str
     """
 
     _validation = {
-        'identity_type': {'required': True},
+        "identity_type": {"required": True},
     }
 
     _attribute_map = {
-        'identity_type': {'key': 'identityType', 'type': 'str'},
-        'client_id': {'key': 'clientId', 'type': 'str'},
-        'object_id': {'key': 'objectId', 'type': 'str'},
-        'resource_id': {'key': 'resourceId', 'type': 'str'},
+        "identity_type": {"key": "identityType", "type": "str"},
+        "client_id": {"key": "clientId", "type": "str"},
+        "object_id": {"key": "objectId", "type": "str"},
+        "resource_id": {"key": "resourceId", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         client_id: Optional[str] = None,
         object_id: Optional[str] = None,
@@ -4147,29 +4183,23 @@
          not set this field.
         :paramtype object_id: str
         :keyword resource_id: Specifies a user-assigned identity by ARM resource ID. For
          system-assigned, do not set this field.
         :paramtype resource_id: str
         """
         super(ManagedIdentity, self).__init__(**kwargs)
-        self.identity_type = 'Managed'  # type: str
+        self.identity_type = "Managed"  # type: str
         self.client_id = client_id
         self.object_id = object_id
         self.resource_id = resource_id
 
 
-class ManagedIdentityCredentialDto(DataReferenceCredentialDto):
+class ManagedIdentityCredentialDto(msrest.serialization.Model):
     """ManagedIdentityCredentialDto.
 
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
     :ivar managed_identity_type:
     :vartype managed_identity_type: str
     :ivar user_managed_identity_client_id: ClientId for the UAMI. For ManagedIdentityType =
      SystemManaged, this field is null.
     :vartype user_managed_identity_client_id: str
     :ivar user_managed_identity_principal_id: PrincipalId for the UAMI. For ManagedIdentityType =
      SystemManaged, this field is null.
@@ -4178,25 +4208,20 @@
      SystemManaged, this field is null.
     :vartype user_managed_identity_resource_id: str
     :ivar user_managed_identity_tenant_id: TenantId for the UAMI. For ManagedIdentityType =
      SystemManaged, this field is null.
     :vartype user_managed_identity_tenant_id: str
     """
 
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
     _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-        'managed_identity_type': {'key': 'managedIdentityType', 'type': 'str'},
-        'user_managed_identity_client_id': {'key': 'userManagedIdentityClientId', 'type': 'str'},
-        'user_managed_identity_principal_id': {'key': 'userManagedIdentityPrincipalId', 'type': 'str'},
-        'user_managed_identity_resource_id': {'key': 'userManagedIdentityResourceId', 'type': 'str'},
-        'user_managed_identity_tenant_id': {'key': 'userManagedIdentityTenantId', 'type': 'str'},
+        "managed_identity_type": {"key": "managedIdentityType", "type": "str"},
+        "user_managed_identity_client_id": {"key": "userManagedIdentityClientId", "type": "str"},
+        "user_managed_identity_principal_id": {"key": "userManagedIdentityPrincipalId", "type": "str"},
+        "user_managed_identity_resource_id": {"key": "userManagedIdentityResourceId", "type": "str"},
+        "user_managed_identity_tenant_id": {"key": "userManagedIdentityTenantId", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         managed_identity_type: Optional[str] = None,
         user_managed_identity_client_id: Optional[str] = None,
@@ -4218,15 +4243,14 @@
          = SystemManaged, this field is null.
         :paramtype user_managed_identity_resource_id: str
         :keyword user_managed_identity_tenant_id: TenantId for the UAMI. For ManagedIdentityType =
          SystemManaged, this field is null.
         :paramtype user_managed_identity_tenant_id: str
         """
         super(ManagedIdentityCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'ManagedIdentity'  # type: str
         self.managed_identity_type = managed_identity_type
         self.user_managed_identity_client_id = user_managed_identity_client_id
         self.user_managed_identity_principal_id = user_managed_identity_principal_id
         self.user_managed_identity_resource_id = user_managed_identity_resource_id
         self.user_managed_identity_tenant_id = user_managed_identity_tenant_id
 
 
@@ -4242,38 +4266,34 @@
     :ivar policy_type: Required. Name of policy configuration.Constant filled by server. Possible
      values include: "Bandit", "MedianStopping", "TruncationSelection".
     :vartype policy_type: str or
      ~azure.mgmt.machinelearningservices.models.EarlyTerminationPolicyType
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        delay_evaluation: Optional[int] = 0,
-        evaluation_interval: Optional[int] = 0,
-        **kwargs
-    ):
+    def __init__(self, *, delay_evaluation: Optional[int] = 0, evaluation_interval: Optional[int] = 0, **kwargs):
         """
         :keyword delay_evaluation: Number of intervals by which to delay the first evaluation.
         :paramtype delay_evaluation: int
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         """
-        super(MedianStoppingPolicy, self).__init__(delay_evaluation=delay_evaluation, evaluation_interval=evaluation_interval, **kwargs)
-        self.policy_type = 'MedianStopping'  # type: str
+        super(MedianStoppingPolicy, self).__init__(
+            delay_evaluation=delay_evaluation, evaluation_interval=evaluation_interval, **kwargs
+        )
+        self.policy_type = "MedianStopping"  # type: str
 
 
 class MLTableData(DataVersionBaseDetails):
     """MLTable data definition.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4297,28 +4317,28 @@
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     :ivar referenced_uris: Uris referenced in the MLTable definition (required for lineage).
     :vartype referenced_uris: list[str]
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
-        'referenced_uris': {'key': 'referencedUris', 'type': '[str]'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
+        "referenced_uris": {"key": "referencedUris", "type": "[str]"},
     }
 
     def __init__(
         self,
         *,
         data_uri: str,
         description: Optional[str] = None,
@@ -4347,19 +4367,60 @@
         :keyword intellectual_property: Intellectual Property details. Used if data is an Intellectual
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         :keyword referenced_uris: Uris referenced in the MLTable definition (required for lineage).
         :paramtype referenced_uris: list[str]
         """
-        super(MLTableData, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, data_uri=data_uri, intellectual_property=intellectual_property, **kwargs)
-        self.data_type = 'mltable'  # type: str
+        super(MLTableData, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            data_uri=data_uri,
+            intellectual_property=intellectual_property,
+            **kwargs
+        )
+        self.data_type = "mltable"  # type: str
         self.referenced_uris = referenced_uris
 
 
+class ModelConfiguration(msrest.serialization.Model):
+    """Model configuration options.
+
+    :ivar mode: Input delivery mode for the model. Possible values include: "Copy", "Download".
+    :vartype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+    :ivar mount_path: Relative mounting path of the model in the target image.
+    :vartype mount_path: str
+    """
+
+    _attribute_map = {
+        "mode": {"key": "mode", "type": "str"},
+        "mount_path": {"key": "mountPath", "type": "str"},
+    }
+
+    def __init__(
+        self,
+        *,
+        mode: Optional[Union[str, "PackageInputDeliveryMode"]] = None,
+        mount_path: Optional[str] = None,
+        **kwargs
+    ):
+        """
+        :keyword mode: Input delivery mode for the model. Possible values include: "Copy", "Download".
+        :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+        :keyword mount_path: Relative mounting path of the model in the target image.
+        :paramtype mount_path: str
+        """
+        super(ModelConfiguration, self).__init__(**kwargs)
+        self.mode = mode
+        self.mount_path = mount_path
+
+
 class ModelContainerData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4375,35 +4436,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ModelContainerDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ModelContainerDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ModelContainerDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "ModelContainerDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "ModelContainerDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ModelContainerDetails
         """
         super(ModelContainerData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -4424,25 +4480,25 @@
     :ivar latest_version: The latest version inside this container.
     :vartype latest_version: str
     :ivar next_version: The next auto incremental version.
     :vartype next_version: str
     """
 
     _validation = {
-        'latest_version': {'readonly': True},
-        'next_version': {'readonly': True},
+        "latest_version": {"readonly": True},
+        "next_version": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'latest_version': {'key': 'latestVersion', 'type': 'str'},
-        'next_version': {'key': 'nextVersion', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "latest_version": {"key": "latestVersion", "type": "str"},
+        "next_version": {"key": "nextVersion", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -4456,51 +4512,104 @@
         :keyword properties: The asset property dictionary.
         :paramtype properties: dict[str, str]
         :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
         :paramtype tags: dict[str, str]
         :keyword is_archived: Is the asset archived?.
         :paramtype is_archived: bool
         """
-        super(ModelContainerDetails, self).__init__(description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs)
+        super(ModelContainerDetails, self).__init__(
+            description=description, properties=properties, tags=tags, is_archived=is_archived, **kwargs
+        )
 
 
 class ModelContainerResourceArmPaginatedResult(msrest.serialization.Model):
     """A paginated list of ModelContainer entities.
 
     :ivar next_link: The link to the next page of ModelContainer objects. If null, there are no
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ModelContainer.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ModelContainerData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ModelContainerData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ModelContainerData]"},
     }
 
     def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["ModelContainerData"]] = None,
-        **kwargs
+        self, *, next_link: Optional[str] = None, value: Optional[List["ModelContainerData"]] = None, **kwargs
     ):
         """
         :keyword next_link: The link to the next page of ModelContainer objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ModelContainer.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ModelContainerData]
         """
         super(ModelContainerResourceArmPaginatedResult, self).__init__(**kwargs)
         self.next_link = next_link
         self.value = value
 
 
+class ModelPackageInput(msrest.serialization.Model):
+    """Model package input options.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_type: Required. Type of the input included in the target image. Possible values
+     include: "UriFile", "UriFolder".
+    :vartype input_type: str or ~azure.mgmt.machinelearningservices.models.PackageInputType
+    :ivar mode: Input delivery mode of the input. Possible values include: "Copy", "Download".
+    :vartype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+    :ivar mount_path: Relative mount path of the input in the target image.
+    :vartype mount_path: str
+    :ivar path: Required. Location of the input.
+    :vartype path: ~azure.mgmt.machinelearningservices.models.PackageInputPathBase
+    """
+
+    _validation = {
+        "input_type": {"required": True},
+        "path": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_type": {"key": "inputType", "type": "str"},
+        "mode": {"key": "mode", "type": "str"},
+        "mount_path": {"key": "mountPath", "type": "str"},
+        "path": {"key": "path", "type": "PackageInputPathBase"},
+    }
+
+    def __init__(
+        self,
+        *,
+        input_type: Union[str, "PackageInputType"],
+        path: "PackageInputPathBase",
+        mode: Optional[Union[str, "PackageInputDeliveryMode"]] = None,
+        mount_path: Optional[str] = None,
+        **kwargs
+    ):
+        """
+        :keyword input_type: Required. Type of the input included in the target image. Possible values
+         include: "UriFile", "UriFolder".
+        :paramtype input_type: str or ~azure.mgmt.machinelearningservices.models.PackageInputType
+        :keyword mode: Input delivery mode of the input. Possible values include: "Copy", "Download".
+        :paramtype mode: str or ~azure.mgmt.machinelearningservices.models.PackageInputDeliveryMode
+        :keyword mount_path: Relative mount path of the input in the target image.
+        :paramtype mount_path: str
+        :keyword path: Required. Location of the input.
+        :paramtype path: ~azure.mgmt.machinelearningservices.models.PackageInputPathBase
+        """
+        super(ModelPackageInput, self).__init__(**kwargs)
+        self.input_type = input_type
+        self.mode = mode
+        self.mount_path = mount_path
+        self.path = path
+
+
 class ModelVersionData(Resource):
     """Azure Resource Manager resource envelope.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4516,35 +4625,30 @@
      information.
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties: ~azure.mgmt.machinelearningservices.models.ModelVersionDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ModelVersionDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ModelVersionDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "ModelVersionDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "ModelVersionDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties: ~azure.mgmt.machinelearningservices.models.ModelVersionDetails
         """
         super(ModelVersionData, self).__init__(**kwargs)
         self.properties = properties
 
@@ -4574,25 +4678,25 @@
     :ivar model_uri: The URI path to the model contents.
     :vartype model_uri: str
     :ivar origin_asset_id: AssetId of origin model.
     :vartype origin_asset_id: str
     """
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'flavors': {'key': 'flavors', 'type': '{FlavorData}'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
-        'job_name': {'key': 'jobName', 'type': 'str'},
-        'model_type': {'key': 'modelType', 'type': 'str'},
-        'model_uri': {'key': 'modelUri', 'type': 'str'},
-        'origin_asset_id': {'key': 'originAssetId', 'type': 'str'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "flavors": {"key": "flavors", "type": "{FlavorData}"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
+        "job_name": {"key": "jobName", "type": "str"},
+        "model_type": {"key": "modelType", "type": "str"},
+        "model_uri": {"key": "modelUri", "type": "str"},
+        "origin_asset_id": {"key": "originAssetId", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -4629,15 +4733,22 @@
         :keyword model_type: The storage format for this entity. Used for NCD.
         :paramtype model_type: str
         :keyword model_uri: The URI path to the model contents.
         :paramtype model_uri: str
         :keyword origin_asset_id: AssetId of origin model.
         :paramtype origin_asset_id: str
         """
-        super(ModelVersionDetails, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, **kwargs)
+        super(ModelVersionDetails, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            **kwargs
+        )
         self.flavors = flavors
         self.intellectual_property = intellectual_property
         self.job_name = job_name
         self.model_type = model_type
         self.model_uri = model_uri
         self.origin_asset_id = origin_asset_id
 
@@ -4649,25 +4760,19 @@
      additional pages.
     :vartype next_link: str
     :ivar value: An array of objects of type ModelVersion.
     :vartype value: list[~azure.mgmt.machinelearningservices.models.ModelVersionData]
     """
 
     _attribute_map = {
-        'next_link': {'key': 'nextLink', 'type': 'str'},
-        'value': {'key': 'value', 'type': '[ModelVersionData]'},
+        "next_link": {"key": "nextLink", "type": "str"},
+        "value": {"key": "value", "type": "[ModelVersionData]"},
     }
 
-    def __init__(
-        self,
-        *,
-        next_link: Optional[str] = None,
-        value: Optional[List["ModelVersionData"]] = None,
-        **kwargs
-    ):
+    def __init__(self, *, next_link: Optional[str] = None, value: Optional[List["ModelVersionData"]] = None, **kwargs):
         """
         :keyword next_link: The link to the next page of ModelVersion objects. If null, there are no
          additional pages.
         :paramtype next_link: str
         :keyword value: An array of objects of type ModelVersion.
         :paramtype value: list[~azure.mgmt.machinelearningservices.models.ModelVersionData]
         """
@@ -4685,34 +4790,29 @@
      by server. Possible values include: "PyTorch", "TensorFlow", "Mpi".
     :vartype distribution_type: str or ~azure.mgmt.machinelearningservices.models.DistributionType
     :ivar process_count_per_instance: Number of processes per MPI node.
     :vartype process_count_per_instance: int
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
-        'process_count_per_instance': {'key': 'processCountPerInstance', 'type': 'int'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
+        "process_count_per_instance": {"key": "processCountPerInstance", "type": "int"},
     }
 
-    def __init__(
-        self,
-        *,
-        process_count_per_instance: Optional[int] = None,
-        **kwargs
-    ):
+    def __init__(self, *, process_count_per_instance: Optional[int] = None, **kwargs):
         """
         :keyword process_count_per_instance: Number of processes per MPI node.
         :paramtype process_count_per_instance: int
         """
         super(Mpi, self).__init__(**kwargs)
-        self.distribution_type = 'Mpi'  # type: str
+        self.distribution_type = "Mpi"  # type: str
         self.process_count_per_instance = process_count_per_instance
 
 
 class NoneDatastoreCredentials(DatastoreCredentials):
     """Empty/none datastore credentials.
 
     All required parameters must be populated in order to send to Azure.
@@ -4720,29 +4820,25 @@
     :ivar credentials_type: Required. Credential type used to authentication with storage.Constant
      filled by server. Possible values include: "AccountKey", "Certificate", "None", "Sas",
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     """
 
     _validation = {
-        'credentials_type': {'required': True},
+        "credentials_type": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
-        """
-        """
+    def __init__(self, **kwargs):
+        """ """
         super(NoneDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'None'  # type: str
+        self.credentials_type = "None"  # type: str
 
 
 class Objective(msrest.serialization.Model):
     """Optimization objective.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4750,42 +4846,91 @@
      include: "Minimize", "Maximize".
     :vartype goal: str or ~azure.mgmt.machinelearningservices.models.Goal
     :ivar primary_metric: Required. Name of the metric to optimize.
     :vartype primary_metric: str
     """
 
     _validation = {
-        'goal': {'required': True},
-        'primary_metric': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "goal": {"required": True},
+        "primary_metric": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'goal': {'key': 'goal', 'type': 'str'},
-        'primary_metric': {'key': 'primaryMetric', 'type': 'str'},
+        "goal": {"key": "goal", "type": "str"},
+        "primary_metric": {"key": "primaryMetric", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        goal: Union[str, "Goal"],
-        primary_metric: str,
-        **kwargs
-    ):
+    def __init__(self, *, goal: Union[str, "Goal"], primary_metric: str, **kwargs):
         """
         :keyword goal: Required. Defines supported metric goals for hyperparameter tuning. Possible
          values include: "Minimize", "Maximize".
         :paramtype goal: str or ~azure.mgmt.machinelearningservices.models.Goal
         :keyword primary_metric: Required. Name of the metric to optimize.
         :paramtype primary_metric: str
         """
         super(Objective, self).__init__(**kwargs)
         self.goal = goal
         self.primary_metric = primary_metric
 
 
+class OnlineInferenceConfiguration(msrest.serialization.Model):
+    """Online inference configuration options.
+
+    :ivar configurations: Additional configurations.
+    :vartype configurations: dict[str, str]
+    :ivar entry_script: Entry script or command to invoke.
+    :vartype entry_script: str
+    :ivar liveness_route: The route to check the liveness of the inference server container.
+    :vartype liveness_route: ~azure.mgmt.machinelearningservices.models.Route
+    :ivar readiness_route: The route to check the readiness of the inference server container.
+    :vartype readiness_route: ~azure.mgmt.machinelearningservices.models.Route
+    :ivar scoring_route: The port to send the scoring requests to, within the inference server
+     container.
+    :vartype scoring_route: ~azure.mgmt.machinelearningservices.models.Route
+    """
+
+    _attribute_map = {
+        "configurations": {"key": "configurations", "type": "{str}"},
+        "entry_script": {"key": "entryScript", "type": "str"},
+        "liveness_route": {"key": "livenessRoute", "type": "Route"},
+        "readiness_route": {"key": "readinessRoute", "type": "Route"},
+        "scoring_route": {"key": "scoringRoute", "type": "Route"},
+    }
+
+    def __init__(
+        self,
+        *,
+        configurations: Optional[Dict[str, str]] = None,
+        entry_script: Optional[str] = None,
+        liveness_route: Optional["Route"] = None,
+        readiness_route: Optional["Route"] = None,
+        scoring_route: Optional["Route"] = None,
+        **kwargs
+    ):
+        """
+        :keyword configurations: Additional configurations.
+        :paramtype configurations: dict[str, str]
+        :keyword entry_script: Entry script or command to invoke.
+        :paramtype entry_script: str
+        :keyword liveness_route: The route to check the liveness of the inference server container.
+        :paramtype liveness_route: ~azure.mgmt.machinelearningservices.models.Route
+        :keyword readiness_route: The route to check the readiness of the inference server container.
+        :paramtype readiness_route: ~azure.mgmt.machinelearningservices.models.Route
+        :keyword scoring_route: The port to send the scoring requests to, within the inference server
+         container.
+        :paramtype scoring_route: ~azure.mgmt.machinelearningservices.models.Route
+        """
+        super(OnlineInferenceConfiguration, self).__init__(**kwargs)
+        self.configurations = configurations
+        self.entry_script = entry_script
+        self.liveness_route = liveness_route
+        self.readiness_route = readiness_route
+        self.scoring_route = scoring_route
+
+
 class OutputPathAssetReference(AssetReferenceBase):
     """Reference to an asset via its path in a job output.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar reference_type: Required. Specifies the type of asset reference.Constant filled by
      server. Possible values include: "Id", "DataPath", "OutputPath".
@@ -4793,42 +4938,347 @@
     :ivar job_id: ARM resource ID of the job.
     :vartype job_id: str
     :ivar path: The path of the file/directory in the job output.
     :vartype path: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
+        "reference_type": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'job_id': {'key': 'jobId', 'type': 'str'},
-        'path': {'key': 'path', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "job_id": {"key": "jobId", "type": "str"},
+        "path": {"key": "path", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        job_id: Optional[str] = None,
-        path: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, job_id: Optional[str] = None, path: Optional[str] = None, **kwargs):
         """
         :keyword job_id: ARM resource ID of the job.
         :paramtype job_id: str
         :keyword path: The path of the file/directory in the job output.
         :paramtype path: str
         """
         super(OutputPathAssetReference, self).__init__(**kwargs)
-        self.reference_type = 'OutputPath'  # type: str
+        self.reference_type = "OutputPath"  # type: str
         self.job_id = job_id
         self.path = path
 
 
+class PackageInputPathBase(msrest.serialization.Model):
+    """PackageInputPathBase.
+
+    You probably want to use the sub-classes and not this class directly. Known
+    sub-classes are: PackageInputPathId, PackageInputPathVersion, PackageInputPathUrl.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+    }
+
+    _subtype_map = {
+        "input_path_type": {
+            "PathId": "PackageInputPathId",
+            "PathVersion": "PackageInputPathVersion",
+            "Url": "PackageInputPathUrl",
+        }
+    }
+
+    def __init__(self, **kwargs):
+        """ """
+        super(PackageInputPathBase, self).__init__(**kwargs)
+        self.input_path_type = None  # type: Optional[str]
+
+
+class PackageInputPathId(PackageInputPathBase):
+    """Package input path specified with a resource id.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    :ivar resource_id: Input resource id.
+    :vartype resource_id: str
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+        "resource_id": {"key": "resourceId", "type": "str"},
+    }
+
+    def __init__(self, *, resource_id: Optional[str] = None, **kwargs):
+        """
+        :keyword resource_id: Input resource id.
+        :paramtype resource_id: str
+        """
+        super(PackageInputPathId, self).__init__(**kwargs)
+        self.input_path_type = "PathId"  # type: str
+        self.resource_id = resource_id
+
+
+class PackageInputPathUrl(PackageInputPathBase):
+    """Package input path specified as an url.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    :ivar url: Input path url.
+    :vartype url: str
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+        "url": {"key": "url", "type": "str"},
+    }
+
+    def __init__(self, *, url: Optional[str] = None, **kwargs):
+        """
+        :keyword url: Input path url.
+        :paramtype url: str
+        """
+        super(PackageInputPathUrl, self).__init__(**kwargs)
+        self.input_path_type = "Url"  # type: str
+        self.url = url
+
+
+class PackageInputPathVersion(PackageInputPathBase):
+    """Package input path specified with name and version.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar input_path_type: Required. Input path type for package inputs.Constant filled by server.
+     Possible values include: "Url", "PathId", "PathVersion".
+    :vartype input_path_type: str or ~azure.mgmt.machinelearningservices.models.InputPathType
+    :ivar resource_name: Input resource name.
+    :vartype resource_name: str
+    :ivar resource_version: Input resource version.
+    :vartype resource_version: str
+    """
+
+    _validation = {
+        "input_path_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "input_path_type": {"key": "inputPathType", "type": "str"},
+        "resource_name": {"key": "resourceName", "type": "str"},
+        "resource_version": {"key": "resourceVersion", "type": "str"},
+    }
+
+    def __init__(self, *, resource_name: Optional[str] = None, resource_version: Optional[str] = None, **kwargs):
+        """
+        :keyword resource_name: Input resource name.
+        :paramtype resource_name: str
+        :keyword resource_version: Input resource version.
+        :paramtype resource_version: str
+        """
+        super(PackageInputPathVersion, self).__init__(**kwargs)
+        self.input_path_type = "PathVersion"  # type: str
+        self.resource_name = resource_name
+        self.resource_version = resource_version
+
+
+class PackageRequest(msrest.serialization.Model):
+    """Model package operation request properties.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar base_environment_source: Base environment to start with.
+    :vartype base_environment_source:
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSource
+    :ivar environment_variables: Collection of environment variables.
+    :vartype environment_variables: dict[str, str]
+    :ivar inferencing_server: Required. Inferencing server configurations.
+    :vartype inferencing_server: ~azure.mgmt.machinelearningservices.models.InferencingServer
+    :ivar inputs: Collection of inputs.
+    :vartype inputs: list[~azure.mgmt.machinelearningservices.models.ModelPackageInput]
+    :ivar model_configuration: Model configuration including the mount mode.
+    :vartype model_configuration: ~azure.mgmt.machinelearningservices.models.ModelConfiguration
+    :ivar properties: Properties dictionary.
+    :vartype properties: dict[str, str]
+    :ivar sku_architecture_type: The sku architecture type.
+    :vartype sku_architecture_type: str
+    :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+    :vartype tags: dict[str, str]
+    :ivar target_environment_id: Required. Arm ID of the target environment to be created by
+     package operation.
+    :vartype target_environment_id: str
+    """
+
+    _validation = {
+        "inferencing_server": {"required": True},
+        "target_environment_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+    }
+
+    _attribute_map = {
+        "base_environment_source": {"key": "baseEnvironmentSource", "type": "BaseEnvironmentSource"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "inferencing_server": {"key": "inferencingServer", "type": "InferencingServer"},
+        "inputs": {"key": "inputs", "type": "[ModelPackageInput]"},
+        "model_configuration": {"key": "modelConfiguration", "type": "ModelConfiguration"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "sku_architecture_type": {"key": "skuArchitectureType", "type": "str"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "target_environment_id": {"key": "targetEnvironmentId", "type": "str"},
+    }
+
+    def __init__(
+        self,
+        *,
+        inferencing_server: "InferencingServer",
+        target_environment_id: str,
+        base_environment_source: Optional["BaseEnvironmentSource"] = None,
+        environment_variables: Optional[Dict[str, str]] = None,
+        inputs: Optional[List["ModelPackageInput"]] = None,
+        model_configuration: Optional["ModelConfiguration"] = None,
+        properties: Optional[Dict[str, str]] = None,
+        sku_architecture_type: Optional[str] = None,
+        tags: Optional[Dict[str, str]] = None,
+        **kwargs
+    ):
+        """
+        :keyword base_environment_source: Base environment to start with.
+        :paramtype base_environment_source:
+         ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSource
+        :keyword environment_variables: Collection of environment variables.
+        :paramtype environment_variables: dict[str, str]
+        :keyword inferencing_server: Required. Inferencing server configurations.
+        :paramtype inferencing_server: ~azure.mgmt.machinelearningservices.models.InferencingServer
+        :keyword inputs: Collection of inputs.
+        :paramtype inputs: list[~azure.mgmt.machinelearningservices.models.ModelPackageInput]
+        :keyword model_configuration: Model configuration including the mount mode.
+        :paramtype model_configuration: ~azure.mgmt.machinelearningservices.models.ModelConfiguration
+        :keyword properties: Properties dictionary.
+        :paramtype properties: dict[str, str]
+        :keyword sku_architecture_type: The sku architecture type.
+        :paramtype sku_architecture_type: str
+        :keyword tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+        :paramtype tags: dict[str, str]
+        :keyword target_environment_id: Required. Arm ID of the target environment to be created by
+         package operation.
+        :paramtype target_environment_id: str
+        """
+        super(PackageRequest, self).__init__(**kwargs)
+        self.base_environment_source = base_environment_source
+        self.environment_variables = environment_variables
+        self.inferencing_server = inferencing_server
+        self.inputs = inputs
+        self.model_configuration = model_configuration
+        self.properties = properties
+        self.sku_architecture_type = sku_architecture_type
+        self.tags = tags
+        self.target_environment_id = target_environment_id
+
+
+class PackageResponse(msrest.serialization.Model):
+    """Package response returned after async package operation completes successfully.
+
+    Variables are only populated by the server, and will be ignored when sending a request.
+
+    :ivar base_environment_source: Base environment to start with.
+    :vartype base_environment_source:
+     ~azure.mgmt.machinelearningservices.models.BaseEnvironmentSource
+    :ivar build_id: Build id of the image build operation.
+    :vartype build_id: str
+    :ivar build_state: Build state of the image build operation. Possible values include:
+     "NotStarted", "Running", "Succeeded", "Failed".
+    :vartype build_state: str or ~azure.mgmt.machinelearningservices.models.PackageBuildState
+    :ivar environment_variables: Collection of environment variables.
+    :vartype environment_variables: dict[str, str]
+    :ivar inferencing_server: Inferencing server configurations.
+    :vartype inferencing_server: ~azure.mgmt.machinelearningservices.models.InferencingServer
+    :ivar inputs: Collection of inputs.
+    :vartype inputs: list[~azure.mgmt.machinelearningservices.models.ModelPackageInput]
+    :ivar log_url: Log url of the image build operation.
+    :vartype log_url: str
+    :ivar model_configuration: Model configuration including the mount mode.
+    :vartype model_configuration: ~azure.mgmt.machinelearningservices.models.ModelConfiguration
+    :ivar properties: Properties dictionary.
+    :vartype properties: dict[str, str]
+    :ivar sku_architecture_type: The sku architecture type.
+    :vartype sku_architecture_type: str
+    :ivar tags: A set of tags. Tag dictionary. Tags can be added, removed, and updated.
+    :vartype tags: dict[str, str]
+    :ivar target_environment_id: Asset ID of the target environment created by package operation.
+    :vartype target_environment_id: str
+    """
+
+    _validation = {
+        "base_environment_source": {"readonly": True},
+        "build_id": {"readonly": True},
+        "build_state": {"readonly": True},
+        "environment_variables": {"readonly": True},
+        "inferencing_server": {"readonly": True},
+        "inputs": {"readonly": True},
+        "log_url": {"readonly": True},
+        "model_configuration": {"readonly": True},
+        "tags": {"readonly": True},
+        "target_environment_id": {"readonly": True},
+    }
+
+    _attribute_map = {
+        "base_environment_source": {"key": "baseEnvironmentSource", "type": "BaseEnvironmentSource"},
+        "build_id": {"key": "buildId", "type": "str"},
+        "build_state": {"key": "buildState", "type": "str"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "inferencing_server": {"key": "inferencingServer", "type": "InferencingServer"},
+        "inputs": {"key": "inputs", "type": "[ModelPackageInput]"},
+        "log_url": {"key": "logUrl", "type": "str"},
+        "model_configuration": {"key": "modelConfiguration", "type": "ModelConfiguration"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "sku_architecture_type": {"key": "skuArchitectureType", "type": "str"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "target_environment_id": {"key": "targetEnvironmentId", "type": "str"},
+    }
+
+    def __init__(
+        self, *, properties: Optional[Dict[str, str]] = None, sku_architecture_type: Optional[str] = None, **kwargs
+    ):
+        """
+        :keyword properties: Properties dictionary.
+        :paramtype properties: dict[str, str]
+        :keyword sku_architecture_type: The sku architecture type.
+        :paramtype sku_architecture_type: str
+        """
+        super(PackageResponse, self).__init__(**kwargs)
+        self.base_environment_source = None
+        self.build_id = None
+        self.build_state = None
+        self.environment_variables = None
+        self.inferencing_server = None
+        self.inputs = None
+        self.log_url = None
+        self.model_configuration = None
+        self.properties = properties
+        self.sku_architecture_type = sku_architecture_type
+        self.tags = None
+        self.target_environment_id = None
+
+
 class PipelineJob(JobBase):
     """Pipeline Job definition: defines generic to MFE attributes.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -4868,36 +5318,36 @@
     :ivar outputs: Data output set for jobs.
     :vartype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
     :ivar settings: Pipeline settings, for things like ContinueRunOnStepFailure etc.
     :vartype settings: any
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
-        'bindings': {'key': 'bindings', 'type': '[Binding]'},
-        'component_jobs': {'key': 'componentJobs', 'type': '{ComponentJob}'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'settings': {'key': 'settings', 'type': 'object'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
+        "bindings": {"key": "bindings", "type": "[Binding]"},
+        "component_jobs": {"key": "componentJobs", "type": "{ComponentJob}"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "settings": {"key": "settings", "type": "object"},
     }
 
     def __init__(
         self,
         *,
         description: Optional[str] = None,
         properties: Optional[Dict[str, str]] = None,
@@ -4940,16 +5390,26 @@
         :keyword inputs: Data input set for jobs.
         :paramtype inputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobInput]
         :keyword outputs: Data output set for jobs.
         :paramtype outputs: dict[str, ~azure.mgmt.machinelearningservices.models.JobOutput]
         :keyword settings: Pipeline settings, for things like ContinueRunOnStepFailure etc.
         :paramtype settings: any
         """
-        super(PipelineJob, self).__init__(description=description, properties=properties, tags=tags, compute_id=compute_id, display_name=display_name, experiment_name=experiment_name, is_archived=is_archived, services=services, **kwargs)
-        self.job_type = 'Pipeline'  # type: str
+        super(PipelineJob, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            compute_id=compute_id,
+            display_name=display_name,
+            experiment_name=experiment_name,
+            is_archived=is_archived,
+            services=services,
+            **kwargs
+        )
+        self.job_type = "Pipeline"  # type: str
         self.bindings = bindings
         self.component_jobs = component_jobs
         self.inputs = inputs
         self.outputs = outputs
         self.settings = settings
 
 
@@ -4962,34 +5422,29 @@
      by server. Possible values include: "PyTorch", "TensorFlow", "Mpi".
     :vartype distribution_type: str or ~azure.mgmt.machinelearningservices.models.DistributionType
     :ivar process_count_per_instance: Number of processes per node.
     :vartype process_count_per_instance: int
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
-        'process_count_per_instance': {'key': 'processCountPerInstance', 'type': 'int'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
+        "process_count_per_instance": {"key": "processCountPerInstance", "type": "int"},
     }
 
-    def __init__(
-        self,
-        *,
-        process_count_per_instance: Optional[int] = None,
-        **kwargs
-    ):
+    def __init__(self, *, process_count_per_instance: Optional[int] = None, **kwargs):
         """
         :keyword process_count_per_instance: Number of processes per node.
         :paramtype process_count_per_instance: int
         """
         super(PyTorch, self).__init__(**kwargs)
-        self.distribution_type = 'PyTorch'  # type: str
+        self.distribution_type = "PyTorch"  # type: str
         self.process_count_per_instance = process_count_per_instance
 
 
 class ResourceConfiguration(msrest.serialization.Model):
     """ResourceConfiguration.
 
     :ivar instance_count: Optional number of instances or nodes used by the compute target.
@@ -4997,17 +5452,17 @@
     :ivar instance_type: Optional type of VM used as supported by the compute target.
     :vartype instance_type: str
     :ivar properties: Additional properties bag.
     :vartype properties: dict[str, any]
     """
 
     _attribute_map = {
-        'instance_count': {'key': 'instanceCount', 'type': 'int'},
-        'instance_type': {'key': 'instanceType', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{object}'},
+        "instance_count": {"key": "instanceCount", "type": "int"},
+        "instance_type": {"key": "instanceType", "type": "str"},
+        "properties": {"key": "properties", "type": "{object}"},
     }
 
     def __init__(
         self,
         *,
         instance_count: Optional[int] = 1,
         instance_type: Optional[str] = None,
@@ -5048,35 +5503,30 @@
     :vartype system_data: ~azure.mgmt.machinelearningservices.models.SystemData
     :ivar properties: Required. Additional attributes of the entity.
     :vartype properties:
      ~azure.mgmt.machinelearningservices.models.ResourceManagementAssetReferenceDetails
     """
 
     _validation = {
-        'id': {'readonly': True},
-        'name': {'readonly': True},
-        'type': {'readonly': True},
-        'system_data': {'readonly': True},
-        'properties': {'required': True},
+        "id": {"readonly": True},
+        "name": {"readonly": True},
+        "type": {"readonly": True},
+        "system_data": {"readonly": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'id', 'type': 'str'},
-        'name': {'key': 'name', 'type': 'str'},
-        'type': {'key': 'type', 'type': 'str'},
-        'system_data': {'key': 'systemData', 'type': 'SystemData'},
-        'properties': {'key': 'properties', 'type': 'ResourceManagementAssetReferenceDetails'},
+        "id": {"key": "id", "type": "str"},
+        "name": {"key": "name", "type": "str"},
+        "type": {"key": "type", "type": "str"},
+        "system_data": {"key": "systemData", "type": "SystemData"},
+        "properties": {"key": "properties", "type": "ResourceManagementAssetReferenceDetails"},
     }
 
-    def __init__(
-        self,
-        *,
-        properties: "ResourceManagementAssetReferenceDetails",
-        **kwargs
-    ):
+    def __init__(self, *, properties: "ResourceManagementAssetReferenceDetails", **kwargs):
         """
         :keyword properties: Required. Additional attributes of the entity.
         :paramtype properties:
          ~azure.mgmt.machinelearningservices.models.ResourceManagementAssetReferenceDetails
         """
         super(ResourceManagementAssetReferenceData, self).__init__(**kwargs)
         self.properties = properties
@@ -5095,23 +5545,23 @@
     :ivar destination_version: Destination asset version for import.
     :vartype destination_version: str
     :ivar source_asset_id: Required. ARM resource ID of the source asset.
     :vartype source_asset_id: str
     """
 
     _validation = {
-        'reference_type': {'required': True},
-        'source_asset_id': {'required': True},
+        "reference_type": {"required": True},
+        "source_asset_id": {"required": True},
     }
 
     _attribute_map = {
-        'reference_type': {'key': 'referenceType', 'type': 'str'},
-        'destination_name': {'key': 'destinationName', 'type': 'str'},
-        'destination_version': {'key': 'destinationVersion', 'type': 'str'},
-        'source_asset_id': {'key': 'sourceAssetId', 'type': 'str'},
+        "reference_type": {"key": "referenceType", "type": "str"},
+        "destination_name": {"key": "destinationName", "type": "str"},
+        "destination_version": {"key": "destinationVersion", "type": "str"},
+        "source_asset_id": {"key": "sourceAssetId", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         source_asset_id: str,
         destination_name: Optional[str] = None,
@@ -5123,15 +5573,15 @@
         :paramtype destination_name: str
         :keyword destination_version: Destination asset version for import.
         :paramtype destination_version: str
         :keyword source_asset_id: Required. ARM resource ID of the source asset.
         :paramtype source_asset_id: str
         """
         super(ResourceManagementAssetReferenceDetails, self).__init__(**kwargs)
-        self.reference_type = 'Id'  # type: str
+        self.reference_type = "Id"  # type: str
         self.destination_name = destination_name
         self.destination_version = destination_version
         self.source_asset_id = source_asset_id
 
 
 class Route(msrest.serialization.Model):
     """Route.
@@ -5141,75 +5591,52 @@
     :ivar path: Required. The path for the route.
     :vartype path: str
     :ivar port: Required. The port for the route.
     :vartype port: int
     """
 
     _validation = {
-        'path': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
-        'port': {'required': True},
+        "path": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
+        "port": {"required": True},
     }
 
     _attribute_map = {
-        'path': {'key': 'path', 'type': 'str'},
-        'port': {'key': 'port', 'type': 'int'},
+        "path": {"key": "path", "type": "str"},
+        "port": {"key": "port", "type": "int"},
     }
 
-    def __init__(
-        self,
-        *,
-        path: str,
-        port: int,
-        **kwargs
-    ):
+    def __init__(self, *, path: str, port: int, **kwargs):
         """
         :keyword path: Required. The path for the route.
         :paramtype path: str
         :keyword port: Required. The port for the route.
         :paramtype port: int
         """
         super(Route, self).__init__(**kwargs)
         self.path = path
         self.port = port
 
 
-class SASCredentialDto(DataReferenceCredentialDto):
+class SASCredentialDto(msrest.serialization.Model):
     """SASCredentialDto.
 
-    All required parameters must be populated in order to send to Azure.
-
-    :ivar credential_type: Required. Constant filled by server. Possible values include: "SAS",
-     "DockerCredentials", "ManagedIdentity", "NoCredentials".
-    :vartype credential_type: str or
-     ~azure.mgmt.machinelearningservices.models.DataReferenceCredentialType
     :ivar sas_uri: Full SAS Uri, including the storage, container/blob path and SAS token.
     :vartype sas_uri: str
     """
 
-    _validation = {
-        'credential_type': {'required': True},
-    }
-
     _attribute_map = {
-        'credential_type': {'key': 'credentialType', 'type': 'str'},
-        'sas_uri': {'key': 'sasUri', 'type': 'str'},
+        "sas_uri": {"key": "sasUri", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        sas_uri: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, sas_uri: Optional[str] = None, **kwargs):
         """
         :keyword sas_uri: Full SAS Uri, including the storage, container/blob path and SAS token.
         :paramtype sas_uri: str
         """
         super(SASCredentialDto, self).__init__(**kwargs)
-        self.credential_type = 'SAS'  # type: str
         self.sas_uri = sas_uri
 
 
 class SasDatastoreCredentials(DatastoreCredentials):
     """SAS datastore credentials configuration.
 
     All required parameters must be populated in order to send to Azure.
@@ -5219,35 +5646,30 @@
      "ServicePrincipal".
     :vartype credentials_type: str or ~azure.mgmt.machinelearningservices.models.CredentialsType
     :ivar secrets: Required. Storage container secrets.
     :vartype secrets: ~azure.mgmt.machinelearningservices.models.SasDatastoreSecrets
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'secrets': {'required': True},
+        "credentials_type": {"required": True},
+        "secrets": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'SasDatastoreSecrets'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "secrets": {"key": "secrets", "type": "SasDatastoreSecrets"},
     }
 
-    def __init__(
-        self,
-        *,
-        secrets: "SasDatastoreSecrets",
-        **kwargs
-    ):
+    def __init__(self, *, secrets: "SasDatastoreSecrets", **kwargs):
         """
         :keyword secrets: Required. Storage container secrets.
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.SasDatastoreSecrets
         """
         super(SasDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'Sas'  # type: str
+        self.credentials_type = "Sas"  # type: str
         self.secrets = secrets
 
 
 class SasDatastoreSecrets(DatastoreSecrets):
     """Datastore SAS secrets.
 
     All required parameters must be populated in order to send to Azure.
@@ -5257,34 +5679,29 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar sas_token: Storage container SAS token.
     :vartype sas_token: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'sas_token': {'key': 'sasToken', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "sas_token": {"key": "sasToken", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        sas_token: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, sas_token: Optional[str] = None, **kwargs):
         """
         :keyword sas_token: Storage container SAS token.
         :paramtype sas_token: str
         """
         super(SasDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'Sas'  # type: str
+        self.secrets_type = "Sas"  # type: str
         self.sas_token = sas_token
 
 
 class ServicePrincipalDatastoreCredentials(DatastoreCredentials):
     """Service Principal datastore credentials configuration.
 
     All required parameters must be populated in order to send to Azure.
@@ -5302,27 +5719,27 @@
     :ivar secrets: Required. Service principal secrets.
     :vartype secrets: ~azure.mgmt.machinelearningservices.models.ServicePrincipalDatastoreSecrets
     :ivar tenant_id: Required. ID of the tenant to which the service principal belongs.
     :vartype tenant_id: str
     """
 
     _validation = {
-        'credentials_type': {'required': True},
-        'client_id': {'required': True},
-        'secrets': {'required': True},
-        'tenant_id': {'required': True},
+        "credentials_type": {"required": True},
+        "client_id": {"required": True},
+        "secrets": {"required": True},
+        "tenant_id": {"required": True},
     }
 
     _attribute_map = {
-        'credentials_type': {'key': 'credentialsType', 'type': 'str'},
-        'authority_url': {'key': 'authorityUrl', 'type': 'str'},
-        'client_id': {'key': 'clientId', 'type': 'str'},
-        'resource_url': {'key': 'resourceUrl', 'type': 'str'},
-        'secrets': {'key': 'secrets', 'type': 'ServicePrincipalDatastoreSecrets'},
-        'tenant_id': {'key': 'tenantId', 'type': 'str'},
+        "credentials_type": {"key": "credentialsType", "type": "str"},
+        "authority_url": {"key": "authorityUrl", "type": "str"},
+        "client_id": {"key": "clientId", "type": "str"},
+        "resource_url": {"key": "resourceUrl", "type": "str"},
+        "secrets": {"key": "secrets", "type": "ServicePrincipalDatastoreSecrets"},
+        "tenant_id": {"key": "tenantId", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         client_id: str,
         secrets: "ServicePrincipalDatastoreSecrets",
@@ -5340,15 +5757,15 @@
         :paramtype resource_url: str
         :keyword secrets: Required. Service principal secrets.
         :paramtype secrets: ~azure.mgmt.machinelearningservices.models.ServicePrincipalDatastoreSecrets
         :keyword tenant_id: Required. ID of the tenant to which the service principal belongs.
         :paramtype tenant_id: str
         """
         super(ServicePrincipalDatastoreCredentials, self).__init__(**kwargs)
-        self.credentials_type = 'ServicePrincipal'  # type: str
+        self.credentials_type = "ServicePrincipal"  # type: str
         self.authority_url = authority_url
         self.client_id = client_id
         self.resource_url = resource_url
         self.secrets = secrets
         self.tenant_id = tenant_id
 
 
@@ -5362,34 +5779,29 @@
      "ServicePrincipal".
     :vartype secrets_type: str or ~azure.mgmt.machinelearningservices.models.SecretsType
     :ivar client_secret: Service principal secret.
     :vartype client_secret: str
     """
 
     _validation = {
-        'secrets_type': {'required': True},
+        "secrets_type": {"required": True},
     }
 
     _attribute_map = {
-        'secrets_type': {'key': 'secretsType', 'type': 'str'},
-        'client_secret': {'key': 'clientSecret', 'type': 'str'},
+        "secrets_type": {"key": "secretsType", "type": "str"},
+        "client_secret": {"key": "clientSecret", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        client_secret: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, client_secret: Optional[str] = None, **kwargs):
         """
         :keyword client_secret: Service principal secret.
         :paramtype client_secret: str
         """
         super(ServicePrincipalDatastoreSecrets, self).__init__(**kwargs)
-        self.secrets_type = 'ServicePrincipal'  # type: str
+        self.secrets_type = "ServicePrincipal"  # type: str
         self.client_secret = client_secret
 
 
 class SweepJob(JobBase):
     """Sweep job definition.
 
     Variables are only populated by the server, and will be ignored when sending a request.
@@ -5446,44 +5858,44 @@
      dictionary key is the name of the parameter.
     :vartype search_space: any
     :ivar trial: Required. Trial component definition.
     :vartype trial: ~azure.mgmt.machinelearningservices.models.TrialComponent
     """
 
     _validation = {
-        'job_type': {'required': True},
-        'parent_job_name': {'readonly': True},
-        'status': {'readonly': True},
-        'objective': {'required': True},
-        'sampling_algorithm': {'required': True},
-        'search_space': {'required': True},
-        'trial': {'required': True},
+        "job_type": {"required": True},
+        "parent_job_name": {"readonly": True},
+        "status": {"readonly": True},
+        "objective": {"required": True},
+        "sampling_algorithm": {"required": True},
+        "search_space": {"required": True},
+        "trial": {"required": True},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'compute_id': {'key': 'computeId', 'type': 'str'},
-        'display_name': {'key': 'displayName', 'type': 'str'},
-        'experiment_name': {'key': 'experimentName', 'type': 'str'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'job_type': {'key': 'jobType', 'type': 'str'},
-        'parent_job_name': {'key': 'parentJobName', 'type': 'str'},
-        'services': {'key': 'services', 'type': '{JobService}'},
-        'status': {'key': 'status', 'type': 'str'},
-        'early_termination': {'key': 'earlyTermination', 'type': 'EarlyTerminationPolicy'},
-        'identity': {'key': 'identity', 'type': 'IdentityConfiguration'},
-        'inputs': {'key': 'inputs', 'type': '{JobInput}'},
-        'limits': {'key': 'limits', 'type': 'SweepJobLimits'},
-        'objective': {'key': 'objective', 'type': 'Objective'},
-        'outputs': {'key': 'outputs', 'type': '{JobOutput}'},
-        'sampling_algorithm': {'key': 'samplingAlgorithm', 'type': 'str'},
-        'search_space': {'key': 'searchSpace', 'type': 'object'},
-        'trial': {'key': 'trial', 'type': 'TrialComponent'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "compute_id": {"key": "computeId", "type": "str"},
+        "display_name": {"key": "displayName", "type": "str"},
+        "experiment_name": {"key": "experimentName", "type": "str"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "job_type": {"key": "jobType", "type": "str"},
+        "parent_job_name": {"key": "parentJobName", "type": "str"},
+        "services": {"key": "services", "type": "{JobService}"},
+        "status": {"key": "status", "type": "str"},
+        "early_termination": {"key": "earlyTermination", "type": "EarlyTerminationPolicy"},
+        "identity": {"key": "identity", "type": "IdentityConfiguration"},
+        "inputs": {"key": "inputs", "type": "{JobInput}"},
+        "limits": {"key": "limits", "type": "SweepJobLimits"},
+        "objective": {"key": "objective", "type": "Objective"},
+        "outputs": {"key": "outputs", "type": "{JobOutput}"},
+        "sampling_algorithm": {"key": "samplingAlgorithm", "type": "str"},
+        "search_space": {"key": "searchSpace", "type": "object"},
+        "trial": {"key": "trial", "type": "TrialComponent"},
     }
 
     def __init__(
         self,
         *,
         objective: "Objective",
         sampling_algorithm: Union[str, "SamplingAlgorithm"],
@@ -5544,16 +5956,26 @@
          ~azure.mgmt.machinelearningservices.models.SamplingAlgorithm
         :keyword search_space: Required. A dictionary containing each parameter and its distribution.
          The dictionary key is the name of the parameter.
         :paramtype search_space: any
         :keyword trial: Required. Trial component definition.
         :paramtype trial: ~azure.mgmt.machinelearningservices.models.TrialComponent
         """
-        super(SweepJob, self).__init__(description=description, properties=properties, tags=tags, compute_id=compute_id, display_name=display_name, experiment_name=experiment_name, is_archived=is_archived, services=services, **kwargs)
-        self.job_type = 'Sweep'  # type: str
+        super(SweepJob, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            compute_id=compute_id,
+            display_name=display_name,
+            experiment_name=experiment_name,
+            is_archived=is_archived,
+            services=services,
+            **kwargs
+        )
+        self.job_type = "Sweep"  # type: str
         self.early_termination = early_termination
         self.identity = identity
         self.inputs = inputs
         self.limits = limits
         self.objective = objective
         self.outputs = outputs
         self.sampling_algorithm = sampling_algorithm
@@ -5577,23 +5999,23 @@
     :ivar max_total_trials: Sweep Job max total trials.
     :vartype max_total_trials: int
     :ivar trial_timeout: Sweep Job Trial timeout value.
     :vartype trial_timeout: ~datetime.timedelta
     """
 
     _validation = {
-        'job_limits_type': {'required': True},
+        "job_limits_type": {"required": True},
     }
 
     _attribute_map = {
-        'job_limits_type': {'key': 'jobLimitsType', 'type': 'str'},
-        'timeout': {'key': 'timeout', 'type': 'duration'},
-        'max_concurrent_trials': {'key': 'maxConcurrentTrials', 'type': 'int'},
-        'max_total_trials': {'key': 'maxTotalTrials', 'type': 'int'},
-        'trial_timeout': {'key': 'trialTimeout', 'type': 'duration'},
+        "job_limits_type": {"key": "jobLimitsType", "type": "str"},
+        "timeout": {"key": "timeout", "type": "duration"},
+        "max_concurrent_trials": {"key": "maxConcurrentTrials", "type": "int"},
+        "max_total_trials": {"key": "maxTotalTrials", "type": "int"},
+        "trial_timeout": {"key": "trialTimeout", "type": "duration"},
     }
 
     def __init__(
         self,
         *,
         timeout: Optional[datetime.timedelta] = None,
         max_concurrent_trials: Optional[int] = None,
@@ -5609,15 +6031,15 @@
         :paramtype max_concurrent_trials: int
         :keyword max_total_trials: Sweep Job max total trials.
         :paramtype max_total_trials: int
         :keyword trial_timeout: Sweep Job Trial timeout value.
         :paramtype trial_timeout: ~datetime.timedelta
         """
         super(SweepJobLimits, self).__init__(timeout=timeout, **kwargs)
-        self.job_limits_type = 'Sweep'  # type: str
+        self.job_limits_type = "Sweep"  # type: str
         self.max_concurrent_trials = max_concurrent_trials
         self.max_total_trials = max_total_trials
         self.trial_timeout = trial_timeout
 
 
 class SystemData(msrest.serialization.Model):
     """Metadata pertaining to creation and last modification of the resource.
@@ -5635,20 +6057,20 @@
      values include: "User", "Application", "ManagedIdentity", "Key".
     :vartype last_modified_by_type: str or ~azure.mgmt.machinelearningservices.models.CreatedByType
     :ivar last_modified_at: The timestamp of resource last modification (UTC).
     :vartype last_modified_at: ~datetime.datetime
     """
 
     _attribute_map = {
-        'created_by': {'key': 'createdBy', 'type': 'str'},
-        'created_by_type': {'key': 'createdByType', 'type': 'str'},
-        'created_at': {'key': 'createdAt', 'type': 'iso-8601'},
-        'last_modified_by': {'key': 'lastModifiedBy', 'type': 'str'},
-        'last_modified_by_type': {'key': 'lastModifiedByType', 'type': 'str'},
-        'last_modified_at': {'key': 'lastModifiedAt', 'type': 'iso-8601'},
+        "created_by": {"key": "createdBy", "type": "str"},
+        "created_by_type": {"key": "createdByType", "type": "str"},
+        "created_at": {"key": "createdAt", "type": "iso-8601"},
+        "last_modified_by": {"key": "lastModifiedBy", "type": "str"},
+        "last_modified_by_type": {"key": "lastModifiedByType", "type": "str"},
+        "last_modified_at": {"key": "lastModifiedAt", "type": "iso-8601"},
     }
 
     def __init__(
         self,
         *,
         created_by: Optional[str] = None,
         created_by_type: Optional[Union[str, "CreatedByType"]] = None,
@@ -5693,17 +6115,17 @@
      used.
     :vartype temporary_data_reference_id: str
     :ivar temporary_data_reference_type: Either TemporaryBlobReference or TemporaryImageReference.
     :vartype temporary_data_reference_type: str
     """
 
     _attribute_map = {
-        'asset_id': {'key': 'assetId', 'type': 'str'},
-        'temporary_data_reference_id': {'key': 'temporaryDataReferenceId', 'type': 'str'},
-        'temporary_data_reference_type': {'key': 'temporaryDataReferenceType', 'type': 'str'},
+        "asset_id": {"key": "assetId", "type": "str"},
+        "temporary_data_reference_id": {"key": "temporaryDataReferenceId", "type": "str"},
+        "temporary_data_reference_type": {"key": "temporaryDataReferenceType", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         asset_id: Optional[str] = None,
         temporary_data_reference_id: Optional[str] = None,
@@ -5738,18 +6160,24 @@
     :ivar temporary_data_reference_id:
     :vartype temporary_data_reference_id: str
     :ivar temporary_data_reference_type:
     :vartype temporary_data_reference_type: str
     """
 
     _attribute_map = {
-        'blob_reference_for_consumption': {'key': 'blobReferenceForConsumption', 'type': 'BlobReferenceForConsumptionDto'},
-        'image_reference_for_consumption': {'key': 'imageReferenceForConsumption', 'type': 'ImageReferenceForConsumptionDto'},
-        'temporary_data_reference_id': {'key': 'temporaryDataReferenceId', 'type': 'str'},
-        'temporary_data_reference_type': {'key': 'temporaryDataReferenceType', 'type': 'str'},
+        "blob_reference_for_consumption": {
+            "key": "blobReferenceForConsumption",
+            "type": "BlobReferenceForConsumptionDto",
+        },
+        "image_reference_for_consumption": {
+            "key": "imageReferenceForConsumption",
+            "type": "ImageReferenceForConsumptionDto",
+        },
+        "temporary_data_reference_id": {"key": "temporaryDataReferenceId", "type": "str"},
+        "temporary_data_reference_type": {"key": "temporaryDataReferenceType", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         blob_reference_for_consumption: Optional["BlobReferenceForConsumptionDto"] = None,
         image_reference_for_consumption: Optional["ImageReferenceForConsumptionDto"] = None,
@@ -5787,38 +6215,32 @@
     :ivar parameter_server_count: Number of parameter server tasks.
     :vartype parameter_server_count: int
     :ivar worker_count: Number of workers. If not specified, will default to the instance count.
     :vartype worker_count: int
     """
 
     _validation = {
-        'distribution_type': {'required': True},
+        "distribution_type": {"required": True},
     }
 
     _attribute_map = {
-        'distribution_type': {'key': 'distributionType', 'type': 'str'},
-        'parameter_server_count': {'key': 'parameterServerCount', 'type': 'int'},
-        'worker_count': {'key': 'workerCount', 'type': 'int'},
+        "distribution_type": {"key": "distributionType", "type": "str"},
+        "parameter_server_count": {"key": "parameterServerCount", "type": "int"},
+        "worker_count": {"key": "workerCount", "type": "int"},
     }
 
-    def __init__(
-        self,
-        *,
-        parameter_server_count: Optional[int] = 0,
-        worker_count: Optional[int] = None,
-        **kwargs
-    ):
+    def __init__(self, *, parameter_server_count: Optional[int] = 0, worker_count: Optional[int] = None, **kwargs):
         """
         :keyword parameter_server_count: Number of parameter server tasks.
         :paramtype parameter_server_count: int
         :keyword worker_count: Number of workers. If not specified, will default to the instance count.
         :paramtype worker_count: int
         """
         super(TensorFlow, self).__init__(**kwargs)
-        self.distribution_type = 'TensorFlow'  # type: str
+        self.distribution_type = "TensorFlow"  # type: str
         self.parameter_server_count = parameter_server_count
         self.worker_count = worker_count
 
 
 class TrialComponent(msrest.serialization.Model):
     """Trial component definition.
 
@@ -5837,25 +6259,25 @@
     :ivar environment_variables: Environment variables included in the job.
     :vartype environment_variables: dict[str, str]
     :ivar resources: Compute Resource configuration for the job.
     :vartype resources: ~azure.mgmt.machinelearningservices.models.ResourceConfiguration
     """
 
     _validation = {
-        'command': {'required': True, 'min_length': 1, 'pattern': r'[a-zA-Z0-9_]'},
-        'environment_id': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "command": {"required": True, "min_length": 1, "pattern": r"[a-zA-Z0-9_]"},
+        "environment_id": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'code_id': {'key': 'codeId', 'type': 'str'},
-        'command': {'key': 'command', 'type': 'str'},
-        'distribution': {'key': 'distribution', 'type': 'DistributionConfiguration'},
-        'environment_id': {'key': 'environmentId', 'type': 'str'},
-        'environment_variables': {'key': 'environmentVariables', 'type': '{str}'},
-        'resources': {'key': 'resources', 'type': 'ResourceConfiguration'},
+        "code_id": {"key": "codeId", "type": "str"},
+        "command": {"key": "command", "type": "str"},
+        "distribution": {"key": "distribution", "type": "DistributionConfiguration"},
+        "environment_id": {"key": "environmentId", "type": "str"},
+        "environment_variables": {"key": "environmentVariables", "type": "{str}"},
+        "resources": {"key": "resources", "type": "ResourceConfiguration"},
     }
 
     def __init__(
         self,
         *,
         command: str,
         environment_id: str,
@@ -5887,14 +6309,47 @@
         self.command = command
         self.distribution = distribution
         self.environment_id = environment_id
         self.environment_variables = environment_variables
         self.resources = resources
 
 
+class TritonInferencingServer(InferencingServer):
+    """Triton inferencing server configurations.
+
+    All required parameters must be populated in order to send to Azure.
+
+    :ivar server_type: Required. Inferencing server type for various targets.Constant filled by
+     server. Possible values include: "AzureMLOnline", "AzureMLBatch", "Triton", "Custom".
+    :vartype server_type: str or ~azure.mgmt.machinelearningservices.models.InferencingServerType
+    :ivar inference_configuration: Inference configuration for Triton.
+    :vartype inference_configuration:
+     ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+    """
+
+    _validation = {
+        "server_type": {"required": True},
+    }
+
+    _attribute_map = {
+        "server_type": {"key": "serverType", "type": "str"},
+        "inference_configuration": {"key": "inferenceConfiguration", "type": "OnlineInferenceConfiguration"},
+    }
+
+    def __init__(self, *, inference_configuration: Optional["OnlineInferenceConfiguration"] = None, **kwargs):
+        """
+        :keyword inference_configuration: Inference configuration for Triton.
+        :paramtype inference_configuration:
+         ~azure.mgmt.machinelearningservices.models.OnlineInferenceConfiguration
+        """
+        super(TritonInferencingServer, self).__init__(**kwargs)
+        self.server_type = "Triton"  # type: str
+        self.inference_configuration = inference_configuration
+
+
 class TruncationSelectionPolicy(EarlyTerminationPolicy):
     """Defines an early termination policy that cancels a given percentage of runs at each evaluation interval.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar delay_evaluation: Number of intervals by which to delay the first evaluation.
     :vartype delay_evaluation: int
@@ -5905,22 +6360,22 @@
     :vartype policy_type: str or
      ~azure.mgmt.machinelearningservices.models.EarlyTerminationPolicyType
     :ivar truncation_percentage: The percentage of runs to cancel at each evaluation interval.
     :vartype truncation_percentage: int
     """
 
     _validation = {
-        'policy_type': {'required': True},
+        "policy_type": {"required": True},
     }
 
     _attribute_map = {
-        'delay_evaluation': {'key': 'delayEvaluation', 'type': 'int'},
-        'evaluation_interval': {'key': 'evaluationInterval', 'type': 'int'},
-        'policy_type': {'key': 'policyType', 'type': 'str'},
-        'truncation_percentage': {'key': 'truncationPercentage', 'type': 'int'},
+        "delay_evaluation": {"key": "delayEvaluation", "type": "int"},
+        "evaluation_interval": {"key": "evaluationInterval", "type": "int"},
+        "policy_type": {"key": "policyType", "type": "str"},
+        "truncation_percentage": {"key": "truncationPercentage", "type": "int"},
     }
 
     def __init__(
         self,
         *,
         delay_evaluation: Optional[int] = 0,
         evaluation_interval: Optional[int] = 0,
@@ -5931,16 +6386,18 @@
         :keyword delay_evaluation: Number of intervals by which to delay the first evaluation.
         :paramtype delay_evaluation: int
         :keyword evaluation_interval: Interval (number of runs) between policy evaluations.
         :paramtype evaluation_interval: int
         :keyword truncation_percentage: The percentage of runs to cancel at each evaluation interval.
         :paramtype truncation_percentage: int
         """
-        super(TruncationSelectionPolicy, self).__init__(delay_evaluation=delay_evaluation, evaluation_interval=evaluation_interval, **kwargs)
-        self.policy_type = 'TruncationSelection'  # type: str
+        super(TruncationSelectionPolicy, self).__init__(
+            delay_evaluation=delay_evaluation, evaluation_interval=evaluation_interval, **kwargs
+        )
+        self.policy_type = "TruncationSelection"  # type: str
         self.truncation_percentage = truncation_percentage
 
 
 class UriFileDataVersion(DataVersionBaseDetails):
     """uri-file data version entity.
 
     All required parameters must be populated in order to send to Azure.
@@ -5963,27 +6420,27 @@
     :vartype data_uri: str
     :ivar intellectual_property: Intellectual Property details. Used if data is an Intellectual
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
     }
 
     def __init__(
         self,
         *,
         data_uri: str,
         description: Optional[str] = None,
@@ -6009,16 +6466,25 @@
          Microsoft.MachineLearning.ManagementFrontEnd.Contracts.V20211001Dataplane.Assets.DataVersionBase.DataType.
         :paramtype data_uri: str
         :keyword intellectual_property: Intellectual Property details. Used if data is an Intellectual
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         """
-        super(UriFileDataVersion, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, data_uri=data_uri, intellectual_property=intellectual_property, **kwargs)
-        self.data_type = 'uri_file'  # type: str
+        super(UriFileDataVersion, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            data_uri=data_uri,
+            intellectual_property=intellectual_property,
+            **kwargs
+        )
+        self.data_type = "uri_file"  # type: str
 
 
 class UriFolderDataVersion(DataVersionBaseDetails):
     """uri-folder data version entity.
 
     All required parameters must be populated in order to send to Azure.
 
@@ -6040,27 +6506,27 @@
     :vartype data_uri: str
     :ivar intellectual_property: Intellectual Property details. Used if data is an Intellectual
      Property.
     :vartype intellectual_property: ~azure.mgmt.machinelearningservices.models.IntellectualProperty
     """
 
     _validation = {
-        'data_type': {'required': True},
-        'data_uri': {'required': True, 'pattern': r'[a-zA-Z0-9_]'},
+        "data_type": {"required": True},
+        "data_uri": {"required": True, "pattern": r"[a-zA-Z0-9_]"},
     }
 
     _attribute_map = {
-        'description': {'key': 'description', 'type': 'str'},
-        'properties': {'key': 'properties', 'type': '{str}'},
-        'tags': {'key': 'tags', 'type': '{str}'},
-        'is_anonymous': {'key': 'isAnonymous', 'type': 'bool'},
-        'is_archived': {'key': 'isArchived', 'type': 'bool'},
-        'data_type': {'key': 'dataType', 'type': 'str'},
-        'data_uri': {'key': 'dataUri', 'type': 'str'},
-        'intellectual_property': {'key': 'intellectualProperty', 'type': 'IntellectualProperty'},
+        "description": {"key": "description", "type": "str"},
+        "properties": {"key": "properties", "type": "{str}"},
+        "tags": {"key": "tags", "type": "{str}"},
+        "is_anonymous": {"key": "isAnonymous", "type": "bool"},
+        "is_archived": {"key": "isArchived", "type": "bool"},
+        "data_type": {"key": "dataType", "type": "str"},
+        "data_uri": {"key": "dataUri", "type": "str"},
+        "intellectual_property": {"key": "intellectualProperty", "type": "IntellectualProperty"},
     }
 
     def __init__(
         self,
         *,
         data_uri: str,
         description: Optional[str] = None,
@@ -6086,39 +6552,42 @@
          Microsoft.MachineLearning.ManagementFrontEnd.Contracts.V20211001Dataplane.Assets.DataVersionBase.DataType.
         :paramtype data_uri: str
         :keyword intellectual_property: Intellectual Property details. Used if data is an Intellectual
          Property.
         :paramtype intellectual_property:
          ~azure.mgmt.machinelearningservices.models.IntellectualProperty
         """
-        super(UriFolderDataVersion, self).__init__(description=description, properties=properties, tags=tags, is_anonymous=is_anonymous, is_archived=is_archived, data_uri=data_uri, intellectual_property=intellectual_property, **kwargs)
-        self.data_type = 'uri_folder'  # type: str
+        super(UriFolderDataVersion, self).__init__(
+            description=description,
+            properties=properties,
+            tags=tags,
+            is_anonymous=is_anonymous,
+            is_archived=is_archived,
+            data_uri=data_uri,
+            intellectual_property=intellectual_property,
+            **kwargs
+        )
+        self.data_type = "uri_folder"  # type: str
 
 
 class UriReference(msrest.serialization.Model):
     """TODO - UriReference.
 
     :ivar file: Single file uri path.
     :vartype file: str
     :ivar folder: Folder uri path.
     :vartype folder: str
     """
 
     _attribute_map = {
-        'file': {'key': 'file', 'type': 'str'},
-        'folder': {'key': 'folder', 'type': 'str'},
+        "file": {"key": "file", "type": "str"},
+        "folder": {"key": "folder", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        file: Optional[str] = None,
-        folder: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, file: Optional[str] = None, folder: Optional[str] = None, **kwargs):
         """
         :keyword file: Single file uri path.
         :paramtype file: str
         :keyword folder: Folder uri path.
         :paramtype folder: str
         """
         super(UriReference, self).__init__(**kwargs)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_containers_operations.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,34 +1,41 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
@@ -40,40 +47,40 @@
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data')
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+        query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
     if list_view_type is not None:
-        _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
+        query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -82,37 +89,37 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -121,37 +128,37 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -161,39 +168,39 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class DataContainersOperations(object):
     """DataContainersOperations operations.
 
@@ -234,45 +241,47 @@
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
         :param list_view_type:
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either DataContainerResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.DataContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
@@ -289,36 +298,30 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data"}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def delete(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
@@ -328,56 +331,51 @@
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
@@ -390,60 +388,55 @@
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: DataContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.DataContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('DataContainerData', pipeline_response)
+        deserialized = self._deserialize("DataContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
     @distributed_trace
     def create_or_update(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
@@ -459,57 +452,53 @@
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.DataContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: DataContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.DataContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'DataContainerData')
+        _json = self._serialize.body(body, "DataContainerData")
 
         request = build_create_or_update_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('DataContainerData', pipeline_response)
+        deserialized = self._deserialize("DataContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_versions_operations.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,202 +1,220 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
-
-from msrest import Serializer
+import warnings
 
 from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
     T = TypeVar('T')
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-    skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
+    order_by = kwargs.pop('order_by', None)  # type: Optional[str]
+    top = kwargs.pop('top', None)  # type: Optional[int]
+    skip = kwargs.pop('skip', None)  # type: Optional[str]
+    tags = kwargs.pop('tags', None)  # type: Optional[str]
+    list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
+    api_version = "2022-05-01"
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions')
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "name": _SERIALIZER.url("name", name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
-    if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    if order_by is not None:
+        query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
+    if top is not None:
+        query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
+    if skip is not None:
+        query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
+    if tags is not None:
+        query_parameters['$tags'] = _SERIALIZER.query("tags", tags, 'str')
+    if list_view_type is not None:
+        query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
-    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
+    api_version = "2022-05-01"
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}')
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "name": _SERIALIZER.url("name", name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
-    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
+    api_version = "2022-05-01"
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}')
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "name": _SERIALIZER.url("name", name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request(
-    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
+    api_version = "2022-05-01"
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}')
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
-class CodeContainersOperations(object):
-    """CodeContainersOperations operations.
+class DataVersionsOperations(object):
+    """DataVersionsOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -213,295 +231,312 @@
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
         self,
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        skiptoken=None,  # type: Optional[str]
+        workspace_name,  # type: str
+        name,  # type: str
+        order_by=None,  # type: Optional[str]
+        top=None,  # type: Optional[int]
+        skip=None,  # type: Optional[str]
+        tags=None,  # type: Optional[str]
+        list_view_type=None,  # type: Optional[Union[str, "_models.ListViewType"]]
         **kwargs  # type: Any
     ):
-        # type: (...) -> Iterable["_models.CodeContainerResourceArmPaginatedResult"]
-        """List containers.
+        # type: (...) -> Iterable["_models.DataVersionBaseResourceArmPaginatedResult"]
+        """List data versions in the data container.
 
-        List containers.
+        List data versions in the data container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :param skiptoken: Continuation token for pagination.
-        :type skiptoken: str
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Data container's name.
+        :type name: str
+        :param order_by: Please choose OrderBy value from ['createdtime', 'modifiedtime'].
+        :type order_by: str
+        :param top: Top count of results, top count cannot be greater than the page size.
+                                       If topCount > page size, results with be default page size count
+         will be returned.
+        :type top: int
+        :param skip: Continuation token for pagination.
+        :type skip: str
+        :param tags: Comma-separated list of tag names (and optionally values). Example:
+         tag1,tag2=value2.
+        :type tags: str
+        :param list_view_type: [ListViewType.ActiveOnly, ListViewType.ArchivedOnly,
+         ListViewType.All]View type for including/excluding (for example) archived entities.
+        :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either CodeContainerResourceArmPaginatedResult or the
+        :return: An iterator like instance of either DataVersionBaseResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
-         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.CodeContainerResourceArmPaginatedResult]
+         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.DataVersionBaseResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainerResourceArmPaginatedResult"]
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseResourceArmPaginatedResult"]
         error_map = {
             401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
         }
         error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
                 
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
-                    registry_name=registry_name,
-                    api_version=api_version,
-                    skiptoken=skiptoken,
+                    workspace_name=workspace_name,
+                    name=name,
+                    order_by=order_by,
+                    top=top,
+                    skip=skip,
+                    tags=tags,
+                    list_view_type=list_view_type,
                     template_url=self.list.metadata['url'],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
                 
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
-                    registry_name=registry_name,
-                    api_version=api_version,
-                    skiptoken=skiptoken,
+                    workspace_name=workspace_name,
+                    name=name,
+                    order_by=order_by,
+                    top=top,
+                    skip=skip,
+                    tags=tags,
+                    list_view_type=list_view_type,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         def extract_data(pipeline_response):
-            deserialized = self._deserialize("CodeContainerResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("DataVersionBaseResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
 
         return ItemPaged(
             get_next, extract_data
         )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes"}  # type: ignore
+    list.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions'}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def delete(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
-        registry_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
+        version,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        """Delete container.
+        """Delete version.
 
-        Delete container.
+        Delete version.
 
-        :param name: Container name.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Container name.
+        :type name: str
+        :param version: Version identifier.
+        :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
         cls = kwargs.pop('cls', None)  # type: ClsType[None]
         error_map = {
             401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
         }
         error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
         
         request = build_delete_request(
-            name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
-            registry_name=registry_name,
-            api_version=api_version,
+            workspace_name=workspace_name,
+            name=name,
+            version=version,
             template_url=self.delete.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
+    delete.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}'}  # type: ignore
 
 
     @distributed_trace
     def get(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
-        registry_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
+        version,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.CodeContainerData"
-        """Get container.
+        # type: (...) -> "_models.DataVersionBaseData"
+        """Get version.
 
-        Get container.
+        Get version.
 
-        :param name: Container name.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Container name.
+        :type name: str
+        :param version: Version identifier.
+        :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: CodeContainerData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainerData
+        :return: DataVersionBaseData, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainerData"]
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseData"]
         error_map = {
             401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
         }
         error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
         
         request = build_get_request(
-            name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
-            registry_name=registry_name,
-            api_version=api_version,
+            workspace_name=workspace_name,
+            name=name,
+            version=version,
             template_url=self.get.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('CodeContainerData', pipeline_response)
+        deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
+    get.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}'}  # type: ignore
 
 
     @distributed_trace
     def create_or_update(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        body,  # type: "_models.CodeContainerData"
+        workspace_name,  # type: str
+        name,  # type: str
+        version,  # type: str
+        body,  # type: "_models.DataVersionBaseData"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.CodeContainerData"
-        """Create or update container.
+        # type: (...) -> "_models.DataVersionBaseData"
+        """Create or update version.
 
-        Create or update container.
+        Create or update version.
 
-        :param name: Container name.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :param body: Container entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.CodeContainerData
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Container name.
+        :type name: str
+        :param version: Version identifier.
+        :type version: str
+        :param body: Version entity to create or update.
+        :type body: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: CodeContainerData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainerData
+        :return: DataVersionBaseData, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainerData"]
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseData"]
         error_map = {
             401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
         }
         error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
         content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'CodeContainerData')
+        _json = self._serialize.body(body, 'DataVersionBaseData')
 
         request = build_create_or_update_request(
-            name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
-            registry_name=registry_name,
-            api_version=api_version,
+            workspace_name=workspace_name,
+            name=name,
+            version=version,
             content_type=content_type,
             json=_json,
             template_url=self.create_or_update.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('CodeContainerData', pipeline_response)
+        if response.status_code == 200:
+            deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
+
+        if response.status_code == 201:
+            deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
+    create_or_update.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}'}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_versions_operations.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,43 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.arm_polling import ARMPolling
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
@@ -46,47 +53,47 @@
     top = kwargs.pop('top', None)  # type: Optional[int]
     skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
     stage = kwargs.pop('stage', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if order_by is not None:
-        _query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
+        query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
     if top is not None:
-        _query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
+        query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
     if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+        query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
     if list_view_type is not None:
-        _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
+        query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
     if stage is not None:
-        _query_parameters['stage'] = _SERIALIZER.query("stage", stage, 'str')
+        query_parameters['stage'] = _SERIALIZER.query("stage", stage, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
     name,  # type: str
     version,  # type: str
@@ -96,38 +103,38 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
     name,  # type: str
     version,  # type: str
@@ -137,38 +144,38 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request_initial(
     name,  # type: str
     version,  # type: str
@@ -179,40 +186,40 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^(?![\-_.])[a-zA-Z0-9\-_.]{1,255}(?<!\.)$'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class EnvironmentVersionsOperations(object):
     """EnvironmentVersionsOperations operations.
 
@@ -265,49 +272,51 @@
         :type top: int
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
         :param stage:
         :type stage: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either EnvironmentVersionResourceArmPaginatedResult or
          the result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.EnvironmentVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
                     stage=stage,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
@@ -328,36 +337,30 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions"}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def delete(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         **kwargs  # type: Any
     ):
@@ -370,57 +373,52 @@
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
@@ -436,122 +434,111 @@
         :type name: str
         :param version: Version identifier. This is case-sensitive.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: EnvironmentVersionData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentVersionData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('EnvironmentVersionData', pipeline_response)
+        deserialized = self._deserialize("EnvironmentVersionData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
 
-
-    def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    def _create_or_update_initial(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.EnvironmentVersionData"
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'EnvironmentVersionData')
+        _json = self._serialize.body(body, "EnvironmentVersionData")
 
         request = build_create_or_update_request_initial(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
-    def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    def begin_create_or_update(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.EnvironmentVersionData"
         **kwargs  # type: Any
@@ -567,60 +554,63 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Version entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.EnvironmentVersionData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of LROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.LROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
                 name=name,
                 version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-
-        if polling is True: polling_method = ARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = NoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_resource_management_asset_reference_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_resource_management_asset_reference_operations.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,35 +1,42 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.arm_polling import ARMPolling
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Optional, TypeVar, Union
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Optional, TypeVar, Union
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_import_method_request_initial(
@@ -40,38 +47,38 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import')
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="POST",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class ResourceManagementAssetReferenceOperations(object):
     """ResourceManagementAssetReferenceOperations operations.
 
@@ -98,65 +105,57 @@
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.ResourceManagementAssetReferenceData"
         **kwargs  # type: Any
     ):
         # type: (...) -> Optional[Any]
-        cls = kwargs.pop('cls', None)  # type: ClsType[Optional[Any]]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[Optional[Any]]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ResourceManagementAssetReferenceData')
+        _json = self._serialize.body(body, "ResourceManagementAssetReferenceData")
 
         request = build_import_method_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._import_method_initial.metadata['url'],
+            template_url=self._import_method_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         deserialized = None
         response_headers = {}
         if response.status_code == 200:
-            deserialized = self._deserialize('object', pipeline_response)
+            deserialized = self._deserialize("object", pipeline_response)
 
         if response.status_code == 202:
-            response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-            response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-            
+            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _import_method_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
-
+    _import_method_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
 
     @distributed_trace
     def begin_import_method(
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.ResourceManagementAssetReferenceData"
@@ -178,61 +177,64 @@
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Import request contains the source asset reference value and destination version
          value.
         :type body: ~azure.mgmt.machinelearningservices.models.ResourceManagementAssetReferenceData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of LROPoller that returns either any or the result of cls(response)
         :rtype: ~azure.core.polling.LROPoller[any]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[Any]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[Any]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._import_method_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             response = pipeline_response.http_response
-            deserialized = self._deserialize('object', pipeline_response)
+            deserialized = self._deserialize("object", pipeline_response)
             if cls:
                 return cls(pipeline_response, deserialized, {})
             return deserialized
 
-
-        if polling is True: polling_method = ARMPolling(lro_delay, lro_options={'final-state-via': 'location'}, **kwargs)
-        elif polling is False: polling_method = NoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_import_method.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
+    begin_import_method.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/import"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_versions_operations.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,43 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.arm_polling import ARMPolling
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
@@ -44,43 +51,43 @@
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     order_by = kwargs.pop('order_by', None)  # type: Optional[str]
     top = kwargs.pop('top', None)  # type: Optional[int]
     skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if order_by is not None:
-        _query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
+        query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
     if top is not None:
-        _query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
+        query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
     if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+        query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
     name,  # type: str
     version,  # type: str
@@ -90,38 +97,38 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
     name,  # type: str
     version,  # type: str
@@ -131,38 +138,38 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request_initial(
     name,  # type: str
     version,  # type: str
@@ -173,40 +180,40 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^(?![\-_.])[a-zA-Z0-9\-_.]{1,255}(?<!\.)$'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class ComponentVersionsOperations(object):
     """ComponentVersionsOperations operations.
 
@@ -253,47 +260,49 @@
         :type registry_name: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either ComponentVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ComponentVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skiptoken=skiptoken,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
@@ -312,36 +321,30 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions"}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def delete(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         **kwargs  # type: Any
     ):
@@ -354,57 +357,52 @@
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
@@ -420,122 +418,111 @@
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: ComponentVersionData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.ComponentVersionData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentVersionData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ComponentVersionData', pipeline_response)
+        deserialized = self._deserialize("ComponentVersionData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
 
-
-    def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    def _create_or_update_initial(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.ComponentVersionData"
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ComponentVersionData')
+        _json = self._serialize.body(body, "ComponentVersionData")
 
         request = build_create_or_update_request_initial(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
-    def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    def begin_create_or_update(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.ComponentVersionData"
         **kwargs  # type: Any
@@ -551,60 +538,63 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Version entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.ComponentVersionData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of LROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.LROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
                 name=name,
                 version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-
-        if polling is True: polling_method = ARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = NoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_environment_containers_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,41 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
@@ -40,40 +47,40 @@
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments')
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+        query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
     if list_view_type is not None:
-        _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
+        query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -82,37 +89,37 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -121,37 +128,37 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -161,39 +168,39 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class EnvironmentContainersOperations(object):
     """EnvironmentContainersOperations operations.
 
@@ -234,45 +241,47 @@
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either EnvironmentContainerResourceArmPaginatedResult or
          the result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.EnvironmentContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     list_view_type=list_view_type,
@@ -289,36 +298,30 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments"}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def delete(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
@@ -328,56 +331,51 @@
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
@@ -390,60 +388,55 @@
 
         :param name: Container name. This is case-sensitive.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: EnvironmentContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('EnvironmentContainerData', pipeline_response)
+        deserialized = self._deserialize("EnvironmentContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
 
     @distributed_trace
     def create_or_update(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
@@ -459,57 +452,53 @@
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: EnvironmentContainerData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.EnvironmentContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.EnvironmentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.EnvironmentContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'EnvironmentContainerData')
+        _json = self._serialize.body(body, "EnvironmentContainerData")
 
         request = build_create_or_update_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('EnvironmentContainerData', pipeline_response)
+        deserialized = self._deserialize("EnvironmentContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/environments/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_references_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_references_operations.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,33 +1,40 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Optional, TypeVar
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Optional, TypeVar
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_get_blob_reference_sas_request(
@@ -40,40 +47,40 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/datarefs/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/datarefs/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="POST",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class DataReferencesOperations(object):
     """DataReferencesOperations operations.
 
@@ -115,58 +122,54 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body:
         :type body: ~azure.mgmt.machinelearningservices.models.BlobReferenceSASRequestDto
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: BlobReferenceSASResponseDto, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.BlobReferenceSASResponseDto
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.BlobReferenceSASResponseDto"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.BlobReferenceSASResponseDto"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'BlobReferenceSASRequestDto')
+        _json = self._serialize.body(body, "BlobReferenceSASRequestDto")
 
         request = build_get_blob_reference_sas_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.get_blob_reference_sas.metadata['url'],
+            template_url=self.get_blob_reference_sas.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('BlobReferenceSASResponseDto', pipeline_response)
+        deserialized = self._deserialize("BlobReferenceSASResponseDto", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get_blob_reference_sas.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/datarefs/{name}/versions/{version}"}  # type: ignore
-
+    get_blob_reference_sas.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/datarefs/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_containers_operations.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,15 +6,21 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import TYPE_CHECKING
 
 from msrest import Serializer
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
@@ -22,48 +28,49 @@
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
     from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-    skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    skip = kwargs.pop('skip', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
-    if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+    if skip is not None:
+        _query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
     if list_view_type is not None:
         _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
 
     # Construct headers
     _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
@@ -72,32 +79,32 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
-def build_delete_request(
-    name,  # type: str
+def build_delete_request_initial(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "name": _SERIALIZER.url("name", name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -112,31 +119,31 @@
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
-    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "name": _SERIALIZER.url("name", name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -151,32 +158,32 @@
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request_initial(
-    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -192,16 +199,16 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 # fmt: on
-class ModelContainersOperations(object):
-    """ModelContainersOperations operations.
+class RegistryDataContainersOperations(object):
+    """RegistryDataContainersOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -219,368 +226,407 @@
         self._config = config
 
     @distributed_trace
     def list(
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
-        skiptoken=None,  # type: Optional[str]
+        skip=None,  # type: Optional[str]
         list_view_type=None,  # type: Optional[Union[str, "_models.ListViewType"]]
         **kwargs  # type: Any
     ):
-        # type: (...) -> Iterable["_models.ModelContainerResourceArmPaginatedResult"]
-        """List model containers.
+        # type: (...) -> Iterable["_models.DataContainerResourceArmPaginatedResult"]
+        """List containers.
 
-        List model containers.
+        List containers.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param skiptoken: Continuation token for pagination.
-        :type skiptoken: str
+        :param skip: Continuation token for pagination.
+        :type skip: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either ModelContainerResourceArmPaginatedResult or the
+        :return: An iterator like instance of either DataContainerResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
-         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ModelContainerResourceArmPaginatedResult]
+         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.DataContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
-                    skiptoken=skiptoken,
+                    skip=skip,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
-                    skiptoken=skiptoken,
+                    skip=skip,
                     list_view_type=list_view_type,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         def extract_data(pipeline_response):
-            deserialized = self._deserialize("ModelContainerResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("DataContainerResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
+                request, stream=False, **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data"}  # type: ignore
 
-    @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def _delete_initial(  # pylint: disable=inconsistent-return-statements
         self,
-        name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
+        name,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        """Delete container.
-
-        Delete container.
-
-        :param name: Container name.
-        :type name: str
-        :param resource_group_name: The name of the resource group. The name is case insensitive.
-        :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
-        :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
-        """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        
-        request = build_delete_request(
-            name=name,
+        request = build_delete_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            name=name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self._delete_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 204]:
+        if response.status_code not in [200, 202, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
-            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
+            raise HttpResponseError(response=response, error_format=ARMErrorFormat)
+
+        response_headers = {}
+        if response.status_code == 202:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
-            return cls(pipeline_response, None, {})
+            return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
+    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
+    @distributed_trace
+    def begin_delete(  # pylint: disable=inconsistent-return-statements
+        self,
+        resource_group_name,  # type: str
+        registry_name,  # type: str
+        name,  # type: str
+        **kwargs  # type: Any
+    ):
+        # type: (...) -> LROPoller[None]
+        """Delete container.
+
+        Delete container.
+
+        :param resource_group_name: The name of the resource group. The name is case insensitive.
+        :type resource_group_name: str
+        :param registry_name: Name of Azure Machine Learning registry.
+        :type registry_name: str
+        :param name: Container name.
+        :type name: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
+        :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
+         operation to not poll, or pass in your own initialized polling object for a personal polling
+         strategy.
+        :paramtype polling: bool or ~azure.core.polling.PollingMethod
+        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
+         Retry-After header is present.
+        :return: An instance of LROPoller that returns either None or the result of cls(response)
+        :rtype: ~azure.core.polling.LROPoller[None]
+        :raises: ~azure.core.exceptions.HttpResponseError
+        """
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        if cont_token is None:
+            raw_result = self._delete_initial(
+                resource_group_name=resource_group_name,
+                registry_name=registry_name,
+                name=name,
+                api_version=api_version,
+                cls=lambda x, y, z: x,
+                **kwargs
+            )
+        kwargs.pop("error_map", None)
+
+        def get_long_running_output(pipeline_response):
+            if cls:
+                return cls(pipeline_response, None, {})
+
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
+        if cont_token:
+            return LROPoller.from_continuation_token(
+                polling_method=polling_method,
+                continuation_token=cont_token,
+                client=self._client,
+                deserialization_callback=get_long_running_output,
+            )
+        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+
+    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
+        name,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ModelContainerData"
+        # type: (...) -> "_models.DataContainer"
         """Get container.
 
         Get container.
 
-        :param name: Container name. This is case-sensitive.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param name: Container name.
+        :type name: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ModelContainerData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ModelContainerData
+        :return: DataContainer, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.DataContainer
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainer"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        
         request = build_get_request(
-            name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            name=name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ModelContainerData', pipeline_response)
+        deserialized = self._deserialize("DataContainer", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
     def _create_or_update_initial(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        body,  # type: "_models.ModelContainerData"
+        name,  # type: str
+        body,  # type: "_models.DataContainer"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ModelContainerData"
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        # type: (...) -> "_models.DataContainer"
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainer"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ModelContainerData')
+        _json = self._serialize.body(body, "DataContainer")
 
         request = build_create_or_update_request_initial(
-            name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            name=name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Azure-AsyncOperation']=self._deserialize('str', response.headers.get('Azure-AsyncOperation'))
+        if response.status_code == 200:
+            deserialized = self._deserialize("DataContainer", pipeline_response)
+
+        if response.status_code == 201:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Azure-AsyncOperation"] = self._deserialize(
+                "str", response.headers.get("Azure-AsyncOperation")
+            )
 
-        deserialized = self._deserialize('ModelContainerData', pipeline_response)
+            deserialized = self._deserialize("DataContainer", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
 
     @distributed_trace
     def begin_create_or_update(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        body,  # type: "_models.ModelContainerData"
+        name,  # type: str
+        body,  # type: "_models.DataContainer"
         **kwargs  # type: Any
     ):
-        # type: (...) -> LROPoller["_models.ModelContainerData"]
-        """Create or update model container.
+        # type: (...) -> LROPoller["_models.DataContainer"]
+        """Create or update container.
 
-        Create or update model container.
+        Create or update container.
 
-        :param name: Container name.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param name: Container name.
+        :type name: str
         :param body: Container entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ModelContainerData
+        :type body: ~azure.mgmt.machinelearningservices.models.DataContainer
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of LROPoller that returns either ModelContainerData or the result of
+        :return: An instance of LROPoller that returns either DataContainer or the result of
          cls(response)
-        :rtype:
-         ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.ModelContainerData]
+        :rtype: ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.DataContainer]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerData"]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainer"]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
-                name=name,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
+                name=name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
-            response_headers = {}
             response = pipeline_response.http_response
-            response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-            response_headers['Azure-AsyncOperation']=self._deserialize('str', response.headers.get('Azure-AsyncOperation'))
-            
-            deserialized = self._deserialize('ModelContainerData', pipeline_response)
+            deserialized = self._deserialize("DataContainer", pipeline_response)
             if cls:
-                return cls(pipeline_response, deserialized, response_headers)
+                return cls(pipeline_response, deserialized, {})
             return deserialized
 
-
-        if polling is True: polling_method = ARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = NoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
         return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_containers_operations.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,34 +1,41 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
@@ -39,38 +46,38 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes')
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+        query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -79,37 +86,37 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -118,37 +125,37 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request(
     name,  # type: str
     subscription_id,  # type: str
@@ -158,45 +165,45 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
-class ComponentContainersOperations(object):
-    """ComponentContainersOperations operations.
+class CodeContainersOperations(object):
+    """CodeContainersOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -217,100 +224,96 @@
     def list(
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
         skiptoken=None,  # type: Optional[str]
         **kwargs  # type: Any
     ):
-        # type: (...) -> Iterable["_models.ComponentContainerResourceArmPaginatedResult"]
+        # type: (...) -> Iterable["_models.CodeContainerResourceArmPaginatedResult"]
         """List containers.
 
         List containers.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param skiptoken: Continuation token for pagination.
         :type skiptoken: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either ComponentContainerResourceArmPaginatedResult or
-         the result of cls(response)
+        :return: An iterator like instance of either CodeContainerResourceArmPaginatedResult or the
+         result of cls(response)
         :rtype:
-         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ComponentContainerResourceArmPaginatedResult]
+         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.CodeContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentContainerResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skiptoken=skiptoken,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         def extract_data(pipeline_response):
-            deserialized = self._deserialize("ComponentContainerResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("CodeContainerResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes"}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def delete(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
@@ -320,188 +323,174 @@
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ComponentContainerData"
+        # type: (...) -> "_models.CodeContainerData"
         """Get container.
 
         Get container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ComponentContainerData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainerData
+        :return: CodeContainerData, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ComponentContainerData', pipeline_response)
+        deserialized = self._deserialize("CodeContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
 
     @distributed_trace
     def create_or_update(
         self,
         name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        body,  # type: "_models.ComponentContainerData"
+        body,  # type: "_models.CodeContainerData"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ComponentContainerData"
+        # type: (...) -> "_models.CodeContainerData"
         """Create or update container.
 
         Create or update container.
 
         :param name: Container name.
         :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Container entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ComponentContainerData
+        :type body: ~azure.mgmt.machinelearningservices.models.CodeContainerData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ComponentContainerData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainerData
+        :return: CodeContainerData, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainerData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentContainerData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeContainerData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ComponentContainerData')
+        _json = self._serialize.body(body, "CodeContainerData")
 
         request = build_create_or_update_request(
             name=name,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ComponentContainerData', pipeline_response)
+        deserialized = self._deserialize("CodeContainerData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{name}"}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_temporary_data_references_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_temporary_data_references_operations.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,33 +1,40 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Optional, TypeVar
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Optional, TypeVar
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_create_or_get_temporary_data_reference_request(
@@ -40,40 +47,40 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/tempdatarefs/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/tempdatarefs/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^(?![\-_.])[a-zA-Z0-9\-_.]{1,255}(?<!\.)$'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class TemporaryDataReferencesOperations(object):
     """TemporaryDataReferencesOperations operations.
 
@@ -115,58 +122,54 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body:
         :type body: ~azure.mgmt.machinelearningservices.models.TemporaryDataReferenceRequestDto
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: TemporaryDataReferenceResponseDto, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.TemporaryDataReferenceResponseDto
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.TemporaryDataReferenceResponseDto"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.TemporaryDataReferenceResponseDto"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'TemporaryDataReferenceRequestDto')
+        _json = self._serialize.body(body, "TemporaryDataReferenceRequestDto")
 
         request = build_create_or_get_temporary_data_reference_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_get_temporary_data_reference.metadata['url'],
+            template_url=self.create_or_get_temporary_data_reference.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('TemporaryDataReferenceResponseDto', pipeline_response)
+        deserialized = self._deserialize("TemporaryDataReferenceResponseDto", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_get_temporary_data_reference.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/tempdatarefs/{name}/versions/{version}"}  # type: ignore
-
+    create_or_get_temporary_data_reference.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/tempdatarefs/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_data_versions_operations.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,43 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
+import warnings
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.arm_polling import ARMPolling
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
@@ -46,47 +53,47 @@
     top = kwargs.pop('top', None)  # type: Optional[int]
     skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
     tags = kwargs.pop('tags', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if order_by is not None:
-        _query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
+        query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
     if top is not None:
-        _query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
+        query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
     if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+        query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
     if tags is not None:
-        _query_parameters['$tags'] = _SERIALIZER.query("tags", tags, 'str')
+        query_parameters['$tags'] = _SERIALIZER.query("tags", tags, 'str')
     if list_view_type is not None:
-        _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
+        query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
     name,  # type: str
     version,  # type: str
@@ -96,38 +103,38 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
     name,  # type: str
     version,  # type: str
@@ -137,38 +144,38 @@
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request_initial(
     name,  # type: str
     version,  # type: str
@@ -179,40 +186,40 @@
 ):
     # type: (...) -> HttpRequest
     api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}')
     path_format_arguments = {
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^(?![\-_.])[a-zA-Z0-9\-_.]{1,255}(?<!\.)$'),
         "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
 class DataVersionsOperations(object):
     """DataVersionsOperations operations.
 
@@ -269,49 +276,51 @@
         :type skiptoken: str
         :param tags: Comma-separated list of tag names (and optionally values). Example:
          tag1,tag2=value2.
         :type tags: str
         :param list_view_type: [ListViewType.ActiveOnly, ListViewType.ArchivedOnly,
          ListViewType.All]View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either DataVersionBaseResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.DataVersionBaseResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataVersionBaseResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skiptoken=skiptoken,
                     tags=tags,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     order_by=order_by,
@@ -332,36 +341,30 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions"}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def delete(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         **kwargs  # type: Any
     ):
@@ -374,57 +377,52 @@
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_delete_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
@@ -440,122 +438,111 @@
         :type name: str
         :param version: Version identifier.
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: DataVersionBaseData, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataVersionBaseData"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        
         request = build_get_request(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
+        deserialized = self._deserialize("DataVersionBaseData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
 
-
-    def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    def _create_or_update_initial(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.DataVersionBaseData"
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'DataVersionBaseData')
+        _json = self._serialize.body(body, "DataVersionBaseData")
 
         request = build_create_or_update_request_initial(
             name=name,
             version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
-
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
-
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
-    def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    def begin_create_or_update(
         self,
         name,  # type: str
         version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
         body,  # type: "_models.DataVersionBaseData"
         **kwargs  # type: Any
@@ -571,60 +558,63 @@
         :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
         :param body: Version entity to create or update.
         :type body: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of LROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.LROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
                 name=name,
                 version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-
-        if polling is True: polling_method = ARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = NoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
-        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_versions_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,15 +6,21 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import TYPE_CHECKING
 
 from msrest import Serializer
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
@@ -22,89 +28,90 @@
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
     from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
-    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    code_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
     order_by = kwargs.pop('order_by', None)  # type: Optional[str]
     top = kwargs.pop('top', None)  # type: Optional[int]
-    skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
+    skip = kwargs.pop('skip', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "codeName": _SERIALIZER.url("code_name", code_name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if order_by is not None:
         _query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
     if top is not None:
         _query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
-    if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+    if skip is not None:
+        _query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
 
     # Construct headers
     _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
-def build_delete_request(
-    name,  # type: str
-    version,  # type: str
+def build_delete_request_initial(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    code_name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "codeName": _SERIALIZER.url("code_name", code_name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -119,33 +126,33 @@
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
-    name,  # type: str
-    version,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    code_name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "codeName": _SERIALIZER.url("code_name", code_name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -160,34 +167,34 @@
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request_initial(
-    name,  # type: str
-    version,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    code_name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^(?![\-_.])[a-zA-Z0-9\-_.]{1,255}(?<!\.)$'),
-        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "codeName": _SERIALIZER.url("code_name", code_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -203,16 +210,16 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 # fmt: on
-class CodeVersionsOperations(object):
-    """CodeVersionsOperations operations.
+class RegistryCodeVersionsOperations(object):
+    """RegistryCodeVersionsOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -228,81 +235,80 @@
         self._serialize = serializer
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
+        code_name,  # type: str
         order_by=None,  # type: Optional[str]
         top=None,  # type: Optional[int]
-        skiptoken=None,  # type: Optional[str]
+        skip=None,  # type: Optional[str]
         **kwargs  # type: Any
     ):
         # type: (...) -> Iterable["_models.CodeVersionResourceArmPaginatedResult"]
         """List versions.
 
         List versions.
 
-        :param name: Container name.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param code_name: Container name.
+        :type code_name: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
-        :param skiptoken: Continuation token for pagination.
-        :type skiptoken: str
+        :param skip: Continuation token for pagination.
+        :type skip: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either CodeVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.CodeVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
-                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
+                    code_name=code_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
-                    skiptoken=skiptoken,
-                    template_url=self.list.metadata['url'],
+                    skip=skip,
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
-                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
+                    code_name=code_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
-                    skiptoken=skiptoken,
+                    skip=skip,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
@@ -313,298 +319,351 @@
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
+                request, stream=False, **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions"}  # type: ignore
 
-    @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def _delete_initial(  # pylint: disable=inconsistent-return-statements
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
+        code_name,  # type: str
+        version,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        """Delete version.
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        Delete version.
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        :param name: Container name.
-        :type name: str
-        :param version: Version identifier.
-        :type version: str
-        :param resource_group_name: The name of the resource group. The name is case insensitive.
-        :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
-        :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
-        """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
-        
-        request = build_delete_request(
-            name=name,
-            version=version,
+        request = build_delete_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            code_name=code_name,
+            version=version,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self._delete_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 204]:
+        if response.status_code not in [200, 202, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
-            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
+            raise HttpResponseError(response=response, error_format=ARMErrorFormat)
+
+        response_headers = {}
+        if response.status_code == 202:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
-            return cls(pipeline_response, None, {})
+            return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
+    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
+    @distributed_trace
+    def begin_delete(  # pylint: disable=inconsistent-return-statements
+        self,
+        resource_group_name,  # type: str
+        registry_name,  # type: str
+        code_name,  # type: str
+        version,  # type: str
+        **kwargs  # type: Any
+    ):
+        # type: (...) -> LROPoller[None]
+        """Delete version.
+
+        Delete version.
+
+        :param resource_group_name: The name of the resource group. The name is case insensitive.
+        :type resource_group_name: str
+        :param registry_name: Name of Azure Machine Learning registry.
+        :type registry_name: str
+        :param code_name: Container name.
+        :type code_name: str
+        :param version: Version identifier.
+        :type version: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
+        :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
+         operation to not poll, or pass in your own initialized polling object for a personal polling
+         strategy.
+        :paramtype polling: bool or ~azure.core.polling.PollingMethod
+        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
+         Retry-After header is present.
+        :return: An instance of LROPoller that returns either None or the result of cls(response)
+        :rtype: ~azure.core.polling.LROPoller[None]
+        :raises: ~azure.core.exceptions.HttpResponseError
+        """
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        if cont_token is None:
+            raw_result = self._delete_initial(
+                resource_group_name=resource_group_name,
+                registry_name=registry_name,
+                code_name=code_name,
+                version=version,
+                api_version=api_version,
+                cls=lambda x, y, z: x,
+                **kwargs
+            )
+        kwargs.pop("error_map", None)
+
+        def get_long_running_output(pipeline_response):
+            if cls:
+                return cls(pipeline_response, None, {})
+
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
+        if cont_token:
+            return LROPoller.from_continuation_token(
+                polling_method=polling_method,
+                continuation_token=cont_token,
+                client=self._client,
+                deserialization_callback=get_long_running_output,
+            )
+        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+
+    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
+        code_name,  # type: str
+        version,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.CodeVersionData"
+        # type: (...) -> "_models.CodeVersion"
         """Get version.
 
         Get version.
 
-        :param name: Container name.
-        :type name: str
-        :param version: Version identifier.
-        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param code_name: Container name.
+        :type code_name: str
+        :param version: Version identifier.
+        :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: CodeVersionData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersionData
+        :return: CodeVersion, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersion
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        
         request = build_get_request(
-            name=name,
-            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            code_name=code_name,
+            version=version,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('CodeVersionData', pipeline_response)
+        deserialized = self._deserialize("CodeVersion", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
-    def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    def _create_or_update_initial(
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        body,  # type: "_models.CodeVersionData"
+        code_name,  # type: str
+        version,  # type: str
+        body,  # type: "_models.CodeVersion"
         **kwargs  # type: Any
     ):
-        # type: (...) -> None
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        # type: (...) -> "_models.CodeVersion"
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'CodeVersionData')
+        _json = self._serialize.body(body, "CodeVersion")
 
         request = build_create_or_update_request_initial(
-            name=name,
-            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            code_name=code_name,
+            version=version,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
+        if response.status_code == 200:
+            deserialized = self._deserialize("CodeVersion", pipeline_response)
+
+        if response.status_code == 201:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Azure-AsyncOperation"] = self._deserialize(
+                "str", response.headers.get("Azure-AsyncOperation")
+            )
 
+            deserialized = self._deserialize("CodeVersion", pipeline_response)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
+        return deserialized
 
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
     @distributed_trace
-    def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    def begin_create_or_update(
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        body,  # type: "_models.CodeVersionData"
+        code_name,  # type: str
+        version,  # type: str
+        body,  # type: "_models.CodeVersion"
         **kwargs  # type: Any
     ):
-        # type: (...) -> LROPoller[None]
+        # type: (...) -> LROPoller["_models.CodeVersion"]
         """Create or update version.
 
         Create or update version.
 
-        :param name: Container name.
-        :type name: str
-        :param version: Version identifier.
-        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param code_name: Container name.
+        :type code_name: str
+        :param version: Version identifier.
+        :type version: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersionData
+        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersion
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of LROPoller that returns either None or the result of cls(response)
-        :rtype: ~azure.core.polling.LROPoller[None]
+        :return: An instance of LROPoller that returns either CodeVersion or the result of
+         cls(response)
+        :rtype: ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.CodeVersion]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
-                name=name,
-                version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
+                code_name=code_name,
+                version=version,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
+            response = pipeline_response.http_response
+            deserialized = self._deserialize("CodeVersion", pipeline_response)
             if cls:
-                return cls(pipeline_response, None, {})
-
+                return cls(pipeline_response, deserialized, {})
+            return deserialized
 
-        if polling is True: polling_method = ARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = NoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
         return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_versions_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,15 +6,21 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import TYPE_CHECKING
 
 from msrest import Serializer
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
@@ -22,56 +28,57 @@
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
     from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
-    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    model_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-    skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    skip = kwargs.pop('skip', None)  # type: Optional[str]
     order_by = kwargs.pop('order_by', None)  # type: Optional[str]
     top = kwargs.pop('top', None)  # type: Optional[int]
     version = kwargs.pop('version', None)  # type: Optional[str]
     description = kwargs.pop('description', None)  # type: Optional[str]
     tags = kwargs.pop('tags', None)  # type: Optional[str]
     properties = kwargs.pop('properties', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "modelName": _SERIALIZER.url("model_name", model_name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
-    if skiptoken is not None:
-        _query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
+    if skip is not None:
+        _query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
     if order_by is not None:
         _query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
     if top is not None:
         _query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
     if version is not None:
         _query_parameters['version'] = _SERIALIZER.query("version", version, 'str')
     if description is not None:
@@ -92,34 +99,34 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
-def build_delete_request(
-    name,  # type: str
-    version,  # type: str
+def build_delete_request_initial(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    model_name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "modelName": _SERIALIZER.url("model_name", model_name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -134,33 +141,33 @@
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
-    name,  # type: str
-    version,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    model_name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "modelName": _SERIALIZER.url("model_name", model_name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -175,34 +182,34 @@
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request_initial(
-    name,  # type: str
-    version,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
+    model_name,  # type: str
+    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
-        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^(?![\-_.])[a-zA-Z0-9\-_.]{1,255}(?<!\.)$'),
-        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "modelName": _SERIALIZER.url("model_name", model_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
+        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -218,16 +225,16 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 # fmt: on
-class ModelVersionsOperations(object):
-    """ModelVersionsOperations operations.
+class RegistryModelVersionsOperations(object):
+    """RegistryModelVersionsOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -243,40 +250,40 @@
         self._serialize = serializer
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
         self,
-        name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        skiptoken=None,  # type: Optional[str]
+        model_name,  # type: str
+        skip=None,  # type: Optional[str]
         order_by=None,  # type: Optional[str]
         top=None,  # type: Optional[int]
         version=None,  # type: Optional[str]
         description=None,  # type: Optional[str]
         tags=None,  # type: Optional[str]
         properties=None,  # type: Optional[str]
         list_view_type=None,  # type: Optional[Union[str, "_models.ListViewType"]]
         **kwargs  # type: Any
     ):
         # type: (...) -> Iterable["_models.ModelVersionResourceArmPaginatedResult"]
         """List versions.
 
         List versions.
 
-        :param name: Container name. This is case-sensitive.
-        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param skiptoken: Continuation token for pagination.
-        :type skiptoken: str
+        :param model_name: Container name. This is case-sensitive.
+        :type model_name: str
+        :param skip: Continuation token for pagination.
+        :type skip: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
         :param version: Version identifier.
         :type version: str
         :param description: Model description.
@@ -292,52 +299,51 @@
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either ModelVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ModelVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersionResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelVersionResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
-                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
+                    model_name=model_name,
                     api_version=api_version,
-                    skiptoken=skiptoken,
+                    skip=skip,
                     order_by=order_by,
                     top=top,
                     version=version,
                     description=description,
                     tags=tags,
                     properties=properties,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
-                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
+                    model_name=model_name,
                     api_version=api_version,
-                    skiptoken=skiptoken,
+                    skip=skip,
                     order_by=order_by,
                     top=top,
                     version=version,
                     description=description,
                     tags=tags,
                     properties=properties,
                     list_view_type=list_view_type,
@@ -355,298 +361,351 @@
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request,
-                stream=False,
-                **kwargs
+                request, stream=False, **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions"}  # type: ignore
 
-    @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def _delete_initial(  # pylint: disable=inconsistent-return-statements
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
+        model_name,  # type: str
+        version,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        """Delete version.
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        Delete version.
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        :param name: Container name.
-        :type name: str
-        :param version: Version identifier.
-        :type version: str
-        :param resource_group_name: The name of the resource group. The name is case insensitive.
-        :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
-        :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
-        """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-
-        
-        request = build_delete_request(
-            name=name,
-            version=version,
+        request = build_delete_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            model_name=model_name,
+            version=version,
             api_version=api_version,
-            template_url=self.delete.metadata['url'],
+            template_url=self._delete_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 204]:
+        if response.status_code not in [200, 202, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
-            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
+            raise HttpResponseError(response=response, error_format=ARMErrorFormat)
+
+        response_headers = {}
+        if response.status_code == 202:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
-            return cls(pipeline_response, None, {})
+            return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
+    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
+    @distributed_trace
+    def begin_delete(  # pylint: disable=inconsistent-return-statements
+        self,
+        resource_group_name,  # type: str
+        registry_name,  # type: str
+        model_name,  # type: str
+        version,  # type: str
+        **kwargs  # type: Any
+    ):
+        # type: (...) -> LROPoller[None]
+        """Delete version.
+
+        Delete version.
+
+        :param resource_group_name: The name of the resource group. The name is case insensitive.
+        :type resource_group_name: str
+        :param registry_name: Name of Azure Machine Learning registry.
+        :type registry_name: str
+        :param model_name: Container name.
+        :type model_name: str
+        :param version: Version identifier.
+        :type version: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
+        :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
+         operation to not poll, or pass in your own initialized polling object for a personal polling
+         strategy.
+        :paramtype polling: bool or ~azure.core.polling.PollingMethod
+        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
+         Retry-After header is present.
+        :return: An instance of LROPoller that returns either None or the result of cls(response)
+        :rtype: ~azure.core.polling.LROPoller[None]
+        :raises: ~azure.core.exceptions.HttpResponseError
+        """
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        if cont_token is None:
+            raw_result = self._delete_initial(
+                resource_group_name=resource_group_name,
+                registry_name=registry_name,
+                model_name=model_name,
+                version=version,
+                api_version=api_version,
+                cls=lambda x, y, z: x,
+                **kwargs
+            )
+        kwargs.pop("error_map", None)
+
+        def get_long_running_output(pipeline_response):
+            if cls:
+                return cls(pipeline_response, None, {})
+
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
+        if cont_token:
+            return LROPoller.from_continuation_token(
+                polling_method=polling_method,
+                continuation_token=cont_token,
+                client=self._client,
+                deserialization_callback=get_long_running_output,
+            )
+        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+
+    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
+        model_name,  # type: str
+        version,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ModelVersionData"
+        # type: (...) -> "_models.ModelVersion"
         """Get version.
 
         Get version.
 
-        :param name: Container name. This is case-sensitive.
-        :type name: str
-        :param version: Version identifier. This is case-sensitive.
-        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param model_name: Container name. This is case-sensitive.
+        :type model_name: str
+        :param version: Version identifier. This is case-sensitive.
+        :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ModelVersionData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ModelVersionData
+        :return: ModelVersion, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ModelVersion
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelVersionData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        
         request = build_get_request(
-            name=name,
-            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            model_name=model_name,
+            version=version,
             api_version=api_version,
-            template_url=self.get.metadata['url'],
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('ModelVersionData', pipeline_response)
+        deserialized = self._deserialize("ModelVersion", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
-    def _create_or_update_initial(  # pylint: disable=inconsistent-return-statements
+    def _create_or_update_initial(
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        body,  # type: "_models.ModelVersionData"
+        model_name,  # type: str
+        version,  # type: str
+        body,  # type: "_models.ModelVersion"
         **kwargs  # type: Any
     ):
-        # type: (...) -> None
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        # type: (...) -> "_models.ModelVersion"
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'ModelVersionData')
+        _json = self._serialize.body(body, "ModelVersion")
 
         request = build_create_or_update_request_initial(
-            name=name,
-            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
+            model_name=model_name,
+            version=version,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata['url'],
+            template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+            request, stream=False, **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
-        response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
-        response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
+        if response.status_code == 200:
+            deserialized = self._deserialize("ModelVersion", pipeline_response)
+
+        if response.status_code == 201:
+            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+                "duration", response.headers.get("x-ms-async-operation-timeout")
+            )
+            response_headers["Azure-AsyncOperation"] = self._deserialize(
+                "str", response.headers.get("Azure-AsyncOperation")
+            )
 
+            deserialized = self._deserialize("ModelVersion", pipeline_response)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
+        return deserialized
 
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
     @distributed_trace
-    def begin_create_or_update(  # pylint: disable=inconsistent-return-statements
+    def begin_create_or_update(
         self,
-        name,  # type: str
-        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        body,  # type: "_models.ModelVersionData"
+        model_name,  # type: str
+        version,  # type: str
+        body,  # type: "_models.ModelVersion"
         **kwargs  # type: Any
     ):
-        # type: (...) -> LROPoller[None]
+        # type: (...) -> LROPoller["_models.ModelVersion"]
         """Create or update version.
 
         Create or update version.
 
-        :param name: Container name.
-        :type name: str
-        :param version: Version identifier.
-        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
+        :param model_name: Container name.
+        :type model_name: str
+        :param version: Version identifier.
+        :type version: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ModelVersionData
+        :type body: ~azure.mgmt.machinelearningservices.models.ModelVersion
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of LROPoller that returns either None or the result of cls(response)
-        :rtype: ~azure.core.polling.LROPoller[None]
+        :return: An instance of LROPoller that returns either ModelVersion or the result of
+         cls(response)
+        :rtype: ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.ModelVersion]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
-        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        lro_delay = kwargs.pop(
-            'polling_interval',
-            self._config.polling_interval
-        )
-        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
+        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
-                name=name,
-                version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
+                model_name=model_name,
+                version=version,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x,y,z: x,
+                cls=lambda x, y, z: x,
                 **kwargs
             )
-        kwargs.pop('error_map', None)
+        kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
+            response = pipeline_response.http_response
+            deserialized = self._deserialize("ModelVersion", pipeline_response)
             if cls:
-                return cls(pipeline_response, None, {})
-
+                return cls(pipeline_response, deserialized, {})
+            return deserialized
 
-        if polling is True: polling_method = ARMPolling(lro_delay, **kwargs)
-        elif polling is False: polling_method = NoPolling()
-        else: polling_method = polling
+        if polling is True:
+            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
+        elif polling is False:
+            polling_method = NoPolling()
+        else:
+            polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output
+                deserialization_callback=get_long_running_output,
             )
         return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{name}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_registry_management_non_workspace_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_registry_management_non_workspace_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_async_operations_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/aio/operations/_async_operations_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/_registry_management_non_workspace_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/_registry_management_non_workspace_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/registry_discovery/operations/_async_operations_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/registry_discovery/operations/_async_operations_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_experiments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_experiments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_spans_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_spans_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_artifacts_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_artifacts_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_delete_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_delete_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_metric_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_metric_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_events_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_events_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_run_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/aio/operations/_runs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/aio/operations/_runs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 16% similar despite different names*

```diff
@@ -3,79 +3,106 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class DatasetConsumptionType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class BatchLoggingLevel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """Log verbosity for batch inferencing.
+    Increasing verbosity order for logging is : Warning, Info and Debug.
+    The default value is Info.
+    """
 
-    RUN_INPUT = "RunInput"
-    REFERENCE = "Reference"
+    INFO = "Info"
+    WARNING = "Warning"
+    DEBUG = "Debug"
 
-class DatasetDeliveryMechanism(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class CreatedByType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """The type of identity that created the resource.
+    """
 
-    DIRECT = "Direct"
-    MOUNT = "Mount"
+    USER = "User"
+    APPLICATION = "Application"
+    MANAGED_IDENTITY = "ManagedIdentity"
+    KEY = "Key"
+
+class DatasetType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+
+    SIMPLE = "Simple"
+    DATAFLOW = "Dataflow"
+
+class InferenceDataInputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+
+    DATASET_VERSION = "DatasetVersion"
+    DATASET_ID = "DatasetId"
+    DATA_URL = "DataUrl"
+
+class InputDeliveryMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """Enum to determine the input data delivery mode.
+    """
+
+    READ_ONLY_MOUNT = "ReadOnlyMount"
+    READ_WRITE_MOUNT = "ReadWriteMount"
     DOWNLOAD = "Download"
-    HDFS = "Hdfs"
+    DIRECT = "Direct"
+    EVAL_MOUNT = "EvalMount"
+    EVAL_DOWNLOAD = "EvalDownload"
 
-class DatasetOutputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobInputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """Enum to determine the Job Input Type.
+    """
 
-    RUN_OUTPUT = "RunOutput"
-    REFERENCE = "Reference"
+    URI_FILE = "UriFile"
+    URI_FOLDER = "UriFolder"
+    ML_TABLE = "MLTable"
+    LITERAL = "Literal"
+    CUSTOM_MODEL = "CustomModel"
+    ML_FLOW_MODEL = "MLFlowModel"
+    TRITON_MODEL = "TritonModel"
 
-class ExperimentViewType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """ViewType filters experiments by their archived state. Default is ActiveOnly
+class JobOutputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """Enum to determine the Job Output Type.
     """
 
-    DEFAULT = "Default"
-    ALL = "All"
-    ACTIVE_ONLY = "ActiveOnly"
-    ARCHIVED_ONLY = "ArchivedOnly"
+    URI_FILE = "UriFile"
+    URI_FOLDER = "UriFolder"
+    ML_TABLE = "MLTable"
+    CUSTOM_MODEL = "CustomModel"
+    ML_FLOW_MODEL = "MLFlowModel"
+    TRITON_MODEL = "TritonModel"
 
-class MetricValueType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
-    INT = "Int"
-    DOUBLE = "Double"
-    STRING = "String"
-    BOOL = "Bool"
-    ARTIFACT = "Artifact"
+    SUCCEEDED = "Succeeded"
+    FAILED = "Failed"
+    CANCELED = "Canceled"
+    IN_PROGRESS = "InProgress"
 
-class RunStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Gets span status.
-    OpenTelemetry sets it to
-    https://github.com/open-telemetry/opentelemetry-dotnet/blob/master/src/OpenTelemetry.Api/Trace/Status.cs
-    That status enums are not very meaningful to us, so we customize this.
+class JobStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """The status of a job.
     """
 
     NOT_STARTED = "NotStarted"
-    UNAPPROVED = "Unapproved"
-    PAUSING = "Pausing"
-    PAUSED = "Paused"
     STARTING = "Starting"
+    PROVISIONING = "Provisioning"
     PREPARING = "Preparing"
     QUEUED = "Queued"
     RUNNING = "Running"
     FINALIZING = "Finalizing"
     CANCEL_REQUESTED = "CancelRequested"
     COMPLETED = "Completed"
     FAILED = "Failed"
     CANCELED = "Canceled"
+    NOT_RESPONDING = "NotResponding"
+    PAUSED = "Paused"
+    UNKNOWN = "Unknown"
 
-class SortOrderDirection(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-
-    ASC = "Asc"
-    DESC = "Desc"
-
-class StoredProcedureParameterType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OutputDeliveryMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """Output data delivery mode enums.
+    """
 
-    STRING = "String"
-    INT = "Int"
-    DECIMAL = "Decimal"
-    GUID = "Guid"
-    BOOLEAN = "Boolean"
-    DATE = "Date"
+    READ_WRITE_MOUNT = "ReadWriteMount"
+    UPLOAD = "Upload"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_experiments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_experiments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_spans_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_spans_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_run_artifacts_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_run_artifacts_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_delete_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_delete_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_metric_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_metric_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_events_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_events_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_run_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_run_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/runhistory/operations/_runs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/operations/_runs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01_preview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_provisions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_provisions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_settings_rule_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_managed_network_settings_rule_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/aio/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_provisions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_provisions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_settings_rule_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_managed_network_settings_rule_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_12_01_preview/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_controller_v2_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_controller_v2_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_v2_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_dataset_v2_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_delete_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_delete_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_datasets_v1_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_datasets_v1_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_call_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_call_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_container_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_container_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_version_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_data_version_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_get_operation_status_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/aio/operations/_get_operation_status_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,38 +3,37 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class DataflowType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DataflowType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     JSON = "Json"
     YAML = "Yaml"
 
-class FieldType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class FieldType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     STRING = "String"
     BOOLEAN = "Boolean"
     INTEGER = "Integer"
     DECIMAL = "Decimal"
     DATE = "Date"
     UNKNOWN = "Unknown"
     ERROR = "Error"
     NULL = "Null"
     DATA_ROW = "DataRow"
     LIST = "List"
     STREAM = "Stream"
 
-class HttpStatusCode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class HttpStatusCode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     CONTINUE_ENUM = "Continue"
     SWITCHING_PROTOCOLS = "SwitchingProtocols"
     PROCESSING = "Processing"
     EARLY_HINTS = "EarlyHints"
     OK = "OK"
     CREATED = "Created"
@@ -90,30 +89,30 @@
     HTTP_VERSION_NOT_SUPPORTED = "HttpVersionNotSupported"
     VARIANT_ALSO_NEGOTIATES = "VariantAlsoNegotiates"
     INSUFFICIENT_STORAGE = "InsufficientStorage"
     LOOP_DETECTED = "LoopDetected"
     NOT_EXTENDED = "NotExtended"
     NETWORK_AUTHENTICATION_REQUIRED = "NetworkAuthenticationRequired"
 
-class HttpVersionPolicy(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class HttpVersionPolicy(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     REQUEST_VERSION_OR_LOWER = "RequestVersionOrLower"
     REQUEST_VERSION_OR_HIGHER = "RequestVersionOrHigher"
     REQUEST_VERSION_EXACT = "RequestVersionExact"
 
-class StoredProcedureParameterType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class StoredProcedureParameterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     STRING = "String"
     INT = "Int"
     DECIMAL = "Decimal"
     GUID = "Guid"
     BOOLEAN = "Boolean"
     DATE = "Date"
 
-class SType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     EMAIL_ADDRESS = "EmailAddress"
     GEOGRAPHIC_COORDINATE = "GeographicCoordinate"
     IPV4_ADDRESS = "Ipv4Address"
     IPV6_ADDRESS = "Ipv6Address"
     US_PHONE_NUMBER = "UsPhoneNumber"
     ZIP_CODE = "ZipCode"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_controller_v2_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_controller_v2_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_v2_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_dataset_v2_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_delete_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_delete_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_datasets_v1_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_datasets_v1_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_call_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_call_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_container_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_container_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_version_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_data_version_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_get_operation_status_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/dataset_dataplane/operations/_get_operation_status_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/_azure_machine_learning_workspaces.py`

 * *Files 14% similar despite different names*

```diff
@@ -10,32 +10,41 @@
 from typing import TYPE_CHECKING
 
 from azure.mgmt.core import ARMPipelineClient
 from msrest import Deserializer, Serializer
 
 from . import models
 from ._configuration import AzureMachineLearningWorkspacesConfiguration
-from .operations import BatchDeploymentsOperations, BatchEndpointsOperations, CodeContainersOperations, CodeVersionsOperations, ComponentContainersOperations, ComponentVersionsOperations, DataContainersOperations, DataVersionsOperations, DatastoresOperations, EnvironmentContainersOperations, EnvironmentVersionsOperations, JobsOperations, ModelContainersOperations, ModelVersionsOperations, OnlineDeploymentsOperations, OnlineEndpointsOperations
+from .operations import (
+    CodeContainersOperations,
+    CodeVersionsOperations,
+    ComponentContainersOperations,
+    ComponentVersionsOperations,
+    DataContainersOperations,
+    DataReferencesOperations,
+    DataVersionsOperations,
+    EnvironmentContainersOperations,
+    EnvironmentVersionsOperations,
+    ModelContainersOperations,
+    ModelVersionsOperations,
+    ResourceManagementAssetReferenceOperations,
+    TemporaryDataReferencesOperations,
+)
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
     from typing import Any, Optional
 
     from azure.core.credentials import TokenCredential
     from azure.core.rest import HttpRequest, HttpResponse
 
+
 class AzureMachineLearningWorkspaces(object):
     """AzureMachineLearningWorkspaces.
 
-    :ivar batch_endpoints: BatchEndpointsOperations operations
-    :vartype batch_endpoints:
-     azure.mgmt.machinelearningservices.operations.BatchEndpointsOperations
-    :ivar batch_deployments: BatchDeploymentsOperations operations
-    :vartype batch_deployments:
-     azure.mgmt.machinelearningservices.operations.BatchDeploymentsOperations
     :ivar code_containers: CodeContainersOperations operations
     :vartype code_containers:
      azure.mgmt.machinelearningservices.operations.CodeContainersOperations
     :ivar code_versions: CodeVersionsOperations operations
     :vartype code_versions: azure.mgmt.machinelearningservices.operations.CodeVersionsOperations
     :ivar component_containers: ComponentContainersOperations operations
     :vartype component_containers:
@@ -44,77 +53,92 @@
     :vartype component_versions:
      azure.mgmt.machinelearningservices.operations.ComponentVersionsOperations
     :ivar data_containers: DataContainersOperations operations
     :vartype data_containers:
      azure.mgmt.machinelearningservices.operations.DataContainersOperations
     :ivar data_versions: DataVersionsOperations operations
     :vartype data_versions: azure.mgmt.machinelearningservices.operations.DataVersionsOperations
-    :ivar datastores: DatastoresOperations operations
-    :vartype datastores: azure.mgmt.machinelearningservices.operations.DatastoresOperations
+    :ivar data_references: DataReferencesOperations operations
+    :vartype data_references:
+     azure.mgmt.machinelearningservices.operations.DataReferencesOperations
     :ivar environment_containers: EnvironmentContainersOperations operations
     :vartype environment_containers:
      azure.mgmt.machinelearningservices.operations.EnvironmentContainersOperations
     :ivar environment_versions: EnvironmentVersionsOperations operations
     :vartype environment_versions:
      azure.mgmt.machinelearningservices.operations.EnvironmentVersionsOperations
-    :ivar jobs: JobsOperations operations
-    :vartype jobs: azure.mgmt.machinelearningservices.operations.JobsOperations
+    :ivar resource_management_asset_reference: ResourceManagementAssetReferenceOperations
+     operations
+    :vartype resource_management_asset_reference:
+     azure.mgmt.machinelearningservices.operations.ResourceManagementAssetReferenceOperations
     :ivar model_containers: ModelContainersOperations operations
     :vartype model_containers:
      azure.mgmt.machinelearningservices.operations.ModelContainersOperations
     :ivar model_versions: ModelVersionsOperations operations
     :vartype model_versions: azure.mgmt.machinelearningservices.operations.ModelVersionsOperations
-    :ivar online_endpoints: OnlineEndpointsOperations operations
-    :vartype online_endpoints:
-     azure.mgmt.machinelearningservices.operations.OnlineEndpointsOperations
-    :ivar online_deployments: OnlineDeploymentsOperations operations
-    :vartype online_deployments:
-     azure.mgmt.machinelearningservices.operations.OnlineDeploymentsOperations
+    :ivar temporary_data_references: TemporaryDataReferencesOperations operations
+    :vartype temporary_data_references:
+     azure.mgmt.machinelearningservices.operations.TemporaryDataReferencesOperations
     :param credential: Credential needed for the client to connect to Azure.
     :type credential: ~azure.core.credentials.TokenCredential
     :param subscription_id: The ID of the target subscription.
     :type subscription_id: str
     :param base_url: Service URL. Default value is 'https://management.azure.com'.
     :type base_url: str
+    :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+     that overriding this default value may result in unsupported behavior.
+    :paramtype api_version: str
     :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
      Retry-After header is present.
     """
 
     def __init__(
         self,
         credential,  # type: "TokenCredential"
         subscription_id,  # type: str
         base_url="https://management.azure.com",  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        self._config = AzureMachineLearningWorkspacesConfiguration(credential=credential, subscription_id=subscription_id, **kwargs)
+        self._config = AzureMachineLearningWorkspacesConfiguration(
+            credential=credential, subscription_id=subscription_id, **kwargs
+        )
         self._client = ARMPipelineClient(base_url=base_url, config=self._config, **kwargs)
 
         client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
         self._serialize = Serializer(client_models)
         self._deserialize = Deserializer(client_models)
         self._serialize.client_side_validation = False
-        self.batch_endpoints = BatchEndpointsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.batch_deployments = BatchDeploymentsOperations(self._client, self._config, self._serialize, self._deserialize)
         self.code_containers = CodeContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.code_versions = CodeVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.component_containers = ComponentContainersOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.component_versions = ComponentVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.component_containers = ComponentContainersOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.component_versions = ComponentVersionsOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
         self.data_containers = DataContainersOperations(self._client, self._config, self._serialize, self._deserialize)
         self.data_versions = DataVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.datastores = DatastoresOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.environment_containers = EnvironmentContainersOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.environment_versions = EnvironmentVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.jobs = JobsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.model_containers = ModelContainersOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.data_references = DataReferencesOperations(self._client, self._config, self._serialize, self._deserialize)
+        self.environment_containers = EnvironmentContainersOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.environment_versions = EnvironmentVersionsOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.resource_management_asset_reference = ResourceManagementAssetReferenceOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
+        self.model_containers = ModelContainersOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
         self.model_versions = ModelVersionsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.online_endpoints = OnlineEndpointsOperations(self._client, self._config, self._serialize, self._deserialize)
-        self.online_deployments = OnlineDeploymentsOperations(self._client, self._config, self._serialize, self._deserialize)
-
+        self.temporary_data_references = TemporaryDataReferencesOperations(
+            self._client, self._config, self._serialize, self._deserialize
+        )
 
     def _send_request(
         self,
         request,  # type: HttpRequest
         **kwargs  # type: Any
     ):
         # type: (...) -> HttpResponse
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 17% similar despite different names*

```diff
@@ -3,36 +3,35 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class BatchLoggingLevel(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class BatchLoggingLevel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Log verbosity for batch inferencing.
     Increasing verbosity order for logging is : Warning, Info and Debug.
     The default value is Info.
     """
 
     INFO = "Info"
     WARNING = "Warning"
     DEBUG = "Debug"
 
-class BatchOutputAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class BatchOutputAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine how batch inferencing will handle output
     """
 
     SUMMARY_ONLY = "SummaryOnly"
     APPEND_ROW = "AppendRow"
 
-class ClassificationModels(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ClassificationModels(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum for all classification models supported by AutoML.
     """
 
     #: Logistic regression is a fundamental classification technique.
     #: It belongs to the group of linear classifiers and is somewhat similar to polynomial and linear
     #: regression.
     #: Logistic regression is fast and relatively uncomplicated, and it's convenient for you to
@@ -88,15 +87,15 @@
     #: The technique of transiting week learners into a strong learner is called Boosting. The
     #: gradient boosting algorithm process works on this theory of execution.
     GRADIENT_BOOSTING = "GradientBoosting"
     #: XGBoost: Extreme Gradient Boosting Algorithm. This algorithm is used for structured data where
     #: target column values can be divided into distinct class values.
     XG_BOOST_CLASSIFIER = "XGBoostClassifier"
 
-class ClassificationMultilabelPrimaryMetrics(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ClassificationMultilabelPrimaryMetrics(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Primary metrics for classification multilabel tasks.
     """
 
     #: AUC is the Area under the curve.
     #: This metric represents arithmetic mean of the score for each class,
     #: weighted by the number of true instances in each class.
     AUC_WEIGHTED = "AUCWeighted"
@@ -110,15 +109,15 @@
     AVERAGE_PRECISION_SCORE_WEIGHTED = "AveragePrecisionScoreWeighted"
     #: The arithmetic mean of precision for each class, weighted by number of true instances in each
     #: class.
     PRECISION_SCORE_WEIGHTED = "PrecisionScoreWeighted"
     #: Intersection Over Union. Intersection of predictions divided by union of predictions.
     IOU = "IOU"
 
-class ClassificationPrimaryMetrics(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ClassificationPrimaryMetrics(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Primary metrics for classification tasks.
     """
 
     #: AUC is the Area under the curve.
     #: This metric represents arithmetic mean of the score for each class,
     #: weighted by the number of true instances in each class.
     AUC_WEIGHTED = "AUCWeighted"
@@ -130,156 +129,156 @@
     #: The arithmetic mean of the average precision score for each class, weighted by
     #: the number of true instances in each class.
     AVERAGE_PRECISION_SCORE_WEIGHTED = "AveragePrecisionScoreWeighted"
     #: The arithmetic mean of precision for each class, weighted by number of true instances in each
     #: class.
     PRECISION_SCORE_WEIGHTED = "PrecisionScoreWeighted"
 
-class ContainerType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ContainerType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     STORAGE_INITIALIZER = "StorageInitializer"
     INFERENCE_SERVER = "InferenceServer"
 
-class CreatedByType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class CreatedByType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of identity that created the resource.
     """
 
     USER = "User"
     APPLICATION = "Application"
     MANAGED_IDENTITY = "ManagedIdentity"
     KEY = "Key"
 
-class CredentialsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class CredentialsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the datastore credentials type.
     """
 
     ACCOUNT_KEY = "AccountKey"
     CERTIFICATE = "Certificate"
     NONE = "None"
     SAS = "Sas"
     SERVICE_PRINCIPAL = "ServicePrincipal"
     KERBEROS_KEYTAB = "KerberosKeytab"
     KERBEROS_PASSWORD = "KerberosPassword"
 
-class DatastoreType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DatastoreType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the datastore contents type.
     """
 
     AZURE_BLOB = "AzureBlob"
     AZURE_DATA_LAKE_GEN1 = "AzureDataLakeGen1"
     AZURE_DATA_LAKE_GEN2 = "AzureDataLakeGen2"
     AZURE_FILE = "AzureFile"
     HDFS = "Hdfs"
 
-class DataType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DataType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the type of data.
     """
 
     URI_FILE = "UriFile"
     URI_FOLDER = "UriFolder"
     ML_TABLE = "MLTable"
 
-class DeploymentProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DeploymentProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Possible values for DeploymentProvisioningState.
     """
 
     CREATING = "Creating"
     DELETING = "Deleting"
     SCALING = "Scaling"
     UPDATING = "Updating"
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
     CANCELED = "Canceled"
 
-class DistributionType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DistributionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the job distribution type.
     """
 
     PY_TORCH = "PyTorch"
     TENSOR_FLOW = "TensorFlow"
     MPI = "Mpi"
 
-class EarlyTerminationPolicyType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EarlyTerminationPolicyType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     BANDIT = "Bandit"
     MEDIAN_STOPPING = "MedianStopping"
     TRUNCATION_SELECTION = "TruncationSelection"
 
-class EgressPublicNetworkAccessType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EgressPublicNetworkAccessType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine whether PublicNetworkAccess is Enabled or Disabled for egress of a
     deployment.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class EndpointAuthMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EndpointAuthMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine endpoint authentication mode.
     """
 
     AML_TOKEN = "AMLToken"
     KEY = "Key"
     AAD_TOKEN = "AADToken"
 
-class EndpointComputeType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EndpointComputeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine endpoint compute type.
     """
 
     MANAGED = "Managed"
     KUBERNETES = "Kubernetes"
     AZURE_ML_COMPUTE = "AzureMLCompute"
 
-class EndpointProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EndpointProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of endpoint provisioning.
     """
 
     CREATING = "Creating"
     DELETING = "Deleting"
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
     UPDATING = "Updating"
     CANCELED = "Canceled"
 
-class EnvironmentType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EnvironmentType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Environment type is either user created or curated by Azure ML service
     """
 
     CURATED = "Curated"
     USER_CREATED = "UserCreated"
 
-class FeatureLags(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class FeatureLags(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Flag for generating lags for the numeric features.
     """
 
     #: No feature lags generated.
     NONE = "None"
     #: System auto-generates feature lags.
     AUTO = "Auto"
 
-class FeaturizationMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class FeaturizationMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Featurization mode - determines data featurization mode.
     """
 
     #: Auto mode, system performs featurization without any custom featurization inputs.
     AUTO = "Auto"
     #: Custom featurization.
     CUSTOM = "Custom"
     #: Featurization off. 'Forecasting' task cannot use this value.
     OFF = "Off"
 
-class ForecastHorizonMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ForecastHorizonMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine forecast horizon selection mode.
     """
 
     #: Forecast horizon to be determined automatically.
     AUTO = "Auto"
     #: Use the custom forecast horizon.
     CUSTOM = "Custom"
 
-class ForecastingModels(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ForecastingModels(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum for all forecasting models supported by AutoML.
     """
 
     #: Auto-Autoregressive Integrated Moving Average (ARIMA) model uses time-series data and
     #: statistical analysis to interpret the data and make future predictions.
     #: This model aims to explain data by using time series data on its past values and uses linear
     #: regression to make predictions.
@@ -350,15 +349,15 @@
     EXTREME_RANDOM_TREES = "ExtremeRandomTrees"
     #: LightGBM is a gradient boosting framework that uses tree based learning algorithms.
     LIGHT_GBM = "LightGBM"
     #: XGBoostRegressor: Extreme Gradient Boosting Regressor is a supervised machine learning model
     #: using ensemble of base learners.
     XG_BOOST_REGRESSOR = "XGBoostRegressor"
 
-class ForecastingPrimaryMetrics(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ForecastingPrimaryMetrics(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Primary metrics for Forecasting task.
     """
 
     #: The Spearman's rank coefficient of correlation is a non-parametric measure of rank correlation.
     SPEARMAN_CORRELATION = "SpearmanCorrelation"
     #: The Normalized Root Mean Squared Error (NRMSE) the RMSE facilitates the comparison between
     #: models with different scales.
@@ -366,77 +365,77 @@
     #: The R2 score is one of the performance evaluation measures for forecasting-based machine
     #: learning models.
     R2_SCORE = "R2Score"
     #: The Normalized Mean Absolute Error (NMAE) is a validation metric to compare the Mean Absolute
     #: Error (MAE) of (time) series with different scales.
     NORMALIZED_MEAN_ABSOLUTE_ERROR = "NormalizedMeanAbsoluteError"
 
-class Goal(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Goal(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Defines supported metric goals for hyperparameter tuning
     """
 
     MINIMIZE = "Minimize"
     MAXIMIZE = "Maximize"
 
-class IdentityConfigurationType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class IdentityConfigurationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine identity framework.
     """
 
     MANAGED = "Managed"
     AML_TOKEN = "AMLToken"
     USER_IDENTITY = "UserIdentity"
 
-class InputDeliveryMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class InputDeliveryMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the input data delivery mode.
     """
 
     READ_ONLY_MOUNT = "ReadOnlyMount"
     READ_WRITE_MOUNT = "ReadWriteMount"
     DOWNLOAD = "Download"
     DIRECT = "Direct"
     EVAL_MOUNT = "EvalMount"
     EVAL_DOWNLOAD = "EvalDownload"
 
-class InstanceSegmentationPrimaryMetrics(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class InstanceSegmentationPrimaryMetrics(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Primary metrics for InstanceSegmentation tasks.
     """
 
     #: Mean Average Precision (MAP) is the average of AP (Average Precision).
     #: AP is calculated for each class and averaged to get the MAP.
     MEAN_AVERAGE_PRECISION = "MeanAveragePrecision"
 
-class JobInputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobInputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the Job Input Type.
     """
 
     LITERAL = "Literal"
     URI_FILE = "UriFile"
     URI_FOLDER = "UriFolder"
     ML_TABLE = "MLTable"
     CUSTOM_MODEL = "CustomModel"
     ML_FLOW_MODEL = "MLFlowModel"
     TRITON_MODEL = "TritonModel"
 
-class JobLimitsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobLimitsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     COMMAND = "Command"
     SWEEP = "Sweep"
 
-class JobOutputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobOutputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the Job Output Type.
     """
 
     URI_FILE = "UriFile"
     URI_FOLDER = "UriFolder"
     ML_TABLE = "MLTable"
     CUSTOM_MODEL = "CustomModel"
     ML_FLOW_MODEL = "MLFlowModel"
     TRITON_MODEL = "TritonModel"
 
-class JobStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The status of a job.
     """
 
     #: Run hasn't started yet.
     NOT_STARTED = "NotStarted"
     #: Run has started. The user has a run ID.
     STARTING = "Starting"
@@ -468,46 +467,46 @@
     #: The job is paused by users. Some adjustment to labeling jobs can be made only in paused state.
     PAUSED = "Paused"
     #: Default job status if not mapped to all other statuses.
     UNKNOWN = "Unknown"
     #: The job is in a scheduled state. Job is not in any active state.
     SCHEDULED = "Scheduled"
 
-class JobType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the type of job.
     """
 
     AUTO_ML = "AutoML"
     COMMAND = "Command"
     SWEEP = "Sweep"
     PIPELINE = "Pipeline"
 
-class KeyType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class KeyType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     PRIMARY = "Primary"
     SECONDARY = "Secondary"
 
-class LearningRateScheduler(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class LearningRateScheduler(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Learning rate scheduler enum.
     """
 
     #: No learning rate scheduler selected.
     NONE = "None"
     #: Cosine Annealing With Warmup.
     WARMUP_COSINE = "WarmupCosine"
     #: Step learning rate scheduler.
     STEP = "Step"
 
-class ListViewType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ListViewType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     ACTIVE_ONLY = "ActiveOnly"
     ARCHIVED_ONLY = "ArchivedOnly"
     ALL = "All"
 
-class LogVerbosity(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class LogVerbosity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum for setting log verbosity.
     """
 
     #: No logs emitted.
     NOT_SET = "NotSet"
     #: Debug and above log statements logged.
     DEBUG = "Debug"
@@ -516,124 +515,124 @@
     #: Warning and above log statements logged.
     WARNING = "Warning"
     #: Error and above log statements logged.
     ERROR = "Error"
     #: Only critical statements logged.
     CRITICAL = "Critical"
 
-class ManagedServiceIdentityType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ManagedServiceIdentityType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Type of managed service identity (where both SystemAssigned and UserAssigned types are
     allowed).
     """
 
     NONE = "None"
     SYSTEM_ASSIGNED = "SystemAssigned"
     USER_ASSIGNED = "UserAssigned"
     SYSTEM_ASSIGNED_USER_ASSIGNED = "SystemAssigned,UserAssigned"
 
-class ModelSize(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ModelSize(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Image model size.
     """
 
     #: No value selected.
     NONE = "None"
     #: Small size.
     SMALL = "Small"
     #: Medium size.
     MEDIUM = "Medium"
     #: Large size.
     LARGE = "Large"
     #: Extra large size.
     EXTRA_LARGE = "ExtraLarge"
 
-class ModelType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ModelType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The async operation state.
     """
 
     CUSTOM_MODEL = "CustomModel"
     ML_FLOW_MODEL = "MLFlowModel"
     TRITON_MODEL = "TritonModel"
 
-class NCrossValidationsMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class NCrossValidationsMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Determines how N-Cross validations value is determined.
     """
 
     #: Determine N-Cross validations value automatically. Supported only for 'Forecasting' AutoML
     #: task.
     AUTO = "Auto"
     #: Use custom N-Cross validations value.
     CUSTOM = "Custom"
 
-class ObjectDetectionPrimaryMetrics(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ObjectDetectionPrimaryMetrics(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Primary metrics for Image ObjectDetection task.
     """
 
     #: Mean Average Precision (MAP) is the average of AP (Average Precision).
     #: AP is calculated for each class and averaged to get the MAP.
     MEAN_AVERAGE_PRECISION = "MeanAveragePrecision"
 
-class OperatingSystemType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OperatingSystemType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of operating system.
     """
 
     LINUX = "Linux"
     WINDOWS = "Windows"
 
-class OrderString(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OrderString(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     CREATED_AT_DESC = "CreatedAtDesc"
     CREATED_AT_ASC = "CreatedAtAsc"
     UPDATED_AT_DESC = "UpdatedAtDesc"
     UPDATED_AT_ASC = "UpdatedAtAsc"
 
-class OutputDeliveryMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OutputDeliveryMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Output data delivery mode enums.
     """
 
     READ_WRITE_MOUNT = "ReadWriteMount"
     UPLOAD = "Upload"
 
-class PublicNetworkAccessType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class PublicNetworkAccessType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine whether PublicNetworkAccess is Enabled or Disabled.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class RandomSamplingAlgorithmRule(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RandomSamplingAlgorithmRule(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The specific type of random algorithm
     """
 
     RANDOM = "Random"
     SOBOL = "Sobol"
 
-class RecurrenceFrequency(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RecurrenceFrequency(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to describe the frequency of a recurrence schedule
     """
 
     #: Minute frequency.
     MINUTE = "Minute"
     #: Hour frequency.
     HOUR = "Hour"
     #: Day frequency.
     DAY = "Day"
     #: Week frequency.
     WEEK = "Week"
     #: Month frequency.
     MONTH = "Month"
 
-class ReferenceType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ReferenceType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine which reference method to use for an asset.
     """
 
     ID = "Id"
     DATA_PATH = "DataPath"
     OUTPUT_PATH = "OutputPath"
 
-class RegressionModels(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RegressionModels(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum for all Regression models supported by AutoML.
     """
 
     #: Elastic net is a popular type of regularized linear regression that combines two popular
     #: penalties, specifically the L1 and L2 penalty functions.
     ELASTIC_NET = "ElasticNet"
     #: The technique of transiting week learners into a strong learner is called Boosting. The
@@ -669,15 +668,15 @@
     EXTREME_RANDOM_TREES = "ExtremeRandomTrees"
     #: LightGBM is a gradient boosting framework that uses tree based learning algorithms.
     LIGHT_GBM = "LightGBM"
     #: XGBoostRegressor: Extreme Gradient Boosting Regressor is a supervised machine learning model
     #: using ensemble of base learners.
     XG_BOOST_REGRESSOR = "XGBoostRegressor"
 
-class RegressionPrimaryMetrics(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RegressionPrimaryMetrics(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Primary metrics for Regression task.
     """
 
     #: The Spearman's rank coefficient of correlation is a nonparametric measure of rank correlation.
     SPEARMAN_CORRELATION = "SpearmanCorrelation"
     #: The Normalized Root Mean Squared Error (NRMSE) the RMSE facilitates the comparison between
     #: models with different scales.
@@ -685,108 +684,108 @@
     #: The R2 score is one of the performance evaluation measures for forecasting-based machine
     #: learning models.
     R2_SCORE = "R2Score"
     #: The Normalized Mean Absolute Error (NMAE) is a validation metric to compare the Mean Absolute
     #: Error (MAE) of (time) series with different scales.
     NORMALIZED_MEAN_ABSOLUTE_ERROR = "NormalizedMeanAbsoluteError"
 
-class SamplingAlgorithmType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SamplingAlgorithmType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     GRID = "Grid"
     RANDOM = "Random"
     BAYESIAN = "Bayesian"
 
-class ScaleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScaleType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     DEFAULT = "Default"
     TARGET_UTILIZATION = "TargetUtilization"
 
-class ScheduleStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScheduleStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to describe status of schedule
     """
 
     #: Schedule is enabled.
     ENABLED = "Enabled"
     #: Schedule is disabled.
     DISABLED = "Disabled"
 
-class ScheduleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScheduleType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to describe type of schedule
     """
 
     #: Cron schedule type.
     CRON = "Cron"
     #: Recurrence schedule type.
     RECURRENCE = "Recurrence"
 
-class SeasonalityMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SeasonalityMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Forecasting seasonality mode.
     """
 
     #: Seasonality to be determined automatically.
     AUTO = "Auto"
     #: Use the custom seasonality value.
     CUSTOM = "Custom"
 
-class SecretsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SecretsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the datastore secrets type.
     """
 
     ACCOUNT_KEY = "AccountKey"
     CERTIFICATE = "Certificate"
     SAS = "Sas"
     SERVICE_PRINCIPAL = "ServicePrincipal"
     KERBEROS_PASSWORD = "KerberosPassword"
     KERBEROS_KEYTAB = "KerberosKeytab"
 
-class ServiceDataAccessAuthIdentity(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ServiceDataAccessAuthIdentity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     #: Do not use any identity for service data access.
     NONE = "None"
     #: Use the system assigned managed identity of the Workspace to authenticate service data access.
     WORKSPACE_SYSTEM_ASSIGNED_IDENTITY = "WorkspaceSystemAssignedIdentity"
     #: Use the user assigned managed identity of the Workspace to authenticate service data access.
     WORKSPACE_USER_ASSIGNED_IDENTITY = "WorkspaceUserAssignedIdentity"
 
-class ShortSeriesHandlingConfiguration(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ShortSeriesHandlingConfiguration(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The parameter defining how if AutoML should handle short time series.
     """
 
     #: Represents no/null value.
     NONE = "None"
     #: Short series will be padded if there are no long series, otherwise short series will be
     #: dropped.
     AUTO = "Auto"
     #: All the short series will be padded.
     PAD = "Pad"
     #: All the short series will be dropped.
     DROP = "Drop"
 
-class SkuScaleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SkuScaleType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Node scaling setting for the compute sku.
     """
 
     #: Automatically scales node count.
     AUTOMATIC = "Automatic"
     #: Node count scaled upon user request.
     MANUAL = "Manual"
     #: Fixed set of nodes.
     NONE = "None"
 
-class SkuTier(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SkuTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """This field is required to be implemented by the Resource Provider if the service has more than
     one tier, but is not required on a PUT.
     """
 
     FREE = "Free"
     BASIC = "Basic"
     STANDARD = "Standard"
     PREMIUM = "Premium"
 
-class StackMetaLearnerType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class StackMetaLearnerType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The meta-learner is a model trained on the output of the individual heterogeneous models.
     Default meta-learners are LogisticRegression for classification tasks (or LogisticRegressionCV
     if cross-validation is enabled) and ElasticNet for regression/forecasting tasks (or
     ElasticNetCV if cross-validation is enabled).
     This parameter can be one of the following strings: LogisticRegression, LogisticRegressionCV,
     LightGBMClassifier, ElasticNet, ElasticNetCV, LightGBMRegressor, or LinearRegression
     """
@@ -800,58 +799,58 @@
     #: Default meta-learners are LogisticRegression for regression task.
     ELASTIC_NET = "ElasticNet"
     #: Default meta-learners are LogisticRegression for regression task when CV is on.
     ELASTIC_NET_CV = "ElasticNetCV"
     LIGHT_GBM_REGRESSOR = "LightGBMRegressor"
     LINEAR_REGRESSION = "LinearRegression"
 
-class StochasticOptimizer(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class StochasticOptimizer(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Stochastic optimizer for image models.
     """
 
     #: No optimizer selected.
     NONE = "None"
     #: Stochastic Gradient Descent optimizer.
     SGD = "Sgd"
     #: Adam is algorithm the optimizes stochastic objective functions based on adaptive estimates of
     #: moments.
     ADAM = "Adam"
     #: AdamW is a variant of the optimizer Adam that has an improved implementation of weight decay.
     ADAMW = "Adamw"
 
-class TargetAggregationFunction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class TargetAggregationFunction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Target aggregate function.
     """
 
     #: Represent no value set.
     NONE = "None"
     SUM = "Sum"
     MAX = "Max"
     MIN = "Min"
     MEAN = "Mean"
 
-class TargetLagsMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class TargetLagsMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Target lags selection modes.
     """
 
     #: Target lags to be determined automatically.
     AUTO = "Auto"
     #: Use the custom target lags.
     CUSTOM = "Custom"
 
-class TargetRollingWindowSizeMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class TargetRollingWindowSizeMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Target rolling windows size mode.
     """
 
     #: Determine rolling windows size automatically.
     AUTO = "Auto"
     #: Use the specified rolling window size.
     CUSTOM = "Custom"
 
-class TaskType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class TaskType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """AutoMLJob Task type.
     """
 
     #: Classification in machine learning and statistics is a supervised learning approach in which
     #: the computer program learns from the data given to it and make new observations or
     #: classifications.
     CLASSIFICATION = "Classification"
@@ -886,37 +885,37 @@
     #: Multilabel classification task assigns each sample to a group (zero or more) of target labels.
     TEXT_CLASSIFICATION_MULTILABEL = "TextClassificationMultilabel"
     #: Text Named Entity Recognition a.k.a. TextNER.
     #: Named Entity Recognition (NER) is the ability to take free-form text and identify the
     #: occurrences of entities such as people, locations, organizations, and more.
     TEXT_NER = "TextNER"
 
-class UseStl(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class UseStl(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Configure STL Decomposition of the time-series target column.
     """
 
     #: No stl decomposition.
     NONE = "None"
     SEASON = "Season"
     SEASON_TREND = "SeasonTrend"
 
-class ValidationMetricType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ValidationMetricType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Metric computation method to use for validation metrics in image tasks.
     """
 
     #: No metric.
     NONE = "None"
     #: Coco metric.
     COCO = "Coco"
     #: Voc metric.
     VOC = "Voc"
     #: CocoVoc metric.
     COCO_VOC = "CocoVoc"
 
-class Weekday(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Weekday(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum of weekdays
     """
 
     #: Monday weekday.
     MONDAY = "Monday"
     #: Tuesday weekday.
     TUESDAY = "Tuesday"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/aio/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_04_01/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/model_dataplane/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/_configuration.py`

 * *Files 4% similar despite different names*

```diff
@@ -25,27 +25,27 @@
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
     :param credential: Credential needed for the client to connect to Azure.
     :type credential: ~azure.core.credentials_async.AsyncTokenCredential
     :param subscription_id: The ID of the target subscription.
     :type subscription_id: str
-    :keyword api_version: Api Version. The default value is "2022-10-01-preview". Note that
+    :keyword api_version: Api Version. The default value is "2023-06-01-preview". Note that
      overriding this default value may result in unsupported behavior.
     :paramtype api_version: str
     """
 
     def __init__(
         self,
         credential: "AsyncTokenCredential",
         subscription_id: str,
         **kwargs: Any
     ) -> None:
         super(AzureMachineLearningWorkspacesConfiguration, self).__init__(**kwargs)
-        api_version = kwargs.pop('api_version', "2022-10-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
         if credential is None:
             raise ValueError("Parameter 'credential' must not be None.")
         if subscription_id is None:
             raise ValueError("Parameter 'subscription_id' must not be None.")
 
         self.credential = credential
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/aio/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_10_01_preview/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_01_01_preview/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 14% similar despite different names*

```diff
@@ -3,92 +3,91 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class AllocationState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class AllocationState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Allocation state of the compute. Possible values are: steady - Indicates that the compute is
     not resizing. There are no changes to the number of compute nodes in the compute in progress. A
     compute enters this state when it is created and when no operations are being performed on the
     compute to change the number of compute nodes. resizing - Indicates that the compute is
     resizing; that is, compute nodes are being added to or removed from the compute.
     """
 
     STEADY = "Steady"
     RESIZING = "Resizing"
 
-class ApplicationSharingPolicy(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ApplicationSharingPolicy(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Policy for sharing applications on this compute instance among users of parent workspace. If
     Personal, only the creator can access applications on this compute instance. When Shared, any
     workspace user can access applications on this instance depending on his/her assigned role.
     """
 
     PERSONAL = "Personal"
     SHARED = "Shared"
 
-class Autosave(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Autosave(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Auto save settings.
     """
 
     NONE = "None"
     LOCAL = "Local"
     REMOTE = "Remote"
 
-class BatchLoggingLevel(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class BatchLoggingLevel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Log verbosity for batch inferencing.
     Increasing verbosity order for logging is : Warning, Info and Debug.
     The default value is Info.
     """
 
     INFO = "Info"
     WARNING = "Warning"
     DEBUG = "Debug"
 
-class BatchOutputAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class BatchOutputAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine how batch inferencing will handle output
     """
 
     SUMMARY_ONLY = "SummaryOnly"
     APPEND_ROW = "AppendRow"
 
-class BillingCurrency(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class BillingCurrency(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Three lettered code specifying the currency of the VM price. Example: USD
     """
 
     USD = "USD"
 
-class Caching(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Caching(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Caching type of Data Disk.
     """
 
     NONE = "None"
     READ_ONLY = "ReadOnly"
     READ_WRITE = "ReadWrite"
 
-class ClusterPurpose(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ClusterPurpose(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Intended usage of the cluster
     """
 
     FAST_PROD = "FastProd"
     DENSE_PROD = "DenseProd"
     DEV_TEST = "DevTest"
 
-class ComputeInstanceAuthorizationType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputeInstanceAuthorizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The Compute Instance Authorization type. Available values are personal (default).
     """
 
     PERSONAL = "personal"
 
-class ComputeInstanceState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputeInstanceState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Current state of an ComputeInstance.
     """
 
     CREATING = "Creating"
     CREATE_FAILED = "CreateFailed"
     DELETING = "Deleting"
     RUNNING = "Running"
@@ -100,225 +99,225 @@
     STOPPED = "Stopped"
     STOPPING = "Stopping"
     USER_SETTING_UP = "UserSettingUp"
     USER_SETUP_FAILED = "UserSetupFailed"
     UNKNOWN = "Unknown"
     UNUSABLE = "Unusable"
 
-class ComputePowerAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputePowerAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The compute power action.
     """
 
     START = "Start"
     STOP = "Stop"
 
-class ComputeType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ComputeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of compute
     """
 
     AKS = "AKS"
     KUBERNETES = "Kubernetes"
     AML_COMPUTE = "AmlCompute"
     COMPUTE_INSTANCE = "ComputeInstance"
     DATA_FACTORY = "DataFactory"
     VIRTUAL_MACHINE = "VirtualMachine"
     HD_INSIGHT = "HDInsight"
     DATABRICKS = "Databricks"
     DATA_LAKE_ANALYTICS = "DataLakeAnalytics"
     SYNAPSE_SPARK = "SynapseSpark"
 
-class ConnectionAuthType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ConnectionAuthType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Authentication type of the connection target
     """
 
     PAT = "PAT"
     MANAGED_IDENTITY = "ManagedIdentity"
     USERNAME_PASSWORD = "UsernamePassword"
     NONE = "None"
     SAS = "SAS"
 
-class ConnectionCategory(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ConnectionCategory(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Category of the connection
     """
 
     PYTHON_FEED = "PythonFeed"
     CONTAINER_REGISTRY = "ContainerRegistry"
     GIT = "Git"
 
-class ContainerType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ContainerType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     STORAGE_INITIALIZER = "StorageInitializer"
     INFERENCE_SERVER = "InferenceServer"
 
-class CreatedByType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class CreatedByType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of identity that created the resource.
     """
 
     USER = "User"
     APPLICATION = "Application"
     MANAGED_IDENTITY = "ManagedIdentity"
     KEY = "Key"
 
-class CredentialsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class CredentialsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the datastore credentials type.
     """
 
     ACCOUNT_KEY = "AccountKey"
     CERTIFICATE = "Certificate"
     NONE = "None"
     SAS = "Sas"
     SERVICE_PRINCIPAL = "ServicePrincipal"
 
-class DatastoreType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DatastoreType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the datastore contents type.
     """
 
     AZURE_BLOB = "AzureBlob"
     AZURE_DATA_LAKE_GEN1 = "AzureDataLakeGen1"
     AZURE_DATA_LAKE_GEN2 = "AzureDataLakeGen2"
     AZURE_FILE = "AzureFile"
 
-class DataType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DataType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the type of data.
     """
 
     URI_FILE = "uri_file"
     URI_FOLDER = "uri_folder"
     MLTABLE = "mltable"
 
-class DeploymentProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DeploymentProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Possible values for DeploymentProvisioningState.
     """
 
     CREATING = "Creating"
     DELETING = "Deleting"
     SCALING = "Scaling"
     UPDATING = "Updating"
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
     CANCELED = "Canceled"
 
-class DiagnoseResultLevel(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DiagnoseResultLevel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Level of workspace setup error
     """
 
     WARNING = "Warning"
     ERROR = "Error"
     INFORMATION = "Information"
 
-class DistributionType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class DistributionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the job distribution type.
     """
 
     PY_TORCH = "PyTorch"
     TENSOR_FLOW = "TensorFlow"
     MPI = "Mpi"
 
-class EarlyTerminationPolicyType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EarlyTerminationPolicyType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     BANDIT = "Bandit"
     MEDIAN_STOPPING = "MedianStopping"
     TRUNCATION_SELECTION = "TruncationSelection"
 
-class EncryptionStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EncryptionStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Indicates whether or not the encryption is enabled for the workspace.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class EndpointAuthMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EndpointAuthMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine endpoint authentication mode.
     """
 
     AML_TOKEN = "AMLToken"
     KEY = "Key"
     AAD_TOKEN = "AADToken"
 
-class EndpointComputeType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EndpointComputeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine endpoint compute type.
     """
 
     MANAGED = "Managed"
     KUBERNETES = "Kubernetes"
     AZURE_ML_COMPUTE = "AzureMLCompute"
 
-class EndpointProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EndpointProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of endpoint provisioning.
     """
 
     CREATING = "Creating"
     DELETING = "Deleting"
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
     UPDATING = "Updating"
     CANCELED = "Canceled"
 
-class EnvironmentType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class EnvironmentType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Environment type is either user created or curated by Azure ML service
     """
 
     CURATED = "Curated"
     USER_CREATED = "UserCreated"
 
-class Goal(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Goal(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Defines supported metric goals for hyperparameter tuning
     """
 
     MINIMIZE = "Minimize"
     MAXIMIZE = "Maximize"
 
-class IdentityConfigurationType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class IdentityConfigurationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine identity framework.
     """
 
     MANAGED = "Managed"
     AML_TOKEN = "AMLToken"
     USER_IDENTITY = "UserIdentity"
 
-class InputDeliveryMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class InputDeliveryMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the input data delivery mode.
     """
 
     READ_ONLY_MOUNT = "ReadOnlyMount"
     READ_WRITE_MOUNT = "ReadWriteMount"
     DOWNLOAD = "Download"
     DIRECT = "Direct"
     EVAL_MOUNT = "EvalMount"
     EVAL_DOWNLOAD = "EvalDownload"
 
-class JobInputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobInputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the Job Input Type.
     """
 
     LITERAL = "literal"
     URI_FILE = "uri_file"
     URI_FOLDER = "uri_folder"
     MLTABLE = "mltable"
     CUSTOM_MODEL = "custom_model"
     MLFLOW_MODEL = "mlflow_model"
     TRITON_MODEL = "triton_model"
 
-class JobLimitsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobLimitsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     COMMAND = "Command"
     SWEEP = "Sweep"
 
-class JobOutputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobOutputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the Job Output Type.
     """
 
     URI_FILE = "uri_file"
     URI_FOLDER = "uri_folder"
     MLTABLE = "mltable"
     CUSTOM_MODEL = "custom_model"
     MLFLOW_MODEL = "mlflow_model"
     TRITON_MODEL = "triton_model"
 
-class JobStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The status of a job.
     """
 
     #: Run hasn't started yet.
     NOT_STARTED = "NotStarted"
     #: Run has started. The user has a run ID.
     STARTING = "Starting"
@@ -348,399 +347,399 @@
     #: NotResponding to any of the previous states.
     NOT_RESPONDING = "NotResponding"
     #: The job is paused by users. Some adjustment to labeling jobs can be made only in paused state.
     PAUSED = "Paused"
     #: Default job status if not mapped to all other statuses.
     UNKNOWN = "Unknown"
 
-class JobType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class JobType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the type of job.
     """
 
     COMMAND = "Command"
     SWEEP = "Sweep"
     PIPELINE = "Pipeline"
 
-class KeyType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class KeyType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     PRIMARY = "Primary"
     SECONDARY = "Secondary"
 
-class ListViewType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ListViewType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     ACTIVE_ONLY = "ActiveOnly"
     ARCHIVED_ONLY = "ArchivedOnly"
     ALL = "All"
 
-class LoadBalancerType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class LoadBalancerType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Load Balancer Type
     """
 
     PUBLIC_IP = "PublicIp"
     INTERNAL_LOAD_BALANCER = "InternalLoadBalancer"
 
-class ManagedServiceIdentityType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ManagedServiceIdentityType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Type of managed service identity (where both SystemAssigned and UserAssigned types are
     allowed).
     """
 
     NONE = "None"
     SYSTEM_ASSIGNED = "SystemAssigned"
     USER_ASSIGNED = "UserAssigned"
     SYSTEM_ASSIGNED_USER_ASSIGNED = "SystemAssigned,UserAssigned"
 
-class MountAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class MountAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Mount Action.
     """
 
     MOUNT = "Mount"
     UNMOUNT = "Unmount"
 
-class MountState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class MountState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Mount state.
     """
 
     MOUNT_REQUESTED = "MountRequested"
     MOUNTED = "Mounted"
     MOUNT_FAILED = "MountFailed"
     UNMOUNT_REQUESTED = "UnmountRequested"
     UNMOUNT_FAILED = "UnmountFailed"
     UNMOUNTED = "Unmounted"
 
-class Network(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Network(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """network of this container.
     """
 
     BRIDGE = "Bridge"
     HOST = "Host"
 
-class NodeState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class NodeState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of the compute node. Values are idle, running, preparing, unusable, leaving and
     preempted.
     """
 
     IDLE = "idle"
     RUNNING = "running"
     PREPARING = "preparing"
     UNUSABLE = "unusable"
     LEAVING = "leaving"
     PREEMPTED = "preempted"
 
-class OperatingSystemType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OperatingSystemType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of operating system.
     """
 
     LINUX = "Linux"
     WINDOWS = "Windows"
 
-class OperationName(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OperationName(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Name of the last operation.
     """
 
     CREATE = "Create"
     START = "Start"
     STOP = "Stop"
     RESTART = "Restart"
     REIMAGE = "Reimage"
     DELETE = "Delete"
 
-class OperationStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OperationStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Operation status.
     """
 
     IN_PROGRESS = "InProgress"
     SUCCEEDED = "Succeeded"
     CREATE_FAILED = "CreateFailed"
     START_FAILED = "StartFailed"
     STOP_FAILED = "StopFailed"
     RESTART_FAILED = "RestartFailed"
     REIMAGE_FAILED = "ReimageFailed"
     DELETE_FAILED = "DeleteFailed"
 
-class OperationTrigger(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OperationTrigger(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Trigger of operation.
     """
 
     USER = "User"
     SCHEDULE = "Schedule"
     IDLE_SHUTDOWN = "IdleShutdown"
 
-class OrderString(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OrderString(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     CREATED_AT_DESC = "CreatedAtDesc"
     CREATED_AT_ASC = "CreatedAtAsc"
     UPDATED_AT_DESC = "UpdatedAtDesc"
     UPDATED_AT_ASC = "UpdatedAtAsc"
 
-class OsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Compute OS Type
     """
 
     LINUX = "Linux"
     WINDOWS = "Windows"
 
-class OutputDeliveryMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class OutputDeliveryMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Output data delivery mode enums.
     """
 
     READ_WRITE_MOUNT = "ReadWriteMount"
     UPLOAD = "Upload"
 
-class PrivateEndpointConnectionProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class PrivateEndpointConnectionProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The current provisioning state.
     """
 
     SUCCEEDED = "Succeeded"
     CREATING = "Creating"
     DELETING = "Deleting"
     FAILED = "Failed"
 
-class PrivateEndpointServiceConnectionStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class PrivateEndpointServiceConnectionStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The private endpoint connection status.
     """
 
     PENDING = "Pending"
     APPROVED = "Approved"
     REJECTED = "Rejected"
     DISCONNECTED = "Disconnected"
     TIMEOUT = "Timeout"
 
-class ProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The current deployment state of workspace resource. The provisioningState is to indicate states
     for resource provisioning.
     """
 
     UNKNOWN = "Unknown"
     UPDATING = "Updating"
     CREATING = "Creating"
     DELETING = "Deleting"
     SUCCEEDED = "Succeeded"
     FAILED = "Failed"
     CANCELED = "Canceled"
 
-class ProvisioningStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ProvisioningStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The current deployment state of schedule.
     """
 
     COMPLETED = "Completed"
     PROVISIONING = "Provisioning"
     FAILED = "Failed"
 
-class PublicNetworkAccess(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class PublicNetworkAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Whether requests from Public Network are allowed.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class QuotaUnit(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class QuotaUnit(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """An enum describing the unit of quota measurement.
     """
 
     COUNT = "Count"
 
-class RandomSamplingAlgorithmRule(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RandomSamplingAlgorithmRule(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The specific type of random algorithm
     """
 
     RANDOM = "Random"
     SOBOL = "Sobol"
 
-class RecurrenceFrequency(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RecurrenceFrequency(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to describe the frequency of a recurrence schedule
     """
 
     #: Minute frequency.
     MINUTE = "Minute"
     #: Hour frequency.
     HOUR = "Hour"
     #: Day frequency.
     DAY = "Day"
     #: Week frequency.
     WEEK = "Week"
     #: Month frequency.
     MONTH = "Month"
 
-class ReferenceType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ReferenceType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine which reference method to use for an asset.
     """
 
     ID = "Id"
     DATA_PATH = "DataPath"
     OUTPUT_PATH = "OutputPath"
 
-class RemoteLoginPortPublicAccess(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class RemoteLoginPortPublicAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh
     port is closed on all nodes of the cluster. Enabled - Indicates that the public ssh port is
     open on all nodes of the cluster. NotSpecified - Indicates that the public ssh port is closed
     on all nodes of the cluster if VNet is defined, else is open all public nodes. It can be
     default only during cluster creation time, after creation it will be either enabled or
     disabled.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
     NOT_SPECIFIED = "NotSpecified"
 
-class SamplingAlgorithmType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SamplingAlgorithmType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     GRID = "Grid"
     RANDOM = "Random"
     BAYESIAN = "Bayesian"
 
-class ScaleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScaleType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     DEFAULT = "Default"
     TARGET_UTILIZATION = "TargetUtilization"
 
-class ScheduleStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScheduleStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to describe status of schedule
     """
 
     #: Schedule is enabled.
     ENABLED = "Enabled"
     #: Schedule is disabled.
     DISABLED = "Disabled"
 
-class ScheduleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ScheduleType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to describe type of schedule
     """
 
     #: Cron schedule type.
     CRON = "Cron"
     #: Recurrence schedule type.
     RECURRENCE = "Recurrence"
 
-class SecretsType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SecretsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum to determine the datastore secrets type.
     """
 
     ACCOUNT_KEY = "AccountKey"
     CERTIFICATE = "Certificate"
     SAS = "Sas"
     SERVICE_PRINCIPAL = "ServicePrincipal"
 
-class ServiceDataAccessAuthIdentity(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ServiceDataAccessAuthIdentity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     #: Do not use any identity for service data access.
     NONE = "None"
     #: Use the system assigned managed identity of the Workspace to authenticate service data access.
     WORKSPACE_SYSTEM_ASSIGNED_IDENTITY = "WorkspaceSystemAssignedIdentity"
     #: Use the user assigned managed identity of the Workspace to authenticate service data access.
     WORKSPACE_USER_ASSIGNED_IDENTITY = "WorkspaceUserAssignedIdentity"
 
-class SkuScaleType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SkuScaleType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """TODO - SKU scale type
     """
 
     AUTOMATIC = "Automatic"
     MANUAL = "Manual"
     NONE = "None"
 
-class SkuTier(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SkuTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """This field is required to be implemented by the Resource Provider if the service has more than
     one tier, but is not required on a PUT.
     """
 
     FREE = "Free"
     BASIC = "Basic"
     STANDARD = "Standard"
     PREMIUM = "Premium"
 
-class SourceType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SourceType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Data source type.
     """
 
     DATASET = "Dataset"
     DATASTORE = "Datastore"
     URI = "URI"
 
-class SshPublicAccess(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SshPublicAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh
     port is closed on this instance. Enabled - Indicates that the public ssh port is open and
     accessible according to the VNet/subnet policy if applicable.
     """
 
     ENABLED = "Enabled"
     DISABLED = "Disabled"
 
-class SslConfigurationStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class SslConfigurationStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enable or disable ssl for scoring
     """
 
     DISABLED = "Disabled"
     ENABLED = "Enabled"
     AUTO = "Auto"
 
-class Status(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Status(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Status of update workspace quota.
     """
 
     UNDEFINED = "Undefined"
     SUCCESS = "Success"
     FAILURE = "Failure"
     INVALID_QUOTA_BELOW_CLUSTER_MINIMUM = "InvalidQuotaBelowClusterMinimum"
     INVALID_QUOTA_EXCEEDS_SUBSCRIPTION_LIMIT = "InvalidQuotaExceedsSubscriptionLimit"
     INVALID_VM_FAMILY_NAME = "InvalidVMFamilyName"
     OPERATION_NOT_SUPPORTED_FOR_SKU = "OperationNotSupportedForSku"
     OPERATION_NOT_ENABLED_FOR_REGION = "OperationNotEnabledForRegion"
 
-class StorageAccountType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class StorageAccountType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """type of this storage account.
     """
 
     STANDARD_LRS = "Standard_LRS"
     PREMIUM_LRS = "Premium_LRS"
 
-class UnderlyingResourceAction(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class UnderlyingResourceAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
     DELETE = "Delete"
     DETACH = "Detach"
 
-class UnitOfMeasure(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class UnitOfMeasure(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The unit of time measurement for the specified VM price. Example: OneHour
     """
 
     ONE_HOUR = "OneHour"
 
-class UsageUnit(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class UsageUnit(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """An enum describing the unit of usage measurement.
     """
 
     COUNT = "Count"
 
-class ValueFormat(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class ValueFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """format for the workspace connection value
     """
 
     JSON = "JSON"
 
-class VMPriceOSType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class VMPriceOSType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Operating system type used by the VM.
     """
 
     LINUX = "Linux"
     WINDOWS = "Windows"
 
-class VmPriority(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class VmPriority(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Virtual Machine priority
     """
 
     DEDICATED = "Dedicated"
     LOW_PRIORITY = "LowPriority"
 
-class VMTier(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class VMTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of the VM.
     """
 
     STANDARD = "Standard"
     LOW_PRIORITY = "LowPriority"
     SPOT = "Spot"
 
-class Weekday(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class Weekday(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Enum of weekdays
     """
 
     #: Monday weekday.
     MONDAY = "Monday"
     #: Tuesday weekday.
     TUESDAY = "Tuesday"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_containers_operations.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,220 +1,212 @@
+# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-import functools
 from typing import TYPE_CHECKING
-import warnings
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from msrest import Serializer
+
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
-from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
-    T = TypeVar('T')
+    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
+
+    T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
-    name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    order_by = kwargs.pop('order_by', None)  # type: Optional[str]
-    top = kwargs.pop('top', None)  # type: Optional[int]
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
     skip = kwargs.pop('skip', None)  # type: Optional[str]
-    tags = kwargs.pop('tags', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
-    api_version = "2022-05-01"
     accept = "application/json"
     # Construct URL
-    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions')
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
-        "name": _SERIALIZER.url("name", name, 'str'),
     }
 
-    url = _format_url_section(url, **path_format_arguments)
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
-    if order_by is not None:
-        query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
-    if top is not None:
-        query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
+    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if skip is not None:
-        query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
-    if tags is not None:
-        query_parameters['$tags'] = _SERIALIZER.query("tags", tags, 'str')
+        _query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
     if list_view_type is not None:
-        query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
+        _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
 
     # Construct headers
-    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=url,
-        params=query_parameters,
-        headers=header_parameters,
+        url=_url,
+        params=_query_parameters,
+        headers=_header_parameters,
         **kwargs
     )
 
 
 def build_delete_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
     name,  # type: str
-    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = "2022-05-01"
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+
     accept = "application/json"
     # Construct URL
-    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}')
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
         "name": _SERIALIZER.url("name", name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    url = _format_url_section(url, **path_format_arguments)
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=url,
-        params=query_parameters,
-        headers=header_parameters,
+        url=_url,
+        params=_query_parameters,
+        headers=_header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
     name,  # type: str
-    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = "2022-05-01"
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+
     accept = "application/json"
     # Construct URL
-    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}')
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
         "name": _SERIALIZER.url("name", name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    url = _format_url_section(url, **path_format_arguments)
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=url,
-        params=query_parameters,
-        headers=header_parameters,
+        url=_url,
+        params=_query_parameters,
+        headers=_header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
     name,  # type: str
-    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
+    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
-    api_version = "2022-05-01"
     accept = "application/json"
     # Construct URL
-    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}')
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
-        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    url = _format_url_section(url, **path_format_arguments)
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=url,
-        params=query_parameters,
-        headers=header_parameters,
+        url=_url,
+        params=_query_parameters,
+        headers=_header_parameters,
         **kwargs
     )
 
 # fmt: on
-class DataVersionsOperations(object):
-    """DataVersionsOperations operations.
+class ComponentContainersOperations(object):
+    """ComponentContainersOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -232,311 +224,281 @@
         self._config = config
 
     @distributed_trace
     def list(
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
-        name,  # type: str
-        order_by=None,  # type: Optional[str]
-        top=None,  # type: Optional[int]
         skip=None,  # type: Optional[str]
-        tags=None,  # type: Optional[str]
         list_view_type=None,  # type: Optional[Union[str, "_models.ListViewType"]]
         **kwargs  # type: Any
     ):
-        # type: (...) -> Iterable["_models.DataVersionBaseResourceArmPaginatedResult"]
-        """List data versions in the data container.
+        # type: (...) -> Iterable["_models.ComponentContainerResourceArmPaginatedResult"]
+        """List component containers.
 
-        List data versions in the data container.
+        List component containers.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
-        :param name: Data container's name.
-        :type name: str
-        :param order_by: Please choose OrderBy value from ['createdtime', 'modifiedtime'].
-        :type order_by: str
-        :param top: Top count of results, top count cannot be greater than the page size.
-                                       If topCount > page size, results with be default page size count
-         will be returned.
-        :type top: int
         :param skip: Continuation token for pagination.
         :type skip: str
-        :param tags: Comma-separated list of tag names (and optionally values). Example:
-         tag1,tag2=value2.
-        :type tags: str
-        :param list_view_type: [ListViewType.ActiveOnly, ListViewType.ArchivedOnly,
-         ListViewType.All]View type for including/excluding (for example) archived entities.
+        :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either DataVersionBaseResourceArmPaginatedResult or the
-         result of cls(response)
+        :return: An iterator like instance of either ComponentContainerResourceArmPaginatedResult or
+         the result of cls(response)
         :rtype:
-         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.DataVersionBaseResourceArmPaginatedResult]
+         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ComponentContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseResourceArmPaginatedResult"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainerResourceArmPaginatedResult"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
+
         def prepare_request(next_link=None):
             if not next_link:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     workspace_name=workspace_name,
-                    name=name,
-                    order_by=order_by,
-                    top=top,
+                    api_version=api_version,
                     skip=skip,
-                    tags=tags,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata['url'],
+                    template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-                
+
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     workspace_name=workspace_name,
-                    name=name,
-                    order_by=order_by,
-                    top=top,
+                    api_version=api_version,
                     skip=skip,
-                    tags=tags,
                     list_view_type=list_view_type,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         def extract_data(pipeline_response):
-            deserialized = self._deserialize("DataVersionBaseResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("ComponentContainerResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
+            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
+                request, stream=False, **kwargs
+            )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
+        return ItemPaged(get_next, extract_data)
 
-        return ItemPaged(
-            get_next, extract_data
-        )
-    list.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions'}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components"}  # type: ignore
 
     @distributed_trace
-    def delete(
+    def delete(  # pylint: disable=inconsistent-return-statements
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
         name,  # type: str
-        version,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        """Delete version.
+        """Delete container.
 
-        Delete version.
+        Delete container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
         :param name: Container name.
         :type name: str
-        :param version: Version identifier.
-        :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
+
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        
         request = build_delete_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             workspace_name=workspace_name,
             name=name,
-            version=version,
-            template_url=self.delete.metadata['url'],
+            api_version=api_version,
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
+        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}'}  # type: ignore
-
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
         name,  # type: str
-        version,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.DataVersionBaseData"
-        """Get version.
+        # type: (...) -> "_models.ComponentContainer"
+        """Get container.
 
-        Get version.
+        Get container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
         :param name: Container name.
         :type name: str
-        :param version: Version identifier.
-        :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: DataVersionBaseData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
+        :return: ComponentContainer, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainer
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainer"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
+
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        
         request = build_get_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             workspace_name=workspace_name,
             name=name,
-            version=version,
-            template_url=self.get.metadata['url'],
+            api_version=api_version,
+            template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
+        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
+        deserialized = self._deserialize("ComponentContainer", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}'}  # type: ignore
-
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}"}  # type: ignore
 
     @distributed_trace
     def create_or_update(
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
         name,  # type: str
-        version,  # type: str
-        body,  # type: "_models.DataVersionBaseData"
+        body,  # type: "_models.ComponentContainer"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.DataVersionBaseData"
-        """Create or update version.
+        # type: (...) -> "_models.ComponentContainer"
+        """Create or update container.
 
-        Create or update version.
+        Create or update container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
         :param name: Container name.
         :type name: str
-        :param version: Version identifier.
-        :type version: str
-        :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
+        :param body: Container entity to create or update.
+        :type body: ~azure.mgmt.machinelearningservices.models.ComponentContainer
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: DataVersionBaseData, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.DataVersionBaseData
+        :return: ComponentContainer, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainer
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.DataVersionBaseData"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainer"]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}))
 
-        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, 'DataVersionBaseData')
+        _json = self._serialize.body(body, "ComponentContainer")
 
         request = build_create_or_update_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             workspace_name=workspace_name,
             name=name,
-            version=version,
+            api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata['url'],
+            template_url=self.create_or_update.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
+        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if response.status_code == 200:
-            deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
+            deserialized = self._deserialize("ComponentContainer", pipeline_response)
 
         if response.status_code == 201:
-            deserialized = self._deserialize('DataVersionBaseData', pipeline_response)
+            deserialized = self._deserialize("ComponentContainer", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/data/{name}/versions/{version}'}  # type: ignore
-
+    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_05_01/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/_configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,28 +27,28 @@
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
     :param credential: Credential needed for the client to connect to Azure.
     :type credential: ~azure.core.credentials.TokenCredential
     :param subscription_id: The ID of the target subscription.
     :type subscription_id: str
-    :keyword api_version: Api Version. The default value is "2020-09-01-dataplanepreview". Note
-     that overriding this default value may result in unsupported behavior.
+    :keyword api_version: Api Version. The default value is "2023-06-01-preview". Note that
+     overriding this default value may result in unsupported behavior.
     :paramtype api_version: str
     """
 
     def __init__(
         self,
         credential,  # type: "TokenCredential"
         subscription_id,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
         super(AzureMachineLearningWorkspacesConfiguration, self).__init__(**kwargs)
-        api_version = kwargs.pop('api_version', "2020-09-01-dataplanepreview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
         if credential is None:
             raise ValueError("Parameter 'credential' must not be None.")
         if subscription_id is None:
             raise ValueError("Parameter 'subscription_id' must not be None.")
 
         self.credential = credential
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2022_02_01_preview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_deployment_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_deployment_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_endpoint_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/aio/operations/_batch_job_endpoint_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_azure_machine_learning_workspaces_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/runhistory/models/_azure_machine_learning_workspaces_enums.py`

 * *Files 22% similar despite different names*

```diff
@@ -3,107 +3,78 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class BatchLoggingLevel(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Log verbosity for batch inferencing.
-    Increasing verbosity order for logging is : Warning, Info and Debug.
-    The default value is Info.
-    """
-
-    INFO = "Info"
-    WARNING = "Warning"
-    DEBUG = "Debug"
-
-class CreatedByType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """The type of identity that created the resource.
-    """
-
-    USER = "User"
-    APPLICATION = "Application"
-    MANAGED_IDENTITY = "ManagedIdentity"
-    KEY = "Key"
+class DatasetConsumptionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
-class DatasetType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+    RUN_INPUT = "RunInput"
+    REFERENCE = "Reference"
 
-    SIMPLE = "Simple"
-    DATAFLOW = "Dataflow"
+class DatasetDeliveryMechanism(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
-class InferenceDataInputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-
-    DATASET_VERSION = "DatasetVersion"
-    DATASET_ID = "DatasetId"
-    DATA_URL = "DataUrl"
-
-class InputDeliveryMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Enum to determine the input data delivery mode.
-    """
-
-    READ_ONLY_MOUNT = "ReadOnlyMount"
-    READ_WRITE_MOUNT = "ReadWriteMount"
-    DOWNLOAD = "Download"
     DIRECT = "Direct"
-    EVAL_MOUNT = "EvalMount"
-    EVAL_DOWNLOAD = "EvalDownload"
+    MOUNT = "Mount"
+    DOWNLOAD = "Download"
+    HDFS = "Hdfs"
 
-class JobInputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Enum to determine the Job Input Type.
-    """
+class DatasetOutputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
-    URI_FILE = "UriFile"
-    URI_FOLDER = "UriFolder"
-    ML_TABLE = "MLTable"
-    LITERAL = "Literal"
-    CUSTOM_MODEL = "CustomModel"
-    ML_FLOW_MODEL = "MLFlowModel"
-    TRITON_MODEL = "TritonModel"
+    RUN_OUTPUT = "RunOutput"
+    REFERENCE = "Reference"
 
-class JobOutputType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Enum to determine the Job Output Type.
+class ExperimentViewType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """ViewType filters experiments by their archived state. Default is ActiveOnly
     """
 
-    URI_FILE = "UriFile"
-    URI_FOLDER = "UriFolder"
-    ML_TABLE = "MLTable"
-    CUSTOM_MODEL = "CustomModel"
-    ML_FLOW_MODEL = "MLFlowModel"
-    TRITON_MODEL = "TritonModel"
+    DEFAULT = "Default"
+    ALL = "All"
+    ACTIVE_ONLY = "ActiveOnly"
+    ARCHIVED_ONLY = "ArchivedOnly"
 
-class JobProvisioningState(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class MetricValueType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
-    SUCCEEDED = "Succeeded"
-    FAILED = "Failed"
-    CANCELED = "Canceled"
-    IN_PROGRESS = "InProgress"
+    INT = "Int"
+    DOUBLE = "Double"
+    STRING = "String"
+    BOOL = "Bool"
+    ARTIFACT = "Artifact"
 
-class JobStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """The status of a job.
+class RunStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """Gets span status.
+    OpenTelemetry sets it to
+    https://github.com/open-telemetry/opentelemetry-dotnet/blob/master/src/OpenTelemetry.Api/Trace/Status.cs
+    That status enums are not very meaningful to us, so we customize this.
     """
 
     NOT_STARTED = "NotStarted"
+    UNAPPROVED = "Unapproved"
+    PAUSING = "Pausing"
+    PAUSED = "Paused"
     STARTING = "Starting"
-    PROVISIONING = "Provisioning"
     PREPARING = "Preparing"
     QUEUED = "Queued"
     RUNNING = "Running"
     FINALIZING = "Finalizing"
     CANCEL_REQUESTED = "CancelRequested"
     COMPLETED = "Completed"
     FAILED = "Failed"
     CANCELED = "Canceled"
-    NOT_RESPONDING = "NotResponding"
-    PAUSED = "Paused"
-    UNKNOWN = "Unknown"
 
-class OutputDeliveryMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Output data delivery mode enums.
-    """
+class SortOrderDirection(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+
+    ASC = "Asc"
+    DESC = "Desc"
+
+class StoredProcedureParameterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
 
-    READ_WRITE_MOUNT = "ReadWriteMount"
-    UPLOAD = "Upload"
+    STRING = "String"
+    INT = "Int"
+    DECIMAL = "Decimal"
+    GUID = "Guid"
+    BOOLEAN = "Boolean"
+    DATE = "Date"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_deployment_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_deployment_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_endpoint_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2020_09_01_dataplanepreview/operations/_batch_job_endpoint_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_vendor.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_vendor.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_azure_machine_learning_workspaces.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_azure_machine_learning_workspaces.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_patch.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_patch.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_versions_operations.py`

 * *Files 8% similar despite different names*

```diff
@@ -23,27 +23,27 @@
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._registry_model_versions_operations import (
+from ...operations._registry_code_versions_operations import (
     build_create_or_update_request_initial,
     build_delete_request_initial,
     build_get_request,
     build_list_request,
 )
 
 T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
 
-class RegistryModelVersionsOperations:
-    """RegistryModelVersionsOperations async operations.
+class RegistryCodeVersionsOperations:
+    """RegistryCodeVersionsOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -61,113 +61,86 @@
         self._config = config
 
     @distributed_trace
     def list(
         self,
         resource_group_name: str,
         registry_name: str,
-        model_name: str,
-        skip: Optional[str] = None,
+        code_name: str,
         order_by: Optional[str] = None,
         top: Optional[int] = None,
-        version: Optional[str] = None,
-        description: Optional[str] = None,
-        tags: Optional[str] = None,
-        properties: Optional[str] = None,
-        list_view_type: Optional[Union[str, "_models.ListViewType"]] = None,
+        skip: Optional[str] = None,
         **kwargs: Any
-    ) -> AsyncIterable["_models.ModelVersionResourceArmPaginatedResult"]:
+    ) -> AsyncIterable["_models.CodeVersionResourceArmPaginatedResult"]:
         """List versions.
 
         List versions.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param model_name: Container name. This is case-sensitive.
-        :type model_name: str
-        :param skip: Continuation token for pagination.
-        :type skip: str
+        :param code_name: Container name.
+        :type code_name: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
-        :param version: Version identifier.
-        :type version: str
-        :param description: Model description.
-        :type description: str
-        :param tags: Comma-separated list of tag names (and optionally values). Example:
-         tag1,tag2=value2.
-        :type tags: str
-        :param properties: Comma-separated list of property names (and optionally values). Example:
-         prop1,prop2=value2.
-        :type properties: str
-        :param list_view_type: View type for including/excluding (for example) archived entities.
-        :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :param skip: Continuation token for pagination.
+        :type skip: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either ModelVersionResourceArmPaginatedResult or the
+        :return: An iterator like instance of either CodeVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
-         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.ModelVersionResourceArmPaginatedResult]
+         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.CodeVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
         api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersionResourceArmPaginatedResult"]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersionResourceArmPaginatedResult"]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
         def prepare_request(next_link=None):
             if not next_link:
 
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
-                    model_name=model_name,
+                    code_name=code_name,
                     api_version=api_version,
-                    skip=skip,
                     order_by=order_by,
                     top=top,
-                    version=version,
-                    description=description,
-                    tags=tags,
-                    properties=properties,
-                    list_view_type=list_view_type,
+                    skip=skip,
                     template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
 
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
-                    model_name=model_name,
+                    code_name=code_name,
                     api_version=api_version,
-                    skip=skip,
                     order_by=order_by,
                     top=top,
-                    version=version,
-                    description=description,
-                    tags=tags,
-                    properties=properties,
-                    list_view_type=list_view_type,
+                    skip=skip,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         async def extract_data(pipeline_response):
-            deserialized = self._deserialize("ModelVersionResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("CodeVersionResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
@@ -182,30 +155,30 @@
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
         return AsyncItemPaged(get_next, extract_data)
 
-    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions"}  # type: ignore
 
     async def _delete_initial(  # pylint: disable=inconsistent-return-statements
-        self, resource_group_name: str, registry_name: str, model_name: str, version: str, **kwargs: Any
+        self, resource_group_name: str, registry_name: str, code_name: str, version: str, **kwargs: Any
     ) -> None:
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
         api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
         request = build_delete_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            model_name=model_name,
+            code_name=code_name,
             version=version,
             api_version=api_version,
             template_url=self._delete_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
@@ -225,30 +198,30 @@
             )
             response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
             response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def begin_delete(  # pylint: disable=inconsistent-return-statements
-        self, resource_group_name: str, registry_name: str, model_name: str, version: str, **kwargs: Any
+        self, resource_group_name: str, registry_name: str, code_name: str, version: str, **kwargs: Any
     ) -> AsyncLROPoller[None]:
         """Delete version.
 
         Delete version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param model_name: Container name.
-        :type model_name: str
+        :param code_name: Container name.
+        :type code_name: str
         :param version: Version identifier.
         :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
@@ -264,15 +237,15 @@
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
         lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
         cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._delete_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
-                model_name=model_name,
+                code_name=code_name,
                 version=version,
                 api_version=api_version,
                 cls=lambda x, y, z: x,
                 **kwargs
             )
         kwargs.pop("error_map", None)
 
@@ -291,48 +264,48 @@
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
                 deserialization_callback=get_long_running_output,
             )
         return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self, resource_group_name: str, registry_name: str, model_name: str, version: str, **kwargs: Any
-    ) -> "_models.ModelVersion":
+        self, resource_group_name: str, registry_name: str, code_name: str, version: str, **kwargs: Any
+    ) -> "_models.CodeVersion":
         """Get version.
 
         Get version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param model_name: Container name. This is case-sensitive.
-        :type model_name: str
-        :param version: Version identifier. This is case-sensitive.
+        :param code_name: Container name.
+        :type code_name: str
+        :param version: Version identifier.
         :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ModelVersion, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ModelVersion
+        :return: CodeVersion, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersion
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
         api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
 
         request = build_get_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            model_name=model_name,
+            code_name=code_name,
             version=version,
             api_version=api_version,
             template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
@@ -342,46 +315,46 @@
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize("ModelVersion", pipeline_response)
+        deserialized = self._deserialize("CodeVersion", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
     async def _create_or_update_initial(
         self,
         resource_group_name: str,
         registry_name: str,
-        model_name: str,
+        code_name: str,
         version: str,
-        body: "_models.ModelVersion",
+        body: "_models.CodeVersion",
         **kwargs: Any
-    ) -> "_models.ModelVersion":
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+    ) -> "_models.CodeVersion":
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
         api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
         content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, "ModelVersion")
+        _json = self._serialize.body(body, "CodeVersion")
 
         request = build_create_or_update_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            model_name=model_name,
+            code_name=code_name,
             version=version,
             api_version=api_version,
             content_type=content_type,
             json=_json,
             template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
@@ -394,94 +367,94 @@
 
         if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
         if response.status_code == 200:
-            deserialized = self._deserialize("ModelVersion", pipeline_response)
+            deserialized = self._deserialize("CodeVersion", pipeline_response)
 
         if response.status_code == 201:
             response_headers["x-ms-async-operation-timeout"] = self._deserialize(
                 "duration", response.headers.get("x-ms-async-operation-timeout")
             )
             response_headers["Azure-AsyncOperation"] = self._deserialize(
                 "str", response.headers.get("Azure-AsyncOperation")
             )
 
-            deserialized = self._deserialize("ModelVersion", pipeline_response)
+            deserialized = self._deserialize("CodeVersion", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def begin_create_or_update(
         self,
         resource_group_name: str,
         registry_name: str,
-        model_name: str,
+        code_name: str,
         version: str,
-        body: "_models.ModelVersion",
+        body: "_models.CodeVersion",
         **kwargs: Any
-    ) -> AsyncLROPoller["_models.ModelVersion"]:
+    ) -> AsyncLROPoller["_models.CodeVersion"]:
         """Create or update version.
 
         Create or update version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param model_name: Container name.
-        :type model_name: str
+        :param code_name: Container name.
+        :type code_name: str
         :param version: Version identifier.
         :type version: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ModelVersion
+        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersion
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of AsyncLROPoller that returns either ModelVersion or the result of
+        :return: An instance of AsyncLROPoller that returns either CodeVersion or the result of
          cls(response)
         :rtype:
-         ~azure.core.polling.AsyncLROPoller[~azure.mgmt.machinelearningservices.models.ModelVersion]
+         ~azure.core.polling.AsyncLROPoller[~azure.mgmt.machinelearningservices.models.CodeVersion]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
         api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
         content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
         polling = kwargs.pop("polling", True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
         lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
         cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
-                model_name=model_name,
+                code_name=code_name,
                 version=version,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
                 cls=lambda x, y, z: x,
                 **kwargs
             )
         kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
             response = pipeline_response.http_response
-            deserialized = self._deserialize("ModelVersion", pipeline_response)
+            deserialized = self._deserialize("CodeVersion", pipeline_response)
             if cls:
                 return cls(pipeline_response, deserialized, {})
             return deserialized
 
         if polling is True:
             polling_method = AsyncARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
         elif polling is False:
@@ -493,8 +466,8 @@
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
                 deserialization_callback=get_long_running_output,
             )
         return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featureset_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_featurestore_entity_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/aio/operations/_registry_component_versions_operations.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,45 +5,32 @@
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar, Union
 
 from azure.core.async_paging import AsyncItemPaged, AsyncList
-from azure.core.exceptions import (
-    ClientAuthenticationError,
-    HttpResponseError,
-    ResourceExistsError,
-    ResourceNotFoundError,
-    map_error,
-)
+from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.polling import AsyncLROPoller, AsyncNoPolling, AsyncPollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.async_arm_polling import AsyncARMPolling
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._registry_code_versions_operations import (
-    build_create_or_update_request_initial,
-    build_delete_request_initial,
-    build_get_request,
-    build_list_request,
-)
-
-T = TypeVar("T")
+from ...operations._registry_component_versions_operations import build_create_or_update_request_initial, build_delete_request_initial, build_get_request, build_list_request
+T = TypeVar('T')
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
-
-class RegistryCodeVersionsOperations:
-    """RegistryCodeVersionsOperations async operations.
+class RegistryComponentVersionsOperations:
+    """RegistryComponentVersionsOperations async operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -61,413 +48,452 @@
         self._config = config
 
     @distributed_trace
     def list(
         self,
         resource_group_name: str,
         registry_name: str,
-        code_name: str,
+        component_name: str,
         order_by: Optional[str] = None,
         top: Optional[int] = None,
         skip: Optional[str] = None,
+        stage: Optional[str] = None,
         **kwargs: Any
-    ) -> AsyncIterable["_models.CodeVersionResourceArmPaginatedResult"]:
+    ) -> AsyncIterable["_models.ComponentVersionResourceArmPaginatedResult"]:
         """List versions.
 
         List versions.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
+        :param component_name: Container name.
+        :type component_name: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
         :param skip: Continuation token for pagination.
         :type skip: str
+        :param stage: Component stage.
+        :type stage: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either CodeVersionResourceArmPaginatedResult or the
+        :return: An iterator like instance of either ComponentVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
-         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.CodeVersionResourceArmPaginatedResult]
+         ~azure.core.async_paging.AsyncItemPaged[~azure.mgmt.machinelearningservices.models.ComponentVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersionResourceArmPaginatedResult"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersionResourceArmPaginatedResult"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
-                    code_name=code_name,
+                    component_name=component_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skip=skip,
-                    template_url=self.list.metadata["url"],
+                    stage=stage,
+                    template_url=self.list.metadata['url'],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
-                    code_name=code_name,
+                    component_name=component_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
                     skip=skip,
+                    stage=stage,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         async def extract_data(pipeline_response):
-            deserialized = self._deserialize("CodeVersionResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("ComponentVersionResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, AsyncList(list_of_elem)
 
         async def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-                request, stream=False, **kwargs
+                request,
+                stream=False,
+                **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
-        return AsyncItemPaged(get_next, extract_data)
 
-    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions"}  # type: ignore
+        return AsyncItemPaged(
+            get_next, extract_data
+        )
+    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{componentName}/versions"}  # type: ignore
 
     async def _delete_initial(  # pylint: disable=inconsistent-return-statements
-        self, resource_group_name: str, registry_name: str, code_name: str, version: str, **kwargs: Any
+        self,
+        resource_group_name: str,
+        registry_name: str,
+        component_name: str,
+        version: str,
+        **kwargs: Any
     ) -> None:
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType[None]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        
         request = build_delete_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            code_name=code_name,
+            component_name=component_name,
             version=version,
             api_version=api_version,
-            template_url=self._delete_initial.metadata["url"],
+            template_url=self._delete_initial.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 202, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
         if response.status_code == 202:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
-            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
+            response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
+            response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
+            response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
+            
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    _delete_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{componentName}/versions/{version}"}  # type: ignore
+
 
     @distributed_trace_async
     async def begin_delete(  # pylint: disable=inconsistent-return-statements
-        self, resource_group_name: str, registry_name: str, code_name: str, version: str, **kwargs: Any
+        self,
+        resource_group_name: str,
+        registry_name: str,
+        component_name: str,
+        version: str,
+        **kwargs: Any
     ) -> AsyncLROPoller[None]:
         """Delete version.
 
         Delete version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
+        :param component_name: Container name.
+        :type component_name: str
         :param version: Version identifier.
         :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of AsyncLROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.AsyncLROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        polling = kwargs.pop("polling", True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
-        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
+        cls = kwargs.pop('cls', None)  # type: ClsType[None]
+        lro_delay = kwargs.pop(
+            'polling_interval',
+            self._config.polling_interval
+        )
+        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._delete_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
-                code_name=code_name,
+                component_name=component_name,
                 version=version,
                 api_version=api_version,
-                cls=lambda x, y, z: x,
+                cls=lambda x,y,z: x,
                 **kwargs
             )
-        kwargs.pop("error_map", None)
+        kwargs.pop('error_map', None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-        if polling is True:
-            polling_method = AsyncARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
-        elif polling is False:
-            polling_method = AsyncNoPolling()
-        else:
-            polling_method = polling
+
+        if polling is True: polling_method = AsyncARMPolling(lro_delay, lro_options={'final-state-via': 'location'}, **kwargs)
+        elif polling is False: polling_method = AsyncNoPolling()
+        else: polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output,
+                deserialization_callback=get_long_running_output
             )
         return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    begin_delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{componentName}/versions/{version}"}  # type: ignore
 
     @distributed_trace_async
     async def get(
-        self, resource_group_name: str, registry_name: str, code_name: str, version: str, **kwargs: Any
-    ) -> "_models.CodeVersion":
+        self,
+        resource_group_name: str,
+        registry_name: str,
+        component_name: str,
+        version: str,
+        **kwargs: Any
+    ) -> "_models.ComponentVersion":
         """Get version.
 
         Get version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
+        :param component_name: Container name.
+        :type component_name: str
         :param version: Version identifier.
         :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: CodeVersion, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersion
+        :return: ComponentVersion, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentVersion
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersion"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        
         request = build_get_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            code_name=code_name,
+            component_name=component_name,
             version=version,
             api_version=api_version,
-            template_url=self.get.metadata["url"],
+            template_url=self.get.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize("CodeVersion", pipeline_response)
+        deserialized = self._deserialize('ComponentVersion', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{componentName}/versions/{version}"}  # type: ignore
+
 
     async def _create_or_update_initial(
         self,
         resource_group_name: str,
         registry_name: str,
-        code_name: str,
+        component_name: str,
         version: str,
-        body: "_models.CodeVersion",
+        body: "_models.ComponentVersion",
         **kwargs: Any
-    ) -> "_models.CodeVersion":
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+    ) -> "_models.ComponentVersion":
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersion"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, "CodeVersion")
+        _json = self._serialize.body(body, 'ComponentVersion')
 
         request = build_create_or_update_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            code_name=code_name,
+            component_name=component_name,
             version=version,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata["url"],
+            template_url=self._create_or_update_initial.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
         if response.status_code == 200:
-            deserialized = self._deserialize("CodeVersion", pipeline_response)
+            deserialized = self._deserialize('ComponentVersion', pipeline_response)
 
         if response.status_code == 201:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Azure-AsyncOperation"] = self._deserialize(
-                "str", response.headers.get("Azure-AsyncOperation")
-            )
-
-            deserialized = self._deserialize("CodeVersion", pipeline_response)
+            response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
+            response_headers['Azure-AsyncOperation']=self._deserialize('str', response.headers.get('Azure-AsyncOperation'))
+            
+            deserialized = self._deserialize('ComponentVersion', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{componentName}/versions/{version}"}  # type: ignore
+
 
     @distributed_trace_async
     async def begin_create_or_update(
         self,
         resource_group_name: str,
         registry_name: str,
-        code_name: str,
+        component_name: str,
         version: str,
-        body: "_models.CodeVersion",
+        body: "_models.ComponentVersion",
         **kwargs: Any
-    ) -> AsyncLROPoller["_models.CodeVersion"]:
+    ) -> AsyncLROPoller["_models.ComponentVersion"]:
         """Create or update version.
 
         Create or update version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
+        :param component_name: Container name.
+        :type component_name: str
         :param version: Version identifier.
         :type version: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersion
+        :type body: ~azure.mgmt.machinelearningservices.models.ComponentVersion
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be AsyncARMPolling. Pass in False for
          this operation to not poll, or pass in your own initialized polling object for a personal
          polling strategy.
         :paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of AsyncLROPoller that returns either CodeVersion or the result of
+        :return: An instance of AsyncLROPoller that returns either ComponentVersion or the result of
          cls(response)
         :rtype:
-         ~azure.core.polling.AsyncLROPoller[~azure.mgmt.machinelearningservices.models.CodeVersion]
+         ~azure.core.polling.AsyncLROPoller[~azure.mgmt.machinelearningservices.models.ComponentVersion]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
-        polling = kwargs.pop("polling", True)  # type: Union[bool, AsyncPollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
-        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
-        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        polling = kwargs.pop('polling', True)  # type: Union[bool, AsyncPollingMethod]
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ComponentVersion"]
+        lro_delay = kwargs.pop(
+            'polling_interval',
+            self._config.polling_interval
+        )
+        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
         if cont_token is None:
             raw_result = await self._create_or_update_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
-                code_name=code_name,
+                component_name=component_name,
                 version=version,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x, y, z: x,
+                cls=lambda x,y,z: x,
                 **kwargs
             )
-        kwargs.pop("error_map", None)
+        kwargs.pop('error_map', None)
 
         def get_long_running_output(pipeline_response):
             response = pipeline_response.http_response
-            deserialized = self._deserialize("CodeVersion", pipeline_response)
+            deserialized = self._deserialize('ComponentVersion', pipeline_response)
             if cls:
                 return cls(pipeline_response, deserialized, {})
             return deserialized
 
-        if polling is True:
-            polling_method = AsyncARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
-        elif polling is False:
-            polling_method = AsyncNoPolling()
-        else:
-            polling_method = polling
+
+        if polling is True: polling_method = AsyncARMPolling(lro_delay, lro_options={'final-state-via': 'original-uri'}, **kwargs)
+        elif polling is False: polling_method = AsyncNoPolling()
+        else: polling_method = polling
         if cont_token:
             return AsyncLROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output,
+                deserialization_callback=get_long_running_output
             )
         return AsyncLROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/components/{componentName}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/aio/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_endpoint_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_endpoint_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_environment_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_data_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_registry_model_containers_operations.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,21 +6,15 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import TYPE_CHECKING
 
 from msrest import Serializer
 
-from azure.core.exceptions import (
-    ClientAuthenticationError,
-    HttpResponseError,
-    ResourceExistsError,
-    ResourceNotFoundError,
-    map_error,
-)
+from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
@@ -28,40 +22,39 @@
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
     from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-
-    T = TypeVar("T")
+    T = TypeVar('T')
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
     skip = kwargs.pop('skip', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
+        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{2,32}$'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -83,28 +76,28 @@
     )
 
 
 def build_delete_request_initial(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
-    name,  # type: str
+    model_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "name": _SERIALIZER.url("name", name, 'str'),
+        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{2,32}$'),
+        "modelName": _SERIALIZER.url("model_name", model_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -122,28 +115,28 @@
     )
 
 
 def build_get_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
-    name,  # type: str
+    model_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "name": _SERIALIZER.url("name", name, 'str'),
+        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{2,32}$'),
+        "modelName": _SERIALIZER.url("model_name", model_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -161,29 +154,29 @@
     )
 
 
 def build_create_or_update_request_initial(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
-    name,  # type: str
+    model_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
+        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{2,32}$'),
+        "modelName": _SERIALIZER.url("model_name", model_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -199,16 +192,16 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 # fmt: on
-class RegistryDataContainersOperations(object):
-    """RegistryDataContainersOperations operations.
+class RegistryModelContainersOperations(object):
+    """RegistryModelContainersOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -230,57 +223,58 @@
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
         skip=None,  # type: Optional[str]
         list_view_type=None,  # type: Optional[Union[str, "_models.ListViewType"]]
         **kwargs  # type: Any
     ):
-        # type: (...) -> Iterable["_models.DataContainerResourceArmPaginatedResult"]
-        """List containers.
+        # type: (...) -> Iterable["_models.ModelContainerResourceArmPaginatedResult"]
+        """List model containers.
 
-        List containers.
+        List model containers.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
         :param skip: Continuation token for pagination.
         :type skip: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either DataContainerResourceArmPaginatedResult or the
+        :return: An iterator like instance of either ModelContainerResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
-         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.DataContainerResourceArmPaginatedResult]
+         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ModelContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainerResourceArmPaginatedResult"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainerResourceArmPaginatedResult"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skip=skip,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata["url"],
+                    template_url=self.list.metadata['url'],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
                     api_version=api_version,
                     skip=skip,
                     list_view_type=list_view_type,
@@ -288,345 +282,364 @@
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         def extract_data(pipeline_response):
-            deserialized = self._deserialize("DataContainerResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("ModelContainerResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request, stream=False, **kwargs
+                request,
+                stream=False,
+                **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
-        return ItemPaged(get_next, extract_data)
 
-    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data"}  # type: ignore
+        return ItemPaged(
+            get_next, extract_data
+        )
+    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models"}  # type: ignore
 
     def _delete_initial(  # pylint: disable=inconsistent-return-statements
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
-        name,  # type: str
+        model_name,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType[None]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        
         request = build_delete_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            name=name,
+            model_name=model_name,
             api_version=api_version,
-            template_url=self._delete_initial.metadata["url"],
+            template_url=self._delete_initial.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 202, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
         if response.status_code == 202:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
-            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
+            response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
+            response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
+            response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
+            
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
+    _delete_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}"}  # type: ignore
+
 
     @distributed_trace
     def begin_delete(  # pylint: disable=inconsistent-return-statements
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
-        name,  # type: str
+        model_name,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> LROPoller[None]
         """Delete container.
 
         Delete container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
-        :param name: Container name.
-        :type name: str
+        :param model_name: Container name.
+        :type model_name: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
         :return: An instance of LROPoller that returns either None or the result of cls(response)
         :rtype: ~azure.core.polling.LROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
-        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop('cls', None)  # type: ClsType[None]
+        lro_delay = kwargs.pop(
+            'polling_interval',
+            self._config.polling_interval
+        )
+        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._delete_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
-                name=name,
+                model_name=model_name,
                 api_version=api_version,
-                cls=lambda x, y, z: x,
+                cls=lambda x,y,z: x,
                 **kwargs
             )
-        kwargs.pop("error_map", None)
+        kwargs.pop('error_map', None)
 
         def get_long_running_output(pipeline_response):
             if cls:
                 return cls(pipeline_response, None, {})
 
-        if polling is True:
-            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
-        elif polling is False:
-            polling_method = NoPolling()
-        else:
-            polling_method = polling
+
+        if polling is True: polling_method = ARMPolling(lro_delay, lro_options={'final-state-via': 'location'}, **kwargs)
+        elif polling is False: polling_method = NoPolling()
+        else: polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output,
+                deserialization_callback=get_long_running_output
             )
         return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
+    begin_delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
-        name,  # type: str
+        model_name,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.DataContainer"
+        # type: (...) -> "_models.ModelContainer"
         """Get container.
 
         Get container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
-        :param name: Container name.
-        :type name: str
+        :param model_name: Container name. This is case-sensitive.
+        :type model_name: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: DataContainer, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.DataContainer
+        :return: ModelContainer, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ModelContainer
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainer"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainer"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        
         request = build_get_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            name=name,
+            model_name=model_name,
             api_version=api_version,
-            template_url=self.get.metadata["url"],
+            template_url=self.get.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize("DataContainer", pipeline_response)
+        deserialized = self._deserialize('ModelContainer', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
+    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}"}  # type: ignore
+
 
     def _create_or_update_initial(
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
-        name,  # type: str
-        body,  # type: "_models.DataContainer"
+        model_name,  # type: str
+        body,  # type: "_models.ModelContainer"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.DataContainer"
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainer"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        # type: (...) -> "_models.ModelContainer"
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainer"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, "DataContainer")
+        _json = self._serialize.body(body, 'ModelContainer')
 
         request = build_create_or_update_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            name=name,
+            model_name=model_name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata["url"],
+            template_url=self._create_or_update_initial.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
         if response.status_code == 200:
-            deserialized = self._deserialize("DataContainer", pipeline_response)
+            deserialized = self._deserialize('ModelContainer', pipeline_response)
 
         if response.status_code == 201:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Azure-AsyncOperation"] = self._deserialize(
-                "str", response.headers.get("Azure-AsyncOperation")
-            )
-
-            deserialized = self._deserialize("DataContainer", pipeline_response)
+            response_headers['x-ms-async-operation-timeout']=self._deserialize('duration', response.headers.get('x-ms-async-operation-timeout'))
+            response_headers['Azure-AsyncOperation']=self._deserialize('str', response.headers.get('Azure-AsyncOperation'))
+            
+            deserialized = self._deserialize('ModelContainer', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
+    _create_or_update_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}"}  # type: ignore
+
 
     @distributed_trace
     def begin_create_or_update(
         self,
         resource_group_name,  # type: str
         registry_name,  # type: str
-        name,  # type: str
-        body,  # type: "_models.DataContainer"
+        model_name,  # type: str
+        body,  # type: "_models.ModelContainer"
         **kwargs  # type: Any
     ):
-        # type: (...) -> LROPoller["_models.DataContainer"]
-        """Create or update container.
+        # type: (...) -> LROPoller["_models.ModelContainer"]
+        """Create or update model container.
 
-        Create or update container.
+        Create or update model container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
+        :param registry_name: Name of Azure Machine Learning registry. This is case-insensitive.
         :type registry_name: str
-        :param name: Container name.
-        :type name: str
+        :param model_name: Container name.
+        :type model_name: str
         :param body: Container entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.DataContainer
+        :type body: ~azure.mgmt.machinelearningservices.models.ModelContainer
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of LROPoller that returns either DataContainer or the result of
+        :return: An instance of LROPoller that returns either ModelContainer or the result of
          cls(response)
-        :rtype: ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.DataContainer]
+        :rtype:
+         ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.ModelContainer]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
-        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.DataContainer"]
-        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
-        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelContainer"]
+        lro_delay = kwargs.pop(
+            'polling_interval',
+            self._config.polling_interval
+        )
+        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
-                name=name,
+                model_name=model_name,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x, y, z: x,
+                cls=lambda x,y,z: x,
                 **kwargs
             )
-        kwargs.pop("error_map", None)
+        kwargs.pop('error_map', None)
 
         def get_long_running_output(pipeline_response):
             response = pipeline_response.http_response
-            deserialized = self._deserialize("DataContainer", pipeline_response)
+            deserialized = self._deserialize('ModelContainer', pipeline_response)
             if cls:
                 return cls(pipeline_response, deserialized, {})
             return deserialized
 
-        if polling is True:
-            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
-        elif polling is False:
-            polling_method = NoPolling()
-        else:
-            polling_method = polling
+
+        if polling is True: polling_method = ARMPolling(lro_delay, lro_options={'final-state-via': 'original-uri'}, **kwargs)
+        elif polling is False: polling_method = NoPolling()
+        else: polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output,
+                deserialization_callback=get_long_running_output
             )
         return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/data/{name}"}  # type: ignore
+    begin_create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_datastores_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_datastores_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registries_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registries_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_environment_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_schedules_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_schedules_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_online_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_quotas_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_quotas_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_usages_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_usages_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_model_versions_operations.py`

 * *Files 7% similar despite different names*

```diff
@@ -6,21 +6,15 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import TYPE_CHECKING
 
 from msrest import Serializer
 
-from azure.core.exceptions import (
-    ClientAuthenticationError,
-    HttpResponseError,
-    ResourceExistsError,
-    ResourceNotFoundError,
-    map_error,
-)
+from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
@@ -28,48 +22,50 @@
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
     from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-
-    T = TypeVar("T")
+    T = TypeVar('T')
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
-    model_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
     skip = kwargs.pop('skip', None)  # type: Optional[str]
     order_by = kwargs.pop('order_by', None)  # type: Optional[str]
     top = kwargs.pop('top', None)  # type: Optional[int]
     version = kwargs.pop('version', None)  # type: Optional[str]
     description = kwargs.pop('description', None)  # type: Optional[str]
+    offset = kwargs.pop('offset', None)  # type: Optional[int]
     tags = kwargs.pop('tags', None)  # type: Optional[str]
     properties = kwargs.pop('properties', None)  # type: Optional[str]
+    feed = kwargs.pop('feed', None)  # type: Optional[str]
     list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
+    stage = kwargs.pop('stage', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "modelName": _SERIALIZER.url("model_name", model_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
+        "name": _SERIALIZER.url("name", name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
@@ -79,53 +75,59 @@
         _query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
     if top is not None:
         _query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
     if version is not None:
         _query_parameters['version'] = _SERIALIZER.query("version", version, 'str')
     if description is not None:
         _query_parameters['description'] = _SERIALIZER.query("description", description, 'str')
+    if offset is not None:
+        _query_parameters['offset'] = _SERIALIZER.query("offset", offset, 'int')
     if tags is not None:
         _query_parameters['tags'] = _SERIALIZER.query("tags", tags, 'str')
     if properties is not None:
         _query_parameters['properties'] = _SERIALIZER.query("properties", properties, 'str')
+    if feed is not None:
+        _query_parameters['feed'] = _SERIALIZER.query("feed", feed, 'str')
     if list_view_type is not None:
         _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
+    if stage is not None:
+        _query_parameters['stage'] = _SERIALIZER.query("stage", stage, 'str')
 
     # Construct headers
     _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
-def build_delete_request_initial(
+def build_delete_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
-    model_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
     version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "modelName": _SERIALIZER.url("model_name", model_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
+        "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
@@ -143,30 +145,30 @@
         **kwargs
     )
 
 
 def build_get_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
-    model_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
     version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "modelName": _SERIALIZER.url("model_name", model_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
+        "name": _SERIALIZER.url("name", name, 'str'),
         "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
@@ -181,34 +183,34 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 
-def build_create_or_update_request_initial(
+def build_create_or_update_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
-    registry_name,  # type: str
-    model_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
     version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "modelName": _SERIALIZER.url("model_name", model_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
+        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
         "version": _SERIALIZER.url("version", version, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
@@ -224,17 +226,61 @@
         method="PUT",
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
+
+def build_package_request_initial(
+    subscription_id,  # type: str
+    resource_group_name,  # type: str
+    workspace_name,  # type: str
+    name,  # type: str
+    version,  # type: str
+    **kwargs  # type: Any
+):
+    # type: (...) -> HttpRequest
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
+
+    accept = "application/json"
+    # Construct URL
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}/package")  # pylint: disable=line-too-long
+    path_format_arguments = {
+        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
+        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
+        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
+        "version": _SERIALIZER.url("version", version, 'str'),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+
+    # Construct headers
+    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    if content_type is not None:
+        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+
+    return HttpRequest(
+        method="POST",
+        url=_url,
+        params=_query_parameters,
+        headers=_header_parameters,
+        **kwargs
+    )
+
 # fmt: on
-class RegistryModelVersionsOperations(object):
-    """RegistryModelVersionsOperations operations.
+class ModelVersionsOperations(object):
+    """ModelVersionsOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -251,106 +297,122 @@
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
         self,
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        model_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
         skip=None,  # type: Optional[str]
         order_by=None,  # type: Optional[str]
         top=None,  # type: Optional[int]
         version=None,  # type: Optional[str]
         description=None,  # type: Optional[str]
+        offset=None,  # type: Optional[int]
         tags=None,  # type: Optional[str]
         properties=None,  # type: Optional[str]
+        feed=None,  # type: Optional[str]
         list_view_type=None,  # type: Optional[Union[str, "_models.ListViewType"]]
+        stage=None,  # type: Optional[str]
         **kwargs  # type: Any
     ):
         # type: (...) -> Iterable["_models.ModelVersionResourceArmPaginatedResult"]
-        """List versions.
+        """List model versions.
 
-        List versions.
+        List model versions.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :param model_name: Container name. This is case-sensitive.
-        :type model_name: str
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Model name. This is case-sensitive.
+        :type name: str
         :param skip: Continuation token for pagination.
         :type skip: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
-        :param version: Version identifier.
+        :param version: Model version.
         :type version: str
         :param description: Model description.
         :type description: str
+        :param offset: Number of initial results to skip.
+        :type offset: int
         :param tags: Comma-separated list of tag names (and optionally values). Example:
          tag1,tag2=value2.
         :type tags: str
         :param properties: Comma-separated list of property names (and optionally values). Example:
          prop1,prop2=value2.
         :type properties: str
+        :param feed: Name of the feed.
+        :type feed: str
         :param list_view_type: View type for including/excluding (for example) archived entities.
         :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
+        :param stage: Model stage.
+        :type stage: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either ModelVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ModelVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersionResourceArmPaginatedResult"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelVersionResourceArmPaginatedResult"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
-                    registry_name=registry_name,
-                    model_name=model_name,
+                    workspace_name=workspace_name,
+                    name=name,
                     api_version=api_version,
                     skip=skip,
                     order_by=order_by,
                     top=top,
                     version=version,
                     description=description,
+                    offset=offset,
                     tags=tags,
                     properties=properties,
+                    feed=feed,
                     list_view_type=list_view_type,
-                    template_url=self.list.metadata["url"],
+                    stage=stage,
+                    template_url=self.list.metadata['url'],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
-                    registry_name=registry_name,
-                    model_name=model_name,
+                    workspace_name=workspace_name,
+                    name=name,
                     api_version=api_version,
                     skip=skip,
                     order_by=order_by,
                     top=top,
                     version=version,
                     description=description,
+                    offset=offset,
                     tags=tags,
                     properties=properties,
+                    feed=feed,
                     list_view_type=list_view_type,
+                    stage=stage,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
@@ -361,351 +423,390 @@
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request, stream=False, **kwargs
+                request,
+                stream=False,
+                **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
-        return ItemPaged(get_next, extract_data)
 
-    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions"}  # type: ignore
+        return ItemPaged(
+            get_next, extract_data
+        )
+    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions"}  # type: ignore
 
-    def _delete_initial(  # pylint: disable=inconsistent-return-statements
+    @distributed_trace
+    def delete(  # pylint: disable=inconsistent-return-statements
         self,
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        model_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
         version,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        """Delete version.
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        Delete version.
 
-        request = build_delete_request_initial(
+        :param resource_group_name: The name of the resource group. The name is case insensitive.
+        :type resource_group_name: str
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Container name. This is case-sensitive.
+        :type name: str
+        :param version: Version identifier. This is case-sensitive.
+        :type version: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None, or the result of cls(response)
+        :rtype: None
+        :raises: ~azure.core.exceptions.HttpResponseError
+        """
+        cls = kwargs.pop('cls', None)  # type: ClsType[None]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
+
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+
+        
+        request = build_delete_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
-            registry_name=registry_name,
-            model_name=model_name,
+            workspace_name=workspace_name,
+            name=name,
             version=version,
             api_version=api_version,
-            template_url=self._delete_initial.metadata["url"],
+            template_url=self.delete.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 202, 204]:
+        if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
-            raise HttpResponseError(response=response, error_format=ARMErrorFormat)
-
-        response_headers = {}
-        if response.status_code == 202:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
-            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
+            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
+            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, None, {})
+
+    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}"}  # type: ignore
 
-    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
     @distributed_trace
-    def begin_delete(  # pylint: disable=inconsistent-return-statements
+    def get(
         self,
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        model_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
         version,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> LROPoller[None]
-        """Delete version.
+        # type: (...) -> "_models.ModelVersion"
+        """Get version.
 
-        Delete version.
+        Get version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :param model_name: Container name.
-        :type model_name: str
-        :param version: Version identifier.
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Container name. This is case-sensitive.
+        :type name: str
+        :param version: Version identifier. This is case-sensitive.
         :type version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
-        :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
-         operation to not poll, or pass in your own initialized polling object for a personal polling
-         strategy.
-        :paramtype polling: bool or ~azure.core.polling.PollingMethod
-        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
-         Retry-After header is present.
-        :return: An instance of LROPoller that returns either None or the result of cls(response)
-        :rtype: ~azure.core.polling.LROPoller[None]
+        :return: ModelVersion, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.ModelVersion
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
-        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
-        if cont_token is None:
-            raw_result = self._delete_initial(
-                resource_group_name=resource_group_name,
-                registry_name=registry_name,
-                model_name=model_name,
-                version=version,
-                api_version=api_version,
-                cls=lambda x, y, z: x,
-                **kwargs
-            )
-        kwargs.pop("error_map", None)
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelVersion"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        def get_long_running_output(pipeline_response):
-            if cls:
-                return cls(pipeline_response, None, {})
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
-        if polling is True:
-            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
-        elif polling is False:
-            polling_method = NoPolling()
-        else:
-            polling_method = polling
-        if cont_token:
-            return LROPoller.from_continuation_token(
-                polling_method=polling_method,
-                continuation_token=cont_token,
-                client=self._client,
-                deserialization_callback=get_long_running_output,
-            )
-        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        
+        request = build_get_request(
+            subscription_id=self._config.subscription_id,
+            resource_group_name=resource_group_name,
+            workspace_name=workspace_name,
+            name=name,
+            version=version,
+            api_version=api_version,
+            template_url=self.get.metadata['url'],
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)
+
+        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
+            request,
+            stream=False,
+            **kwargs
+        )
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
+            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
+
+        deserialized = self._deserialize('ModelVersion', pipeline_response)
+
+        if cls:
+            return cls(pipeline_response, deserialized, {})
+
+        return deserialized
+
+    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}"}  # type: ignore
 
-    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
 
     @distributed_trace
-    def get(
+    def create_or_update(
         self,
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        model_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
         version,  # type: str
+        body,  # type: "_models.ModelVersion"
         **kwargs  # type: Any
     ):
         # type: (...) -> "_models.ModelVersion"
-        """Get version.
+        """Create or update version.
 
-        Get version.
+        Create or update version.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :param model_name: Container name. This is case-sensitive.
-        :type model_name: str
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Container name. This is case-sensitive.
+        :type name: str
         :param version: Version identifier. This is case-sensitive.
         :type version: str
+        :param body: Version entity to create or update.
+        :type body: ~azure.mgmt.machinelearningservices.models.ModelVersion
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: ModelVersion, or the result of cls(response)
         :rtype: ~azure.mgmt.machinelearningservices.models.ModelVersion
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ModelVersion"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
 
-        request = build_get_request(
+        _json = self._serialize.body(body, 'ModelVersion')
+
+        request = build_create_or_update_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
-            registry_name=registry_name,
-            model_name=model_name,
+            workspace_name=workspace_name,
+            name=name,
             version=version,
             api_version=api_version,
-            template_url=self.get.metadata["url"],
+            content_type=content_type,
+            json=_json,
+            template_url=self.create_or_update.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize("ModelVersion", pipeline_response)
+        if response.status_code == 200:
+            deserialized = self._deserialize('ModelVersion', pipeline_response)
+
+        if response.status_code == 201:
+            deserialized = self._deserialize('ModelVersion', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}"}  # type: ignore
 
-    def _create_or_update_initial(
+
+    def _package_initial(
         self,
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        model_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
         version,  # type: str
-        body,  # type: "_models.ModelVersion"
+        body,  # type: "_models.PackageRequest"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ModelVersion"
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        # type: (...) -> Optional["_models.PackageResponse"]
+        cls = kwargs.pop('cls', None)  # type: ClsType[Optional["_models.PackageResponse"]]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, "ModelVersion")
+        _json = self._serialize.body(body, 'PackageRequest')
 
-        request = build_create_or_update_request_initial(
+        request = build_package_request_initial(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
-            registry_name=registry_name,
-            model_name=model_name,
+            workspace_name=workspace_name,
+            name=name,
             version=version,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self._create_or_update_initial.metadata["url"],
+            template_url=self._package_initial.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 201]:
+        if response.status_code not in [200, 202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
+        deserialized = None
         response_headers = {}
         if response.status_code == 200:
-            deserialized = self._deserialize("ModelVersion", pipeline_response)
-
-        if response.status_code == 201:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Azure-AsyncOperation"] = self._deserialize(
-                "str", response.headers.get("Azure-AsyncOperation")
-            )
+            deserialized = self._deserialize('PackageResponse', pipeline_response)
 
-            deserialized = self._deserialize("ModelVersion", pipeline_response)
+        if response.status_code == 202:
+            response_headers['Location']=self._deserialize('str', response.headers.get('Location'))
+            response_headers['Retry-After']=self._deserialize('int', response.headers.get('Retry-After'))
+            
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    _package_initial.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}/package"}  # type: ignore
+
 
     @distributed_trace
-    def begin_create_or_update(
+    def begin_package(
         self,
         resource_group_name,  # type: str
-        registry_name,  # type: str
-        model_name,  # type: str
+        workspace_name,  # type: str
+        name,  # type: str
         version,  # type: str
-        body,  # type: "_models.ModelVersion"
+        body,  # type: "_models.PackageRequest"
         **kwargs  # type: Any
     ):
-        # type: (...) -> LROPoller["_models.ModelVersion"]
-        """Create or update version.
+        # type: (...) -> LROPoller["_models.PackageResponse"]
+        """Model Version Package operation.
 
-        Create or update version.
+        Model Version Package operation.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :param model_name: Container name.
-        :type model_name: str
-        :param version: Version identifier.
+        :param workspace_name: Name of Azure Machine Learning workspace.
+        :type workspace_name: str
+        :param name: Container name. This is case-sensitive.
+        :type name: str
+        :param version: Version identifier. This is case-sensitive.
         :type version: str
-        :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ModelVersion
+        :param body: Package operation request body.
+        :type body: ~azure.mgmt.machinelearningservices.models.PackageRequest
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of LROPoller that returns either ModelVersion or the result of
+        :return: An instance of LROPoller that returns either PackageResponse or the result of
          cls(response)
-        :rtype: ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.ModelVersion]
+        :rtype:
+         ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.PackageResponse]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
-        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ModelVersion"]
-        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
-        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
+        polling = kwargs.pop('polling', True)  # type: Union[bool, PollingMethod]
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.PackageResponse"]
+        lro_delay = kwargs.pop(
+            'polling_interval',
+            self._config.polling_interval
+        )
+        cont_token = kwargs.pop('continuation_token', None)  # type: Optional[str]
         if cont_token is None:
-            raw_result = self._create_or_update_initial(
+            raw_result = self._package_initial(
                 resource_group_name=resource_group_name,
-                registry_name=registry_name,
-                model_name=model_name,
+                workspace_name=workspace_name,
+                name=name,
                 version=version,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
-                cls=lambda x, y, z: x,
+                cls=lambda x,y,z: x,
                 **kwargs
             )
-        kwargs.pop("error_map", None)
+        kwargs.pop('error_map', None)
 
         def get_long_running_output(pipeline_response):
             response = pipeline_response.http_response
-            deserialized = self._deserialize("ModelVersion", pipeline_response)
+            deserialized = self._deserialize('PackageResponse', pipeline_response)
             if cls:
                 return cls(pipeline_response, deserialized, {})
             return deserialized
 
-        if polling is True:
-            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
-        elif polling is False:
-            polling_method = NoPolling()
-        else:
-            polling_method = polling
+
+        if polling is True: polling_method = ARMPolling(lro_delay, lro_options={'final-state-via': 'location'}, **kwargs)
+        elif polling is False: polling_method = NoPolling()
+        else: polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
-                deserialization_callback=get_long_running_output,
+                deserialization_callback=get_long_running_output
             )
         return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/models/{modelName}/versions/{version}"}  # type: ignore
+    begin_package.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/models/{name}/versions/{version}/package"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_component_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_06_01_preview/operations/_code_containers_operations.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,71 +6,61 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 from typing import TYPE_CHECKING
 
 from msrest import Serializer
 
-from azure.core.exceptions import (
-    ClientAuthenticationError,
-    HttpResponseError,
-    ResourceExistsError,
-    ResourceNotFoundError,
-    map_error,
-)
+from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
-
-    T = TypeVar("T")
+    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar
+    T = TypeVar('T')
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
     skip = kwargs.pop('skip', None)  # type: Optional[str]
-    list_view_type = kwargs.pop('list_view_type', None)  # type: Optional[Union[str, "_models.ListViewType"]]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if skip is not None:
         _query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
-    if list_view_type is not None:
-        _query_parameters['listViewType'] = _SERIALIZER.query("list_view_type", list_view_type, 'str')
 
     # Construct headers
     _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
@@ -85,23 +75,23 @@
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
     name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
         "name": _SERIALIZER.url("name", name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
@@ -124,23 +114,23 @@
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
     name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
         "name": _SERIALIZER.url("name", name, 'str'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
@@ -163,24 +153,24 @@
     subscription_id,  # type: str
     resource_group_name,  # type: str
     workspace_name,  # type: str
     name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}")  # pylint: disable=line-too-long
+    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes/{name}")  # pylint: disable=line-too-long
     path_format_arguments = {
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
-        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str'),
+        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9_-]{2,32}$'),
         "name": _SERIALIZER.url("name", name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
@@ -197,16 +187,16 @@
         url=_url,
         params=_query_parameters,
         headers=_header_parameters,
         **kwargs
     )
 
 # fmt: on
-class ComponentContainersOperations(object):
-    """ComponentContainersOperations operations.
+class CodeContainersOperations(object):
+    """CodeContainersOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -225,99 +215,99 @@
 
     @distributed_trace
     def list(
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
         skip=None,  # type: Optional[str]
-        list_view_type=None,  # type: Optional[Union[str, "_models.ListViewType"]]
         **kwargs  # type: Any
     ):
-        # type: (...) -> Iterable["_models.ComponentContainerResourceArmPaginatedResult"]
-        """List component containers.
+        # type: (...) -> Iterable["_models.CodeContainerResourceArmPaginatedResult"]
+        """List containers.
 
-        List component containers.
+        List containers.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
         :param skip: Continuation token for pagination.
         :type skip: str
-        :param list_view_type: View type for including/excluding (for example) archived entities.
-        :type list_view_type: str or ~azure.mgmt.machinelearningservices.models.ListViewType
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: An iterator like instance of either ComponentContainerResourceArmPaginatedResult or
-         the result of cls(response)
+        :return: An iterator like instance of either CodeContainerResourceArmPaginatedResult or the
+         result of cls(response)
         :rtype:
-         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.ComponentContainerResourceArmPaginatedResult]
+         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.CodeContainerResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainerResourceArmPaginatedResult"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainerResourceArmPaginatedResult"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
         def prepare_request(next_link=None):
             if not next_link:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     workspace_name=workspace_name,
                     api_version=api_version,
                     skip=skip,
-                    list_view_type=list_view_type,
-                    template_url=self.list.metadata["url"],
+                    template_url=self.list.metadata['url'],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
-
+                
                 request = build_list_request(
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     workspace_name=workspace_name,
                     api_version=api_version,
                     skip=skip,
-                    list_view_type=list_view_type,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
         def extract_data(pipeline_response):
-            deserialized = self._deserialize("ComponentContainerResourceArmPaginatedResult", pipeline_response)
+            deserialized = self._deserialize("CodeContainerResourceArmPaginatedResult", pipeline_response)
             list_of_elem = deserialized.value
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
             pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request, stream=False, **kwargs
+                request,
+                stream=False,
+                **kwargs
             )
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
-        return ItemPaged(get_next, extract_data)
 
-    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components"}  # type: ignore
+        return ItemPaged(
+            get_next, extract_data
+        )
+    list.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes"}  # type: ignore
 
     @distributed_trace
     def delete(  # pylint: disable=inconsistent-return-statements
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
         name,  # type: str
@@ -328,177 +318,194 @@
 
         Delete container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
-        :param name: Container name.
+        :param name: Container name. This is case-sensitive.
         :type name: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None, or the result of cls(response)
         :rtype: None
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType[None]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        
         request = build_delete_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             workspace_name=workspace_name,
             name=name,
             api_version=api_version,
-            template_url=self.delete.metadata["url"],
+            template_url=self.delete.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
             return cls(pipeline_response, None, {})
 
-    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}"}  # type: ignore
+    delete.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes/{name}"}  # type: ignore
+
 
     @distributed_trace
     def get(
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
         name,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ComponentContainer"
+        # type: (...) -> "_models.CodeContainer"
         """Get container.
 
         Get container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
-        :param name: Container name.
+        :param name: Container name. This is case-sensitive.
         :type name: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ComponentContainer, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainer
+        :return: CodeContainer, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainer
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainer"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainer"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
 
+        
         request = build_get_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             workspace_name=workspace_name,
             name=name,
             api_version=api_version,
-            template_url=self.get.metadata["url"],
+            template_url=self.get.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize("ComponentContainer", pipeline_response)
+        deserialized = self._deserialize('CodeContainer', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}"}  # type: ignore
+    get.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes/{name}"}  # type: ignore
+
 
     @distributed_trace
     def create_or_update(
         self,
         resource_group_name,  # type: str
         workspace_name,  # type: str
         name,  # type: str
-        body,  # type: "_models.ComponentContainer"
+        body,  # type: "_models.CodeContainer"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.ComponentContainer"
+        # type: (...) -> "_models.CodeContainer"
         """Create or update container.
 
         Create or update container.
 
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param workspace_name: Name of Azure Machine Learning workspace.
         :type workspace_name: str
-        :param name: Container name.
+        :param name: Container name. This is case-sensitive.
         :type name: str
         :param body: Container entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.ComponentContainer
+        :type body: ~azure.mgmt.machinelearningservices.models.CodeContainer
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ComponentContainer, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.ComponentContainer
+        :return: CodeContainer, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeContainer
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.ComponentContainer"]
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}))
+        cls = kwargs.pop('cls', None)  # type: ClsType["_models.CodeContainer"]
+        error_map = {
+            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
+        }
+        error_map.update(kwargs.pop('error_map', {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
+        api_version = kwargs.pop('api_version', "2023-06-01-preview")  # type: str
+        content_type = kwargs.pop('content_type', "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, "ComponentContainer")
+        _json = self._serialize.body(body, 'CodeContainer')
 
         request = build_create_or_update_request(
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             workspace_name=workspace_name,
             name=name,
             api_version=api_version,
             content_type=content_type,
             json=_json,
-            template_url=self.create_or_update.metadata["url"],
+            template_url=self.create_or_update.metadata['url'],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request,
+            stream=False,
+            **kwargs
         )
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if response.status_code == 200:
-            deserialized = self._deserialize("ComponentContainer", pipeline_response)
+            deserialized = self._deserialize('CodeContainer', pipeline_response)
 
         if response.status_code == 201:
-            deserialized = self._deserialize("ComponentContainer", pipeline_response)
+            deserialized = self._deserialize('CodeContainer', pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/components/{name}"}  # type: ignore
+    create_or_update.metadata = {'url': "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/codes/{name}"}  # type: ignore
+
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featureset_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_endpoints_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_batch_endpoints_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_features_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspace_features_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_virtual_machine_sizes_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_virtual_machine_sizes_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_containers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_featurestore_entity_containers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_labeling_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_labeling_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_data_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_link_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_private_link_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_jobs_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_jobs_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_code_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_code_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2021_10_01_dataplanepreview/operations/_code_versions_operations.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# pylint: disable=too-many-lines
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
+import functools
 from typing import TYPE_CHECKING
-
-from msrest import Serializer
+import warnings
 
 from azure.core.exceptions import (
     ClientAuthenticationError,
     HttpResponseError,
     ResourceExistsError,
     ResourceNotFoundError,
     map_error,
@@ -21,205 +20,206 @@
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.polling import LROPoller, NoPolling, PollingMethod
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.mgmt.core.exceptions import ARMErrorFormat
 from azure.mgmt.core.polling.arm_polling import ARMPolling
+from msrest import Serializer
 
 from .. import models as _models
 from .._vendor import _convert_request, _format_url_section
 
 if TYPE_CHECKING:
     # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, Iterable, Optional, TypeVar, Union
+    from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar, Union
 
     T = TypeVar("T")
     ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 # fmt: off
 
 def build_list_request(
+    name,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
-    code_name,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     order_by = kwargs.pop('order_by', None)  # type: Optional[str]
     top = kwargs.pop('top', None)  # type: Optional[int]
-    skip = kwargs.pop('skip', None)  # type: Optional[str]
+    skiptoken = kwargs.pop('skiptoken', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions')
     path_format_arguments = {
+        "name": _SERIALIZER.url("name", name, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "codeName": _SERIALIZER.url("code_name", code_name, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
     if order_by is not None:
-        _query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
+        query_parameters['$orderBy'] = _SERIALIZER.query("order_by", order_by, 'str')
     if top is not None:
-        _query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
-    if skip is not None:
-        _query_parameters['$skip'] = _SERIALIZER.query("skip", skip, 'str')
+        query_parameters['$top'] = _SERIALIZER.query("top", top, 'int')
+    if skiptoken is not None:
+        query_parameters['$skiptoken'] = _SERIALIZER.query("skiptoken", skiptoken, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
-def build_delete_request_initial(
+def build_delete_request(
+    name,  # type: str
+    version,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
-    code_name,  # type: str
-    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}')
     path_format_arguments = {
+        "name": _SERIALIZER.url("name", name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "codeName": _SERIALIZER.url("code_name", code_name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_get_request(
+    name,  # type: str
+    version,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
-    code_name,  # type: str
-    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}')
     path_format_arguments = {
+        "name": _SERIALIZER.url("name", name, 'str'),
+        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "codeName": _SERIALIZER.url("code_name", code_name, 'str'),
-        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 
 def build_create_or_update_request_initial(
+    name,  # type: str
+    version,  # type: str
     subscription_id,  # type: str
     resource_group_name,  # type: str
     registry_name,  # type: str
-    code_name,  # type: str
-    version,  # type: str
     **kwargs  # type: Any
 ):
     # type: (...) -> HttpRequest
-    api_version = kwargs.pop('api_version', "2023-02-01-preview")  # type: str
+    api_version = kwargs.pop('api_version', "2021-10-01-dataplanepreview")  # type: str
     content_type = kwargs.pop('content_type', None)  # type: Optional[str]
 
     accept = "application/json"
     # Construct URL
-    _url = kwargs.pop("template_url", "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}")  # pylint: disable=line-too-long
+    url = kwargs.pop("template_url", '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}')
     path_format_arguments = {
+        "name": _SERIALIZER.url("name", name, 'str', pattern=r'^(?![\-_.])[a-zA-Z0-9\-_.]{1,255}(?<!\.)$'),
+        "version": _SERIALIZER.url("version", version, 'str'),
         "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, 'str', min_length=1),
         "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, 'str', max_length=90, min_length=1),
         "registryName": _SERIALIZER.url("registry_name", registry_name, 'str'),
-        "codeName": _SERIALIZER.url("code_name", code_name, 'str', pattern=r'^[a-zA-Z0-9][a-zA-Z0-9\-_]{0,254}$'),
-        "version": _SERIALIZER.url("version", version, 'str'),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    url = _format_url_section(url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
+    query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    query_parameters['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
+    header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
 
     return HttpRequest(
         method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
+        url=url,
+        params=query_parameters,
+        headers=header_parameters,
         **kwargs
     )
 
 # fmt: on
-class RegistryCodeVersionsOperations(object):
-    """RegistryCodeVersionsOperations operations.
+class CodeVersionsOperations(object):
+    """CodeVersionsOperations operations.
 
     You should not instantiate this class directly. Instead, you should create a Client instance that
     instantiates it for you and attaches it as an attribute.
 
     :ivar models: Alias to model classes used in this operation group.
     :type models: ~azure.mgmt.machinelearningservices.models
     :param client: Client for service requests.
@@ -235,80 +235,83 @@
         self._serialize = serializer
         self._deserialize = deserializer
         self._config = config
 
     @distributed_trace
     def list(
         self,
+        name,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        code_name,  # type: str
         order_by=None,  # type: Optional[str]
         top=None,  # type: Optional[int]
-        skip=None,  # type: Optional[str]
+        skiptoken=None,  # type: Optional[str]
         **kwargs  # type: Any
     ):
         # type: (...) -> Iterable["_models.CodeVersionResourceArmPaginatedResult"]
         """List versions.
 
         List versions.
 
+        :param name: Container name.
+        :type name: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
         :param order_by: Ordering of list.
         :type order_by: str
         :param top: Maximum number of records to return.
         :type top: int
-        :param skip: Continuation token for pagination.
-        :type skip: str
+        :param skiptoken: Continuation token for pagination.
+        :type skiptoken: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: An iterator like instance of either CodeVersionResourceArmPaginatedResult or the
          result of cls(response)
         :rtype:
          ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.CodeVersionResourceArmPaginatedResult]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
         cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersionResourceArmPaginatedResult"]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
         def prepare_request(next_link=None):
             if not next_link:
 
                 request = build_list_request(
+                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
-                    code_name=code_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
-                    skip=skip,
+                    skiptoken=skiptoken,
                     template_url=self.list.metadata["url"],
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
 
             else:
 
                 request = build_list_request(
+                    name=name,
                     subscription_id=self._config.subscription_id,
                     resource_group_name=resource_group_name,
                     registry_name=registry_name,
-                    code_name=code_name,
                     api_version=api_version,
                     order_by=order_by,
                     top=top,
-                    skip=skip,
+                    skiptoken=skiptoken,
                     template_url=next_link,
                 )
                 request = _convert_request(request)
                 request.url = self._client.format_url(request.url)
                 request.method = "GET"
             return request
 
@@ -318,352 +321,280 @@
             if cls:
                 list_of_elem = cls(list_of_elem)
             return deserialized.next_link or None, iter(list_of_elem)
 
         def get_next(next_link=None):
             request = prepare_request(next_link)
 
-            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-                request, stream=False, **kwargs
-            )
+            pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
             response = pipeline_response.http_response
 
             if response.status_code not in [200]:
                 map_error(status_code=response.status_code, response=response, error_map=error_map)
                 error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                 raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
             return pipeline_response
 
         return ItemPaged(get_next, extract_data)
 
-    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions"}  # type: ignore
+    list.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions"}  # type: ignore
 
-    def _delete_initial(  # pylint: disable=inconsistent-return-statements
+    @distributed_trace
+    def delete(
         self,
+        name,  # type: str
+        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        code_name,  # type: str
-        version,  # type: str
         **kwargs  # type: Any
     ):
         # type: (...) -> None
+        """Delete version.
+
+        Delete version.
+
+        :param name: Container name.
+        :type name: str
+        :param version: Version identifier.
+        :type version: str
+        :param resource_group_name: The name of the resource group. The name is case insensitive.
+        :type resource_group_name: str
+        :param registry_name: Name of Azure Machine Learning registry.
+        :type registry_name: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None, or the result of cls(response)
+        :rtype: None
+        :raises: ~azure.core.exceptions.HttpResponseError
+        """
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
-        request = build_delete_request_initial(
+        request = build_delete_request(
+            name=name,
+            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            code_name=code_name,
-            version=version,
             api_version=api_version,
-            template_url=self._delete_initial.metadata["url"],
+            template_url=self.delete.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 202, 204]:
+        if response.status_code not in [200, 204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
-            raise HttpResponseError(response=response, error_format=ARMErrorFormat)
-
-        response_headers = {}
-        if response.status_code == 202:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
-            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
+            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
+            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    _delete_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
-
-    @distributed_trace
-    def begin_delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        resource_group_name,  # type: str
-        registry_name,  # type: str
-        code_name,  # type: str
-        version,  # type: str
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> LROPoller[None]
-        """Delete version.
-
-        Delete version.
-
-        :param resource_group_name: The name of the resource group. The name is case insensitive.
-        :type resource_group_name: str
-        :param registry_name: Name of Azure Machine Learning registry.
-        :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
-        :param version: Version identifier.
-        :type version: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
-        :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
-         operation to not poll, or pass in your own initialized polling object for a personal polling
-         strategy.
-        :paramtype polling: bool or ~azure.core.polling.PollingMethod
-        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
-         Retry-After header is present.
-        :return: An instance of LROPoller that returns either None or the result of cls(response)
-        :rtype: ~azure.core.polling.LROPoller[None]
-        :raises: ~azure.core.exceptions.HttpResponseError
-        """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
-        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
-        cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
-        if cont_token is None:
-            raw_result = self._delete_initial(
-                resource_group_name=resource_group_name,
-                registry_name=registry_name,
-                code_name=code_name,
-                version=version,
-                api_version=api_version,
-                cls=lambda x, y, z: x,
-                **kwargs
-            )
-        kwargs.pop("error_map", None)
-
-        def get_long_running_output(pipeline_response):
-            if cls:
-                return cls(pipeline_response, None, {})
-
-        if polling is True:
-            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "location"}, **kwargs)
-        elif polling is False:
-            polling_method = NoPolling()
-        else:
-            polling_method = polling
-        if cont_token:
-            return LROPoller.from_continuation_token(
-                polling_method=polling_method,
-                continuation_token=cont_token,
-                client=self._client,
-                deserialization_callback=get_long_running_output,
-            )
-        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+            return cls(pipeline_response, None, {})
 
-    begin_delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    delete.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
     def get(
         self,
+        name,  # type: str
+        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        code_name,  # type: str
-        version,  # type: str
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.CodeVersion"
+        # type: (...) -> "_models.CodeVersionData"
         """Get version.
 
         Get version.
 
+        :param name: Container name.
+        :type name: str
+        :param version: Version identifier.
+        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
-        :param version: Version identifier.
-        :type version: str
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: CodeVersion, or the result of cls(response)
-        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersion
+        :return: CodeVersionData, or the result of cls(response)
+        :rtype: ~azure.mgmt.machinelearningservices.models.CodeVersionData
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
+        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersionData"]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
 
         request = build_get_request(
+            name=name,
+            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            code_name=code_name,
-            version=version,
             api_version=api_version,
             template_url=self.get.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
             raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
 
-        deserialized = self._deserialize("CodeVersion", pipeline_response)
+        deserialized = self._deserialize("CodeVersionData", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, {})
 
         return deserialized
 
-    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    get.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
 
     def _create_or_update_initial(
         self,
+        name,  # type: str
+        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        code_name,  # type: str
-        version,  # type: str
-        body,  # type: "_models.CodeVersion"
+        body,  # type: "_models.CodeVersionData"
         **kwargs  # type: Any
     ):
-        # type: (...) -> "_models.CodeVersion"
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
+        # type: (...) -> None
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}))
 
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
         content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
 
-        _json = self._serialize.body(body, "CodeVersion")
+        _json = self._serialize.body(body, "CodeVersionData")
 
         request = build_create_or_update_request_initial(
+            name=name,
+            version=version,
             subscription_id=self._config.subscription_id,
             resource_group_name=resource_group_name,
             registry_name=registry_name,
-            code_name=code_name,
-            version=version,
             api_version=api_version,
             content_type=content_type,
             json=_json,
             template_url=self._create_or_update_initial.metadata["url"],
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
+        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 201]:
+        if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             raise HttpResponseError(response=response, error_format=ARMErrorFormat)
 
         response_headers = {}
-        if response.status_code == 200:
-            deserialized = self._deserialize("CodeVersion", pipeline_response)
-
-        if response.status_code == 201:
-            response_headers["x-ms-async-operation-timeout"] = self._deserialize(
-                "duration", response.headers.get("x-ms-async-operation-timeout")
-            )
-            response_headers["Azure-AsyncOperation"] = self._deserialize(
-                "str", response.headers.get("Azure-AsyncOperation")
-            )
-
-            deserialized = self._deserialize("CodeVersion", pipeline_response)
+        response_headers["x-ms-async-operation-timeout"] = self._deserialize(
+            "duration", response.headers.get("x-ms-async-operation-timeout")
+        )
+        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
+        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
 
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    _create_or_update_initial.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
 
     @distributed_trace
     def begin_create_or_update(
         self,
+        name,  # type: str
+        version,  # type: str
         resource_group_name,  # type: str
         registry_name,  # type: str
-        code_name,  # type: str
-        version,  # type: str
-        body,  # type: "_models.CodeVersion"
+        body,  # type: "_models.CodeVersionData"
         **kwargs  # type: Any
     ):
-        # type: (...) -> LROPoller["_models.CodeVersion"]
+        # type: (...) -> LROPoller[None]
         """Create or update version.
 
         Create or update version.
 
+        :param name: Container name.
+        :type name: str
+        :param version: Version identifier.
+        :type version: str
         :param resource_group_name: The name of the resource group. The name is case insensitive.
         :type resource_group_name: str
         :param registry_name: Name of Azure Machine Learning registry.
         :type registry_name: str
-        :param code_name: Container name.
-        :type code_name: str
-        :param version: Version identifier.
-        :type version: str
         :param body: Version entity to create or update.
-        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersion
+        :type body: ~azure.mgmt.machinelearningservices.models.CodeVersionData
+        :keyword api_version: Api Version. The default value is "2021-10-01-dataplanepreview". Note
+         that overriding this default value may result in unsupported behavior.
+        :paramtype api_version: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :keyword str continuation_token: A continuation token to restart a poller from a saved state.
         :keyword polling: By default, your polling method will be ARMPolling. Pass in False for this
          operation to not poll, or pass in your own initialized polling object for a personal polling
          strategy.
         :paramtype polling: bool or ~azure.core.polling.PollingMethod
         :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
          Retry-After header is present.
-        :return: An instance of LROPoller that returns either CodeVersion or the result of
-         cls(response)
-        :rtype: ~azure.core.polling.LROPoller[~azure.mgmt.machinelearningservices.models.CodeVersion]
+        :return: An instance of LROPoller that returns either None or the result of cls(response)
+        :rtype: ~azure.core.polling.LROPoller[None]
         :raises: ~azure.core.exceptions.HttpResponseError
         """
-        api_version = kwargs.pop("api_version", "2023-02-01-preview")  # type: str
+        api_version = kwargs.pop("api_version", "2021-10-01-dataplanepreview")  # type: str
         content_type = kwargs.pop("content_type", "application/json")  # type: Optional[str]
-        polling = kwargs.pop("polling", True)  # type: Union[bool, PollingMethod]
-        cls = kwargs.pop("cls", None)  # type: ClsType["_models.CodeVersion"]
+        polling = kwargs.pop("polling", True)  # type: Union[bool, azure.core.polling.PollingMethod]
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
         lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
         cont_token = kwargs.pop("continuation_token", None)  # type: Optional[str]
         if cont_token is None:
             raw_result = self._create_or_update_initial(
+                name=name,
+                version=version,
                 resource_group_name=resource_group_name,
                 registry_name=registry_name,
-                code_name=code_name,
-                version=version,
                 body=body,
                 api_version=api_version,
                 content_type=content_type,
                 cls=lambda x, y, z: x,
                 **kwargs
             )
         kwargs.pop("error_map", None)
 
         def get_long_running_output(pipeline_response):
-            response = pipeline_response.http_response
-            deserialized = self._deserialize("CodeVersion", pipeline_response)
             if cls:
-                return cls(pipeline_response, deserialized, {})
-            return deserialized
+                return cls(pipeline_response, None, {})
 
         if polling is True:
-            polling_method = ARMPolling(lro_delay, lro_options={"final-state-via": "original-uri"}, **kwargs)
+            polling_method = ARMPolling(lro_delay, **kwargs)
         elif polling is False:
             polling_method = NoPolling()
         else:
             polling_method = polling
         if cont_token:
             return LROPoller.from_continuation_token(
                 polling_method=polling_method,
                 continuation_token=cont_token,
                 client=self._client,
                 deserialization_callback=get_long_running_output,
             )
-        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
+        else:
+            return LROPoller(self._client, raw_result, get_long_running_output, polling_method)
 
-    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{codeName}/versions/{version}"}  # type: ignore
+    begin_create_or_update.metadata = {"url": "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/registries/{registryName}/codes/{name}/versions/{version}"}  # type: ignore
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspaces_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_workspaces_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_model_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_versions_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_restclient/v2023_02_01_preview/operations/_registry_component_versions_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_file_utils/file_utils.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_file_utils/file_utils.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/_resource_management_client.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/_resource_management_client.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/flatten_json/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/flatten_json/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,14 @@
 
 import copy
 import json
 import re
 import sys
 from math import isnan
 
-import six
 
 try:
     # 3.8 and up
     from collections.abc import Iterable
 except ImportError:
     from collections import Iterable
 
@@ -61,15 +60,15 @@
     :param nested_dict: dictionary we want to flatten
     :param separator: string to separate dictionary keys by
     :param root_keys_to_ignore: set of root keys to ignore from flattening
     :param str replace_separators: Replace separators within keys
     :return: flattened dictionary
     """
     assert isinstance(nested_dict, dict), "flatten requires a dictionary input"
-    assert isinstance(separator, six.string_types), "separator must be string"
+    assert isinstance(separator, str), "separator must be string"
 
     if root_keys_to_ignore is None:
         root_keys_to_ignore = set()
 
     if len(nested_dict) == 0:
         return {}
 
@@ -132,15 +131,15 @@
     :param max_list_index: maximum list index to process
     :param max_depth: maximum nesting depth to process
     :param str replace_separators: Replace separators within keys
     :return: flattened dictionary
     """
 
     assert isinstance(nested_dict, dict), "flatten requires a dictionary input"
-    assert isinstance(separator, six.string_types), "separator must be a string"
+    assert isinstance(separator, str), "separator must be a string"
 
     if root_keys_to_ignore is None:
         root_keys_to_ignore = set()
 
     # This global dictionary stores the flattened keys and values and is
     # ultimately returned
     flattened_dict = dict()
@@ -309,20 +308,17 @@
     _flatten_low_entropy(nested_dict, None, cur_depth=0, max_depth_inner=max_depth)
 
     return list_prebuilt_flattened_dict["0"]
 
 
 def _unflatten_asserts(flat_dict, separator):
     assert isinstance(flat_dict, dict), "un_flatten requires dictionary input"
-    assert isinstance(separator, six.string_types), "separator must be string"
+    assert isinstance(separator, str), "separator must be string"
     assert all(
-        (
-            not value or not isinstance(value, Iterable) or isinstance(value, six.string_types)
-            for value in flat_dict.values()
-        )
+        (not value or not isinstance(value, Iterable) or isinstance(value, str) for value in flat_dict.values())
     ), "provided dict is not flat"
 
 
 def unflatten(flat_dict, separator="_"):
     """
     Creates a hierarchical dictionary from a flattened dictionary
     Assumes no lists are present
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/_resource_management_client.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/_resource_management_client.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/_configuration.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/_configuration.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_providers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_providers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resource_groups_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_resource_groups_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployment_operations_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployment_operations_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_tags_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_tags_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/aio/operations/_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_models.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_models.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_resource_management_client_enums.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_resource_management_client_enums.py`

 * *Files 15% similar despite different names*

```diff
@@ -2,114 +2,97 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
-from enum import Enum, EnumMeta
-from six import with_metaclass
+from enum import Enum
+from azure.core import CaseInsensitiveEnumMeta
 
 
-class _CaseInsensitiveEnumMeta(EnumMeta):
-    def __getitem__(self, name):
-        return super().__getitem__(name.upper())
-
-    def __getattr__(cls, name):
-        """Return the enum member matching `name`
-        We use __getattr__ instead of descriptors or inserting into the enum
-        class' __dict__ in order to support `name` and `value` being both
-        properties for enum members (which live in the class' __dict__) and
-        enum members themselves.
-        """
-        try:
-            return cls._member_map_[name.upper()]
-        except KeyError:
-            raise AttributeError(name)
-
-
-class AliasPathAttributes(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class AliasPathAttributes(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The attributes of the token that the alias path is referring to."""
 
     NONE = "None"  #: The token that the alias path is referring to has no attributes.
     MODIFIABLE = (
         "Modifiable"  #: The token that the alias path is referring to is modifiable by policies with 'modify' effect.
     )
 
 
-class AliasPathTokenType(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class AliasPathTokenType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of the token that the alias path is referring to."""
 
     NOT_SPECIFIED = "NotSpecified"  #: The token type is not specified.
     ANY = "Any"  #: The token type can be anything.
     STRING = "String"  #: The token type is string.
     OBJECT = "Object"  #: The token type is object.
     ARRAY = "Array"  #: The token type is array.
     INTEGER = "Integer"  #: The token type is integer.
     NUMBER = "Number"  #: The token type is number.
     BOOLEAN = "Boolean"  #: The token type is boolean.
 
 
-class AliasPatternType(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class AliasPatternType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of alias pattern"""
 
     NOT_SPECIFIED = "NotSpecified"  #: NotSpecified is not allowed.
     EXTRACT = "Extract"  #: Extract is the only allowed value.
 
 
-class AliasType(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class AliasType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of the alias."""
 
     NOT_SPECIFIED = "NotSpecified"  #: Alias type is unknown (same as not providing alias type).
     PLAIN_TEXT = "PlainText"  #: Alias value is not secret.
     MASK = "Mask"  #: Alias value is secret.
 
 
-class ChangeType(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class ChangeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Type of change that will be made to the resource when the deployment is executed."""
 
     CREATE = "Create"  #: The resource does not exist in the current state but is present in the desired state. The resource will be created when the deployment is executed.
     DELETE = "Delete"  #: The resource exists in the current state and is missing from the desired state. The resource will be deleted when the deployment is executed.
     IGNORE = "Ignore"  #: The resource exists in the current state and is missing from the desired state. The resource will not be deployed or modified when the deployment is executed.
     DEPLOY = "Deploy"  #: The resource exists in the current state and the desired state and will be redeployed when the deployment is executed. The properties of the resource may or may not change.
     NO_CHANGE = "NoChange"  #: The resource exists in the current state and the desired state and will be redeployed when the deployment is executed. The properties of the resource will not change.
     MODIFY = "Modify"  #: The resource exists in the current state and the desired state and will be redeployed when the deployment is executed. The properties of the resource will change.
 
 
-class DeploymentMode(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class DeploymentMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The mode that is used to deploy resources. This value can be either Incremental or Complete. In
     Incremental mode, resources are deployed without deleting existing resources that are not
     included in the template. In Complete mode, resources are deployed and existing resources in
     the resource group that are not included in the template are deleted. Be careful when using
     Complete mode as you may unintentionally delete resources.
     """
 
     INCREMENTAL = "Incremental"
     COMPLETE = "Complete"
 
 
-class OnErrorDeploymentType(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class OnErrorDeploymentType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The deployment on error behavior type. Possible values are LastSuccessful and
     SpecificDeployment.
     """
 
     LAST_SUCCESSFUL = "LastSuccessful"
     SPECIFIC_DEPLOYMENT = "SpecificDeployment"
 
 
-class PropertyChangeType(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class PropertyChangeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The type of property change."""
 
     CREATE = "Create"  #: The property does not exist in the current state but is present in the desired state. The property will be created when the deployment is executed.
     DELETE = "Delete"  #: The property exists in the current state and is missing from the desired state. It will be deleted when the deployment is executed.
     MODIFY = "Modify"  #: The property exists in both current and desired state and is different. The value of the property will change when the deployment is executed.
     ARRAY = "Array"  #: The property is an array and contains nested changes.
 
 
-class ProvisioningOperation(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class ProvisioningOperation(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The name of the current provisioning operation."""
 
     NOT_SPECIFIED = "NotSpecified"  #: The provisioning operation is not specified.
     CREATE = "Create"  #: The provisioning operation is create.
     DELETE = "Delete"  #: The provisioning operation is delete.
     WAITING = "Waiting"  #: The provisioning operation is waiting.
     AZURE_ASYNC_OPERATION_WAITING = (
@@ -118,15 +101,15 @@
     RESOURCE_CACHE_WAITING = "ResourceCacheWaiting"  #: The provisioning operation is waiting for resource cache.
     ACTION = "Action"  #: The provisioning operation is action.
     READ = "Read"  #: The provisioning operation is read.
     EVALUATE_DEPLOYMENT_OUTPUT = "EvaluateDeploymentOutput"  #: The provisioning operation is evaluate output.
     DEPLOYMENT_CLEANUP = "DeploymentCleanup"  #: The provisioning operation is cleanup. This operation is part of the 'complete' mode deployment.
 
 
-class ProvisioningState(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class ProvisioningState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """Denotes the state of provisioning."""
 
     NOT_SPECIFIED = "NotSpecified"
     ACCEPTED = "Accepted"
     RUNNING = "Running"
     READY = "Ready"
     CREATING = "Creating"
@@ -135,29 +118,29 @@
     DELETED = "Deleted"
     CANCELED = "Canceled"
     FAILED = "Failed"
     SUCCEEDED = "Succeeded"
     UPDATING = "Updating"
 
 
-class ResourceIdentityType(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class ResourceIdentityType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The identity type."""
 
     SYSTEM_ASSIGNED = "SystemAssigned"
     USER_ASSIGNED = "UserAssigned"
     SYSTEM_ASSIGNED_USER_ASSIGNED = "SystemAssigned, UserAssigned"
     NONE = "None"
 
 
-class TagsPatchOperation(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class TagsPatchOperation(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The operation type for the patch API."""
 
     REPLACE = "Replace"  #: The 'replace' option replaces the entire set of existing tags with a new set.
     MERGE = "Merge"  #: The 'merge' option allows adding tags with new names and updating the values of tags with existing names.
     DELETE = "Delete"  #: The 'delete' option allows selectively deleting tags based on given names or name/value pairs.
 
 
-class WhatIfResultFormat(with_metaclass(_CaseInsensitiveEnumMeta, str, Enum)):
+class WhatIfResultFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """The format of the What-If results"""
 
     RESOURCE_ID_ONLY = "ResourceIdOnly"
     FULL_RESOURCE_PAYLOADS = "FullResourcePayloads"
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/models/_models_py3.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/models/_models_py3.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_providers_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_providers_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_resources_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_resources_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_resource_groups_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_resource_groups_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_deployment_operations_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_deployment_operations_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_tags_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_tags_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/_vendor/azure_resources/operations/_deployments_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/_vendor/azure_resources/operations/_deployments_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_connections_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_connections_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_online_deployment_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_online_deployment_operations.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,49 +2,50 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access,no-self-use,broad-except
 
 import random
 import re
+import subprocess
 from typing import Dict, Optional
-
 from marshmallow.exceptions import ValidationError as SchemaValidationError
 
+from azure.core.credentials import TokenCredential
+from azure.core.paging import ItemPaged
+from azure.core.polling import LROPoller
+from azure.core.tracing.decorator import distributed_trace
+
 from azure.ai.ml._exception_helper import log_and_raise_error
 from azure.ai.ml._local_endpoints import LocalEndpointMode
-from azure.ai.ml._restclient.v2023_04_01_preview import AzureMachineLearningWorkspaces as ServiceClient042023Preview
 from azure.ai.ml._restclient.v2022_02_01_preview.models import DeploymentLogsRequest
+from azure.ai.ml._restclient.v2023_04_01_preview import AzureMachineLearningWorkspaces as ServiceClient042023Preview
 from azure.ai.ml._scope_dependent_operations import (
     OperationConfig,
     OperationsContainer,
     OperationScope,
     _ScopeDependentOperations,
 )
-from azure.ai.ml._utils._arm_id_utils import AMLVersionedArmId
-
 from azure.ai.ml._telemetry import ActivityType, monitor_with_activity
+from azure.ai.ml._utils._arm_id_utils import AMLVersionedArmId
 from azure.ai.ml._utils._azureml_polling import AzureMLPolling
 from azure.ai.ml._utils._endpoint_utils import upload_dependencies, validate_scoring_script
-from azure.ai.ml._utils._package_utils import package_deployment
 from azure.ai.ml._utils._logger_utils import OpsLogger
+from azure.ai.ml._utils._package_utils import package_deployment
 from azure.ai.ml.constants._common import ARM_ID_PREFIX, AzureMLResourceType, LROConfigurations
-from azure.ai.ml.constants._deployment import EndpointDeploymentLogContainerType, SmallSKUs, DEFAULT_MDC_PATH
-from azure.ai.ml.entities import OnlineDeployment, Data
+from azure.ai.ml.constants._deployment import DEFAULT_MDC_PATH, EndpointDeploymentLogContainerType, SmallSKUs
+from azure.ai.ml.entities import Data, OnlineDeployment
 from azure.ai.ml.exceptions import (
     ErrorCategory,
     ErrorTarget,
     InvalidVSCodeRequestError,
+    LocalDeploymentGPUNotAvailable,
     ValidationErrorType,
     ValidationException,
 )
-from azure.core.credentials import TokenCredential
-from azure.core.paging import ItemPaged
-from azure.core.polling import LROPoller
-from azure.core.tracing.decorator import distributed_trace
 
 from ._local_deployment_helper import _LocalDeploymentHelper
 from ._operation_orchestrator import OperationOrchestrator
 
 ops_logger = OpsLogger(__name__)
 logger, module_logger = ops_logger.package_logger, ops_logger.module_logger
 
@@ -80,24 +81,27 @@
     def begin_create_or_update(
         self,
         deployment: OnlineDeployment,
         *,
         local: bool = False,
         vscode_debug: bool = False,
         skip_script_validation: bool = False,
+        local_enable_gpu: bool = False,
         **kwargs,
     ) -> LROPoller[OnlineDeployment]:
         """Create or update a deployment.
 
         :param deployment: the deployment entity
         :type deployment: ~azure.ai.ml.entities.OnlineDeployment
         :param local: Whether deployment should be created locally, defaults to False
         :type local: bool, optional
         :param vscode_debug: Whether to open VSCode instance to debug local deployment, defaults to False
         :type vscode_debug: bool, optional
+        :param local_enable_gpu: enable local container to access gpu
+        :type local_enable_gpu: bool, optional
         :raises ~azure.ai.ml.exceptions.ValidationException: Raised if OnlineDeployment cannot
             be successfully validated. Details will be provided in the error message.
         :raises ~azure.ai.ml.exceptions.AssetException: Raised if OnlineDeployment assets
             (e.g. Data, Code, Model, Environment) cannot be successfully validated.
             Details will be provided in the error message.
         :raises ~azure.ai.ml.exceptions.ModelException: Raised if OnlineDeployment model cannot be
             successfully validated. Details will be provided in the error message.
@@ -109,27 +113,40 @@
             found for local deployment.
         :raises ~azure.ai.ml.exceptions.LocalEndpointImageBuildError: Raised if Docker image cannot be
             successfully built for local deployment.
         :raises ~azure.ai.ml.exceptions.RequiredLocalArtifactsNotFoundError: Raised if local artifacts cannot be
             found for local deployment.
         :raises ~azure.ai.ml.exceptions.InvalidVSCodeRequestError: Raised if VS Debug is invoked with a remote endpoint.
             VSCode debug is only supported for local endpoints.
+        :raises ~azure.ai.ml.exceptions.LocalDeploymentGPUNotAvailable: Raised if Nvidia GPU is not available in the
+            system and local_enable_gpu is set while local deployment
         :raises ~azure.ai.ml.exceptions.VSCodeCommandNotFound: Raised if VSCode instance cannot be instantiated.
         :return: A poller to track the operation status
         :rtype: ~azure.core.polling.LROPoller[~azure.ai.ml.entities.OnlineDeployment]
         """
         try:
             if vscode_debug and not local:
                 raise InvalidVSCodeRequestError(
                     msg="VSCode Debug is only support for local endpoints. Please set local to True."
                 )
             if local:
+                if local_enable_gpu:
+                    try:
+                        subprocess.run("nvidia-smi", check=True)
+                    except Exception as ex:
+                        raise LocalDeploymentGPUNotAvailable(
+                            msg=(
+                                "Nvidia GPU is not available in your local system."
+                                " Use nvidia-smi command to see the available GPU"
+                            )
+                        ) from ex
                 return self._local_deployment_helper.create_or_update(
                     deployment=deployment,
                     local_endpoint_mode=self._get_local_endpoint_mode(vscode_debug),
+                    local_enable_gpu=local_enable_gpu,
                 )
             if deployment and deployment.instance_type and deployment.instance_type.lower() in SmallSKUs:
                 module_logger.warning(
                     "Instance type %s may be too small for compute resources. "  # pylint: disable=line-too-long
                     "Minimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: "  # pylint: disable=line-too-long
                     "https://learn.microsoft.com/en-us/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list",
                     deployment.instance_type,  # pylint: disable=line-too-long
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/__init__.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/__init__.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_endpoint_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_endpoint_helper.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_outbound_rule_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_outbound_rule_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_operation_orchestrator.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_operation_orchestrator.py`

 * *Files 1% similar despite different names*

```diff
@@ -251,15 +251,15 @@
                 msg = f"Error creating {azureml_type} asset : {e.message}"
                 raise AssetException(
                     message=msg.format(azureml_type, e.message),
                     target=ErrorTarget.ASSET,
                     no_personal_data_message=msg.format(azureml_type, ""),
                     error=e,
                     error_category=ErrorCategory.SYSTEM_ERROR,
-                )
+                ) from e
             return result
         msg = f"Error creating {azureml_type} asset: must be type Optional[Union[str, Asset]]"
         raise ValidationException(
             message=msg,
             target=ErrorTarget.ASSET,
             no_personal_data_message=msg,
             error_category=ErrorCategory.USER_ERROR,
@@ -299,15 +299,15 @@
         except Exception as e:
             raise AssetException(
                 message=f"Error with code: {e}",
                 target=ErrorTarget.ASSET,
                 no_personal_data_message="Error getting code asset",
                 error=e,
                 error_category=ErrorCategory.SYSTEM_ERROR,
-            )
+            ) from e
 
     def _get_environment_arm_id(self, environment: Environment, register_asset: bool = True) -> Union[str, Environment]:
         if register_asset:
             if environment.id:
                 return environment.id
             env_response = self._environments.create_or_update(environment)
             return env_response.id
@@ -348,15 +348,15 @@
         except Exception as e:
             raise ModelException(
                 message=f"Error with model: {e}",
                 target=ErrorTarget.MODEL,
                 no_personal_data_message="Error getting model",
                 error=e,
                 error_category=ErrorCategory.SYSTEM_ERROR,
-            )
+            ) from e
 
     def _get_data_arm_id(self, data_asset: Data, register_asset: bool = True) -> Union[str, Data]:
         self._validate_datastore_name(data_asset.path)
 
         if register_asset:
             return self._data.create_or_update(data_asset).id
         data_asset, _ = _check_and_upload_path(
@@ -504,16 +504,16 @@
                     # local path
                     return
 
                 if datastore_name.startswith(ARM_ID_PREFIX):
                     datastore_name = datastore_name[len(ARM_ID_PREFIX) :]
 
                 self._datastore_operation.get(datastore_name)
-            except ResourceNotFoundError:
+            except ResourceNotFoundError as e:
                 msg = "The datastore {} could not be found in this workspace."
                 raise ValidationException(
                     message=msg.format(datastore_name),
                     target=ErrorTarget.DATASTORE,
                     no_personal_data_message=msg.format(""),
                     error_category=ErrorCategory.USER_ERROR,
                     error_type=ValidationErrorType.RESOURCE_NOT_FOUND,
-                )
+                ) from e
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_code_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_code_operations.py`

 * *Files 1% similar despite different names*

```diff
@@ -172,15 +172,15 @@
                 # service side raises an exception if we attempt to update an existing asset's asset path
                 if str(ex) == ASSET_PATH_ERROR:
                     raise AssetPathException(
                         message=CHANGED_ASSET_PATH_MSG,
                         target=ErrorTarget.CODE,
                         no_personal_data_message=CHANGED_ASSET_PATH_MSG_NO_PERSONAL_DATA,
                         error_category=ErrorCategory.USER_ERROR,
-                    )
+                    ) from ex
             raise ex
 
     @monitor_with_activity(logger, "Code.Get", ActivityType.PUBLICAPI)
     def get(self, name: str, version: str) -> Code:
         """Returns information about the specified code asset.
 
         :param name: Name of the code asset.
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_run_history_constants.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_run_history_constants.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_job_ops_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_job_ops_helper.py`

 * *Files 1% similar despite different names*

```diff
@@ -314,27 +314,27 @@
                     target=ErrorTarget.JOB,
                     no_personal_data_message="Exception raised on failed job.",
                     error_category=ErrorCategory.SYSTEM_ERROR,
                 )
 
         file_handle.write("\n")
         file_handle.flush()
-    except KeyboardInterrupt:
+    except KeyboardInterrupt as e:
         error_message = (
             "The output streaming for the run interrupted.\n"
             "But the run is still executing on the compute target. \n"
             "Details for canceling the run can be found here: "
             "https://aka.ms/aml-docs-cancel-run"
         )
         raise JobException(
             message=error_message,
             target=ErrorTarget.JOB,
             no_personal_data_message=error_message,
             error_category=ErrorCategory.USER_ERROR,
-        )
+        ) from e
 
 
 def get_git_properties() -> Dict[str, str]:
     """Gather Git tracking info from the local environment.
 
     :return: Properties dictionary.
     :rtype: dict
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_model_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_model_operations.py`

 * *Files 0% similar despite different names*

```diff
@@ -215,15 +215,15 @@
                 # service side raises an exception if we attempt to update an existing asset's path
                 if str(e) == ASSET_PATH_ERROR:
                     raise AssetPathException(
                         message=CHANGED_ASSET_PATH_MSG,
                         target=ErrorTarget.MODEL,
                         no_personal_data_message=CHANGED_ASSET_PATH_MSG_NO_PERSONAL_DATA,
                         error_category=ErrorCategory.USER_ERROR,
-                    )
+                    ) from e
                 raise e
 
             model = Model._from_rest_object(result)
             if auto_increment_version and indicator_file:
                 datastore_info = _get_default_datastore_info(self._datastore_operation)
                 _update_metadata(model.name, model.version, indicator_file, datastore_info)  # update version in storage
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_batch_endpoint_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_batch_endpoint_operations.py`

 * *Files 0% similar despite different names*

```diff
@@ -449,8 +449,8 @@
                 "a registered data asset, or a local folder path.\n"
                 f"Met {type(e)}:\n{e}",
                 target=ErrorTarget.BATCH_ENDPOINT,
                 no_personal_data_message="Supported input path value are: path on the datastore, "
                 "public URI, a registered data asset, or a local folder path.",
                 error=e,
                 error_type=ValidationErrorType.INVALID_VALUE,
-            )
+            ) from e
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_dataset_dataplane_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_dataset_dataplane_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_deployment_helper.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_deployment_helper.py`

 * *Files 3% similar despite different names*

```diff
@@ -47,22 +47,27 @@
     ):
         self._docker_client = DockerClient()
         self._model_operations = operation_container.all_operations.get(AzureMLResourceType.MODEL)
         self._code_operations = operation_container.all_operations.get(AzureMLResourceType.CODE)
         self._environment_operations = operation_container.all_operations.get(AzureMLResourceType.ENVIRONMENT)
 
     def create_or_update(
-        self, deployment: OnlineDeployment, local_endpoint_mode: LocalEndpointMode
+        self,
+        deployment: OnlineDeployment,
+        local_endpoint_mode: LocalEndpointMode,
+        local_enable_gpu: Optional[bool] = False,
     ) -> OnlineDeployment:
         """Create or update an deployment locally using Docker.
 
         :param deployment: OnlineDeployment object with information from user yaml.
         :type deployment: OnlineDeployment
         :param local_endpoint_mode: Mode for how to create the local user container.
         :type local_endpoint_mode: LocalEndpointMode
+        :param local_enable_gpu: enable local container to access gpu
+        :type local_enable_gpu: bool
         """
         try:
             if deployment is None:
                 msg = "The entity provided for local endpoint was null. Please provide valid entity."
                 raise InvalidLocalEndpointError(message=msg, no_personal_data_message=msg)
 
             endpoint_metadata = None
@@ -81,14 +86,15 @@
             )
             local_endpoint_polling_wrapper(
                 func=self._create_deployment,
                 message=f"{operation_message} ({deployment.endpoint_name} / {deployment.name}) ",
                 endpoint_name=deployment.endpoint_name,
                 deployment=deployment,
                 local_endpoint_mode=local_endpoint_mode,
+                local_enable_gpu=local_enable_gpu,
                 endpoint_metadata=endpoint_metadata,
                 deployment_metadata=deployment_metadata,
             )
             return self.get(endpoint_name=deployment.endpoint_name, deployment_name=deployment.name)
         except Exception as ex:  # pylint: disable=broad-except
             if isinstance(ex, (ValidationException, SchemaValidationError)):
                 log_and_raise_error(ex)
@@ -150,25 +156,28 @@
             pass
 
     def _create_deployment(
         self,
         endpoint_name: str,
         deployment: OnlineDeployment,
         local_endpoint_mode: LocalEndpointMode,
+        local_enable_gpu: Optional[bool] = False,
         endpoint_metadata: Optional[dict] = None,
         deployment_metadata: Optional[dict] = None,
     ):
         """Create deployment locally using Docker.
 
         :param endpoint: OnlineDeployment object with information from user yaml.
         :type endpoint: OnlineDeployment
         :param deployment: Deployment to create
         :type deployment: Deployment entity
         :param local_endpoint_mode: Mode for local endpoint.
         :type local_endpoint_mode: LocalEndpointMode
+        :param local_enable_gpu: enable local container to access gpu
+        :type local_enable_gpu: bool
         :param endpoint_metadata: Endpoint metadata (json serialied Endpoint entity)
         :type endpoint_metadata: dict
         :param deployment_metadata: Deployment metadata (json serialied Deployment entity)
         :type deployment_metadata: dict
         """
         deployment_name = deployment.name
         deployment_directory = _create_build_directory(endpoint_name=endpoint_name, deployment_name=deployment_name)
@@ -283,14 +292,15 @@
             conda_source_path=yaml_env_conda_file_path,
             conda_yaml_contents=yaml_env_conda_file_contents,
             volumes=volumes,
             environment=environment_variables,
             azureml_port=inference_config.scoring_route.port if is_byoc else LocalEndpointConstants.DOCKER_PORT,
             local_endpoint_mode=local_endpoint_mode,
             prebuilt_image_name=yaml_base_image_name if is_byoc else None,
+            local_enable_gpu=local_enable_gpu,
         )
 
 
 def _convert_container_to_deployment(container: "docker.models.containers.Container") -> OnlineDeployment:
     """Converts provided Container for local deployment to OnlineDeployment entity.
 
     :param container: Container for a local deployment.
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_model_dataplane_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_model_dataplane_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_virtual_cluster_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_virtual_cluster_operations.py`

 * *Files 2% similar despite different names*

```diff
@@ -81,21 +81,21 @@
             subscription_list = [self._subscription_id]
         else:
             message = f"Invalid scope: {scope}. Valid values are 'subscription' or None."
             raise UserErrorException(message=message, no_personal_data_message=message)
 
         try:
             return get_virtual_clusters_from_subscriptions(self._credentials, subscription_list=subscription_list)
-        except ImportError:
+        except ImportError as e:
             raise UserErrorException(
                 message="Met ImportError when trying to list virtual clusters. "
                 "Please install azure-mgmt-resource to enable this feature; "
                 "and please install azure-mgmt-resource to enable listing virtual clusters "
                 "across all subscriptions a customer has access to."
-            )
+            ) from e
 
     @distributed_trace
     @monitor_with_activity(logger, "VirtualCluster.ListJobs", ActivityType.PUBLICAPI)
     def list_jobs(self, name: str) -> Iterable[Job]:
         """List of jobs that target the virtual cluster
 
         :param name: Name of virtual cluster
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_local_job_invoker.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_local_job_invoker.py`

 * *Files 2% similar despite different names*

```diff
@@ -143,23 +143,23 @@
         (url, encodedBody) = local.endpoint.split(EXECUTION_SERVICE_URL_KEY)
         body = urllib.parse.unquote_plus(encodedBody)
         body = json.loads(body)
         response = requests_pipeline.post(url, json=body, headers={"Authorization": "Bearer " + token})
         response.raise_for_status()
         return (response.content, body.get("SnapshotId", None))
     except AzureError as err:
-        raise SystemExit(err)
-    except Exception:
+        raise SystemExit(err) from err
+    except Exception as e:
         msg = "Failed to read in local executable job"
         raise JobException(
             message=msg,
             target=ErrorTarget.LOCAL_JOB,
             no_personal_data_message=msg,
             error_category=ErrorCategory.SYSTEM_ERROR,
-        )
+        ) from e
 
 
 def is_local_run(job_definition: JobBaseData) -> bool:
     local = job_definition.properties.services.get("Local", None)
     return local is not None and EXECUTION_SERVICE_URL_KEY in local.endpoint
 
 
@@ -213,30 +213,30 @@
         :type registry: Dict[str, str]
         :return: Docker client
         :rtype: docker.DockerClient
         """
         try:
             client = docker.from_env(version="auto")
         except docker.errors.DockerException as e:
-            raise Exception(self.DOCKER_CLIENT_FAILURE_MSG.format(e))
+            raise Exception(self.DOCKER_CLIENT_FAILURE_MSG.format(e)) from e
 
         try:
             client.version()
         except Exception as e:
-            raise Exception(self.DOCKER_DAEMON_FAILURE_MSG.format(e))
+            raise Exception(self.DOCKER_DAEMON_FAILURE_MSG.format(e)) from e
 
         if registry:
             try:
                 client.login(
                     username=registry["username"],
                     password=registry["password"],
                     registry=registry["url"],
                 )
             except Exception as e:
-                raise RuntimeError(self.DOCKER_LOGIN_FAILURE_MSG.format(registry["url"], e))
+                raise RuntimeError(self.DOCKER_LOGIN_FAILURE_MSG.format(registry["url"], e)) from e
         else:
             raise RuntimeError("Registry information is missing from bootstrapper configuration.")
 
         return client
 
     def copy_bootstrapper_from_container(self, container: "docker.models.containers.Container") -> None:
         """Copy file/folder from container to local machine.
@@ -254,15 +254,15 @@
                 for chunk in data_stream:
                     f.write(chunk)
             with tarfile.open(tar_file, mode="r") as tar:
                 for file_name in tar.getnames():
                     tar.extract(file_name, os.path.dirname(path_in_host))
             os.remove(tar_file)
         except docker.errors.APIError as e:
-            raise Exception(f"Copying {path_in_container} from container has failed. Detailed message: {e}")
+            raise Exception(f"Copying {path_in_container} from container has failed. Detailed message: {e}") from e
 
     def get_common_runtime_info_from_response(self, response: Dict[str, str]) -> Tuple[Dict[str, str], str]:
         """Extract common-runtime info from Execution Service response.
 
         :param response: Content of zip file from Execution Service containing all the
             scripts required to invoke a local run.
         :type response: Dict[str, str]
@@ -409,15 +409,15 @@
         ) and not cr_helper.check_bootstrapper_process_status(bootstrapper_process):
             time.sleep(3)
     else:
         try:
             temp_dir = unzip_to_temporary_file(job_definition, zip_content)
             invoke_command(temp_dir)
         except Exception as e:
-            raise Exception(LOCAL_JOB_FAILURE_MSG.format(e))
+            raise Exception(LOCAL_JOB_FAILURE_MSG.format(e)) from e
     return snapshot_id
 
 
 def _log_subprocess(output_io, file, show_in_console=False):
     def log_subprocess():
         for line in iter(output_io.readline, ""):
             if show_in_console:
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_store_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_store_operations.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,46 +1,42 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
 
 from typing import Dict, Iterable, Optional
-
 from marshmallow import ValidationError
 
-from azure.ai.ml._restclient.v2023_04_01_preview import AzureMachineLearningWorkspaces as ServiceClient042023Preview
-from azure.ai.ml._scope_dependent_operations import OperationsContainer, OperationScope
-
-from azure.ai.ml._telemetry import ActivityType, monitor_with_activity
 from azure.core.credentials import TokenCredential
+from azure.core.exceptions import ResourceNotFoundError
 from azure.core.polling import LROPoller
 from azure.core.tracing.decorator import distributed_trace
-from azure.core.exceptions import ResourceNotFoundError
+
+from azure.ai.ml._restclient.v2023_04_01_preview import AzureMachineLearningWorkspaces as ServiceClient042023Preview
+from azure.ai.ml._scope_dependent_operations import OperationsContainer, OperationScope
+from azure.ai.ml._telemetry import ActivityType, monitor_with_activity
 from azure.ai.ml._utils._logger_utils import OpsLogger
-from azure.ai.ml.entities._feature_store.feature_store import FeatureStore
-from azure.ai.ml.entities._workspace.feature_store_settings import FeatureStoreSettings
-from azure.ai.ml.entities._feature_store.materialization_store import MaterializationStore
-from azure.ai.ml.entities import (
-    ManagedIdentityConfiguration,
-    IdentityConfiguration,
-    WorkspaceConnection,
-)
+from azure.ai.ml._utils.utils import camel_to_snake
+from azure.ai.ml.constants import ManagedServiceIdentityType
 from azure.ai.ml.constants._common import Scope
+from azure.ai.ml.entities import IdentityConfiguration, ManagedIdentityConfiguration, WorkspaceConnection
 from azure.ai.ml.entities._feature_store._constants import (
-    OFFLINE_STORE_CONNECTION_NAME,
+    FEATURE_STORE_KIND,
     OFFLINE_MATERIALIZATION_STORE_TYPE,
     OFFLINE_STORE_CONNECTION_CATEGORY,
-    ONLINE_STORE_CONNECTION_NAME,
+    OFFLINE_STORE_CONNECTION_NAME,
     ONLINE_MATERIALIZATION_STORE_TYPE,
     ONLINE_STORE_CONNECTION_CATEGORY,
-    FEATURE_STORE_KIND,
+    ONLINE_STORE_CONNECTION_NAME,
 )
-from azure.ai.ml.constants import ManagedServiceIdentityType
-from azure.ai.ml._utils.utils import camel_to_snake
+from azure.ai.ml.entities._feature_store.feature_store import FeatureStore
+from azure.ai.ml.entities._feature_store.materialization_store import MaterializationStore
+from azure.ai.ml.entities._workspace.feature_store_settings import FeatureStoreSettings
+
 from ._workspace_operations_base import WorkspaceOperationsBase
 
 ops_logger = OpsLogger(__name__)
 logger, module_logger = ops_logger.package_logger, ops_logger.module_logger
 
 
 class FeatureStoreOperations(WorkspaceOperationsBase):
@@ -187,14 +183,24 @@
 
         :param feature store: FeatureStore definition.
         :type feature store: FeatureStore
         :type update_dependent_resources: boolean
         :return: An instance of LROPoller that returns a FeatureStore.
         :rtype: ~azure.core.polling.LROPoller[~azure.ai.ml.entities.FeatureStore]
         """
+        resource_group = kwargs.get("resource_group", self._resource_group_name)
+        try:
+            rest_workspace_obj = self._operation.get(resource_group, feature_store.name)
+            if rest_workspace_obj:
+                return self.begin_update(
+                    feature_store=feature_store, update_dependent_resources=update_dependent_resources, kwargs=kwargs
+                )
+        except Exception:  # pylint: disable=broad-except
+            pass
+
         if feature_store.offline_store and feature_store.offline_store.type != OFFLINE_MATERIALIZATION_STORE_TYPE:
             raise ValidationError("offline store type should be azure_data_lake_gen2")
         if feature_store.offline_store and not feature_store.materialization_identity:
             raise ValidationError("materialization_identity is required to setup offline store")
 
         if feature_store.online_store and feature_store.online_store.type != ONLINE_MATERIALIZATION_STORE_TYPE:
             raise ValidationError("online store type should be redis")
@@ -236,25 +242,36 @@
             Azure Container Registry and Azure Application Insights will fail.
         :param application_insights: Application insights resource for feature store.
         :param container_registry: Container registry resource for feature store.
         :type feature store: FeatureStore
         :return: An instance of LROPoller that returns a FeatureStore.
         :rtype: ~azure.core.polling.LROPoller[~azure.ai.ml.entities.FeatureStore]
         """
-        resource_group = kwargs.get("resource_group") or self._resource_group_name
+        resource_group = kwargs.get("resource_group", self._resource_group_name)
         rest_workspace_obj = self._operation.get(resource_group, feature_store.name)
         if not (
             rest_workspace_obj and rest_workspace_obj.kind and rest_workspace_obj.kind.lower() == FEATURE_STORE_KIND
         ):
             raise ValidationError("{0} is not a feature store".format(feature_store.name))
 
         resource_group = kwargs.get("resource_group") or self._resource_group_name
         offline_store = kwargs.get("offline_store", feature_store.offline_store)
         online_store = kwargs.get("online_store", feature_store.online_store)
-        materialization_identity = kwargs.get("materialization_identity", feature_store.materialization_identity)
+        existing_materialization_identity = None
+        if rest_workspace_obj.identity:
+            identity = IdentityConfiguration._from_workspace_rest_object(rest_workspace_obj.identity)
+            if (
+                identity
+                and identity.user_assigned_identities
+                and isinstance(identity.user_assigned_identities[0], ManagedIdentityConfiguration)
+            ):
+                existing_materialization_identity = identity.user_assigned_identities[0]
+        materialization_identity = kwargs.get(
+            "materialization_identity", feature_store.materialization_identity or existing_materialization_identity
+        )
 
         if offline_store and offline_store.type != OFFLINE_MATERIALIZATION_STORE_TYPE:
             raise ValidationError("offline store type should be azure_data_lake_gen2")
 
         if offline_store and rest_workspace_obj.feature_store_settings.offline_store_connection_name:
             existing_offline_store_connection = self._workspace_connection_operation.get(
                 resource_group,
@@ -268,17 +285,16 @@
                     or existing_offline_store_connection.properties.target != offline_store.target
                 ):
                     module_logger.info(
                         "Warning: You have changed the offline store connection, "
                         "any data that was materialized "
                         "earlier will not be available. You have to run backfill again."
                     )
-            else:
-                if not materialization_identity:
-                    raise ValidationError("Materialization identity is required to setup offline store connection")
+            elif not materialization_identity:
+                raise ValidationError("Materialization identity is required to setup offline store connection")
 
         if online_store and online_store.type != ONLINE_MATERIALIZATION_STORE_TYPE:
             raise ValidationError("online store type should be redis")
 
         if online_store and rest_workspace_obj.feature_store_settings.online_store_connection_name:
             existing_online_store_connection = self._workspace_connection_operation.get(
                 resource_group,
@@ -292,17 +308,16 @@
                     or existing_online_store_connection.properties.target != online_store.target
                 ):
                     module_logger.info(
                         "Warning: You have changed the online store connection, "
                         "any data that was materialized earlier "
                         "will not be available. You have to run backfill again."
                     )
-            else:
-                if not materialization_identity:
-                    raise ValidationError("Materialization identity is required to setup online store connection")
+            elif not materialization_identity:
+                raise ValidationError("Materialization identity is required to setup online store connection")
 
         feature_store_settings = FeatureStoreSettings._from_rest_object(rest_workspace_obj.feature_store_settings)
 
         if offline_store and materialization_identity:
             offline_store_connection_name = (
                 feature_store_settings.offline_store_connection_name
                 if feature_store_settings.offline_store_connection_name
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_batch_deployment_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_batch_deployment_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_registry_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_registry_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_schedule_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_schedule_operations.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 # pylint: disable=protected-access
-
 from typing import Any, Iterable
 
 from azure.ai.ml._restclient.v2023_04_01_preview import AzureMachineLearningWorkspaces as ServiceClient042023Preview
 from azure.ai.ml._scope_dependent_operations import (
     OperationConfig,
     OperationsContainer,
     OperationScope,
@@ -23,15 +22,19 @@
 from azure.ai.ml.entities._inputs_outputs.input import Input
 from azure.ai.ml.exceptions import ScheduleException, ErrorCategory, ErrorTarget
 from azure.core.credentials import TokenCredential
 from azure.core.polling import LROPoller
 from azure.core.tracing.decorator import distributed_trace
 
 from .._restclient.v2022_10_01.models import ScheduleListViewType
-from .._utils._arm_id_utils import is_ARM_id_for_parented_resource, AMLNamedArmId
+from .._utils._arm_id_utils import (
+    is_ARM_id_for_parented_resource,
+    AMLNamedArmId,
+    AMLVersionedArmId,
+)
 from .._utils.utils import snake_to_camel
 from .._utils._azureml_polling import AzureMLPolling
 from ..constants._common import (
     ARM_ID_PREFIX,
     AzureMLResourceType,
     LROConfigurations,
     NAMED_RESOURCE_ID_FORMAT_WITH_PARENT,
@@ -279,20 +282,31 @@
         model_inputs_name, model_outputs_name = None, None
         model_inputs_version, model_outputs_version = None, None
         mdc_input_enabled, mdc_output_enabled = False, False
         target = schedule.create_monitor.monitoring_target
         if target and target.endpoint_deployment_id:
             endpoint_name, deployment_name = self._process_and_get_endpoint_deployment_names_from_id(target)
             online_deployment = self._online_deployment_operations.get(deployment_name, endpoint_name)
-            model_inputs_name = online_deployment.tags.get(DEPLOYMENT_MODEL_INPUTS_NAME_KEY)
-            model_inputs_version = online_deployment.tags.get(DEPLOYMENT_MODEL_INPUTS_VERSION_KEY)
-            model_outputs_name = online_deployment.tags.get(DEPLOYMENT_MODEL_OUTPUTS_NAME_KEY)
-            model_outputs_version = online_deployment.tags.get(DEPLOYMENT_MODEL_OUTPUTS_VERSION_KEY)
-            mdc_input_enabled_str = online_deployment.tags.get(DEPLOYMENT_MODEL_INPUTS_COLLECTION_KEY)
-            mdc_output_enabled_str = online_deployment.tags.get(DEPLOYMENT_MODEL_OUTPUTS_COLLECTION_KEY)
+            deployment_data_collector = online_deployment.data_collector
+            if deployment_data_collector:
+                in_reg = AMLVersionedArmId(deployment_data_collector.collections.get("model_inputs").data)
+                out_reg = AMLVersionedArmId(deployment_data_collector.collections.get("model_outputs").data)
+                model_inputs_name = in_reg.asset_name
+                model_inputs_version = in_reg.asset_version
+                model_outputs_name = out_reg.asset_name
+                model_outputs_version = out_reg.asset_version
+                mdc_input_enabled_str = deployment_data_collector.collections.get("model_inputs").enabled
+                mdc_output_enabled_str = deployment_data_collector.collections.get("model_outputs").enabled
+            else:
+                model_inputs_name = online_deployment.tags.get(DEPLOYMENT_MODEL_INPUTS_NAME_KEY)
+                model_inputs_version = online_deployment.tags.get(DEPLOYMENT_MODEL_INPUTS_VERSION_KEY)
+                model_outputs_name = online_deployment.tags.get(DEPLOYMENT_MODEL_OUTPUTS_NAME_KEY)
+                model_outputs_version = online_deployment.tags.get(DEPLOYMENT_MODEL_OUTPUTS_VERSION_KEY)
+                mdc_input_enabled_str = online_deployment.tags.get(DEPLOYMENT_MODEL_INPUTS_COLLECTION_KEY)
+                mdc_output_enabled_str = online_deployment.tags.get(DEPLOYMENT_MODEL_OUTPUTS_COLLECTION_KEY)
             if mdc_input_enabled_str and mdc_input_enabled_str.lower() == "true":
                 mdc_input_enabled = True
             if mdc_output_enabled_str and mdc_output_enabled_str.lower() == "true":
                 mdc_output_enabled = True
         elif target and target.model_id:
             target.model_id = self._orchestrators.get_asset_arm_id(
                 target.model_id,
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_data_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_data_operations.py`

 * *Files 0% similar despite different names*

```diff
@@ -360,15 +360,15 @@
                 # service side raises an exception if we attempt to update an existing asset's asset path
                 if str(ex) == ASSET_PATH_ERROR:
                     raise AssetPathException(
                         message=CHANGED_ASSET_PATH_MSG,
                         tartget=ErrorTarget.DATA,
                         no_personal_data_message=CHANGED_ASSET_PATH_MSG_NO_PERSONAL_DATA,
                         error_category=ErrorCategory.USER_ERROR,
-                    )
+                    ) from ex
             raise ex
 
     @monitor_with_activity(logger, "Data.ImportData", ActivityType.PUBLICAPI)
     @experimental
     def import_data(self, data_import: DataImport, **kwargs) -> PipelineJob:
         """Returns the data import job that is creating the data asset.
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_run_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_run_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_compute_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_compute_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_online_endpoint_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_online_endpoint_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_store_entity_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_store_entity_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_datastore_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_datastore_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_environment_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_environment_operations.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_job_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_job_operations.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,14 +6,19 @@
 import json
 import os.path
 from os import PathLike
 from pathlib import Path
 from typing import TYPE_CHECKING, Any, Callable, Dict, Iterable, Optional, Union
 
 import jwt
+from azure.core.credentials import TokenCredential
+from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
+from azure.core.polling import LROPoller
+from azure.core.tracing.decorator import distributed_trace
+
 from azure.ai.ml._artifacts._artifact_utilities import (
     _upload_and_generate_remote_uri,
     aml_datastore_path_exists,
     download_artifact_from_aml_uri,
 )
 from azure.ai.ml._azure_environments import (
     _get_aml_resource_id_from_metadata,
@@ -84,18 +89,14 @@
     PipelineChildJobError,
     UserErrorException,
     ValidationErrorType,
     ValidationException,
 )
 from azure.ai.ml.operations._run_history_constants import RunHistoryConstants
 from azure.ai.ml.sweep import SweepJob
-from azure.core.credentials import TokenCredential
-from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
-from azure.core.polling import LROPoller
-from azure.core.tracing.decorator import distributed_trace
 
 from .._utils._experimental import experimental
 from ..constants._component import ComponentSource
 from ..entities._builders.control_flow_node import ControlFlowNode
 from ..entities._job.pipeline._io import InputOutputBase, PipelineInput, _GroupAttrDict
 from ._component_operations import ComponentOperations
 from ._compute_operations import ComputeOperations
@@ -396,15 +397,15 @@
             try:
                 return self._compute_operations.get(compute_name).id
             except ResourceNotFoundError as e:
                 # the original error is not helpful (Operation returned an invalid status 'Not Found'),
                 # so we raise a more helpful one
                 response = e.response
                 response.reason = "Not found compute with name {}".format(compute_name)
-                raise ResourceNotFoundError(response=response)
+                raise ResourceNotFoundError(response=response) from e
         return None
 
     @distributed_trace
     @experimental
     @monitor_with_telemetry_mixin(logger, "Job.Validate", ActivityType.PUBLICAPI)
     def validate(self, job: Job, *, raise_on_failure: bool = False, **kwargs) -> ValidationResult:
         """Validate a job. Anonymous assets may be created if there are inline
@@ -709,15 +710,18 @@
             raise JobException(
                 message=msg,
                 target=ErrorTarget.JOB,
                 no_personal_data_message=msg,
                 error_category=ErrorCategory.USER_ERROR,
             )
 
-        is_batch_job = job_details.tags.get("azureml.batchrun", None) == "true"
+        is_batch_job = (
+            job_details.tags.get("azureml.batchrun", None) == "true"
+            and job_details.tags.get("azureml.jobtype", None) != PipelineConstants.PIPELINE_JOB_TYPE
+        )
         outputs = {}
         download_path = Path(download_path)
         artifact_directory_name = "artifacts"
         output_directory_name = "named-outputs"
 
         def log_missing_uri(what: str):
             module_logger.debug(
@@ -887,15 +891,15 @@
         :rtype: Job
         """
 
         self._resolve_arm_id_or_azureml_id(job, self._orchestrators.get_asset_arm_id)
 
         if isinstance(job, PipelineJob):
             # Resolve top-level inputs
-            self._resolve_pipeline_job_inputs(job, job._base_path)
+            self._resolve_job_inputs(self._flatten_group_inputs(job.inputs), job._base_path)
             # inputs in sub-pipelines has been resolved in
             # self._resolve_arm_id_or_azureml_id(job, self._orchestrators.get_asset_arm_id)
             # as they are part of the pipeline component
         elif isinstance(job, AutoMLJob):
             self._resolve_automl_job_inputs(job)
         elif isinstance(job, Spark):
             self._resolve_job_inputs(job._job_inputs.values(), job._base_path)
@@ -967,28 +971,29 @@
             return resolver(target, azureml_type=AzureMLResourceType.COMPUTE)
 
     def _resolve_job_inputs(self, entries: Iterable[Union[Input, str, bool, int, float]], base_path: str):
         """resolve job inputs as ARM id or remote url."""
         for entry in entries:
             self._resolve_job_input(entry, base_path)
 
-    def _resolve_pipeline_job_inputs(self, job: PipelineJob, base_path: str):
-        """resolve pipeline job inputs as ARM id or remote url."""
-        inputs = []
+    # TODO: move it to somewhere else?
+    @classmethod
+    def _flatten_group_inputs(cls, inputs):
+        """Get flatten values from an InputDict."""
+        input_values = []
         # Flatten inputs for pipeline job
-        for key, item in job.inputs.items():
+        for key, item in inputs.items():
             if isinstance(item, _GroupAttrDict):
-                inputs.extend(item.flatten(group_parameter_name=key))
+                input_values.extend(item.flatten(group_parameter_name=key))
             else:
                 # skip resolving inferred optional input without path (in do-while + dynamic input case)
                 if isinstance(item._data, Input) and not item._data.path and item._meta._is_inferred_optional:
                     continue
-                inputs.append(item._data)
-        for entry in inputs:
-            self._resolve_job_input(entry, base_path)
+                input_values.append(item._data)
+        return input_values
 
     def _resolve_job_input(self, entry: Union[Input, str, bool, int, float], base_path: str) -> None:
         """resolve job input as ARM id or remote url."""
 
         # path can be empty if the job was created from builder functions
         if isinstance(entry, Input) and not entry.path:
             msg = "Input path can't be empty for jobs."
@@ -1070,15 +1075,15 @@
                 message=f"Supported input path value are ARM id, AzureML id, remote uri or local path.\n"
                 f"Met {type(e)}:\n{e}",
                 target=ErrorTarget.JOB,
                 no_personal_data_message="Supported input path value are ARM id, AzureML id, remote uri or local path.",
                 error=e,
                 error_category=ErrorCategory.USER_ERROR,
                 error_type=ValidationErrorType.INVALID_VALUE,
-            )
+            ) from e
 
     def _resolve_job_inputs_arm_id(self, job: Job) -> None:
         try:
             inputs: Dict[str, Union[Input, InputOutputBase, str, bool, int, float]] = job.inputs
             for _, entry in inputs.items():
                 if isinstance(entry, InputOutputBase):
                     # extract original input form input builder.
@@ -1232,15 +1237,15 @@
             )
         except ComponentException as e:
             raise JobException(
                 message=e.message,
                 target=ErrorTarget.JOB,
                 no_personal_data_message=e.no_personal_data_message,
                 error_category=e.error_category,
-            )
+            ) from e
 
         # Create a pipeline component for pipeline job if user specified component in job yaml.
         if (
             not isinstance(pipeline_job.component, str)
             and getattr(pipeline_job.component, "_source", None) == ComponentSource.YAML_COMPONENT
         ):
             pipeline_job.component = resolver(
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_workspace_operations_base.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_workspace_operations_base.py`

 * *Files identical despite different names*

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_component_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_component_operations.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,19 +6,21 @@
 
 import time
 import types
 from functools import partial
 from inspect import Parameter, signature
 from typing import Any, Callable, Dict, Iterable, List, Optional, Union
 
+from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
+
 from azure.ai.ml._restclient.v2021_10_01_dataplanepreview import (
     AzureMachineLearningWorkspaces as ServiceClient102021Dataplane,
 )
 from azure.ai.ml._restclient.v2022_10_01 import AzureMachineLearningWorkspaces as ServiceClient102022
-from azure.ai.ml._restclient.v2022_10_01.models import ListViewType
+from azure.ai.ml._restclient.v2022_10_01.models import ComponentVersion, ListViewType
 from azure.ai.ml._scope_dependent_operations import (
     OperationConfig,
     OperationsContainer,
     OperationScope,
     _ScopeDependentOperations,
 )
 from azure.ai.ml._telemetry import ActivityType, monitor_with_activity, monitor_with_telemetry_mixin
@@ -45,14 +47,15 @@
 from .._utils._cache_utils import CachedNodeResolver
 from .._utils._experimental import experimental
 from .._utils.utils import is_data_binding_expression
 from ..entities._builders import BaseNode
 from ..entities._builders.condition_node import ConditionNode
 from ..entities._builders.control_flow_node import LoopNode
 from ..entities._component.automl_component import AutoMLComponent
+from ..entities._component.code import ComponentCodeMixin
 from ..entities._component.pipeline_component import PipelineComponent
 from ..entities._job.pipeline._attr_dict import has_attr_safe
 from ._code_operations import CodeOperations
 from ._environment_operations import EnvironmentOperations
 from ._operation_orchestrator import OperationOrchestrator
 from ._workspace_operations import WorkspaceOperations
 
@@ -85,14 +88,16 @@
         self._all_operations = all_operations
         self._init_args = kwargs
         # Maps a label to a function which given an asset name,
         # returns the asset associated with the label
         self._managed_label_resolver = {"latest": self._get_latest_version}
         self._orchestrators = OperationOrchestrator(self._all_operations, self._operation_scope, self._operation_config)
 
+        self._client_key: Optional[str] = None
+
     @property
     def _code_operations(self) -> CodeOperations:
         return self._all_operations.get_operation(AzureMLResourceType.CODE, lambda x: isinstance(x, CodeOperations))
 
     @property
     def _environment_operations(self) -> EnvironmentOperations:
         return self._all_operations.get_operation(
@@ -163,14 +168,44 @@
                 workspace_name=self._workspace_name,
                 list_view_type=list_view_type,
                 **self._init_args,
                 cls=lambda objs: [Component._from_container_rest_object(obj) for obj in objs],
             )
         )
 
+    @monitor_with_telemetry_mixin(logger, "ComponentVersion.Get", ActivityType.INTERNALCALL)
+    def _get_component_version(self, name: str, version: Optional[str] = DEFAULT_COMPONENT_VERSION) -> ComponentVersion:
+        """Returns ComponentVersion information about the specified component name and version.
+
+        :param name: Name of the code component.
+        :type name: str
+        :param version: Version of the component.
+        :type version: Optional[str]
+        :return: The ComponentVersion object of the specified component name and version.
+        :rtype: ~azure.ai.ml.entities.ComponentVersion
+        """
+        result = (
+            self._version_operation.get(
+                name=name,
+                version=version,
+                resource_group_name=self._resource_group_name,
+                registry_name=self._registry_name,
+                **self._init_args,
+            )
+            if self._registry_name
+            else self._version_operation.get(
+                name=name,
+                version=version,
+                resource_group_name=self._resource_group_name,
+                workspace_name=self._workspace_name,
+                **self._init_args,
+            )
+        )
+        return result
+
     @monitor_with_telemetry_mixin(logger, "Component.Get", ActivityType.PUBLICAPI)
     def get(self, name: str, version: Optional[str] = None, label: Optional[str] = None) -> Component:
         """Returns information about the specified component.
 
         :param name: Name of the code component.
         :type name: str
         :param version: Version of the component.
@@ -197,31 +232,15 @@
         if label == DEFAULT_LABEL_NAME:
             label = None
             version = DEFAULT_COMPONENT_VERSION
 
         if label:
             return _resolve_label_to_asset(self, name, label)
 
-        result = (
-            self._version_operation.get(
-                name=name,
-                version=version,
-                resource_group_name=self._resource_group_name,
-                registry_name=self._registry_name,
-                **self._init_args,
-            )
-            if self._registry_name
-            else self._version_operation.get(
-                name=name,
-                version=version,
-                resource_group_name=self._resource_group_name,
-                workspace_name=self._workspace_name,
-                **self._init_args,
-            )
-        )
+        result = self._get_component_version(name, version)
         component = Component._from_rest_object(result)
         self._resolve_dependencies_for_pipeline_component_jobs(
             component,
             resolver=self._orchestrators.resolve_azureml_id,
             resolve_inputs=False,
         )
         return component
@@ -350,14 +369,34 @@
         if not component._intellectual_property:
             self._resolve_arm_id_or_upload_dependencies(component)
 
         name, version = component._get_rest_name_version()
         rest_component_resource = component._to_rest_object()
         result = None
         try:
+            if not component._is_anonymous and kwargs.get("skip_if_no_change"):
+                client_component_hash = rest_component_resource.properties.properties.get("client_component_hash")
+                remote_component_version = self._get_component_version(name=name)  # will raise error if not found.
+                remote_component_hash = remote_component_version.properties.properties.get("client_component_hash")
+                if client_component_hash == remote_component_hash:
+                    component.version = remote_component_version.properties.component_spec.get(
+                        "version"
+                    )  # only update the default version component instead of creating a new version component
+                    version = component.version
+                    rest_component_resource = component._to_rest_object()
+                    logger.warning(
+                        "The component is not modified compared to the default version "
+                        "and the new version component registration is skipped."
+                    )
+        except ResourceNotFoundError as e:
+            logger.info("Failed to get component version, %s", e)
+        except Exception as e:  # pylint: disable=broad-except
+            logger.error("Failed to compare client_component_hash, %s", e)
+
+        try:
             if self._registry_name:
                 start_time = time.time()
                 path_format_arguments = {
                     "componentName": component.name,
                     "resourceGroupName": self._resource_group_name,
                     "registryName": self._registry_name,
                 }
@@ -548,29 +587,23 @@
 
         :param jobs: A dict of nodes in a pipeline component.
         :type jobs: Dict[str, Any]
         :param base_path: The base path used to resolve inputs. Usually it's
         the base path of the pipeline component.
         :type base_path: str
         """
-        from azure.ai.ml.entities._builders import Pipeline
         from azure.ai.ml.entities._job.automl.automl_job import AutoMLJob
 
         for _, job_instance in jobs.items():
             # resolve inputs for each job's component
-            if isinstance(job_instance, Pipeline):
-                node: Pipeline = job_instance
-                self._job_operations._resolve_pipeline_job_inputs(
-                    node,
-                    base_path,
-                )
-            elif isinstance(job_instance, BaseNode):
+            if isinstance(job_instance, BaseNode):
                 node: BaseNode = job_instance
                 self._job_operations._resolve_job_inputs(
-                    map(lambda x: x._data, node.inputs.values()),
+                    # parameter group input need to be flattened first
+                    self._job_operations._flatten_group_inputs(node.inputs),
                     base_path,
                 )
             elif isinstance(job_instance, AutoMLJob):
                 self._job_operations._resolve_automl_job_inputs(job_instance)
 
     @classmethod
     def _resolve_binding_on_supported_fields_for_node(cls, node):
@@ -715,14 +748,52 @@
         # if there is subgraph, the last item in layers will be empty for now as all leaf nodes are stored in leaf_nodes
         if len(layers) != 0:
             layers.pop()
             layers.append(leaf_nodes)
 
         return layers
 
+    def _get_workspace_key(self) -> str:
+        try:
+            workspace_rest = self._workspace_operations._operation.get(
+                resource_group_name=self._resource_group_name, workspace_name=self._workspace_name
+            )
+            return workspace_rest.workspace_id
+        except HttpResponseError:
+            return "{}/{}/{}".format(self._subscription_id, self._resource_group_name, self._workspace_name)
+
+    def _get_registry_key(self) -> str:
+        """Get key for used registry.
+        Note that, although registry id is in registry discovery response, it is not in RegistryDiscoveryDto; and we'll
+        lose the information after deserialization.
+        To avoid changing related rest client, we simply use registry related information from self to construct
+        registry key, which means that on-disk cache will be invalid if a registry is deleted and then created
+        again with the same name.
+        """
+        return "{}/{}/{}".format(self._subscription_id, self._resource_group_name, self._registry_name)
+
+    def _get_client_key(self) -> str:
+        """Get key for used client.
+        Key should be able to uniquely identify used registry or workspace.
+        """
+        # check cache first
+        if self._client_key:
+            return self._client_key
+
+        # registry name has a higher priority comparing to workspace name according to current __init__ implementation
+        # of MLClient
+        if self._registry_name:
+            self._client_key = "registry/" + self._get_registry_key()
+        elif self._workspace_name:
+            self._client_key = "workspace/" + self._get_workspace_key()
+        else:
+            # This should never happen.
+            raise ValueError("Either workspace name or registry name must be provided to use component operations.")
+        return self._client_key
+
     def _resolve_dependencies_for_pipeline_component_jobs(
         self, component: Union[Component, str], resolver: Callable, *, resolve_inputs: bool = True
     ):
         """Resolve dependencies for pipeline component jobs.
         Will directly return if component is not a pipeline component.
 
         :param component: The pipeline component to resolve.
@@ -756,18 +827,15 @@
         )
 
         # cache anonymous component only for now
         # request level in-memory cache can be a better solution for other type of assets as they are
         # relatively simple and of small number of distinct instances
         component_cache = CachedNodeResolver(
             resolver=resolver,
-            subscription_id=self._subscription_id,
-            resource_group_name=self._resource_group_name,
-            workspace_name=self._workspace_name,
-            registry_name=self._registry_name,
+            client_key=self._get_client_key(),
         )
 
         for layer in reversed(layers):
             for _, job_instance in layer:
                 if isinstance(job_instance, AutoMLJob):
                     # only compute is resolved here
                     self._job_operations._resolve_arm_id_for_automl_job(job_instance, resolver, inside_pipeline=True)
@@ -858,11 +926,12 @@
         no_personal_data_message=msg.format("component"),
         error_category=ErrorCategory.USER_ERROR,
         target=ErrorTarget.COMPONENT,
     )
 
 
 def _try_resolve_code_for_component(component: Component, get_arm_id_and_fill_back: Callable) -> None:
-    with component._resolve_local_code() as code:
-        if code is None:
-            return
-        component.code = get_arm_id_and_fill_back(code, azureml_type=AzureMLResourceType.CODE)
+    if isinstance(component, ComponentCodeMixin):
+        with component._build_code() as code:
+            if code is None:
+                return
+            component.code = get_arm_id_and_fill_back(code, azureml_type=AzureMLResourceType.CODE)
```

## Comparing `azure-ai-ml-1.8.0/azure/ai/ml/operations/_feature_set_operations.py` & `azure-ai-ml-1.9.0/azure/ai/ml/operations/_feature_set_operations.py`

 * *Files identical despite different names*

