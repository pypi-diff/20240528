# Comparing `tmp/scikit_decide-0.9.8-cp39-cp39-win_amd64.whl.zip` & `tmp/scikit_decide-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,193 +1,291 @@
-Zip file size: 2218841 bytes, number of entries: 191
--rw-r--r--  2.0 fat     1106 b- defN 80-Jan-01 00:00 LICENSE
--rw-r--r--  2.0 fat     2274 b- defN 80-Jan-01 00:00 README.md
--rw-r--r--  2.0 fat      346 b- defN 80-Jan-01 00:00 skdecide/__init__.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/builders/__init__.py
--rw-r--r--  2.0 fat      720 b- defN 80-Jan-01 00:00 skdecide/builders/domain/__init__.py
--rw-r--r--  2.0 fat     1184 b- defN 80-Jan-01 00:00 skdecide/builders/domain/agent.py
--rw-r--r--  2.0 fat      681 b- defN 80-Jan-01 00:00 skdecide/builders/domain/concurrency.py
--rw-r--r--  2.0 fat     2340 b- defN 80-Jan-01 00:00 skdecide/builders/domain/constraints.py
--rw-r--r--  2.0 fat    24067 b- defN 80-Jan-01 00:00 skdecide/builders/domain/dynamics.py
--rw-r--r--  2.0 fat    14312 b- defN 80-Jan-01 00:00 skdecide/builders/domain/events.py
--rw-r--r--  2.0 fat     4276 b- defN 80-Jan-01 00:00 skdecide/builders/domain/goals.py
--rw-r--r--  2.0 fat     6096 b- defN 80-Jan-01 00:00 skdecide/builders/domain/initialization.py
--rw-r--r--  2.0 fat     4064 b- defN 80-Jan-01 00:00 skdecide/builders/domain/memory.py
--rw-r--r--  2.0 fat     8150 b- defN 80-Jan-01 00:00 skdecide/builders/domain/observability.py
--rw-r--r--  2.0 fat     2642 b- defN 80-Jan-01 00:00 skdecide/builders/domain/renderability.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/__init__.py
--rw-r--r--  2.0 fat     8453 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/conditional_tasks.py
--rw-r--r--  2.0 fat     3990 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/graph_toolbox.py
--rw-r--r--  2.0 fat     8060 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/modes.py
--rw-r--r--  2.0 fat     1349 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/preallocations.py
--rw-r--r--  2.0 fat     4052 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/precedence.py
--rw-r--r--  2.0 fat     4585 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/preemptivity.py
--rw-r--r--  2.0 fat     4740 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/resource_availability.py
--rw-r--r--  2.0 fat     1437 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/resource_consumption.py
--rw-r--r--  2.0 fat     2911 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/resource_costs.py
--rw-r--r--  2.0 fat     3652 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/resource_renewability.py
--rw-r--r--  2.0 fat     2860 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/resource_type.py
--rw-r--r--  2.0 fat    75012 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/scheduling_domains.py
--rw-r--r--  2.0 fat    11504 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/scheduling_domains_modelling.py
--rw-r--r--  2.0 fat     5956 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/skills.py
--rw-r--r--  2.0 fat     1724 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/task.py
--rw-r--r--  2.0 fat    13202 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/task_duration.py
--rw-r--r--  2.0 fat     2071 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/task_progress.py
--rw-r--r--  2.0 fat     3324 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/time_lag.py
--rw-r--r--  2.0 fat     5890 b- defN 80-Jan-01 00:00 skdecide/builders/domain/scheduling/time_windows.py
--rw-r--r--  2.0 fat     2468 b- defN 80-Jan-01 00:00 skdecide/builders/domain/value.py
--rw-r--r--  2.0 fat      383 b- defN 80-Jan-01 00:00 skdecide/builders/solver/__init__.py
--rw-r--r--  2.0 fat     4071 b- defN 80-Jan-01 00:00 skdecide/builders/solver/assessability.py
--rw-r--r--  2.0 fat     3970 b- defN 80-Jan-01 00:00 skdecide/builders/solver/parallelability.py
--rw-r--r--  2.0 fat     4962 b- defN 80-Jan-01 00:00 skdecide/builders/solver/policy.py
--rw-r--r--  2.0 fat     1711 b- defN 80-Jan-01 00:00 skdecide/builders/solver/restorability.py
--rw-r--r--  2.0 fat    27850 b- defN 80-Jan-01 00:00 skdecide/core.py
--rw-r--r--  2.0 fat    12000 b- defN 80-Jan-01 00:00 skdecide/domains.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/hub/__init__.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/hub/domain/__init__.py
--rw-r--r--  2.0 fat      254 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/__init__.py
--rw-r--r--  2.0 fat    59170 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/domain.py
--rw-r--r--  2.0 fat     8073 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/flightplanning_utils.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/__init__.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/__init__.py
--rw-r--r--  2.0 fat     4567 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/common_utils.py
--rw-r--r--  2.0 fat    16822 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/get_weather_noaa.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/__init__.py
--rw-r--r--  2.0 fat    23309 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/GenericInterpolator.py
--rw-r--r--  2.0 fat     9329 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/intergrid.py
--rw-r--r--  2.0 fat    23337 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/WeatherInterpolator.py
--rw-r--r--  2.0 fat    23705 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/parser_pygrib.py
--rw-r--r--  2.0 fat    40593 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/std_atm.py
--rw-r--r--  2.0 fat    23006 b- defN 80-Jan-01 00:00 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/unit_conversion.py
--rw-r--r--  2.0 fat      483 b- defN 80-Jan-01 00:00 skdecide/hub/domain/gym/__init__.py
--rw-r--r--  2.0 fat    49048 b- defN 80-Jan-01 00:00 skdecide/hub/domain/gym/gym.py
--rw-r--r--  2.0 fat      208 b- defN 80-Jan-01 00:00 skdecide/hub/domain/mastermind/__init__.py
--rw-r--r--  2.0 fat     5226 b- defN 80-Jan-01 00:00 skdecide/hub/domain/mastermind/mastermind.py
--rw-r--r--  2.0 fat      196 b- defN 80-Jan-01 00:00 skdecide/hub/domain/maze/__init__.py
--rw-r--r--  2.0 fat     5380 b- defN 80-Jan-01 00:00 skdecide/hub/domain/maze/maze.py
--rw-r--r--  2.0 fat      347 b- defN 80-Jan-01 00:00 skdecide/hub/domain/rcpsp/__init__.py
--rw-r--r--  2.0 fat    25414 b- defN 80-Jan-01 00:00 skdecide/hub/domain/rcpsp/rcpsp_sk.py
--rw-r--r--  2.0 fat     3568 b- defN 80-Jan-01 00:00 skdecide/hub/domain/rcpsp/rcpsp_sk_parser.py
--rw-r--r--  2.0 fat      224 b- defN 80-Jan-01 00:00 skdecide/hub/domain/rock_paper_scissors/__init__.py
--rw-r--r--  2.0 fat     3343 b- defN 80-Jan-01 00:00 skdecide/hub/domain/rock_paper_scissors/rock_paper_scissors.py
--rw-r--r--  2.0 fat      220 b- defN 80-Jan-01 00:00 skdecide/hub/domain/simple_grid_world/__init__.py
--rw-r--r--  2.0 fat     2981 b- defN 80-Jan-01 00:00 skdecide/hub/domain/simple_grid_world/simple_grid_world.py
--rw-r--r--  2.0 fat      221 b- defN 80-Jan-01 00:00 skdecide/hub/domain/up/__init__.py
--rw-r--r--  2.0 fat    22912 b- defN 80-Jan-01 00:00 skdecide/hub/domain/up/up.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/hub/solver/__init__.py
--rw-r--r--  2.0 fat      200 b- defN 80-Jan-01 00:00 skdecide/hub/solver/aostar/__init__.py
--rw-r--r--  2.0 fat     4608 b- defN 80-Jan-01 00:00 skdecide/hub/solver/aostar/aostar.py
--rw-r--r--  2.0 fat      212 b- defN 80-Jan-01 00:00 skdecide/hub/solver/ars/__init__.py
--rw-r--r--  2.0 fat     7903 b- defN 80-Jan-01 00:00 skdecide/hub/solver/ars/ars.py
--rw-r--r--  2.0 fat      198 b- defN 80-Jan-01 00:00 skdecide/hub/solver/astar/__init__.py
--rw-r--r--  2.0 fat     4196 b- defN 80-Jan-01 00:00 skdecide/hub/solver/astar/astar.py
--rw-r--r--  2.0 fat      196 b- defN 80-Jan-01 00:00 skdecide/hub/solver/bfws/__init__.py
--rw-r--r--  2.0 fat     4894 b- defN 80-Jan-01 00:00 skdecide/hub/solver/bfws/bfws.py
--rw-r--r--  2.0 fat      208 b- defN 80-Jan-01 00:00 skdecide/hub/solver/cgp/__init__.py
--rw-r--r--  2.0 fat    13040 b- defN 80-Jan-01 00:00 skdecide/hub/solver/cgp/cgp.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/hub/solver/cgp/pycgp/__init__.py
--rw-r--r--  2.0 fat    13284 b- defN 80-Jan-01 00:00 skdecide/hub/solver/cgp/pycgp/cgp.py
--rw-r--r--  2.0 fat     4635 b- defN 80-Jan-01 00:00 skdecide/hub/solver/cgp/pycgp/cgpes.py
--rw-r--r--  2.0 fat     1497 b- defN 80-Jan-01 00:00 skdecide/hub/solver/cgp/pycgp/cgpfunctions.py
--rw-r--r--  2.0 fat      413 b- defN 80-Jan-01 00:00 skdecide/hub/solver/cgp/pycgp/evaluator.py
--rw-r--r--  2.0 fat      216 b- defN 80-Jan-01 00:00 skdecide/hub/solver/do_solver/__init__.py
--rw-r--r--  2.0 fat     8292 b- defN 80-Jan-01 00:00 skdecide/hub/solver/do_solver/do_solver_scheduling.py
--rw-r--r--  2.0 fat    18087 b- defN 80-Jan-01 00:00 skdecide/hub/solver/do_solver/sk_to_do_binding.py
--rw-r--r--  2.0 fat      390 b- defN 80-Jan-01 00:00 skdecide/hub/solver/gphh/__init__.py
--rw-r--r--  2.0 fat    48433 b- defN 80-Jan-01 00:00 skdecide/hub/solver/gphh/gphh.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/hub/solver/graph_explorer/__init__.py
--rw-r--r--  2.0 fat     3931 b- defN 80-Jan-01 00:00 skdecide/hub/solver/graph_explorer/DFS_Uncertain_Exploration.py
--rw-r--r--  2.0 fat     3363 b- defN 80-Jan-01 00:00 skdecide/hub/solver/graph_explorer/DFSExploration.py
--rw-r--r--  2.0 fat     3476 b- defN 80-Jan-01 00:00 skdecide/hub/solver/graph_explorer/FullSpaceExploration.py
--rw-r--r--  2.0 fat     7880 b- defN 80-Jan-01 00:00 skdecide/hub/solver/graph_explorer/GraphDomain.py
--rw-r--r--  2.0 fat      567 b- defN 80-Jan-01 00:00 skdecide/hub/solver/graph_explorer/GraphExploration.py
--rw-r--r--  2.0 fat      204 b- defN 80-Jan-01 00:00 skdecide/hub/solver/ilaostar/__init__.py
--rw-r--r--  2.0 fat     4900 b- defN 80-Jan-01 00:00 skdecide/hub/solver/ilaostar/ilaostar.py
--rw-r--r--  2.0 fat      192 b- defN 80-Jan-01 00:00 skdecide/hub/solver/iw/__init__.py
--rw-r--r--  2.0 fat     5085 b- defN 80-Jan-01 00:00 skdecide/hub/solver/iw/iw.py
--rw-r--r--  2.0 fat      207 b- defN 80-Jan-01 00:00 skdecide/hub/solver/lazy_astar/__init__.py
--rw-r--r--  2.0 fat     7301 b- defN 80-Jan-01 00:00 skdecide/hub/solver/lazy_astar/lazy_astar.py
--rw-r--r--  2.0 fat      204 b- defN 80-Jan-01 00:00 skdecide/hub/solver/lrtastar/__init__.py
--rw-r--r--  2.0 fat     6062 b- defN 80-Jan-01 00:00 skdecide/hub/solver/lrtastar/lrtastar.py
--rw-r--r--  2.0 fat      198 b- defN 80-Jan-01 00:00 skdecide/hub/solver/lrtdp/__init__.py
--rw-r--r--  2.0 fat     6848 b- defN 80-Jan-01 00:00 skdecide/hub/solver/lrtdp/lrtdp.py
--rw-r--r--  2.0 fat      196 b- defN 80-Jan-01 00:00 skdecide/hub/solver/mahd/__init__.py
--rw-r--r--  2.0 fat     7909 b- defN 80-Jan-01 00:00 skdecide/hub/solver/mahd/mahd.py
--rw-r--r--  2.0 fat      200 b- defN 80-Jan-01 00:00 skdecide/hub/solver/martdp/__init__.py
--rw-r--r--  2.0 fat     7645 b- defN 80-Jan-01 00:00 skdecide/hub/solver/martdp/martdp.py
--rw-r--r--  2.0 fat      207 b- defN 80-Jan-01 00:00 skdecide/hub/solver/maxent_irl/__init__.py
--rw-r--r--  2.0 fat     9855 b- defN 80-Jan-01 00:00 skdecide/hub/solver/maxent_irl/maxent_irl.py
--rw-r--r--  2.0 fat      214 b- defN 80-Jan-01 00:00 skdecide/hub/solver/mcts/__init__.py
--rw-r--r--  2.0 fat    18581 b- defN 80-Jan-01 00:00 skdecide/hub/solver/mcts/mcts.py
--rw-r--r--  2.0 fat      211 b- defN 80-Jan-01 00:00 skdecide/hub/solver/meta_policy/__init__.py
--rw-r--r--  2.0 fat     2729 b- defN 80-Jan-01 00:00 skdecide/hub/solver/meta_policy/meta_policies.py
--rw-r--r--  2.0 fat      223 b- defN 80-Jan-01 00:00 skdecide/hub/solver/pile_policy/__init__.py
--rw-r--r--  2.0 fat     5114 b- defN 80-Jan-01 00:00 skdecide/hub/solver/pile_policy/pile_policy.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/hub/solver/policy_evaluators/__init__.py
--rw-r--r--  2.0 fat     6796 b- defN 80-Jan-01 00:00 skdecide/hub/solver/policy_evaluators/policy_evaluator.py
--rw-r--r--  2.0 fat      198 b- defN 80-Jan-01 00:00 skdecide/hub/solver/pomcp/__init__.py
--rw-r--r--  2.0 fat    10208 b- defN 80-Jan-01 00:00 skdecide/hub/solver/pomcp/pomcp.py
--rw-r--r--  2.0 fat      205 b- defN 80-Jan-01 00:00 skdecide/hub/solver/ray_rllib/__init__.py
--rw-r--r--  2.0 fat     6412 b- defN 80-Jan-01 00:00 skdecide/hub/solver/ray_rllib/custom_models.py
--rw-r--r--  2.0 fat    20567 b- defN 80-Jan-01 00:00 skdecide/hub/solver/ray_rllib/ray_rllib.py
--rw-r--r--  2.0 fat      194 b- defN 80-Jan-01 00:00 skdecide/hub/solver/riw/__init__.py
--rw-r--r--  2.0 fat     7255 b- defN 80-Jan-01 00:00 skdecide/hub/solver/riw/riw.py
--rw-r--r--  2.0 fat      249 b- defN 80-Jan-01 00:00 skdecide/hub/solver/sgs_policies/__init__.py
--rw-r--r--  2.0 fat    18069 b- defN 80-Jan-01 00:00 skdecide/hub/solver/sgs_policies/sgs_policies.py
--rw-r--r--  2.0 fat      213 b- defN 80-Jan-01 00:00 skdecide/hub/solver/simple_greedy/__init__.py
--rw-r--r--  2.0 fat     2382 b- defN 80-Jan-01 00:00 skdecide/hub/solver/simple_greedy/simple_greedy.py
--rw-r--r--  2.0 fat      218 b- defN 80-Jan-01 00:00 skdecide/hub/solver/stable_baselines/__init__.py
--rw-r--r--  2.0 fat     3558 b- defN 80-Jan-01 00:00 skdecide/hub/solver/stable_baselines/stable_baselines.py
--rw-r--r--  2.0 fat      198 b- defN 80-Jan-01 00:00 skdecide/hub/solver/up/__init__.py
--rw-r--r--  2.0 fat     3670 b- defN 80-Jan-01 00:00 skdecide/hub/solver/up/up.py
--rw-r--r--  2.0 fat      170 b- defN 80-Jan-01 00:00 skdecide/hub/space/__init__.py
--rw-r--r--  2.0 fat      389 b- defN 80-Jan-01 00:00 skdecide/hub/space/gym/__init__.py
--rw-r--r--  2.0 fat    17837 b- defN 80-Jan-01 00:00 skdecide/hub/space/gym/gym.py
--rw-r--r--  2.0 fat    25047 b- defN 80-Jan-01 00:00 skdecide/parallel_domains.py
--rw-r--r--  2.0 fat    11087 b- defN 80-Jan-01 00:00 skdecide/solvers.py
--rw-r--r--  2.0 fat    16419 b- defN 80-Jan-01 00:00 skdecide/utils.py
--rw-r--r--  2.0 fat 10720768 b- defN 80-Jan-01 00:00 skdecide/hub/__skdecide_hub_cpp.cp39-win_amd64.pyd
--rw-r--r--  2.0 fat      975 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/bus.h
--rw-r--r--  2.0 fat      955 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/inproc.h
--rw-r--r--  2.0 fat     1296 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/ipc.h
--rw-r--r--  2.0 fat     8179 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/nn.h
--rw-r--r--  2.0 fat     1286 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/pair.h
--rw-r--r--  2.0 fat     1068 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/pipeline.h
--rw-r--r--  2.0 fat     1141 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/pubsub.h
--rw-r--r--  2.0 fat     1096 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/reqrep.h
--rw-r--r--  2.0 fat     1142 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/survey.h
--rw-r--r--  2.0 fat      951 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/tcp.h
--rw-r--r--  2.0 fat     1313 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/compat/nanomsg/ws.h
--rw-r--r--  2.0 fat    65650 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/nng.h
--rw-r--r--  2.0 fat      947 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/bus0/bus.h
--rw-r--r--  2.0 fat      835 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/pair0/pair.h
--rw-r--r--  2.0 fat     1064 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/pair1/pair.h
--rw-r--r--  2.0 fat      845 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/pipeline0/pull.h
--rw-r--r--  2.0 fat      845 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/pipeline0/push.h
--rw-r--r--  2.0 fat      828 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/pubsub0/pub.h
--rw-r--r--  2.0 fat      975 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/pubsub0/sub.h
--rw-r--r--  2.0 fat      954 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/reqrep0/rep.h
--rw-r--r--  2.0 fat     1004 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/reqrep0/req.h
--rw-r--r--  2.0 fat     1062 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/survey0/respond.h
--rw-r--r--  2.0 fat     1097 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/protocol/survey0/survey.h
--rw-r--r--  2.0 fat    26428 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/supplemental/http/http.h
--rw-r--r--  2.0 fat     9902 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/supplemental/tls/engine.h
--rw-r--r--  2.0 fat     6322 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/supplemental/tls/tls.h
--rw-r--r--  2.0 fat     1818 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/supplemental/util/options.h
--rw-r--r--  2.0 fat     4285 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/supplemental/util/platform.h
--rw-r--r--  2.0 fat      771 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/transport/inproc/inproc.h
--rw-r--r--  2.0 fat      779 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/transport/ipc/ipc.h
--rw-r--r--  2.0 fat      747 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/transport/tcp/tcp.h
--rw-r--r--  2.0 fat      760 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/transport/tls/tls.h
--rw-r--r--  2.0 fat      989 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/transport/ws/websocket.h
--rw-r--r--  2.0 fat     7462 b- defN 80-Jan-01 00:00 skdecide/hub/include/nng/transport/zerotier/zerotier.h
--rw-r--r--  2.0 fat     2827 b- defN 80-Jan-01 00:00 skdecide/hub/lib/cmake/nng/nng-config-version.cmake
--rw-r--r--  2.0 fat     1635 b- defN 80-Jan-01 00:00 skdecide/hub/lib/cmake/nng/nng-config.cmake
--rw-r--r--  2.0 fat      822 b- defN 80-Jan-01 00:00 skdecide/hub/lib/cmake/nng/nng-targets-release.cmake
--rw-r--r--  2.0 fat     4257 b- defN 80-Jan-01 00:00 skdecide/hub/lib/cmake/nng/nng-targets.cmake
--rw-r--r--  2.0 fat  1637286 b- defN 80-Jan-01 00:00 skdecide/hub/lib/nng.lib
--rw-r--r--  2.0 fat     2552 b- defN 80-Jan-01 00:00 scikit_decide-0.9.8.dist-info/entry_points.txt
--rw-r--r--  2.0 fat     1106 b- defN 80-Jan-01 00:00 scikit_decide-0.9.8.dist-info/LICENSE
--rw-r--r--  2.0 fat     5490 b- defN 80-Jan-01 00:00 scikit_decide-0.9.8.dist-info/METADATA
--rw-r--r--  2.0 fat       96 b- defN 80-Jan-01 00:00 scikit_decide-0.9.8.dist-info/WHEEL
-?rw-r--r--  2.0 fat    19295 b- defN 16-Jan-01 00:00 scikit_decide-0.9.8.dist-info/RECORD
-191 files, 13585391 bytes uncompressed, 2187303 bytes compressed:  83.9%
+Zip file size: 5714709 bytes, number of entries: 289
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 scikit_decide-1.0.0.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 scikit_decide.libs/
+-rw-r--r--  2.0 unx     2216 b- defN 24-May-28 15:15 README.md
+-rw-r--r--  2.0 unx     1085 b- defN 24-May-28 15:15 LICENSE
+-rw-r--r--  2.0 unx      149 b- defN 24-May-28 15:15 scikit_decide-1.0.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx     1085 b- defN 24-May-28 15:15 scikit_decide-1.0.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2552 b- defN 24-May-28 15:15 scikit_decide-1.0.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx    22156 b- defN 24-May-28 15:15 scikit_decide-1.0.0.dist-info/RECORD
+-rw-r--r--  2.0 unx     5451 b- defN 24-May-28 15:15 scikit_decide-1.0.0.dist-info/METADATA
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/builders/
+-rw-r--r--  2.0 unx      335 b- defN 24-May-28 15:15 skdecide/__init__.py
+-rw-r--r--  2.0 unx    24640 b- defN 24-May-28 15:15 skdecide/parallel_domains.py
+-rw-r--r--  2.0 unx     7808 b- defN 24-May-28 15:15 skdecide/solvers.py
+-rw-r--r--  2.0 unx    11776 b- defN 24-May-28 15:15 skdecide/utils.py
+-rw-r--r--  2.0 unx    27026 b- defN 24-May-28 15:15 skdecide/core.py
+-rw-r--r--  2.0 unx    10412 b- defN 24-May-28 15:15 skdecide/domains.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/space/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/lib64/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/
+-rw-r--r--  2.0 unx      167 b- defN 24-May-28 15:15 skdecide/hub/__init__.py
+-rwxr-xr-x  2.0 unx 15818569 b- defN 24-May-28 15:15 skdecide/hub/__skdecide_hub_cpp.cpython-311-x86_64-linux-gnu.so
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/space/gym/
+-rw-r--r--  2.0 unx      167 b- defN 24-May-28 15:15 skdecide/hub/space/__init__.py
+-rw-r--r--  2.0 unx      372 b- defN 24-May-28 15:15 skdecide/hub/space/gym/__init__.py
+-rw-r--r--  2.0 unx    17326 b- defN 24-May-28 15:15 skdecide/hub/space/gym/gym.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/meta_policy_scheduling/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/martdp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/bfws/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/iw/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/simple_greedy/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/ray_rllib/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/stable_baselines/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/mahd/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/pomcp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/lazy_astar/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/aostar/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/lrtdp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/do_solver/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/lrtastar/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/pile_policy_scheduling/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/riw/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/cgp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/ars/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/up/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/astar/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/mcts/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/ilaostar/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/maxent_irl/
+-rw-r--r--  2.0 unx      167 b- defN 24-May-28 15:15 skdecide/hub/solver/__init__.py
+-rw-r--r--  2.0 unx      206 b- defN 24-May-28 15:15 skdecide/hub/solver/meta_policy_scheduling/__init__.py
+-rw-r--r--  2.0 unx     3128 b- defN 24-May-28 15:15 skdecide/hub/solver/meta_policy_scheduling/meta_policies.py
+-rw-r--r--  2.0 unx     6032 b- defN 24-May-28 15:15 skdecide/hub/solver/meta_policy_scheduling/policy_evaluator.py
+-rw-r--r--  2.0 unx      195 b- defN 24-May-28 15:15 skdecide/hub/solver/martdp/__init__.py
+-rw-r--r--  2.0 unx    16289 b- defN 24-May-28 15:15 skdecide/hub/solver/martdp/martdp.py
+-rw-r--r--  2.0 unx      191 b- defN 24-May-28 15:15 skdecide/hub/solver/bfws/__init__.py
+-rw-r--r--  2.0 unx    12300 b- defN 24-May-28 15:15 skdecide/hub/solver/bfws/bfws.py
+-rw-r--r--  2.0 unx      187 b- defN 24-May-28 15:15 skdecide/hub/solver/iw/__init__.py
+-rw-r--r--  2.0 unx    12324 b- defN 24-May-28 15:15 skdecide/hub/solver/iw/iw.py
+-rw-r--r--  2.0 unx      208 b- defN 24-May-28 15:15 skdecide/hub/solver/simple_greedy/__init__.py
+-rw-r--r--  2.0 unx     2288 b- defN 24-May-28 15:15 skdecide/hub/solver/simple_greedy/simple_greedy.py
+-rw-r--r--  2.0 unx    26361 b- defN 24-May-28 15:15 skdecide/hub/solver/ray_rllib/ray_rllib.py
+-rw-r--r--  2.0 unx      200 b- defN 24-May-28 15:15 skdecide/hub/solver/ray_rllib/__init__.py
+-rw-r--r--  2.0 unx     6266 b- defN 24-May-28 15:15 skdecide/hub/solver/ray_rllib/custom_models.py
+-rw-r--r--  2.0 unx      213 b- defN 24-May-28 15:15 skdecide/hub/solver/stable_baselines/__init__.py
+-rw-r--r--  2.0 unx     5442 b- defN 24-May-28 15:15 skdecide/hub/solver/stable_baselines/stable_baselines.py
+-rw-r--r--  2.0 unx      191 b- defN 24-May-28 15:15 skdecide/hub/solver/mahd/__init__.py
+-rw-r--r--  2.0 unx    14449 b- defN 24-May-28 15:15 skdecide/hub/solver/mahd/mahd.py
+-rw-r--r--  2.0 unx      193 b- defN 24-May-28 15:15 skdecide/hub/solver/pomcp/__init__.py
+-rw-r--r--  2.0 unx    10564 b- defN 24-May-28 15:15 skdecide/hub/solver/pomcp/pomcp.py
+-rw-r--r--  2.0 unx      202 b- defN 24-May-28 15:15 skdecide/hub/solver/lazy_astar/__init__.py
+-rw-r--r--  2.0 unx     8329 b- defN 24-May-28 15:15 skdecide/hub/solver/lazy_astar/lazy_astar.py
+-rw-r--r--  2.0 unx      195 b- defN 24-May-28 15:15 skdecide/hub/solver/aostar/__init__.py
+-rw-r--r--  2.0 unx    11616 b- defN 24-May-28 15:15 skdecide/hub/solver/aostar/aostar.py
+-rw-r--r--  2.0 unx      198 b- defN 24-May-28 15:15 skdecide/hub/solver/lrtdp/__init__.py
+-rw-r--r--  2.0 unx    15227 b- defN 24-May-28 15:15 skdecide/hub/solver/lrtdp/lrtdp.py
+-rw-r--r--  2.0 unx      494 b- defN 24-May-28 15:15 skdecide/hub/solver/do_solver/__init__.py
+-rw-r--r--  2.0 unx    10973 b- defN 24-May-28 15:15 skdecide/hub/solver/do_solver/do_solver_scheduling.py
+-rw-r--r--  2.0 unx    18192 b- defN 24-May-28 15:15 skdecide/hub/solver/do_solver/sk_to_do_binding.py
+-rw-r--r--  2.0 unx    20879 b- defN 24-May-28 15:15 skdecide/hub/solver/do_solver/sgs_policies.py
+-rw-r--r--  2.0 unx    43650 b- defN 24-May-28 15:15 skdecide/hub/solver/do_solver/gphh.py
+-rw-r--r--  2.0 unx      199 b- defN 24-May-28 15:15 skdecide/hub/solver/lrtastar/__init__.py
+-rw-r--r--  2.0 unx     6882 b- defN 24-May-28 15:15 skdecide/hub/solver/lrtastar/lrtastar.py
+-rw-r--r--  2.0 unx      218 b- defN 24-May-28 15:15 skdecide/hub/solver/pile_policy_scheduling/__init__.py
+-rw-r--r--  2.0 unx     6217 b- defN 24-May-28 15:15 skdecide/hub/solver/pile_policy_scheduling/pile_policy.py
+-rw-r--r--  2.0 unx      189 b- defN 24-May-28 15:15 skdecide/hub/solver/riw/__init__.py
+-rw-r--r--  2.0 unx    17605 b- defN 24-May-28 15:15 skdecide/hub/solver/riw/riw.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/solver/cgp/pycgp/
+-rw-r--r--  2.0 unx      203 b- defN 24-May-28 15:15 skdecide/hub/solver/cgp/__init__.py
+-rwxr-xr-x  2.0 unx    13319 b- defN 24-May-28 15:15 skdecide/hub/solver/cgp/cgp.py
+-rw-r--r--  2.0 unx      400 b- defN 24-May-28 15:15 skdecide/hub/solver/cgp/pycgp/evaluator.py
+-rw-r--r--  2.0 unx      167 b- defN 24-May-28 15:15 skdecide/hub/solver/cgp/pycgp/__init__.py
+-rw-r--r--  2.0 unx     4986 b- defN 24-May-28 15:15 skdecide/hub/solver/cgp/pycgp/cgpes.py
+-rw-r--r--  2.0 unx     1403 b- defN 24-May-28 15:15 skdecide/hub/solver/cgp/pycgp/cgpfunctions.py
+-rw-r--r--  2.0 unx    12934 b- defN 24-May-28 15:15 skdecide/hub/solver/cgp/pycgp/cgp.py
+-rw-r--r--  2.0 unx      207 b- defN 24-May-28 15:15 skdecide/hub/solver/ars/__init__.py
+-rwxr-xr-x  2.0 unx     8620 b- defN 24-May-28 15:15 skdecide/hub/solver/ars/ars.py
+-rw-r--r--  2.0 unx      193 b- defN 24-May-28 15:15 skdecide/hub/solver/up/__init__.py
+-rw-r--r--  2.0 unx     3930 b- defN 24-May-28 15:15 skdecide/hub/solver/up/up.py
+-rw-r--r--  2.0 unx    12116 b- defN 24-May-28 15:15 skdecide/hub/solver/astar/astar.py
+-rw-r--r--  2.0 unx      193 b- defN 24-May-28 15:15 skdecide/hub/solver/astar/__init__.py
+-rw-r--r--  2.0 unx      209 b- defN 24-May-28 15:15 skdecide/hub/solver/mcts/__init__.py
+-rw-r--r--  2.0 unx    52414 b- defN 24-May-28 15:15 skdecide/hub/solver/mcts/mcts.py
+-rw-r--r--  2.0 unx      199 b- defN 24-May-28 15:15 skdecide/hub/solver/ilaostar/__init__.py
+-rw-r--r--  2.0 unx    10665 b- defN 24-May-28 15:15 skdecide/hub/solver/ilaostar/ilaostar.py
+-rw-r--r--  2.0 unx      202 b- defN 24-May-28 15:15 skdecide/hub/solver/maxent_irl/__init__.py
+-rwxr-xr-x  2.0 unx    10417 b- defN 24-May-28 15:15 skdecide/hub/solver/maxent_irl/maxent_irl.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/
+-rw-r--r--  2.0 unx   141149 b- defN 24-May-28 15:15 skdecide/hub/include/backward.hpp
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/transport/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/supplemental/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/compat/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/
+-rw-r--r--  2.0 unx    64317 b- defN 24-May-28 15:15 skdecide/hub/include/nng/nng.h
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/transport/inproc/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/transport/zerotier/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/transport/ws/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/transport/ipc/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/transport/tcp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/transport/tls/
+-rw-r--r--  2.0 unx      742 b- defN 24-May-28 15:15 skdecide/hub/include/nng/transport/inproc/inproc.h
+-rw-r--r--  2.0 unx     7301 b- defN 24-May-28 15:15 skdecide/hub/include/nng/transport/zerotier/zerotier.h
+-rw-r--r--  2.0 unx      954 b- defN 24-May-28 15:15 skdecide/hub/include/nng/transport/ws/websocket.h
+-rw-r--r--  2.0 unx      748 b- defN 24-May-28 15:15 skdecide/hub/include/nng/transport/ipc/ipc.h
+-rw-r--r--  2.0 unx      717 b- defN 24-May-28 15:15 skdecide/hub/include/nng/transport/tcp/tcp.h
+-rw-r--r--  2.0 unx      730 b- defN 24-May-28 15:15 skdecide/hub/include/nng/transport/tls/tls.h
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/supplemental/util/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/supplemental/tls/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/supplemental/http/
+-rw-r--r--  2.0 unx     1770 b- defN 24-May-28 15:15 skdecide/hub/include/nng/supplemental/util/options.h
+-rw-r--r--  2.0 unx     4174 b- defN 24-May-28 15:15 skdecide/hub/include/nng/supplemental/util/platform.h
+-rw-r--r--  2.0 unx     6180 b- defN 24-May-28 15:15 skdecide/hub/include/nng/supplemental/tls/tls.h
+-rw-r--r--  2.0 unx     9687 b- defN 24-May-28 15:15 skdecide/hub/include/nng/supplemental/tls/engine.h
+-rw-r--r--  2.0 unx    25889 b- defN 24-May-28 15:15 skdecide/hub/include/nng/supplemental/http/http.h
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/
+-rw-r--r--  2.0 unx     7895 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/nn.h
+-rw-r--r--  2.0 unx     1106 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/survey.h
+-rw-r--r--  2.0 unx     1257 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/ipc.h
+-rw-r--r--  2.0 unx      942 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/bus.h
+-rw-r--r--  2.0 unx     1034 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/pipeline.h
+-rw-r--r--  2.0 unx     1247 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/pair.h
+-rw-r--r--  2.0 unx     1272 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/ws.h
+-rw-r--r--  2.0 unx      924 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/inproc.h
+-rw-r--r--  2.0 unx     1061 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/reqrep.h
+-rw-r--r--  2.0 unx      918 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/tcp.h
+-rw-r--r--  2.0 unx     1105 b- defN 24-May-28 15:15 skdecide/hub/include/nng/compat/nanomsg/pubsub.h
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/bus0/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/pair1/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/pubsub0/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/pair0/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/survey0/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/reqrep0/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/include/nng/protocol/pipeline0/
+-rw-r--r--  2.0 unx      908 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/bus0/bus.h
+-rw-r--r--  2.0 unx     1024 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/pair1/pair.h
+-rw-r--r--  2.0 unx      795 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/pubsub0/pub.h
+-rw-r--r--  2.0 unx      936 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/pubsub0/sub.h
+-rw-r--r--  2.0 unx      801 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/pair0/pair.h
+-rw-r--r--  2.0 unx     1057 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/survey0/survey.h
+-rw-r--r--  2.0 unx     1024 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/survey0/respond.h
+-rw-r--r--  2.0 unx      916 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/reqrep0/rep.h
+-rw-r--r--  2.0 unx      965 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/reqrep0/req.h
+-rw-r--r--  2.0 unx      812 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/pipeline0/pull.h
+-rw-r--r--  2.0 unx      812 b- defN 24-May-28 15:15 skdecide/hub/include/nng/protocol/pipeline0/push.h
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/lib64/backward/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/lib64/cmake/
+-rw-r--r--  2.0 unx  1042954 b- defN 24-May-28 15:15 skdecide/hub/lib64/libnng.a
+-rw-r--r--  2.0 unx     9384 b- defN 24-May-28 15:15 skdecide/hub/lib64/backward/BackwardConfig.cmake
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/lib64/cmake/nng/
+-rw-r--r--  2.0 unx      809 b- defN 24-May-28 15:15 skdecide/hub/lib64/cmake/nng/nng-targets-release.cmake
+-rw-r--r--  2.0 unx     4303 b- defN 24-May-28 15:15 skdecide/hub/lib64/cmake/nng/nng-targets.cmake
+-rw-r--r--  2.0 unx     2762 b- defN 24-May-28 15:15 skdecide/hub/lib64/cmake/nng/nng-config-version.cmake
+-rw-r--r--  2.0 unx     1592 b- defN 24-May-28 15:15 skdecide/hub/lib64/cmake/nng/nng-config.cmake
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/maze/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/gym/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/graph_domain/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/mastermind/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/simple_grid_world/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/rcpsp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/rock_paper_scissors/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/up/
+-rw-r--r--  2.0 unx      167 b- defN 24-May-28 15:15 skdecide/hub/domain/__init__.py
+-rw-r--r--  2.0 unx     5216 b- defN 24-May-28 15:15 skdecide/hub/domain/maze/maze.py
+-rw-r--r--  2.0 unx      191 b- defN 24-May-28 15:15 skdecide/hub/domain/maze/__init__.py
+-rw-r--r--  2.0 unx      466 b- defN 24-May-28 15:15 skdecide/hub/domain/gym/__init__.py
+-rw-r--r--  2.0 unx    47914 b- defN 24-May-28 15:15 skdecide/hub/domain/gym/gym.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/
+-rw-r--r--  2.0 unx      249 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/__init__.py
+-rw-r--r--  2.0 unx    12633 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/flightplanning_utils.py
+-rw-r--r--  2.0 unx    62254 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/domain.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/__init__.py
+-rw-r--r--  2.0 unx     2871 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/base.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/data/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/
+-rw-r--r--  2.0 unx     6665 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/pollschumann.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/__init__.py
+-rw-r--r--  2.0 unx     2905 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/engine_loader.py
+-rw-r--r--  2.0 unx    14679 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/data/aircraft_engine_params.csv
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/__init__.py
+-rw-r--r--  2.0 unx       53 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/aero.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/__init__.py
+-rw-r--r--  2.0 unx     2104 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/units.py
+-rw-r--r--  2.0 unx    15186 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/atmospheric_parameters.py
+-rw-r--r--  2.0 unx     2997 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/aircraft_parameters.py
+-rw-r--r--  2.0 unx     3141 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/jet.py
+-rw-r--r--  2.0 unx     3197 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/operational_limits.py
+-rw-r--r--  2.0 unx      483 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/constants.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/__init__.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/
+-rw-r--r--  2.0 unx    22331 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/unit_conversion.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/__init__.py
+-rw-r--r--  2.0 unx    16330 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/get_weather_noaa.py
+-rw-r--r--  2.0 unx    22926 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/parser_pygrib.py
+-rw-r--r--  2.0 unx    39321 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/std_atm.py
+-rw-r--r--  2.0 unx     4407 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/common_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/__init__.py
+-rw-r--r--  2.0 unx    22793 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/WeatherInterpolator.py
+-rw-r--r--  2.0 unx    23000 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/GenericInterpolator.py
+-rw-r--r--  2.0 unx     9084 b- defN 24-May-28 15:15 skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/intergrid.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/hub/domain/graph_domain/graph_domain_builders/
+-rw-r--r--  2.0 unx        0 b- defN 24-May-28 15:15 skdecide/hub/domain/graph_domain/__init__.py
+-rw-r--r--  2.0 unx     8350 b- defN 24-May-28 15:15 skdecide/hub/domain/graph_domain/GraphDomain.py
+-rw-r--r--  2.0 unx      175 b- defN 24-May-28 15:15 skdecide/hub/domain/graph_domain/graph_domain_builders/__init__.py
+-rw-r--r--  2.0 unx     3708 b- defN 24-May-28 15:15 skdecide/hub/domain/graph_domain/graph_domain_builders/DFSExploration.py
+-rw-r--r--  2.0 unx      631 b- defN 24-May-28 15:15 skdecide/hub/domain/graph_domain/graph_domain_builders/GraphExploration.py
+-rw-r--r--  2.0 unx     3804 b- defN 24-May-28 15:15 skdecide/hub/domain/graph_domain/graph_domain_builders/FullSpaceExploration.py
+-rw-r--r--  2.0 unx     4130 b- defN 24-May-28 15:15 skdecide/hub/domain/graph_domain/graph_domain_builders/DFS_Uncertain_Exploration.py
+-rw-r--r--  2.0 unx      203 b- defN 24-May-28 15:15 skdecide/hub/domain/mastermind/__init__.py
+-rw-r--r--  2.0 unx     5080 b- defN 24-May-28 15:15 skdecide/hub/domain/mastermind/mastermind.py
+-rw-r--r--  2.0 unx      215 b- defN 24-May-28 15:15 skdecide/hub/domain/simple_grid_world/__init__.py
+-rw-r--r--  2.0 unx     2892 b- defN 24-May-28 15:15 skdecide/hub/domain/simple_grid_world/simple_grid_world.py
+-rw-r--r--  2.0 unx      333 b- defN 24-May-28 15:15 skdecide/hub/domain/rcpsp/__init__.py
+-rw-r--r--  2.0 unx    29705 b- defN 24-May-28 15:15 skdecide/hub/domain/rcpsp/rcpsp_sk.py
+-rw-r--r--  2.0 unx     3488 b- defN 24-May-28 15:15 skdecide/hub/domain/rcpsp/rcpsp_sk_parser.py
+-rw-r--r--  2.0 unx      219 b- defN 24-May-28 15:15 skdecide/hub/domain/rock_paper_scissors/__init__.py
+-rw-r--r--  2.0 unx     3238 b- defN 24-May-28 15:15 skdecide/hub/domain/rock_paper_scissors/rock_paper_scissors.py
+-rw-r--r--  2.0 unx      216 b- defN 24-May-28 15:15 skdecide/hub/domain/up/__init__.py
+-rw-r--r--  2.0 unx    23101 b- defN 24-May-28 15:15 skdecide/hub/domain/up/up.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/builders/solver/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/builders/domain/
+-rw-r--r--  2.0 unx      167 b- defN 24-May-28 15:15 skdecide/builders/__init__.py
+-rw-r--r--  2.0 unx     3591 b- defN 24-May-28 15:15 skdecide/builders/solver/parallelability.py
+-rw-r--r--  2.0 unx      438 b- defN 24-May-28 15:15 skdecide/builders/solver/__init__.py
+-rw-r--r--  2.0 unx     3976 b- defN 24-May-28 15:15 skdecide/builders/solver/assessability.py
+-rw-r--r--  2.0 unx     1457 b- defN 24-May-28 15:15 skdecide/builders/solver/restorability.py
+-rw-r--r--  2.0 unx     4644 b- defN 24-May-28 15:15 skdecide/builders/solver/fromanystatesolvability.py
+-rw-r--r--  2.0 unx     4824 b- defN 24-May-28 15:15 skdecide/builders/solver/policy.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-28 15:15 skdecide/builders/domain/scheduling/
+-rw-r--r--  2.0 unx     2265 b- defN 24-May-28 15:15 skdecide/builders/domain/constraints.py
+-rw-r--r--  2.0 unx     2576 b- defN 24-May-28 15:15 skdecide/builders/domain/renderability.py
+-rw-r--r--  2.0 unx      705 b- defN 24-May-28 15:15 skdecide/builders/domain/__init__.py
+-rw-r--r--  2.0 unx    13963 b- defN 24-May-28 15:15 skdecide/builders/domain/events.py
+-rw-r--r--  2.0 unx      660 b- defN 24-May-28 15:15 skdecide/builders/domain/concurrency.py
+-rw-r--r--  2.0 unx     4170 b- defN 24-May-28 15:15 skdecide/builders/domain/goals.py
+-rw-r--r--  2.0 unx     2393 b- defN 24-May-28 15:15 skdecide/builders/domain/value.py
+-rw-r--r--  2.0 unx     5948 b- defN 24-May-28 15:15 skdecide/builders/domain/initialization.py
+-rw-r--r--  2.0 unx     3946 b- defN 24-May-28 15:15 skdecide/builders/domain/memory.py
+-rw-r--r--  2.0 unx     7946 b- defN 24-May-28 15:15 skdecide/builders/domain/observability.py
+-rw-r--r--  2.0 unx    23481 b- defN 24-May-28 15:15 skdecide/builders/domain/dynamics.py
+-rw-r--r--  2.0 unx     1145 b- defN 24-May-28 15:15 skdecide/builders/domain/agent.py
+-rw-r--r--  2.0 unx     2783 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/resource_type.py
+-rw-r--r--  2.0 unx     7874 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/modes.py
+-rw-r--r--  2.0 unx     8269 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/conditional_tasks.py
+-rw-r--r--  2.0 unx      167 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/__init__.py
+-rw-r--r--  2.0 unx     3946 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/precedence.py
+-rw-r--r--  2.0 unx     3873 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/graph_toolbox.py
+-rw-r--r--  2.0 unx     5711 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/time_windows.py
+-rw-r--r--  2.0 unx     1405 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/resource_consumption.py
+-rw-r--r--  2.0 unx     4656 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/resource_availability.py
+-rw-r--r--  2.0 unx     3569 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/resource_renewability.py
+-rw-r--r--  2.0 unx     5826 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/skills.py
+-rw-r--r--  2.0 unx     1313 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/preallocations.py
+-rw-r--r--  2.0 unx    11316 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/scheduling_domains_modelling.py
+-rw-r--r--  2.0 unx     4461 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/preemptivity.py
+-rw-r--r--  2.0 unx     3224 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/time_lag.py
+-rw-r--r--  2.0 unx    12910 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/task_duration.py
+-rw-r--r--  2.0 unx    79426 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/scheduling_domains.py
+-rw-r--r--  2.0 unx     1660 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/task.py
+-rw-r--r--  2.0 unx     2831 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/resource_costs.py
+-rw-r--r--  2.0 unx     2002 b- defN 24-May-28 15:15 skdecide/builders/domain/scheduling/task_progress.py
+-rwxr-xr-x  2.0 unx   168193 b- defN 24-May-28 15:15 scikit_decide.libs/libgomp-a34b3233.so.1.0.0
+289 files, 18576462 bytes uncompressed, 5666633 bytes compressed:  69.5%
```

## zipnote {}

```diff
@@ -1,574 +1,868 @@
-Filename: LICENSE
+Filename: scikit_decide-1.0.0.dist-info/
 Comment: 
 
-Filename: README.md
+Filename: skdecide/
 Comment: 
 
-Filename: skdecide/__init__.py
+Filename: scikit_decide.libs/
 Comment: 
 
-Filename: skdecide/builders/__init__.py
+Filename: README.md
 Comment: 
 
-Filename: skdecide/builders/domain/__init__.py
+Filename: LICENSE
 Comment: 
 
-Filename: skdecide/builders/domain/agent.py
+Filename: scikit_decide-1.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: skdecide/builders/domain/concurrency.py
+Filename: scikit_decide-1.0.0.dist-info/LICENSE
 Comment: 
 
-Filename: skdecide/builders/domain/constraints.py
+Filename: scikit_decide-1.0.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: skdecide/builders/domain/dynamics.py
+Filename: scikit_decide-1.0.0.dist-info/RECORD
 Comment: 
 
-Filename: skdecide/builders/domain/events.py
+Filename: scikit_decide-1.0.0.dist-info/METADATA
 Comment: 
 
-Filename: skdecide/builders/domain/goals.py
+Filename: skdecide/hub/
 Comment: 
 
-Filename: skdecide/builders/domain/initialization.py
+Filename: skdecide/builders/
 Comment: 
 
-Filename: skdecide/builders/domain/memory.py
+Filename: skdecide/__init__.py
 Comment: 
 
-Filename: skdecide/builders/domain/observability.py
+Filename: skdecide/parallel_domains.py
 Comment: 
 
-Filename: skdecide/builders/domain/renderability.py
+Filename: skdecide/solvers.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/__init__.py
+Filename: skdecide/utils.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/conditional_tasks.py
+Filename: skdecide/core.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/graph_toolbox.py
+Filename: skdecide/domains.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/modes.py
+Filename: skdecide/hub/space/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/preallocations.py
+Filename: skdecide/hub/solver/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/precedence.py
+Filename: skdecide/hub/include/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/preemptivity.py
+Filename: skdecide/hub/lib64/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/resource_availability.py
+Filename: skdecide/hub/domain/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/resource_consumption.py
+Filename: skdecide/hub/__init__.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/resource_costs.py
+Filename: skdecide/hub/__skdecide_hub_cpp.cpython-311-x86_64-linux-gnu.so
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/resource_renewability.py
+Filename: skdecide/hub/space/gym/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/resource_type.py
+Filename: skdecide/hub/space/__init__.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/scheduling_domains.py
+Filename: skdecide/hub/space/gym/__init__.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/scheduling_domains_modelling.py
+Filename: skdecide/hub/space/gym/gym.py
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/skills.py
+Filename: skdecide/hub/solver/meta_policy_scheduling/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/task.py
+Filename: skdecide/hub/solver/martdp/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/task_duration.py
+Filename: skdecide/hub/solver/bfws/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/task_progress.py
+Filename: skdecide/hub/solver/iw/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/time_lag.py
+Filename: skdecide/hub/solver/simple_greedy/
 Comment: 
 
-Filename: skdecide/builders/domain/scheduling/time_windows.py
+Filename: skdecide/hub/solver/ray_rllib/
 Comment: 
 
-Filename: skdecide/builders/domain/value.py
+Filename: skdecide/hub/solver/stable_baselines/
 Comment: 
 
-Filename: skdecide/builders/solver/__init__.py
+Filename: skdecide/hub/solver/mahd/
 Comment: 
 
-Filename: skdecide/builders/solver/assessability.py
+Filename: skdecide/hub/solver/pomcp/
 Comment: 
 
-Filename: skdecide/builders/solver/parallelability.py
+Filename: skdecide/hub/solver/lazy_astar/
 Comment: 
 
-Filename: skdecide/builders/solver/policy.py
+Filename: skdecide/hub/solver/aostar/
 Comment: 
 
-Filename: skdecide/builders/solver/restorability.py
+Filename: skdecide/hub/solver/lrtdp/
 Comment: 
 
-Filename: skdecide/core.py
+Filename: skdecide/hub/solver/do_solver/
 Comment: 
 
-Filename: skdecide/domains.py
+Filename: skdecide/hub/solver/lrtastar/
 Comment: 
 
-Filename: skdecide/hub/__init__.py
+Filename: skdecide/hub/solver/pile_policy_scheduling/
 Comment: 
 
-Filename: skdecide/hub/domain/__init__.py
+Filename: skdecide/hub/solver/riw/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/__init__.py
+Filename: skdecide/hub/solver/cgp/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/domain.py
+Filename: skdecide/hub/solver/ars/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/flightplanning_utils.py
+Filename: skdecide/hub/solver/up/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/__init__.py
+Filename: skdecide/hub/solver/astar/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/__init__.py
+Filename: skdecide/hub/solver/mcts/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/common_utils.py
+Filename: skdecide/hub/solver/ilaostar/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/get_weather_noaa.py
+Filename: skdecide/hub/solver/maxent_irl/
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/__init__.py
+Filename: skdecide/hub/solver/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/GenericInterpolator.py
+Filename: skdecide/hub/solver/meta_policy_scheduling/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/intergrid.py
+Filename: skdecide/hub/solver/meta_policy_scheduling/meta_policies.py
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/WeatherInterpolator.py
+Filename: skdecide/hub/solver/meta_policy_scheduling/policy_evaluator.py
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/parser_pygrib.py
+Filename: skdecide/hub/solver/martdp/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/std_atm.py
+Filename: skdecide/hub/solver/martdp/martdp.py
 Comment: 
 
-Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/unit_conversion.py
+Filename: skdecide/hub/solver/bfws/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/gym/__init__.py
+Filename: skdecide/hub/solver/bfws/bfws.py
 Comment: 
 
-Filename: skdecide/hub/domain/gym/gym.py
+Filename: skdecide/hub/solver/iw/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/mastermind/__init__.py
+Filename: skdecide/hub/solver/iw/iw.py
 Comment: 
 
-Filename: skdecide/hub/domain/mastermind/mastermind.py
+Filename: skdecide/hub/solver/simple_greedy/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/maze/__init__.py
+Filename: skdecide/hub/solver/simple_greedy/simple_greedy.py
 Comment: 
 
-Filename: skdecide/hub/domain/maze/maze.py
+Filename: skdecide/hub/solver/ray_rllib/ray_rllib.py
 Comment: 
 
-Filename: skdecide/hub/domain/rcpsp/__init__.py
+Filename: skdecide/hub/solver/ray_rllib/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/rcpsp/rcpsp_sk.py
+Filename: skdecide/hub/solver/ray_rllib/custom_models.py
 Comment: 
 
-Filename: skdecide/hub/domain/rcpsp/rcpsp_sk_parser.py
+Filename: skdecide/hub/solver/stable_baselines/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/rock_paper_scissors/__init__.py
+Filename: skdecide/hub/solver/stable_baselines/stable_baselines.py
 Comment: 
 
-Filename: skdecide/hub/domain/rock_paper_scissors/rock_paper_scissors.py
+Filename: skdecide/hub/solver/mahd/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/simple_grid_world/__init__.py
+Filename: skdecide/hub/solver/mahd/mahd.py
 Comment: 
 
-Filename: skdecide/hub/domain/simple_grid_world/simple_grid_world.py
+Filename: skdecide/hub/solver/pomcp/__init__.py
 Comment: 
 
-Filename: skdecide/hub/domain/up/__init__.py
+Filename: skdecide/hub/solver/pomcp/pomcp.py
 Comment: 
 
-Filename: skdecide/hub/domain/up/up.py
+Filename: skdecide/hub/solver/lazy_astar/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/__init__.py
+Filename: skdecide/hub/solver/lazy_astar/lazy_astar.py
 Comment: 
 
 Filename: skdecide/hub/solver/aostar/__init__.py
 Comment: 
 
 Filename: skdecide/hub/solver/aostar/aostar.py
 Comment: 
 
-Filename: skdecide/hub/solver/ars/__init__.py
+Filename: skdecide/hub/solver/lrtdp/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/ars/ars.py
+Filename: skdecide/hub/solver/lrtdp/lrtdp.py
 Comment: 
 
-Filename: skdecide/hub/solver/astar/__init__.py
+Filename: skdecide/hub/solver/do_solver/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/astar/astar.py
+Filename: skdecide/hub/solver/do_solver/do_solver_scheduling.py
 Comment: 
 
-Filename: skdecide/hub/solver/bfws/__init__.py
+Filename: skdecide/hub/solver/do_solver/sk_to_do_binding.py
 Comment: 
 
-Filename: skdecide/hub/solver/bfws/bfws.py
+Filename: skdecide/hub/solver/do_solver/sgs_policies.py
+Comment: 
+
+Filename: skdecide/hub/solver/do_solver/gphh.py
+Comment: 
+
+Filename: skdecide/hub/solver/lrtastar/__init__.py
+Comment: 
+
+Filename: skdecide/hub/solver/lrtastar/lrtastar.py
+Comment: 
+
+Filename: skdecide/hub/solver/pile_policy_scheduling/__init__.py
+Comment: 
+
+Filename: skdecide/hub/solver/pile_policy_scheduling/pile_policy.py
+Comment: 
+
+Filename: skdecide/hub/solver/riw/__init__.py
+Comment: 
+
+Filename: skdecide/hub/solver/riw/riw.py
+Comment: 
+
+Filename: skdecide/hub/solver/cgp/pycgp/
 Comment: 
 
 Filename: skdecide/hub/solver/cgp/__init__.py
 Comment: 
 
 Filename: skdecide/hub/solver/cgp/cgp.py
 Comment: 
 
-Filename: skdecide/hub/solver/cgp/pycgp/__init__.py
+Filename: skdecide/hub/solver/cgp/pycgp/evaluator.py
 Comment: 
 
-Filename: skdecide/hub/solver/cgp/pycgp/cgp.py
+Filename: skdecide/hub/solver/cgp/pycgp/__init__.py
 Comment: 
 
 Filename: skdecide/hub/solver/cgp/pycgp/cgpes.py
 Comment: 
 
 Filename: skdecide/hub/solver/cgp/pycgp/cgpfunctions.py
 Comment: 
 
-Filename: skdecide/hub/solver/cgp/pycgp/evaluator.py
+Filename: skdecide/hub/solver/cgp/pycgp/cgp.py
 Comment: 
 
-Filename: skdecide/hub/solver/do_solver/__init__.py
+Filename: skdecide/hub/solver/ars/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/do_solver/do_solver_scheduling.py
+Filename: skdecide/hub/solver/ars/ars.py
 Comment: 
 
-Filename: skdecide/hub/solver/do_solver/sk_to_do_binding.py
+Filename: skdecide/hub/solver/up/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/gphh/__init__.py
+Filename: skdecide/hub/solver/up/up.py
 Comment: 
 
-Filename: skdecide/hub/solver/gphh/gphh.py
+Filename: skdecide/hub/solver/astar/astar.py
 Comment: 
 
-Filename: skdecide/hub/solver/graph_explorer/__init__.py
+Filename: skdecide/hub/solver/astar/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/graph_explorer/DFS_Uncertain_Exploration.py
+Filename: skdecide/hub/solver/mcts/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/graph_explorer/DFSExploration.py
+Filename: skdecide/hub/solver/mcts/mcts.py
 Comment: 
 
-Filename: skdecide/hub/solver/graph_explorer/FullSpaceExploration.py
+Filename: skdecide/hub/solver/ilaostar/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/graph_explorer/GraphDomain.py
+Filename: skdecide/hub/solver/ilaostar/ilaostar.py
 Comment: 
 
-Filename: skdecide/hub/solver/graph_explorer/GraphExploration.py
+Filename: skdecide/hub/solver/maxent_irl/__init__.py
 Comment: 
 
-Filename: skdecide/hub/solver/ilaostar/__init__.py
+Filename: skdecide/hub/solver/maxent_irl/maxent_irl.py
 Comment: 
 
-Filename: skdecide/hub/solver/ilaostar/ilaostar.py
+Filename: skdecide/hub/include/nng/
 Comment: 
 
-Filename: skdecide/hub/solver/iw/__init__.py
+Filename: skdecide/hub/include/backward.hpp
 Comment: 
 
-Filename: skdecide/hub/solver/iw/iw.py
+Filename: skdecide/hub/include/nng/transport/
 Comment: 
 
-Filename: skdecide/hub/solver/lazy_astar/__init__.py
+Filename: skdecide/hub/include/nng/supplemental/
 Comment: 
 
-Filename: skdecide/hub/solver/lazy_astar/lazy_astar.py
+Filename: skdecide/hub/include/nng/compat/
 Comment: 
 
-Filename: skdecide/hub/solver/lrtastar/__init__.py
+Filename: skdecide/hub/include/nng/protocol/
 Comment: 
 
-Filename: skdecide/hub/solver/lrtastar/lrtastar.py
+Filename: skdecide/hub/include/nng/nng.h
 Comment: 
 
-Filename: skdecide/hub/solver/lrtdp/__init__.py
+Filename: skdecide/hub/include/nng/transport/inproc/
 Comment: 
 
-Filename: skdecide/hub/solver/lrtdp/lrtdp.py
+Filename: skdecide/hub/include/nng/transport/zerotier/
 Comment: 
 
-Filename: skdecide/hub/solver/mahd/__init__.py
+Filename: skdecide/hub/include/nng/transport/ws/
 Comment: 
 
-Filename: skdecide/hub/solver/mahd/mahd.py
+Filename: skdecide/hub/include/nng/transport/ipc/
 Comment: 
 
-Filename: skdecide/hub/solver/martdp/__init__.py
+Filename: skdecide/hub/include/nng/transport/tcp/
 Comment: 
 
-Filename: skdecide/hub/solver/martdp/martdp.py
+Filename: skdecide/hub/include/nng/transport/tls/
 Comment: 
 
-Filename: skdecide/hub/solver/maxent_irl/__init__.py
+Filename: skdecide/hub/include/nng/transport/inproc/inproc.h
 Comment: 
 
-Filename: skdecide/hub/solver/maxent_irl/maxent_irl.py
+Filename: skdecide/hub/include/nng/transport/zerotier/zerotier.h
 Comment: 
 
-Filename: skdecide/hub/solver/mcts/__init__.py
+Filename: skdecide/hub/include/nng/transport/ws/websocket.h
 Comment: 
 
-Filename: skdecide/hub/solver/mcts/mcts.py
+Filename: skdecide/hub/include/nng/transport/ipc/ipc.h
 Comment: 
 
-Filename: skdecide/hub/solver/meta_policy/__init__.py
+Filename: skdecide/hub/include/nng/transport/tcp/tcp.h
 Comment: 
 
-Filename: skdecide/hub/solver/meta_policy/meta_policies.py
+Filename: skdecide/hub/include/nng/transport/tls/tls.h
 Comment: 
 
-Filename: skdecide/hub/solver/pile_policy/__init__.py
+Filename: skdecide/hub/include/nng/supplemental/util/
 Comment: 
 
-Filename: skdecide/hub/solver/pile_policy/pile_policy.py
+Filename: skdecide/hub/include/nng/supplemental/tls/
 Comment: 
 
-Filename: skdecide/hub/solver/policy_evaluators/__init__.py
+Filename: skdecide/hub/include/nng/supplemental/http/
 Comment: 
 
-Filename: skdecide/hub/solver/policy_evaluators/policy_evaluator.py
+Filename: skdecide/hub/include/nng/supplemental/util/options.h
 Comment: 
 
-Filename: skdecide/hub/solver/pomcp/__init__.py
+Filename: skdecide/hub/include/nng/supplemental/util/platform.h
 Comment: 
 
-Filename: skdecide/hub/solver/pomcp/pomcp.py
+Filename: skdecide/hub/include/nng/supplemental/tls/tls.h
 Comment: 
 
-Filename: skdecide/hub/solver/ray_rllib/__init__.py
+Filename: skdecide/hub/include/nng/supplemental/tls/engine.h
 Comment: 
 
-Filename: skdecide/hub/solver/ray_rllib/custom_models.py
+Filename: skdecide/hub/include/nng/supplemental/http/http.h
 Comment: 
 
-Filename: skdecide/hub/solver/ray_rllib/ray_rllib.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/
 Comment: 
 
-Filename: skdecide/hub/solver/riw/__init__.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/nn.h
 Comment: 
 
-Filename: skdecide/hub/solver/riw/riw.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/survey.h
 Comment: 
 
-Filename: skdecide/hub/solver/sgs_policies/__init__.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/ipc.h
 Comment: 
 
-Filename: skdecide/hub/solver/sgs_policies/sgs_policies.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/bus.h
 Comment: 
 
-Filename: skdecide/hub/solver/simple_greedy/__init__.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/pipeline.h
 Comment: 
 
-Filename: skdecide/hub/solver/simple_greedy/simple_greedy.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/pair.h
 Comment: 
 
-Filename: skdecide/hub/solver/stable_baselines/__init__.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/ws.h
 Comment: 
 
-Filename: skdecide/hub/solver/stable_baselines/stable_baselines.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/inproc.h
 Comment: 
 
-Filename: skdecide/hub/solver/up/__init__.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/reqrep.h
 Comment: 
 
-Filename: skdecide/hub/solver/up/up.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/tcp.h
 Comment: 
 
-Filename: skdecide/hub/space/__init__.py
+Filename: skdecide/hub/include/nng/compat/nanomsg/pubsub.h
 Comment: 
 
-Filename: skdecide/hub/space/gym/__init__.py
+Filename: skdecide/hub/include/nng/protocol/bus0/
 Comment: 
 
-Filename: skdecide/hub/space/gym/gym.py
+Filename: skdecide/hub/include/nng/protocol/pair1/
 Comment: 
 
-Filename: skdecide/parallel_domains.py
+Filename: skdecide/hub/include/nng/protocol/pubsub0/
 Comment: 
 
-Filename: skdecide/solvers.py
+Filename: skdecide/hub/include/nng/protocol/pair0/
 Comment: 
 
-Filename: skdecide/utils.py
+Filename: skdecide/hub/include/nng/protocol/survey0/
 Comment: 
 
-Filename: skdecide/hub/__skdecide_hub_cpp.cp39-win_amd64.pyd
+Filename: skdecide/hub/include/nng/protocol/reqrep0/
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/bus.h
+Filename: skdecide/hub/include/nng/protocol/pipeline0/
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/inproc.h
+Filename: skdecide/hub/include/nng/protocol/bus0/bus.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/ipc.h
+Filename: skdecide/hub/include/nng/protocol/pair1/pair.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/nn.h
+Filename: skdecide/hub/include/nng/protocol/pubsub0/pub.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/pair.h
+Filename: skdecide/hub/include/nng/protocol/pubsub0/sub.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/pipeline.h
+Filename: skdecide/hub/include/nng/protocol/pair0/pair.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/pubsub.h
+Filename: skdecide/hub/include/nng/protocol/survey0/survey.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/reqrep.h
+Filename: skdecide/hub/include/nng/protocol/survey0/respond.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/survey.h
+Filename: skdecide/hub/include/nng/protocol/reqrep0/rep.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/tcp.h
+Filename: skdecide/hub/include/nng/protocol/reqrep0/req.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/compat/nanomsg/ws.h
+Filename: skdecide/hub/include/nng/protocol/pipeline0/pull.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/nng.h
+Filename: skdecide/hub/include/nng/protocol/pipeline0/push.h
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/bus0/bus.h
+Filename: skdecide/hub/lib64/backward/
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/pair0/pair.h
+Filename: skdecide/hub/lib64/cmake/
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/pair1/pair.h
+Filename: skdecide/hub/lib64/libnng.a
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/pipeline0/pull.h
+Filename: skdecide/hub/lib64/backward/BackwardConfig.cmake
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/pipeline0/push.h
+Filename: skdecide/hub/lib64/cmake/nng/
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/pubsub0/pub.h
+Filename: skdecide/hub/lib64/cmake/nng/nng-targets-release.cmake
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/pubsub0/sub.h
+Filename: skdecide/hub/lib64/cmake/nng/nng-targets.cmake
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/reqrep0/rep.h
+Filename: skdecide/hub/lib64/cmake/nng/nng-config-version.cmake
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/reqrep0/req.h
+Filename: skdecide/hub/lib64/cmake/nng/nng-config.cmake
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/survey0/respond.h
+Filename: skdecide/hub/domain/maze/
 Comment: 
 
-Filename: skdecide/hub/include/nng/protocol/survey0/survey.h
+Filename: skdecide/hub/domain/gym/
 Comment: 
 
-Filename: skdecide/hub/include/nng/supplemental/http/http.h
+Filename: skdecide/hub/domain/flight_planning/
 Comment: 
 
-Filename: skdecide/hub/include/nng/supplemental/tls/engine.h
+Filename: skdecide/hub/domain/graph_domain/
 Comment: 
 
-Filename: skdecide/hub/include/nng/supplemental/tls/tls.h
+Filename: skdecide/hub/domain/mastermind/
 Comment: 
 
-Filename: skdecide/hub/include/nng/supplemental/util/options.h
+Filename: skdecide/hub/domain/simple_grid_world/
 Comment: 
 
-Filename: skdecide/hub/include/nng/supplemental/util/platform.h
+Filename: skdecide/hub/domain/rcpsp/
 Comment: 
 
-Filename: skdecide/hub/include/nng/transport/inproc/inproc.h
+Filename: skdecide/hub/domain/rock_paper_scissors/
 Comment: 
 
-Filename: skdecide/hub/include/nng/transport/ipc/ipc.h
+Filename: skdecide/hub/domain/up/
 Comment: 
 
-Filename: skdecide/hub/include/nng/transport/tcp/tcp.h
+Filename: skdecide/hub/domain/__init__.py
 Comment: 
 
-Filename: skdecide/hub/include/nng/transport/tls/tls.h
+Filename: skdecide/hub/domain/maze/maze.py
 Comment: 
 
-Filename: skdecide/hub/include/nng/transport/ws/websocket.h
+Filename: skdecide/hub/domain/maze/__init__.py
 Comment: 
 
-Filename: skdecide/hub/include/nng/transport/zerotier/zerotier.h
+Filename: skdecide/hub/domain/gym/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/gym/gym.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/flightplanning_utils.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/domain.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/base.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/data/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/pollschumann.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/engine_loader.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/data/aircraft_engine_params.csv
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/aero.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/units.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/atmospheric_parameters.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/aircraft_parameters.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/jet.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/operational_limits.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/constants.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/unit_conversion.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/get_weather_noaa.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/parser_pygrib.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/std_atm.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/common_utils.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/WeatherInterpolator.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/GenericInterpolator.py
+Comment: 
+
+Filename: skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/intergrid.py
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/graph_domain_builders/
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/GraphDomain.py
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/graph_domain_builders/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/graph_domain_builders/DFSExploration.py
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/graph_domain_builders/GraphExploration.py
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/graph_domain_builders/FullSpaceExploration.py
+Comment: 
+
+Filename: skdecide/hub/domain/graph_domain/graph_domain_builders/DFS_Uncertain_Exploration.py
+Comment: 
+
+Filename: skdecide/hub/domain/mastermind/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/mastermind/mastermind.py
+Comment: 
+
+Filename: skdecide/hub/domain/simple_grid_world/__init__.py
 Comment: 
 
-Filename: skdecide/hub/lib/cmake/nng/nng-config-version.cmake
+Filename: skdecide/hub/domain/simple_grid_world/simple_grid_world.py
+Comment: 
+
+Filename: skdecide/hub/domain/rcpsp/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/rcpsp/rcpsp_sk.py
+Comment: 
+
+Filename: skdecide/hub/domain/rcpsp/rcpsp_sk_parser.py
+Comment: 
+
+Filename: skdecide/hub/domain/rock_paper_scissors/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/rock_paper_scissors/rock_paper_scissors.py
+Comment: 
+
+Filename: skdecide/hub/domain/up/__init__.py
+Comment: 
+
+Filename: skdecide/hub/domain/up/up.py
+Comment: 
+
+Filename: skdecide/builders/solver/
+Comment: 
+
+Filename: skdecide/builders/domain/
+Comment: 
+
+Filename: skdecide/builders/__init__.py
+Comment: 
+
+Filename: skdecide/builders/solver/parallelability.py
+Comment: 
+
+Filename: skdecide/builders/solver/__init__.py
+Comment: 
+
+Filename: skdecide/builders/solver/assessability.py
+Comment: 
+
+Filename: skdecide/builders/solver/restorability.py
+Comment: 
+
+Filename: skdecide/builders/solver/fromanystatesolvability.py
+Comment: 
+
+Filename: skdecide/builders/solver/policy.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/
+Comment: 
+
+Filename: skdecide/builders/domain/constraints.py
+Comment: 
+
+Filename: skdecide/builders/domain/renderability.py
+Comment: 
+
+Filename: skdecide/builders/domain/__init__.py
+Comment: 
+
+Filename: skdecide/builders/domain/events.py
+Comment: 
+
+Filename: skdecide/builders/domain/concurrency.py
+Comment: 
+
+Filename: skdecide/builders/domain/goals.py
+Comment: 
+
+Filename: skdecide/builders/domain/value.py
+Comment: 
+
+Filename: skdecide/builders/domain/initialization.py
+Comment: 
+
+Filename: skdecide/builders/domain/memory.py
+Comment: 
+
+Filename: skdecide/builders/domain/observability.py
+Comment: 
+
+Filename: skdecide/builders/domain/dynamics.py
+Comment: 
+
+Filename: skdecide/builders/domain/agent.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/resource_type.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/modes.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/conditional_tasks.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/__init__.py
 Comment: 
 
-Filename: skdecide/hub/lib/cmake/nng/nng-config.cmake
+Filename: skdecide/builders/domain/scheduling/precedence.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/graph_toolbox.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/time_windows.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/resource_consumption.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/resource_availability.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/resource_renewability.py
 Comment: 
 
-Filename: skdecide/hub/lib/cmake/nng/nng-targets-release.cmake
+Filename: skdecide/builders/domain/scheduling/skills.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/preallocations.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/scheduling_domains_modelling.py
+Comment: 
+
+Filename: skdecide/builders/domain/scheduling/preemptivity.py
 Comment: 
 
-Filename: skdecide/hub/lib/cmake/nng/nng-targets.cmake
+Filename: skdecide/builders/domain/scheduling/time_lag.py
 Comment: 
 
-Filename: skdecide/hub/lib/nng.lib
+Filename: skdecide/builders/domain/scheduling/task_duration.py
 Comment: 
 
-Filename: scikit_decide-0.9.8.dist-info/entry_points.txt
+Filename: skdecide/builders/domain/scheduling/scheduling_domains.py
 Comment: 
 
-Filename: scikit_decide-0.9.8.dist-info/LICENSE
+Filename: skdecide/builders/domain/scheduling/task.py
 Comment: 
 
-Filename: scikit_decide-0.9.8.dist-info/METADATA
+Filename: skdecide/builders/domain/scheduling/resource_costs.py
 Comment: 
 
-Filename: scikit_decide-0.9.8.dist-info/WHEEL
+Filename: skdecide/builders/domain/scheduling/task_progress.py
 Comment: 
 
-Filename: scikit_decide-0.9.8.dist-info/RECORD
+Filename: scikit_decide.libs/libgomp-a34b3233.so.1.0.0
 Comment: 
 
 Zip file comment:
```

## filetype from file(1)

```diff
@@ -1 +1 @@
-Zip archive data, at least v2.0 to extract, compression method=deflate
+Zip archive data, at least v2.0 to extract, compression method=store
```

## LICENSE

 * *Ordering differences only*

```diff
@@ -1,21 +1,21 @@
-The MIT License
-
-Copyright (c) 2019 AIRBUS http://airbus.com
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+The MIT License
+
+Copyright (c) 2019 AIRBUS http://airbus.com
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
```

## README.md

```diff
@@ -1,52 +1,52 @@
-
-                    _  __    _  __              __             _      __
-       _____ _____ (_)/ /__ (_)/ /_        ____/ /___   _____ (_)____/ /___
-      / ___// ___// // //_// // __/______ / __  // _ \ / ___// // __  // _ \
-     (__  )/ /__ / // ,<  / // /_ /_____// /_/ //  __// /__ / // /_/ //  __/
-    /____/ \___//_//_/|_|/_/ \__/        \__,_/ \___/ \___//_/ \__,_/ \___/
-
-<br>
-<p align="center">
-  <a href="https://github.com/airbus/scikit-decide/actions/workflows/build.yml?query=branch%3Amaster">
-    <img src="https://img.shields.io/github/actions/workflow/status/airbus/scikit-decide/build.yml?branch=master&logo=github&label=CI%20status" alt="actions status">
-  </a>
-  <a href="https://github.com/airbus/scikit-decide/tags">
-    <img src="https://img.shields.io/github/tag/airbus/scikit-decide.svg?label=current%20version" alt="version">
-  </a>
-  <a href="https://github.com/airbus/scikit-decide/stargazers">
-    <img src="https://img.shields.io/github/stars/airbus/scikit-decide.svg" alt="stars">
-  </a>
-  <a href="https://github.com/airbus/scikit-decide/network">
-    <img src="https://img.shields.io/github/forks/airbus/scikit-decide.svg" alt="forks">
-  </a>
-</p>
-<br>
-
-# Scikit-decide for Python
-
-Scikit-decide is an AI framework for Reinforcement Learning, Automated Planning and Scheduling.
-
-## Installation
-
-Quick version:
-```shell
-pip install scikit-decide[all]
-```
-For more details, see the [online documentation](https://airbus.github.io/scikit-decide/install).
-
-## Documentation
-
-The latest documentation is available [online](https://airbus.github.io/scikit-decide).
-
-## Examples
-
-Some educational notebooks are available in `notebooks/` folder.
-Links to launch them online with [binder](https://mybinder.org/) are provided in the
-[Notebooks section](https://airbus.github.io/scikit-decide/notebooks) of the online documentation.
-
-More examples can be found as Python scripts in the `examples/` folder, showing how to import or define a domain,
-and how to run or solve it. Most of the examples rely on scikit-decide Hub, an extensible catalog of domains/solvers.
-
-## Contributing
-
-See more about how to contribute in the [online documentation](https://airbus.github.io/scikit-decide/contribute).
+
+                    _  __    _  __              __             _      __
+       _____ _____ (_)/ /__ (_)/ /_        ____/ /___   _____ (_)____/ /___
+      / ___// ___// // //_// // __/______ / __  // _ \ / ___// // __  // _ \
+     (__  )/ /__ / // ,<  / // /_ /_____// /_/ //  __// /__ / // /_/ //  __/
+    /____/ \___//_//_/|_|/_/ \__/        \__,_/ \___/ \___//_/ \__,_/ \___/
+
+<br>
+<p align="center">
+  <a href="https://github.com/airbus/scikit-decide/actions/workflows/ci.yml?query=branch%3Amaster">
+    <img src="https://img.shields.io/github/actions/workflow/status/airbus/scikit-decide/ci.yml?branch=master&logo=github&label=CI%20status" alt="actions status">
+  </a>
+  <a href="https://github.com/airbus/scikit-decide/tags">
+    <img src="https://img.shields.io/github/tag/airbus/scikit-decide.svg?label=current%20version" alt="version">
+  </a>
+  <a href="https://github.com/airbus/scikit-decide/stargazers">
+    <img src="https://img.shields.io/github/stars/airbus/scikit-decide.svg" alt="stars">
+  </a>
+  <a href="https://github.com/airbus/scikit-decide/network">
+    <img src="https://img.shields.io/github/forks/airbus/scikit-decide.svg" alt="forks">
+  </a>
+</p>
+<br>
+
+# Scikit-decide for Python
+
+Scikit-decide is an AI framework for Reinforcement Learning, Automated Planning and Scheduling.
+
+## Installation
+
+Quick version:
+```shell
+pip install scikit-decide[all]
+```
+For more details, see the [online documentation](https://airbus.github.io/scikit-decide/install).
+
+## Documentation
+
+The latest documentation is available [online](https://airbus.github.io/scikit-decide).
+
+## Examples
+
+Some educational notebooks are available in `notebooks/` folder.
+Links to launch them online with [binder](https://mybinder.org/) are provided in the
+[Notebooks section](https://airbus.github.io/scikit-decide/notebooks) of the online documentation.
+
+More examples can be found as Python scripts in the `examples/` folder, showing how to import or define a domain,
+and how to run or solve it. Most of the examples rely on scikit-decide Hub, an extensible catalog of domains/solvers.
+
+## Contributing
+
+See more about how to contribute in the [online documentation](https://airbus.github.io/scikit-decide/contribute).
```

## skdecide/__init__.py

```diff
@@ -1,11 +1,11 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from skdecide import hub
-from skdecide.core import *
-from skdecide.domains import *
-from skdecide.solvers import *
-from skdecide.utils import *
-
-__version__ = "0.9.8"
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from skdecide import hub
+from skdecide.core import *
+from skdecide.domains import *
+from skdecide.solvers import *
+from skdecide.utils import *
+
+__version__ = "1.0.0"
```

## skdecide/builders/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
```

## skdecide/builders/domain/__init__.py

 * *Ordering differences only*

```diff
@@ -1,15 +1,15 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from skdecide.builders.domain.agent import *
-from skdecide.builders.domain.concurrency import *
-from skdecide.builders.domain.constraints import *
-from skdecide.builders.domain.dynamics import *
-from skdecide.builders.domain.events import *
-from skdecide.builders.domain.goals import *
-from skdecide.builders.domain.initialization import *
-from skdecide.builders.domain.memory import *
-from skdecide.builders.domain.observability import *
-from skdecide.builders.domain.renderability import *
-from skdecide.builders.domain.value import *
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from skdecide.builders.domain.agent import *
+from skdecide.builders.domain.concurrency import *
+from skdecide.builders.domain.constraints import *
+from skdecide.builders.domain.dynamics import *
+from skdecide.builders.domain.events import *
+from skdecide.builders.domain.goals import *
+from skdecide.builders.domain.initialization import *
+from skdecide.builders.domain.memory import *
+from skdecide.builders.domain.observability import *
+from skdecide.builders.domain.renderability import *
+from skdecide.builders.domain.value import *
```

## skdecide/builders/domain/agent.py

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Set, Union
-
-from skdecide.core import SINGLE_AGENT_ID, StrDict
-
-__all__ = ["MultiAgent", "SingleAgent"]
-
-
-class MultiAgent:
-    """A domain must inherit this class if it is multi-agent (i.e hosting multiple independent agents).
-
-    Agents are identified by (string) agent names.
-    """
-
-    T_agent = StrDict
-
-    def get_agents(self) -> Set[str]:
-        """Return the set of available agents ids."""
-        return set(self.get_observation_space())
-
-
-class SingleAgent(MultiAgent):
-    """A domain must inherit this class if it is single-agent (i.e hosting only one agent)."""
-
-    T_agent = Union
-
-    def get_agents(self) -> Set[str]:
-        """Return a singleton for single agent domains.
-
-        We must be here consistent with `skdecide.core.autocast()` which transforms a single agent domain
-        into a multi agents domain whose only agent has the id "agent".
-
-        """
-        return {SINGLE_AGENT_ID}
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Set, Union
+
+from skdecide.core import SINGLE_AGENT_ID, StrDict
+
+__all__ = ["MultiAgent", "SingleAgent"]
+
+
+class MultiAgent:
+    """A domain must inherit this class if it is multi-agent (i.e hosting multiple independent agents).
+
+    Agents are identified by (string) agent names.
+    """
+
+    T_agent = StrDict
+
+    def get_agents(self) -> Set[str]:
+        """Return the set of available agents ids."""
+        return set(self.get_observation_space())
+
+
+class SingleAgent(MultiAgent):
+    """A domain must inherit this class if it is single-agent (i.e hosting only one agent)."""
+
+    T_agent = Union
+
+    def get_agents(self) -> Set[str]:
+        """Return a singleton for single agent domains.
+
+        We must be here consistent with `skdecide.core.autocast()` which transforms a single agent domain
+        into a multi agents domain whose only agent has the id "agent".
+
+        """
+        return {SINGLE_AGENT_ID}
```

## skdecide/builders/domain/concurrency.py

 * *Ordering differences only*

```diff
@@ -1,21 +1,21 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import List, Union
-
-__all__ = ["Parallel", "Sequential"]
-
-
-class Parallel:
-    """A domain must inherit this class if multiple events/actions can happen in parallel."""
-
-    T_concurrency = List  # note: Set cannot handle non-hashable events (and Iterable would not provide enough guidance)
-
-
-class Sequential(Parallel):
-    """A domain must inherit this class if its events/actions are sequential (non-parallel)."""
-
-    T_concurrency = Union
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import List, Union
+
+__all__ = ["Parallel", "Sequential"]
+
+
+class Parallel:
+    """A domain must inherit this class if multiple events/actions can happen in parallel."""
+
+    T_concurrency = List  # note: Set cannot handle non-hashable events (and Iterable would not provide enough guidance)
+
+
+class Sequential(Parallel):
+    """A domain must inherit this class if its events/actions are sequential (non-parallel)."""
+
+    T_concurrency = Union
```

## skdecide/builders/domain/constraints.py

 * *Ordering differences only*

```diff
@@ -1,75 +1,75 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-from typing import List
-
-from skdecide.core import Constraint, D, autocastable
-
-__all__ = ["Constrained"]
-
-
-class Constrained:
-    """A domain must inherit this class if it has constraints."""
-
-    @autocastable
-    def get_constraints(
-        self,
-    ) -> List[
-        Constraint[
-            D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state
-        ]
-    ]:
-        """Get the (cached) domain constraints.
-
-        By default, #Constrained.get_constraints() internally calls #Constrained._get_constraints_() the first time and
-        automatically caches its value to make future calls more efficient (since the list of constraints is assumed to
-        be constant).
-
-        # Returns
-        The list of constraints.
-        """
-        return self._get_constraints()
-
-    @functools.lru_cache()
-    def _get_constraints(
-        self,
-    ) -> List[
-        Constraint[
-            D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state
-        ]
-    ]:
-        """Get the (cached) domain constraints.
-
-        By default, #Constrained._get_constraints() internally calls #Constrained._get_constraints_() the first time and
-        automatically caches its value to make future calls more efficient (since the list of constraints is assumed to
-        be constant).
-
-        # Returns
-        The list of constraints.
-        """
-        return self._get_constraints_()
-
-    def _get_constraints_(
-        self,
-    ) -> List[
-        Constraint[
-            D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state
-        ]
-    ]:
-        """Get the domain constraints.
-
-        This is a helper function called by default from #Constrained.get_constraints(), the difference being that the
-        result is not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        The list of constraints.
-        """
-        raise NotImplementedError
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+from typing import List
+
+from skdecide.core import Constraint, D, autocastable
+
+__all__ = ["Constrained"]
+
+
+class Constrained:
+    """A domain must inherit this class if it has constraints."""
+
+    @autocastable
+    def get_constraints(
+        self,
+    ) -> List[
+        Constraint[
+            D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state
+        ]
+    ]:
+        """Get the (cached) domain constraints.
+
+        By default, #Constrained.get_constraints() internally calls #Constrained._get_constraints_() the first time and
+        automatically caches its value to make future calls more efficient (since the list of constraints is assumed to
+        be constant).
+
+        # Returns
+        The list of constraints.
+        """
+        return self._get_constraints()
+
+    @functools.lru_cache()
+    def _get_constraints(
+        self,
+    ) -> List[
+        Constraint[
+            D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state
+        ]
+    ]:
+        """Get the (cached) domain constraints.
+
+        By default, #Constrained._get_constraints() internally calls #Constrained._get_constraints_() the first time and
+        automatically caches its value to make future calls more efficient (since the list of constraints is assumed to
+        be constant).
+
+        # Returns
+        The list of constraints.
+        """
+        return self._get_constraints_()
+
+    def _get_constraints_(
+        self,
+    ) -> List[
+        Constraint[
+            D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state
+        ]
+    ]:
+        """Get the domain constraints.
+
+        This is a helper function called by default from #Constrained.get_constraints(), the difference being that the
+        result is not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        The list of constraints.
+        """
+        raise NotImplementedError
```

## skdecide/builders/domain/dynamics.py

 * *Ordering differences only*

```diff
@@ -1,586 +1,586 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-from typing import Optional
-
-from skdecide.core import (
-    D,
-    DiscreteDistribution,
-    Distribution,
-    EnvironmentOutcome,
-    SingleValueDistribution,
-    TransitionOutcome,
-    Value,
-    autocastable,
-)
-
-__all__ = [
-    "Environment",
-    "Simulation",
-    "UncertainTransitions",
-    "EnumerableTransitions",
-    "DeterministicTransitions",
-]
-
-
-class Environment:
-    """A domain must inherit this class if agents interact with it like a black-box environment.
-
-    Black-box environment examples include: the real world, compiled ATARI games, etc.
-
-    !!! tip
-        Environment domains are typically stateful: they must keep the current state or history in their memory to
-        compute next steps (automatically done by default in the #_memory attribute).
-    """
-
-    @autocastable
-    def step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> EnvironmentOutcome[
-        D.T_agent[D.T_observation],
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        """Run one step of the environment's dynamics.
-
-        By default, #Environment.step() provides some boilerplate code and internally calls #Environment._step() (which
-        returns a transition outcome). The boilerplate code automatically stores next state into the #_memory attribute
-        and samples a corresponding observation.
-
-        !!! tip
-            Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled
-            ATARI games), it is recommended to overwrite #Environment.step() to call the external environment and not
-            use the #Environment._step() helper function.
-
-        !!! warning
-            Before calling #Environment.step() the first time or when the end of an episode is
-            reached, #Initializable.reset() must be called to reset the environment's state.
-
-        # Parameters
-        action: The action taken in the current memory (state or history) triggering the transition.
-
-        # Returns
-        The environment outcome of this step.
-        """
-        return self._step(action)
-
-    def _step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> EnvironmentOutcome[
-        D.T_agent[D.T_observation],
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        """Run one step of the environment's dynamics.
-
-        By default, #Environment._step() provides some boilerplate code and internally
-        calls #Environment._state_step() (which returns a transition outcome). The boilerplate code automatically stores
-        next state into the #_memory attribute and samples a corresponding observation.
-
-        !!! tip
-            Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled
-            ATARI games), it is recommended to overwrite #Environment._step() to call the external environment and not
-            use the #Environment._state_step() helper function.
-
-        !!! warning
-            Before calling #Environment._step() the first time or when the end of an episode is
-            reached, #Initializable._reset() must be called to reset the environment's state.
-
-        # Parameters
-        action: The action taken in the current memory (state or history) triggering the transition.
-
-        # Returns
-        The environment outcome of this step.
-        """
-        transition_outcome = self._state_step(action)
-        next_state = transition_outcome.state
-        observation = self._get_observation_distribution(next_state, action).sample()
-        if self._get_memory_maxlen() == 1:
-            self._memory = next_state
-        elif self._get_memory_maxlen() > 1:
-            self._memory.append(next_state)
-        return EnvironmentOutcome(
-            observation,
-            transition_outcome.value,
-            transition_outcome.termination,
-            transition_outcome.info,
-        )
-
-    def _state_step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        """Compute one step of the transition's dynamics.
-
-        This is a helper function called by default from #Environment._step(). It focuses on the state level, as opposed
-        to the observation one for the latter.
-
-        # Parameters
-        action: The action taken in the current memory (state or history) triggering the transition.
-
-        # Returns
-        The transition outcome of this step.
-        """
-        raise NotImplementedError
-
-
-class Simulation(Environment):
-    """A domain must inherit this class if agents interact with it like a simulation.
-
-    Compared to pure environment domains, simulation ones have the additional ability to sample transitions from any
-    given state.
-
-    !!! tip
-        Simulation domains are typically stateless: they do not need to store the current state or history in memory
-        since it is usually passed as parameter of their functions. By default, they only become stateful whenever they
-        are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
-    """
-
-    def _state_step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        return self._state_sample(self._memory, action)
-
-    @autocastable
-    def set_memory(self, memory: D.T_memory[D.T_state]) -> None:
-        """Set internal memory attribute #_memory to given one.
-
-        This can be useful to set a specific "starting point" before doing a rollout with successive #Environment.step()
-        calls.
-
-        # Parameters
-        memory: The memory to set internally.
-
-        # Example
-        ```python
-        # Set simulation_domain memory to my_state (assuming Markovian domain)
-        simulation_domain.set_memory(my_state)
-
-        # Start a 100-steps rollout from here (applying my_action at every step)
-        for _ in range(100):
-            simulation_domain.step(my_action)
-        ```
-        """
-        return self._set_memory(memory)
-
-    def _set_memory(self, memory: D.T_memory[D.T_state]) -> None:
-        """Set internal memory attribute #_memory to given one.
-
-        This can be useful to set a specific "starting point" before doing a rollout with
-        successive #Environment._step() calls.
-
-        # Parameters
-        memory: The memory to set internally.
-
-        # Example
-        ```python
-        # Set simulation_domain memory to my_state (assuming Markovian domain)
-        simulation_domain._set_memory(my_state)
-
-        # Start a 100-steps rollout from here (applying my_action at every step)
-        for _ in range(100):
-            simulation_domain._step(my_action)
-        ```
-        """
-        self._memory = memory
-
-    @autocastable
-    def sample(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> EnvironmentOutcome[
-        D.T_agent[D.T_observation],
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        """Sample one transition of the simulator's dynamics.
-
-        By default, #Simulation.sample() provides some boilerplate code and internally calls #Simulation._sample()
-        (which returns a transition outcome). The boilerplate code automatically samples an observation corresponding to
-        the sampled next state.
-
-        !!! tip
-            Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a
-            simulator), it is recommended to overwrite #Simulation.sample() to call the external simulator and not use
-            the #Simulation._sample() helper function.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The environment outcome of the sampled transition.
-        """
-        return self._sample(memory, action)
-
-    def _sample(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> EnvironmentOutcome[
-        D.T_agent[D.T_observation],
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        """Sample one transition of the simulator's dynamics.
-
-        By default, #Simulation._sample() provides some boilerplate code and internally
-        calls #Simulation._state_sample() (which returns a transition outcome). The boilerplate code automatically
-        samples an observation corresponding to the sampled next state.
-
-        !!! tip
-            Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a
-            simulator), it is recommended to overwrite #Simulation._sample() to call the external simulator and not use
-            the #Simulation._state_sample() helper function.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The environment outcome of the sampled transition.
-        """
-        transition_outcome = self._state_sample(memory, action)
-        next_state = transition_outcome.state
-        observation = self._get_observation_distribution(next_state, action).sample()
-        return EnvironmentOutcome(
-            observation,
-            transition_outcome.value,
-            transition_outcome.termination,
-            transition_outcome.info,
-        )
-
-    def _state_sample(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        """Compute one sample of the transition's dynamics.
-
-        This is a helper function called by default from #Simulation._sample(). It focuses on the state level, as
-        opposed to the observation one for the latter.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The transition outcome of the sampled transition.
-        """
-        raise NotImplementedError
-
-
-class UncertainTransitions(Simulation):
-    """A domain must inherit this class if its dynamics is uncertain and provided as a white-box model.
-
-    Compared to pure simulation domains, uncertain transition ones provide in addition the full probability distribution
-    of next states given a memory and action.
-
-    !!! tip
-        Uncertain transition domains are typically stateless: they do not need to store the current state or history in
-        memory since it is usually passed as parameter of their functions. By default, they only become stateful
-        whenever they are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
-    """
-
-    def _state_sample(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        next_state = self._get_next_state_distribution(memory, action).sample()
-        value = self._get_transition_value(memory, action, next_state)
-        # Termination could be inferred using get_next_state_distribution based on next_state,
-        # but would introduce multiple constraints on class definitions
-        termination = self._is_terminal(next_state)
-        return TransitionOutcome(next_state, value, termination, None)
-
-    @autocastable
-    def get_next_state_distribution(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> Distribution[D.T_state]:
-        """Get the probability distribution of next state given a memory and action.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The probability distribution of next state.
-        """
-        return self._get_next_state_distribution(memory, action)
-
-    def _get_next_state_distribution(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> Distribution[D.T_state]:
-        """Get the probability distribution of next state given a memory and action.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The probability distribution of next state.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def get_transition_value(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-        next_state: Optional[D.T_state] = None,
-    ) -> D.T_agent[Value[D.T_value]]:
-        """Get the value (reward or cost) of a transition.
-
-        The transition to consider is defined by the function parameters.
-
-        !!! tip
-            If this function never depends on the next_state parameter for its computation, it is recommended to
-            indicate it by overriding #UncertainTransitions._is_transition_value_dependent_on_next_state_() to return
-            False. This information can then be exploited by solvers to avoid computing next state to evaluate a
-            transition value (more efficient).
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-        next_state: The next state in which the transition ends (if needed for the computation).
-
-        # Returns
-        The transition value (reward or cost).
-        """
-        return self._get_transition_value(memory, action, next_state)
-
-    def _get_transition_value(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-        next_state: Optional[D.T_state] = None,
-    ) -> D.T_agent[Value[D.T_value]]:
-        """Get the value (reward or cost) of a transition.
-
-        The transition to consider is defined by the function parameters.
-
-        !!! tip
-            If this function never depends on the next_state parameter for its computation, it is recommended to
-            indicate it by overriding #UncertainTransitions._is_transition_value_dependent_on_next_state_() to return
-            False. This information can then be exploited by solvers to avoid computing next state to evaluate a
-            transition value (more efficient).
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-        next_state: The next state in which the transition ends (if needed for the computation).
-
-        # Returns
-        The transition value (reward or cost).
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def is_transition_value_dependent_on_next_state(self) -> bool:
-        """Indicate whether get_transition_value() requires the next_state parameter for its computation (cached).
-
-        By default, #UncertainTransitions.is_transition_value_dependent_on_next_state() internally
-        calls #UncertainTransitions._is_transition_value_dependent_on_next_state_() the first time and automatically
-        caches its value to make future calls more efficient (since the returned value is assumed to be constant).
-
-        # Returns
-        True if the transition value computation depends on next_state (False otherwise).
-        """
-        return self._is_transition_value_dependent_on_next_state()
-
-    @functools.lru_cache()
-    def _is_transition_value_dependent_on_next_state(self) -> bool:
-        """Indicate whether _get_transition_value() requires the next_state parameter for its computation (cached).
-
-        By default, #UncertainTransitions._is_transition_value_dependent_on_next_state() internally
-        calls #UncertainTransitions._is_transition_value_dependent_on_next_state_() the first time and automatically
-        caches its value to make future calls more efficient (since the returned value is assumed to be constant).
-
-        # Returns
-        True if the transition value computation depends on next_state (False otherwise).
-        """
-        return self._is_transition_value_dependent_on_next_state_()
-
-    def _is_transition_value_dependent_on_next_state_(self) -> bool:
-        """Indicate whether _get_transition_value() requires the next_state parameter for its computation.
-
-        This is a helper function called by default
-        from #UncertainTransitions._is_transition_value_dependent_on_next_state(), the difference being that the result
-        is not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        True if the transition value computation depends on next_state (False otherwise).
-        """
-        return True
-
-    @autocastable
-    def is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
-        """Indicate whether a state is terminal.
-
-        A terminal state is a state with no outgoing transition (except to itself with value 0).
-
-        # Parameters
-        state: The state to consider.
-
-        # Returns
-        True if the state is terminal (False otherwise).
-        """
-        return self._is_terminal(state)
-
-    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
-        """Indicate whether a state is terminal.
-
-        A terminal state is a state with no outgoing transition (except to itself with value 0).
-
-        # Parameters
-        state: The state to consider.
-
-        # Returns
-        True if the state is terminal (False otherwise).
-        """
-        raise NotImplementedError
-
-
-class EnumerableTransitions(UncertainTransitions):
-    """A domain must inherit this class if its dynamics is uncertain (with enumerable transitions) and provided as a
-    white-box model.
-
-    Compared to pure uncertain transition domains, enumerable transition ones guarantee that all probability
-    distributions of next state are discrete.
-
-    !!! tip
-        Enumerable transition domains are typically stateless: they do not need to store the current state or history in
-        memory since it is usually passed as parameter of their functions. By default, they only become stateful
-        whenever they are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
-    """
-
-    @autocastable
-    def get_next_state_distribution(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> DiscreteDistribution[D.T_state]:
-        """Get the discrete probability distribution of next state given a memory and action.
-
-        !!! tip
-            In the Markovian case (memory only holds last state $s$), given an action $a$, this function can
-            be mathematically represented by $P(S'|s, a)$, where $S'$ is the next state random variable.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The discrete probability distribution of next state.
-        """
-        return self._get_next_state_distribution(memory, action)
-
-    def _get_next_state_distribution(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> DiscreteDistribution[D.T_state]:
-        """Get the discrete probability distribution of next state given a memory and action.
-
-        !!! tip
-            In the Markovian case (memory only holds last state $s$), given an action $a$, this function can
-            be mathematically represented by $P(S'|s, a)$, where $S'$ is the next state random variable.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The discrete probability distribution of next state.
-        """
-        raise NotImplementedError
-
-
-class DeterministicTransitions(EnumerableTransitions):
-    """A domain must inherit this class if its dynamics is deterministic and provided as a white-box model.
-
-    Compared to pure enumerable transition domains, deterministic transition ones guarantee that there is only one next
-    state for a given source memory (state or history) and action.
-
-    !!! tip
-        Deterministic transition domains are typically stateless: they do not need to store the current state or history
-        in memory since it is usually passed as parameter of their functions. By default, they only become stateful
-        whenever they are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
-    """
-
-    def _get_next_state_distribution(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> SingleValueDistribution[D.T_state]:
-        return SingleValueDistribution(self._get_next_state(memory, action))
-
-    @autocastable
-    def get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        """Get the next state given a memory and action.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The deterministic next state.
-        """
-        return self._get_next_state(memory, action)
-
-    def _get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        """Get the next state given a memory and action.
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-
-        # Returns
-        The deterministic next state.
-        """
-        raise NotImplementedError
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+from typing import Optional
+
+from skdecide.core import (
+    D,
+    DiscreteDistribution,
+    Distribution,
+    EnvironmentOutcome,
+    SingleValueDistribution,
+    TransitionOutcome,
+    Value,
+    autocastable,
+)
+
+__all__ = [
+    "Environment",
+    "Simulation",
+    "UncertainTransitions",
+    "EnumerableTransitions",
+    "DeterministicTransitions",
+]
+
+
+class Environment:
+    """A domain must inherit this class if agents interact with it like a black-box environment.
+
+    Black-box environment examples include: the real world, compiled ATARI games, etc.
+
+    !!! tip
+        Environment domains are typically stateful: they must keep the current state or history in their memory to
+        compute next steps (automatically done by default in the #_memory attribute).
+    """
+
+    @autocastable
+    def step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> EnvironmentOutcome[
+        D.T_agent[D.T_observation],
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        """Run one step of the environment's dynamics.
+
+        By default, #Environment.step() provides some boilerplate code and internally calls #Environment._step() (which
+        returns a transition outcome). The boilerplate code automatically stores next state into the #_memory attribute
+        and samples a corresponding observation.
+
+        !!! tip
+            Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled
+            ATARI games), it is recommended to overwrite #Environment.step() to call the external environment and not
+            use the #Environment._step() helper function.
+
+        !!! warning
+            Before calling #Environment.step() the first time or when the end of an episode is
+            reached, #Initializable.reset() must be called to reset the environment's state.
+
+        # Parameters
+        action: The action taken in the current memory (state or history) triggering the transition.
+
+        # Returns
+        The environment outcome of this step.
+        """
+        return self._step(action)
+
+    def _step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> EnvironmentOutcome[
+        D.T_agent[D.T_observation],
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        """Run one step of the environment's dynamics.
+
+        By default, #Environment._step() provides some boilerplate code and internally
+        calls #Environment._state_step() (which returns a transition outcome). The boilerplate code automatically stores
+        next state into the #_memory attribute and samples a corresponding observation.
+
+        !!! tip
+            Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled
+            ATARI games), it is recommended to overwrite #Environment._step() to call the external environment and not
+            use the #Environment._state_step() helper function.
+
+        !!! warning
+            Before calling #Environment._step() the first time or when the end of an episode is
+            reached, #Initializable._reset() must be called to reset the environment's state.
+
+        # Parameters
+        action: The action taken in the current memory (state or history) triggering the transition.
+
+        # Returns
+        The environment outcome of this step.
+        """
+        transition_outcome = self._state_step(action)
+        next_state = transition_outcome.state
+        observation = self._get_observation_distribution(next_state, action).sample()
+        if self._get_memory_maxlen() == 1:
+            self._memory = next_state
+        elif self._get_memory_maxlen() > 1:
+            self._memory.append(next_state)
+        return EnvironmentOutcome(
+            observation,
+            transition_outcome.value,
+            transition_outcome.termination,
+            transition_outcome.info,
+        )
+
+    def _state_step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        """Compute one step of the transition's dynamics.
+
+        This is a helper function called by default from #Environment._step(). It focuses on the state level, as opposed
+        to the observation one for the latter.
+
+        # Parameters
+        action: The action taken in the current memory (state or history) triggering the transition.
+
+        # Returns
+        The transition outcome of this step.
+        """
+        raise NotImplementedError
+
+
+class Simulation(Environment):
+    """A domain must inherit this class if agents interact with it like a simulation.
+
+    Compared to pure environment domains, simulation ones have the additional ability to sample transitions from any
+    given state.
+
+    !!! tip
+        Simulation domains are typically stateless: they do not need to store the current state or history in memory
+        since it is usually passed as parameter of their functions. By default, they only become stateful whenever they
+        are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
+    """
+
+    def _state_step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        return self._state_sample(self._memory, action)
+
+    @autocastable
+    def set_memory(self, memory: D.T_memory[D.T_state]) -> None:
+        """Set internal memory attribute #_memory to given one.
+
+        This can be useful to set a specific "starting point" before doing a rollout with successive #Environment.step()
+        calls.
+
+        # Parameters
+        memory: The memory to set internally.
+
+        # Example
+        ```python
+        # Set simulation_domain memory to my_state (assuming Markovian domain)
+        simulation_domain.set_memory(my_state)
+
+        # Start a 100-steps rollout from here (applying my_action at every step)
+        for _ in range(100):
+            simulation_domain.step(my_action)
+        ```
+        """
+        return self._set_memory(memory)
+
+    def _set_memory(self, memory: D.T_memory[D.T_state]) -> None:
+        """Set internal memory attribute #_memory to given one.
+
+        This can be useful to set a specific "starting point" before doing a rollout with
+        successive #Environment._step() calls.
+
+        # Parameters
+        memory: The memory to set internally.
+
+        # Example
+        ```python
+        # Set simulation_domain memory to my_state (assuming Markovian domain)
+        simulation_domain._set_memory(my_state)
+
+        # Start a 100-steps rollout from here (applying my_action at every step)
+        for _ in range(100):
+            simulation_domain._step(my_action)
+        ```
+        """
+        self._memory = memory
+
+    @autocastable
+    def sample(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> EnvironmentOutcome[
+        D.T_agent[D.T_observation],
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        """Sample one transition of the simulator's dynamics.
+
+        By default, #Simulation.sample() provides some boilerplate code and internally calls #Simulation._sample()
+        (which returns a transition outcome). The boilerplate code automatically samples an observation corresponding to
+        the sampled next state.
+
+        !!! tip
+            Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a
+            simulator), it is recommended to overwrite #Simulation.sample() to call the external simulator and not use
+            the #Simulation._sample() helper function.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The environment outcome of the sampled transition.
+        """
+        return self._sample(memory, action)
+
+    def _sample(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> EnvironmentOutcome[
+        D.T_agent[D.T_observation],
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        """Sample one transition of the simulator's dynamics.
+
+        By default, #Simulation._sample() provides some boilerplate code and internally
+        calls #Simulation._state_sample() (which returns a transition outcome). The boilerplate code automatically
+        samples an observation corresponding to the sampled next state.
+
+        !!! tip
+            Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a
+            simulator), it is recommended to overwrite #Simulation._sample() to call the external simulator and not use
+            the #Simulation._state_sample() helper function.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The environment outcome of the sampled transition.
+        """
+        transition_outcome = self._state_sample(memory, action)
+        next_state = transition_outcome.state
+        observation = self._get_observation_distribution(next_state, action).sample()
+        return EnvironmentOutcome(
+            observation,
+            transition_outcome.value,
+            transition_outcome.termination,
+            transition_outcome.info,
+        )
+
+    def _state_sample(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        """Compute one sample of the transition's dynamics.
+
+        This is a helper function called by default from #Simulation._sample(). It focuses on the state level, as
+        opposed to the observation one for the latter.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The transition outcome of the sampled transition.
+        """
+        raise NotImplementedError
+
+
+class UncertainTransitions(Simulation):
+    """A domain must inherit this class if its dynamics is uncertain and provided as a white-box model.
+
+    Compared to pure simulation domains, uncertain transition ones provide in addition the full probability distribution
+    of next states given a memory and action.
+
+    !!! tip
+        Uncertain transition domains are typically stateless: they do not need to store the current state or history in
+        memory since it is usually passed as parameter of their functions. By default, they only become stateful
+        whenever they are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
+    """
+
+    def _state_sample(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        next_state = self._get_next_state_distribution(memory, action).sample()
+        value = self._get_transition_value(memory, action, next_state)
+        # Termination could be inferred using get_next_state_distribution based on next_state,
+        # but would introduce multiple constraints on class definitions
+        termination = self._is_terminal(next_state)
+        return TransitionOutcome(next_state, value, termination, None)
+
+    @autocastable
+    def get_next_state_distribution(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> Distribution[D.T_state]:
+        """Get the probability distribution of next state given a memory and action.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The probability distribution of next state.
+        """
+        return self._get_next_state_distribution(memory, action)
+
+    def _get_next_state_distribution(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> Distribution[D.T_state]:
+        """Get the probability distribution of next state given a memory and action.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The probability distribution of next state.
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_state] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+        """Get the value (reward or cost) of a transition.
+
+        The transition to consider is defined by the function parameters.
+
+        !!! tip
+            If this function never depends on the next_state parameter for its computation, it is recommended to
+            indicate it by overriding #UncertainTransitions._is_transition_value_dependent_on_next_state_() to return
+            False. This information can then be exploited by solvers to avoid computing next state to evaluate a
+            transition value (more efficient).
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+        next_state: The next state in which the transition ends (if needed for the computation).
+
+        # Returns
+        The transition value (reward or cost).
+        """
+        return self._get_transition_value(memory, action, next_state)
+
+    def _get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_state] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+        """Get the value (reward or cost) of a transition.
+
+        The transition to consider is defined by the function parameters.
+
+        !!! tip
+            If this function never depends on the next_state parameter for its computation, it is recommended to
+            indicate it by overriding #UncertainTransitions._is_transition_value_dependent_on_next_state_() to return
+            False. This information can then be exploited by solvers to avoid computing next state to evaluate a
+            transition value (more efficient).
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+        next_state: The next state in which the transition ends (if needed for the computation).
+
+        # Returns
+        The transition value (reward or cost).
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def is_transition_value_dependent_on_next_state(self) -> bool:
+        """Indicate whether get_transition_value() requires the next_state parameter for its computation (cached).
+
+        By default, #UncertainTransitions.is_transition_value_dependent_on_next_state() internally
+        calls #UncertainTransitions._is_transition_value_dependent_on_next_state_() the first time and automatically
+        caches its value to make future calls more efficient (since the returned value is assumed to be constant).
+
+        # Returns
+        True if the transition value computation depends on next_state (False otherwise).
+        """
+        return self._is_transition_value_dependent_on_next_state()
+
+    @functools.lru_cache()
+    def _is_transition_value_dependent_on_next_state(self) -> bool:
+        """Indicate whether _get_transition_value() requires the next_state parameter for its computation (cached).
+
+        By default, #UncertainTransitions._is_transition_value_dependent_on_next_state() internally
+        calls #UncertainTransitions._is_transition_value_dependent_on_next_state_() the first time and automatically
+        caches its value to make future calls more efficient (since the returned value is assumed to be constant).
+
+        # Returns
+        True if the transition value computation depends on next_state (False otherwise).
+        """
+        return self._is_transition_value_dependent_on_next_state_()
+
+    def _is_transition_value_dependent_on_next_state_(self) -> bool:
+        """Indicate whether _get_transition_value() requires the next_state parameter for its computation.
+
+        This is a helper function called by default
+        from #UncertainTransitions._is_transition_value_dependent_on_next_state(), the difference being that the result
+        is not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        True if the transition value computation depends on next_state (False otherwise).
+        """
+        return True
+
+    @autocastable
+    def is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
+        """Indicate whether a state is terminal.
+
+        A terminal state is a state with no outgoing transition (except to itself with value 0).
+
+        # Parameters
+        state: The state to consider.
+
+        # Returns
+        True if the state is terminal (False otherwise).
+        """
+        return self._is_terminal(state)
+
+    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
+        """Indicate whether a state is terminal.
+
+        A terminal state is a state with no outgoing transition (except to itself with value 0).
+
+        # Parameters
+        state: The state to consider.
+
+        # Returns
+        True if the state is terminal (False otherwise).
+        """
+        raise NotImplementedError
+
+
+class EnumerableTransitions(UncertainTransitions):
+    """A domain must inherit this class if its dynamics is uncertain (with enumerable transitions) and provided as a
+    white-box model.
+
+    Compared to pure uncertain transition domains, enumerable transition ones guarantee that all probability
+    distributions of next state are discrete.
+
+    !!! tip
+        Enumerable transition domains are typically stateless: they do not need to store the current state or history in
+        memory since it is usually passed as parameter of their functions. By default, they only become stateful
+        whenever they are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
+    """
+
+    @autocastable
+    def get_next_state_distribution(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> DiscreteDistribution[D.T_state]:
+        """Get the discrete probability distribution of next state given a memory and action.
+
+        !!! tip
+            In the Markovian case (memory only holds last state $s$), given an action $a$, this function can
+            be mathematically represented by $P(S'|s, a)$, where $S'$ is the next state random variable.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The discrete probability distribution of next state.
+        """
+        return self._get_next_state_distribution(memory, action)
+
+    def _get_next_state_distribution(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> DiscreteDistribution[D.T_state]:
+        """Get the discrete probability distribution of next state given a memory and action.
+
+        !!! tip
+            In the Markovian case (memory only holds last state $s$), given an action $a$, this function can
+            be mathematically represented by $P(S'|s, a)$, where $S'$ is the next state random variable.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The discrete probability distribution of next state.
+        """
+        raise NotImplementedError
+
+
+class DeterministicTransitions(EnumerableTransitions):
+    """A domain must inherit this class if its dynamics is deterministic and provided as a white-box model.
+
+    Compared to pure enumerable transition domains, deterministic transition ones guarantee that there is only one next
+    state for a given source memory (state or history) and action.
+
+    !!! tip
+        Deterministic transition domains are typically stateless: they do not need to store the current state or history
+        in memory since it is usually passed as parameter of their functions. By default, they only become stateful
+        whenever they are used as environments (e.g. via #Initializable.reset() and #Environment.step() functions).
+    """
+
+    def _get_next_state_distribution(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> SingleValueDistribution[D.T_state]:
+        return SingleValueDistribution(self._get_next_state(memory, action))
+
+    @autocastable
+    def get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        """Get the next state given a memory and action.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The deterministic next state.
+        """
+        return self._get_next_state(memory, action)
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        """Get the next state given a memory and action.
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+
+        # Returns
+        The deterministic next state.
+        """
+        raise NotImplementedError
```

## skdecide/builders/domain/events.py

 * *Ordering differences only*

```diff
@@ -1,349 +1,349 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-from typing import Optional, Union
-
-from skdecide.core import D, EmptySpace, Space, autocastable
-
-__all__ = ["Events", "Actions", "UnrestrictedActions"]
-
-
-class Events:
-    """A domain must inherit this class if it handles events (controllable or not not by the agents)."""
-
-    @autocastable
-    def get_enabled_events(
-        self, memory: Optional[D.T_memory[D.T_state]] = None
-    ) -> Space[D.T_event]:
-        """Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or
-        history), or in the internal one if omitted.
-
-        By default, #Events.get_enabled_events() provides some boilerplate code and internally
-        calls #Events._get_enabled_events(). The boilerplate code automatically passes the #_memory attribute instead of
-        the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        The space of enabled events.
-        """
-        return self._get_enabled_events(memory)
-
-    def _get_enabled_events(
-        self, memory: Optional[D.T_memory[D.T_state]] = None
-    ) -> Space[D.T_event]:
-        """Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or
-        history), or in the internal one if omitted.
-
-        By default, #Events._get_enabled_events() provides some boilerplate code and internally
-        calls #Events._get_enabled_events_from(). The boilerplate code automatically passes the #_memory attribute
-        instead of the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        The space of enabled events.
-        """
-        if memory is None:
-            memory = self._memory
-        return self._get_enabled_events_from(memory)
-
-    def _get_enabled_events_from(
-        self, memory: D.T_memory[D.T_state]
-    ) -> Space[D.T_event]:
-        """Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or
-        history).
-
-        This is a helper function called by default from #Events._get_enabled_events(), the difference being that the
-        memory parameter is mandatory here.
-
-        # Parameters
-        memory: The memory to consider.
-
-        # Returns
-        The space of enabled events.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def is_enabled_event(
-        self, event: D.T_event, memory: Optional[D.T_memory[D.T_state]] = None
-    ) -> bool:
-        """Indicate whether an uncontrollable event is enabled in the given memory (state or history), or in the
-        internal one if omitted.
-
-        By default, #Events.is_enabled_event() provides some boilerplate code and internally
-        calls #Events._is_enabled_event(). The boilerplate code automatically passes the #_memory attribute instead of
-        the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        True if the event is enabled (False otherwise).
-        """
-        return self._is_enabled_event(event, memory)
-
-    def _is_enabled_event(
-        self, event: D.T_event, memory: Optional[D.T_memory[D.T_state]] = None
-    ) -> bool:
-        """Indicate whether an uncontrollable event is enabled in the given memory (state or history), or in the
-        internal one if omitted.
-
-        By default, #Events._is_enabled_event() provides some boilerplate code and internally
-        calls #Events._is_enabled_event_from(). The boilerplate code automatically passes the #_memory attribute instead
-        of the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        True if the event is enabled (False otherwise).
-        """
-        if memory is None:
-            memory = self._memory
-        return self._is_enabled_event_from(event, memory)
-
-    def _is_enabled_event_from(
-        self, event: D.T_event, memory: D.T_memory[D.T_state]
-    ) -> bool:
-        """Indicate whether an event is enabled in the given memory (state or history).
-
-        This is a helper function called by default from #Events._is_enabled_event(), the difference being that the
-        memory parameter is mandatory here.
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the space of
-            enabled events provided by #Events._get_enabled_events_from(), but it can be overridden for faster
-            implementations.
-
-        # Parameters
-        memory: The memory to consider.
-
-        # Returns
-        True if the event is enabled (False otherwise).
-        """
-        return self._get_enabled_events_from(memory).contains(event)
-
-    @autocastable
-    def get_action_space(self) -> D.T_agent[Space[D.T_event]]:
-        """Get the (cached) domain action space (finite or infinite set).
-
-        By default, #Events.get_action_space() internally calls #Events._get_action_space_() the first time and
-        automatically caches its value to make future calls more efficient (since the action space is assumed to be
-        constant).
-
-        # Returns
-        The action space.
-        """
-        return self._get_action_space()
-
-    @functools.lru_cache()
-    def _get_action_space(self) -> D.T_agent[Space[D.T_event]]:
-        """Get the (cached) domain action space (finite or infinite set).
-
-        By default, #Events._get_action_space() internally calls #Events._get_action_space_() the first time and
-        automatically caches its value to make future calls more efficient (since the action space is assumed to be
-        constant).
-
-        # Returns
-        The action space.
-        """
-        return self._get_action_space_()
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        """Get the domain action space (finite or infinite set).
-
-        This is a helper function called by default from #Events._get_action_space(), the difference being that the
-        result is not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        The action space.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def is_action(self, event: D.T_event) -> bool:
-        """Indicate whether an event is an action (i.e. a controllable event for the agents).
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
-            action space provided by #Events.get_action_space(), but it can be overridden for faster implementations.
-
-        # Parameters
-        event: The event to consider.
-
-        # Returns
-        True if the event is an action (False otherwise).
-        """
-        return self._is_action(event)
-
-    def _is_action(self, event: D.T_event) -> bool:
-        """Indicate whether an event is an action (i.e. a controllable event for the agents).
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
-            action space provided by #Events._get_action_space(), but it can be overridden for faster implementations.
-
-        # Parameters
-        event: The event to consider.
-
-        # Returns
-        True if the event is an action (False otherwise).
-        """
-        return self._get_action_space().contains(event)
-
-    @autocastable
-    def get_applicable_actions(
-        self, memory: Optional[D.T_memory[D.T_state]] = None
-    ) -> D.T_agent[Space[D.T_event]]:
-        """Get the space (finite or infinite set) of applicable actions in the given memory (state or history), or in
-        the internal one if omitted.
-
-        By default, #Events.get_applicable_actions() provides some boilerplate code and internally
-        calls #Events._get_applicable_actions(). The boilerplate code automatically passes the #_memory attribute
-        instead of the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        The space of applicable actions.
-        """
-        return self._get_applicable_actions(memory)
-
-    def _get_applicable_actions(
-        self, memory: Optional[D.T_memory[D.T_state]] = None
-    ) -> D.T_agent[Space[D.T_event]]:
-        """Get the space (finite or infinite set) of applicable actions in the given memory (state or history), or in
-        the internal one if omitted.
-
-        By default, #Events._get_applicable_actions() provides some boilerplate code and internally
-        calls #Events._get_applicable_actions_from(). The boilerplate code automatically passes the #_memory attribute
-        instead of the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        The space of applicable actions.
-        """
-        if memory is None:
-            memory = self._memory
-        return self._get_applicable_actions_from(memory)
-
-    def _get_applicable_actions_from(
-        self, memory: D.T_memory[D.T_state]
-    ) -> D.T_agent[Space[D.T_event]]:
-        """Get the space (finite or infinite set) of applicable actions in the given memory (state or history).
-
-        This is a helper function called by default from #Events._get_applicable_actions(), the difference being that
-        the memory parameter is mandatory here.
-
-        # Parameters
-        memory: The memory to consider.
-
-        # Returns
-        The space of applicable actions.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def is_applicable_action(
-        self,
-        action: D.T_agent[D.T_event],
-        memory: Optional[D.T_memory[D.T_state]] = None,
-    ) -> bool:
-        """Indicate whether an action is applicable in the given memory (state or history), or in the internal one if
-        omitted.
-
-        By default, #Events.is_applicable_action() provides some boilerplate code and internally
-        calls #Events._is_applicable_action(). The boilerplate code automatically passes the #_memory attribute instead
-        of the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        True if the action is applicable (False otherwise).
-        """
-        return self._is_applicable_action(action, memory)
-
-    def _is_applicable_action(
-        self,
-        action: D.T_agent[D.T_event],
-        memory: Optional[D.T_memory[D.T_state]] = None,
-    ) -> bool:
-        """Indicate whether an action is applicable in the given memory (state or history), or in the internal one if
-        omitted.
-
-        By default, #Events._is_applicable_action() provides some boilerplate code and internally
-        calls #Events._is_applicable_action_from(). The boilerplate code automatically passes the #_memory attribute
-        instead of the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        True if the action is applicable (False otherwise).
-        """
-        if memory is None:
-            memory = self._memory
-        return self._is_applicable_action_from(action, memory)
-
-    def _is_applicable_action_from(
-        self, action: D.T_agent[D.T_event], memory: D.T_memory[D.T_state]
-    ) -> bool:
-        """Indicate whether an action is applicable in the given memory (state or history).
-
-        This is a helper function called by default from #Events._is_applicable_action(), the difference being that the
-        memory parameter is mandatory here.
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the space of
-            applicable actions provided by #Events._get_applicable_actions_from(), but it can be overridden for faster
-            implementations.
-
-        # Parameters
-        memory: The memory to consider.
-
-        # Returns
-        True if the action is applicable (False otherwise).
-        """
-        applicable_actions = self._get_applicable_actions_from(memory)
-        if self.T_agent == Union:
-            return applicable_actions.contains(action)
-        else:  # StrDict
-            return all(applicable_actions[k].contains(v) for k, v in action.items())
-
-
-class Actions(Events):
-    """A domain must inherit this class if it handles only actions (i.e. controllable events)."""
-
-    def _get_enabled_events_from(
-        self, memory: D.T_memory[D.T_state]
-    ) -> Space[D.T_event]:
-        # TODO: check definition of enabled events (only uncontrollable?)
-        # return self._get_enabled_actions_from(memory)
-        return EmptySpace()
-
-
-class UnrestrictedActions(Actions):
-    """A domain must inherit this class if it handles only actions (i.e. controllable events), which are always all
-    applicable.
-    """
-
-    def _get_applicable_actions_from(
-        self, memory: D.T_memory[D.T_state]
-    ) -> D.T_agent[Space[D.T_event]]:
-        return self._get_action_space()
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+from typing import Optional, Union
+
+from skdecide.core import D, EmptySpace, Space, autocastable
+
+__all__ = ["Events", "Actions", "UnrestrictedActions"]
+
+
+class Events:
+    """A domain must inherit this class if it handles events (controllable or not not by the agents)."""
+
+    @autocastable
+    def get_enabled_events(
+        self, memory: Optional[D.T_memory[D.T_state]] = None
+    ) -> Space[D.T_event]:
+        """Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or
+        history), or in the internal one if omitted.
+
+        By default, #Events.get_enabled_events() provides some boilerplate code and internally
+        calls #Events._get_enabled_events(). The boilerplate code automatically passes the #_memory attribute instead of
+        the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        The space of enabled events.
+        """
+        return self._get_enabled_events(memory)
+
+    def _get_enabled_events(
+        self, memory: Optional[D.T_memory[D.T_state]] = None
+    ) -> Space[D.T_event]:
+        """Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or
+        history), or in the internal one if omitted.
+
+        By default, #Events._get_enabled_events() provides some boilerplate code and internally
+        calls #Events._get_enabled_events_from(). The boilerplate code automatically passes the #_memory attribute
+        instead of the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        The space of enabled events.
+        """
+        if memory is None:
+            memory = self._memory
+        return self._get_enabled_events_from(memory)
+
+    def _get_enabled_events_from(
+        self, memory: D.T_memory[D.T_state]
+    ) -> Space[D.T_event]:
+        """Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or
+        history).
+
+        This is a helper function called by default from #Events._get_enabled_events(), the difference being that the
+        memory parameter is mandatory here.
+
+        # Parameters
+        memory: The memory to consider.
+
+        # Returns
+        The space of enabled events.
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def is_enabled_event(
+        self, event: D.T_event, memory: Optional[D.T_memory[D.T_state]] = None
+    ) -> bool:
+        """Indicate whether an uncontrollable event is enabled in the given memory (state or history), or in the
+        internal one if omitted.
+
+        By default, #Events.is_enabled_event() provides some boilerplate code and internally
+        calls #Events._is_enabled_event(). The boilerplate code automatically passes the #_memory attribute instead of
+        the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        True if the event is enabled (False otherwise).
+        """
+        return self._is_enabled_event(event, memory)
+
+    def _is_enabled_event(
+        self, event: D.T_event, memory: Optional[D.T_memory[D.T_state]] = None
+    ) -> bool:
+        """Indicate whether an uncontrollable event is enabled in the given memory (state or history), or in the
+        internal one if omitted.
+
+        By default, #Events._is_enabled_event() provides some boilerplate code and internally
+        calls #Events._is_enabled_event_from(). The boilerplate code automatically passes the #_memory attribute instead
+        of the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        True if the event is enabled (False otherwise).
+        """
+        if memory is None:
+            memory = self._memory
+        return self._is_enabled_event_from(event, memory)
+
+    def _is_enabled_event_from(
+        self, event: D.T_event, memory: D.T_memory[D.T_state]
+    ) -> bool:
+        """Indicate whether an event is enabled in the given memory (state or history).
+
+        This is a helper function called by default from #Events._is_enabled_event(), the difference being that the
+        memory parameter is mandatory here.
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the space of
+            enabled events provided by #Events._get_enabled_events_from(), but it can be overridden for faster
+            implementations.
+
+        # Parameters
+        memory: The memory to consider.
+
+        # Returns
+        True if the event is enabled (False otherwise).
+        """
+        return self._get_enabled_events_from(memory).contains(event)
+
+    @autocastable
+    def get_action_space(self) -> D.T_agent[Space[D.T_event]]:
+        """Get the (cached) domain action space (finite or infinite set).
+
+        By default, #Events.get_action_space() internally calls #Events._get_action_space_() the first time and
+        automatically caches its value to make future calls more efficient (since the action space is assumed to be
+        constant).
+
+        # Returns
+        The action space.
+        """
+        return self._get_action_space()
+
+    @functools.lru_cache()
+    def _get_action_space(self) -> D.T_agent[Space[D.T_event]]:
+        """Get the (cached) domain action space (finite or infinite set).
+
+        By default, #Events._get_action_space() internally calls #Events._get_action_space_() the first time and
+        automatically caches its value to make future calls more efficient (since the action space is assumed to be
+        constant).
+
+        # Returns
+        The action space.
+        """
+        return self._get_action_space_()
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        """Get the domain action space (finite or infinite set).
+
+        This is a helper function called by default from #Events._get_action_space(), the difference being that the
+        result is not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        The action space.
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def is_action(self, event: D.T_event) -> bool:
+        """Indicate whether an event is an action (i.e. a controllable event for the agents).
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
+            action space provided by #Events.get_action_space(), but it can be overridden for faster implementations.
+
+        # Parameters
+        event: The event to consider.
+
+        # Returns
+        True if the event is an action (False otherwise).
+        """
+        return self._is_action(event)
+
+    def _is_action(self, event: D.T_event) -> bool:
+        """Indicate whether an event is an action (i.e. a controllable event for the agents).
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
+            action space provided by #Events._get_action_space(), but it can be overridden for faster implementations.
+
+        # Parameters
+        event: The event to consider.
+
+        # Returns
+        True if the event is an action (False otherwise).
+        """
+        return self._get_action_space().contains(event)
+
+    @autocastable
+    def get_applicable_actions(
+        self, memory: Optional[D.T_memory[D.T_state]] = None
+    ) -> D.T_agent[Space[D.T_event]]:
+        """Get the space (finite or infinite set) of applicable actions in the given memory (state or history), or in
+        the internal one if omitted.
+
+        By default, #Events.get_applicable_actions() provides some boilerplate code and internally
+        calls #Events._get_applicable_actions(). The boilerplate code automatically passes the #_memory attribute
+        instead of the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        The space of applicable actions.
+        """
+        return self._get_applicable_actions(memory)
+
+    def _get_applicable_actions(
+        self, memory: Optional[D.T_memory[D.T_state]] = None
+    ) -> D.T_agent[Space[D.T_event]]:
+        """Get the space (finite or infinite set) of applicable actions in the given memory (state or history), or in
+        the internal one if omitted.
+
+        By default, #Events._get_applicable_actions() provides some boilerplate code and internally
+        calls #Events._get_applicable_actions_from(). The boilerplate code automatically passes the #_memory attribute
+        instead of the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        The space of applicable actions.
+        """
+        if memory is None:
+            memory = self._memory
+        return self._get_applicable_actions_from(memory)
+
+    def _get_applicable_actions_from(
+        self, memory: D.T_memory[D.T_state]
+    ) -> D.T_agent[Space[D.T_event]]:
+        """Get the space (finite or infinite set) of applicable actions in the given memory (state or history).
+
+        This is a helper function called by default from #Events._get_applicable_actions(), the difference being that
+        the memory parameter is mandatory here.
+
+        # Parameters
+        memory: The memory to consider.
+
+        # Returns
+        The space of applicable actions.
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def is_applicable_action(
+        self,
+        action: D.T_agent[D.T_event],
+        memory: Optional[D.T_memory[D.T_state]] = None,
+    ) -> bool:
+        """Indicate whether an action is applicable in the given memory (state or history), or in the internal one if
+        omitted.
+
+        By default, #Events.is_applicable_action() provides some boilerplate code and internally
+        calls #Events._is_applicable_action(). The boilerplate code automatically passes the #_memory attribute instead
+        of the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        True if the action is applicable (False otherwise).
+        """
+        return self._is_applicable_action(action, memory)
+
+    def _is_applicable_action(
+        self,
+        action: D.T_agent[D.T_event],
+        memory: Optional[D.T_memory[D.T_state]] = None,
+    ) -> bool:
+        """Indicate whether an action is applicable in the given memory (state or history), or in the internal one if
+        omitted.
+
+        By default, #Events._is_applicable_action() provides some boilerplate code and internally
+        calls #Events._is_applicable_action_from(). The boilerplate code automatically passes the #_memory attribute
+        instead of the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        True if the action is applicable (False otherwise).
+        """
+        if memory is None:
+            memory = self._memory
+        return self._is_applicable_action_from(action, memory)
+
+    def _is_applicable_action_from(
+        self, action: D.T_agent[D.T_event], memory: D.T_memory[D.T_state]
+    ) -> bool:
+        """Indicate whether an action is applicable in the given memory (state or history).
+
+        This is a helper function called by default from #Events._is_applicable_action(), the difference being that the
+        memory parameter is mandatory here.
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the space of
+            applicable actions provided by #Events._get_applicable_actions_from(), but it can be overridden for faster
+            implementations.
+
+        # Parameters
+        memory: The memory to consider.
+
+        # Returns
+        True if the action is applicable (False otherwise).
+        """
+        applicable_actions = self._get_applicable_actions_from(memory)
+        if self.T_agent == Union:
+            return applicable_actions.contains(action)
+        else:  # StrDict
+            return all(applicable_actions[k].contains(v) for k, v in action.items())
+
+
+class Actions(Events):
+    """A domain must inherit this class if it handles only actions (i.e. controllable events)."""
+
+    def _get_enabled_events_from(
+        self, memory: D.T_memory[D.T_state]
+    ) -> Space[D.T_event]:
+        # TODO: check definition of enabled events (only uncontrollable?)
+        # return self._get_enabled_actions_from(memory)
+        return EmptySpace()
+
+
+class UnrestrictedActions(Actions):
+    """A domain must inherit this class if it handles only actions (i.e. controllable events), which are always all
+    applicable.
+    """
+
+    def _get_applicable_actions_from(
+        self, memory: D.T_memory[D.T_state]
+    ) -> D.T_agent[Space[D.T_event]]:
+        return self._get_action_space()
```

## skdecide/builders/domain/goals.py

 * *Ordering differences only*

```diff
@@ -1,106 +1,106 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-from typing import Union
-
-from skdecide.core import D, Space, autocastable
-
-__all__ = ["Goals"]
-
-
-class Goals:
-    """A domain must inherit this class if it has formalized goals."""
-
-    @autocastable
-    def get_goals(self) -> D.T_agent[Space[D.T_observation]]:
-        """Get the (cached) domain goals space (finite or infinite set).
-
-        By default, #Goals.get_goals() internally calls #Goals._get_goals_() the first time and automatically caches its
-        value to make future calls more efficient (since the goals space is assumed to be constant).
-
-        !!! warning
-            Goal states are assumed to be fully observable (i.e. observation = state) so that there is never uncertainty
-            about whether the goal has been reached or not. This assumption guarantees that any policy that does not
-            reach the goal with certainty incurs in infinite expected cost. - *Geffner, 2013: A Concise Introduction to
-            Models and Methods for Automated Planning*
-
-        # Returns
-        The goals space.
-        """
-        return self._get_goals()
-
-    @functools.lru_cache()
-    def _get_goals(self) -> D.T_agent[Space[D.T_observation]]:
-        """Get the (cached) domain goals space (finite or infinite set).
-
-        By default, #Goals._get_goals() internally calls #Goals._get_goals_() the first time and automatically caches
-        its value to make future calls more efficient (since the goals space is assumed to be constant).
-
-        !!! warning
-            Goal states are assumed to be fully observable (i.e. observation = state) so that there is never uncertainty
-            about whether the goal has been reached or not. This assumption guarantees that any policy that does not
-            reach the goal with certainty incurs in infinite expected cost. - *Geffner, 2013: A Concise Introduction to
-            Models and Methods for Automated Planning*
-
-        # Returns
-        The goals space.
-        """
-        return self._get_goals_()
-
-    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
-        """Get the domain goals space (finite or infinite set).
-
-        This is a helper function called by default from #Goals._get_goals(), the difference being that the result is
-        not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        The goals space.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def is_goal(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_predicate]:
-        """Indicate whether an observation belongs to the goals.
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
-            goals space provided by #Goals.get_goals(), but it can be overridden for faster implementations.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        True if the observation is a goal (False otherwise).
-        """
-        return self._is_goal(observation)
-
-    def _is_goal(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_predicate]:
-        """Indicate whether an observation belongs to the goals.
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
-            goals space provided by #Goals._get_goals(), but it can be overridden for faster implementations.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        True if the observation is a goal (False otherwise).
-        """
-        goals = self._get_goals()
-        if self.T_agent == Union:
-            return goals.contains(observation)
-        else:  # StrDict
-            return {k: goals[k].contains(v) for k, v in observation.items()}
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+from typing import Union
+
+from skdecide.core import D, Space, autocastable
+
+__all__ = ["Goals"]
+
+
+class Goals:
+    """A domain must inherit this class if it has formalized goals."""
+
+    @autocastable
+    def get_goals(self) -> D.T_agent[Space[D.T_observation]]:
+        """Get the (cached) domain goals space (finite or infinite set).
+
+        By default, #Goals.get_goals() internally calls #Goals._get_goals_() the first time and automatically caches its
+        value to make future calls more efficient (since the goals space is assumed to be constant).
+
+        !!! warning
+            Goal states are assumed to be fully observable (i.e. observation = state) so that there is never uncertainty
+            about whether the goal has been reached or not. This assumption guarantees that any policy that does not
+            reach the goal with certainty incurs in infinite expected cost. - *Geffner, 2013: A Concise Introduction to
+            Models and Methods for Automated Planning*
+
+        # Returns
+        The goals space.
+        """
+        return self._get_goals()
+
+    @functools.lru_cache()
+    def _get_goals(self) -> D.T_agent[Space[D.T_observation]]:
+        """Get the (cached) domain goals space (finite or infinite set).
+
+        By default, #Goals._get_goals() internally calls #Goals._get_goals_() the first time and automatically caches
+        its value to make future calls more efficient (since the goals space is assumed to be constant).
+
+        !!! warning
+            Goal states are assumed to be fully observable (i.e. observation = state) so that there is never uncertainty
+            about whether the goal has been reached or not. This assumption guarantees that any policy that does not
+            reach the goal with certainty incurs in infinite expected cost. - *Geffner, 2013: A Concise Introduction to
+            Models and Methods for Automated Planning*
+
+        # Returns
+        The goals space.
+        """
+        return self._get_goals_()
+
+    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
+        """Get the domain goals space (finite or infinite set).
+
+        This is a helper function called by default from #Goals._get_goals(), the difference being that the result is
+        not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        The goals space.
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def is_goal(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_predicate]:
+        """Indicate whether an observation belongs to the goals.
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
+            goals space provided by #Goals.get_goals(), but it can be overridden for faster implementations.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        True if the observation is a goal (False otherwise).
+        """
+        return self._is_goal(observation)
+
+    def _is_goal(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_predicate]:
+        """Indicate whether an observation belongs to the goals.
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
+            goals space provided by #Goals._get_goals(), but it can be overridden for faster implementations.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        True if the observation is a goal (False otherwise).
+        """
+        goals = self._get_goals()
+        if self.T_agent == Union:
+            return goals.contains(observation)
+        else:  # StrDict
+            return {k: goals[k].contains(v) for k, v in observation.items()}
```

## skdecide/builders/domain/initialization.py

 * *Ordering differences only*

```diff
@@ -1,148 +1,148 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-
-from skdecide.core import D, Distribution, SingleValueDistribution, autocastable
-
-__all__ = ["Initializable", "UncertainInitialized", "DeterministicInitialized"]
-
-
-class Initializable:
-    """A domain must inherit this class if it can be initialized."""
-
-    @autocastable
-    def reset(self) -> D.T_agent[D.T_observation]:
-        """Reset the state of the environment and return an initial observation.
-
-        By default, #Initializable.reset() provides some boilerplate code and internally calls #Initializable._reset()
-        (which returns an initial state). The boilerplate code automatically stores the initial state into the #_memory
-        attribute and samples a corresponding observation.
-
-        # Returns
-        An initial observation.
-        """
-        return self._reset()
-
-    def _reset(self) -> D.T_agent[D.T_observation]:
-        """Reset the state of the environment and return an initial observation.
-
-        By default, #Initializable._reset() provides some boilerplate code and internally
-        calls #Initializable._state_reset() (which returns an initial state). The boilerplate code automatically stores
-        the initial state into the #_memory attribute and samples a corresponding observation.
-
-        # Returns
-        An initial observation.
-        """
-        initial_state = self._state_reset()
-        self._memory = self._init_memory(initial_state)
-        initial_observation = self._get_observation_distribution(initial_state).sample()
-        return initial_observation
-
-    def _state_reset(self) -> D.T_state:
-        """Reset the state of the environment and return an initial state.
-
-        This is a helper function called by default from #Initializable._reset(). It focuses on the state level, as
-        opposed to the observation one for the latter.
-
-        # Returns
-        An initial state.
-        """
-        raise NotImplementedError
-
-
-class UncertainInitialized(Initializable):
-    """A domain must inherit this class if its states are initialized according to a probability distribution known as
-    white-box."""
-
-    def _state_reset(self) -> D.T_state:
-        initial_state = self._get_initial_state_distribution().sample()
-        return initial_state
-
-    @autocastable
-    def get_initial_state_distribution(self) -> Distribution[D.T_state]:
-        """Get the (cached) probability distribution of initial states.
-
-        By default, #UncertainInitialized.get_initial_state_distribution() internally
-        calls #UncertainInitialized._get_initial_state_distribution_() the first time and automatically caches its value
-        to make future calls more efficient (since the initial state distribution is assumed to be constant).
-
-        # Returns
-        The probability distribution of initial states.
-        """
-        return self._get_initial_state_distribution()
-
-    @functools.lru_cache()
-    def _get_initial_state_distribution(self) -> Distribution[D.T_state]:
-        """Get the (cached) probability distribution of initial states.
-
-        By default, #UncertainInitialized._get_initial_state_distribution() internally
-        calls #UncertainInitialized._get_initial_state_distribution_() the first time and automatically caches its value
-        to make future calls more efficient (since the initial state distribution is assumed to be constant).
-
-        # Returns
-        The probability distribution of initial states.
-        """
-        return self._get_initial_state_distribution_()
-
-    def _get_initial_state_distribution_(self) -> Distribution[D.T_state]:
-        """Get the probability distribution of initial states.
-
-        This is a helper function called by default from #UncertainInitialized._get_initial_state_distribution(), the
-        difference being that the result is not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        The probability distribution of initial states.
-        """
-        raise NotImplementedError
-
-
-class DeterministicInitialized(UncertainInitialized):
-    """A domain must inherit this class if it has a deterministic initial state known as white-box."""
-
-    def _get_initial_state_distribution_(self) -> Distribution[D.T_state]:
-        return SingleValueDistribution(self._get_initial_state())
-
-    @autocastable
-    def get_initial_state(self) -> D.T_state:
-        """Get the (cached) initial state.
-
-        By default, #DeterministicInitialized.get_initial_state() internally
-        calls #DeterministicInitialized._get_initial_state_() the first time and automatically caches its value to make
-        future calls more efficient (since the initial state is assumed to be constant).
-
-        # Returns
-        The initial state.
-        """
-        return self._get_initial_state()
-
-    @functools.lru_cache()
-    def _get_initial_state(self) -> D.T_state:
-        """Get the (cached) initial state.
-
-        By default, #DeterministicInitialized._get_initial_state() internally
-        calls #DeterministicInitialized._get_initial_state_() the first time and automatically caches its value to make
-        future calls more efficient (since the initial state is assumed to be constant).
-
-        # Returns
-        The initial state.
-        """
-        return self._get_initial_state_()
-
-    def _get_initial_state_(self) -> D.T_state:
-        """Get the initial state.
-
-        This is a helper function called by default from #DeterministicInitialized._get_initial_state(), the difference
-        being that the result is not cached here.
-
-        # Returns
-        The initial state.
-        """
-        raise NotImplementedError
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+
+from skdecide.core import D, Distribution, SingleValueDistribution, autocastable
+
+__all__ = ["Initializable", "UncertainInitialized", "DeterministicInitialized"]
+
+
+class Initializable:
+    """A domain must inherit this class if it can be initialized."""
+
+    @autocastable
+    def reset(self) -> D.T_agent[D.T_observation]:
+        """Reset the state of the environment and return an initial observation.
+
+        By default, #Initializable.reset() provides some boilerplate code and internally calls #Initializable._reset()
+        (which returns an initial state). The boilerplate code automatically stores the initial state into the #_memory
+        attribute and samples a corresponding observation.
+
+        # Returns
+        An initial observation.
+        """
+        return self._reset()
+
+    def _reset(self) -> D.T_agent[D.T_observation]:
+        """Reset the state of the environment and return an initial observation.
+
+        By default, #Initializable._reset() provides some boilerplate code and internally
+        calls #Initializable._state_reset() (which returns an initial state). The boilerplate code automatically stores
+        the initial state into the #_memory attribute and samples a corresponding observation.
+
+        # Returns
+        An initial observation.
+        """
+        initial_state = self._state_reset()
+        self._memory = self._init_memory(initial_state)
+        initial_observation = self._get_observation_distribution(initial_state).sample()
+        return initial_observation
+
+    def _state_reset(self) -> D.T_state:
+        """Reset the state of the environment and return an initial state.
+
+        This is a helper function called by default from #Initializable._reset(). It focuses on the state level, as
+        opposed to the observation one for the latter.
+
+        # Returns
+        An initial state.
+        """
+        raise NotImplementedError
+
+
+class UncertainInitialized(Initializable):
+    """A domain must inherit this class if its states are initialized according to a probability distribution known as
+    white-box."""
+
+    def _state_reset(self) -> D.T_state:
+        initial_state = self._get_initial_state_distribution().sample()
+        return initial_state
+
+    @autocastable
+    def get_initial_state_distribution(self) -> Distribution[D.T_state]:
+        """Get the (cached) probability distribution of initial states.
+
+        By default, #UncertainInitialized.get_initial_state_distribution() internally
+        calls #UncertainInitialized._get_initial_state_distribution_() the first time and automatically caches its value
+        to make future calls more efficient (since the initial state distribution is assumed to be constant).
+
+        # Returns
+        The probability distribution of initial states.
+        """
+        return self._get_initial_state_distribution()
+
+    @functools.lru_cache()
+    def _get_initial_state_distribution(self) -> Distribution[D.T_state]:
+        """Get the (cached) probability distribution of initial states.
+
+        By default, #UncertainInitialized._get_initial_state_distribution() internally
+        calls #UncertainInitialized._get_initial_state_distribution_() the first time and automatically caches its value
+        to make future calls more efficient (since the initial state distribution is assumed to be constant).
+
+        # Returns
+        The probability distribution of initial states.
+        """
+        return self._get_initial_state_distribution_()
+
+    def _get_initial_state_distribution_(self) -> Distribution[D.T_state]:
+        """Get the probability distribution of initial states.
+
+        This is a helper function called by default from #UncertainInitialized._get_initial_state_distribution(), the
+        difference being that the result is not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        The probability distribution of initial states.
+        """
+        raise NotImplementedError
+
+
+class DeterministicInitialized(UncertainInitialized):
+    """A domain must inherit this class if it has a deterministic initial state known as white-box."""
+
+    def _get_initial_state_distribution_(self) -> Distribution[D.T_state]:
+        return SingleValueDistribution(self._get_initial_state())
+
+    @autocastable
+    def get_initial_state(self) -> D.T_state:
+        """Get the (cached) initial state.
+
+        By default, #DeterministicInitialized.get_initial_state() internally
+        calls #DeterministicInitialized._get_initial_state_() the first time and automatically caches its value to make
+        future calls more efficient (since the initial state is assumed to be constant).
+
+        # Returns
+        The initial state.
+        """
+        return self._get_initial_state()
+
+    @functools.lru_cache()
+    def _get_initial_state(self) -> D.T_state:
+        """Get the (cached) initial state.
+
+        By default, #DeterministicInitialized._get_initial_state() internally
+        calls #DeterministicInitialized._get_initial_state_() the first time and automatically caches its value to make
+        future calls more efficient (since the initial state is assumed to be constant).
+
+        # Returns
+        The initial state.
+        """
+        return self._get_initial_state_()
+
+    def _get_initial_state_(self) -> D.T_state:
+        """Get the initial state.
+
+        This is a helper function called by default from #DeterministicInitialized._get_initial_state(), the difference
+        being that the result is not cached here.
+
+        # Returns
+        The initial state.
+        """
+        raise NotImplementedError
```

## skdecide/builders/domain/memory.py

 * *Ordering differences only*

```diff
@@ -1,118 +1,118 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-from typing import Optional, Union
-
-from skdecide.core import D, Memory
-
-__all__ = ["History", "FiniteHistory", "Markovian", "Memoryless"]
-
-
-class History:
-    """A domain must inherit this class if its full state history must be stored to compute its dynamics (non-Markovian
-    domain)."""
-
-    _memory: D.T_memory[D.T_state]
-    T_memory = Memory
-
-    def _init_memory(self, state: Optional[D.T_state] = None) -> D.T_memory[D.T_state]:
-        """Initialize memory (possibly with a state) according to its specification and return it.
-
-        This function is automatically called by #Initializable._reset() to reinitialize the internal memory whenever
-        the domain is used as an environment.
-
-        # Parameters
-        state: An optional state to initialize the memory with (typically the initial state).
-
-        # Returns
-        The new initialized memory.
-        """
-        content = [state] if state is not None else []
-        return Memory(content, maxlen=self._get_memory_maxlen())
-
-    def _get_memory_maxlen(self) -> Optional[int]:
-        """Get the memory max length (or None if unbounded).
-
-        !!! tip
-            This function returns always None by default because the memory length is unbounded at this level.
-
-        # Returns
-        The memory max length (or None if unbounded).
-        """
-        return None
-
-
-class FiniteHistory(History):
-    """A domain must inherit this class if the last N states must be stored to compute its dynamics (Markovian
-    domain of order N).
-
-    N is specified by the return value of the #FiniteHistory._get_memory_maxlen() function.
-    """
-
-    T_memory = Memory
-
-    @functools.lru_cache()
-    def _get_memory_maxlen(self) -> int:
-        """Get the (cached) memory max length.
-
-        By default, #FiniteHistory._get_memory_maxlen() internally calls #FiniteHistory._get_memory_maxlen_() the first
-        time and automatically caches its value to make future calls more efficient (since the memory max length is
-        assumed to be constant).
-
-        # Returns
-        The memory max length.
-        """
-        return self._get_memory_maxlen_()
-
-    def _get_memory_maxlen_(self) -> int:
-        """Get the memory max length.
-
-        This is a helper function called by default from #FiniteHistory._get_memory_maxlen(), the difference being that
-        the result is not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        The memory max length.
-        """
-        raise NotImplementedError
-
-
-class Markovian(FiniteHistory):
-    """A domain must inherit this class if only its last state must be stored to compute its dynamics (pure Markovian
-    domain)."""
-
-    T_memory = Union
-
-    def _init_memory(self, state: Optional[D.T_state] = None) -> D.T_memory[D.T_state]:
-        return state
-
-    def _get_memory_maxlen_(self) -> int:
-        return 1
-
-
-class Memoryless(Markovian):
-    """A domain must inherit this class if it does not require any previous state(s) to be stored to compute its
-    dynamics.
-
-    A dice roll simulator is an example of memoryless domain (next states are independent of previous ones).
-
-    !!! tip
-        Whenever an existing domain (environment, simulator...) needs to be wrapped instead of implemented fully in
-        scikit-decide (e.g. compiled ATARI games), Memoryless can be used because the domain memory (if any) would
-        be handled externally.
-    """
-
-    T_memory = Union
-
-    def _init_memory(self, state: Optional[D.T_state] = None) -> D.T_memory[D.T_state]:
-        return None
-
-    def _get_memory_maxlen_(self) -> int:
-        return 0
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+from typing import Optional, Union
+
+from skdecide.core import D, Memory
+
+__all__ = ["History", "FiniteHistory", "Markovian", "Memoryless"]
+
+
+class History:
+    """A domain must inherit this class if its full state history must be stored to compute its dynamics (non-Markovian
+    domain)."""
+
+    _memory: D.T_memory[D.T_state]
+    T_memory = Memory
+
+    def _init_memory(self, state: Optional[D.T_state] = None) -> D.T_memory[D.T_state]:
+        """Initialize memory (possibly with a state) according to its specification and return it.
+
+        This function is automatically called by #Initializable._reset() to reinitialize the internal memory whenever
+        the domain is used as an environment.
+
+        # Parameters
+        state: An optional state to initialize the memory with (typically the initial state).
+
+        # Returns
+        The new initialized memory.
+        """
+        content = [state] if state is not None else []
+        return Memory(content, maxlen=self._get_memory_maxlen())
+
+    def _get_memory_maxlen(self) -> Optional[int]:
+        """Get the memory max length (or None if unbounded).
+
+        !!! tip
+            This function returns always None by default because the memory length is unbounded at this level.
+
+        # Returns
+        The memory max length (or None if unbounded).
+        """
+        return None
+
+
+class FiniteHistory(History):
+    """A domain must inherit this class if the last N states must be stored to compute its dynamics (Markovian
+    domain of order N).
+
+    N is specified by the return value of the #FiniteHistory._get_memory_maxlen() function.
+    """
+
+    T_memory = Memory
+
+    @functools.lru_cache()
+    def _get_memory_maxlen(self) -> int:
+        """Get the (cached) memory max length.
+
+        By default, #FiniteHistory._get_memory_maxlen() internally calls #FiniteHistory._get_memory_maxlen_() the first
+        time and automatically caches its value to make future calls more efficient (since the memory max length is
+        assumed to be constant).
+
+        # Returns
+        The memory max length.
+        """
+        return self._get_memory_maxlen_()
+
+    def _get_memory_maxlen_(self) -> int:
+        """Get the memory max length.
+
+        This is a helper function called by default from #FiniteHistory._get_memory_maxlen(), the difference being that
+        the result is not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        The memory max length.
+        """
+        raise NotImplementedError
+
+
+class Markovian(FiniteHistory):
+    """A domain must inherit this class if only its last state must be stored to compute its dynamics (pure Markovian
+    domain)."""
+
+    T_memory = Union
+
+    def _init_memory(self, state: Optional[D.T_state] = None) -> D.T_memory[D.T_state]:
+        return state
+
+    def _get_memory_maxlen_(self) -> int:
+        return 1
+
+
+class Memoryless(Markovian):
+    """A domain must inherit this class if it does not require any previous state(s) to be stored to compute its
+    dynamics.
+
+    A dice roll simulator is an example of memoryless domain (next states are independent of previous ones).
+
+    !!! tip
+        Whenever an existing domain (environment, simulator...) needs to be wrapped instead of implemented fully in
+        scikit-decide (e.g. compiled ATARI games), Memoryless can be used because the domain memory (if any) would
+        be handled externally.
+    """
+
+    T_memory = Union
+
+    def _init_memory(self, state: Optional[D.T_state] = None) -> D.T_memory[D.T_state]:
+        return None
+
+    def _get_memory_maxlen_(self) -> int:
+        return 0
```

## skdecide/builders/domain/observability.py

 * *Ordering differences only*

```diff
@@ -1,204 +1,204 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-from typing import Optional, Union
-
-from skdecide.core import D, Distribution, SingleValueDistribution, Space, autocastable
-
-__all__ = ["PartiallyObservable", "TransformedObservable", "FullyObservable"]
-
-
-class PartiallyObservable:
-    """A domain must inherit this class if it is partially observable.
-
-    "Partially observable" means that the observation provided to the agent is computed from (but generally not equal
-    to) the internal state of the domain. Additionally, according to literature, a partially observable domain must
-    provide the probability distribution of the observation given a state and action.
-    """
-
-    @autocastable
-    def get_observation_space(self) -> D.T_agent[Space[D.T_observation]]:
-        """Get the (cached) observation space (finite or infinite set).
-
-        By default, #PartiallyObservable.get_observation_space() internally
-        calls #PartiallyObservable._get_observation_space_() the first time and automatically caches its value to make
-        future calls more efficient (since the observation space is assumed to be constant).
-
-        # Returns
-        The observation space.
-        """
-        return self._get_observation_space()
-
-    @functools.lru_cache()
-    def _get_observation_space(self) -> D.T_agent[Space[D.T_observation]]:
-        """Get the (cached) observation space (finite or infinite set).
-
-        By default, #PartiallyObservable._get_observation_space() internally
-        calls #PartiallyObservable._get_observation_space_() the first time and automatically caches its value to make
-        future calls more efficient (since the observation space is assumed to be constant).
-
-        # Returns
-        The observation space.
-        """
-        return self._get_observation_space_()
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        """Get the observation space (finite or infinite set).
-
-        This is a helper function called by default from #PartiallyObservable._get_observation_space(), the difference
-        being that the result is not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        The observation space.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def is_observation(self, observation: D.T_agent[D.T_observation]) -> bool:
-        """Check that an observation indeed belongs to the domain observation space.
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
-            observation space provided by #PartiallyObservable.get_observation_space(), but it can be overridden for
-            faster implementations.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        True if the observation belongs to the domain observation space (False otherwise).
-        """
-        return self._is_observation(observation)
-
-    def _is_observation(self, observation: D.T_agent[D.T_observation]) -> bool:
-        """Check that an observation indeed belongs to the domain observation space.
-
-        !!! tip
-            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
-            observation space provided by #PartiallyObservable._get_observation_space(), but it can be overridden for
-            faster implementations.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        True if the observation belongs to the domain observation space (False otherwise).
-        """
-        observation_space = self._get_observation_space()
-        if self.T_agent == Union:
-            return observation_space.contains(observation)
-        else:  # StrDict
-            return all(observation_space[k].contains(v) for k, v in observation.items())
-
-    @autocastable
-    def get_observation_distribution(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> Distribution[D.T_agent[D.T_observation]]:
-        """Get the probability distribution of the observation given a state and action.
-
-        In mathematical terms (discrete case), given an action $a$, this function represents: $P(O|s, a)$,
-        where $O$ is the random variable of the observation.
-
-        # Parameters
-        state: The state to be observed.
-        action: The last applied action (or None if the state is an initial state).
-
-        # Returns
-        The probability distribution of the observation.
-        """
-        return self._get_observation_distribution(state, action)
-
-    def _get_observation_distribution(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> Distribution[D.T_agent[D.T_observation]]:
-        """Get the probability distribution of the observation given a state and action.
-
-        In mathematical terms (discrete case), given an action $a$, this function represents: $P(O|s, a)$,
-        where $O$ is the random variable of the observation.
-
-        # Parameters
-        state: The state to be observed.
-        action: The last applied action (or None if the state is an initial state).
-
-        # Returns
-        The probability distribution of the observation.
-        """
-        raise NotImplementedError
-
-
-class TransformedObservable(PartiallyObservable):
-    """A domain must inherit this class if it is transformed observable.
-
-    "Transformed observable" means that the observation provided to the agent is deterministically computed from (but
-    generally not equal to) the internal state of the domain.
-    """
-
-    def _get_observation_distribution(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> Distribution[D.T_agent[D.T_observation]]:
-        return SingleValueDistribution(self._get_observation(state, action))
-
-    @autocastable
-    def get_observation(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> D.T_agent[D.T_observation]:
-        """Get the deterministic observation given a state and action.
-
-        # Parameters
-        state: The state to be observed.
-        action: The last applied action (or None if the state is an initial state).
-
-        # Returns
-        The probability distribution of the observation.
-        """
-        return self._get_observation(state, action)
-
-    def _get_observation(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> D.T_agent[D.T_observation]:
-        """Get the deterministic observation given a state and action.
-
-        # Parameters
-        state: The state to be observed.
-        action: The last applied action (or None if the state is an initial state).
-
-        # Returns
-        The probability distribution of the observation.
-        """
-        raise NotImplementedError
-
-
-class FullyObservable(TransformedObservable):
-    """A domain must inherit this class if it is fully observable.
-
-    "Fully observable" means that the observation provided to the agent is equal to the internal state of the domain.
-
-    !!! warning
-        In the case of fully observable domains, make sure that the observation type D.T_observation is equal to the
-        state type D.T_state.
-    """
-
-    def _get_observation(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> D.T_agent[D.T_observation]:
-        return state
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+from typing import Optional, Union
+
+from skdecide.core import D, Distribution, SingleValueDistribution, Space, autocastable
+
+__all__ = ["PartiallyObservable", "TransformedObservable", "FullyObservable"]
+
+
+class PartiallyObservable:
+    """A domain must inherit this class if it is partially observable.
+
+    "Partially observable" means that the observation provided to the agent is computed from (but generally not equal
+    to) the internal state of the domain. Additionally, according to literature, a partially observable domain must
+    provide the probability distribution of the observation given a state and action.
+    """
+
+    @autocastable
+    def get_observation_space(self) -> D.T_agent[Space[D.T_observation]]:
+        """Get the (cached) observation space (finite or infinite set).
+
+        By default, #PartiallyObservable.get_observation_space() internally
+        calls #PartiallyObservable._get_observation_space_() the first time and automatically caches its value to make
+        future calls more efficient (since the observation space is assumed to be constant).
+
+        # Returns
+        The observation space.
+        """
+        return self._get_observation_space()
+
+    @functools.lru_cache()
+    def _get_observation_space(self) -> D.T_agent[Space[D.T_observation]]:
+        """Get the (cached) observation space (finite or infinite set).
+
+        By default, #PartiallyObservable._get_observation_space() internally
+        calls #PartiallyObservable._get_observation_space_() the first time and automatically caches its value to make
+        future calls more efficient (since the observation space is assumed to be constant).
+
+        # Returns
+        The observation space.
+        """
+        return self._get_observation_space_()
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        """Get the observation space (finite or infinite set).
+
+        This is a helper function called by default from #PartiallyObservable._get_observation_space(), the difference
+        being that the result is not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        The observation space.
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def is_observation(self, observation: D.T_agent[D.T_observation]) -> bool:
+        """Check that an observation indeed belongs to the domain observation space.
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
+            observation space provided by #PartiallyObservable.get_observation_space(), but it can be overridden for
+            faster implementations.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        True if the observation belongs to the domain observation space (False otherwise).
+        """
+        return self._is_observation(observation)
+
+    def _is_observation(self, observation: D.T_agent[D.T_observation]) -> bool:
+        """Check that an observation indeed belongs to the domain observation space.
+
+        !!! tip
+            By default, this function is implemented using the #skdecide.core.Space.contains() function on the domain
+            observation space provided by #PartiallyObservable._get_observation_space(), but it can be overridden for
+            faster implementations.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        True if the observation belongs to the domain observation space (False otherwise).
+        """
+        observation_space = self._get_observation_space()
+        if self.T_agent == Union:
+            return observation_space.contains(observation)
+        else:  # StrDict
+            return all(observation_space[k].contains(v) for k, v in observation.items())
+
+    @autocastable
+    def get_observation_distribution(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> Distribution[D.T_agent[D.T_observation]]:
+        """Get the probability distribution of the observation given a state and action.
+
+        In mathematical terms (discrete case), given an action $a$, this function represents: $P(O|s, a)$,
+        where $O$ is the random variable of the observation.
+
+        # Parameters
+        state: The state to be observed.
+        action: The last applied action (or None if the state is an initial state).
+
+        # Returns
+        The probability distribution of the observation.
+        """
+        return self._get_observation_distribution(state, action)
+
+    def _get_observation_distribution(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> Distribution[D.T_agent[D.T_observation]]:
+        """Get the probability distribution of the observation given a state and action.
+
+        In mathematical terms (discrete case), given an action $a$, this function represents: $P(O|s, a)$,
+        where $O$ is the random variable of the observation.
+
+        # Parameters
+        state: The state to be observed.
+        action: The last applied action (or None if the state is an initial state).
+
+        # Returns
+        The probability distribution of the observation.
+        """
+        raise NotImplementedError
+
+
+class TransformedObservable(PartiallyObservable):
+    """A domain must inherit this class if it is transformed observable.
+
+    "Transformed observable" means that the observation provided to the agent is deterministically computed from (but
+    generally not equal to) the internal state of the domain.
+    """
+
+    def _get_observation_distribution(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> Distribution[D.T_agent[D.T_observation]]:
+        return SingleValueDistribution(self._get_observation(state, action))
+
+    @autocastable
+    def get_observation(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> D.T_agent[D.T_observation]:
+        """Get the deterministic observation given a state and action.
+
+        # Parameters
+        state: The state to be observed.
+        action: The last applied action (or None if the state is an initial state).
+
+        # Returns
+        The probability distribution of the observation.
+        """
+        return self._get_observation(state, action)
+
+    def _get_observation(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> D.T_agent[D.T_observation]:
+        """Get the deterministic observation given a state and action.
+
+        # Parameters
+        state: The state to be observed.
+        action: The last applied action (or None if the state is an initial state).
+
+        # Returns
+        The probability distribution of the observation.
+        """
+        raise NotImplementedError
+
+
+class FullyObservable(TransformedObservable):
+    """A domain must inherit this class if it is fully observable.
+
+    "Fully observable" means that the observation provided to the agent is equal to the internal state of the domain.
+
+    !!! warning
+        In the case of fully observable domains, make sure that the observation type D.T_observation is equal to the
+        state type D.T_state.
+    """
+
+    def _get_observation(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> D.T_agent[D.T_observation]:
+        return state
```

## skdecide/builders/domain/renderability.py

 * *Ordering differences only*

```diff
@@ -1,66 +1,66 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Optional
-
-from skdecide.core import D, autocastable
-
-__all__ = ["Renderable"]
-
-
-class Renderable:
-    """A domain must inherit this class if it can be rendered with any kind of visualization."""
-
-    @autocastable
-    def render(
-        self, memory: Optional[D.T_memory[D.T_state]] = None, **kwargs: Any
-    ) -> Any:
-        """Compute a visual render of the given memory (state or history), or the internal one if omitted.
-
-        By default, #Renderable.render() provides some boilerplate code and internally calls #Renderable._render(). The
-        boilerplate code automatically passes the #_memory attribute instead of the memory parameter whenever the latter
-        is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        A render (e.g. image) or nothing (if the function handles the display directly).
-        """
-        return self._render(memory, **kwargs)
-
-    def _render(
-        self, memory: Optional[D.T_memory[D.T_state]] = None, **kwargs: Any
-    ) -> Any:
-        """Compute a visual render of the given memory (state or history), or the internal one if omitted.
-
-        By default, #Renderable._render() provides some boilerplate code and internally
-        calls #Renderable._render_from(). The boilerplate code automatically passes the #_memory attribute instead of
-        the memory parameter whenever the latter is None.
-
-        # Parameters
-        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
-
-        # Returns
-        A render (e.g. image) or nothing (if the function handles the display directly).
-        """
-        if memory is None:
-            memory = self._memory
-        return self._render_from(memory, **kwargs)
-
-    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
-        """Compute a visual render of the given memory (state or history).
-
-        This is a helper function called by default from #Renderable._render(), the difference being that the
-        memory parameter is mandatory here.
-
-        # Parameters
-        memory: The memory to consider.
-
-        # Returns
-        A render (e.g. image) or nothing (if the function handles the display directly).
-        """
-        raise NotImplementedError
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Optional
+
+from skdecide.core import D, autocastable
+
+__all__ = ["Renderable"]
+
+
+class Renderable:
+    """A domain must inherit this class if it can be rendered with any kind of visualization."""
+
+    @autocastable
+    def render(
+        self, memory: Optional[D.T_memory[D.T_state]] = None, **kwargs: Any
+    ) -> Any:
+        """Compute a visual render of the given memory (state or history), or the internal one if omitted.
+
+        By default, #Renderable.render() provides some boilerplate code and internally calls #Renderable._render(). The
+        boilerplate code automatically passes the #_memory attribute instead of the memory parameter whenever the latter
+        is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        A render (e.g. image) or nothing (if the function handles the display directly).
+        """
+        return self._render(memory, **kwargs)
+
+    def _render(
+        self, memory: Optional[D.T_memory[D.T_state]] = None, **kwargs: Any
+    ) -> Any:
+        """Compute a visual render of the given memory (state or history), or the internal one if omitted.
+
+        By default, #Renderable._render() provides some boilerplate code and internally
+        calls #Renderable._render_from(). The boilerplate code automatically passes the #_memory attribute instead of
+        the memory parameter whenever the latter is None.
+
+        # Parameters
+        memory: The memory to consider (if None, the internal memory attribute #_memory is used instead).
+
+        # Returns
+        A render (e.g. image) or nothing (if the function handles the display directly).
+        """
+        if memory is None:
+            memory = self._memory
+        return self._render_from(memory, **kwargs)
+
+    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
+        """Compute a visual render of the given memory (state or history).
+
+        This is a helper function called by default from #Renderable._render(), the difference being that the
+        memory parameter is mandatory here.
+
+        # Parameters
+        memory: The memory to consider.
+
+        # Returns
+        A render (e.g. image) or nothing (if the function handles the display directly).
+        """
+        raise NotImplementedError
```

## skdecide/builders/domain/scheduling/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
```

## skdecide/builders/domain/scheduling/conditional_tasks.py

 * *Ordering differences only*

```diff
@@ -1,184 +1,184 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import random
-from enum import Enum
-from typing import Dict, List, Set, Tuple
-
-from skdecide.core import Distribution
-
-# from skdecide.builders.scheduling.scheduling_domains import State
-
-__all__ = ["WithConditionalTasks", "WithoutConditionalTasks"]
-
-
-class WithConditionalTasks:
-    """A domain must inherit this class if some tasks only need be executed under some conditions
-    and that the condition model can be expressed with Distribution objects."""
-
-    # def __init__(self):
-    #     self._current_conditions = set()
-
-    # def _get_current_conditions(self) -> Set[int]:
-    #     return self._current_conditions
-
-    # def _reset_current_conditions(self):
-    #     self._current_conditions = set()
-
-    def get_all_condition_items(self) -> Enum:
-        """Return an Enum with all the elements that can be used to define a condition.
-
-        Example:
-            return
-                ConditionElementsExample(Enum):
-                    OK = 0
-                    NC_PART_1_OPERATION_1 = 1
-                    NC_PART_1_OPERATION_2 = 2
-                    NC_PART_2_OPERATION_1 = 3
-                    NC_PART_2_OPERATION_2 = 4
-                    HARDWARE_ISSUE_MACHINE_A = 5
-                    HARDWARE_ISSUE_MACHINE_B = 6
-        """
-        return self._get_all_condition_items()
-
-    def _get_all_condition_items(self) -> Enum:
-        raise NotImplementedError
-
-    def get_task_on_completion_added_conditions(self) -> Dict[int, List[Distribution]]:
-        """Return a dict of list. The key of the dict is the task id and each list is composed of a list of tuples.
-        Each tuple contains the probability (first item in tuple) that the conditionElement (second item in tuple)
-        is True. The probabilities in the inner list should sum up to 1. The dictionary should only contains the keys
-        of tasks that can create conditions.
-
-        Example:
-             return
-                {
-                    12:
-                        [
-                        DiscreteDistribution([(ConditionElementsExample.NC_PART_1_OPERATION_1, 0.1), (ConditionElementsExample.OK, 0.9)]),
-                        DiscreteDistribution([(ConditionElementsExample.HARDWARE_ISSUE_MACHINE_A, 0.05), ('paper', 0.1), (ConditionElementsExample.OK, 0.95)])
-                        ]
-                }
-        """
-        return self._get_task_on_completion_added_conditions()
-
-    def _get_task_on_completion_added_conditions(self) -> Dict[int, List[Distribution]]:
-        raise NotImplementedError
-
-    def _sample_completion_conditions(self, task: int) -> List[int]:
-        """Samples the condition distributions associated with the given task and return a list of sampled
-        conditions."""
-        conditions_to_add = []
-        tests = self.get_task_on_completion_added_conditions()[task]
-        for test in tests:
-            conditions_to_add.append(test.sample())
-        return conditions_to_add
-
-    def sample_completion_conditions(self, task: int) -> List[int]:
-        """Samples the condition distributions associated with the given task and return a list of sampled
-        conditions."""
-        return self._sample_completion_conditions(task=task)
-
-    def _get_task_existence_conditions(self) -> Dict[int, List[int]]:
-        """Return a dictionary where the key is a task id and the value a list of conditions to be respected (True)
-        for the task to be part of the schedule. If a task has no entry in the dictionary,
-        there is no conditions for that task.
-
-        Example:
-            return
-                 {
-                    20: [get_all_condition_items().NC_PART_1_OPERATION_1],
-                    21: [get_all_condition_items().HARDWARE_ISSUE_MACHINE_A]
-                    22: [get_all_condition_items().NC_PART_1_OPERATION_1, get_all_condition_items().NC_PART_1_OPERATION_2]
-                 }e
-
-        """
-        raise NotImplementedError
-
-    def get_task_existence_conditions(self) -> Dict[int, List[int]]:
-        """Return a dictionary where the key is a task id and the value a list of conditions to be respected (True)
-        for the task to be part of the schedule. If a task has no entry in the dictionary,
-        there is no conditions for that task.
-
-        Example:
-            return
-                 {
-                    20: [get_all_condition_items().NC_PART_1_OPERATION_1],
-                    21: [get_all_condition_items().HARDWARE_ISSUE_MACHINE_A]
-                    22: [get_all_condition_items().NC_PART_1_OPERATION_1, get_all_condition_items().NC_PART_1_OPERATION_2]
-                 }e
-
-        """
-        return self._get_task_existence_conditions()
-
-    def _add_to_current_conditions(self, task: int, state):
-        """Samples completion conditions for a given task and add these conditions to the list of conditions in the
-        given state. This function should be called when a task complete."""
-        conditions_to_add = self.sample_completion_conditions(task)
-        for x in conditions_to_add:
-            state._current_conditions.add(x)
-
-    def add_to_current_conditions(self, task: int, state):
-        """Samples completion conditions for a given task and add these conditions to the list of conditions in the
-        given state. This function should be called when a task complete."""
-        return self._add_to_current_conditions(task=task, state=state)
-
-    def _get_available_tasks(self, state) -> Set[int]:
-        """Returns the set of all task ids that can be considered under the conditions defined in the given state.
-        Note that the set will contains all ids for all tasks in the domain that meet the conditions, that is tasks
-        that are remaining, or that have been completed, paused or started / resumed."""
-        all_ids = self.get_tasks_ids()
-        available_ids = set()
-        # [for id in all_ids if id not in self.get_task_existence_conditions().keys() and ]
-        for id in all_ids:
-            if id not in self.get_task_existence_conditions().keys():
-                available_ids.add(id)
-            else:
-                test = True
-                for cond in self.get_task_existence_conditions()[id]:
-                    if cond not in state._current_conditions:
-                        test = False
-                if test:
-                    available_ids.add(id)
-        return available_ids
-
-    def get_available_tasks(self, state) -> Set[int]:
-        """Returns the set of all task ids that can be considered under the conditions defined in the given state.
-        Note that the set will contains all ids for all tasks in the domain that meet the conditions, that is tasks
-        that are remaining, or that have been completed, paused or started / resumed."""
-        return self._get_available_tasks(state=state)
-
-    def _get_all_unconditional_tasks(self) -> Set[int]:
-        """Returns the set of all task ids for which there are no conditions. These tasks are to be considered at
-        the start of a project (i.e. in the initial state)."""
-        all_ids = self.get_tasks_ids()
-        available_ids = set()
-        for id in all_ids:
-            if (id not in self.get_task_existence_conditions().keys()) or (
-                len(self.get_task_existence_conditions()[id]) == 0
-            ):
-                available_ids.add(id)
-        return available_ids
-
-    def get_all_unconditional_tasks(self) -> Set[int]:
-        """Returns the set of all task ids for which there are no conditions. These tasks are to be considered at
-        the start of a project (i.e. in the initial state)."""
-        return self._get_all_unconditional_tasks()
-
-
-class WithoutConditionalTasks(WithConditionalTasks):
-    """A domain must inherit this class if all tasks need be executed without conditions."""
-
-    def _get_all_condition_items(self) -> Enum:
-        return None
-
-    def _get_task_on_completion_added_conditions(
-        self,
-    ) -> Dict[int, List[List[Tuple[float, int]]]]:
-        return {}
-
-    def _get_task_existence_conditions(self) -> Dict[int, List[int]]:
-        return {}
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import random
+from enum import Enum
+from typing import Dict, List, Set, Tuple
+
+from skdecide.core import Distribution
+
+# from skdecide.builders.scheduling.scheduling_domains import State
+
+__all__ = ["WithConditionalTasks", "WithoutConditionalTasks"]
+
+
+class WithConditionalTasks:
+    """A domain must inherit this class if some tasks only need be executed under some conditions
+    and that the condition model can be expressed with Distribution objects."""
+
+    # def __init__(self):
+    #     self._current_conditions = set()
+
+    # def _get_current_conditions(self) -> Set[int]:
+    #     return self._current_conditions
+
+    # def _reset_current_conditions(self):
+    #     self._current_conditions = set()
+
+    def get_all_condition_items(self) -> Enum:
+        """Return an Enum with all the elements that can be used to define a condition.
+
+        Example:
+            return
+                ConditionElementsExample(Enum):
+                    OK = 0
+                    NC_PART_1_OPERATION_1 = 1
+                    NC_PART_1_OPERATION_2 = 2
+                    NC_PART_2_OPERATION_1 = 3
+                    NC_PART_2_OPERATION_2 = 4
+                    HARDWARE_ISSUE_MACHINE_A = 5
+                    HARDWARE_ISSUE_MACHINE_B = 6
+        """
+        return self._get_all_condition_items()
+
+    def _get_all_condition_items(self) -> Enum:
+        raise NotImplementedError
+
+    def get_task_on_completion_added_conditions(self) -> Dict[int, List[Distribution]]:
+        """Return a dict of list. The key of the dict is the task id and each list is composed of a list of tuples.
+        Each tuple contains the probability (first item in tuple) that the conditionElement (second item in tuple)
+        is True. The probabilities in the inner list should sum up to 1. The dictionary should only contains the keys
+        of tasks that can create conditions.
+
+        Example:
+             return
+                {
+                    12:
+                        [
+                        DiscreteDistribution([(ConditionElementsExample.NC_PART_1_OPERATION_1, 0.1), (ConditionElementsExample.OK, 0.9)]),
+                        DiscreteDistribution([(ConditionElementsExample.HARDWARE_ISSUE_MACHINE_A, 0.05), ('paper', 0.1), (ConditionElementsExample.OK, 0.95)])
+                        ]
+                }
+        """
+        return self._get_task_on_completion_added_conditions()
+
+    def _get_task_on_completion_added_conditions(self) -> Dict[int, List[Distribution]]:
+        raise NotImplementedError
+
+    def _sample_completion_conditions(self, task: int) -> List[int]:
+        """Samples the condition distributions associated with the given task and return a list of sampled
+        conditions."""
+        conditions_to_add = []
+        tests = self.get_task_on_completion_added_conditions()[task]
+        for test in tests:
+            conditions_to_add.append(test.sample())
+        return conditions_to_add
+
+    def sample_completion_conditions(self, task: int) -> List[int]:
+        """Samples the condition distributions associated with the given task and return a list of sampled
+        conditions."""
+        return self._sample_completion_conditions(task=task)
+
+    def _get_task_existence_conditions(self) -> Dict[int, List[int]]:
+        """Return a dictionary where the key is a task id and the value a list of conditions to be respected (True)
+        for the task to be part of the schedule. If a task has no entry in the dictionary,
+        there is no conditions for that task.
+
+        Example:
+            return
+                 {
+                    20: [get_all_condition_items().NC_PART_1_OPERATION_1],
+                    21: [get_all_condition_items().HARDWARE_ISSUE_MACHINE_A]
+                    22: [get_all_condition_items().NC_PART_1_OPERATION_1, get_all_condition_items().NC_PART_1_OPERATION_2]
+                 }e
+
+        """
+        raise NotImplementedError
+
+    def get_task_existence_conditions(self) -> Dict[int, List[int]]:
+        """Return a dictionary where the key is a task id and the value a list of conditions to be respected (True)
+        for the task to be part of the schedule. If a task has no entry in the dictionary,
+        there is no conditions for that task.
+
+        Example:
+            return
+                 {
+                    20: [get_all_condition_items().NC_PART_1_OPERATION_1],
+                    21: [get_all_condition_items().HARDWARE_ISSUE_MACHINE_A]
+                    22: [get_all_condition_items().NC_PART_1_OPERATION_1, get_all_condition_items().NC_PART_1_OPERATION_2]
+                 }e
+
+        """
+        return self._get_task_existence_conditions()
+
+    def _add_to_current_conditions(self, task: int, state):
+        """Samples completion conditions for a given task and add these conditions to the list of conditions in the
+        given state. This function should be called when a task complete."""
+        conditions_to_add = self.sample_completion_conditions(task)
+        for x in conditions_to_add:
+            state._current_conditions.add(x)
+
+    def add_to_current_conditions(self, task: int, state):
+        """Samples completion conditions for a given task and add these conditions to the list of conditions in the
+        given state. This function should be called when a task complete."""
+        return self._add_to_current_conditions(task=task, state=state)
+
+    def _get_available_tasks(self, state) -> Set[int]:
+        """Returns the set of all task ids that can be considered under the conditions defined in the given state.
+        Note that the set will contains all ids for all tasks in the domain that meet the conditions, that is tasks
+        that are remaining, or that have been completed, paused or started / resumed."""
+        all_ids = self.get_tasks_ids()
+        available_ids = set()
+        # [for id in all_ids if id not in self.get_task_existence_conditions().keys() and ]
+        for id in all_ids:
+            if id not in self.get_task_existence_conditions().keys():
+                available_ids.add(id)
+            else:
+                test = True
+                for cond in self.get_task_existence_conditions()[id]:
+                    if cond not in state._current_conditions:
+                        test = False
+                if test:
+                    available_ids.add(id)
+        return available_ids
+
+    def get_available_tasks(self, state) -> Set[int]:
+        """Returns the set of all task ids that can be considered under the conditions defined in the given state.
+        Note that the set will contains all ids for all tasks in the domain that meet the conditions, that is tasks
+        that are remaining, or that have been completed, paused or started / resumed."""
+        return self._get_available_tasks(state=state)
+
+    def _get_all_unconditional_tasks(self) -> Set[int]:
+        """Returns the set of all task ids for which there are no conditions. These tasks are to be considered at
+        the start of a project (i.e. in the initial state)."""
+        all_ids = self.get_tasks_ids()
+        available_ids = set()
+        for id in all_ids:
+            if (id not in self.get_task_existence_conditions().keys()) or (
+                len(self.get_task_existence_conditions()[id]) == 0
+            ):
+                available_ids.add(id)
+        return available_ids
+
+    def get_all_unconditional_tasks(self) -> Set[int]:
+        """Returns the set of all task ids for which there are no conditions. These tasks are to be considered at
+        the start of a project (i.e. in the initial state)."""
+        return self._get_all_unconditional_tasks()
+
+
+class WithoutConditionalTasks(WithConditionalTasks):
+    """A domain must inherit this class if all tasks need be executed without conditions."""
+
+    def _get_all_condition_items(self) -> Enum:
+        return None
+
+    def _get_task_on_completion_added_conditions(
+        self,
+    ) -> Dict[int, List[List[Tuple[float, int]]]]:
+        return {}
+
+    def _get_task_existence_conditions(self) -> Dict[int, List[int]]:
+        return {}
```

## skdecide/builders/domain/scheduling/graph_toolbox.py

 * *Ordering differences only*

```diff
@@ -1,117 +1,117 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Dict, Hashable, List, Tuple
-
-import networkx as nx
-
-
-class Graph:
-    def __init__(
-        self,
-        nodes: List[Tuple[Hashable, Dict[str, Any]]],
-        edges: List[Tuple[Hashable, Hashable, Dict[str, Any]]],
-        undirected=True,
-    ):
-        self.nodes = nodes
-        self.edges = edges
-        self.undirected = undirected
-        self.neighbors_dict = {}
-        self.predecessors_dict = {}
-        self.edges_infos_dict = {}
-        self.nodes_infos_dict = {}
-        self.build_nodes_infos_dict()
-        self.build_edges()
-        self.nodes_name = sorted(self.nodes_infos_dict)
-        self.graph_nx = self.to_networkx()
-
-    def get_edges(self):
-        return self.edges_infos_dict.keys()
-
-    def get_nodes(self):
-        return self.nodes_name
-
-    def build_nodes_infos_dict(self):
-        for n, d in self.nodes:
-            self.nodes_infos_dict[n] = d
-
-    def build_edges(self):
-        for n1, n2, d in self.edges:
-            self.edges_infos_dict[(n1, n2)] = d
-            if n2 not in self.predecessors_dict:
-                self.predecessors_dict[n2] = set()
-            if n1 not in self.neighbors_dict:
-                self.neighbors_dict[n1] = set()
-            self.predecessors_dict[n2].add(n1)
-            self.neighbors_dict[n1].add(n2)
-            if self.undirected:
-                if n1 not in self.predecessors_dict:
-                    self.predecessors_dict[n1] = set()
-                if n2 not in self.neighbors_dict:
-                    self.neighbors_dict[n2] = set()
-                self.predecessors_dict[n1].add(n2)
-                self.neighbors_dict[n2].add(n1)
-                self.edges_infos_dict[(n2, n1)] = d
-
-    def get_neighbors(self, node):
-        return self.neighbors_dict.get(node, [])
-
-    def get_predecessors(self, node):
-        return self.predecessors_dict.get(node, [])
-
-    def get_attr_node(self, node, attr):
-        return self.nodes_infos_dict.get(node, {}).get(attr, None)
-
-    def get_attr_edge(self, node1, node2, attr):
-        return self.edges_infos_dict.get((node1, node2), {}).get(attr, None)
-
-    def to_networkx(self):
-        graph_nx = nx.DiGraph() if not self.undirected else nx.Graph()
-        graph_nx.add_nodes_from(self.nodes)
-        graph_nx.add_edges_from(self.edges)
-        return graph_nx
-
-    def check_loop(self):
-        try:
-            cycles = nx.find_cycle(self.graph_nx, orientation="original")
-        except:
-            cycles = None
-        return cycles
-
-    def precedessors_nodes(self, n):
-        return nx.algorithms.ancestors(self.graph_nx, n)
-
-    def ancestors_map(self):
-        return {
-            n: nx.algorithms.ancestors(self.graph_nx, n) for n in self.graph_nx.nodes()
-        }
-
-    def descendants_map(self):
-        return {
-            n: nx.algorithms.descendants(self.graph_nx, n)
-            for n in self.graph_nx.nodes()
-        }
-
-    def successors_map(self):
-        return {n: list(nx.neighbors(self.graph_nx, n)) for n in self.graph_nx.nodes()}
-
-    def predecessors_map(self):
-        return {n: list(self.graph_nx.predecessors(n)) for n in self.graph_nx.nodes()}
-
-
-if __name__ == "__main__":
-    nodes = [(0, {"name": 0}), (1, {"name": 1})]
-    edges = [(0, 1, {"weight": 1.1}), (1, 0, {"weight": 2})]
-    graph = Graph(nodes, edges, False)
-    graph_nx = graph.to_networkx()
-    print(graph.get_attr_edge(0, 1, "weight"))
-    print(graph.get_attr_edge(1, 0, "weight"))
-    print(graph.get_attr_edge(0, 0, "weight"))  # None
-
-    print(graph_nx.size())
-    print(nx.number_of_nodes(graph_nx), nx.number_of_edges(graph_nx))
-    print(graph_nx[0][1]["weight"])
-    print(graph_nx[1][0]["weight"])
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Dict, Hashable, List, Tuple
+
+import networkx as nx
+
+
+class Graph:
+    def __init__(
+        self,
+        nodes: List[Tuple[Hashable, Dict[str, Any]]],
+        edges: List[Tuple[Hashable, Hashable, Dict[str, Any]]],
+        undirected=True,
+    ):
+        self.nodes = nodes
+        self.edges = edges
+        self.undirected = undirected
+        self.neighbors_dict = {}
+        self.predecessors_dict = {}
+        self.edges_infos_dict = {}
+        self.nodes_infos_dict = {}
+        self.build_nodes_infos_dict()
+        self.build_edges()
+        self.nodes_name = sorted(self.nodes_infos_dict)
+        self.graph_nx = self.to_networkx()
+
+    def get_edges(self):
+        return self.edges_infos_dict.keys()
+
+    def get_nodes(self):
+        return self.nodes_name
+
+    def build_nodes_infos_dict(self):
+        for n, d in self.nodes:
+            self.nodes_infos_dict[n] = d
+
+    def build_edges(self):
+        for n1, n2, d in self.edges:
+            self.edges_infos_dict[(n1, n2)] = d
+            if n2 not in self.predecessors_dict:
+                self.predecessors_dict[n2] = set()
+            if n1 not in self.neighbors_dict:
+                self.neighbors_dict[n1] = set()
+            self.predecessors_dict[n2].add(n1)
+            self.neighbors_dict[n1].add(n2)
+            if self.undirected:
+                if n1 not in self.predecessors_dict:
+                    self.predecessors_dict[n1] = set()
+                if n2 not in self.neighbors_dict:
+                    self.neighbors_dict[n2] = set()
+                self.predecessors_dict[n1].add(n2)
+                self.neighbors_dict[n2].add(n1)
+                self.edges_infos_dict[(n2, n1)] = d
+
+    def get_neighbors(self, node):
+        return self.neighbors_dict.get(node, [])
+
+    def get_predecessors(self, node):
+        return self.predecessors_dict.get(node, [])
+
+    def get_attr_node(self, node, attr):
+        return self.nodes_infos_dict.get(node, {}).get(attr, None)
+
+    def get_attr_edge(self, node1, node2, attr):
+        return self.edges_infos_dict.get((node1, node2), {}).get(attr, None)
+
+    def to_networkx(self):
+        graph_nx = nx.DiGraph() if not self.undirected else nx.Graph()
+        graph_nx.add_nodes_from(self.nodes)
+        graph_nx.add_edges_from(self.edges)
+        return graph_nx
+
+    def check_loop(self):
+        try:
+            cycles = nx.find_cycle(self.graph_nx, orientation="original")
+        except:
+            cycles = None
+        return cycles
+
+    def precedessors_nodes(self, n):
+        return nx.algorithms.ancestors(self.graph_nx, n)
+
+    def ancestors_map(self):
+        return {
+            n: nx.algorithms.ancestors(self.graph_nx, n) for n in self.graph_nx.nodes()
+        }
+
+    def descendants_map(self):
+        return {
+            n: nx.algorithms.descendants(self.graph_nx, n)
+            for n in self.graph_nx.nodes()
+        }
+
+    def successors_map(self):
+        return {n: list(nx.neighbors(self.graph_nx, n)) for n in self.graph_nx.nodes()}
+
+    def predecessors_map(self):
+        return {n: list(self.graph_nx.predecessors(n)) for n in self.graph_nx.nodes()}
+
+
+if __name__ == "__main__":
+    nodes = [(0, {"name": 0}), (1, {"name": 1})]
+    edges = [(0, 1, {"weight": 1.1}), (1, 0, {"weight": 2})]
+    graph = Graph(nodes, edges, False)
+    graph_nx = graph.to_networkx()
+    print(graph.get_attr_edge(0, 1, "weight"))
+    print(graph.get_attr_edge(1, 0, "weight"))
+    print(graph.get_attr_edge(0, 0, "weight"))  # None
+
+    print(graph_nx.size())
+    print(nx.number_of_nodes(graph_nx), nx.number_of_edges(graph_nx))
+    print(graph_nx[0][1]["weight"])
+    print(graph_nx[1][0]["weight"])
```

## skdecide/builders/domain/scheduling/modes.py

 * *Ordering differences only*

```diff
@@ -1,186 +1,186 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Dict, List, Set, Union
-
-__all__ = ["MultiMode", "SingleMode"]
-
-
-class ModeConsumption:
-    def _get_resource_need_at_time(self, resource_name: str, time: int):
-        """Return the resource consumption for the given resource at the given time.
-        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
-        raise NotImplementedError
-
-    def _get_non_zero_ressource_need_names(self, time: int):
-        raise NotImplementedError
-
-    def _get_ressource_names(self):
-        raise NotImplementedError
-
-    def get_resource_need_at_time(self, resource_name: str, time: int):
-        """Return the resource consumption for the given resource at the given time.
-        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
-        return self._get_resource_need_at_time(resource_name=resource_name, time=time)
-
-    def get_non_zero_ressource_need_names(self, time: int):
-        return self._get_non_zero_ressource_need_names(time=time)
-
-    def get_ressource_names(self):
-        return self._get_ressource_names()
-
-
-class VaryingModeConsumption(ModeConsumption):
-    """Defines the most generic type of mode."""
-
-    def __init__(self, mode_dict: Dict[str, List[int]]):
-        self.mode_details = mode_dict
-
-    def _get_resource_need_at_time(self, resource_name: str, time: int):
-        """Return the resource consumption for the given resource at the given time.
-        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
-        if resource_name in self.mode_details:
-            return self.mode_details[resource_name][time]
-        else:
-            return 0
-
-    def _get_non_zero_ressource_need_names(self, time: int = 0):
-        return [
-            r for r in self.mode_details if self.get_resource_need_at_time(r, time) > 0
-        ]
-
-    def _get_ressource_names(self):
-        return self.mode_details.keys()
-
-
-class ConstantModeConsumption(VaryingModeConsumption):
-    """Defines a mode where the resource consumption is constant throughout
-    the duration of the task."""
-
-    def __init__(self, mode_dict: Dict[str, int]):
-        self.mode_details = {}
-        for key in mode_dict.keys():
-            # TODO i challenge this to be usefull?
-            self.mode_details[key] = [mode_dict[key]]
-
-    def get_resource_need(self, resource_name: str):
-        """Return the resource consumption for the given resource."""
-        return self._get_resource_need(resource_name=resource_name)
-
-    def _get_resource_need(self, resource_name: str):
-        """Return the resource consumption for the given resource."""
-        return self.mode_details.get(resource_name, [0])[0]
-
-    def _get_resource_need_at_time(self, resource_name: str, time: int):
-        """Return the resource consumption for the given resource at the given time.
-        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
-        return self._get_resource_need(resource_name=resource_name)
-
-
-class MultiMode:
-    """A domain must inherit this class if tasks can be done in 1 or more modes."""
-
-    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        """Return a set or dict of int = id of tasks"""
-        raise NotImplementedError
-
-    def get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        return self._get_tasks_ids()
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        """Return a nested dictionary where the first key is a task id and the second key is a mode id.
-         The value is a Mode object defining the resource consumption.
-        If the domain is an instance of VariableResourceConsumption, VaryingModeConsumption objects should be used.
-        If this is not the case (i.e. the domain is an instance of ConstantResourceConsumption),
-        then ConstantModeConsumption should be used.
-
-        E.g. with constant resource consumption
-            {
-                12: {
-                        1: ConstantModeConsumption({'rt_1': 2, 'rt_2': 0, 'ru_1': 1}),
-                        2: ConstantModeConsumption({'rt_1': 0, 'rt_2': 3, 'ru_1': 1}),
-                    }
-            }
-
-        E.g. with time varying resource consumption
-            {
-            12: {
-                1: VaryingModeConsumption({'rt_1': [2,2,2,2,3], 'rt_2': [0,0,0,0,0], 'ru_1': [1,1,1,1,1]}),
-                2: VaryingModeConsumption({'rt_1': [1,1,1,1,2,2,2], 'rt_2': [0,0,0,0,0,0,0], 'ru_1': [1,1,1,1,1,1,1]}),
-                }
-            }
-        """
-        raise NotImplementedError
-
-    def get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        return self._get_tasks_modes()
-
-    def _get_ressource_names_for_task_mode(self, task: int, mode: int):
-        return self.get_tasks_modes()[task][mode].get_ressource_names()
-
-    def get_ressource_names_for_task_mode(self, task: int, mode: int):
-        return self._get_ressource_names_for_task_mode(task=task, mode=mode)
-
-    def _get_task_modes(self, task_id: int):
-        return self.get_tasks_modes()[task_id]
-
-    def get_task_modes(self, task_id: int):
-        return self._get_task_modes(task_id=task_id)
-
-    def _get_task_consumption(
-        self, task: int, mode: int, resource_name: str, time: int
-    ):
-        return self.get_task_modes(task)[mode].get_resource_need_at_time(
-            resource_name=resource_name, time=time
-        )
-
-    def get_task_consumption(self, task: int, mode: int, resource_name: str, time: int):
-        return self._get_task_consumption(
-            task=task, mode=mode, resource_name=resource_name, time=time
-        )
-
-
-class SingleMode(MultiMode):
-    """A domain must inherit this class if ALL tasks only have 1 possible execution mode."""
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        """Return a nested dictionary where the first key is a task id and the second key is a mode id.
-        The value is a Mode object defining the resource consumption."""
-        modes = {}
-        tmp_dict = self.get_tasks_mode()
-        for key in tmp_dict:
-            modes[key] = {}
-            modes[key][1] = tmp_dict[key]
-        return modes
-
-    def _get_tasks_mode(self) -> Dict[int, ModeConsumption]:
-        """Return a dictionary where the key is a task id and the value is a ModeConsumption object defining
-        the resource consumption.
-        If the domain is an instance of VariableResourceConsumption, VaryingModeConsumption objects should be used.
-        If this is not the case (i.e. the domain is an instance of ConstantResourceConsumption),
-        then ConstantModeConsumption should be used.
-
-        E.g. with constant resource consumption
-            {
-                12: ConstantModeConsumption({'rt_1': 2, 'rt_2': 0, 'ru_1': 1})
-            }
-
-        E.g. with time varying resource consumption
-            {
-                12: VaryingModeConsumption({'rt_1': [2,2,2,2,3], 'rt_2': [0,0,0,0,0], 'ru_1': [1,1,1,1,1]})
-            }
-        """
-
-        # TODO: Check if the test below is correct and should be placed here
-        # if issubclass(type(self), VariableResourceConsumption) and\
-        #         (not issubclass(type(self), DeterministicTaskDuration)):
-        #     raise NotImplementedError('Use of varying resource consumption and non0-deterministic task durations '
-        #                               'not supported yet')
-
-        raise NotImplementedError
-
-    def get_tasks_mode(self) -> Dict[int, ModeConsumption]:
-        return self._get_tasks_mode()
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Dict, List, Set, Union
+
+__all__ = ["MultiMode", "SingleMode"]
+
+
+class ModeConsumption:
+    def _get_resource_need_at_time(self, resource_name: str, time: int):
+        """Return the resource consumption for the given resource at the given time.
+        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
+        raise NotImplementedError
+
+    def _get_non_zero_ressource_need_names(self, time: int):
+        raise NotImplementedError
+
+    def _get_ressource_names(self):
+        raise NotImplementedError
+
+    def get_resource_need_at_time(self, resource_name: str, time: int):
+        """Return the resource consumption for the given resource at the given time.
+        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
+        return self._get_resource_need_at_time(resource_name=resource_name, time=time)
+
+    def get_non_zero_ressource_need_names(self, time: int):
+        return self._get_non_zero_ressource_need_names(time=time)
+
+    def get_ressource_names(self):
+        return self._get_ressource_names()
+
+
+class VaryingModeConsumption(ModeConsumption):
+    """Defines the most generic type of mode."""
+
+    def __init__(self, mode_dict: Dict[str, List[int]]):
+        self.mode_details = mode_dict
+
+    def _get_resource_need_at_time(self, resource_name: str, time: int):
+        """Return the resource consumption for the given resource at the given time.
+        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
+        if resource_name in self.mode_details:
+            return self.mode_details[resource_name][time]
+        else:
+            return 0
+
+    def _get_non_zero_ressource_need_names(self, time: int = 0):
+        return [
+            r for r in self.mode_details if self.get_resource_need_at_time(r, time) > 0
+        ]
+
+    def _get_ressource_names(self):
+        return self.mode_details.keys()
+
+
+class ConstantModeConsumption(VaryingModeConsumption):
+    """Defines a mode where the resource consumption is constant throughout
+    the duration of the task."""
+
+    def __init__(self, mode_dict: Dict[str, int]):
+        self.mode_details = {}
+        for key in mode_dict.keys():
+            # TODO i challenge this to be usefull?
+            self.mode_details[key] = [mode_dict[key]]
+
+    def get_resource_need(self, resource_name: str):
+        """Return the resource consumption for the given resource."""
+        return self._get_resource_need(resource_name=resource_name)
+
+    def _get_resource_need(self, resource_name: str):
+        """Return the resource consumption for the given resource."""
+        return self.mode_details.get(resource_name, [0])[0]
+
+    def _get_resource_need_at_time(self, resource_name: str, time: int):
+        """Return the resource consumption for the given resource at the given time.
+        Note that the time should be the time from the start of the execution of the task (starting from 0)."""
+        return self._get_resource_need(resource_name=resource_name)
+
+
+class MultiMode:
+    """A domain must inherit this class if tasks can be done in 1 or more modes."""
+
+    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        """Return a set or dict of int = id of tasks"""
+        raise NotImplementedError
+
+    def get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        return self._get_tasks_ids()
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        """Return a nested dictionary where the first key is a task id and the second key is a mode id.
+         The value is a Mode object defining the resource consumption.
+        If the domain is an instance of VariableResourceConsumption, VaryingModeConsumption objects should be used.
+        If this is not the case (i.e. the domain is an instance of ConstantResourceConsumption),
+        then ConstantModeConsumption should be used.
+
+        E.g. with constant resource consumption
+            {
+                12: {
+                        1: ConstantModeConsumption({'rt_1': 2, 'rt_2': 0, 'ru_1': 1}),
+                        2: ConstantModeConsumption({'rt_1': 0, 'rt_2': 3, 'ru_1': 1}),
+                    }
+            }
+
+        E.g. with time varying resource consumption
+            {
+            12: {
+                1: VaryingModeConsumption({'rt_1': [2,2,2,2,3], 'rt_2': [0,0,0,0,0], 'ru_1': [1,1,1,1,1]}),
+                2: VaryingModeConsumption({'rt_1': [1,1,1,1,2,2,2], 'rt_2': [0,0,0,0,0,0,0], 'ru_1': [1,1,1,1,1,1,1]}),
+                }
+            }
+        """
+        raise NotImplementedError
+
+    def get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        return self._get_tasks_modes()
+
+    def _get_ressource_names_for_task_mode(self, task: int, mode: int):
+        return self.get_tasks_modes()[task][mode].get_ressource_names()
+
+    def get_ressource_names_for_task_mode(self, task: int, mode: int):
+        return self._get_ressource_names_for_task_mode(task=task, mode=mode)
+
+    def _get_task_modes(self, task_id: int):
+        return self.get_tasks_modes()[task_id]
+
+    def get_task_modes(self, task_id: int):
+        return self._get_task_modes(task_id=task_id)
+
+    def _get_task_consumption(
+        self, task: int, mode: int, resource_name: str, time: int
+    ):
+        return self.get_task_modes(task)[mode].get_resource_need_at_time(
+            resource_name=resource_name, time=time
+        )
+
+    def get_task_consumption(self, task: int, mode: int, resource_name: str, time: int):
+        return self._get_task_consumption(
+            task=task, mode=mode, resource_name=resource_name, time=time
+        )
+
+
+class SingleMode(MultiMode):
+    """A domain must inherit this class if ALL tasks only have 1 possible execution mode."""
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        """Return a nested dictionary where the first key is a task id and the second key is a mode id.
+        The value is a Mode object defining the resource consumption."""
+        modes = {}
+        tmp_dict = self.get_tasks_mode()
+        for key in tmp_dict:
+            modes[key] = {}
+            modes[key][1] = tmp_dict[key]
+        return modes
+
+    def _get_tasks_mode(self) -> Dict[int, ModeConsumption]:
+        """Return a dictionary where the key is a task id and the value is a ModeConsumption object defining
+        the resource consumption.
+        If the domain is an instance of VariableResourceConsumption, VaryingModeConsumption objects should be used.
+        If this is not the case (i.e. the domain is an instance of ConstantResourceConsumption),
+        then ConstantModeConsumption should be used.
+
+        E.g. with constant resource consumption
+            {
+                12: ConstantModeConsumption({'rt_1': 2, 'rt_2': 0, 'ru_1': 1})
+            }
+
+        E.g. with time varying resource consumption
+            {
+                12: VaryingModeConsumption({'rt_1': [2,2,2,2,3], 'rt_2': [0,0,0,0,0], 'ru_1': [1,1,1,1,1]})
+            }
+        """
+
+        # TODO: Check if the test below is correct and should be placed here
+        # if issubclass(type(self), VariableResourceConsumption) and\
+        #         (not issubclass(type(self), DeterministicTaskDuration)):
+        #     raise NotImplementedError('Use of varying resource consumption and non0-deterministic task durations '
+        #                               'not supported yet')
+
+        raise NotImplementedError
+
+    def get_tasks_mode(self) -> Dict[int, ModeConsumption]:
+        return self._get_tasks_mode()
```

## skdecide/builders/domain/scheduling/preallocations.py

 * *Ordering differences only*

```diff
@@ -1,36 +1,36 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict, List
-
-__all__ = ["WithPreallocations", "WithoutPreallocations"]
-
-
-class WithPreallocations:
-    """A domain must inherit this class if there are some pre-allocations to consider."""
-
-    def _get_preallocations(
-        self,
-    ) -> Dict[int, List[str]]:  # TODO: To be handled by domain (applicable actions)
-        """
-        Return a dictionary where the key is the id of a task (int)
-        and the value indicates the pre-allocated resources for this task (as a list of str)"""
-        raise NotImplementedError
-
-    def get_preallocations(
-        self,
-    ) -> Dict[int, List[str]]:  # TODO: To be handled by domain (applicable actions)
-        """
-        Return a dictionary where the key is the id of a task (int)
-        and the value indicates the pre-allocated resources for this task (as a list of str)"""
-        return self._get_preallocations()
-
-
-class WithoutPreallocations(WithPreallocations):
-    """A domain must inherit this class if there are no pre-allocations to consider."""
-
-    def _get_preallocations(self) -> Dict[int, List[str]]:
-        return {}
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict, List
+
+__all__ = ["WithPreallocations", "WithoutPreallocations"]
+
+
+class WithPreallocations:
+    """A domain must inherit this class if there are some pre-allocations to consider."""
+
+    def _get_preallocations(
+        self,
+    ) -> Dict[int, List[str]]:  # TODO: To be handled by domain (applicable actions)
+        """
+        Return a dictionary where the key is the id of a task (int)
+        and the value indicates the pre-allocated resources for this task (as a list of str)"""
+        raise NotImplementedError
+
+    def get_preallocations(
+        self,
+    ) -> Dict[int, List[str]]:  # TODO: To be handled by domain (applicable actions)
+        """
+        Return a dictionary where the key is the id of a task (int)
+        and the value indicates the pre-allocated resources for this task (as a list of str)"""
+        return self._get_preallocations()
+
+
+class WithoutPreallocations(WithPreallocations):
+    """A domain must inherit this class if there are no pre-allocations to consider."""
+
+    def _get_preallocations(self) -> Dict[int, List[str]]:
+        return {}
```

## skdecide/builders/domain/scheduling/precedence.py

 * *Ordering differences only*

```diff
@@ -1,106 +1,106 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict, List
-
-from skdecide.builders.domain.scheduling.graph_toolbox import Graph
-from skdecide.builders.domain.scheduling.scheduling_domains_modelling import State
-
-__all__ = ["WithPrecedence", "WithoutPrecedence"]
-
-
-class WithPrecedence:
-    """A domain must inherit this class if there exist some predecence constraints between tasks."""
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
-        raise NotImplementedError
-
-    def get_successors(self) -> Dict[int, List[int]]:
-        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
-        return self._get_successors()
-
-    def _get_successors_task(self, task_id: int) -> List[int]:
-        return self.get_successors()[task_id]
-
-    def get_successors_task(self, task_id: int) -> List[int]:
-        return self._get_successors_task(task_id=task_id)
-
-    def _get_predecessors(self) -> Dict[int, List[int]]:
-        """Return the predecessors of the task. Successors are given as a list for a task given as a key."""
-        return self.graph.predecessors_map()
-
-    def get_predecessors(self) -> Dict[int, List[int]]:
-        """Return the predecessors of the task. Successors are given as a list for a task given as a key."""
-        return self._get_predecessors()
-
-    def _get_predecessors_task(self, task_id: int) -> List[int]:
-        return self.get_predecessors()[task_id]
-
-    def get_predecessors_task(self, task_id: int) -> List[int]:
-        return self._get_predecessors_task(task_id=task_id)
-
-    def compute_graph(self):
-        task_ids = self.get_tasks_ids()
-        successors = self.get_successors()
-        mode_details = self.get_tasks_modes()
-        nodes = [
-            (
-                n,
-                {
-                    mode: self.sample_task_duration(task=n, mode=mode)
-                    for mode in mode_details[n]
-                },
-            )
-            for n in task_ids
-        ]
-        edges = []
-        for n in successors:
-            for succ in successors[n]:
-                edges += [(n, succ, {})]
-        return Graph(nodes, edges, False)
-
-    def _task_modes_possible_to_launch(self, state: State):
-        mode_details = self.get_tasks_modes()
-        return [
-            (n, mode)
-            for n in state.tasks_remaining
-            for mode in mode_details[n]
-            if all(m in state.tasks_complete for m in self.ancestors[n])
-        ]
-
-    def task_modes_possible_to_launch(self, state: State):
-        return self._task_modes_possible_to_launch(state=state)
-
-    def _task_possible_to_launch_precedence(self, state: State):
-        return [
-            n
-            for n in state.tasks_remaining
-            if all(m in state.tasks_complete for m in self.ancestors[n])
-        ]
-
-    def task_possible_to_launch_precedence(self, state: State):
-        return self._task_possible_to_launch_precedence(state=state)
-
-
-class WithoutPrecedence(WithPrecedence):
-    """A domain must inherit this class if there are no predecence constraints between tasks."""
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
-        ids = self.get_tasks_ids()
-        succ = {}
-        for id in ids:
-            succ[id] = []
-        return succ
-
-    def _get_predecessors(self) -> Dict[int, List[int]]:
-        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
-        ids = self.get_tasks_ids()
-        prec = {}
-        for id in ids:
-            prec[id] = []
-        return prec
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict, List
+
+from skdecide.builders.domain.scheduling.graph_toolbox import Graph
+from skdecide.builders.domain.scheduling.scheduling_domains_modelling import State
+
+__all__ = ["WithPrecedence", "WithoutPrecedence"]
+
+
+class WithPrecedence:
+    """A domain must inherit this class if there exist some predecence constraints between tasks."""
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
+        raise NotImplementedError
+
+    def get_successors(self) -> Dict[int, List[int]]:
+        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
+        return self._get_successors()
+
+    def _get_successors_task(self, task_id: int) -> List[int]:
+        return self.get_successors()[task_id]
+
+    def get_successors_task(self, task_id: int) -> List[int]:
+        return self._get_successors_task(task_id=task_id)
+
+    def _get_predecessors(self) -> Dict[int, List[int]]:
+        """Return the predecessors of the task. Successors are given as a list for a task given as a key."""
+        return self.graph.predecessors_map()
+
+    def get_predecessors(self) -> Dict[int, List[int]]:
+        """Return the predecessors of the task. Successors are given as a list for a task given as a key."""
+        return self._get_predecessors()
+
+    def _get_predecessors_task(self, task_id: int) -> List[int]:
+        return self.get_predecessors()[task_id]
+
+    def get_predecessors_task(self, task_id: int) -> List[int]:
+        return self._get_predecessors_task(task_id=task_id)
+
+    def compute_graph(self):
+        task_ids = self.get_tasks_ids()
+        successors = self.get_successors()
+        mode_details = self.get_tasks_modes()
+        nodes = [
+            (
+                n,
+                {
+                    mode: self.sample_task_duration(task=n, mode=mode)
+                    for mode in mode_details[n]
+                },
+            )
+            for n in task_ids
+        ]
+        edges = []
+        for n in successors:
+            for succ in successors[n]:
+                edges += [(n, succ, {})]
+        return Graph(nodes, edges, False)
+
+    def _task_modes_possible_to_launch(self, state: State):
+        mode_details = self.get_tasks_modes()
+        return [
+            (n, mode)
+            for n in state.tasks_remaining
+            for mode in mode_details[n]
+            if all(m in state.tasks_complete for m in self.ancestors[n])
+        ]
+
+    def task_modes_possible_to_launch(self, state: State):
+        return self._task_modes_possible_to_launch(state=state)
+
+    def _task_possible_to_launch_precedence(self, state: State):
+        return [
+            n
+            for n in state.tasks_remaining
+            if all(m in state.tasks_complete for m in self.ancestors[n])
+        ]
+
+    def task_possible_to_launch_precedence(self, state: State):
+        return self._task_possible_to_launch_precedence(state=state)
+
+
+class WithoutPrecedence(WithPrecedence):
+    """A domain must inherit this class if there are no predecence constraints between tasks."""
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
+        ids = self.get_tasks_ids()
+        succ = {}
+        for id in ids:
+            succ[id] = []
+        return succ
+
+    def _get_predecessors(self) -> Dict[int, List[int]]:
+        """Return the successors of the tasks. Successors are given as a list for a task given as a key."""
+        ids = self.get_tasks_ids()
+        prec = {}
+        for id in ids:
+            prec[id] = []
+        return prec
```

## skdecide/builders/domain/scheduling/preemptivity.py

 * *Ordering differences only*

```diff
@@ -1,124 +1,124 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict, List
-
-__all__ = ["WithPreemptivity", "WithoutPreemptivity"]
-
-from enum import Enum
-
-
-class ResumeType(Enum):
-    NA = 0
-    Restart = 1
-    Resume = 2
-
-
-class WithPreemptivity:
-    """A domain must inherit this class if there exist at least 1 task that can be paused."""
-
-    def _get_task_preemptivity(self) -> Dict[int, bool]:
-        """Return a dictionary where the key is a task id and the value a boolean indicating
-        if the task can be paused or stopped.
-        E.g. {
-                1: False
-                2: True
-                3: False
-                4: False
-                5: True
-                6: False
-                }
-        """
-        raise NotImplementedError
-
-    def get_task_preemptivity(self) -> Dict[int, bool]:
-        """Return a dictionary where the key is a task id and the value a boolean indicating
-        if the task can be paused or stopped.
-        E.g. {
-                1: False
-                2: True
-                3: False
-                4: False
-                5: True
-                6: False
-                }
-        """
-        return self._get_task_preemptivity()
-
-    def _get_task_resuming_type(self) -> Dict[int, ResumeType]:
-        """Return a dictionary where the key is a task id and the value is of type ResumeType indicating
-        if the task can be resumed (restarted from where it was paused with no time loss)
-        or restarted (restarted from the start).
-        E.g. {
-                1: ResumeType.NA
-                2: ResumeType.Resume
-                3: ResumeType.NA
-                4: ResumeType.NA
-                5: ResumeType.Restart
-                6: ResumeType.NA
-                }
-        """
-        raise NotImplementedError
-
-    def get_task_resuming_type(self) -> Dict[int, ResumeType]:
-        """Return a dictionary where the key is a task id and the value is of type ResumeType indicating
-        if the task can be resumed (restarted from where it was paused with no time loss)
-        or restarted (restarted from the start).
-        E.g. {
-                1: ResumeType.NA
-                2: ResumeType.Resume
-                3: ResumeType.NA
-                4: ResumeType.NA
-                5: ResumeType.Restart
-                6: ResumeType.NA
-                }
-        """
-        return self._get_task_resuming_type()
-
-    def _get_task_paused_non_renewable_resource_returned(self) -> Dict[int, bool]:
-        """Return a dictionary where the key is a task id and the value is of type bool indicating
-        if the non-renewable resources are consumed when the task is paused (False) or made available again (True).
-        E.g. {
-                2: False  # if paused, non-renewable resource will be consumed
-                5: True  # if paused, the non-renewable resource will be available again
-                }
-        """
-        raise NotImplementedError
-
-    def get_task_paused_non_renewable_resource_returned(self) -> Dict[int, bool]:
-        """Return a dictionary where the key is a task id and the value is of type bool indicating
-        if the non-renewable resources are consumed when the task is paused (False) or made available again (True).
-        E.g. {
-                2: False  # if paused, non-renewable resource will be consumed
-                5: True  # if paused, the non-renewable resource will be available again
-                }
-        """
-        return self._get_task_paused_non_renewable_resource_returned()
-
-
-class WithoutPreemptivity(WithPreemptivity):
-    """A domain must inherit this class if none of the task can be paused."""
-
-    def _get_task_preemptivity(self) -> Dict[int, bool]:
-        preemptivity = {}
-        ids = self.get_tasks_ids()
-        for id in ids:
-            preemptivity[id] = False
-        return preemptivity
-
-    def _get_task_resuming_type(self) -> Dict[int, ResumeType]:
-        resume_types = {}
-        ids = self.get_tasks_ids()
-        for id in ids:
-            resume_types[id] = ResumeType.NA
-        return resume_types
-
-    def _get_task_paused_non_renewable_resource_returned(self) -> Dict[int, bool]:
-        handling = {}
-        ids = self.get_tasks_ids()
-        for id in ids:
-            handling[id] = True
-        return handling
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict, List
+
+__all__ = ["WithPreemptivity", "WithoutPreemptivity"]
+
+from enum import Enum
+
+
+class ResumeType(Enum):
+    NA = 0
+    Restart = 1
+    Resume = 2
+
+
+class WithPreemptivity:
+    """A domain must inherit this class if there exist at least 1 task that can be paused."""
+
+    def _get_task_preemptivity(self) -> Dict[int, bool]:
+        """Return a dictionary where the key is a task id and the value a boolean indicating
+        if the task can be paused or stopped.
+        E.g. {
+                1: False
+                2: True
+                3: False
+                4: False
+                5: True
+                6: False
+                }
+        """
+        raise NotImplementedError
+
+    def get_task_preemptivity(self) -> Dict[int, bool]:
+        """Return a dictionary where the key is a task id and the value a boolean indicating
+        if the task can be paused or stopped.
+        E.g. {
+                1: False
+                2: True
+                3: False
+                4: False
+                5: True
+                6: False
+                }
+        """
+        return self._get_task_preemptivity()
+
+    def _get_task_resuming_type(self) -> Dict[int, ResumeType]:
+        """Return a dictionary where the key is a task id and the value is of type ResumeType indicating
+        if the task can be resumed (restarted from where it was paused with no time loss)
+        or restarted (restarted from the start).
+        E.g. {
+                1: ResumeType.NA
+                2: ResumeType.Resume
+                3: ResumeType.NA
+                4: ResumeType.NA
+                5: ResumeType.Restart
+                6: ResumeType.NA
+                }
+        """
+        raise NotImplementedError
+
+    def get_task_resuming_type(self) -> Dict[int, ResumeType]:
+        """Return a dictionary where the key is a task id and the value is of type ResumeType indicating
+        if the task can be resumed (restarted from where it was paused with no time loss)
+        or restarted (restarted from the start).
+        E.g. {
+                1: ResumeType.NA
+                2: ResumeType.Resume
+                3: ResumeType.NA
+                4: ResumeType.NA
+                5: ResumeType.Restart
+                6: ResumeType.NA
+                }
+        """
+        return self._get_task_resuming_type()
+
+    def _get_task_paused_non_renewable_resource_returned(self) -> Dict[int, bool]:
+        """Return a dictionary where the key is a task id and the value is of type bool indicating
+        if the non-renewable resources are consumed when the task is paused (False) or made available again (True).
+        E.g. {
+                2: False  # if paused, non-renewable resource will be consumed
+                5: True  # if paused, the non-renewable resource will be available again
+                }
+        """
+        raise NotImplementedError
+
+    def get_task_paused_non_renewable_resource_returned(self) -> Dict[int, bool]:
+        """Return a dictionary where the key is a task id and the value is of type bool indicating
+        if the non-renewable resources are consumed when the task is paused (False) or made available again (True).
+        E.g. {
+                2: False  # if paused, non-renewable resource will be consumed
+                5: True  # if paused, the non-renewable resource will be available again
+                }
+        """
+        return self._get_task_paused_non_renewable_resource_returned()
+
+
+class WithoutPreemptivity(WithPreemptivity):
+    """A domain must inherit this class if none of the task can be paused."""
+
+    def _get_task_preemptivity(self) -> Dict[int, bool]:
+        preemptivity = {}
+        ids = self.get_tasks_ids()
+        for id in ids:
+            preemptivity[id] = False
+        return preemptivity
+
+    def _get_task_resuming_type(self) -> Dict[int, ResumeType]:
+        resume_types = {}
+        ids = self.get_tasks_ids()
+        for id in ids:
+            resume_types[id] = ResumeType.NA
+        return resume_types
+
+    def _get_task_paused_non_renewable_resource_returned(self) -> Dict[int, bool]:
+        handling = {}
+        ids = self.get_tasks_ids()
+        for id in ids:
+            handling[id] = True
+        return handling
```

## skdecide/builders/domain/scheduling/resource_availability.py

 * *Ordering differences only*

```diff
@@ -1,84 +1,84 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from enum import Enum
-from typing import Dict, List, Optional, Union
-
-__all__ = [
-    "UncertainResourceAvailabilityChanges",
-    "DeterministicResourceAvailabilityChanges",
-    "WithoutResourceAvailabilityChange",
-]
-
-
-class UncertainResourceAvailabilityChanges:
-    """A domain must inherit this class if the availability of its resource vary in an uncertain way over time."""
-
-    def _sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        """Sample an amount of resource availability (int) for the given resource
-        (either resource type or resource unit) at the given time. This number should be the sum of the number of
-        resource available at time t and the number of resource of this type consumed so far)."""
-        raise NotImplementedError
-
-    def sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        """Sample an amount of resource availability (int) for the given resource
-        (either resource type or resource unit) at the given time. This number should be the sum of the number of
-        resource available at time t and the number of resource of this type consumed so far)."""
-        return self._sample_quantity_resource(resource=resource, time=time, **kwargs)
-
-    def check_unique_resource_names(
-        self,
-    ) -> bool:  # TODO: How to enforce a call to this function when initialising a domain ?
-        """Return True if there are no duplicates in resource names across both resource types
-        and resource units name lists."""
-        list1 = self.get_resource_types_names() + self.get_resource_units_names()
-        list2 = list(set(list1))
-        check_1 = len(list1) == len(list2)  # no duplicated names
-        check_2 = len(list2) > 0  # at least one resource
-        return check_1 and check_2
-
-
-class DeterministicResourceAvailabilityChanges(UncertainResourceAvailabilityChanges):
-    """A domain must inherit this class if the availability of its resource vary in a deterministic way over time."""
-
-    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        """Return the resource availability (int) for the given resource
-        (either resource type or resource unit) at the given time."""
-        raise NotImplementedError
-
-    def get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        """Return the resource availability (int) for the given resource
-        (either resource type or resource unit) at the given time."""
-        return self._get_quantity_resource(resource=resource, time=time, **kwargs)
-
-    def _sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        """Sample an amount of resource availability (int) for the given resource
-        (either resource type or resource unit) at the given time. This number should be the sum of the number of
-        resource available at time t and the number of resource of this type consumed so far)."""
-        return self.get_quantity_resource(resource, time, **kwargs)
-
-
-class WithoutResourceAvailabilityChange(DeterministicResourceAvailabilityChanges):
-    """A domain must inherit this class if the availability of its resource does not vary over time."""
-
-    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        """Return the resource availability (int) for the given resource (either resource type or resource unit)."""
-        raise NotImplementedError
-
-    def get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        """Return the resource availability (int) for the given resource (either resource type or resource unit)."""
-        return self._get_original_quantity_resource(resource=resource, **kwargs)
-
-    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        """Return the resource availability (int) for the given resource
-        (either resource type or resource unit) at the given time."""
-        return self.get_original_quantity_resource(resource)
-
-    def _sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        """Sample an amount of resource availability (int) for the given resource
-        (either resource type or resource unit) at the given time. This number should be the sum of the number of
-        resource available at time t and the number of resource of this type consumed so far)."""
-        return self.get_original_quantity_resource(resource)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from enum import Enum
+from typing import Dict, List, Optional, Union
+
+__all__ = [
+    "UncertainResourceAvailabilityChanges",
+    "DeterministicResourceAvailabilityChanges",
+    "WithoutResourceAvailabilityChange",
+]
+
+
+class UncertainResourceAvailabilityChanges:
+    """A domain must inherit this class if the availability of its resource vary in an uncertain way over time."""
+
+    def _sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        """Sample an amount of resource availability (int) for the given resource
+        (either resource type or resource unit) at the given time. This number should be the sum of the number of
+        resource available at time t and the number of resource of this type consumed so far)."""
+        raise NotImplementedError
+
+    def sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        """Sample an amount of resource availability (int) for the given resource
+        (either resource type or resource unit) at the given time. This number should be the sum of the number of
+        resource available at time t and the number of resource of this type consumed so far)."""
+        return self._sample_quantity_resource(resource=resource, time=time, **kwargs)
+
+    def check_unique_resource_names(
+        self,
+    ) -> bool:  # TODO: How to enforce a call to this function when initialising a domain ?
+        """Return True if there are no duplicates in resource names across both resource types
+        and resource units name lists."""
+        list1 = self.get_resource_types_names() + self.get_resource_units_names()
+        list2 = list(set(list1))
+        check_1 = len(list1) == len(list2)  # no duplicated names
+        check_2 = len(list2) > 0  # at least one resource
+        return check_1 and check_2
+
+
+class DeterministicResourceAvailabilityChanges(UncertainResourceAvailabilityChanges):
+    """A domain must inherit this class if the availability of its resource vary in a deterministic way over time."""
+
+    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        """Return the resource availability (int) for the given resource
+        (either resource type or resource unit) at the given time."""
+        raise NotImplementedError
+
+    def get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        """Return the resource availability (int) for the given resource
+        (either resource type or resource unit) at the given time."""
+        return self._get_quantity_resource(resource=resource, time=time, **kwargs)
+
+    def _sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        """Sample an amount of resource availability (int) for the given resource
+        (either resource type or resource unit) at the given time. This number should be the sum of the number of
+        resource available at time t and the number of resource of this type consumed so far)."""
+        return self.get_quantity_resource(resource, time, **kwargs)
+
+
+class WithoutResourceAvailabilityChange(DeterministicResourceAvailabilityChanges):
+    """A domain must inherit this class if the availability of its resource does not vary over time."""
+
+    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        """Return the resource availability (int) for the given resource (either resource type or resource unit)."""
+        raise NotImplementedError
+
+    def get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        """Return the resource availability (int) for the given resource (either resource type or resource unit)."""
+        return self._get_original_quantity_resource(resource=resource, **kwargs)
+
+    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        """Return the resource availability (int) for the given resource
+        (either resource type or resource unit) at the given time."""
+        return self.get_original_quantity_resource(resource)
+
+    def _sample_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        """Sample an amount of resource availability (int) for the given resource
+        (either resource type or resource unit) at the given time. This number should be the sum of the number of
+        resource available at time t and the number of resource of this type consumed so far)."""
+        return self.get_original_quantity_resource(resource)
```

## skdecide/builders/domain/scheduling/resource_consumption.py

 * *Ordering differences only*

```diff
@@ -1,32 +1,32 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Dict, List, Set, Union
-
-__all__ = ["VariableResourceConsumption", "ConstantResourceConsumption"]
-
-
-class VariableResourceConsumption:
-    """A domain must inherit this class if the amount of resource needed by some tasks vary in time."""
-
-    def _get_variable_resource_consumption(self) -> bool:
-        """Return true if the domain has variable resource consumption,
-        false if the consumption of resource does not vary in time for any of the tasks"""
-        return True
-
-    def get_variable_resource_consumption(self) -> bool:
-        """Return true if the domain has variable resource consumption,
-        false if the consumption of resource does not vary in time for any of the tasks"""
-        return self._get_variable_resource_consumption()
-
-
-class ConstantResourceConsumption(VariableResourceConsumption):
-    """A domain must inherit this class if the amount of resource needed by all tasks do not vary in time."""
-
-    def _get_variable_resource_consumption(self) -> bool:
-        """Return true if the domain has variable resource consumption,
-        false if the consumption of resource does not vary in time for any of the tasks"""
-        return False
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Dict, List, Set, Union
+
+__all__ = ["VariableResourceConsumption", "ConstantResourceConsumption"]
+
+
+class VariableResourceConsumption:
+    """A domain must inherit this class if the amount of resource needed by some tasks vary in time."""
+
+    def _get_variable_resource_consumption(self) -> bool:
+        """Return true if the domain has variable resource consumption,
+        false if the consumption of resource does not vary in time for any of the tasks"""
+        return True
+
+    def get_variable_resource_consumption(self) -> bool:
+        """Return true if the domain has variable resource consumption,
+        false if the consumption of resource does not vary in time for any of the tasks"""
+        return self._get_variable_resource_consumption()
+
+
+class ConstantResourceConsumption(VariableResourceConsumption):
+    """A domain must inherit this class if the amount of resource needed by all tasks do not vary in time."""
+
+    def _get_variable_resource_consumption(self) -> bool:
+        """Return true if the domain has variable resource consumption,
+        false if the consumption of resource does not vary in time for any of the tasks"""
+        return False
```

## skdecide/builders/domain/scheduling/resource_costs.py

 * *Ordering differences only*

```diff
@@ -1,80 +1,80 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict, List
-
-__all__ = [
-    "WithModeCosts",
-    "WithoutModeCosts",
-    "WithResourceCosts",
-    "WithoutResourceCosts",
-]
-
-
-class WithModeCosts:
-    """A domain must inherit this class if there are some mode costs to consider."""
-
-    def _get_mode_costs(
-        self,
-    ) -> Dict[
-        int, Dict[int, float]
-    ]:  # TODO: To be handled by domain (in transition cost)
-        """
-        Return a nested dictionary where the first key is the id of a task (int), the second key the id of a mode
-        and the value indicates the cost of execution the task in the mode."""
-        raise NotImplementedError
-
-    def get_mode_costs(
-        self,
-    ) -> Dict[
-        int, Dict[int, float]
-    ]:  # TODO: To be handled by domain (in transition cost)
-        """
-        Return a nested dictionary where the first key is the id of a task (int), the second key the id of a mode
-        and the value indicates the cost of execution the task in the mode."""
-        return self._get_mode_costs()
-
-
-class WithoutModeCosts(WithModeCosts):
-    """A domain must inherit this class if there are no mode cost to consider."""
-
-    def _get_mode_costs(self) -> Dict[int, Dict[int, float]]:
-        cost_dict = {}
-        for task_id, modes in self.get_tasks_modes().items():
-            cost_dict[task_id] = {mode_id: 0.0 for mode_id in modes}
-        return cost_dict
-
-
-class WithResourceCosts:
-    """A domain must inherit this class if there are some resource costs to consider."""
-
-    def _get_resource_cost_per_time_unit(
-        self,
-    ) -> Dict[str, float]:  # TODO: To be handled by domain (in transition cost)
-        """
-        Return a dictionary where the key is the name of a resource (str)
-        and the value indicates the cost of using this resource per time unit."""
-        raise NotImplementedError
-
-    def get_resource_cost_per_time_unit(
-        self,
-    ) -> Dict[str, float]:  # TODO: To be handled by domain (in transition cost)
-        """
-        Return a dictionary where the key is the name of a resource (str)
-        and the value indicates the cost of using this resource per time unit."""
-        return self._get_resource_cost_per_time_unit()
-
-
-class WithoutResourceCosts(WithResourceCosts):
-    """A domain must inherit this class if there are no resource cost to consider."""
-
-    def _get_resource_cost_per_time_unit(self) -> Dict[str, float]:
-        cost_dict = {}
-        for res in self.get_resource_types_names():
-            cost_dict[res] = 0.0
-        for res in self.get_resource_units_names():
-            cost_dict[res] = 0.0
-        return cost_dict
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict, List
+
+__all__ = [
+    "WithModeCosts",
+    "WithoutModeCosts",
+    "WithResourceCosts",
+    "WithoutResourceCosts",
+]
+
+
+class WithModeCosts:
+    """A domain must inherit this class if there are some mode costs to consider."""
+
+    def _get_mode_costs(
+        self,
+    ) -> Dict[
+        int, Dict[int, float]
+    ]:  # TODO: To be handled by domain (in transition cost)
+        """
+        Return a nested dictionary where the first key is the id of a task (int), the second key the id of a mode
+        and the value indicates the cost of execution the task in the mode."""
+        raise NotImplementedError
+
+    def get_mode_costs(
+        self,
+    ) -> Dict[
+        int, Dict[int, float]
+    ]:  # TODO: To be handled by domain (in transition cost)
+        """
+        Return a nested dictionary where the first key is the id of a task (int), the second key the id of a mode
+        and the value indicates the cost of execution the task in the mode."""
+        return self._get_mode_costs()
+
+
+class WithoutModeCosts(WithModeCosts):
+    """A domain must inherit this class if there are no mode cost to consider."""
+
+    def _get_mode_costs(self) -> Dict[int, Dict[int, float]]:
+        cost_dict = {}
+        for task_id, modes in self.get_tasks_modes().items():
+            cost_dict[task_id] = {mode_id: 0.0 for mode_id in modes}
+        return cost_dict
+
+
+class WithResourceCosts:
+    """A domain must inherit this class if there are some resource costs to consider."""
+
+    def _get_resource_cost_per_time_unit(
+        self,
+    ) -> Dict[str, float]:  # TODO: To be handled by domain (in transition cost)
+        """
+        Return a dictionary where the key is the name of a resource (str)
+        and the value indicates the cost of using this resource per time unit."""
+        raise NotImplementedError
+
+    def get_resource_cost_per_time_unit(
+        self,
+    ) -> Dict[str, float]:  # TODO: To be handled by domain (in transition cost)
+        """
+        Return a dictionary where the key is the name of a resource (str)
+        and the value indicates the cost of using this resource per time unit."""
+        return self._get_resource_cost_per_time_unit()
+
+
+class WithoutResourceCosts(WithResourceCosts):
+    """A domain must inherit this class if there are no resource cost to consider."""
+
+    def _get_resource_cost_per_time_unit(self) -> Dict[str, float]:
+        cost_dict = {}
+        for res in self.get_resource_types_names():
+            cost_dict[res] = 0.0
+        for res in self.get_resource_units_names():
+            cost_dict[res] = 0.0
+        return cost_dict
```

## skdecide/builders/domain/scheduling/resource_renewability.py

 * *Ordering differences only*

```diff
@@ -1,83 +1,83 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict
-
-from skdecide.builders.domain.scheduling.scheduling_domains_modelling import State
-
-__all__ = ["MixedRenewable", "RenewableOnly"]
-
-
-class MixedRenewable:
-    """A domain must inherit this class if the resource available are non-renewable and renewable."""
-
-    def get_resource_renewability(self) -> Dict[str, bool]:
-        """
-        Return a dictionary where the key is a resource name (string)
-        and the value whether this resource is renewable (True) or not (False)."""
-        return self._get_resource_renewability()
-
-    def _get_resource_renewability(self) -> Dict[str, bool]:
-        """
-        Return a dictionary where the key is a resource name (string)
-        and the value whether this resource is renewable (True) or not (False)."""
-        raise NotImplementedError
-
-    def is_renewable(self, resource: str):
-        return self.get_resource_renewability()[resource]
-
-    def all_tasks_possible(self, state: State) -> bool:
-        """Return a True is for each task there is at least one mode in which the task can be executed, given the
-        resource configuration in the state provided as argument. Returns False otherwise.
-        If this function returns False, the scheduling problem is unsolvable from this state.
-        This is to cope with the use of non-renable resources that may lead to state from which a
-        task will not be possible anymore."""
-        resource_types_names = self.get_resource_types_names()
-        resource_not_renewable = set(
-            res
-            for res, renewable in self.get_resource_renewability().items()
-            if res in resource_types_names and not renewable
-        )
-        modes_details = self.get_tasks_modes()
-        remaining_tasks = (
-            state.task_ids.difference(state.tasks_complete)
-            .difference(state.tasks_progress)
-            .difference(state.tasks_unsatisfiable)
-        )
-        for task_id in remaining_tasks:
-            for mode_consumption in modes_details[task_id].values():
-                for res in resource_not_renewable:
-                    need = mode_consumption.get_resource_need(res)
-                    avail = state.resource_availability[res] - state.resource_used[res]
-                    if avail - need < 0:
-                        break
-                else:
-                    # The else-clause runs if loop completes normally, which means
-                    # that we found a mode for which all resources are available, and
-                    # we can exit from the loop on modes.
-                    break
-            else:
-                # This task is not possible
-                return False
-        return True
-
-
-class RenewableOnly(MixedRenewable):
-    """A domain must inherit this class if the resource available are ALL renewable."""
-
-    def _get_resource_renewability(self) -> Dict[str, bool]:
-        """Return a dictionary where the key is a resource name (string)
-        and the value whether this resource is renewable (True) or not (False)."""
-        names = (
-            self.get_resource_types_names() + self.get_resource_units_names()
-        )  # comes from resource_handling...
-        renewability = {}
-        for name in names:
-            renewability[name] = True
-        return renewability
-
-    def is_renewable(self, resource: str):
-        return True
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict
+
+from skdecide.builders.domain.scheduling.scheduling_domains_modelling import State
+
+__all__ = ["MixedRenewable", "RenewableOnly"]
+
+
+class MixedRenewable:
+    """A domain must inherit this class if the resource available are non-renewable and renewable."""
+
+    def get_resource_renewability(self) -> Dict[str, bool]:
+        """
+        Return a dictionary where the key is a resource name (string)
+        and the value whether this resource is renewable (True) or not (False)."""
+        return self._get_resource_renewability()
+
+    def _get_resource_renewability(self) -> Dict[str, bool]:
+        """
+        Return a dictionary where the key is a resource name (string)
+        and the value whether this resource is renewable (True) or not (False)."""
+        raise NotImplementedError
+
+    def is_renewable(self, resource: str):
+        return self.get_resource_renewability()[resource]
+
+    def all_tasks_possible(self, state: State) -> bool:
+        """Return a True is for each task there is at least one mode in which the task can be executed, given the
+        resource configuration in the state provided as argument. Returns False otherwise.
+        If this function returns False, the scheduling problem is unsolvable from this state.
+        This is to cope with the use of non-renable resources that may lead to state from which a
+        task will not be possible anymore."""
+        resource_types_names = self.get_resource_types_names()
+        resource_not_renewable = set(
+            res
+            for res, renewable in self.get_resource_renewability().items()
+            if res in resource_types_names and not renewable
+        )
+        modes_details = self.get_tasks_modes()
+        remaining_tasks = (
+            state.task_ids.difference(state.tasks_complete)
+            .difference(state.tasks_progress)
+            .difference(state.tasks_unsatisfiable)
+        )
+        for task_id in remaining_tasks:
+            for mode_consumption in modes_details[task_id].values():
+                for res in resource_not_renewable:
+                    need = mode_consumption.get_resource_need(res)
+                    avail = state.resource_availability[res] - state.resource_used[res]
+                    if avail - need < 0:
+                        break
+                else:
+                    # The else-clause runs if loop completes normally, which means
+                    # that we found a mode for which all resources are available, and
+                    # we can exit from the loop on modes.
+                    break
+            else:
+                # This task is not possible
+                return False
+        return True
+
+
+class RenewableOnly(MixedRenewable):
+    """A domain must inherit this class if the resource available are ALL renewable."""
+
+    def _get_resource_renewability(self) -> Dict[str, bool]:
+        """Return a dictionary where the key is a resource name (string)
+        and the value whether this resource is renewable (True) or not (False)."""
+        names = (
+            self.get_resource_types_names() + self.get_resource_units_names()
+        )  # comes from resource_handling...
+        renewability = {}
+        for name in names:
+            renewability[name] = True
+        return renewability
+
+    def is_renewable(self, resource: str):
+        return True
```

## skdecide/builders/domain/scheduling/resource_type.py

 * *Ordering differences only*

```diff
@@ -1,77 +1,77 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Dict, List
-
-__all__ = [
-    "WithResourceTypes",
-    "WithoutResourceTypes",
-    "WithResourceUnits",
-    "SingleResourceUnit",
-    "WithoutResourceUnit",
-]
-
-
-class WithResourceTypes:
-    """A domain must inherit this class if some of its resources are resource types."""
-
-    def get_resource_types_names(self) -> List[str]:
-        """Return the names (string) of all resource types as a list."""
-        return self._get_resource_types_names()
-
-    def _get_resource_types_names(self) -> List[str]:
-        """Return the names (string) of all resource types as a list."""
-        raise NotImplementedError
-
-
-class WithoutResourceTypes(WithResourceTypes):
-    """A domain must inherit this class if it only uses resource types."""
-
-    def _get_resource_types_names(self) -> List[str]:
-        """Return the names (string) of all resource types as a list."""
-        return []
-
-
-class WithResourceUnits:
-    """A domain must inherit this class if some of its resources are resource units."""
-
-    def get_resource_units_names(self) -> List[str]:
-        """Return the names (string) of all resource units as a list."""
-        return self._get_resource_units_names()
-
-    def _get_resource_units_names(self) -> List[str]:
-        """Return the names (string) of all resource units as a list."""
-        raise NotImplementedError
-
-    def get_resource_type_for_unit(self) -> Dict[str, str]:
-        """Return a dictionary where the key is a resource unit name and the value a resource type name.
-        An empty dictionary can be used if there are no resource unit matching a resource type."""
-        return self._get_resource_type_for_unit()
-
-    def _get_resource_type_for_unit(self) -> Dict[str, str]:
-        """Return a dictionary where the key is a resource unit name and the value a resource type name.
-        An empty dictionary can be used if there are no resource unit matching a resource type."""
-        raise NotImplementedError
-
-
-class SingleResourceUnit(WithResourceUnits):
-    """A domain must inherit this class if there is no allocation to be done (i.e. there is a single resource)."""
-
-    def _get_resource_units_names(self) -> List[str]:
-        return ["single_resource"]
-
-    def _get_resource_type_for_unit(self) -> Dict[str, str]:
-        return {}
-
-
-class WithoutResourceUnit(SingleResourceUnit):
-    """A domain must inherit this class if it only uses resource types."""
-
-    def _get_resource_units_names(self) -> List[str]:
-        return []
-
-    def _get_resource_type_for_unit(self) -> Dict[str, str]:
-        return {}
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Dict, List
+
+__all__ = [
+    "WithResourceTypes",
+    "WithoutResourceTypes",
+    "WithResourceUnits",
+    "SingleResourceUnit",
+    "WithoutResourceUnit",
+]
+
+
+class WithResourceTypes:
+    """A domain must inherit this class if some of its resources are resource types."""
+
+    def get_resource_types_names(self) -> List[str]:
+        """Return the names (string) of all resource types as a list."""
+        return self._get_resource_types_names()
+
+    def _get_resource_types_names(self) -> List[str]:
+        """Return the names (string) of all resource types as a list."""
+        raise NotImplementedError
+
+
+class WithoutResourceTypes(WithResourceTypes):
+    """A domain must inherit this class if it only uses resource types."""
+
+    def _get_resource_types_names(self) -> List[str]:
+        """Return the names (string) of all resource types as a list."""
+        return []
+
+
+class WithResourceUnits:
+    """A domain must inherit this class if some of its resources are resource units."""
+
+    def get_resource_units_names(self) -> List[str]:
+        """Return the names (string) of all resource units as a list."""
+        return self._get_resource_units_names()
+
+    def _get_resource_units_names(self) -> List[str]:
+        """Return the names (string) of all resource units as a list."""
+        raise NotImplementedError
+
+    def get_resource_type_for_unit(self) -> Dict[str, str]:
+        """Return a dictionary where the key is a resource unit name and the value a resource type name.
+        An empty dictionary can be used if there are no resource unit matching a resource type."""
+        return self._get_resource_type_for_unit()
+
+    def _get_resource_type_for_unit(self) -> Dict[str, str]:
+        """Return a dictionary where the key is a resource unit name and the value a resource type name.
+        An empty dictionary can be used if there are no resource unit matching a resource type."""
+        raise NotImplementedError
+
+
+class SingleResourceUnit(WithResourceUnits):
+    """A domain must inherit this class if there is no allocation to be done (i.e. there is a single resource)."""
+
+    def _get_resource_units_names(self) -> List[str]:
+        return ["single_resource"]
+
+    def _get_resource_type_for_unit(self) -> Dict[str, str]:
+        return {}
+
+
+class WithoutResourceUnit(SingleResourceUnit):
+    """A domain must inherit this class if it only uses resource types."""
+
+    def _get_resource_units_names(self) -> List[str]:
+        return []
+
+    def _get_resource_type_for_unit(self) -> Dict[str, str]:
+        return {}
```

## skdecide/builders/domain/scheduling/scheduling_domains.py

```diff
@@ -1,1769 +1,1892 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import random
-from enum import Enum
-from itertools import product
-from typing import Dict, Iterable, List, Optional, Set, Tuple
-
-from skdecide import (
-    DiscreteDistribution,
-    Distribution,
-    Domain,
-    EnumerableSpace,
-    ImplicitSpace,
-    SamplableSpace,
-    Space,
-    T,
-    TransitionOutcome,
-    Value,
-)
-from skdecide.builders.domain import (
-    Actions,
-    DeterministicInitialized,
-    DeterministicTransitions,
-    FullyObservable,
-    Goals,
-    Markovian,
-    Sequential,
-    Simulation,
-    SingleAgent,
-    UncertainTransitions,
-)
-from skdecide.builders.domain.scheduling.conditional_tasks import (
-    WithConditionalTasks,
-    WithoutConditionalTasks,
-)
-from skdecide.builders.domain.scheduling.graph_toolbox import Graph
-from skdecide.builders.domain.scheduling.modes import MultiMode, SingleMode
-from skdecide.builders.domain.scheduling.preallocations import (
-    WithoutPreallocations,
-    WithPreallocations,
-)
-from skdecide.builders.domain.scheduling.precedence import WithPrecedence
-from skdecide.builders.domain.scheduling.preemptivity import (
-    WithoutPreemptivity,
-    WithPreemptivity,
-)
-from skdecide.builders.domain.scheduling.resource_availability import (
-    DeterministicResourceAvailabilityChanges,
-    UncertainResourceAvailabilityChanges,
-    WithoutResourceAvailabilityChange,
-)
-from skdecide.builders.domain.scheduling.resource_consumption import (
-    ConstantResourceConsumption,
-    VariableResourceConsumption,
-)
-from skdecide.builders.domain.scheduling.resource_costs import (
-    WithModeCosts,
-    WithoutModeCosts,
-    WithoutResourceCosts,
-    WithResourceCosts,
-)
-from skdecide.builders.domain.scheduling.resource_renewability import (
-    MixedRenewable,
-    RenewableOnly,
-)
-from skdecide.builders.domain.scheduling.resource_type import (
-    WithoutResourceUnit,
-    WithResourceTypes,
-    WithResourceUnits,
-)
-from skdecide.builders.domain.scheduling.scheduling_domains_modelling import (
-    SchedulingAction,
-    SchedulingActionEnum,
-    State,
-)
-from skdecide.builders.domain.scheduling.skills import (
-    WithoutResourceSkills,
-    WithResourceSkills,
-)
-from skdecide.builders.domain.scheduling.task import Task
-from skdecide.builders.domain.scheduling.task_duration import (
-    DeterministicTaskDuration,
-    SimulatedTaskDuration,
-    UncertainUnivariateTaskDuration,
-)
-from skdecide.builders.domain.scheduling.task_progress import (
-    CustomTaskProgress,
-    DeterministicTaskProgress,
-)
-from skdecide.builders.domain.scheduling.time_lag import WithoutTimeLag, WithTimeLag
-from skdecide.builders.domain.scheduling.time_windows import (
-    WithoutTimeWindow,
-    WithTimeWindow,
-)
-
-
-class SchedulingObjectiveEnum(Enum):
-    """
-    Enum defining the different scheduling objectives:
-    - MAKESPAN: makespan (to be minimize)
-    - COST: cost of resources (to be minimized)
-    """
-
-    MAKESPAN = 0
-    COST = 1
-
-
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    Simulation,
-    DeterministicInitialized,
-    Actions,
-    FullyObservable,
-    Markovian,
-    Goals,
-):
-    """
-    Base class for any scheduling statefull domain
-    """
-
-    T_state = State  # Type of states
-    T_observation = State  # Type of observations
-    T_event = SchedulingAction  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_info = (
-        None  # Type of additional information given as part of an environment outcome
-    )
-
-
-class SchedulingDomain(
-    WithPrecedence,
-    MultiMode,
-    VariableResourceConsumption,
-    WithPreemptivity,
-    WithResourceTypes,
-    WithResourceUnits,
-    MixedRenewable,
-    SimulatedTaskDuration,
-    CustomTaskProgress,
-    WithResourceSkills,
-    WithTimeLag,
-    WithTimeWindow,
-    WithPreallocations,
-    WithConditionalTasks,
-    UncertainResourceAvailabilityChanges,
-    WithModeCosts,
-    WithResourceCosts,
-    D,
-):
-    """
-    This is the highest level scheduling domain class (inheriting top-level class for each mandatory
-    domain characteristic).
-    This is where the implementation of the statefull scheduling domain is implemented,
-    letting to the user the possibility
-    to the user to define the scheduling problem without having to think of a statefull version.
-    """
-
-    def _state_sample(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_info]]:
-        """This function will be used if the domain is defined as a Simulation (i.e. transitions are defined by call to
-        a simulation). This function may also be used by simulation-based solvers on non-Simulation domains."""
-        current_state: State = memory
-        next_state = current_state if self.inplace_environment else current_state.copy()
-        next_state = self.update_pause_tasks_simulation(next_state, action)
-        next_state = self.update_resume_tasks_simulation(next_state, action)
-        next_state = self.update_start_tasks_simulation(next_state, action)
-        next_state = self.update_complete_dummy_tasks_simulation(next_state, action)
-        next_state = self.update_conditional_tasks_simulation(next_state, action)
-        next_state = self.update_time_simulation(next_state, action)
-        next_state = self.update_resource_availability_simulation(next_state, action)
-        is_terminal = self._is_terminal(next_state)
-        is_goal = self._is_goal(next_state)
-        return TransitionOutcome(
-            state=next_state,
-            value=self._get_transition_value(memory, action, next_state),
-            termination=is_goal or is_terminal,
-            info=None,
-        )
-
-    def _get_next_state_distribution(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> Distribution[D.T_state]:
-        """This function will be used if the domain is defined with UncertainTransitions. This function will be ignored
-        if the domain is defined as a Simulation. This function may also be used by uncertainty-specialised solvers
-         on deterministic domains."""
-        current_state: State = memory
-        next_state = current_state if self.inplace_environment else current_state.copy()
-        next_state = self.update_pause_tasks_uncertain(next_state, action)
-        next_state = self.update_resume_tasks_uncertain(next_state, action)
-        next_state_distrib = self.update_start_tasks_uncertain(next_state, action)
-        next_state_distrib = self.update_complete_dummy_tasks_uncertain(
-            next_state_distrib, action
-        )
-        next_state_distrib = self.update_conditional_tasks_uncertain(
-            next_state_distrib, action
-        )
-        next_state_distrib = self.update_time_uncertain(next_state_distrib, action)
-        next_state_distrib = self.update_resource_availability_uncertain(
-            next_state_distrib, action
-        )  # maybe this should be done after self.update_time too ??
-        return next_state_distrib
-
-    def _get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        """
-        This function will be used if the domain is defined with DeterministicTransitions. This function will be ignored
-        if the domain is defined as having UncertainTransitions or Simulation."""
-        current_state: State = memory
-        next_state = current_state if self.inplace_environment else current_state.copy()
-        next_state = self.update_pause_tasks(next_state, action)
-        next_state = self.update_resume_tasks(next_state, action)
-        next_state = self.update_start_tasks(next_state, action)
-        next_state = self.update_complete_dummy_tasks(next_state, action)
-        next_state = self.update_conditional_tasks(next_state, action)
-        next_state = self.update_time(next_state, action)
-        next_state = self.update_resource_availability(
-            next_state, action
-        )  # maybe this should be done after self.update_time too ??
-
-        return next_state
-
-    def _get_initial_state_(self) -> D.T_state:
-        """
-        Create and return an empty initial state
-        """
-        s = State(
-            task_ids=self.get_tasks_ids(),
-            tasks_available=self.get_all_unconditional_tasks(),
-        )
-        s.t = 0
-        resource_availability = {
-            r: self.sample_quantity_resource(resource=r, time=s.t)
-            for r in self.get_resource_types_names()
-        }
-        resource_availability.update(
-            {
-                runit: self.sample_quantity_resource(resource=runit, time=s.t)
-                for runit in self.get_resource_units_names()
-            }
-        )
-        s.resource_availability = resource_availability
-        s.resource_used = {r: 0 for r in s.resource_availability}
-        return s
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        """
-        To be implemented if needed one day.
-        """
-        pass
-
-    def _get_applicable_actions_from(
-        self, memory: D.T_memory[D.T_state]
-    ) -> D.T_agent[Space[D.T_event]]:
-        """
-        Returns the action space from a state.
-        TODO : think about a way to avoid the instaceof usage.
-        """
-        if isinstance(self, WithoutResourceSkills) and isinstance(
-            self, WithoutResourceUnit
-        ):
-            return SchedulingActionSpace(domain=self, state=memory)
-        else:
-            # return SchedulingActionSpaceWithResourceUnit(domain=self, state=memory)
-            return SchedulingActionSpaceWithResourceUnitSamplable(
-                domain=self, state=memory
-            )
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        """
-        To be implemented if needed one day.
-        """
-        pass
-
-    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
-        return ImplicitSpace(
-            lambda state: (
-                len(state.task_ids)
-                == len(state.tasks_complete) + len(state.tasks_unsatisfiable)
-                and (len(state.tasks_ongoing) == 0)
-                and (len(state.tasks_paused) == 0)
-            )
-        )
-
-    def get_max_horizon(self) -> int:
-        """Return the maximum time horizon (int)"""
-        return self._get_max_horizon()
-
-    def _get_max_horizon(self) -> int:
-        """Return the maximum time horizon (int)"""
-        raise NotImplementedError
-
-    def initialize_domain(self):
-        """Initialize a scheduling domain. This function needs to be called when instantiating a scheduling domain."""
-        self.sampled_durations = {}  # TODO : remove ?
-        self.graph = (
-            self.compute_graph()
-        )  # TODO : this is very specific to the precendence caracteristic,
-        # should it be done there ?
-        self.ancestors = self.graph.predecessors_map()
-        self.successors = self.graph.successors_map()
-        self.full_predecessors = self.graph.ancestors_map()
-        self.full_successors = self.graph.descendants_map()
-        self.inplace_environment = False
-
-    def set_inplace_environment(self, inplace_environment: bool):
-        """
-        Activate or not the fact that the simulator modifies the given state inplace or create a copy before.
-        The inplace version is several times faster but will lead to bugs in graph search solver.
-        """
-        self.inplace_environment = inplace_environment
-
-    # Build the precedence graph.
-    # TODO : maybe this function should be in the precedence module.
-    def compute_graph(self):
-        task_ids = self.get_tasks_ids()
-        successors = self.get_successors()
-        mode_details = self.get_tasks_modes()
-        nodes = [
-            (
-                n,
-                {
-                    mode: self.sample_task_duration(task=n, mode=mode)
-                    for mode in mode_details[n]
-                },
-            )
-            for n in task_ids
-        ]
-        edges = []
-        for n in successors:
-            for succ in successors[n]:
-                edges += [(n, succ, {})]
-        return Graph(nodes, edges, False)
-
-    def update_time(self, state: State, action: SchedulingAction):
-        """Update the time of the state if the time_progress attribute of the given EnumerableAction is True."""
-        next_state = state  # .copy()
-        if action.time_progress:
-            next_state = self.update_progress(next_state)
-            next_state = self.update_res_consumption(next_state)
-            next_state = self.update_complete_tasks(next_state)
-            next_state.t = state.t + 1
-        return next_state
-
-    def update_time_uncertain(
-        self, states: DiscreteDistribution[State], action: SchedulingAction
-    ):
-        """Update the time of the state if the time_progress attribute of the given EnumerableAction is True."""
-        next_states = DiscreteDistribution(
-            [(state, prob) for (state, prob) in states.get_values()]
-        )
-        if action.time_progress:
-            next_states = self.update_progress_uncertain(next_states)
-            next_states = self.update_res_consumption_uncertain(next_states)
-            next_states = self.update_complete_tasks_uncertain(next_states)
-            for next_state, _ in next_states.get_values():
-                next_state.t = next_state.t + 1
-        return next_states
-
-    def update_time_simulation(self, state: State, action: SchedulingAction):
-        """In a simulated scheduling environment, update the time of the state if the time_progress attribute of the
-        given EnumerableAction is True."""
-        next_state = state  # .copy()
-        if action.time_progress:
-            next_state = self.update_progress_simulation(next_state)
-            next_state = self.update_res_consumption_simulation(next_state)
-            next_state = self.update_complete_tasks_simulation(next_state)
-            next_state.t = state.t + 1
-        return next_state
-
-    def update_res_consumption(self, state: State):
-        # TODO : test this.
-        next_state = state  # .copy()
-        for task_id in state.tasks_ongoing:
-            resource_to_use = self.get_resource_used(
-                task=task_id,
-                mode=state.tasks_mode[task_id],
-                resource_unit_names=set(),
-                time_since_start=state.tasks_details[task_id].get_task_active_time(
-                    state.t + 1
-                ),
-            )
-            for r in resource_to_use:
-                prev = next_state.resource_used_for_task[task_id][r]
-                new = resource_to_use[r]
-                next_state.resource_used_for_task[task_id][r] = resource_to_use[r]
-                next_state.resource_used[r] += new - prev
-        return next_state
-
-    def update_res_consumption_uncertain(self, states: DiscreteDistribution[State]):
-        next_states = DiscreteDistribution(
-            [(state, prob) for (state, prob) in states.get_values()]
-        )
-
-        for next_state, _ in next_states.get_values():
-            for task_id in next_state.tasks_ongoing:
-                resource_to_use = self.get_resource_used(
-                    task=task_id,
-                    mode=next_state.tasks_mode[task_id],
-                    resource_unit_names=set(),
-                    time_since_start=next_state.tasks_details[
-                        task_id
-                    ].get_task_active_time(next_state.t + 1),
-                )
-                for r in resource_to_use:
-                    prev = next_state.resource_used_for_task[task_id][r]
-                    new = resource_to_use[r]
-                    next_state.resource_used_for_task[task_id][r] = resource_to_use[r]
-                    next_state.resource_used[r] += new - prev
-
-        return next_states
-
-    def update_res_consumption_simulation(self, state: State):
-        return self.update_res_consumption(state)
-
-    def update_progress(self, state: State):
-        """Update the progress of all ongoing tasks in the state."""
-        next_state = state  # .copy()
-        for task_id in next_state.tasks_ongoing:
-            # TODO : update the resource used dictionnary also, for the task that consumes a varying number
-            # of ressource
-            next_state.tasks_progress[task_id] += self.get_task_progress(
-                task_id,
-                t_from=next_state.t,
-                t_to=next_state.t + 1,
-                mode=next_state.tasks_mode[task_id],
-                sampled_duration=next_state.tasks_details[task_id].sampled_duration,
-            )
-        return next_state
-
-    def update_progress_uncertain(self, states: DiscreteDistribution[State]):
-        """In an uncertain scheduling environment, update the progress of all ongoing tasks in the state."""
-        next_states = DiscreteDistribution(
-            [(state, prob) for (state, prob) in states.get_values()]
-        )
-
-        for next_state, _ in next_states.get_values():
-            for task_id in next_state.tasks_ongoing:
-                # TODO : update the resource used dictionnary also, for the task that consumes a varying number
-                # of ressource
-                next_state.tasks_progress[task_id] += self.get_task_progress(
-                    task_id,
-                    t_from=next_state.t,
-                    t_to=next_state.t + 1,
-                    mode=next_state.tasks_mode[task_id],
-                    sampled_duration=next_state.tasks_details[task_id].sampled_duration,
-                )
-        return next_states
-
-    def update_progress_simulation(self, state: State):
-        """In a simulation scheduling environment, update the progress of all ongoing tasks in the state."""
-        return self.update_progress(state)
-
-    def update_complete_tasks(self, state: State):
-        """Update the status of newly completed tasks in the state from ongoing to complete
-        and update resource availability. This function will also log in task_details the time it was complete"""
-        next_state = state  # .copy()
-        completed_tmp = []
-        for task_id in next_state.tasks_ongoing:
-            if next_state.tasks_progress[task_id] >= 0.9999:
-                next_state.tasks_progress[task_id] = 1
-                completed_tmp.append(task_id)
-        for completed_task in completed_tmp:
-            next_state.tasks_complete.add(completed_task)
-            next_state.tasks_ongoing.remove(completed_task)
-            for res in next_state.resource_used_for_task[completed_task]:
-                res_consumption = next_state.resource_used_for_task[completed_task][res]
-                if self.is_renewable(res):
-                    next_state.resource_used[res] -= res_consumption
-            next_state.resource_used_for_task.pop(completed_task)
-            next_state.tasks_details[completed_task].end = next_state.t + 1
-            # WARNING : considering how it's coded, we should put +1 here. could be ccleaner if it was done in the update_progress.
-            next_state.tasks_complete_details.push_front(
-                next_state.tasks_details[completed_task]
-            )
-            del next_state.tasks_details[completed_task]
-            next_state.tasks_complete_progress.push_front(
-                next_state.tasks_progress[completed_task]
-            )
-            del next_state.tasks_progress[completed_task]
-            next_state.tasks_complete_mode.push_front(
-                (completed_task, next_state.tasks_mode[completed_task])
-            )
-            del next_state.tasks_mode[completed_task]
-
-        return next_state
-
-    def update_complete_tasks_uncertain(self, states: DiscreteDistribution[State]):
-        """In an uncertain scheduling environment, update the status of newly completed tasks in the state from ongoing
-        to complete, update resource availability and update on-completion conditions.
-        This function will also log in task_details the time it was complete."""
-        next_states = DiscreteDistribution(
-            [(state, prob) for (state, prob) in states.get_values()]
-        )
-
-        states_and_proba = []
-        for next_state, _ in next_states.get_values():
-            completed_tmp = []
-            for task_id in next_state.tasks_ongoing:
-                if next_state.tasks_progress[task_id] >= 0.9999:
-                    next_state.tasks_progress[task_id] = 1
-                    completed_tmp.append(task_id)
-
-            all_values = []
-            all_models = {}
-            for completed_task in completed_tmp:
-                next_state.tasks_complete.add(completed_task)
-                next_state.tasks_ongoing.remove(completed_task)
-                for res in next_state.resource_used_for_task[completed_task]:
-                    res_consumption = next_state.resource_used_for_task[completed_task][
-                        res
-                    ]
-                    if self.is_renewable(res):
-                        next_state.resource_used[res] -= res_consumption
-                next_state.resource_used_for_task.pop(completed_task)
-                next_state.tasks_details[completed_task].end = (
-                    next_state.t + 1
-                )  # WARNING : considering how it's coded, we should put +1 here.
-                next_state.tasks_complete_details.push_front(
-                    next_state.tasks_details[completed_task]
-                )
-                del next_state.tasks_details[completed_task]
-                next_state.tasks_complete_progress.push_front(
-                    next_state.tasks_progress[completed_task]
-                )
-                del next_state.tasks_progress[completed_task]
-                next_state.tasks_complete_mode.push_front(
-                    (completed_task, next_state.tasks_mode[completed_task])
-                )
-                del next_state.tasks_mode[completed_task]
-                if completed_task in self.get_task_on_completion_added_conditions():
-                    all_models[completed_task] = []
-                    for i in range(
-                        len(
-                            self.get_task_on_completion_added_conditions()[
-                                completed_task
-                            ]
-                        )
-                    ):
-                        for j in range(
-                            len(
-                                self.get_task_on_completion_added_conditions()[
-                                    completed_task
-                                ][i].get_values()
-                            )
-                        ):
-                            all_values.append(
-                                {
-                                    "task": completed_task,
-                                    "cond": self.get_task_on_completion_added_conditions()[
-                                        completed_task
-                                    ][
-                                        i
-                                    ].get_values()[
-                                        j
-                                    ][
-                                        0
-                                    ],
-                                    "prob": self.get_task_on_completion_added_conditions()[
-                                        completed_task
-                                    ][
-                                        i
-                                    ].get_values()[
-                                        j
-                                    ][
-                                        1
-                                    ],
-                                }
-                            )
-                            all_models[completed_task].append(len(all_values) - 1)
-
-            combinations = list(product(*all_models.values()))
-            # for comb in combinations:
-            #     next_state_2 = next_state.copy()
-            #     proba = 1.
-            #     for i in comb:
-            #         next_state_2._current_conditions.add(all_values[i]['cond'])
-            #         proba *= all_values[i]['prob']
-            #     states_and_proba += [(next_state_2, proba)]
-            for comb in combinations:
-                do_copy = len(comb) > 0
-                next_state_2 = next_state.copy() if do_copy else next_state
-                proba = 1.0
-                for i in comb:
-                    next_state_2._current_conditions.add(all_values[i]["cond"])
-                    proba *= all_values[i]["prob"]
-                states_and_proba += [(next_state_2, proba)]
-        return DiscreteDistribution(states_and_proba)
-
-    def update_complete_tasks_simulation(self, state: State):
-        """In a simulated scheduling environment, update the status of newly completed tasks in the state from ongoing to complete
-        and update resource availability. This function will also log in task_details the time it was complete"""
-        next_state: State = state
-        next_state = self.update_complete_tasks_uncertain(
-            states=DiscreteDistribution([(next_state, 1.0)])
-        ).sample()
-        return next_state
-
-    def update_complete_dummy_tasks(self, state: State, action: SchedulingAction):
-        """Update the status of newly started tasks whose duration is 0 from ongoing to complete."""
-        next_state = state  # .copy()
-        if action.action == SchedulingActionEnum.START:
-            task = action.task
-            if next_state.tasks_details[task].sampled_duration == 0:
-                next_state.tasks_complete.add(task)
-                next_state.tasks_progress[task] = 1
-                next_state.tasks_ongoing.remove(task)
-                next_state.tasks_details[task].end = next_state.t
-                next_state.tasks_complete_details.push_front(
-                    next_state.tasks_details[task]
-                )
-                del next_state.tasks_details[task]
-                next_state.tasks_complete_progress.push_front(
-                    next_state.tasks_progress[task]
-                )
-                del next_state.tasks_progress[task]
-                next_state.tasks_complete_mode.push_front(
-                    (task, next_state.tasks_mode[task])
-                )
-                del next_state.tasks_mode[task]
-                next_state.resource_used_for_task.pop(task)
-        return next_state
-
-    def update_complete_dummy_tasks_uncertain(
-        self, states: DiscreteDistribution[State], action: SchedulingAction
-    ):
-        """In an uncertain scheduling environment, update the status of newly started tasks whose duration is 0
-        from ongoing to complete."""
-        next_states = DiscreteDistribution(
-            [(state, prob) for (state, prob) in states.get_values()]
-        )
-        if action.action == SchedulingActionEnum.START:
-            task = action.task
-            for next_state, _ in next_states.get_values():
-                if next_state.tasks_details[task].sampled_duration == 0:
-                    next_state.tasks_complete.add(task)
-                    next_state.tasks_progress[task] = 1
-                    next_state.tasks_ongoing.remove(task)
-                    next_state.tasks_details[task].end = next_state.t
-                    next_state.tasks_complete_details.push_front(
-                        next_state.tasks_details[task]
-                    )
-                    del next_state.tasks_details[task]
-                    next_state.tasks_complete_progress.push_front(
-                        next_state.tasks_progress[task]
-                    )
-                    del next_state.tasks_progress[task]
-                    next_state.tasks_complete_mode.push_front(
-                        (task, next_state.tasks_mode[task])
-                    )
-                    del next_state.tasks_mode[task]
-                    next_state.resource_used_for_task.pop(task)
-        return next_states
-
-    def update_complete_dummy_tasks_simulation(
-        self, state: State, action: SchedulingAction
-    ):
-        """In a simulated scheduling environment, update the status of newly started tasks whose duration is 0
-        from ongoing to complete."""
-        return self.update_complete_dummy_tasks(state, action)
-
-    def update_pause_tasks(self, state: State, action: SchedulingAction):
-        """Update the status of a task from ongoing to paused if specified in the action
-        and update resource availability. This function will also log in task_details the time it was paused."""
-        next_state = state  # .copy()
-        if action.action == SchedulingActionEnum.PAUSE:
-            paused_task = action.task
-            next_state.tasks_paused.add(paused_task)
-            next_state.tasks_ongoing.remove(paused_task)
-            # time_since_start = next_state.tasks_details[paused_task].get_task_active_time(next_state.t)
-            for res in next_state.resource_used_for_task[paused_task]:
-                res_consumption = next_state.resource_used_for_task[paused_task][res]
-                if self.is_renewable(res) or (
-                    not self.is_renewable(res)
-                    and self.get_task_paused_non_renewable_resource_returned()[res]
-                ):
-                    next_state.resource_used[res] -= res_consumption
-            next_state.resource_used_for_task.pop(paused_task)
-            next_state.tasks_details[paused_task].paused.append(next_state.t)
-            # Need to call this after get_task_active_time()
-        return next_state
-
-    def update_pause_tasks_uncertain(self, state: State, action: SchedulingAction):
-        """In an uncertain scheduling environment, update the status of a task from ongoing to paused if
-        specified in the action and update resource availability. This function will also log in task_details
-        the time it was paused."""
-        return self.update_pause_tasks(state, action)
-
-    def update_pause_tasks_simulation(self, state: State, action: SchedulingAction):
-        """In a simulation scheduling environment, update the status of a task from ongoing to paused if
-        specified in the action and update resource availability. This function will also log in task_details
-        the time it was paused."""
-        return self.update_pause_tasks(state, action)
-
-    def update_resume_tasks(self, state: State, action: SchedulingAction):
-        """Update the status of a task from paused to ongoing if specified in the action
-        and update resource availability. This function will also log in task_details the time it was resumed"""
-        next_state = state  # .copy()
-        if action.action == SchedulingActionEnum.RESUME:
-            resumed_task = action.task
-            mode = action.mode  # use mode specified in action if any
-            if mode is None:
-                mode = state.tasks_mode[resumed_task]  # or use previous mode
-            next_state.tasks_ongoing.add(resumed_task)
-            next_state.tasks_paused.remove(resumed_task)
-            next_state.tasks_details[resumed_task].resumed.append(
-                next_state.t
-            )  # Need to call this before get_task_active_time()
-            b, resource_to_use = self.check_if_action_can_be_started(
-                next_state, action=action
-            )
-            if not b:
-                return next_state
-            for res in resource_to_use:
-                next_state.resource_used[res] += resource_to_use[res]
-            next_state.resource_used_for_task[resumed_task] = resource_to_use
-            # self.get_latest_sampled_duration(task=resumed_task , mode=mode,
-            #                                 progress_from=next_state.tasks_progress[resumed_task])  # TODO: what to do with this, so far the sample is stored and then used by get_task_progress()
-            # Out of scope normally, there shouldn't be a "get_resource_need_at_time" function
-            # for ressource unit, or it doesn't make completely sense as of today
-            # for res in self.get_resource_units_names():
-            #     res_consumption = self.get_tasks_modes()[resumed_task][next_state.tasks_mode[resumed_task]]\
-            #         .get_resource_need_at_time(resource_name=res, time=time_since_start)
-            #     # next_state.resource_availability[res] -= res_consumption
-            #     next_state.resource_used[res] += res_consumption
-            #     if resumed_task not in next_state.resource_used_for_task:
-            #         next_state.resource_used_for_task[resumed_task] = {}
-            #     next_state.resource_used_for_task[resumed_task][res] = res_consumption
-            # for res in self.get_resource_types_names():
-            #     res_consumption = self.get_tasks_modes()[resumed_task][next_state.tasks_mode[resumed_task]]\
-            #         .get_resource_need_at_time(resource_name=res, time=time_since_start)
-            #     # next_state.resource_availability[res] -= res_consumption
-            #     next_state.resource_used[res] += res_consumption
-            #     if resumed_task not in next_state.resource_used_for_task:
-            #         next_state.resource_used_for_task[resumed_task] = {}
-            #     next_state.resource_used_for_task[resumed_task][res] = res_consumption
-            # if action.resource_unit_names is not None:
-            #     for resource_unit_name in action.resource_unit_names:
-            #         next_state.resource_used[resource_unit_name] = 1
-            #         next_state.resource_used_for_task[resumed_task][resource_unit_name] = 1
-        return next_state
-
-    def update_resume_tasks_uncertain(self, state: State, action: SchedulingAction):
-        """In an uncertain scheduling environment, update the status of a task from paused to ongoing if specified
-        in the action and update resource availability. This function will also log in task_details the time it was
-        resumed."""
-        return self.update_resume_tasks(state, action)
-
-    def update_resume_tasks_simulation(self, state: State, action: SchedulingAction):
-        """In a simulationn scheduling environment, update the status of a task from paused to ongoing if specified
-        in the action and update resource availability. This function will also log in task_details the time it was
-        resumed."""
-        return self.update_resume_tasks(state, action)
-
-    def check_if_action_can_be_started(
-        self, state: State, action: SchedulingAction
-    ) -> Tuple[bool, Dict[str, int]]:
-        """Check if a start or resume action can be applied. It returns a boolean and a dictionary of resources to use."""
-        started_task = action.task
-        if action.action == SchedulingActionEnum.START:
-            time_since_start = state.t
-        elif action.action == SchedulingActionEnum.RESUME:
-            time_since_start = state.tasks_details[started_task].get_task_active_time(
-                state.t
-            )
-        else:
-            return True, {}
-        resource_to_use = self.get_resource_used(
-            task=started_task,
-            mode=action.mode,
-            resource_unit_names=action.resource_unit_names,
-            time_since_start=time_since_start,
-        )
-        if any(
-            resource_to_use[r] > state.resource_availability[r] - state.resource_used[r]
-            for r in resource_to_use
-        ):
-            return False, resource_to_use
-        b = self.check_if_skills_are_fulfilled(
-            task=started_task, mode=action.mode, resource_used=resource_to_use
-        )
-        return b, resource_to_use
-
-    def get_resource_used(
-        self, task: int, mode: int, resource_unit_names: Set[str], time_since_start: int
-    ):
-        r_used = {}
-        mode_details = self.get_tasks_modes()
-        for res in self.get_resource_types_names():
-            res_consumption = mode_details[task][mode].get_resource_need_at_time(
-                resource_name=res, time=time_since_start
-            )
-            # next_state.resource_availability[res] -= res_consumption
-            r_used[res] = res_consumption
-        if resource_unit_names is not None:
-            for resource_unit_name in resource_unit_names:
-                r_used[resource_unit_name] = 1
-        return r_used
-
-    def update_start_tasks(self, state: State, action: SchedulingAction):
-        """Update the status of a task from remaining to ongoing if specified in the action
-        and update resource availability. This function will also log in task_details the time it was started."""
-        if action.action == SchedulingActionEnum.START:
-            can_be_started, resource_to_use = self.check_if_action_can_be_started(
-                state, action
-            )
-            if not can_be_started:
-                return state
-            next_state: State = state  # .copy()
-            started_task = action.task
-            mode = action.mode
-            next_state.tasks_mode[started_task] = mode
-            next_state.tasks_ongoing.add(started_task)
-            sampled_duration = self.get_latest_sampled_duration(
-                task=started_task, mode=mode, progress_from=0.0
-            )  # TODO: what to do with this, so far the sample is stored and then used by get_task_progress()
-            next_state.tasks_details[started_task] = Task(
-                started_task, next_state.t, sampled_duration
-            )
-            for res in resource_to_use:
-                next_state.resource_used[res] += resource_to_use[res]
-            next_state.resource_used_for_task[started_task] = resource_to_use
-            next_state.tasks_progress[started_task] = 0.0
-            return next_state
-        return state
-
-    def update_start_tasks_uncertain(self, state: State, action: SchedulingAction):
-        """In an uncertain scheduling environment, update the status of a task from remaining to ongoing
-        if specified in the action and update resource availability.
-        This function returns a DsicreteDistribution of State.
-        This function will also log in task_details the time it was started."""
-
-        if action.action == SchedulingActionEnum.START:
-            can_be_started, resource_to_use = self.check_if_action_can_be_started(
-                state, action
-            )
-            if not can_be_started:
-                return DiscreteDistribution([(state, 1)])
-            started_task = action.task
-            mode = action.mode
-            duration_distrib = self.get_task_duration_distribution(
-                started_task, mode, multivariate_settings={"t": state.t}
-            )
-            states_and_proba = []
-
-            for value_duration in duration_distrib.get_values():
-                next_state: State = state.copy()
-                next_state.tasks_mode[started_task] = mode
-                next_state.tasks_ongoing.add(started_task)
-                next_state.tasks_details[started_task] = Task(
-                    started_task, state.t, value_duration[0]
-                )
-                for res in resource_to_use:
-                    next_state.resource_used[res] += resource_to_use[res]
-                next_state.resource_used_for_task[started_task] = resource_to_use
-                next_state.tasks_progress[started_task] = 0.0
-
-                states_and_proba += [(next_state, value_duration[1])]
-
-            return DiscreteDistribution(states_and_proba)
-        return DiscreteDistribution([(state, 1)])
-
-    def update_start_tasks_simulation(self, state: State, action: SchedulingAction):
-        """In a simulated scheduling environment, update the status of a task from remaining to ongoing if
-        specified in the action and update resource availability. This function will also log in task_details the
-        time it was started."""
-        return self.update_start_tasks(state, action)
-
-    def get_possible_starting_tasks(self, state: State):
-
-        mode_details = self.get_tasks_modes()
-        possible_task_precedence = [
-            (n, mode_details[n])
-            for n in state.tasks_remaining
-            if all(
-                m in state.tasks_complete
-                for m in set(self.ancestors[n]).intersection(
-                    self.get_available_tasks(state)
-                )
-            )
-        ]
-
-        possible_task_with_ressource = [
-            (n, mode, mode_consumption)
-            for n, modes in possible_task_precedence
-            for mode, mode_consumption in modes.items()
-            if all(
-                state.resource_availability[key]
-                - state.resource_used[key]
-                - mode_consumption.get_resource_need_at_time(
-                    resource_name=key, time=state.t
-                )
-                >= 0
-                for key in self.get_resource_types_names()
-            )
-        ]
-        # print("Possible task with ressource : ", possible_task_with_ressource)
-        return {
-            n: {mode: mode_consumption.get_non_zero_ressource_need_names(0)}
-            for n, mode, mode_consumption in possible_task_with_ressource
-        }
-
-    def get_possible_resume_tasks(self, state: State):
-        mode_details = self.get_tasks_modes()
-        possible_task_precedence = [
-            (n, mode_details[n])
-            for n in state.tasks_paused
-            if all(m in state.tasks_complete for m in self.ancestors[n])
-        ]
-        # print("Possible task precedence : ", possible_task_precedence)
-        possible_task_with_ressource = [
-            (n, mode, mode_consumption)
-            for n, modes in possible_task_precedence
-            for mode, mode_consumption in modes.items()
-            if all(
-                state.resource_availability[key]
-                - state.resource_used[key]
-                - mode_consumption.get_resource_need_at_time(
-                    resource_name=key, time=state.t
-                )
-                >= 0
-                for key in self.get_resource_types_names()
-            )
-        ]
-        # print("Possible task with ressource : ", possible_task_with_ressource)
-        return {
-            n: {mode: mode_consumption.get_non_zero_ressource_need_names(0)}
-            for n, mode, mode_consumption in possible_task_with_ressource
-        }
-
-    def state_is_overconsuming(self, state: State):
-        return any(
-            state.resource_used[k] > state.resource_availability[k]
-            for k in state.resource_used
-        )
-
-    def update_resource_availability(self, state: State, action: SchedulingAction):
-        """Update resource availability for next time step. This should be called after update_time()."""
-        if action.time_progress:
-            next_state: State = state  # .copy()
-            # update the resource used / resource availability function on the possible new availability
-            # and consumption of ongoing task -> quite boring to code and debug probably
-            for res in self.get_resource_units_names():
-                next_state.resource_availability[res] = self.sample_quantity_resource(
-                    resource=res, time=next_state.t
-                )
-            for res in self.get_resource_types_names():
-                next_state.resource_availability[res] = self.sample_quantity_resource(
-                    resource=res, time=next_state.t
-                )
-            # TODO :
-            # Here, if the resource_used[res] is > resource_availability[res] we should be forced to pause some task??
-            # If yes which one ? all ? and we let the algorithm resume the one of its choice in the next time step ?
-            return next_state
-        return state
-
-    def update_resource_availability_uncertain(
-        self, states: DiscreteDistribution[State], action: SchedulingAction
-    ):
-        """Update resource availability for next time step. This should be called after update_time()."""
-        next_states = DiscreteDistribution(
-            [(state, prob) for (state, prob) in states.get_values()]
-        )
-
-        if action.time_progress:
-            for next_state, _ in next_states.get_values():
-                # update the resource used / resource availability function on the possible new availability
-                # and consumption of ongoing task -> quite boring to code and debug probably
-                for res in self.get_resource_units_names():
-                    next_state.resource_availability[
-                        res
-                    ] = self.sample_quantity_resource(resource=res, time=next_state.t)
-                for res in self.get_resource_types_names():
-                    next_state.resource_availability[
-                        res
-                    ] = self.sample_quantity_resource(resource=res, time=next_state.t)
-                # TODO :
-                # Here, if the resource_used[res] is > resource_availability[res] we should be forced to pause some task??
-                # If yes which one ? all ? and we let the algorithm resume the one of its choice in the next time step ?
-        return next_states
-
-    def update_resource_availability_simulation(
-        self, state: State, action: SchedulingAction
-    ):
-        """In a simulated scheduling environment, update resource availability for next time step.
-        This should be called after update_time()."""
-        return self.update_resource_availability(state, action)
-
-    def update_conditional_tasks(self, state: State, action: SchedulingAction):
-        """Update remaining tasks by checking conditions and potentially adding conditional tasks."""
-        return state
-
-    def update_conditional_tasks_uncertain(
-        self, states: DiscreteDistribution[State], action: SchedulingAction
-    ):
-        """Update remaining tasks by checking conditions and potentially adding conditional tasks."""
-        next_states = DiscreteDistribution(
-            [(state, prob) for (state, prob) in states.get_values()]
-        )
-
-        if action.time_progress:
-            for next_state, _ in next_states.get_values():
-                all_available_tasks = self.get_available_tasks(next_state)
-                all_considered_tasks = next_state.task_ids.difference(
-                    next_state.tasks_unsatisfiable
-                )
-                new_tasks = all_available_tasks.symmetric_difference(
-                    all_considered_tasks
-                )
-                for task in new_tasks:
-                    next_state.tasks_unsatisfiable.remove(task)
-            return next_states
-        return next_states
-
-    def update_conditional_tasks_simulation(
-        self, state: State, action: SchedulingAction
-    ):
-        """In a simulated scheduling environment, update remaining tasks by checking conditions and potentially
-        adding conditional tasks."""
-        next_state: State = state
-        next_state = self.update_conditional_tasks_uncertain(
-            states=DiscreteDistribution([(next_state, 1.0)]), action=action
-        ).sample()
-        return next_state
-
-    # WARNING : the two following functions are not required with the current signature of the Domain
-    # BUT i feel it's necessary to code it somewhere when i tested it in skdecide/hub/domain/rcpsp_pi2/rcpsp where
-    # i had to code those two functions.
-    #
-    def _get_transition_value(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-        next_state: Optional[D.T_state] = None,
-    ) -> D.T_agent[Value[D.T_value]]:
-
-        transition_makespan = 0.0
-        transition_cost = 0.0
-
-        if SchedulingObjectiveEnum.MAKESPAN in self.get_objectives():
-            transition_makespan = next_state.t - memory.t
-
-        if SchedulingObjectiveEnum.COST in self.get_objectives():
-            mode_cost_val = 0.0
-            if action.action == SchedulingActionEnum.START:
-                mode_cost_val += self.get_mode_costs()[action.task][action.mode]
-            renewable_type_cost_val = 0.0
-            nonrenewable_type_cost_val = 0.0
-            for res in self.get_resource_types_names():
-                if self.is_renewable(res):
-                    renewable_type_cost_val += (
-                        self.get_resource_cost_per_time_unit()[res]
-                        * next_state.resource_used[res]
-                    )
-                else:
-                    nonrenewable_type_cost_val += (
-                        next_state.resource_used[res] - memory.resource_used[res]
-                    )  # res used not decreased for NR resources so need to compute difference from previous state
-            renewable_unit_cost_val = 0.0
-            nonrenewable_unit_cost_val = 0.0
-            for res in self.get_resource_units_names():
-                if self.is_renewable(res):
-                    renewable_unit_cost_val += (
-                        self.get_resource_cost_per_time_unit()[res]
-                        * next_state.resource_used[res]
-                    )
-                else:
-                    nonrenewable_unit_cost_val += (
-                        next_state.resource_used[res] - memory.resource_used[res]
-                    )  # res used not decreased for NR resources so need to compute difference from previous state
-            transition_cost = (
-                mode_cost_val
-                + renewable_type_cost_val
-                + nonrenewable_type_cost_val
-                + renewable_unit_cost_val
-                + nonrenewable_unit_cost_val
-            )
-
-        # TODO: Handle more than 1 objective in the transition value (need weights ?)
-        weighed_transition_cost = 1.0 * transition_makespan + 1.0 * transition_cost
-        return Value(cost=weighed_transition_cost)
-
-    def _is_terminal(self, state: D.T_state) -> bool:
-        all_task_possible = self.all_tasks_possible(state)
-        return (
-            state.t > self.get_max_horizon()
-            or (not all_task_possible)
-            or (
-                len(state.task_ids)
-                == len(state.tasks_complete) + len(state.tasks_unsatisfiable)
-                and (len(state.tasks_ongoing) == 0)
-                and (len(state.tasks_paused) == 0)
-            )
-        )
-        # TODO, is there a cleaner way ? We can check completion of the sink task
-
-    def get_objectives(self) -> List[SchedulingObjectiveEnum]:
-        """Return the objectives to consider as a list. The items should be of SchedulingObjectiveEnum type."""
-        return self._get_objectives()
-
-    def _get_objectives(self) -> List[SchedulingObjectiveEnum]:
-        """Return the objectives to consider as a list. The items should be of SchedulingObjectiveEnum type."""
-        raise NotImplementedError
-
-
-class D_det(
-    Domain,
-    SingleAgent,
-    Sequential,
-    DeterministicTransitions,
-    DeterministicInitialized,
-    Actions,
-    FullyObservable,
-    Markovian,
-    Goals,
-):
-    """Base class for deterministic scheduling problems"""
-
-    T_state = State  # Type of states
-    T_observation = State  # Type of observations
-    T_event = SchedulingAction  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_info = (
-        None  # Type of additional information given as part of an environment outcome
-    )
-
-
-class D_uncertain(
-    Domain,
-    SingleAgent,
-    Sequential,
-    UncertainTransitions,
-    DeterministicInitialized,
-    Actions,
-    FullyObservable,
-    Markovian,
-    Goals,
-):
-    """Base class for uncertain scheduling problems where we can compute distributions"""
-
-    T_state = State  # Type of states
-    T_observation = State  # Type of observations
-    T_event = SchedulingAction  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_info = (
-        None  # Type of additional information given as part of an environment outcome
-    )
-
-
-# Specific for uncertain domain
-class UncertainSchedulingDomain(SchedulingDomain, D_uncertain):
-    """This is the highest level scheduling domain class (inheriting top-level class for each mandatory
-    domain characteristic).
-    """
-
-    def _state_sample(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_info]]:
-        """This function will be used if the domain is defined as a Simulation (i.e. transitions are defined by call to
-        a simulation). This function may also be used by simulation-based solvers on non-Simulation domains."""
-        return UncertainTransitions._state_sample(self, memory, action)
-
-
-# Specific for deterministic domain
-class DeterministicSchedulingDomain(SchedulingDomain, D_det):
-    """This is the highest level scheduling domain class (inheriting top-level class for each mandatory
-    domain characteristic).
-    """
-
-    def _state_sample(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_info]]:
-        """This function will be used if the domain is defined as a Simulation (i.e. transitions are defined by call to
-        a simulation). This function may also be used by simulation-based solvers on non-Simulation domains."""
-        return DeterministicTransitions._state_sample(self, memory, action)
-
-    def _get_next_state_distribution(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> Distribution[D.T_state]:
-        """This function will be used if the domain is defined with UncertainTransitions. This function will be ignored
-        if the domain is defined as a Simulation. This function may also be used by uncertainty-specialised solvers
-         on deterministic domains."""
-        return DeterministicTransitions._get_next_state_distribution(
-            self, memory, action
-        )
-
-
-"""
-Scheduling action space that will work for domains that don't require any
-ressource unit allocation in its formulation.
-"""
-
-
-class SchedulingActionSpace(
-    EnumerableSpace[SchedulingAction], SamplableSpace[SchedulingAction]
-):
-    def __init__(self, domain: SchedulingDomain, state: State):
-        self.domain = domain
-        self.state = state
-        self.elements = self._get_elements()
-
-    def _get_elements(self) -> Iterable[T]:
-        choices = [
-            SchedulingActionEnum.START,
-            SchedulingActionEnum.PAUSE,
-            SchedulingActionEnum.RESUME,
-            SchedulingActionEnum.TIME_PR,
-        ]
-        list_action = []
-        if self.domain.state_is_overconsuming(self.state):
-            choices = [
-                SchedulingActionEnum.PAUSE,
-                SchedulingActionEnum.TIME_PR,
-            ]  # we have to pause some task before doing anything
-        for choice in choices:
-            if choice == SchedulingActionEnum.START:
-                # task, mode, list of Ressources
-                task_possible_to_start: Dict[
-                    int, Dict[int, List[str]]
-                ] = self.domain.get_possible_starting_tasks(self.state)
-                list_action += [
-                    SchedulingAction(
-                        task=t,
-                        action=SchedulingActionEnum.START,
-                        mode=m,
-                        time_progress=False,
-                    )
-                    for t in task_possible_to_start
-                    for m in task_possible_to_start[t]
-                ]
-            if choice == SchedulingActionEnum.PAUSE:
-                task_possible_to_pause = self.state.tasks_ongoing
-                list_action += [
-                    SchedulingAction(
-                        task=t,
-                        action=SchedulingActionEnum.PAUSE,
-                        mode=None,
-                        time_progress=False,
-                    )
-                    for t in task_possible_to_pause
-                    if self.domain.get_task_preemptivity()[t]
-                ]
-            if choice == SchedulingActionEnum.RESUME:
-                task_possible_to_resume = self.state.tasks_paused
-                list_action += [
-                    SchedulingAction(
-                        task=t,
-                        action=SchedulingActionEnum.RESUME,
-                        mode=self.state.tasks_mode[t],
-                        time_progress=False,
-                    )
-                    for t in task_possible_to_resume
-                ]
-            if choice == SchedulingActionEnum.TIME_PR:
-                list_action.append(
-                    SchedulingAction(
-                        task=None,
-                        action=SchedulingActionEnum.TIME_PR,
-                        mode=None,
-                        time_progress=True,
-                    )
-                )
-        return list_action
-
-    def get_elements(self) -> Iterable[T]:
-        return self.elements
-
-    def sample(self) -> T:
-        return random.choice(self.elements)
-
-
-# TODO : will work well for domains where a task can be done by one ressource unit (and not a combination of ressource units)
-# In this case we can enumerate the "worker" ressource. This is the case of the MultiSkill RCPSP of the Imopse benchmark
-class SchedulingActionSpaceWithResourceUnit(
-    EnumerableSpace[SchedulingAction], SamplableSpace[SchedulingAction]
-):
-    def __init__(self, domain: SchedulingDomain, state: State):
-        self.domain = domain
-        self.state = state
-        self.elements = self._get_elements()
-
-    def _get_elements(self) -> Iterable[T]:
-        choices = [
-            SchedulingActionEnum.START,
-            SchedulingActionEnum.PAUSE,
-            SchedulingActionEnum.RESUME,
-            SchedulingActionEnum.TIME_PR,
-        ]
-        list_action = []
-        if self.domain.state_is_overconsuming(self.state):
-            choices = [
-                SchedulingActionEnum.PAUSE,
-                SchedulingActionEnum.TIME_PR,
-            ]  # we have to pause some task before doing anything
-        for choice in choices:
-            if choice == SchedulingActionEnum.START:
-                # task, mode, list of Ressources
-                task_possible_to_start: Dict[
-                    int, Dict[int, List[str]]
-                ] = self.domain.get_possible_starting_tasks(self.state)
-                for possible_to_start in task_possible_to_start:
-                    for mode in task_possible_to_start[possible_to_start]:
-                        possible = self.domain.find_one_ressource_to_do_one_task(
-                            task=possible_to_start, mode=mode
-                        )
-                        list_action += [
-                            SchedulingAction(
-                                task=possible_to_start,
-                                action=SchedulingActionEnum.START,
-                                mode=mode,
-                                time_progress=False,
-                                resource_unit_names={r} if r is not None else None,
-                            )
-                            for r in possible
-                            if r is None
-                            or self.state.resource_used[r] + 1
-                            <= self.state.resource_availability[r]
-                        ]
-
-            if choice == SchedulingActionEnum.PAUSE:
-                task_possible_to_pause = self.state.tasks_ongoing
-                list_action += [
-                    SchedulingAction(
-                        task=t,
-                        action=SchedulingActionEnum.PAUSE,
-                        mode=None,
-                        time_progress=False,
-                    )
-                    for t in task_possible_to_pause
-                    if self.domain.get_task_preemptivity()[t]
-                ]
-            if choice == SchedulingActionEnum.RESUME:
-                task_possible_to_resume = self.state.tasks_paused
-
-                for possible_to_resume in task_possible_to_resume:
-                    possible = self.domain.find_one_ressource_to_do_one_task(
-                        task=possible_to_resume,
-                        mode=self.state.tasks_mode[possible_to_resume],
-                    )
-
-                    list_action += [
-                        SchedulingAction(
-                            task=possible_to_resume,
-                            action=SchedulingActionEnum.START,
-                            mode=self.state.tasks_mode[possible_to_resume],
-                            time_progress=False,
-                            resource_unit_names={r} if r is not None else None,
-                        )
-                        for r in possible
-                        if r is None
-                        or self.state.resource_used[r] + 1
-                        <= self.state.resource_availability[r]
-                    ]
-            if choice == SchedulingActionEnum.TIME_PR:
-                list_action.append(
-                    SchedulingAction(
-                        task=None,
-                        action=SchedulingActionEnum.TIME_PR,
-                        mode=None,
-                        time_progress=True,
-                    )
-                )
-        return list_action
-
-    def get_elements(self) -> Iterable[T]:
-        return self.elements
-
-    def sample(self) -> T:
-        return random.choice(self.elements)
-
-
-class SchedulingActionSpaceWithResourceUnitSamplable(SamplableSpace[SchedulingAction]):
-    def __init__(self, domain: SchedulingDomain, state: State):
-        self.domain = domain
-        self.state = state
-
-    def sample(self) -> T:
-        choices = [
-            SchedulingActionEnum.START,
-            SchedulingActionEnum.PAUSE,
-            SchedulingActionEnum.RESUME,
-            SchedulingActionEnum.TIME_PR,
-        ]
-        if self.domain.state_is_overconsuming(self.state):
-            choices = [
-                SchedulingActionEnum.PAUSE
-            ]  # we have to pause some task before doing anything
-        random_choice = random.choice(choices)
-        if random_choice in {SchedulingActionEnum.START, SchedulingActionEnum.RESUME}:
-            if random_choice == SchedulingActionEnum.START:
-                task_possible_to_start: Dict[
-                    int, Dict[int, List[str]]
-                ] = self.domain.get_possible_starting_tasks(self.state)
-            else:
-                task_possible_to_start: Dict[
-                    int, Dict[int, List[str]]
-                ] = self.domain.get_possible_resume_tasks(self.state)
-            task_modes = [
-                (t, m)
-                for t in task_possible_to_start
-                for m in task_possible_to_start[t]
-            ]
-            if len(task_modes) > 0:
-                random_ch = random.choice(task_modes)
-                possible_to_start = random_ch[0]
-                mode = random_ch[1]
-                skill_of_task = self.domain.get_skills_of_task(possible_to_start, mode)
-                resources = []
-                if len(skill_of_task) == 0:
-                    return SchedulingAction(
-                        task=possible_to_start,
-                        action=random_choice,
-                        mode=mode,
-                        time_progress=False,
-                    )
-                resources_skills = list(self.domain.get_all_resources_skills().keys())
-                random.shuffle(resources_skills)
-                cur_usage = {s: 0 for s in skill_of_task}
-                success = False
-                for resource in resources_skills:
-                    if (
-                        self.state.resource_used[resource] + 1
-                        > self.state.resource_availability[resource]
-                    ):
-                        continue
-                    if any(
-                        self.domain.get_skills_of_resource(resource=resource).get(s, 0)
-                        > 0
-                        for s in skill_of_task
-                    ):
-                        resources += [resource]
-                        for s in cur_usage:
-                            cur_usage[s] += self.domain.get_skills_of_resource(
-                                resource=resource
-                            ).get(s, 0)
-                        if all(cur_usage[s] >= skill_of_task[s] for s in skill_of_task):
-                            success = True
-                            break
-                if success:
-                    return SchedulingAction(
-                        task=possible_to_start,
-                        action=random_choice,
-                        mode=mode,
-                        time_progress=False,
-                        resource_unit_names=resources,
-                    )
-                else:
-                    return SchedulingAction(
-                        task=None,
-                        action=SchedulingActionEnum.TIME_PR,
-                        mode=None,
-                        time_progress=True,
-                    )
-            else:
-                return SchedulingAction(
-                    task=None,
-                    action=SchedulingActionEnum.TIME_PR,
-                    mode=None,
-                    time_progress=True,
-                )
-
-        if random_choice == SchedulingActionEnum.PAUSE:
-            task_possible_to_pause = [
-                t
-                for t in self.state.tasks_ongoing
-                if self.domain.get_task_preemptivity()[t]
-            ]
-            if len(task_possible_to_pause) > 0:
-                return SchedulingAction(
-                    task=random.choice(task_possible_to_pause),
-                    action=SchedulingActionEnum.PAUSE,
-                    mode=None,
-                    time_progress=False,
-                )
-            else:
-
-                return SchedulingAction(
-                    task=None,
-                    action=SchedulingActionEnum.TIME_PR,
-                    mode=None,
-                    time_progress=True,
-                )
-
-        if random_choice == SchedulingActionEnum.TIME_PR:
-            return SchedulingAction(
-                task=None,
-                action=SchedulingActionEnum.TIME_PR,
-                mode=None,
-                time_progress=True,
-            )
-
-    def contains(self, x: T) -> bool:
-        return True
-
-
-class SingleModeRCPSP(
-    DeterministicSchedulingDomain,
-    SingleMode,
-    DeterministicTaskDuration,
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    WithoutResourceAvailabilityChange,
-    WithoutConditionalTasks,
-    RenewableOnly,
-    ConstantResourceConsumption,  # problem with unimplemented classes with this
-    WithoutPreemptivity,  # problem with unimplemented classes with this
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class SingleModeRCPSPCalendar(
-    DeterministicSchedulingDomain,
-    SingleMode,
-    DeterministicTaskDuration,
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    # WithoutResourceAvailabilityChange,
-    DeterministicResourceAvailabilityChanges,
-    WithoutConditionalTasks,
-    RenewableOnly,
-    ConstantResourceConsumption,  # problem with unimplemented classes with this
-    WithoutPreemptivity,  # problem with unimplemented classes with this
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class MultiModeRCPSP(
-    DeterministicSchedulingDomain,
-    MultiMode,  # this changed from Single mode RCPSP
-    DeterministicTaskDuration,
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    WithoutResourceAvailabilityChange,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    MixedRenewable,  # this changed from Single mode RCPSP
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class MultiModeRCPSPWithCost(
-    DeterministicSchedulingDomain,
-    MultiMode,
-    DeterministicTaskDuration,
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    WithoutResourceAvailabilityChange,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    MixedRenewable,
-    WithModeCosts,
-    WithResourceCosts,
-):
-    pass
-
-
-class MultiModeRCPSPCalendar(
-    DeterministicSchedulingDomain,
-    MultiMode,  # this changed from Single mode RCPSP
-    DeterministicTaskDuration,
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    # WithoutResourceAvailabilityChange,
-    DeterministicResourceAvailabilityChanges,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    MixedRenewable,  # this changed from Single mode RCPSP
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class MultiModeRCPSPCalendar_Stochastic_Durations(
-    UncertainSchedulingDomain,
-    MultiMode,  # this changed from Single mode RCPSP
-    UncertainUnivariateTaskDuration,
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    # WithoutResourceAvailabilityChange,
-    DeterministicResourceAvailabilityChanges,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    MixedRenewable,  # this changed from Single mode RCPSP
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class MultiModeMultiSkillRCPSP(
-    DeterministicSchedulingDomain,
-    MultiMode,
-    DeterministicTaskDuration,
-    DeterministicTaskProgress,
-    # WithResourceUnits,
-    # WithResourceTypes,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    # WithResourceSkills, # This change from MultiModeRCPSP
-    WithoutResourceAvailabilityChange,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    MixedRenewable,
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class MultiModeMultiSkillRCPSPCalendar(
-    DeterministicSchedulingDomain,
-    MultiMode,
-    DeterministicTaskDuration,
-    DeterministicTaskProgress,
-    # WithResourceUnits,
-    # WithResourceTypes,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    # WithResourceSkills, # This change from MultiModeRCPSP
-    # WithoutResourceAvailabilityChange,
-    DeterministicResourceAvailabilityChanges,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    MixedRenewable,
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class MultiModeRCPSP_Stochastic_Durations(
-    UncertainSchedulingDomain,
-    UncertainUnivariateTaskDuration,  # this changed from Single mode RCPSP
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    WithoutResourceAvailabilityChange,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    RenewableOnly,
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class SingleModeRCPSP_Stochastic_Durations(
-    UncertainSchedulingDomain,
-    SingleMode,
-    UncertainUnivariateTaskDuration,  # this changed from Single mode RCPSP
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    WithoutResourceAvailabilityChange,
-    WithoutConditionalTasks,
-    ConstantResourceConsumption,
-    RenewableOnly,
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class SingleModeRCPSP_Stochastic_Durations_WithConditionalTasks(
-    UncertainSchedulingDomain,
-    SingleMode,
-    UncertainUnivariateTaskDuration,  # this changed from Single mode RCPSP
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    WithoutResourceAvailabilityChange,
-    # WithConditionalTasks,
-    ConstantResourceConsumption,
-    RenewableOnly,
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
-
-
-class SingleModeRCPSP_Simulated_Stochastic_Durations_WithConditionalTasks(
-    SchedulingDomain,
-    SingleMode,
-    # SimulatedTaskDuration,
-    DeterministicTaskProgress,
-    WithoutResourceUnit,
-    WithoutPreemptivity,
-    WithoutPreallocations,
-    WithoutTimeLag,
-    WithoutTimeWindow,
-    WithoutResourceSkills,
-    WithoutResourceAvailabilityChange,
-    # WithConditionalTasks,
-    ConstantResourceConsumption,
-    RenewableOnly,
-    WithoutModeCosts,
-    WithoutResourceCosts,
-):
-    pass
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import random
+from enum import Enum
+from itertools import product
+from typing import Dict, Iterable, List, Optional, Set, Tuple
+
+from skdecide import (
+    DiscreteDistribution,
+    Distribution,
+    Domain,
+    EnumerableSpace,
+    ImplicitSpace,
+    SamplableSpace,
+    Space,
+    T,
+    TransitionOutcome,
+    Value,
+)
+from skdecide.builders.domain import (
+    Actions,
+    DeterministicInitialized,
+    DeterministicTransitions,
+    FullyObservable,
+    Goals,
+    Markovian,
+    Sequential,
+    Simulation,
+    SingleAgent,
+    UncertainTransitions,
+)
+from skdecide.builders.domain.scheduling.conditional_tasks import (
+    WithConditionalTasks,
+    WithoutConditionalTasks,
+)
+from skdecide.builders.domain.scheduling.graph_toolbox import Graph
+from skdecide.builders.domain.scheduling.modes import MultiMode, SingleMode
+from skdecide.builders.domain.scheduling.preallocations import (
+    WithoutPreallocations,
+    WithPreallocations,
+)
+from skdecide.builders.domain.scheduling.precedence import WithPrecedence
+from skdecide.builders.domain.scheduling.preemptivity import (
+    WithoutPreemptivity,
+    WithPreemptivity,
+)
+from skdecide.builders.domain.scheduling.resource_availability import (
+    DeterministicResourceAvailabilityChanges,
+    UncertainResourceAvailabilityChanges,
+    WithoutResourceAvailabilityChange,
+)
+from skdecide.builders.domain.scheduling.resource_consumption import (
+    ConstantResourceConsumption,
+    VariableResourceConsumption,
+)
+from skdecide.builders.domain.scheduling.resource_costs import (
+    WithModeCosts,
+    WithoutModeCosts,
+    WithoutResourceCosts,
+    WithResourceCosts,
+)
+from skdecide.builders.domain.scheduling.resource_renewability import (
+    MixedRenewable,
+    RenewableOnly,
+)
+from skdecide.builders.domain.scheduling.resource_type import (
+    WithoutResourceUnit,
+    WithResourceTypes,
+    WithResourceUnits,
+)
+from skdecide.builders.domain.scheduling.scheduling_domains_modelling import (
+    SchedulingAction,
+    SchedulingActionEnum,
+    State,
+)
+from skdecide.builders.domain.scheduling.skills import (
+    WithoutResourceSkills,
+    WithResourceSkills,
+)
+from skdecide.builders.domain.scheduling.task import Task
+from skdecide.builders.domain.scheduling.task_duration import (
+    DeterministicTaskDuration,
+    SimulatedTaskDuration,
+    UncertainUnivariateTaskDuration,
+)
+from skdecide.builders.domain.scheduling.task_progress import (
+    CustomTaskProgress,
+    DeterministicTaskProgress,
+)
+from skdecide.builders.domain.scheduling.time_lag import WithoutTimeLag, WithTimeLag
+from skdecide.builders.domain.scheduling.time_windows import (
+    WithoutTimeWindow,
+    WithTimeWindow,
+)
+
+
+class SchedulingObjectiveEnum(Enum):
+    """Enum defining the different scheduling objectives"""
+
+    MAKESPAN = 0
+    COST = 1
+
+
+SchedulingObjectiveEnum.MAKESPAN.__doc__ = "makespan (to be minimized)"
+SchedulingObjectiveEnum.COST.__doc__ = "cost of resources (to be minimized)"
+
+
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    Simulation,
+    DeterministicInitialized,
+    Actions,
+    FullyObservable,
+    Markovian,
+    Goals,
+):
+    """
+    Base class for any scheduling statefull domain
+    """
+
+    T_state = State  # Type of states
+    T_observation = State  # Type of observations
+    T_event = SchedulingAction  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_info = (
+        None  # Type of additional information given as part of an environment outcome
+    )
+
+
+class SchedulingDomain(
+    WithPrecedence,
+    MultiMode,
+    VariableResourceConsumption,
+    WithPreemptivity,
+    WithResourceTypes,
+    WithResourceUnits,
+    MixedRenewable,
+    SimulatedTaskDuration,
+    CustomTaskProgress,
+    WithResourceSkills,
+    WithTimeLag,
+    WithTimeWindow,
+    WithPreallocations,
+    WithConditionalTasks,
+    UncertainResourceAvailabilityChanges,
+    WithModeCosts,
+    WithResourceCosts,
+    D,
+):
+    """
+    This is the highest level scheduling domain class (inheriting top-level class for each mandatory
+    domain characteristic).
+    This is where the implementation of the statefull scheduling domain is implemented,
+    letting to the user the possibility
+    to the user to define the scheduling problem without having to think of a statefull version.
+    """
+
+    def _state_sample(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_info]]:
+        """This function will be used if the domain is defined as a Simulation (i.e. transitions are defined by call to
+        a simulation). This function may also be used by simulation-based solvers on non-Simulation domains."""
+        current_state: State = memory
+        next_state = current_state if self.inplace_environment else current_state.copy()
+        next_state = self.update_pause_tasks_simulation(next_state, action)
+        next_state = self.update_resume_tasks_simulation(next_state, action)
+        next_state = self.update_start_tasks_simulation(next_state, action)
+        next_state = self.update_complete_dummy_tasks_simulation(next_state, action)
+        next_state = self.update_conditional_tasks_simulation(next_state, action)
+        next_state = self.update_time_simulation(next_state, action)
+        next_state = self.update_resource_availability_simulation(next_state, action)
+        is_terminal = self._is_terminal(next_state)
+        is_goal = self._is_goal(next_state)
+        return TransitionOutcome(
+            state=next_state,
+            value=self._get_transition_value(memory, action, next_state),
+            termination=is_goal or is_terminal,
+            info=None,
+        )
+
+    def _get_next_state_distribution(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> Distribution[D.T_state]:
+        """This function will be used if the domain is defined with UncertainTransitions. This function will be ignored
+        if the domain is defined as a Simulation. This function may also be used by uncertainty-specialised solvers
+         on deterministic domains."""
+        current_state: State = memory
+        next_state = current_state if self.inplace_environment else current_state.copy()
+        next_state = self.update_pause_tasks_uncertain(next_state, action)
+        next_state = self.update_resume_tasks_uncertain(next_state, action)
+        next_state_distrib = self.update_start_tasks_uncertain(next_state, action)
+        next_state_distrib = self.update_complete_dummy_tasks_uncertain(
+            next_state_distrib, action
+        )
+        next_state_distrib = self.update_conditional_tasks_uncertain(
+            next_state_distrib, action
+        )
+        next_state_distrib = self.update_time_uncertain(next_state_distrib, action)
+        next_state_distrib = self.update_resource_availability_uncertain(
+            next_state_distrib, action
+        )  # maybe this should be done after self.update_time too ??
+        return next_state_distrib
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        """
+        This function will be used if the domain is defined with DeterministicTransitions. This function will be ignored
+        if the domain is defined as having UncertainTransitions or Simulation."""
+        current_state: State = memory
+        next_state = current_state if self.inplace_environment else current_state.copy()
+        next_state = self.update_pause_tasks(next_state, action)
+        next_state = self.update_resume_tasks(next_state, action)
+        next_state = self.update_start_tasks(next_state, action)
+        next_state = self.update_complete_dummy_tasks(next_state, action)
+        next_state = self.update_conditional_tasks(next_state, action)
+        next_state = self.update_time(next_state, action)
+        next_state = self.update_resource_availability(
+            next_state, action
+        )  # maybe this should be done after self.update_time too ??
+
+        return next_state
+
+    def _get_initial_state_(self) -> D.T_state:
+        """
+        Create and return an empty initial state
+        """
+        s = State(
+            task_ids=self.get_tasks_ids(),
+            tasks_available=self.get_all_unconditional_tasks(),
+        )
+        s.t = 0
+        resource_availability = {
+            r: self.sample_quantity_resource(resource=r, time=s.t)
+            for r in self.get_resource_types_names()
+        }
+        resource_availability.update(
+            {
+                runit: self.sample_quantity_resource(resource=runit, time=s.t)
+                for runit in self.get_resource_units_names()
+            }
+        )
+        s.resource_availability = resource_availability
+        s.resource_used = {r: 0 for r in s.resource_availability}
+        return s
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        """
+        To be implemented if needed one day.
+        """
+        pass
+
+    def _get_applicable_actions_from(
+        self, memory: D.T_memory[D.T_state]
+    ) -> D.T_agent[Space[D.T_event]]:
+        """
+        Returns the action space from a state.
+        TODO : think about a way to avoid the instaceof usage.
+        """
+        if isinstance(self, WithoutResourceSkills) and isinstance(
+            self, WithoutResourceUnit
+        ):
+            return SchedulingActionSpace(domain=self, state=memory)
+        else:
+            # return SchedulingActionSpaceWithResourceUnit(domain=self, state=memory)
+            return SchedulingActionSpaceWithResourceUnitSamplable(
+                domain=self, state=memory
+            )
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        """
+        To be implemented if needed one day.
+        """
+        pass
+
+    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
+        return ImplicitSpace(
+            lambda state: (
+                len(state.task_ids)
+                == len(state.tasks_complete) + len(state.tasks_unsatisfiable)
+                and (len(state.tasks_ongoing) == 0)
+                and (len(state.tasks_paused) == 0)
+            )
+        )
+
+    def get_max_horizon(self) -> int:
+        """Return the maximum time horizon (int)"""
+        return self._get_max_horizon()
+
+    def _get_max_horizon(self) -> int:
+        """Return the maximum time horizon (int)"""
+        raise NotImplementedError
+
+    def initialize_domain(self):
+        """Initialize a scheduling domain. This function needs to be called when instantiating a scheduling domain."""
+        self.sampled_durations = {}  # TODO : remove ?
+        self.graph = (
+            self.compute_graph()
+        )  # TODO : this is very specific to the precendence caracteristic,
+        # should it be done there ?
+        self.ancestors = self.graph.predecessors_map()
+        self.successors = self.graph.successors_map()
+        self.full_predecessors = self.graph.ancestors_map()
+        self.full_successors = self.graph.descendants_map()
+        self.inplace_environment = False
+
+    def set_inplace_environment(self, inplace_environment: bool):
+        """
+        Activate or not the fact that the simulator modifies the given state inplace or create a copy before.
+        The inplace version is several times faster but will lead to bugs in graph search solver.
+        """
+        self.inplace_environment = inplace_environment
+
+    # Build the precedence graph.
+    # TODO : maybe this function should be in the precedence module.
+    def compute_graph(self):
+        task_ids = self.get_tasks_ids()
+        successors = self.get_successors()
+        mode_details = self.get_tasks_modes()
+        nodes = [
+            (
+                n,
+                {
+                    mode: self.sample_task_duration(task=n, mode=mode)
+                    for mode in mode_details[n]
+                },
+            )
+            for n in task_ids
+        ]
+        edges = []
+        for n in successors:
+            for succ in successors[n]:
+                edges += [(n, succ, {})]
+        return Graph(nodes, edges, False)
+
+    def update_time(self, state: State, action: SchedulingAction):
+        """Update the time of the state if the time_progress attribute of the given EnumerableAction is True."""
+        next_state = state  # .copy()
+        if action.time_progress:
+            next_state = self.update_progress(next_state)
+            next_state = self.update_res_consumption(next_state)
+            next_state = self.update_complete_tasks(next_state)
+            next_state.t = state.t + 1
+        return next_state
+
+    def update_time_uncertain(
+        self, states: DiscreteDistribution[State], action: SchedulingAction
+    ):
+        """Update the time of the state if the time_progress attribute of the given EnumerableAction is True."""
+        next_states = DiscreteDistribution(
+            [(state, prob) for (state, prob) in states.get_values()]
+        )
+        if action.time_progress:
+            next_states = self.update_progress_uncertain(next_states)
+            next_states = self.update_res_consumption_uncertain(next_states)
+            next_states = self.update_complete_tasks_uncertain(next_states)
+            for next_state, _ in next_states.get_values():
+                next_state.t = next_state.t + 1
+        return next_states
+
+    def update_time_simulation(self, state: State, action: SchedulingAction):
+        """In a simulated scheduling environment, update the time of the state if the time_progress attribute of the
+        given EnumerableAction is True."""
+        next_state = state  # .copy()
+        if action.time_progress:
+            next_state = self.update_progress_simulation(next_state)
+            next_state = self.update_res_consumption_simulation(next_state)
+            next_state = self.update_complete_tasks_simulation(next_state)
+            next_state.t = state.t + 1
+        return next_state
+
+    def update_res_consumption(self, state: State):
+        # TODO : test this.
+        next_state = state  # .copy()
+        for task_id in state.tasks_ongoing:
+            resource_to_use = self.get_resource_used(
+                task=task_id,
+                mode=state.tasks_mode[task_id],
+                resource_unit_names=set(),
+                time_since_start=state.tasks_details[task_id].get_task_active_time(
+                    state.t + 1
+                ),
+            )
+            for r in resource_to_use:
+                prev = next_state.resource_used_for_task[task_id][r]
+                new = resource_to_use[r]
+                next_state.resource_used_for_task[task_id][r] = resource_to_use[r]
+                next_state.resource_used[r] += new - prev
+        return next_state
+
+    def update_res_consumption_uncertain(self, states: DiscreteDistribution[State]):
+        next_states = DiscreteDistribution(
+            [(state, prob) for (state, prob) in states.get_values()]
+        )
+
+        for next_state, _ in next_states.get_values():
+            for task_id in next_state.tasks_ongoing:
+                resource_to_use = self.get_resource_used(
+                    task=task_id,
+                    mode=next_state.tasks_mode[task_id],
+                    resource_unit_names=set(),
+                    time_since_start=next_state.tasks_details[
+                        task_id
+                    ].get_task_active_time(next_state.t + 1),
+                )
+                for r in resource_to_use:
+                    prev = next_state.resource_used_for_task[task_id][r]
+                    new = resource_to_use[r]
+                    next_state.resource_used_for_task[task_id][r] = resource_to_use[r]
+                    next_state.resource_used[r] += new - prev
+
+        return next_states
+
+    def update_res_consumption_simulation(self, state: State):
+        return self.update_res_consumption(state)
+
+    def update_progress(self, state: State):
+        """Update the progress of all ongoing tasks in the state."""
+        next_state = state  # .copy()
+        for task_id in next_state.tasks_ongoing:
+            # TODO : update the resource used dictionnary also, for the task that consumes a varying number
+            # of ressource
+            next_state.tasks_progress[task_id] += self.get_task_progress(
+                task_id,
+                t_from=next_state.t,
+                t_to=next_state.t + 1,
+                mode=next_state.tasks_mode[task_id],
+                sampled_duration=next_state.tasks_details[task_id].sampled_duration,
+            )
+        return next_state
+
+    def update_progress_uncertain(self, states: DiscreteDistribution[State]):
+        """In an uncertain scheduling environment, update the progress of all ongoing tasks in the state."""
+        next_states = DiscreteDistribution(
+            [(state, prob) for (state, prob) in states.get_values()]
+        )
+
+        for next_state, _ in next_states.get_values():
+            for task_id in next_state.tasks_ongoing:
+                # TODO : update the resource used dictionnary also, for the task that consumes a varying number
+                # of ressource
+                next_state.tasks_progress[task_id] += self.get_task_progress(
+                    task_id,
+                    t_from=next_state.t,
+                    t_to=next_state.t + 1,
+                    mode=next_state.tasks_mode[task_id],
+                    sampled_duration=next_state.tasks_details[task_id].sampled_duration,
+                )
+        return next_states
+
+    def update_progress_simulation(self, state: State):
+        """In a simulation scheduling environment, update the progress of all ongoing tasks in the state."""
+        return self.update_progress(state)
+
+    def update_complete_tasks(self, state: State):
+        """Update the status of newly completed tasks in the state from ongoing to complete
+        and update resource availability. This function will also log in task_details the time it was complete"""
+        next_state = state  # .copy()
+        completed_tmp = []
+        for task_id in next_state.tasks_ongoing:
+            if next_state.tasks_progress[task_id] >= 0.9999:
+                next_state.tasks_progress[task_id] = 1
+                completed_tmp.append(task_id)
+        for completed_task in completed_tmp:
+            next_state.tasks_complete.add(completed_task)
+            next_state.tasks_ongoing.remove(completed_task)
+            for res in next_state.resource_used_for_task[completed_task]:
+                res_consumption = next_state.resource_used_for_task[completed_task][res]
+                if self.is_renewable(res):
+                    next_state.resource_used[res] -= res_consumption
+            next_state.resource_used_for_task.pop(completed_task)
+            next_state.tasks_details[completed_task].end = next_state.t + 1
+            # WARNING : considering how it's coded, we should put +1 here. could be ccleaner if it was done in the update_progress.
+            next_state.tasks_complete_details.push_front(
+                next_state.tasks_details[completed_task]
+            )
+            del next_state.tasks_details[completed_task]
+            next_state.tasks_complete_progress.push_front(
+                next_state.tasks_progress[completed_task]
+            )
+            del next_state.tasks_progress[completed_task]
+            next_state.tasks_complete_mode.push_front(
+                (completed_task, next_state.tasks_mode[completed_task])
+            )
+            del next_state.tasks_mode[completed_task]
+
+        return next_state
+
+    def update_complete_tasks_uncertain(self, states: DiscreteDistribution[State]):
+        """In an uncertain scheduling environment, update the status of newly completed tasks in the state from ongoing
+        to complete, update resource availability and update on-completion conditions.
+        This function will also log in task_details the time it was complete."""
+        next_states = DiscreteDistribution(
+            [(state, prob) for (state, prob) in states.get_values()]
+        )
+
+        states_and_proba = []
+        for next_state, _ in next_states.get_values():
+            completed_tmp = []
+            for task_id in next_state.tasks_ongoing:
+                if next_state.tasks_progress[task_id] >= 0.9999:
+                    next_state.tasks_progress[task_id] = 1
+                    completed_tmp.append(task_id)
+
+            all_values = []
+            all_models = {}
+            for completed_task in completed_tmp:
+                next_state.tasks_complete.add(completed_task)
+                next_state.tasks_ongoing.remove(completed_task)
+                for res in next_state.resource_used_for_task[completed_task]:
+                    res_consumption = next_state.resource_used_for_task[completed_task][
+                        res
+                    ]
+                    if self.is_renewable(res):
+                        next_state.resource_used[res] -= res_consumption
+                next_state.resource_used_for_task.pop(completed_task)
+                next_state.tasks_details[completed_task].end = (
+                    next_state.t + 1
+                )  # WARNING : considering how it's coded, we should put +1 here.
+                next_state.tasks_complete_details.push_front(
+                    next_state.tasks_details[completed_task]
+                )
+                del next_state.tasks_details[completed_task]
+                next_state.tasks_complete_progress.push_front(
+                    next_state.tasks_progress[completed_task]
+                )
+                del next_state.tasks_progress[completed_task]
+                next_state.tasks_complete_mode.push_front(
+                    (completed_task, next_state.tasks_mode[completed_task])
+                )
+                del next_state.tasks_mode[completed_task]
+                if completed_task in self.get_task_on_completion_added_conditions():
+                    all_models[completed_task] = []
+                    for i in range(
+                        len(
+                            self.get_task_on_completion_added_conditions()[
+                                completed_task
+                            ]
+                        )
+                    ):
+                        for j in range(
+                            len(
+                                self.get_task_on_completion_added_conditions()[
+                                    completed_task
+                                ][i].get_values()
+                            )
+                        ):
+                            all_values.append(
+                                {
+                                    "task": completed_task,
+                                    "cond": self.get_task_on_completion_added_conditions()[
+                                        completed_task
+                                    ][
+                                        i
+                                    ].get_values()[
+                                        j
+                                    ][
+                                        0
+                                    ],
+                                    "prob": self.get_task_on_completion_added_conditions()[
+                                        completed_task
+                                    ][
+                                        i
+                                    ].get_values()[
+                                        j
+                                    ][
+                                        1
+                                    ],
+                                }
+                            )
+                            all_models[completed_task].append(len(all_values) - 1)
+
+            combinations = list(product(*all_models.values()))
+            # for comb in combinations:
+            #     next_state_2 = next_state.copy()
+            #     proba = 1.
+            #     for i in comb:
+            #         next_state_2._current_conditions.add(all_values[i]['cond'])
+            #         proba *= all_values[i]['prob']
+            #     states_and_proba += [(next_state_2, proba)]
+            for comb in combinations:
+                do_copy = len(comb) > 0
+                next_state_2 = next_state.copy() if do_copy else next_state
+                proba = 1.0
+                for i in comb:
+                    next_state_2._current_conditions.add(all_values[i]["cond"])
+                    proba *= all_values[i]["prob"]
+                states_and_proba += [(next_state_2, proba)]
+        return DiscreteDistribution(states_and_proba)
+
+    def update_complete_tasks_simulation(self, state: State):
+        """In a simulated scheduling environment, update the status of newly completed tasks in the state from ongoing to complete
+        and update resource availability. This function will also log in task_details the time it was complete"""
+        next_state: State = state
+        next_state = self.update_complete_tasks_uncertain(
+            states=DiscreteDistribution([(next_state, 1.0)])
+        ).sample()
+        return next_state
+
+    def update_complete_dummy_tasks(self, state: State, action: SchedulingAction):
+        """Update the status of newly started tasks whose duration is 0 from ongoing to complete."""
+        next_state = state  # .copy()
+        if action.action == SchedulingActionEnum.START:
+            task = action.task
+            if next_state.tasks_details[task].sampled_duration == 0:
+                next_state.tasks_complete.add(task)
+                next_state.tasks_progress[task] = 1
+                next_state.tasks_ongoing.remove(task)
+                next_state.tasks_details[task].end = next_state.t
+                next_state.tasks_complete_details.push_front(
+                    next_state.tasks_details[task]
+                )
+                del next_state.tasks_details[task]
+                next_state.tasks_complete_progress.push_front(
+                    next_state.tasks_progress[task]
+                )
+                del next_state.tasks_progress[task]
+                next_state.tasks_complete_mode.push_front(
+                    (task, next_state.tasks_mode[task])
+                )
+                del next_state.tasks_mode[task]
+                next_state.resource_used_for_task.pop(task)
+        return next_state
+
+    def update_complete_dummy_tasks_uncertain(
+        self, states: DiscreteDistribution[State], action: SchedulingAction
+    ):
+        """In an uncertain scheduling environment, update the status of newly started tasks whose duration is 0
+        from ongoing to complete."""
+        next_states = DiscreteDistribution(
+            [(state, prob) for (state, prob) in states.get_values()]
+        )
+        if action.action == SchedulingActionEnum.START:
+            task = action.task
+            for next_state, _ in next_states.get_values():
+                if next_state.tasks_details[task].sampled_duration == 0:
+                    next_state.tasks_complete.add(task)
+                    next_state.tasks_progress[task] = 1
+                    next_state.tasks_ongoing.remove(task)
+                    next_state.tasks_details[task].end = next_state.t
+                    next_state.tasks_complete_details.push_front(
+                        next_state.tasks_details[task]
+                    )
+                    del next_state.tasks_details[task]
+                    next_state.tasks_complete_progress.push_front(
+                        next_state.tasks_progress[task]
+                    )
+                    del next_state.tasks_progress[task]
+                    next_state.tasks_complete_mode.push_front(
+                        (task, next_state.tasks_mode[task])
+                    )
+                    del next_state.tasks_mode[task]
+                    next_state.resource_used_for_task.pop(task)
+        return next_states
+
+    def update_complete_dummy_tasks_simulation(
+        self, state: State, action: SchedulingAction
+    ):
+        """In a simulated scheduling environment, update the status of newly started tasks whose duration is 0
+        from ongoing to complete."""
+        return self.update_complete_dummy_tasks(state, action)
+
+    def update_pause_tasks(self, state: State, action: SchedulingAction):
+        """Update the status of a task from ongoing to paused if specified in the action
+        and update resource availability. This function will also log in task_details the time it was paused."""
+        next_state = state  # .copy()
+        if action.action == SchedulingActionEnum.PAUSE:
+            paused_task = action.task
+            next_state.tasks_paused.add(paused_task)
+            next_state.tasks_ongoing.remove(paused_task)
+            # time_since_start = next_state.tasks_details[paused_task].get_task_active_time(next_state.t)
+            for res in next_state.resource_used_for_task[paused_task]:
+                res_consumption = next_state.resource_used_for_task[paused_task][res]
+                if self.is_renewable(res) or (
+                    not self.is_renewable(res)
+                    and self.get_task_paused_non_renewable_resource_returned()[res]
+                ):
+                    next_state.resource_used[res] -= res_consumption
+            next_state.resource_used_for_task.pop(paused_task)
+            next_state.tasks_details[paused_task].paused.append(next_state.t)
+            # Need to call this after get_task_active_time()
+        return next_state
+
+    def update_pause_tasks_uncertain(self, state: State, action: SchedulingAction):
+        """In an uncertain scheduling environment, update the status of a task from ongoing to paused if
+        specified in the action and update resource availability. This function will also log in task_details
+        the time it was paused."""
+        return self.update_pause_tasks(state, action)
+
+    def update_pause_tasks_simulation(self, state: State, action: SchedulingAction):
+        """In a simulation scheduling environment, update the status of a task from ongoing to paused if
+        specified in the action and update resource availability. This function will also log in task_details
+        the time it was paused."""
+        return self.update_pause_tasks(state, action)
+
+    def update_resume_tasks(self, state: State, action: SchedulingAction):
+        """Update the status of a task from paused to ongoing if specified in the action
+        and update resource availability. This function will also log in task_details the time it was resumed"""
+        next_state = state  # .copy()
+        if action.action == SchedulingActionEnum.RESUME:
+            resumed_task = action.task
+            mode = action.mode  # use mode specified in action if any
+            if mode is None:
+                mode = state.tasks_mode[resumed_task]  # or use previous mode
+            next_state.tasks_ongoing.add(resumed_task)
+            next_state.tasks_paused.remove(resumed_task)
+            next_state.tasks_details[resumed_task].resumed.append(
+                next_state.t
+            )  # Need to call this before get_task_active_time()
+            b, resource_to_use = self.check_if_action_can_be_started(
+                next_state, action=action
+            )
+            if not b:
+                return next_state
+            for res in resource_to_use:
+                next_state.resource_used[res] += resource_to_use[res]
+            next_state.resource_used_for_task[resumed_task] = resource_to_use
+            # self.get_latest_sampled_duration(task=resumed_task , mode=mode,
+            #                                 progress_from=next_state.tasks_progress[resumed_task])  # TODO: what to do with this, so far the sample is stored and then used by get_task_progress()
+            # Out of scope normally, there shouldn't be a "get_resource_need_at_time" function
+            # for ressource unit, or it doesn't make completely sense as of today
+            # for res in self.get_resource_units_names():
+            #     res_consumption = self.get_tasks_modes()[resumed_task][next_state.tasks_mode[resumed_task]]\
+            #         .get_resource_need_at_time(resource_name=res, time=time_since_start)
+            #     # next_state.resource_availability[res] -= res_consumption
+            #     next_state.resource_used[res] += res_consumption
+            #     if resumed_task not in next_state.resource_used_for_task:
+            #         next_state.resource_used_for_task[resumed_task] = {}
+            #     next_state.resource_used_for_task[resumed_task][res] = res_consumption
+            # for res in self.get_resource_types_names():
+            #     res_consumption = self.get_tasks_modes()[resumed_task][next_state.tasks_mode[resumed_task]]\
+            #         .get_resource_need_at_time(resource_name=res, time=time_since_start)
+            #     # next_state.resource_availability[res] -= res_consumption
+            #     next_state.resource_used[res] += res_consumption
+            #     if resumed_task not in next_state.resource_used_for_task:
+            #         next_state.resource_used_for_task[resumed_task] = {}
+            #     next_state.resource_used_for_task[resumed_task][res] = res_consumption
+            # if action.resource_unit_names is not None:
+            #     for resource_unit_name in action.resource_unit_names:
+            #         next_state.resource_used[resource_unit_name] = 1
+            #         next_state.resource_used_for_task[resumed_task][resource_unit_name] = 1
+        return next_state
+
+    def update_resume_tasks_uncertain(self, state: State, action: SchedulingAction):
+        """In an uncertain scheduling environment, update the status of a task from paused to ongoing if specified
+        in the action and update resource availability. This function will also log in task_details the time it was
+        resumed."""
+        return self.update_resume_tasks(state, action)
+
+    def update_resume_tasks_simulation(self, state: State, action: SchedulingAction):
+        """In a simulationn scheduling environment, update the status of a task from paused to ongoing if specified
+        in the action and update resource availability. This function will also log in task_details the time it was
+        resumed."""
+        return self.update_resume_tasks(state, action)
+
+    def check_if_action_can_be_started(
+        self, state: State, action: SchedulingAction
+    ) -> Tuple[bool, Dict[str, int]]:
+        """Check if a start or resume action can be applied. It returns a boolean and a dictionary of resources to use."""
+        started_task = action.task
+        if action.action == SchedulingActionEnum.START:
+            time_since_start = state.t
+        elif action.action == SchedulingActionEnum.RESUME:
+            time_since_start = state.tasks_details[started_task].get_task_active_time(
+                state.t
+            )
+        else:
+            return True, {}
+        resource_to_use = self.get_resource_used(
+            task=started_task,
+            mode=action.mode,
+            resource_unit_names=action.resource_unit_names,
+            time_since_start=time_since_start,
+        )
+        if any(
+            resource_to_use[r] > state.resource_availability[r] - state.resource_used[r]
+            for r in resource_to_use
+        ):
+            return False, resource_to_use
+        b = self.check_if_skills_are_fulfilled(
+            task=started_task, mode=action.mode, resource_used=resource_to_use
+        )
+        return b, resource_to_use
+
+    def get_resource_used(
+        self, task: int, mode: int, resource_unit_names: Set[str], time_since_start: int
+    ):
+        r_used = {}
+        mode_details = self.get_tasks_modes()
+        for res in self.get_resource_types_names():
+            res_consumption = mode_details[task][mode].get_resource_need_at_time(
+                resource_name=res, time=time_since_start
+            )
+            # next_state.resource_availability[res] -= res_consumption
+            r_used[res] = res_consumption
+        if resource_unit_names is not None:
+            for resource_unit_name in resource_unit_names:
+                r_used[resource_unit_name] = 1
+        return r_used
+
+    def update_start_tasks(self, state: State, action: SchedulingAction):
+        """Update the status of a task from remaining to ongoing if specified in the action
+        and update resource availability. This function will also log in task_details the time it was started."""
+        if action.action == SchedulingActionEnum.START:
+            can_be_started, resource_to_use = self.check_if_action_can_be_started(
+                state, action
+            )
+            if not can_be_started:
+                return state
+            next_state: State = state  # .copy()
+            started_task = action.task
+            mode = action.mode
+            next_state.tasks_mode[started_task] = mode
+            next_state.tasks_ongoing.add(started_task)
+            sampled_duration = self.get_latest_sampled_duration(
+                task=started_task, mode=mode, progress_from=0.0
+            )  # TODO: what to do with this, so far the sample is stored and then used by get_task_progress()
+            next_state.tasks_details[started_task] = Task(
+                started_task, next_state.t, sampled_duration
+            )
+            for res in resource_to_use:
+                next_state.resource_used[res] += resource_to_use[res]
+            next_state.resource_used_for_task[started_task] = resource_to_use
+            next_state.tasks_progress[started_task] = 0.0
+            return next_state
+        return state
+
+    def update_start_tasks_uncertain(self, state: State, action: SchedulingAction):
+        """In an uncertain scheduling environment, update the status of a task from remaining to ongoing
+        if specified in the action and update resource availability.
+        This function returns a DsicreteDistribution of State.
+        This function will also log in task_details the time it was started."""
+
+        if action.action == SchedulingActionEnum.START:
+            can_be_started, resource_to_use = self.check_if_action_can_be_started(
+                state, action
+            )
+            if not can_be_started:
+                return DiscreteDistribution([(state, 1)])
+            started_task = action.task
+            mode = action.mode
+            duration_distrib = self.get_task_duration_distribution(
+                started_task, mode, multivariate_settings={"t": state.t}
+            )
+            states_and_proba = []
+
+            for value_duration in duration_distrib.get_values():
+                next_state: State = state.copy()
+                next_state.tasks_mode[started_task] = mode
+                next_state.tasks_ongoing.add(started_task)
+                next_state.tasks_details[started_task] = Task(
+                    started_task, state.t, value_duration[0]
+                )
+                for res in resource_to_use:
+                    next_state.resource_used[res] += resource_to_use[res]
+                next_state.resource_used_for_task[started_task] = resource_to_use
+                next_state.tasks_progress[started_task] = 0.0
+
+                states_and_proba += [(next_state, value_duration[1])]
+
+            return DiscreteDistribution(states_and_proba)
+        return DiscreteDistribution([(state, 1)])
+
+    def update_start_tasks_simulation(self, state: State, action: SchedulingAction):
+        """In a simulated scheduling environment, update the status of a task from remaining to ongoing if
+        specified in the action and update resource availability. This function will also log in task_details the
+        time it was started."""
+        return self.update_start_tasks(state, action)
+
+    def get_possible_starting_tasks(self, state: State):
+
+        mode_details = self.get_tasks_modes()
+        possible_task_precedence = [
+            (n, mode_details[n])
+            for n in state.tasks_remaining
+            if all(
+                m in state.tasks_complete
+                for m in set(self.ancestors[n]).intersection(
+                    self.get_available_tasks(state)
+                )
+            )
+        ]
+
+        possible_task_with_ressource = [
+            (n, mode, mode_consumption)
+            for n, modes in possible_task_precedence
+            for mode, mode_consumption in modes.items()
+            if all(
+                state.resource_availability[key]
+                - state.resource_used[key]
+                - mode_consumption.get_resource_need_at_time(
+                    resource_name=key, time=state.t
+                )
+                >= 0
+                for key in self.get_resource_types_names()
+            )
+        ]
+        # print("Possible task with ressource : ", possible_task_with_ressource)
+        return {
+            n: {mode: mode_consumption.get_non_zero_ressource_need_names(0)}
+            for n, mode, mode_consumption in possible_task_with_ressource
+        }
+
+    def get_possible_resume_tasks(self, state: State):
+        mode_details = self.get_tasks_modes()
+        possible_task_precedence = [
+            (n, mode_details[n])
+            for n in state.tasks_paused
+            if all(m in state.tasks_complete for m in self.ancestors[n])
+        ]
+        # print("Possible task precedence : ", possible_task_precedence)
+        possible_task_with_ressource = [
+            (n, mode, mode_consumption)
+            for n, modes in possible_task_precedence
+            for mode, mode_consumption in modes.items()
+            if all(
+                state.resource_availability[key]
+                - state.resource_used[key]
+                - mode_consumption.get_resource_need_at_time(
+                    resource_name=key, time=state.t
+                )
+                >= 0
+                for key in self.get_resource_types_names()
+            )
+        ]
+        # print("Possible task with ressource : ", possible_task_with_ressource)
+        return {
+            n: {mode: mode_consumption.get_non_zero_ressource_need_names(0)}
+            for n, mode, mode_consumption in possible_task_with_ressource
+        }
+
+    def state_is_overconsuming(self, state: State):
+        return any(
+            state.resource_used[k] > state.resource_availability[k]
+            for k in state.resource_used
+        )
+
+    def update_resource_availability(self, state: State, action: SchedulingAction):
+        """Update resource availability for next time step. This should be called after update_time()."""
+        if action.time_progress:
+            next_state: State = state  # .copy()
+            # update the resource used / resource availability function on the possible new availability
+            # and consumption of ongoing task -> quite boring to code and debug probably
+            for res in self.get_resource_units_names():
+                next_state.resource_availability[res] = self.sample_quantity_resource(
+                    resource=res, time=next_state.t
+                )
+            for res in self.get_resource_types_names():
+                next_state.resource_availability[res] = self.sample_quantity_resource(
+                    resource=res, time=next_state.t
+                )
+            # TODO :
+            # Here, if the resource_used[res] is > resource_availability[res] we should be forced to pause some task??
+            # If yes which one ? all ? and we let the algorithm resume the one of its choice in the next time step ?
+            return next_state
+        return state
+
+    def update_resource_availability_uncertain(
+        self, states: DiscreteDistribution[State], action: SchedulingAction
+    ):
+        """Update resource availability for next time step. This should be called after update_time()."""
+        next_states = DiscreteDistribution(
+            [(state, prob) for (state, prob) in states.get_values()]
+        )
+
+        if action.time_progress:
+            for next_state, _ in next_states.get_values():
+                # update the resource used / resource availability function on the possible new availability
+                # and consumption of ongoing task -> quite boring to code and debug probably
+                for res in self.get_resource_units_names():
+                    next_state.resource_availability[
+                        res
+                    ] = self.sample_quantity_resource(resource=res, time=next_state.t)
+                for res in self.get_resource_types_names():
+                    next_state.resource_availability[
+                        res
+                    ] = self.sample_quantity_resource(resource=res, time=next_state.t)
+                # TODO :
+                # Here, if the resource_used[res] is > resource_availability[res] we should be forced to pause some task??
+                # If yes which one ? all ? and we let the algorithm resume the one of its choice in the next time step ?
+        return next_states
+
+    def update_resource_availability_simulation(
+        self, state: State, action: SchedulingAction
+    ):
+        """In a simulated scheduling environment, update resource availability for next time step.
+        This should be called after update_time()."""
+        return self.update_resource_availability(state, action)
+
+    def update_conditional_tasks(self, state: State, action: SchedulingAction):
+        """Update remaining tasks by checking conditions and potentially adding conditional tasks."""
+        return state
+
+    def update_conditional_tasks_uncertain(
+        self, states: DiscreteDistribution[State], action: SchedulingAction
+    ):
+        """Update remaining tasks by checking conditions and potentially adding conditional tasks."""
+        next_states = DiscreteDistribution(
+            [(state, prob) for (state, prob) in states.get_values()]
+        )
+
+        if action.time_progress:
+            for next_state, _ in next_states.get_values():
+                all_available_tasks = self.get_available_tasks(next_state)
+                all_considered_tasks = next_state.task_ids.difference(
+                    next_state.tasks_unsatisfiable
+                )
+                new_tasks = all_available_tasks.symmetric_difference(
+                    all_considered_tasks
+                )
+                for task in new_tasks:
+                    next_state.tasks_unsatisfiable.remove(task)
+            return next_states
+        return next_states
+
+    def update_conditional_tasks_simulation(
+        self, state: State, action: SchedulingAction
+    ):
+        """In a simulated scheduling environment, update remaining tasks by checking conditions and potentially
+        adding conditional tasks."""
+        next_state: State = state
+        next_state = self.update_conditional_tasks_uncertain(
+            states=DiscreteDistribution([(next_state, 1.0)]), action=action
+        ).sample()
+        return next_state
+
+    # WARNING : the two following functions are not required with the current signature of the Domain
+    # BUT i feel it's necessary to code it somewhere when i tested it in skdecide/hub/domain/rcpsp_pi2/rcpsp where
+    # i had to code those two functions.
+    #
+    def _get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_state] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+
+        transition_makespan = 0.0
+        transition_cost = 0.0
+
+        if SchedulingObjectiveEnum.MAKESPAN in self.get_objectives():
+            transition_makespan = next_state.t - memory.t
+
+        if SchedulingObjectiveEnum.COST in self.get_objectives():
+            mode_cost_val = 0.0
+            if action.action == SchedulingActionEnum.START:
+                mode_cost_val += self.get_mode_costs()[action.task][action.mode]
+            renewable_type_cost_val = 0.0
+            nonrenewable_type_cost_val = 0.0
+            for res in self.get_resource_types_names():
+                if self.is_renewable(res):
+                    renewable_type_cost_val += (
+                        self.get_resource_cost_per_time_unit()[res]
+                        * next_state.resource_used[res]
+                    )
+                else:
+                    nonrenewable_type_cost_val += (
+                        next_state.resource_used[res] - memory.resource_used[res]
+                    )  # res used not decreased for NR resources so need to compute difference from previous state
+            renewable_unit_cost_val = 0.0
+            nonrenewable_unit_cost_val = 0.0
+            for res in self.get_resource_units_names():
+                if self.is_renewable(res):
+                    renewable_unit_cost_val += (
+                        self.get_resource_cost_per_time_unit()[res]
+                        * next_state.resource_used[res]
+                    )
+                else:
+                    nonrenewable_unit_cost_val += (
+                        next_state.resource_used[res] - memory.resource_used[res]
+                    )  # res used not decreased for NR resources so need to compute difference from previous state
+            transition_cost = (
+                mode_cost_val
+                + renewable_type_cost_val
+                + nonrenewable_type_cost_val
+                + renewable_unit_cost_val
+                + nonrenewable_unit_cost_val
+            )
+
+        # TODO: Handle more than 1 objective in the transition value (need weights ?)
+        weighed_transition_cost = 1.0 * transition_makespan + 1.0 * transition_cost
+        return Value(cost=weighed_transition_cost)
+
+    def _is_terminal(self, state: D.T_state) -> bool:
+        all_task_possible = self.all_tasks_possible(state)
+        return (
+            state.t > self.get_max_horizon()
+            or (not all_task_possible)
+            or (
+                len(state.task_ids)
+                == len(state.tasks_complete) + len(state.tasks_unsatisfiable)
+                and (len(state.tasks_ongoing) == 0)
+                and (len(state.tasks_paused) == 0)
+            )
+        )
+        # TODO, is there a cleaner way ? We can check completion of the sink task
+
+    def get_objectives(self) -> List[SchedulingObjectiveEnum]:
+        """Return the objectives to consider as a list. The items should be of SchedulingObjectiveEnum type."""
+        return self._get_objectives()
+
+    def _get_objectives(self) -> List[SchedulingObjectiveEnum]:
+        """Return the objectives to consider as a list. The items should be of SchedulingObjectiveEnum type."""
+        raise NotImplementedError
+
+
+class D_det(
+    Domain,
+    SingleAgent,
+    Sequential,
+    DeterministicTransitions,
+    DeterministicInitialized,
+    Actions,
+    FullyObservable,
+    Markovian,
+    Goals,
+):
+    """Base class for deterministic scheduling problems"""
+
+    T_state = State  # Type of states
+    T_observation = State  # Type of observations
+    T_event = SchedulingAction  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_info = (
+        None  # Type of additional information given as part of an environment outcome
+    )
+
+
+class D_uncertain(
+    Domain,
+    SingleAgent,
+    Sequential,
+    UncertainTransitions,
+    DeterministicInitialized,
+    Actions,
+    FullyObservable,
+    Markovian,
+    Goals,
+):
+    """Base class for uncertain scheduling problems where we can compute distributions"""
+
+    T_state = State  # Type of states
+    T_observation = State  # Type of observations
+    T_event = SchedulingAction  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_info = (
+        None  # Type of additional information given as part of an environment outcome
+    )
+
+
+# Specific for uncertain domain
+class UncertainSchedulingDomain(SchedulingDomain, D_uncertain):
+    """This is the highest level scheduling domain class (inheriting top-level class for each mandatory
+    domain characteristic).
+    """
+
+    def _state_sample(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_info]]:
+        """This function will be used if the domain is defined as a Simulation (i.e. transitions are defined by call to
+        a simulation). This function may also be used by simulation-based solvers on non-Simulation domains."""
+        return UncertainTransitions._state_sample(self, memory, action)
+
+
+# Specific for deterministic domain
+class DeterministicSchedulingDomain(SchedulingDomain, D_det):
+    """This is the highest level scheduling domain class (inheriting top-level class for each mandatory
+    domain characteristic).
+    """
+
+    def _state_sample(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_info]]:
+        """This function will be used if the domain is defined as a Simulation (i.e. transitions are defined by call to
+        a simulation). This function may also be used by simulation-based solvers on non-Simulation domains."""
+        return DeterministicTransitions._state_sample(self, memory, action)
+
+    def _get_next_state_distribution(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> Distribution[D.T_state]:
+        """This function will be used if the domain is defined with UncertainTransitions. This function will be ignored
+        if the domain is defined as a Simulation. This function may also be used by uncertainty-specialised solvers
+         on deterministic domains."""
+        return DeterministicTransitions._get_next_state_distribution(
+            self, memory, action
+        )
+
+
+"""
+Scheduling action space that will work for domains that don't require any
+ressource unit allocation in its formulation.
+"""
+
+
+class SchedulingActionSpace(
+    EnumerableSpace[SchedulingAction], SamplableSpace[SchedulingAction]
+):
+    def __init__(self, domain: SchedulingDomain, state: State):
+        self.domain = domain
+        self.state = state
+        self.elements = self._get_elements()
+
+    def _get_elements(self) -> Iterable[T]:
+        choices = [
+            SchedulingActionEnum.START,
+            SchedulingActionEnum.PAUSE,
+            SchedulingActionEnum.RESUME,
+            SchedulingActionEnum.TIME_PR,
+        ]
+        list_action = []
+        if self.domain.state_is_overconsuming(self.state):
+            choices = [
+                SchedulingActionEnum.PAUSE,
+                SchedulingActionEnum.TIME_PR,
+            ]  # we have to pause some task before doing anything
+        for choice in choices:
+            if choice == SchedulingActionEnum.START:
+                # task, mode, list of Ressources
+                task_possible_to_start: Dict[
+                    int, Dict[int, List[str]]
+                ] = self.domain.get_possible_starting_tasks(self.state)
+                list_action += [
+                    SchedulingAction(
+                        task=t,
+                        action=SchedulingActionEnum.START,
+                        mode=m,
+                        time_progress=False,
+                    )
+                    for t in task_possible_to_start
+                    for m in task_possible_to_start[t]
+                ]
+            if choice == SchedulingActionEnum.PAUSE:
+                task_possible_to_pause = self.state.tasks_ongoing
+                list_action += [
+                    SchedulingAction(
+                        task=t,
+                        action=SchedulingActionEnum.PAUSE,
+                        mode=None,
+                        time_progress=False,
+                    )
+                    for t in task_possible_to_pause
+                    if self.domain.get_task_preemptivity()[t]
+                ]
+            if choice == SchedulingActionEnum.RESUME:
+                task_possible_to_resume = self.state.tasks_paused
+                list_action += [
+                    SchedulingAction(
+                        task=t,
+                        action=SchedulingActionEnum.RESUME,
+                        mode=self.state.tasks_mode[t],
+                        time_progress=False,
+                    )
+                    for t in task_possible_to_resume
+                ]
+            if choice == SchedulingActionEnum.TIME_PR:
+                list_action.append(
+                    SchedulingAction(
+                        task=None,
+                        action=SchedulingActionEnum.TIME_PR,
+                        mode=None,
+                        time_progress=True,
+                    )
+                )
+        return list_action
+
+    def get_elements(self) -> Iterable[T]:
+        return self.elements
+
+    def sample(self) -> T:
+        return random.choice(self.elements)
+
+
+# TODO : will work well for domains where a task can be done by one ressource unit (and not a combination of ressource units)
+# In this case we can enumerate the "worker" ressource. This is the case of the MultiSkill RCPSP of the Imopse benchmark
+class SchedulingActionSpaceWithResourceUnit(
+    EnumerableSpace[SchedulingAction], SamplableSpace[SchedulingAction]
+):
+    def __init__(self, domain: SchedulingDomain, state: State):
+        self.domain = domain
+        self.state = state
+        self.elements = self._get_elements()
+
+    def _get_elements(self) -> Iterable[T]:
+        choices = [
+            SchedulingActionEnum.START,
+            SchedulingActionEnum.PAUSE,
+            SchedulingActionEnum.RESUME,
+            SchedulingActionEnum.TIME_PR,
+        ]
+        list_action = []
+        if self.domain.state_is_overconsuming(self.state):
+            choices = [
+                SchedulingActionEnum.PAUSE,
+                SchedulingActionEnum.TIME_PR,
+            ]  # we have to pause some task before doing anything
+        for choice in choices:
+            if choice == SchedulingActionEnum.START:
+                # task, mode, list of Ressources
+                task_possible_to_start: Dict[
+                    int, Dict[int, List[str]]
+                ] = self.domain.get_possible_starting_tasks(self.state)
+                for possible_to_start in task_possible_to_start:
+                    for mode in task_possible_to_start[possible_to_start]:
+                        possible = self.domain.find_one_ressource_to_do_one_task(
+                            task=possible_to_start, mode=mode
+                        )
+                        list_action += [
+                            SchedulingAction(
+                                task=possible_to_start,
+                                action=SchedulingActionEnum.START,
+                                mode=mode,
+                                time_progress=False,
+                                resource_unit_names={r} if r is not None else None,
+                            )
+                            for r in possible
+                            if r is None
+                            or self.state.resource_used[r] + 1
+                            <= self.state.resource_availability[r]
+                        ]
+
+            if choice == SchedulingActionEnum.PAUSE:
+                task_possible_to_pause = self.state.tasks_ongoing
+                list_action += [
+                    SchedulingAction(
+                        task=t,
+                        action=SchedulingActionEnum.PAUSE,
+                        mode=None,
+                        time_progress=False,
+                    )
+                    for t in task_possible_to_pause
+                    if self.domain.get_task_preemptivity()[t]
+                ]
+            if choice == SchedulingActionEnum.RESUME:
+                task_possible_to_resume = self.state.tasks_paused
+
+                for possible_to_resume in task_possible_to_resume:
+                    possible = self.domain.find_one_ressource_to_do_one_task(
+                        task=possible_to_resume,
+                        mode=self.state.tasks_mode[possible_to_resume],
+                    )
+
+                    list_action += [
+                        SchedulingAction(
+                            task=possible_to_resume,
+                            action=SchedulingActionEnum.START,
+                            mode=self.state.tasks_mode[possible_to_resume],
+                            time_progress=False,
+                            resource_unit_names={r} if r is not None else None,
+                        )
+                        for r in possible
+                        if r is None
+                        or self.state.resource_used[r] + 1
+                        <= self.state.resource_availability[r]
+                    ]
+            if choice == SchedulingActionEnum.TIME_PR:
+                list_action.append(
+                    SchedulingAction(
+                        task=None,
+                        action=SchedulingActionEnum.TIME_PR,
+                        mode=None,
+                        time_progress=True,
+                    )
+                )
+        return list_action
+
+    def get_elements(self) -> Iterable[T]:
+        return self.elements
+
+    def sample(self) -> T:
+        return random.choice(self.elements)
+
+
+class SchedulingActionSpaceWithResourceUnitSamplable(SamplableSpace[SchedulingAction]):
+    def __init__(self, domain: SchedulingDomain, state: State):
+        self.domain = domain
+        self.state = state
+
+    def sample(self) -> T:
+        choices = [
+            SchedulingActionEnum.START,
+            SchedulingActionEnum.PAUSE,
+            SchedulingActionEnum.RESUME,
+            SchedulingActionEnum.TIME_PR,
+        ]
+        if self.domain.state_is_overconsuming(self.state):
+            choices = [
+                SchedulingActionEnum.PAUSE
+            ]  # we have to pause some task before doing anything
+        random_choice = random.choice(choices)
+        if random_choice in {SchedulingActionEnum.START, SchedulingActionEnum.RESUME}:
+            if random_choice == SchedulingActionEnum.START:
+                task_possible_to_start: Dict[
+                    int, Dict[int, List[str]]
+                ] = self.domain.get_possible_starting_tasks(self.state)
+            else:
+                task_possible_to_start: Dict[
+                    int, Dict[int, List[str]]
+                ] = self.domain.get_possible_resume_tasks(self.state)
+            task_modes = [
+                (t, m)
+                for t in task_possible_to_start
+                for m in task_possible_to_start[t]
+            ]
+            if len(task_modes) > 0:
+                random_ch = random.choice(task_modes)
+                possible_to_start = random_ch[0]
+                mode = random_ch[1]
+                skill_of_task = self.domain.get_skills_of_task(possible_to_start, mode)
+                resources = []
+                if len(skill_of_task) == 0:
+                    return SchedulingAction(
+                        task=possible_to_start,
+                        action=random_choice,
+                        mode=mode,
+                        time_progress=False,
+                    )
+                resources_skills = list(self.domain.get_all_resources_skills().keys())
+                random.shuffle(resources_skills)
+                cur_usage = {s: 0 for s in skill_of_task}
+                success = False
+                for resource in resources_skills:
+                    if (
+                        self.state.resource_used[resource] + 1
+                        > self.state.resource_availability[resource]
+                    ):
+                        continue
+                    if any(
+                        self.domain.get_skills_of_resource(resource=resource).get(s, 0)
+                        > 0
+                        for s in skill_of_task
+                    ):
+                        resources += [resource]
+                        for s in cur_usage:
+                            cur_usage[s] += self.domain.get_skills_of_resource(
+                                resource=resource
+                            ).get(s, 0)
+                        if all(cur_usage[s] >= skill_of_task[s] for s in skill_of_task):
+                            success = True
+                            break
+                if success:
+                    return SchedulingAction(
+                        task=possible_to_start,
+                        action=random_choice,
+                        mode=mode,
+                        time_progress=False,
+                        resource_unit_names=resources,
+                    )
+                else:
+                    return SchedulingAction(
+                        task=None,
+                        action=SchedulingActionEnum.TIME_PR,
+                        mode=None,
+                        time_progress=True,
+                    )
+            else:
+                return SchedulingAction(
+                    task=None,
+                    action=SchedulingActionEnum.TIME_PR,
+                    mode=None,
+                    time_progress=True,
+                )
+
+        if random_choice == SchedulingActionEnum.PAUSE:
+            task_possible_to_pause = [
+                t
+                for t in self.state.tasks_ongoing
+                if self.domain.get_task_preemptivity()[t]
+            ]
+            if len(task_possible_to_pause) > 0:
+                return SchedulingAction(
+                    task=random.choice(task_possible_to_pause),
+                    action=SchedulingActionEnum.PAUSE,
+                    mode=None,
+                    time_progress=False,
+                )
+            else:
+
+                return SchedulingAction(
+                    task=None,
+                    action=SchedulingActionEnum.TIME_PR,
+                    mode=None,
+                    time_progress=True,
+                )
+
+        if random_choice == SchedulingActionEnum.TIME_PR:
+            return SchedulingAction(
+                task=None,
+                action=SchedulingActionEnum.TIME_PR,
+                mode=None,
+                time_progress=True,
+            )
+
+    def contains(self, x: T) -> bool:
+        return True
+
+
+class SingleModeRCPSP(
+    DeterministicSchedulingDomain,
+    SingleMode,
+    DeterministicTaskDuration,
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    WithoutResourceAvailabilityChange,
+    WithoutConditionalTasks,
+    RenewableOnly,
+    ConstantResourceConsumption,  # problem with unimplemented classes with this
+    WithoutPreemptivity,  # problem with unimplemented classes with this
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Single mode (classic) Resource project scheduling problem template.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - task having deterministic resource consumption
+    The goal is to minimize the overall makespan, respecting the cumulative resource consumption constraint
+    """
+
+    pass
+
+
+class SingleModeRCPSPCalendar(
+    DeterministicSchedulingDomain,
+    SingleMode,
+    DeterministicTaskDuration,
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    # WithoutResourceAvailabilityChange,
+    DeterministicResourceAvailabilityChanges,
+    WithoutConditionalTasks,
+    RenewableOnly,
+    ConstantResourceConsumption,  # problem with unimplemented classes with this
+    WithoutPreemptivity,  # problem with unimplemented classes with this
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Single mode Resource project scheduling problem with varying resource availability template.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with variable availability through time
+    - task having deterministic resource consumption
+    The goal is to minimize the overall makespan, respecting the cumulative resource consumption constraint
+    at any time
+    """
+
+    pass
+
+
+class MultiModeRCPSP(
+    DeterministicSchedulingDomain,
+    MultiMode,  # this changed from Single mode RCPSP
+    DeterministicTaskDuration,
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    WithoutResourceAvailabilityChange,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    MixedRenewable,  # this changed from Single mode RCPSP
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Multimode (classic) Resource project scheduling problem template.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - a set of non-renewable resource (consumable)
+    - task having several modes of execution, giving for each mode a deterministic resource consumption and duration
+    The goal is to minimize the overall makespan, respecting the cumulative resource consumption constraint
+    """
+
+    pass
+
+
+class MultiModeRCPSPWithCost(
+    DeterministicSchedulingDomain,
+    MultiMode,
+    DeterministicTaskDuration,
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    WithoutResourceAvailabilityChange,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    MixedRenewable,
+    WithModeCosts,
+    WithResourceCosts,
+):
+    """
+    Multimode (classic) Resource project scheduling problem template with cost based on modes.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - a set of non-renewable resource (consumable)
+    - task having several modes of execution, giving for each mode a deterministic resource consumption and duration
+    The goal is to minimize the overall cost that is function of the mode chosen for each task
+    """
+
+    pass
+
+
+class MultiModeRCPSPCalendar(
+    DeterministicSchedulingDomain,
+    MultiMode,  # this changed from Single mode RCPSP
+    DeterministicTaskDuration,
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    DeterministicResourceAvailabilityChanges,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    MixedRenewable,  # this changed from Single mode RCPSP
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Multimode (classic) Resource project scheduling problem template with cost based on modes.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with variable availability (capacity)
+    - a set of non-renewable resource (consumable)
+    - task having several modes of execution, giving for each mode a deterministic resource consumption and duration
+    The goal is to minimize the overall makespan
+    """
+
+    pass
+
+
+class MultiModeRCPSPCalendar_Stochastic_Durations(
+    UncertainSchedulingDomain,
+    MultiMode,  # this changed from Single mode RCPSP
+    UncertainUnivariateTaskDuration,
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    # WithoutResourceAvailabilityChange,
+    DeterministicResourceAvailabilityChanges,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    MixedRenewable,  # this changed from Single mode RCPSP
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Multimode (classic) Resource project scheduling problem template.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with variable availability (capacity)
+    - a set of non-renewable resource (consumable)
+    - task having several modes of execution, giving for each mode a deterministic resource consumption and
+    a stochastic duration
+    The goal is to minimize the overall makespan
+    """
+
+    pass
+
+
+class MultiModeMultiSkillRCPSP(
+    DeterministicSchedulingDomain,
+    MultiMode,
+    DeterministicTaskDuration,
+    DeterministicTaskProgress,
+    # WithResourceUnits,
+    # WithResourceTypes,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    # WithResourceSkills, # This change from MultiModeRCPSP
+    WithoutResourceAvailabilityChange,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    MixedRenewable,
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Multimode multiskill Resource project scheduling problem template
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - resource can be unitary and have skills
+    - a set of non-renewable resource (consumable)
+    - task having several modes of execution, giving for each mode a deterministic resource consumption,
+    deterministic duration and skills needed
+    The goal is to minimize the overall makespan, allocating unit resource to tasks fulfilling the skills requirement.
+    """
+
+    pass
+
+
+class MultiModeMultiSkillRCPSPCalendar(
+    DeterministicSchedulingDomain,
+    MultiMode,
+    DeterministicTaskDuration,
+    DeterministicTaskProgress,
+    # WithResourceUnits,
+    # WithResourceTypes,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    # WithResourceSkills, # This change from MultiModeRCPSP
+    # WithoutResourceAvailabilityChange,
+    DeterministicResourceAvailabilityChanges,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    MixedRenewable,
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Multimode multiskill Resource project scheduling problem with resource variability template
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with variable availability
+    - resource can be unitary and have skills
+    - a set of non-renewable resource (consumable)
+    - task having several modes of execution, giving for each mode a deterministic resource consumption,
+    deterministic duration and skills needed
+    The goal is to minimize the overall makespan, allocating unit resource to tasks fulfilling the skills requirement.
+    """
+
+    pass
+
+
+class MultiModeRCPSP_Stochastic_Durations(
+    UncertainSchedulingDomain,
+    UncertainUnivariateTaskDuration,  # this changed from Single mode RCPSP
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    WithoutResourceAvailabilityChange,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    RenewableOnly,
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Multimode Resource project scheduling problem with stochastic durations template.
+    It consists in :
+    - a scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - a set of non-renewable resource (consumable)
+    - task having several modes of execution, giving for each mode a deterministic resource consumption and
+    a stochastic duration
+    The goal is to minimize the overall expected makespan
+    """
+
+    pass
+
+
+class SingleModeRCPSP_Stochastic_Durations(
+    UncertainSchedulingDomain,
+    SingleMode,
+    UncertainUnivariateTaskDuration,  # this changed from Single mode RCPSP
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    WithoutResourceAvailabilityChange,
+    WithoutConditionalTasks,
+    ConstantResourceConsumption,
+    RenewableOnly,
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Resource project scheduling problem template.
+    It consists in :
+    - a scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - task having a deterministic resource consumption and a stochastic duration
+    The goal is to minimize the overall expected makespan
+    """
+
+    pass
+
+
+class SingleModeRCPSP_Stochastic_Durations_WithConditionalTasks(
+    UncertainSchedulingDomain,
+    SingleMode,
+    UncertainUnivariateTaskDuration,  # this changed from Single mode RCPSP
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    WithoutResourceAvailabilityChange,
+    # WithConditionalTasks,
+    ConstantResourceConsumption,
+    RenewableOnly,
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Resource project scheduling problem with stochastic duration and conditional tasks template.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - task having a deterministic resource consumption and a stochastic duration given as a distribution
+    - based on duration of tasks, some optional tasks have to be executed.
+    The goal is to minimize the overall expected makespan
+    """
+
+    pass
+
+
+class SingleModeRCPSP_Simulated_Stochastic_Durations_WithConditionalTasks(
+    SchedulingDomain,
+    SingleMode,
+    # SimulatedTaskDuration,
+    DeterministicTaskProgress,
+    WithoutResourceUnit,
+    WithoutPreemptivity,
+    WithoutPreallocations,
+    WithoutTimeLag,
+    WithoutTimeWindow,
+    WithoutResourceSkills,
+    WithoutResourceAvailabilityChange,
+    # WithConditionalTasks,
+    ConstantResourceConsumption,
+    RenewableOnly,
+    WithoutModeCosts,
+    WithoutResourceCosts,
+):
+    """
+    Resource project scheduling problem with stochastic duration and conditional tasks template.
+    It consists in :
+    - a deterministic scheduling problem with precedence constraint between task
+    - a set of renewable resource with constant availability (capacity)
+    - task having a deterministic resource consumption and a stochastic duration that is simulated as blackbox
+    - based on duration of tasks, some optional tasks have to be executed.
+    The goal is to minimize the overall expected makespan
+    """
+
+    pass
```

## skdecide/builders/domain/scheduling/scheduling_domains_modelling.py

```diff
@@ -1,291 +1,293 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from collections.abc import Collection
-from copy import copy, deepcopy
-from enum import Enum
-from typing import Dict, Iterable, Optional, Set, Tuple, Union
-
-from skdecide.builders.domain.scheduling.task import Task
-
-
-def rebuild_tasks_complete_details_dict(state: State) -> Dict[int, Task]:
-    tasks_complete_details = {p.value.id: p.value for p in state.tasks_complete_details}
-    return tasks_complete_details
-
-
-def rebuild_all_tasks_dict(state: State) -> Dict[int, Task]:
-    tasks_details = {
-        task_id: Task(id=task_id, start=None, sampled_duration=None)
-        for task_id in state.task_ids
-    }
-    tasks_details.update({p.value.id: p.value for p in state.tasks_complete_details})
-    tasks_details.update(state.tasks_details)
-    return tasks_details
-
-
-def rebuild_tasks_modes_dict(state: State) -> Dict[int, int]:
-    tasks_modes = {p.value[0]: p.value[1] for p in state.tasks_complete_mode}
-    return tasks_modes
-
-
-def rebuild_schedule_dict(state: State) -> Dict[int, Dict[str, int]]:
-    schedule = {
-        p.value.id: {"start_time": p.value.start, "end_time": p.value.end}
-        for p in state.tasks_complete_details
-    }
-    return schedule
-
-
-class Node:
-    __slots__ = ("value", "next_node")
-
-    def __init__(self, value: Task = None, next_node=None):
-        self.value = value
-        self.next_node = next_node
-
-
-class SinglyLinkedList(Collection):
-    def __init__(self, head=None):
-        self.head = head
-
-    def push_front(self, value: Union[int, float, Task, Tuple[int, int]]):
-        self.head = Node(value, self.head)
-
-    def __iter__(self):
-        current = self.head
-        while current:
-            yield current
-            current = current.next_node
-
-    def __len__(self) -> int:
-        return sum(1 for _ in iter(self))
-
-    def __contains__(self, value: Union[int, float, Task]) -> bool:
-        for node in iter(self):
-            if node.value == value:
-                return True
-        return False
-
-    def __copy__(self):
-        return SinglyLinkedList(self.head)
-
-
-class SchedulingActionEnum(Enum):
-    """
-    Enum defining the different types of scheduling actions:
-    - START: start a task
-    - PAUSE: pause a task
-    - RESUME: resume a task
-    - TIME_PR: do not apply actions on tasks and progress in time
-    """
-
-    START = 0
-    PAUSE = 1
-    RESUME = 2
-    TIME_PR = 3
-
-
-class State:
-    """Class modelling a scheduling state and used by sk-decide scheduling domains.
-
-    It contains the following information:
-        t: the timestamp.
-        task_ids: a list of all task ids in the scheduling domain.
-        tasks_unsatisfiable: a set containing the ids of tasks for which canditions are not fulfilled
-        tasks_ongoing: a set containing the ids of tasks started and not paused and still to be completed
-        tasks_complete: a set containing the ids of tasks that have been completed
-        tasks_paused: a set containing the ids of tasks that have been started and paused but not resumed yet
-        tasks_progress: a dictionary where the key is a task id (int) and
-            the value the progress of the task between 0 and 1 (float)
-        tasks_mode: a dictionary where the key is a task id (int) and
-            the value the mode used to execute the task (int)
-        resource_to_task: dictionary where the key is the name of a resource (str) and the value a task
-            it is currently assigned to (int)
-        resource_availability: dictionary where the key is the name of a resource (str) and the value the number of
-            resource units available for this type of resource regardless of the task assignments (int). Where the
-            resource name is a resource unit itself, the availability value takes a value of either 1 (available)
-            or 0 (unavailable)
-        resource_used: dictionary where the key is the name of a resource (str) and the value the number of
-            resource units for this resource type used/assigned on tasks at this time (int). Where the resource
-            name is a resource unit itself, the value takes a value of either 1 (used) or 0 (not used)
-        resource_used_for_task: nested dictionary where the first key is a task id (int), the second key is the name of
-            a resource (str) and the value is the number of resource units for this resource type used/assigned on tasks
-            at this time (int). Where the resource name is a resource unit itself, the value takes a value of either 1
-            (used) or 0 (not used).
-        tasks_details: dictionary where the key is the id of a task (int) and the value a Task object. This Task object
-            contains information about the task execution and can be used to post-process the run. It is only used
-            by the domain to store execution information and not used by scheduling solvers.
-        tasks_full_details: like taks_details but containing all taks, even the ones not completed.
-        _current_conditions: set of conditions observed so far, to be used by domains with WithConditionalTask
-            properties
-
-    """
-
-    # TODO : code efficient hash/eq functions. will probably be mandatory in some planning algo.
-    t: int
-    tasks_unsatisfiable: Set[int]
-    tasks_ongoing: Set[int]
-    tasks_complete: Set[int]
-    tasks_paused: Set[int]
-    tasks_progress: Dict[int, float]
-    tasks_mode: Dict[int, int]
-    resource_to_task: Dict[str, int]
-    resource_availability: Dict[str, int]
-    resource_used: Dict[str, int]
-    resource_used_for_task: Dict[int, Dict[str, int]]
-    tasks_details: Dict[
-        int, Task
-    ]  # Use to store task stats, resource used etc... for post-processing purposes
-    tasks_complete_details: SinglyLinkedList
-    tasks_complete_progress: SinglyLinkedList
-    tasks_complete_mode: SinglyLinkedList
-    _current_conditions: Set
-
-    # TODO : put the attributes in the __init__ ?!
-    def __init__(self, task_ids: Iterable[int], tasks_available: Set[int] = None):
-        """Initialize a scheduling state.
-
-        # Parameters
-        task_ids: a list of all task ids in the scheduling domain.
-        tasks_available: a set of task ids that are available for scheduling. This may differ from task_ids if the
-         domain contains conditional tasks.
-        """
-        self.t = 0
-        self.task_ids = task_ids if isinstance(task_ids, set) else set(task_ids)
-        self.tasks_unsatisfiable = (
-            set()
-            if tasks_available is None
-            else set(t for t in self.task_ids if t not in tasks_available)
-        )
-        self.tasks_ongoing = set()
-        self.tasks_complete = set()
-        self.tasks_paused = set()
-        self.tasks_progress = {}
-        self.tasks_mode = {}
-        self.resource_to_task = {}
-        self.resource_availability = {}
-        self.resource_used = {}
-        self.resource_used_for_task = {}
-        self.tasks_details = {}
-        self.tasks_complete_details = SinglyLinkedList()
-        self.tasks_complete_progress = SinglyLinkedList()
-        self.tasks_complete_mode = SinglyLinkedList()
-        self._current_conditions = set()
-
-    def copy(self):
-        s = State(task_ids=self.task_ids)
-        s.t = self.t
-        s.tasks_unsatisfiable = deepcopy(self.tasks_unsatisfiable)
-        s.tasks_ongoing = deepcopy(self.tasks_ongoing)
-        s.tasks_complete = deepcopy(self.tasks_complete)
-        s.tasks_paused = deepcopy(self.tasks_paused)
-        s.tasks_progress = deepcopy(self.tasks_progress)
-        s.tasks_mode = deepcopy(self.tasks_mode)
-        s.resource_to_task = deepcopy(self.resource_to_task)
-        s.resource_availability = deepcopy(self.resource_availability)
-        s.resource_used = deepcopy(self.resource_used)
-        s.resource_used_for_task = deepcopy(self.resource_used_for_task)
-        s.tasks_details = deepcopy(self.tasks_details)
-        s._current_conditions = deepcopy(self._current_conditions)
-        s.tasks_complete_details = copy(self.tasks_complete_details)
-        s.tasks_complete_progress = copy(self.tasks_complete_progress)
-        s.tasks_complete_mode = copy(self.tasks_complete_mode)
-        return s
-
-    @property
-    def tasks_full_details(self) -> Dict[int, Task]:
-        return rebuild_all_tasks_dict(self)
-
-    @property
-    def tasks_remaining(self):
-        for task in self.task_ids:
-            if (
-                task not in self.tasks_complete
-                and task not in self.tasks_progress
-                and task not in self.tasks_unsatisfiable
-            ):
-                yield task
-
-    def __str__(self):
-        s = "State : " + "\n"
-        for key in sorted(self.__dict__.keys()):
-            if key == "tasks_details":
-                for key2 in sorted(self.tasks_details.keys()):
-                    s += str(self.tasks_details[key2]) + "\t"
-            elif key.startswith("tasks_complete_"):
-                for node in getattr(self, key):
-                    s += str(node.value) + "\t"
-            else:
-                s += str(key) + ":" + str(getattr(self, key)) + "\n"
-        return s
-
-    def __repr__(self):
-        return str(self)
-
-    def __hash__(self):
-        return hash(str(self))
-
-    def __eq__(self, other):
-        return self.__hash__() == other.__hash__()
-
-
-class SchedulingAction:
-    """
-    Can be used to define actions on single task. Resource allocation can only be managed through changes in the mode.
-    The time_progress attribute triggers a change in time (i.e. triggers the domain to increment its current time).
-    It should thus be used as the last action to be applied at any point in time
-    These actions are enumerable due to their coarse grain definition.
-
-    E.g.
-        task = 12 (start action 12 in mode 1)
-        action = EnumerableActionEnum.START
-        mode = 1
-        time_progress = False
-
-    E.g. (pause action 13, NB: mode info is not useful here)
-        task = 13
-        action = EnumerableActionEnum.PAUSE
-        mode = None
-        time_progress = False
-
-    E.g. (do nothing and progress in time)
-        task = None
-        action = None
-        mode = None
-        time_progress = True
-    """
-
-    task: int
-    action: SchedulingActionEnum
-    mode: int
-    time_progress: bool
-
-    def __init__(
-        self,
-        task: Union[int, None],
-        action: SchedulingActionEnum,
-        mode: Union[int, None],
-        time_progress: bool,
-        resource_unit_names: Optional[Set[str]] = None,
-    ):
-        self.task = task
-        self.action = action
-        self.mode = mode
-        self.time_progress = time_progress
-        self.resource_unit_names = resource_unit_names
-
-    def __str__(self):
-        s = "Action \n"
-        s += "Task : " + str(self.task) + "\n"
-        s += "Mode : " + str(self.mode) + "\n"
-        s += "Action type " + str(self.action.name) + "\n"
-        s += "Time progress " + str(self.time_progress) + "\n"
-        s += "Resource : " + str(self.resource_unit_names)
-        return s
-
-    def __repr__(self):
-        return str(self)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from collections.abc import Collection
+from copy import copy, deepcopy
+from enum import Enum
+from typing import Dict, Iterable, Optional, Set, Tuple, Union
+
+from skdecide.builders.domain.scheduling.task import Task
+
+
+def rebuild_tasks_complete_details_dict(state: State) -> Dict[int, Task]:
+    tasks_complete_details = {p.value.id: p.value for p in state.tasks_complete_details}
+    return tasks_complete_details
+
+
+def rebuild_all_tasks_dict(state: State) -> Dict[int, Task]:
+    tasks_details = {
+        task_id: Task(id=task_id, start=None, sampled_duration=None)
+        for task_id in state.task_ids
+    }
+    tasks_details.update({p.value.id: p.value for p in state.tasks_complete_details})
+    tasks_details.update(state.tasks_details)
+    return tasks_details
+
+
+def rebuild_tasks_modes_dict(state: State) -> Dict[int, int]:
+    tasks_modes = {p.value[0]: p.value[1] for p in state.tasks_complete_mode}
+    return tasks_modes
+
+
+def rebuild_schedule_dict(state: State) -> Dict[int, Dict[str, int]]:
+    schedule = {
+        p.value.id: {"start_time": p.value.start, "end_time": p.value.end}
+        for p in state.tasks_complete_details
+    }
+    return schedule
+
+
+class Node:
+    __slots__ = ("value", "next_node")
+
+    def __init__(self, value: Task = None, next_node=None):
+        self.value = value
+        self.next_node = next_node
+
+
+class SinglyLinkedList(Collection):
+    def __init__(self, head=None):
+        self.head = head
+
+    def push_front(self, value: Union[int, float, Task, Tuple[int, int]]):
+        self.head = Node(value, self.head)
+
+    def __iter__(self):
+        current = self.head
+        while current:
+            yield current
+            current = current.next_node
+
+    def __len__(self) -> int:
+        return sum(1 for _ in iter(self))
+
+    def __contains__(self, value: Union[int, float, Task]) -> bool:
+        for node in iter(self):
+            if node.value == value:
+                return True
+        return False
+
+    def __copy__(self):
+        return SinglyLinkedList(self.head)
+
+
+class SchedulingActionEnum(Enum):
+    """Enum defining the different types of scheduling actions"""
+
+    START = 0
+    PAUSE = 1
+    RESUME = 2
+    TIME_PR = 3
+
+
+SchedulingActionEnum.START.__doc__ = "start a task"
+SchedulingActionEnum.PAUSE.__doc__ = "pause a task"
+SchedulingActionEnum.RESUME.__doc__ = "resume a task"
+SchedulingActionEnum.TIME_PR.__doc__ = (
+    "do not apply actions on tasks and progress in time"
+)
+
+
+class State:
+    """Class modelling a scheduling state and used by sk-decide scheduling domains.
+
+    It contains the following information:
+        t: the timestamp.
+        task_ids: a list of all task ids in the scheduling domain.
+        tasks_unsatisfiable: a set containing the ids of tasks for which canditions are not fulfilled
+        tasks_ongoing: a set containing the ids of tasks started and not paused and still to be completed
+        tasks_complete: a set containing the ids of tasks that have been completed
+        tasks_paused: a set containing the ids of tasks that have been started and paused but not resumed yet
+        tasks_progress: a dictionary where the key is a task id (int) and
+            the value the progress of the task between 0 and 1 (float)
+        tasks_mode: a dictionary where the key is a task id (int) and
+            the value the mode used to execute the task (int)
+        resource_to_task: dictionary where the key is the name of a resource (str) and the value a task
+            it is currently assigned to (int)
+        resource_availability: dictionary where the key is the name of a resource (str) and the value the number of
+            resource units available for this type of resource regardless of the task assignments (int). Where the
+            resource name is a resource unit itself, the availability value takes a value of either 1 (available)
+            or 0 (unavailable)
+        resource_used: dictionary where the key is the name of a resource (str) and the value the number of
+            resource units for this resource type used/assigned on tasks at this time (int). Where the resource
+            name is a resource unit itself, the value takes a value of either 1 (used) or 0 (not used)
+        resource_used_for_task: nested dictionary where the first key is a task id (int), the second key is the name of
+            a resource (str) and the value is the number of resource units for this resource type used/assigned on tasks
+            at this time (int). Where the resource name is a resource unit itself, the value takes a value of either 1
+            (used) or 0 (not used).
+        tasks_details: dictionary where the key is the id of a task (int) and the value a Task object. This Task object
+            contains information about the task execution and can be used to post-process the run. It is only used
+            by the domain to store execution information and not used by scheduling solvers.
+        tasks_full_details: like taks_details but containing all taks, even the ones not completed.
+        _current_conditions: set of conditions observed so far, to be used by domains with WithConditionalTask
+            properties
+
+    """
+
+    # TODO : code efficient hash/eq functions. will probably be mandatory in some planning algo.
+    t: int
+    tasks_unsatisfiable: Set[int]
+    tasks_ongoing: Set[int]
+    tasks_complete: Set[int]
+    tasks_paused: Set[int]
+    tasks_progress: Dict[int, float]
+    tasks_mode: Dict[int, int]
+    resource_to_task: Dict[str, int]
+    resource_availability: Dict[str, int]
+    resource_used: Dict[str, int]
+    resource_used_for_task: Dict[int, Dict[str, int]]
+    tasks_details: Dict[
+        int, Task
+    ]  # Use to store task stats, resource used etc... for post-processing purposes
+    tasks_complete_details: SinglyLinkedList
+    tasks_complete_progress: SinglyLinkedList
+    tasks_complete_mode: SinglyLinkedList
+    _current_conditions: Set
+
+    # TODO : put the attributes in the __init__ ?!
+    def __init__(self, task_ids: Iterable[int], tasks_available: Set[int] = None):
+        """Initialize a scheduling state.
+
+        # Parameters
+        task_ids: a list of all task ids in the scheduling domain.
+        tasks_available: a set of task ids that are available for scheduling. This may differ from task_ids if the
+         domain contains conditional tasks.
+        """
+        self.t = 0
+        self.task_ids = task_ids if isinstance(task_ids, set) else set(task_ids)
+        self.tasks_unsatisfiable = (
+            set()
+            if tasks_available is None
+            else set(t for t in self.task_ids if t not in tasks_available)
+        )
+        self.tasks_ongoing = set()
+        self.tasks_complete = set()
+        self.tasks_paused = set()
+        self.tasks_progress = {}
+        self.tasks_mode = {}
+        self.resource_to_task = {}
+        self.resource_availability = {}
+        self.resource_used = {}
+        self.resource_used_for_task = {}
+        self.tasks_details = {}
+        self.tasks_complete_details = SinglyLinkedList()
+        self.tasks_complete_progress = SinglyLinkedList()
+        self.tasks_complete_mode = SinglyLinkedList()
+        self._current_conditions = set()
+
+    def copy(self):
+        s = State(task_ids=self.task_ids)
+        s.t = self.t
+        s.tasks_unsatisfiable = deepcopy(self.tasks_unsatisfiable)
+        s.tasks_ongoing = deepcopy(self.tasks_ongoing)
+        s.tasks_complete = deepcopy(self.tasks_complete)
+        s.tasks_paused = deepcopy(self.tasks_paused)
+        s.tasks_progress = deepcopy(self.tasks_progress)
+        s.tasks_mode = deepcopy(self.tasks_mode)
+        s.resource_to_task = deepcopy(self.resource_to_task)
+        s.resource_availability = deepcopy(self.resource_availability)
+        s.resource_used = deepcopy(self.resource_used)
+        s.resource_used_for_task = deepcopy(self.resource_used_for_task)
+        s.tasks_details = deepcopy(self.tasks_details)
+        s._current_conditions = deepcopy(self._current_conditions)
+        s.tasks_complete_details = copy(self.tasks_complete_details)
+        s.tasks_complete_progress = copy(self.tasks_complete_progress)
+        s.tasks_complete_mode = copy(self.tasks_complete_mode)
+        return s
+
+    @property
+    def tasks_full_details(self) -> Dict[int, Task]:
+        return rebuild_all_tasks_dict(self)
+
+    @property
+    def tasks_remaining(self):
+        for task in self.task_ids:
+            if (
+                task not in self.tasks_complete
+                and task not in self.tasks_progress
+                and task not in self.tasks_unsatisfiable
+            ):
+                yield task
+
+    def __str__(self):
+        s = "State : " + "\n"
+        for key in sorted(self.__dict__.keys()):
+            if key == "tasks_details":
+                for key2 in sorted(self.tasks_details.keys()):
+                    s += str(self.tasks_details[key2]) + "\t"
+            elif key.startswith("tasks_complete_"):
+                for node in getattr(self, key):
+                    s += str(node.value) + "\t"
+            else:
+                s += str(key) + ":" + str(getattr(self, key)) + "\n"
+        return s
+
+    def __repr__(self):
+        return str(self)
+
+    def __hash__(self):
+        return hash(str(self))
+
+    def __eq__(self, other):
+        return self.__hash__() == other.__hash__()
+
+
+class SchedulingAction:
+    """
+    Can be used to define actions on single task. Resource allocation can only be managed through changes in the mode.
+    The time_progress attribute triggers a change in time (i.e. triggers the domain to increment its current time).
+    It should thus be used as the last action to be applied at any point in time
+    These actions are enumerable due to their coarse grain definition.
+
+    E.g.
+        task = 12 (start action 12 in mode 1)
+        action = EnumerableActionEnum.START
+        mode = 1
+        time_progress = False
+
+    E.g. (pause action 13, NB: mode info is not useful here)
+        task = 13
+        action = EnumerableActionEnum.PAUSE
+        mode = None
+        time_progress = False
+
+    E.g. (do nothing and progress in time)
+        task = None
+        action = None
+        mode = None
+        time_progress = True
+    """
+
+    task: int
+    action: SchedulingActionEnum
+    mode: int
+    time_progress: bool
+
+    def __init__(
+        self,
+        task: Union[int, None],
+        action: SchedulingActionEnum,
+        mode: Union[int, None],
+        time_progress: bool,
+        resource_unit_names: Optional[Set[str]] = None,
+    ):
+        self.task = task
+        self.action = action
+        self.mode = mode
+        self.time_progress = time_progress
+        self.resource_unit_names = resource_unit_names
+
+    def __str__(self):
+        s = "Action \n"
+        s += "Task : " + str(self.task) + "\n"
+        s += "Mode : " + str(self.mode) + "\n"
+        s += "Action type " + str(self.action.name) + "\n"
+        s += "Time progress " + str(self.time_progress) + "\n"
+        s += "Resource : " + str(self.resource_unit_names)
+        return s
+
+    def __repr__(self):
+        return str(self)
```

## skdecide/builders/domain/scheduling/skills.py

 * *Ordering differences only*

```diff
@@ -1,130 +1,130 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Dict, List, Set
-
-__all__ = ["WithResourceSkills", "WithoutResourceSkills"]
-
-
-class WithResourceSkills:
-    """A domain must inherit this class if its resources (either resource types or resource units)
-    have different set of skills."""
-
-    def get_skills_names(self) -> Set[str]:
-        """Return a list of all skill names as a list of str. Skill names are defined in the 2 dictionaries returned
-        by the get_all_resources_skills and get_all_tasks_skills functions."""
-        all_names = set()
-        skill_dict = self.get_all_resources_skills()
-        for key1 in skill_dict.keys():
-            for key2 in skill_dict[key1].keys():
-                all_names.add(key2)
-
-        skill_dict = self.get_all_tasks_skills()
-        for key1 in skill_dict.keys():
-            for mode in skill_dict[key1].keys():
-                for key2 in skill_dict[key1][mode].keys():
-                    all_names.add(key2)
-        return all_names
-
-    def get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
-        """Return a nested dictionary where the first key is the name of a resource type or resource unit
-        and the second key is the name of a skill. The value defines the details of the skill.
-         E.g. {unit: {skill: (detail of skill)}}"""
-        return self._get_all_resources_skills()
-
-    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
-        """Return a nested dictionary where the first key is the name of a resource type or resource unit
-        and the second key is the name of a skill. The value defines the details of the skill.
-         E.g. {unit: {skill: (detail of skill)}}"""
-        raise NotImplementedError
-
-    def get_skills_of_resource(self, resource: str) -> Dict[str, Any]:
-        """Return the skills of a given resource"""
-        return self.get_all_resources_skills()[resource]
-
-    def get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
-        """Return a nested dictionary where the first key is the name of a task
-        and the second key is the name of a skill. The value defines the details of the skill.
-         E.g. {task: {skill: (detail of skill)}}"""
-        return self._get_all_tasks_skills()
-
-    def _get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
-        """Return a nested dictionary where the first key is the name of a task
-        and the second key is the name of a skill. The value defines the details of the skill.
-         E.g. {task: {skill: (detail of skill)}}"""
-        raise NotImplementedError
-
-    def get_skills_of_task(self, task: int, mode: int) -> Dict[str, Any]:
-        """Return the skill requirements for a given task"""
-        return {
-            s: self.get_all_tasks_skills()[task][mode][s]
-            for s in self.get_all_tasks_skills()[task][mode]
-            if self.get_all_tasks_skills()[task][mode][s] > 0
-        }
-
-    def find_one_ressource_to_do_one_task(self, task: int, mode: int) -> List[str]:
-        """
-        For the common case when it is possible to do the task by one resource unit.
-        For general case, it might just return no possible ressource unit.
-        """
-        skill_of_task = self.get_skills_of_task(task, mode)
-        resources = []
-        if len(skill_of_task) == 0:
-            return [None]
-        for resource in self.get_all_resources_skills():
-            if all(
-                self.get_skills_of_resource(resource=resource).get(s, 0)
-                >= skill_of_task[s]
-                for s in skill_of_task
-            ):
-                resources += [resource]
-        # print("Ressources ", resources, " can do the task")
-        return resources
-
-    def check_if_skills_are_fulfilled(
-        self, task: int, mode: int, resource_used: Dict[str, int]
-    ):
-        skill_of_task = self.get_skills_of_task(task, mode)
-        if len(skill_of_task) == 0:
-            return True  # No need of skills here.
-        skills = {s: 0 for s in skill_of_task}
-        for r in resource_used:
-            skill_of_ressource = self.get_skills_of_resource(resource=r)
-            for s in skill_of_ressource:
-                if s in skills:
-                    skills[s] += skill_of_ressource[s]
-        # print("Ressource used : ", skills)
-        # print("Skills required", skill_of_task)
-        return all(skills[s] >= skill_of_task[s] for s in skill_of_task)
-
-
-class WithoutResourceSkills(WithResourceSkills):
-    """A domain must inherit this class if no resources skills have to be considered."""
-
-    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
-        """Return a nested dictionary where the first key is the name of a resource type or resource unit
-        and the second key is the name of a skill. The value defines the details of the skill.
-         E.g. {unit: {skill: (detail of skill)}}"""
-        return {}
-
-    def get_skills_of_resource(self, resource: str) -> Dict[str, Any]:
-        """Return the skills of a given resource"""
-        return {}
-
-    def _get_all_tasks_skills(self) -> Dict[int, Dict[str, Any]]:
-        """Return a nested dictionary where the first key is the name of a task
-        and the second key is the name of a skill. The value defines the details of the skill.
-         E.g. {task: {skill: (detail of skill)}}"""
-        return {}
-
-    def get_skills_of_task(self, task: int, mode: int) -> Dict[str, Any]:
-        """Return the skill requirements for a given task"""
-        return {}
-
-    def check_if_skills_are_fulfilled(
-        self, task: int, mode: int, resource_used: Dict[str, int]
-    ):
-        return True
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Dict, List, Set
+
+__all__ = ["WithResourceSkills", "WithoutResourceSkills"]
+
+
+class WithResourceSkills:
+    """A domain must inherit this class if its resources (either resource types or resource units)
+    have different set of skills."""
+
+    def get_skills_names(self) -> Set[str]:
+        """Return a list of all skill names as a list of str. Skill names are defined in the 2 dictionaries returned
+        by the get_all_resources_skills and get_all_tasks_skills functions."""
+        all_names = set()
+        skill_dict = self.get_all_resources_skills()
+        for key1 in skill_dict.keys():
+            for key2 in skill_dict[key1].keys():
+                all_names.add(key2)
+
+        skill_dict = self.get_all_tasks_skills()
+        for key1 in skill_dict.keys():
+            for mode in skill_dict[key1].keys():
+                for key2 in skill_dict[key1][mode].keys():
+                    all_names.add(key2)
+        return all_names
+
+    def get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
+        """Return a nested dictionary where the first key is the name of a resource type or resource unit
+        and the second key is the name of a skill. The value defines the details of the skill.
+         E.g. {unit: {skill: (detail of skill)}}"""
+        return self._get_all_resources_skills()
+
+    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
+        """Return a nested dictionary where the first key is the name of a resource type or resource unit
+        and the second key is the name of a skill. The value defines the details of the skill.
+         E.g. {unit: {skill: (detail of skill)}}"""
+        raise NotImplementedError
+
+    def get_skills_of_resource(self, resource: str) -> Dict[str, Any]:
+        """Return the skills of a given resource"""
+        return self.get_all_resources_skills()[resource]
+
+    def get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
+        """Return a nested dictionary where the first key is the name of a task
+        and the second key is the name of a skill. The value defines the details of the skill.
+         E.g. {task: {skill: (detail of skill)}}"""
+        return self._get_all_tasks_skills()
+
+    def _get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
+        """Return a nested dictionary where the first key is the name of a task
+        and the second key is the name of a skill. The value defines the details of the skill.
+         E.g. {task: {skill: (detail of skill)}}"""
+        raise NotImplementedError
+
+    def get_skills_of_task(self, task: int, mode: int) -> Dict[str, Any]:
+        """Return the skill requirements for a given task"""
+        return {
+            s: self.get_all_tasks_skills()[task][mode][s]
+            for s in self.get_all_tasks_skills()[task][mode]
+            if self.get_all_tasks_skills()[task][mode][s] > 0
+        }
+
+    def find_one_ressource_to_do_one_task(self, task: int, mode: int) -> List[str]:
+        """
+        For the common case when it is possible to do the task by one resource unit.
+        For general case, it might just return no possible ressource unit.
+        """
+        skill_of_task = self.get_skills_of_task(task, mode)
+        resources = []
+        if len(skill_of_task) == 0:
+            return [None]
+        for resource in self.get_all_resources_skills():
+            if all(
+                self.get_skills_of_resource(resource=resource).get(s, 0)
+                >= skill_of_task[s]
+                for s in skill_of_task
+            ):
+                resources += [resource]
+        # print("Ressources ", resources, " can do the task")
+        return resources
+
+    def check_if_skills_are_fulfilled(
+        self, task: int, mode: int, resource_used: Dict[str, int]
+    ):
+        skill_of_task = self.get_skills_of_task(task, mode)
+        if len(skill_of_task) == 0:
+            return True  # No need of skills here.
+        skills = {s: 0 for s in skill_of_task}
+        for r in resource_used:
+            skill_of_ressource = self.get_skills_of_resource(resource=r)
+            for s in skill_of_ressource:
+                if s in skills:
+                    skills[s] += skill_of_ressource[s]
+        # print("Ressource used : ", skills)
+        # print("Skills required", skill_of_task)
+        return all(skills[s] >= skill_of_task[s] for s in skill_of_task)
+
+
+class WithoutResourceSkills(WithResourceSkills):
+    """A domain must inherit this class if no resources skills have to be considered."""
+
+    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
+        """Return a nested dictionary where the first key is the name of a resource type or resource unit
+        and the second key is the name of a skill. The value defines the details of the skill.
+         E.g. {unit: {skill: (detail of skill)}}"""
+        return {}
+
+    def get_skills_of_resource(self, resource: str) -> Dict[str, Any]:
+        """Return the skills of a given resource"""
+        return {}
+
+    def _get_all_tasks_skills(self) -> Dict[int, Dict[str, Any]]:
+        """Return a nested dictionary where the first key is the name of a task
+        and the second key is the name of a skill. The value defines the details of the skill.
+         E.g. {task: {skill: (detail of skill)}}"""
+        return {}
+
+    def get_skills_of_task(self, task: int, mode: int) -> Dict[str, Any]:
+        """Return the skill requirements for a given task"""
+        return {}
+
+    def check_if_skills_are_fulfilled(
+        self, task: int, mode: int, resource_used: Dict[str, int]
+    ):
+        return True
```

## skdecide/builders/domain/scheduling/task.py

 * *Ordering differences only*

```diff
@@ -1,64 +1,64 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from enum import Enum
-from typing import Dict, List, Optional
-
-# __all__ = ['Task', 'Status']
-#
-#
-# class Status(Enum):
-#     unreleased = 0
-#     released = 1
-#     ongoing = 2
-#     complete = 3
-
-
-class Task:
-
-    id: int
-    start: int
-    end: int
-    sampled_duration: int
-    mode: int
-    paused: List[int]
-    resumed: List[int]
-
-    def __init__(self, id: int, start: int, sampled_duration: int):
-        self.id = id
-        self.start = start
-        self.end = None
-        self.sampled_duration = sampled_duration
-        self.mode = None
-        self.paused = []
-        self.resumed = []
-
-    def get_task_active_time(self, t: Optional[int] = None):
-        tt = t
-        if self.end is not None:
-            tt = min(t, self.end)
-        if self.start is None:
-            return 0
-        time_since_start = tt - self.start
-        time_paused = 0
-        for i in range(len(self.paused)):
-            time_paused += self.resumed[i] - self.paused[i]
-        total_active_time = time_since_start - time_paused
-        return total_active_time
-
-    def __str__(self):
-        out = ""
-        for key in sorted(self.__dict__.keys()):
-            out += str(key) + ":" + str(getattr(self, key)) + ","
-        return out
-
-    # def __copy__(self):
-    #     s = Task(id=self.id, status=self.status)
-    #     s.start = self.start
-    #     s.end = self.end
-    #     s.progress = self.progress
-    #     s.mode = self.mode
-    #     return s
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from enum import Enum
+from typing import Dict, List, Optional
+
+# __all__ = ['Task', 'Status']
+#
+#
+# class Status(Enum):
+#     unreleased = 0
+#     released = 1
+#     ongoing = 2
+#     complete = 3
+
+
+class Task:
+
+    id: int
+    start: int
+    end: int
+    sampled_duration: int
+    mode: int
+    paused: List[int]
+    resumed: List[int]
+
+    def __init__(self, id: int, start: int, sampled_duration: int):
+        self.id = id
+        self.start = start
+        self.end = None
+        self.sampled_duration = sampled_duration
+        self.mode = None
+        self.paused = []
+        self.resumed = []
+
+    def get_task_active_time(self, t: Optional[int] = None):
+        tt = t
+        if self.end is not None:
+            tt = min(t, self.end)
+        if self.start is None:
+            return 0
+        time_since_start = tt - self.start
+        time_paused = 0
+        for i in range(len(self.paused)):
+            time_paused += self.resumed[i] - self.paused[i]
+        total_active_time = time_since_start - time_paused
+        return total_active_time
+
+    def __str__(self):
+        out = ""
+        for key in sorted(self.__dict__.keys()):
+            out += str(key) + ":" + str(getattr(self, key)) + ","
+        return out
+
+    # def __copy__(self):
+    #     s = Task(id=self.id, status=self.status)
+    #     s.start = self.start
+    #     s.end = self.end
+    #     s.progress = self.progress
+    #     s.mode = self.mode
+    #     return s
```

## skdecide/builders/domain/scheduling/task_duration.py

 * *Ordering differences only*

```diff
@@ -1,292 +1,292 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict, Optional
-
-from skdecide.core import DiscreteDistribution, Distribution
-
-__all__ = [
-    "SimulatedTaskDuration",
-    "UncertainMultivariateTaskDuration",
-    "UncertainUnivariateTaskDuration",
-    "UncertainBoundedTaskDuration",
-    "UniformBoundedTaskDuration",
-    "EnumerableTaskDuration",
-    "DeterministicTaskDuration",
-]
-
-
-class SimulatedTaskDuration:
-    """A domain must inherit this class if the task duration requires sampling from a simulation."""
-
-    # TODO, this can be challenged.. for uncertain domain (with adistribution, you want to sample a different value each time.
-    # that 's why i override this sample_task_duration in below level.
-    def sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Sample, store and return task duration for the given task in the given mode."""
-        if task not in self.sampled_durations:
-            self.sampled_durations[task] = {}
-        if mode not in self.sampled_durations[task]:
-            self.sampled_durations[task][mode] = {}
-        if progress_from not in self.sampled_durations[task][mode]:
-            self.sampled_durations[task][mode][
-                progress_from
-            ] = self._sample_task_duration(task, mode, progress_from)
-        return self.sampled_durations[task][mode][progress_from]
-
-    def _sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode."""
-        raise NotImplementedError
-
-    def get_latest_sampled_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ):
-        if task in self.sampled_durations:
-            if mode in self.sampled_durations[task]:
-                if progress_from in self.sampled_durations[task][mode]:
-                    return self.sampled_durations[task][mode][progress_from]
-        return self.sample_task_duration(task, mode, progress_from)
-
-
-# TODO: Can we currently model multivariate distribution with the Distribution object ?
-class UncertainMultivariateTaskDuration(SimulatedTaskDuration):
-    """A domain must inherit this class if the task duration is uncertain and follows a know multivariate
-    distribution."""
-
-    def sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode,
-        sampled from the underlying multiivariate distribution."""
-        return self._sample_task_duration(
-            task=task, mode=mode, progress_from=progress_from
-        )
-
-    def _sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode,
-        sampled from the underlying multiivariate distribution."""
-        return self.get_task_duration_distribution(task, mode).sample()
-
-    def get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> Distribution:
-        """Return the multivariate Distribution of the duration of the given task in the given mode.
-        Multivariate seetings need to be provided."""
-        return self._get_task_duration_distribution(
-            task, mode, progress_from, multivariate_settings
-        )
-
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> Distribution:
-        """Return the multivariate Distribution of the duration of the given task in the given mode.
-        Multivariate seetings need to be provided."""
-        raise NotImplementedError
-
-
-class UncertainUnivariateTaskDuration(UncertainMultivariateTaskDuration):
-    """A domain must inherit this class if the task duration is uncertain and follows a know univariate distribution."""
-
-    def _sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode,
-        sampled from the underlying univariate distribution."""
-        return self.get_task_duration_distribution(task, mode).sample()
-
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> Distribution:  # TODO, problem here i think
-        """Return the univariate Distribution of the duration of the given task in the given mode."""
-        raise NotImplementedError
-
-
-class UncertainBoundedTaskDuration(UncertainUnivariateTaskDuration):
-    """A domain must inherit this class if the task duration is known to be between a lower and upper bound
-    and follows a known distribution between these bounds."""
-
-    def _sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode,
-        sampled from the underlying univariate bounded distribution."""
-        return self.get_task_duration_distribution(task, mode).sample()
-
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> DiscreteDistribution:
-        """Return the Distribution of the duration of the given task in the given mode.
-        The distribution returns values beween the defined lower and upper bounds."""
-        raise NotImplementedError
-
-    def get_task_duration_upper_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the upper bound for the task duration of the given task in the given mode."""
-        return self._get_task_duration_upper_bound(task, mode, progress_from)
-
-    def _get_task_duration_upper_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the upper bound for the task duration of the given task in the given mode."""
-        raise NotImplementedError
-
-    def get_task_duration_lower_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the lower bound for the task duration of the given task in the given mode."""
-        return self._get_task_duration_lower_bound(task, mode, progress_from)
-
-    def _get_task_duration_lower_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the lower bound for the task duration of the given task in the given mode."""
-        raise NotImplementedError
-
-
-class UniformBoundedTaskDuration(UncertainBoundedTaskDuration):
-    """A domain must inherit this class if the task duration is known to be between a lower and upper bound
-    and follows a uniform distribution between these bounds."""
-
-    def _sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode,
-        sampled from the underlying univariate uniform bounded distribution."""
-        return self.get_task_duration_distribution(task, mode).sample()
-
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> DiscreteDistribution:
-        """Return the Distribution of the duration of the given task in the given mode.
-        The distribution is uniform between the defined lower and upper bounds."""
-        lb = self.get_task_duration_lower_bound(task, mode)
-        ub = self.get_task_duration_upper_bound(task, mode)
-        n_vals = ub - lb + 1
-        p = 1.0 / float(n_vals)
-        values = [(x, p) for x in range(lb, ub + 1)]
-        return DiscreteDistribution(values)
-
-    def _get_task_duration_upper_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the upper bound for the task duration of the given task in the given mode."""
-        raise NotImplementedError
-
-    def _get_task_duration_lower_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the lower bound for the task duration of the given task in the given mode."""
-        raise NotImplementedError
-
-
-class EnumerableTaskDuration(UncertainBoundedTaskDuration):
-    """A domain must inherit this class if the task duration for each task is enumerable."""
-
-    def _sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode."""
-        return self.get_task_duration_distribution(task, mode).sample()
-
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> DiscreteDistribution:
-        """Return the Distribution of the duration of the given task in the given mode.
-        as an Enumerable."""
-        raise NotImplementedError
-
-    def _get_task_duration_upper_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the upper bound for the task duration of the given task in the given mode."""
-        duration_vals = [
-            x[0] for x in self.get_task_duration_distribution(task, mode).get_values()
-        ]
-        return max(duration_vals)
-
-    def _get_task_duration_lower_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the lower bound for the task duration of the given task in the given mode."""
-        duration_vals = [
-            x[0] for x in self.get_task_duration_distribution(task, mode).get_values()
-        ]
-        return min(duration_vals)
-
-
-class DeterministicTaskDuration(EnumerableTaskDuration):
-    """A domain must inherit this class if the task durations are known and deterministic."""
-
-    def _sample_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return a task duration for the given task in the given mode."""
-        return self.get_task_duration(task, mode, progress_from)
-
-    def get_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the fixed deterministic task duration of the given task in the given mode."""
-        return self._get_task_duration(task, mode, progress_from)
-
-    def _get_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the fixed deterministic task duration of the given task in the given mode."""
-        raise NotImplementedError
-
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ):
-        """Return the Distribution of the duration of the given task in the given mode.
-        Because the duration is deterministic, the distribution always returns the same duration."""
-        return DiscreteDistribution([(self.get_task_duration(task, mode), 1)])
-
-    def _get_task_duration_upper_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the upper bound for the task duration of the given task in the given mode."""
-        return self.get_task_duration(task, mode)
-
-    def _get_task_duration_lower_bound(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        """Return the lower bound for the task duration of the given task in the given mode."""
-        return self.get_task_duration(task, mode)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict, Optional
+
+from skdecide.core import DiscreteDistribution, Distribution
+
+__all__ = [
+    "SimulatedTaskDuration",
+    "UncertainMultivariateTaskDuration",
+    "UncertainUnivariateTaskDuration",
+    "UncertainBoundedTaskDuration",
+    "UniformBoundedTaskDuration",
+    "EnumerableTaskDuration",
+    "DeterministicTaskDuration",
+]
+
+
+class SimulatedTaskDuration:
+    """A domain must inherit this class if the task duration requires sampling from a simulation."""
+
+    # TODO, this can be challenged.. for uncertain domain (with adistribution, you want to sample a different value each time.
+    # that 's why i override this sample_task_duration in below level.
+    def sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Sample, store and return task duration for the given task in the given mode."""
+        if task not in self.sampled_durations:
+            self.sampled_durations[task] = {}
+        if mode not in self.sampled_durations[task]:
+            self.sampled_durations[task][mode] = {}
+        if progress_from not in self.sampled_durations[task][mode]:
+            self.sampled_durations[task][mode][
+                progress_from
+            ] = self._sample_task_duration(task, mode, progress_from)
+        return self.sampled_durations[task][mode][progress_from]
+
+    def _sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode."""
+        raise NotImplementedError
+
+    def get_latest_sampled_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ):
+        if task in self.sampled_durations:
+            if mode in self.sampled_durations[task]:
+                if progress_from in self.sampled_durations[task][mode]:
+                    return self.sampled_durations[task][mode][progress_from]
+        return self.sample_task_duration(task, mode, progress_from)
+
+
+# TODO: Can we currently model multivariate distribution with the Distribution object ?
+class UncertainMultivariateTaskDuration(SimulatedTaskDuration):
+    """A domain must inherit this class if the task duration is uncertain and follows a know multivariate
+    distribution."""
+
+    def sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode,
+        sampled from the underlying multiivariate distribution."""
+        return self._sample_task_duration(
+            task=task, mode=mode, progress_from=progress_from
+        )
+
+    def _sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode,
+        sampled from the underlying multiivariate distribution."""
+        return self.get_task_duration_distribution(task, mode).sample()
+
+    def get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> Distribution:
+        """Return the multivariate Distribution of the duration of the given task in the given mode.
+        Multivariate seetings need to be provided."""
+        return self._get_task_duration_distribution(
+            task, mode, progress_from, multivariate_settings
+        )
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> Distribution:
+        """Return the multivariate Distribution of the duration of the given task in the given mode.
+        Multivariate seetings need to be provided."""
+        raise NotImplementedError
+
+
+class UncertainUnivariateTaskDuration(UncertainMultivariateTaskDuration):
+    """A domain must inherit this class if the task duration is uncertain and follows a know univariate distribution."""
+
+    def _sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode,
+        sampled from the underlying univariate distribution."""
+        return self.get_task_duration_distribution(task, mode).sample()
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> Distribution:  # TODO, problem here i think
+        """Return the univariate Distribution of the duration of the given task in the given mode."""
+        raise NotImplementedError
+
+
+class UncertainBoundedTaskDuration(UncertainUnivariateTaskDuration):
+    """A domain must inherit this class if the task duration is known to be between a lower and upper bound
+    and follows a known distribution between these bounds."""
+
+    def _sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode,
+        sampled from the underlying univariate bounded distribution."""
+        return self.get_task_duration_distribution(task, mode).sample()
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> DiscreteDistribution:
+        """Return the Distribution of the duration of the given task in the given mode.
+        The distribution returns values beween the defined lower and upper bounds."""
+        raise NotImplementedError
+
+    def get_task_duration_upper_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the upper bound for the task duration of the given task in the given mode."""
+        return self._get_task_duration_upper_bound(task, mode, progress_from)
+
+    def _get_task_duration_upper_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the upper bound for the task duration of the given task in the given mode."""
+        raise NotImplementedError
+
+    def get_task_duration_lower_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the lower bound for the task duration of the given task in the given mode."""
+        return self._get_task_duration_lower_bound(task, mode, progress_from)
+
+    def _get_task_duration_lower_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the lower bound for the task duration of the given task in the given mode."""
+        raise NotImplementedError
+
+
+class UniformBoundedTaskDuration(UncertainBoundedTaskDuration):
+    """A domain must inherit this class if the task duration is known to be between a lower and upper bound
+    and follows a uniform distribution between these bounds."""
+
+    def _sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode,
+        sampled from the underlying univariate uniform bounded distribution."""
+        return self.get_task_duration_distribution(task, mode).sample()
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> DiscreteDistribution:
+        """Return the Distribution of the duration of the given task in the given mode.
+        The distribution is uniform between the defined lower and upper bounds."""
+        lb = self.get_task_duration_lower_bound(task, mode)
+        ub = self.get_task_duration_upper_bound(task, mode)
+        n_vals = ub - lb + 1
+        p = 1.0 / float(n_vals)
+        values = [(x, p) for x in range(lb, ub + 1)]
+        return DiscreteDistribution(values)
+
+    def _get_task_duration_upper_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the upper bound for the task duration of the given task in the given mode."""
+        raise NotImplementedError
+
+    def _get_task_duration_lower_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the lower bound for the task duration of the given task in the given mode."""
+        raise NotImplementedError
+
+
+class EnumerableTaskDuration(UncertainBoundedTaskDuration):
+    """A domain must inherit this class if the task duration for each task is enumerable."""
+
+    def _sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode."""
+        return self.get_task_duration_distribution(task, mode).sample()
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> DiscreteDistribution:
+        """Return the Distribution of the duration of the given task in the given mode.
+        as an Enumerable."""
+        raise NotImplementedError
+
+    def _get_task_duration_upper_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the upper bound for the task duration of the given task in the given mode."""
+        duration_vals = [
+            x[0] for x in self.get_task_duration_distribution(task, mode).get_values()
+        ]
+        return max(duration_vals)
+
+    def _get_task_duration_lower_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the lower bound for the task duration of the given task in the given mode."""
+        duration_vals = [
+            x[0] for x in self.get_task_duration_distribution(task, mode).get_values()
+        ]
+        return min(duration_vals)
+
+
+class DeterministicTaskDuration(EnumerableTaskDuration):
+    """A domain must inherit this class if the task durations are known and deterministic."""
+
+    def _sample_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return a task duration for the given task in the given mode."""
+        return self.get_task_duration(task, mode, progress_from)
+
+    def get_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the fixed deterministic task duration of the given task in the given mode."""
+        return self._get_task_duration(task, mode, progress_from)
+
+    def _get_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the fixed deterministic task duration of the given task in the given mode."""
+        raise NotImplementedError
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ):
+        """Return the Distribution of the duration of the given task in the given mode.
+        Because the duration is deterministic, the distribution always returns the same duration."""
+        return DiscreteDistribution([(self.get_task_duration(task, mode), 1)])
+
+    def _get_task_duration_upper_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the upper bound for the task duration of the given task in the given mode."""
+        return self.get_task_duration(task, mode)
+
+    def _get_task_duration_lower_bound(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        """Return the lower bound for the task duration of the given task in the given mode."""
+        return self.get_task_duration(task, mode)
```

## skdecide/builders/domain/scheduling/task_progress.py

 * *Ordering differences only*

```diff
@@ -1,69 +1,69 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict, List, Optional, Union
-
-__all__ = ["CustomTaskProgress", "DeterministicTaskProgress"]
-
-
-class CustomTaskProgress:
-    """A domain must inherit this class if the task progress is uncertain."""
-
-    def get_task_progress(
-        self,
-        task: int,
-        t_from: int,
-        t_to: int,
-        mode: Optional[int],
-        sampled_duration: Optional[int] = None,
-    ) -> float:
-        """
-        # Returns
-         The task progress (float) between t_from and t_to.
-        """
-        return self._get_task_progress(task, t_from, t_to, mode, sampled_duration)
-
-    def _get_task_progress(
-        self,
-        task: int,
-        t_from: int,
-        t_to: int,
-        mode: Optional[int],
-        sampled_duration: Optional[int] = None,
-    ) -> float:
-        """
-        # Returns
-         The task progress (float) between t_from and t_to.
-        """
-        raise NotImplementedError
-
-
-class DeterministicTaskProgress(CustomTaskProgress):
-    """A domain must inherit this class if the task progress is deterministic and can be considered as linear
-    over the duration of the task."""
-
-    def _get_task_progress(
-        self,
-        task: int,
-        t_from: int,
-        t_to: int,
-        mode: Optional[int],
-        sampled_duration: Optional[int] = None,
-    ) -> float:
-        """
-        # Returns
-         The task progress (float) between t_from and t_to based on the task duration
-        and assuming linear progress."""
-        duration = (
-            self.get_latest_sampled_duration(task, mode)
-            if sampled_duration is None
-            else sampled_duration
-        )
-        if duration == 0.0:
-            progress = 1
-        else:
-            progress = float((t_to - t_from)) / float(duration)
-        return progress
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict, List, Optional, Union
+
+__all__ = ["CustomTaskProgress", "DeterministicTaskProgress"]
+
+
+class CustomTaskProgress:
+    """A domain must inherit this class if the task progress is uncertain."""
+
+    def get_task_progress(
+        self,
+        task: int,
+        t_from: int,
+        t_to: int,
+        mode: Optional[int],
+        sampled_duration: Optional[int] = None,
+    ) -> float:
+        """
+        # Returns
+         The task progress (float) between t_from and t_to.
+        """
+        return self._get_task_progress(task, t_from, t_to, mode, sampled_duration)
+
+    def _get_task_progress(
+        self,
+        task: int,
+        t_from: int,
+        t_to: int,
+        mode: Optional[int],
+        sampled_duration: Optional[int] = None,
+    ) -> float:
+        """
+        # Returns
+         The task progress (float) between t_from and t_to.
+        """
+        raise NotImplementedError
+
+
+class DeterministicTaskProgress(CustomTaskProgress):
+    """A domain must inherit this class if the task progress is deterministic and can be considered as linear
+    over the duration of the task."""
+
+    def _get_task_progress(
+        self,
+        task: int,
+        t_from: int,
+        t_to: int,
+        mode: Optional[int],
+        sampled_duration: Optional[int] = None,
+    ) -> float:
+        """
+        # Returns
+         The task progress (float) between t_from and t_to based on the task duration
+        and assuming linear progress."""
+        duration = (
+            self.get_latest_sampled_duration(task, mode)
+            if sampled_duration is None
+            else sampled_duration
+        )
+        if duration == 0.0:
+            progress = 1
+        else:
+            progress = float((t_to - t_from)) / float(duration)
+        return progress
```

## skdecide/builders/domain/scheduling/time_lag.py

 * *Ordering differences only*

```diff
@@ -1,100 +1,100 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict
-
-__all__ = [
-    "TimeLag",
-    "MinimumOnlyTimeLag",
-    "MaximumOnlyTimeLag",
-    "WithTimeLag",
-    "WithoutTimeLag",
-]
-
-
-class TimeLag:
-    """Defines a time lag with both a minimum time lag and maximum time lag."""
-
-    def __init__(self, minimum_time_lag, maximum_time_lags):
-        self.minimum_time_lag = minimum_time_lag
-        self.maximum_time_lags = maximum_time_lags
-
-
-class MinimumOnlyTimeLag(TimeLag):
-    """Defines a minimum time lag."""
-
-    def __init__(self, minimum_time_lag):
-        self.minimum_time_lag = minimum_time_lag
-        self.maximum_time_lags = self.get_max_horizon()
-
-
-class MaximumOnlyTimeLag(TimeLag):
-    """Defines a maximum time lag."""
-
-    def __init__(self, maximum_time_lags):
-        self.minimum_time_lag = 0
-        self.maximum_time_lags = maximum_time_lags
-
-
-class WithTimeLag:
-    """A domain must inherit this class if there are minimum and maximum time lags between some of its tasks."""
-
-    def get_time_lags(self) -> Dict[int, Dict[int, TimeLag]]:
-        """
-        Return nested dictionaries where the first key is the id of a task (int)
-        and the second key is the id of another task (int).
-        The value is a TimeLag object containing the MINIMUM and MAXIMUM time (int) that needs to separate the end
-        of the first task to the start of the second task.
-
-        e.g.
-            {
-                12:{
-                    15: TimeLag(5, 10),
-                    16: TimeLag(5, 20),
-                    17: MinimumOnlyTimeLag(5),
-                    18: MaximumOnlyTimeLag(15),
-                }
-            }
-
-        # Returns
-        A dictionary of TimeLag objects.
-
-        """
-        return self._get_time_lags()
-
-    def _get_time_lags(self) -> Dict[int, Dict[int, TimeLag]]:
-        """
-        Return nested dictionaries where the first key is the id of a task (int)
-        and the second key is the id of another task (int).
-        The value is a TimeLag object containing the MINIMUM and MAXIMUM time (int) that needs to separate the end
-        of the first task to the start of the second task.
-
-        e.g.
-            {
-                12:{
-                    15: TimeLag(5, 10),
-                    16: TimeLag(5, 20),
-                    17: MinimumOnlyTimeLag(5),
-                    18: MaximumOnlyTimeLag(15),
-                }
-            }
-
-        # Returns
-        A dictionary of TimeLag objects.
-        """
-        raise NotImplementedError
-
-
-class WithoutTimeLag(WithTimeLag):
-    """A domain must inherit this class if there is no required time lag between its tasks."""
-
-    def _get_time_lags(self) -> Dict[int, Dict[int, TimeLag]]:
-        """
-        Return nested dictionaries where the first key is the id of a task (int)
-        and the second key is the id of another task (int).
-        The value is a TimeLag object containing the MINIMUM and MAXIMUM time (int) that needs to separate the end
-        of the first task to the start of the second task."""
-        return {}
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict
+
+__all__ = [
+    "TimeLag",
+    "MinimumOnlyTimeLag",
+    "MaximumOnlyTimeLag",
+    "WithTimeLag",
+    "WithoutTimeLag",
+]
+
+
+class TimeLag:
+    """Defines a time lag with both a minimum time lag and maximum time lag."""
+
+    def __init__(self, minimum_time_lag, maximum_time_lags):
+        self.minimum_time_lag = minimum_time_lag
+        self.maximum_time_lags = maximum_time_lags
+
+
+class MinimumOnlyTimeLag(TimeLag):
+    """Defines a minimum time lag."""
+
+    def __init__(self, minimum_time_lag):
+        self.minimum_time_lag = minimum_time_lag
+        self.maximum_time_lags = self.get_max_horizon()
+
+
+class MaximumOnlyTimeLag(TimeLag):
+    """Defines a maximum time lag."""
+
+    def __init__(self, maximum_time_lags):
+        self.minimum_time_lag = 0
+        self.maximum_time_lags = maximum_time_lags
+
+
+class WithTimeLag:
+    """A domain must inherit this class if there are minimum and maximum time lags between some of its tasks."""
+
+    def get_time_lags(self) -> Dict[int, Dict[int, TimeLag]]:
+        """
+        Return nested dictionaries where the first key is the id of a task (int)
+        and the second key is the id of another task (int).
+        The value is a TimeLag object containing the MINIMUM and MAXIMUM time (int) that needs to separate the end
+        of the first task to the start of the second task.
+
+        e.g.
+            {
+                12:{
+                    15: TimeLag(5, 10),
+                    16: TimeLag(5, 20),
+                    17: MinimumOnlyTimeLag(5),
+                    18: MaximumOnlyTimeLag(15),
+                }
+            }
+
+        # Returns
+        A dictionary of TimeLag objects.
+
+        """
+        return self._get_time_lags()
+
+    def _get_time_lags(self) -> Dict[int, Dict[int, TimeLag]]:
+        """
+        Return nested dictionaries where the first key is the id of a task (int)
+        and the second key is the id of another task (int).
+        The value is a TimeLag object containing the MINIMUM and MAXIMUM time (int) that needs to separate the end
+        of the first task to the start of the second task.
+
+        e.g.
+            {
+                12:{
+                    15: TimeLag(5, 10),
+                    16: TimeLag(5, 20),
+                    17: MinimumOnlyTimeLag(5),
+                    18: MaximumOnlyTimeLag(15),
+                }
+            }
+
+        # Returns
+        A dictionary of TimeLag objects.
+        """
+        raise NotImplementedError
+
+
+class WithoutTimeLag(WithTimeLag):
+    """A domain must inherit this class if there is no required time lag between its tasks."""
+
+    def _get_time_lags(self) -> Dict[int, Dict[int, TimeLag]]:
+        """
+        Return nested dictionaries where the first key is the id of a task (int)
+        and the second key is the id of another task (int).
+        The value is a TimeLag object containing the MINIMUM and MAXIMUM time (int) that needs to separate the end
+        of the first task to the start of the second task."""
+        return {}
```

## skdecide/builders/domain/scheduling/time_windows.py

 * *Ordering differences only*

```diff
@@ -1,179 +1,179 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Dict
-
-__all__ = [
-    "TimeWindow",
-    "ClassicTimeWindow",
-    "StartFromOnlyTimeWindow",
-    "StartBeforeOnlyTimeWindow",
-    "EndFromOnlyTimeWindow",
-    "EndBeforeOnlyTimeWindow",
-    "StartTimeWindow",
-    "EndTimeWindow",
-    "EmptyTimeWindow",
-    "WithTimeWindow",
-    "WithoutTimeWindow",
-]
-
-
-class TimeWindow:
-    """Defines a time window with earliest start, latest start, earliest end and latest end only."""
-
-    def __init__(
-        self,
-        earliest_start: int,
-        latest_start: int,
-        earliest_end: int,
-        latest_end: int,
-        max_horizon: int,
-    ) -> None:
-        self.earliest_start = earliest_start
-        self.latest_start = latest_start
-        self.earliest_end = earliest_end
-        self.latest_end = latest_end
-
-
-class ClassicTimeWindow(TimeWindow):
-    """Defines a time window with earliest start and latest end only."""
-
-    def __init__(self, earliest_start: int, latest_end: int, max_horizon: int) -> None:
-        self.earliest_start = earliest_start
-        self.latest_start = max_horizon
-        self.earliest_end = 0
-        self.latest_end = latest_end
-
-
-class StartFromOnlyTimeWindow(TimeWindow):
-    """Defines a time window with an earliest start only."""
-
-    def __init__(self, earliest_start: int, max_horizon: int) -> None:
-        self.earliest_start = earliest_start
-        self.latest_start = max_horizon
-        self.earliest_end = 0
-        self.latest_end = max_horizon
-
-
-class StartBeforeOnlyTimeWindow(TimeWindow):
-    """Defines a time window with an latest start only."""
-
-    def __init__(self, latest_start: int, max_horizon: int) -> None:
-        self.earliest_start = 0
-        self.latest_start = latest_start
-        self.earliest_end = 0
-        self.latest_end = max_horizon
-
-
-class EndFromOnlyTimeWindow(TimeWindow):
-    """Defines a time window with an earliest end only."""
-
-    def __init__(self, earliest_end: int, max_horizon: int) -> None:
-        self.earliest_start = 0
-        self.latest_start = max_horizon
-        self.earliest_end = earliest_end
-        self.latest_end = max_horizon
-
-
-class EndBeforeOnlyTimeWindow(TimeWindow):
-    """Defines a time window with a latest end only."""
-
-    def __init__(self, latest_end: int, max_horizon: int) -> None:
-        self.earliest_start = 0
-        self.latest_start = max_horizon
-        self.earliest_end = 0
-        self.latest_end = latest_end
-
-
-class StartTimeWindow(TimeWindow):
-    """Defines a time window with an earliest start and a latest start only."""
-
-    def __init__(
-        self, earliest_start: int, latest_start: int, max_horizon: int
-    ) -> None:
-        self.earliest_start = earliest_start
-        self.latest_start = latest_start
-        self.earliest_end = 0
-        self.latest_end = max_horizon
-
-
-class EndTimeWindow(TimeWindow):
-    """Defines a time window with an earliest end and a latest end only."""
-
-    def __init__(self, earliest_end: int, latest_end: int, max_horizon: int) -> None:
-        self.earliest_start = 0
-        self.latest_start = max_horizon
-        self.earliest_end = earliest_end
-        self.latest_end = latest_end
-
-
-class EmptyTimeWindow(TimeWindow):
-    """Defines an empty time window."""
-
-    def __init__(self, max_horizon: int) -> None:
-        self.earliest_start = 0
-        self.latest_start = max_horizon
-        self.earliest_end = 0
-        self.latest_end = max_horizon
-
-
-class WithTimeWindow:
-    """A domain must inherit this class if some tasks have time windows defined."""
-
-    def get_time_window(self) -> Dict[int, TimeWindow]:
-        """
-        Return a dictionary where the key is the id of a task (int)
-        and the value is a TimeWindow object.
-        Note that the max time horizon needs to be provided to the TimeWindow constructors
-        e.g.
-            {
-                1: TimeWindow(10, 15, 20, 30, self.get_max_horizon())
-                2: EmptyTimeWindow(self.get_max_horizon())
-                3: EndTimeWindow(20, 25, self.get_max_horizon())
-                4: EndBeforeOnlyTimeWindow(40, self.get_max_horizon())
-            }
-
-        # Returns
-        A dictionary of TimeWindow objects.
-        """
-        return self._get_time_window()
-
-    def _get_time_window(self) -> Dict[int, TimeWindow]:
-        """
-        Return a dictionary where the key is the id of a task (int)
-        and the value is a TimeWindow object.
-        Note that the max time horizon needs to be provided to the TimeWindow constructors
-        e.g.
-            {
-                1: TimeWindow(10, 15, 20, 30, self.get_max_horizon())
-                2: EmptyTimeWindow(self.get_max_horizon())
-                3: EndTimeWindow(20, 25, self.get_max_horizon())
-                4: EndBeforeOnlyTimeWindow(40, self.get_max_horizon())
-            }
-
-        # Returns
-        A dictionary of TimeWindow objects.
-
-        """
-        raise NotImplementedError
-
-
-class WithoutTimeWindow(WithTimeWindow):
-    """A domain must inherit this class if none of the tasks have restrictions on start times or end times."""
-
-    def _get_time_window(self) -> Dict[int, TimeWindow]:
-        """
-        Return a dictionary where the key is the id of a task (int)
-        and the value is a dictionary of EmptyTimeWindow object.
-
-        # Returns
-        A dictionary of TimeWindow objects.
-        """
-        ids = self.get_tasks_ids()
-        the_dict = {}
-        for id in ids:
-            the_dict[id] = EmptyTimeWindow(self.get_max_horizon())
-        return the_dict
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Dict
+
+__all__ = [
+    "TimeWindow",
+    "ClassicTimeWindow",
+    "StartFromOnlyTimeWindow",
+    "StartBeforeOnlyTimeWindow",
+    "EndFromOnlyTimeWindow",
+    "EndBeforeOnlyTimeWindow",
+    "StartTimeWindow",
+    "EndTimeWindow",
+    "EmptyTimeWindow",
+    "WithTimeWindow",
+    "WithoutTimeWindow",
+]
+
+
+class TimeWindow:
+    """Defines a time window with earliest start, latest start, earliest end and latest end only."""
+
+    def __init__(
+        self,
+        earliest_start: int,
+        latest_start: int,
+        earliest_end: int,
+        latest_end: int,
+        max_horizon: int,
+    ) -> None:
+        self.earliest_start = earliest_start
+        self.latest_start = latest_start
+        self.earliest_end = earliest_end
+        self.latest_end = latest_end
+
+
+class ClassicTimeWindow(TimeWindow):
+    """Defines a time window with earliest start and latest end only."""
+
+    def __init__(self, earliest_start: int, latest_end: int, max_horizon: int) -> None:
+        self.earliest_start = earliest_start
+        self.latest_start = max_horizon
+        self.earliest_end = 0
+        self.latest_end = latest_end
+
+
+class StartFromOnlyTimeWindow(TimeWindow):
+    """Defines a time window with an earliest start only."""
+
+    def __init__(self, earliest_start: int, max_horizon: int) -> None:
+        self.earliest_start = earliest_start
+        self.latest_start = max_horizon
+        self.earliest_end = 0
+        self.latest_end = max_horizon
+
+
+class StartBeforeOnlyTimeWindow(TimeWindow):
+    """Defines a time window with an latest start only."""
+
+    def __init__(self, latest_start: int, max_horizon: int) -> None:
+        self.earliest_start = 0
+        self.latest_start = latest_start
+        self.earliest_end = 0
+        self.latest_end = max_horizon
+
+
+class EndFromOnlyTimeWindow(TimeWindow):
+    """Defines a time window with an earliest end only."""
+
+    def __init__(self, earliest_end: int, max_horizon: int) -> None:
+        self.earliest_start = 0
+        self.latest_start = max_horizon
+        self.earliest_end = earliest_end
+        self.latest_end = max_horizon
+
+
+class EndBeforeOnlyTimeWindow(TimeWindow):
+    """Defines a time window with a latest end only."""
+
+    def __init__(self, latest_end: int, max_horizon: int) -> None:
+        self.earliest_start = 0
+        self.latest_start = max_horizon
+        self.earliest_end = 0
+        self.latest_end = latest_end
+
+
+class StartTimeWindow(TimeWindow):
+    """Defines a time window with an earliest start and a latest start only."""
+
+    def __init__(
+        self, earliest_start: int, latest_start: int, max_horizon: int
+    ) -> None:
+        self.earliest_start = earliest_start
+        self.latest_start = latest_start
+        self.earliest_end = 0
+        self.latest_end = max_horizon
+
+
+class EndTimeWindow(TimeWindow):
+    """Defines a time window with an earliest end and a latest end only."""
+
+    def __init__(self, earliest_end: int, latest_end: int, max_horizon: int) -> None:
+        self.earliest_start = 0
+        self.latest_start = max_horizon
+        self.earliest_end = earliest_end
+        self.latest_end = latest_end
+
+
+class EmptyTimeWindow(TimeWindow):
+    """Defines an empty time window."""
+
+    def __init__(self, max_horizon: int) -> None:
+        self.earliest_start = 0
+        self.latest_start = max_horizon
+        self.earliest_end = 0
+        self.latest_end = max_horizon
+
+
+class WithTimeWindow:
+    """A domain must inherit this class if some tasks have time windows defined."""
+
+    def get_time_window(self) -> Dict[int, TimeWindow]:
+        """
+        Return a dictionary where the key is the id of a task (int)
+        and the value is a TimeWindow object.
+        Note that the max time horizon needs to be provided to the TimeWindow constructors
+        e.g.
+            {
+                1: TimeWindow(10, 15, 20, 30, self.get_max_horizon())
+                2: EmptyTimeWindow(self.get_max_horizon())
+                3: EndTimeWindow(20, 25, self.get_max_horizon())
+                4: EndBeforeOnlyTimeWindow(40, self.get_max_horizon())
+            }
+
+        # Returns
+        A dictionary of TimeWindow objects.
+        """
+        return self._get_time_window()
+
+    def _get_time_window(self) -> Dict[int, TimeWindow]:
+        """
+        Return a dictionary where the key is the id of a task (int)
+        and the value is a TimeWindow object.
+        Note that the max time horizon needs to be provided to the TimeWindow constructors
+        e.g.
+            {
+                1: TimeWindow(10, 15, 20, 30, self.get_max_horizon())
+                2: EmptyTimeWindow(self.get_max_horizon())
+                3: EndTimeWindow(20, 25, self.get_max_horizon())
+                4: EndBeforeOnlyTimeWindow(40, self.get_max_horizon())
+            }
+
+        # Returns
+        A dictionary of TimeWindow objects.
+
+        """
+        raise NotImplementedError
+
+
+class WithoutTimeWindow(WithTimeWindow):
+    """A domain must inherit this class if none of the tasks have restrictions on start times or end times."""
+
+    def _get_time_window(self) -> Dict[int, TimeWindow]:
+        """
+        Return a dictionary where the key is the id of a task (int)
+        and the value is a dictionary of EmptyTimeWindow object.
+
+        # Returns
+        A dictionary of TimeWindow objects.
+        """
+        ids = self.get_tasks_ids()
+        the_dict = {}
+        for id in ids:
+            the_dict[id] = EmptyTimeWindow(self.get_max_horizon())
+        return the_dict
```

## skdecide/builders/domain/value.py

 * *Ordering differences only*

```diff
@@ -1,75 +1,75 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from skdecide.core import D, Value, autocastable
-
-__all__ = ["Rewards", "PositiveCosts"]
-
-
-class Rewards:
-    """A domain must inherit this class if it sends rewards (positive and/or negative)."""
-
-    @autocastable
-    def check_value(self, value: Value[D.T_value]) -> bool:
-        """Check that a value is compliant with its reward specification.
-
-        !!! tip
-            This function returns always True by default because any kind of reward should be accepted at this level.
-
-        # Parameters
-        value: The value to check.
-
-        # Returns
-        True if the value is compliant (False otherwise).
-        """
-        return self._check_value(value)
-
-    def _check_value(self, value: Value[D.T_value]) -> bool:
-        """Check that a value is compliant with its reward specification.
-
-        !!! tip
-            This function returns always True by default because any kind of reward should be accepted at this level.
-
-        # Parameters
-        value: The value to check.
-
-        # Returns
-        True if the value is compliant (False otherwise).
-        """
-        return True
-
-
-class PositiveCosts(Rewards):
-    """A domain must inherit this class if it sends only positive costs (i.e. negative rewards).
-
-    Having only positive costs is a required assumption for certain solvers to work, such as classical planners.
-    """
-
-    def _check_value(self, value: Value[D.T_value]) -> bool:
-        """Check that a value is compliant with its cost specification (must be positive).
-
-        !!! tip
-            This function calls #PositiveCost._is_positive() to determine if a value is positive (can be overridden for
-            advanced value types).
-
-        # Parameters
-        value: The value to check.
-
-        # Returns
-        True if the value is compliant (False otherwise).
-        """
-        return self._is_positive(value.cost)
-
-    def _is_positive(self, cost: D.T_value) -> bool:
-        """Determine if a value is positive (can be overridden for advanced value types).
-
-        # Parameters
-        cost: The cost to evaluate.
-
-        # Returns
-        True if the cost is positive (False otherwise).
-        """
-        return cost >= 0
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from skdecide.core import D, Value, autocastable
+
+__all__ = ["Rewards", "PositiveCosts"]
+
+
+class Rewards:
+    """A domain must inherit this class if it sends rewards (positive and/or negative)."""
+
+    @autocastable
+    def check_value(self, value: Value[D.T_value]) -> bool:
+        """Check that a value is compliant with its reward specification.
+
+        !!! tip
+            This function returns always True by default because any kind of reward should be accepted at this level.
+
+        # Parameters
+        value: The value to check.
+
+        # Returns
+        True if the value is compliant (False otherwise).
+        """
+        return self._check_value(value)
+
+    def _check_value(self, value: Value[D.T_value]) -> bool:
+        """Check that a value is compliant with its reward specification.
+
+        !!! tip
+            This function returns always True by default because any kind of reward should be accepted at this level.
+
+        # Parameters
+        value: The value to check.
+
+        # Returns
+        True if the value is compliant (False otherwise).
+        """
+        return True
+
+
+class PositiveCosts(Rewards):
+    """A domain must inherit this class if it sends only positive costs (i.e. negative rewards).
+
+    Having only positive costs is a required assumption for certain solvers to work, such as classical planners.
+    """
+
+    def _check_value(self, value: Value[D.T_value]) -> bool:
+        """Check that a value is compliant with its cost specification (must be positive).
+
+        !!! tip
+            This function calls #PositiveCost._is_positive() to determine if a value is positive (can be overridden for
+            advanced value types).
+
+        # Parameters
+        value: The value to check.
+
+        # Returns
+        True if the value is compliant (False otherwise).
+        """
+        return self._is_positive(value.cost)
+
+    def _is_positive(self, cost: D.T_value) -> bool:
+        """Determine if a value is positive (can be overridden for advanced value types).
+
+        # Parameters
+        cost: The cost to evaluate.
+
+        # Returns
+        True if the cost is positive (False otherwise).
+        """
+        return cost >= 0
```

## skdecide/builders/solver/__init__.py

```diff
@@ -1,8 +1,9 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from skdecide.builders.solver.assessability import *
-from skdecide.builders.solver.parallelability import *
-from skdecide.builders.solver.policy import *
-from skdecide.builders.solver.restorability import *
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from skdecide.builders.solver.assessability import *
+from skdecide.builders.solver.fromanystatesolvability import *
+from skdecide.builders.solver.parallelability import *
+from skdecide.builders.solver.policy import *
+from skdecide.builders.solver.restorability import *
```

## skdecide/builders/solver/assessability.py

 * *Ordering differences only*

```diff
@@ -1,95 +1,95 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from skdecide.core import D, autocastable
-
-__all__ = ["Utilities", "QValues"]
-
-
-class Utilities:
-    """A solver must inherit this class if it can provide the utility function (i.e. value function)."""
-
-    @autocastable
-    def get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-        """Get the estimated on-policy utility of the given observation.
-
-        In mathematical terms, for a fully observable domain, this function estimates:
-        $$V^\\pi(s)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s]$$
-        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
-        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$ the initial state for the trajectories.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        The estimated on-policy utility of the given observation.
-        """
-        return self._get_utility(observation)
-
-    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-        """Get the estimated on-policy utility of the given observation.
-
-        In mathematical terms, for a fully observable domain, this function estimates:
-        $$V^\\pi(s)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s]$$
-        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
-        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$ the initial state for the trajectories.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        The estimated on-policy utility of the given observation.
-        """
-        raise NotImplementedError
-
-
-class QValues(Utilities):
-    """A solver must inherit this class if it can provide the Q function (i.e. action-value function)."""
-
-    @autocastable
-    def get_q_value(
-        self,
-        observation: D.T_agent[D.T_observation],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_value:
-        """Get the estimated on-policy Q value of the given observation and action.
-
-        In mathematical terms, for a fully observable domain, this function estimates:
-        $$Q^\\pi(s,a)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s,a_0=a]$$
-        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
-        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$/$a_0$ the initial state/action for the
-        trajectories.
-
-        # Parameters
-        observation: The observation to consider.
-        action: The action to consider.
-
-        # Returns
-        The estimated on-policy Q value of the given observation and action.
-        """
-        return self._get_q_value(observation, action)
-
-    def _get_q_value(
-        self,
-        observation: D.T_agent[D.T_observation],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_value:
-        """Get the estimated on-policy Q value of the given observation and action.
-
-        In mathematical terms, for a fully observable domain, this function estimates:
-        $$Q^\\pi(s,a)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s,a_0=a]$$
-        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
-        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$/$a_0$ the initial state/action for the
-        trajectories.
-
-        # Parameters
-        observation: The observation to consider.
-        action: The action to consider.
-
-        # Returns
-        The estimated on-policy Q value of the given observation and action.
-        """
-        raise NotImplementedError
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from skdecide.core import D, autocastable
+
+__all__ = ["Utilities", "QValues"]
+
+
+class Utilities:
+    """A solver must inherit this class if it can provide the utility function (i.e. value function)."""
+
+    @autocastable
+    def get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+        """Get the estimated on-policy utility of the given observation.
+
+        In mathematical terms, for a fully observable domain, this function estimates:
+        $$V^\\pi(s)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s]$$
+        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
+        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$ the initial state for the trajectories.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        The estimated on-policy utility of the given observation.
+        """
+        return self._get_utility(observation)
+
+    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+        """Get the estimated on-policy utility of the given observation.
+
+        In mathematical terms, for a fully observable domain, this function estimates:
+        $$V^\\pi(s)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s]$$
+        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
+        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$ the initial state for the trajectories.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        The estimated on-policy utility of the given observation.
+        """
+        raise NotImplementedError
+
+
+class QValues(Utilities):
+    """A solver must inherit this class if it can provide the Q function (i.e. action-value function)."""
+
+    @autocastable
+    def get_q_value(
+        self,
+        observation: D.T_agent[D.T_observation],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_value:
+        """Get the estimated on-policy Q value of the given observation and action.
+
+        In mathematical terms, for a fully observable domain, this function estimates:
+        $$Q^\\pi(s,a)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s,a_0=a]$$
+        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
+        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$/$a_0$ the initial state/action for the
+        trajectories.
+
+        # Parameters
+        observation: The observation to consider.
+        action: The action to consider.
+
+        # Returns
+        The estimated on-policy Q value of the given observation and action.
+        """
+        return self._get_q_value(observation, action)
+
+    def _get_q_value(
+        self,
+        observation: D.T_agent[D.T_observation],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_value:
+        """Get the estimated on-policy Q value of the given observation and action.
+
+        In mathematical terms, for a fully observable domain, this function estimates:
+        $$Q^\\pi(s,a)=\\underset{\\tau\\sim\\pi}{\\mathbb{E}}[R(\\tau)|s_0=s,a_0=a]$$
+        where $\\pi$ is the current policy, any $\\tau=(s_0,a_0, s_1, a_1, ...)$ represents a trajectory sampled from
+        the policy, $R(\\tau)$ is the return (cumulative reward) and $s_0$/$a_0$ the initial state/action for the
+        trajectories.
+
+        # Parameters
+        observation: The observation to consider.
+        action: The action to consider.
+
+        # Returns
+        The estimated on-policy Q value of the given observation and action.
+        """
+        raise NotImplementedError
```

## skdecide/builders/solver/parallelability.py

```diff
@@ -1,95 +1,89 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Callable, List
-
-from skdecide.domains import Domain
-from skdecide.parallel_domains import PipeParallelDomain, ShmParallelDomain
-
-__all__ = ["ParallelSolver"]
-
-
-class ParallelSolver:
-    """A solver must inherit this class if it wants to call several cloned parallel domains in separate concurrent processes.
-    The solver is meant to be called either within a 'with' context statement, or to be cleaned up using the close() method.
-    """
-
-    def __init__(
-        self,
-        domain_factory: Callable[[], Domain],
-        parallel: bool = False,
-        shared_memory_proxy=None,
-    ):
-        """Creates a parallelizable solver
-        # Parameters
-        domain_factory: A callable with no argument returning the domain to solve (factory is the domain class if None).
-        parallel: True if the solver is run in parallel mode.
-        shared_memory_proxy: Shared memory proxy to use if not None, otherwise run piped parallel domains.
-        """
-        self._domain_factory = domain_factory
-        self._parallel = parallel
-        self._shared_memory_proxy = shared_memory_proxy
-        self._domain = None
-        self._lambdas = []  # to define in the inherited class!
-        self._ipc_notify = False  # to define in the inherited class!
-
-    def _initialize(self):
-        """Launches the parallel domains.
-        This method requires to have previously recorded the self._domain_factory (e.g. after calling _init_solve),
-        the set of lambda functions passed to the solver's constructor (e.g. heuristic lambda for heuristic-based solvers),
-        and whether the parallel domain jobs should notify their status via the IPC protocol (required when interacting with
-        other programming languages like C++)
-        """
-        if self._parallel:
-            if self._shared_memory_proxy is None:
-                self._domain = PipeParallelDomain(
-                    self._domain_factory,
-                    lambdas=self._lambdas,
-                    ipc_notify=self._ipc_notify,
-                )
-            else:
-                self._domain = ShmParallelDomain(
-                    self._domain_factory,
-                    self._shared_memory_proxy,
-                    lambdas=self._lambdas,
-                    ipc_notify=self._ipc_notify,
-                )
-            # Launch parallel domains before created the algorithm object
-            # otherwise spawning new processes (the default on Windows)
-            # will fail trying to pickle the C++ underlying algorithm
-            self._domain._launch_processes()
-        else:
-            self._domain = self._domain_factory()
-
-    def close(self):
-        """Joins the parallel domains' processes.
-        Not calling this method (or not using the 'with' context statement)
-        results in the solver forever waiting for the domain processes to exit.
-        """
-        if self._domain is not None and self._parallel:
-            self._domain.close()
-            self._domain = None
-
-    def _cleanup(self):
-        self.close()
-
-    def get_domain(self):
-        """
-        Returns the domain, optionally creating a parallel domain if not already created.
-        """
-        if self._domain is None:
-            self._initialize()
-        return self._domain
-
-    def call_domain_method(self, name, *args):
-        """Calls a parallel domain's method.
-        This is the only way to get a domain method for a parallel domain.
-        """
-        if self._parallel:
-            process_id = getattr(self._domain, name)(*args)
-            return self._domain.get_result(process_id)
-        else:
-            return getattr(self._domain, name)(*args)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from skdecide.parallel_domains import PipeParallelDomain, ShmParallelDomain
+
+__all__ = ["ParallelSolver"]
+
+
+class ParallelSolver:
+    """A solver must inherit this class if it wants to call several cloned parallel domains in separate concurrent processes.
+    The solver is meant to be called either within a 'with' context statement, or to be cleaned up using the close() method.
+    """
+
+    def __init__(
+        self,
+        parallel: bool = False,
+        shared_memory_proxy=None,
+    ):
+        """Creates a parallelizable solver
+        # Parameters
+        parallel: True if the solver is run in parallel mode.
+        shared_memory_proxy: Shared memory proxy to use if not None, otherwise run piped parallel domains.
+        """
+        self._parallel = parallel
+        self._shared_memory_proxy = shared_memory_proxy
+        self._domain = None
+        self._lambdas = []  # to define in the inherited class!
+        self._ipc_notify = False  # to define in the inherited class!
+
+    def _initialize(self):
+        """Launches the parallel domains.
+        This method requires to have previously recorded the self._domain_factory (e.g. after calling _init_solve),
+        the set of lambda functions passed to the solver's constructor (e.g. heuristic lambda for heuristic-based solvers),
+        and whether the parallel domain jobs should notify their status via the IPC protocol (required when interacting with
+        other programming languages like C++)
+        """
+        if self._parallel:
+            if self._shared_memory_proxy is None:
+                self._domain = PipeParallelDomain(
+                    self._domain_factory,
+                    lambdas=self._lambdas,
+                    ipc_notify=self._ipc_notify,
+                )
+            else:
+                self._domain = ShmParallelDomain(
+                    self._domain_factory,
+                    self._shared_memory_proxy,
+                    lambdas=self._lambdas,
+                    ipc_notify=self._ipc_notify,
+                )
+            # Launch parallel domains before created the algorithm object
+            # otherwise spawning new processes (the default on Windows)
+            # will fail trying to pickle the C++ underlying algorithm
+            self._domain._launch_processes()
+        else:
+            self._domain = self._domain_factory()
+
+    def close(self):
+        """Joins the parallel domains' processes.
+        Not calling this method (or not using the 'with' context statement)
+        results in the solver forever waiting for the domain processes to exit.
+        """
+        if self._domain is not None and self._parallel:
+            self._domain.close()
+            self._domain = None
+
+    def _cleanup(self):
+        self.close()
+
+    def get_domain(self):
+        """
+        Returns the domain, optionally creating a parallel domain if not already created.
+        """
+        if self._domain is None:
+            self._initialize()
+        return self._domain
+
+    def call_domain_method(self, name, *args):
+        """Calls a parallel domain's method.
+        This is the only way to get a domain method for a parallel domain.
+        """
+        if self._parallel:
+            process_id = getattr(self._domain, name)(*args)
+            return self._domain.get_result(process_id)
+        else:
+            return getattr(self._domain, name)(*args)
```

## skdecide/builders/solver/policy.py

 * *Ordering differences only*

```diff
@@ -1,138 +1,138 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from skdecide.core import D, Distribution, SingleValueDistribution, autocastable
-
-__all__ = ["Policies", "UncertainPolicies", "DeterministicPolicies"]
-
-
-class Policies:
-    """A solver must inherit this class if it computes a stochastic policy as part of the solving process."""
-
-    @autocastable
-    def sample_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        """Sample an action for the given observation (from the solver's current policy).
-
-        # Parameters
-        observation: The observation for which an action must be sampled.
-
-        # Returns
-        The sampled action.
-        """
-        return self._sample_action(observation)
-
-    def _sample_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        """Sample an action for the given observation (from the solver's current policy).
-
-        # Parameters
-        observation: The observation for which an action must be sampled.
-
-        # Returns
-        The sampled action.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        """Check whether the solver's current policy is defined for the given observation.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        True if the policy is defined for the given observation memory (False otherwise).
-        """
-        return self._is_policy_defined_for(observation)
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        """Check whether the solver's current policy is defined for the given observation.
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        True if the policy is defined for the given observation memory (False otherwise).
-        """
-        raise NotImplementedError
-
-
-class UncertainPolicies(Policies):
-    """A solver must inherit this class if it computes a stochastic policy (providing next action distribution
-    explicitly) as part of the solving process."""
-
-    def _sample_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        return self._get_next_action_distribution(observation).sample()
-
-    @autocastable
-    def get_next_action_distribution(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> Distribution[D.T_agent[D.T_concurrency[D.T_event]]]:
-        """Get the probabilistic distribution of next action for the given observation (from the solver's current
-        policy).
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        The probabilistic distribution of next action.
-        """
-        return self._get_next_action_distribution(observation)
-
-    def _get_next_action_distribution(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> Distribution[D.T_agent[D.T_concurrency[D.T_event]]]:
-        """Get the probabilistic distribution of next action for the given observation (from the solver's current
-        policy).
-
-        # Parameters
-        observation: The observation to consider.
-
-        # Returns
-        The probabilistic distribution of next action.
-        """
-        raise NotImplementedError
-
-
-class DeterministicPolicies(UncertainPolicies):
-    """A solver must inherit this class if it computes a deterministic policy as part of the solving process."""
-
-    def _get_next_action_distribution(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> Distribution[D.T_agent[D.T_concurrency[D.T_event]]]:
-        return SingleValueDistribution(self._get_next_action(observation))
-
-    @autocastable
-    def get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        """Get the next deterministic action (from the solver's current policy).
-
-        # Parameters
-        observation: The observation for which next action is requested.
-
-        # Returns
-        The next deterministic action.
-        """
-        return self._get_next_action(observation)
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        """Get the next deterministic action (from the solver's current policy).
-
-        # Parameters
-        observation: The observation for which next action is requested.
-
-        # Returns
-        The next deterministic action.
-        """
-        raise NotImplementedError
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from skdecide.core import D, Distribution, SingleValueDistribution, autocastable
+
+__all__ = ["Policies", "UncertainPolicies", "DeterministicPolicies"]
+
+
+class Policies:
+    """A solver must inherit this class if it computes a stochastic policy as part of the solving process."""
+
+    @autocastable
+    def sample_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        """Sample an action for the given observation (from the solver's current policy).
+
+        # Parameters
+        observation: The observation for which an action must be sampled.
+
+        # Returns
+        The sampled action.
+        """
+        return self._sample_action(observation)
+
+    def _sample_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        """Sample an action for the given observation (from the solver's current policy).
+
+        # Parameters
+        observation: The observation for which an action must be sampled.
+
+        # Returns
+        The sampled action.
+        """
+        raise NotImplementedError
+
+    @autocastable
+    def is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        """Check whether the solver's current policy is defined for the given observation.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        True if the policy is defined for the given observation memory (False otherwise).
+        """
+        return self._is_policy_defined_for(observation)
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        """Check whether the solver's current policy is defined for the given observation.
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        True if the policy is defined for the given observation memory (False otherwise).
+        """
+        raise NotImplementedError
+
+
+class UncertainPolicies(Policies):
+    """A solver must inherit this class if it computes a stochastic policy (providing next action distribution
+    explicitly) as part of the solving process."""
+
+    def _sample_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        return self._get_next_action_distribution(observation).sample()
+
+    @autocastable
+    def get_next_action_distribution(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> Distribution[D.T_agent[D.T_concurrency[D.T_event]]]:
+        """Get the probabilistic distribution of next action for the given observation (from the solver's current
+        policy).
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        The probabilistic distribution of next action.
+        """
+        return self._get_next_action_distribution(observation)
+
+    def _get_next_action_distribution(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> Distribution[D.T_agent[D.T_concurrency[D.T_event]]]:
+        """Get the probabilistic distribution of next action for the given observation (from the solver's current
+        policy).
+
+        # Parameters
+        observation: The observation to consider.
+
+        # Returns
+        The probabilistic distribution of next action.
+        """
+        raise NotImplementedError
+
+
+class DeterministicPolicies(UncertainPolicies):
+    """A solver must inherit this class if it computes a deterministic policy as part of the solving process."""
+
+    def _get_next_action_distribution(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> Distribution[D.T_agent[D.T_concurrency[D.T_event]]]:
+        return SingleValueDistribution(self._get_next_action(observation))
+
+    @autocastable
+    def get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        """Get the next deterministic action (from the solver's current policy).
+
+        # Parameters
+        observation: The observation for which next action is requested.
+
+        # Returns
+        The next deterministic action.
+        """
+        return self._get_next_action(observation)
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        """Get the next deterministic action (from the solver's current policy).
+
+        # Parameters
+        observation: The observation for which next action is requested.
+
+        # Returns
+        The next deterministic action.
+        """
+        raise NotImplementedError
```

## skdecide/builders/solver/restorability.py

```diff
@@ -1,52 +1,52 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Callable
-
-from skdecide.core import D, autocastable
-
-__all__ = ["Restorable"]
-
-
-class Restorable:
-    """A solver must inherit this class if its state can be saved and reloaded (to continue computation later on or
-    reuse its solution)."""
-
-    @autocastable
-    def save(self, path: str) -> None:
-        """Save the solver state to given path.
-
-        # Parameters
-        path: The path to store the saved state.
-        """
-        return self._save(path)
-
-    def _save(self, path: str) -> None:
-        """Save the solver state to given path.
-
-        # Parameters
-        path: The path to store the saved state.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def load(self, path: str, domain_factory: Callable[[], D]) -> None:
-        """Restore the solver state from given path.
-
-        # Parameters
-        path: The path where the solver state was saved.
-        domain_factory: A callable with no argument returning the domain to solve (useful in some implementations).
-        """
-        return self._load(path, domain_factory)
-
-    def _load(self, path: str, domain_factory: Callable[[], D]) -> None:
-        """Restore the solver state from given path.
-
-        # Parameters
-        path: The path where the solver state was saved.
-        domain_factory: A callable with no argument returning the domain to solve (useful in some implementations).
-        """
-        raise NotImplementedError
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Callable
+
+from skdecide.core import D, autocastable
+
+__all__ = ["Restorable"]
+
+
+class Restorable:
+    """A solver must inherit this class if its state can be saved and reloaded (to continue computation later on or
+    reuse its solution)."""
+
+    def save(self, path: str) -> None:
+        """Save the solver state to given path.
+
+        # Parameters
+        path: The path to store the saved state.
+        """
+        return self._save(path)
+
+    def _save(self, path: str) -> None:
+        """Save the solver state to given path.
+
+        # Parameters
+        path: The path to store the saved state.
+        """
+        raise NotImplementedError
+
+    def load(self, path: str) -> None:
+        """Restore the solver state from given path.
+
+        After calling self._load(), autocast itself so that rollout methods apply
+        to the domain original characteristics.
+
+        # Parameters
+        path: The path where the solver state was saved.
+        """
+        self._load(path)
+        self.autocast()
+
+    def _load(self, path: str) -> None:
+        """Restore the solver state from given path.
+
+        # Parameters
+        path: The path where the solver state was saved.
+        """
+        raise NotImplementedError
```

## skdecide/core.py

 * *Ordering differences only*

```diff
@@ -1,824 +1,824 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import functools
-import inspect
-import random
-import re
-from dataclasses import asdict, astuple, dataclass, replace
-from typing import (
-    Callable,
-    Deque,
-    Dict,
-    Generic,
-    Iterable,
-    List,
-    Optional,
-    Sequence,
-    Tuple,
-    TypeVar,
-    Union,
-)
-
-__all__ = [
-    "T",
-    "D",
-    "Space",
-    "ImplicitSpace",
-    "EnumerableSpace",
-    "EmptySpace",
-    "SamplableSpace",
-    "SerializableSpace",
-    "Distribution",
-    "ImplicitDistribution",
-    "DiscreteDistribution",
-    "SingleValueDistribution",
-    "Value",
-    "EnvironmentOutcome",
-    "TransitionOutcome",
-    "Memory",
-    "StrDict",
-    "Constraint",
-    "ImplicitConstraint",
-    "BoundConstraint",
-    "autocast_all",
-    "autocastable",
-    "nocopy",
-]
-
-T = TypeVar("T")  # Any type
-
-
-class D:
-    T_state = TypeVar("T_state")  # Type of states
-    T_observation = TypeVar("T_observation")  # Type of observations
-    T_event = TypeVar("T_event")  # Type of events
-    T_value = TypeVar("T_value")  # Type of transition values (rewards or costs)
-    T_predicate = TypeVar("T_predicate")  # Type of logical checks
-    T_info = TypeVar(
-        "T_info"
-    )  # Type of additional information given as part of an environment outcome
-    T_memory = TypeVar("T_memory")
-    T_agent = TypeVar("T_agent")
-    T_concurrency = TypeVar("T_concurrency")
-
-
-# Tree (utility class)
-class Tree:
-    def __init__(self, type_: object, sub: List[Tree] = []):
-        self.type = type_
-        self.sub = sub
-
-
-# Castable (utility class)
-class Castable:
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        raise NotImplementedError
-
-
-# Space
-class Space(Generic[T]):
-    """A space representing a finite or infinite set.
-
-    This class (or any of its descendant) is typically used to specify action, observation or goal spaces.
-    """
-
-    def contains(self, x: T) -> bool:
-        """Check whether x is a valid member of this space.
-
-        # Parameters
-        x: The member to consider.
-
-        # Returns
-        True if x is a valid member of this space (False otherwise).
-        """
-        raise NotImplementedError
-
-    def __contains__(self, item: T) -> bool:
-        return self.contains(item)
-
-
-class ImplicitSpace(Space[T]):
-    """A space formalized implicitly, i.e. by a black-box contains() function."""
-
-    def __init__(self, contains_function: Callable[[T], bool]) -> None:
-        """Initialize ImplicitSpace.
-
-        # Parameters
-        contains_function: The contains() function to use.
-
-        # Example
-        ```python
-        my_space = ImplicitSpace(lambda x: 10 > x['position'] > 5)
-        ```
-        """
-        self.contains_function = contains_function
-
-    def contains(self, x: T) -> bool:
-        return self.contains_function(x)
-
-
-class EnumerableSpace(Space[T]):
-    """A space which elements can be enumerated."""
-
-    def get_elements(self) -> Iterable[T]:
-        """Get the elements of this space.
-
-        # Returns
-        The elements of this space.
-        """
-        raise NotImplementedError
-
-    def contains(self, x: T) -> bool:
-        return x in self.get_elements()
-
-
-class EmptySpace(EnumerableSpace[T]):
-    """An (enumerable) empty space."""
-
-    def get_elements(self) -> Iterable[T]:
-        return ()
-
-
-class SamplableSpace(Space[T]):
-    """A space which can be sampled (uniformly randomly)."""
-
-    def sample(self) -> T:
-        """Uniformly randomly sample a random element of this space.
-
-        # Returns
-        The sampled element.
-        """
-        raise NotImplementedError
-
-
-class SerializableSpace(Space[T]):
-    """A space which can be serialized (to/from JSON)."""
-
-    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
-        """Convert a batch of samples from this space to a JSONable data type.
-
-        # Parameters
-        sample_n: The batch of samples to convert.
-
-        # Returns
-        The resulting JSONable data type.
-        """
-        # By default, assume identity is JSONable
-        return sample_n
-
-    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
-        """Convert a JSONable data type to a batch of samples from this space.
-
-        # Parameters
-        sample_n: The JSONable data type to convert.
-
-        # Returns
-        The resulting batch of samples.
-        """
-        # By default, assume identity is JSONable
-        return sample_n
-
-
-# Distribution
-class Distribution(Generic[T], Castable):
-    """A probability distribution."""
-
-    def sample(self) -> T:
-        """Sample from this distribution.
-
-        # Returns
-        The sampled element.
-        """
-        raise NotImplementedError
-
-
-class ImplicitDistribution(Distribution[T]):
-    """A probability distribution formalized implicitly, i.e. by a black-box sample() function."""
-
-    def __init__(self, sample_function: Callable[[], T]) -> None:
-        """Initialize ImplicitDistribution.
-
-        # Parameters
-        sample_function: The sample() function to use.
-
-        # Example
-        ```python
-        import random
-
-        dice = ImplicitDistribution(lambda: random.randint(1, 6))
-        roll = dice.sample()
-        ```
-        """
-        self._sample_function = sample_function
-
-    def sample(self) -> T:
-        return self._sample_function()
-
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        def cast_sample_function():
-            result = self._sample_function()
-            return cast(result, src_sub[0], dst_sub[0])
-
-        return ImplicitDistribution(cast_sample_function)
-
-
-class DiscreteDistribution(Distribution[T]):
-    """A discrete probability distribution."""
-
-    def __init__(self, values: List[Tuple[T, float]]) -> None:
-        """Initialize DiscreteDistribution.
-
-        !!! tip
-            If the given probabilities do not sum to 1, they are implicitly normalized as such for sampling.
-
-        # Parameters
-        values: The list of (element, probability) pairs.
-
-        # Example
-        ```python
-        game_strategy = DiscreteDistribution([('rock', 0.7), ('paper', 0.1), ('scissors', 0.2)])
-        move = game_strategy.sample()
-        ```
-        """
-        self._values = values
-        unzip_values = list(zip(*values))
-        # TODO: make sure every population member is unique (and if not, aggregate same ones by summing their weights)?
-        self._population = unzip_values[0]
-        self._weights = unzip_values[1]
-
-    def sample(self) -> T:
-        return random.choices(self._population, self._weights)[0]
-
-    def get_values(self) -> List[Tuple[T, float]]:
-        """Get the list of (element, probability) pairs.
-
-        # Returns
-        The (element, probability) pairs.
-        """
-        return self._values
-
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        return DiscreteDistribution(
-            [(cast(e, src_sub[0], dst_sub[0]), p) for e, p in self._values]
-        )
-
-
-class SingleValueDistribution(DiscreteDistribution[T]):
-    """A single value distribution (i.e. Dirac distribution)."""
-
-    def __init__(self, value: T) -> None:
-        """Initialize SingleValueDistribution.
-
-        # Parameters
-        value: The single value of this distribution.
-        """
-        self._value = value
-
-    def sample(self) -> T:
-        return self._value
-
-    def get_values(self) -> List[Tuple[T, float]]:
-        return [(self._value, 1.0)]
-
-    def get_value(self) -> T:
-        """Get the single value of this distribution.
-
-        # Returns
-        The single value of this distribution.
-        """
-        return self._value
-
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        return SingleValueDistribution(cast(self._value, src_sub[0], dst_sub[0]))
-
-
-# ExtendedDataclass (dataclasses can inherit from it to extended their methods with useful utilities)
-class ExtendedDataclass:
-    def asdict(self):
-        """Return the fields of the instance as a new dictionary mapping field names to field values."""
-        return asdict(self)
-
-    def astuple(self):
-        """Return the fields of the instance as a new tuple of field values."""
-        return astuple(self)
-
-    def replace(self, **changes):
-        """Return a new object replacing specified fields with new values."""
-        return replace(self, **changes)
-
-
-# Value
-@dataclass
-class Value(Generic[D.T_value]):
-    """A value (reward or cost).
-
-    !!! warning
-        It is recommended to use either the reward or the cost parameter. If no one is used, a reward/cost of 0 is
-        assumed. If both are used, reward will be considered and cost ignored. In any case, both reward and cost
-        attributes will be defined after initialization.
-
-    # Parameters
-    reward: The optional reward.
-    cost: The optional cost.
-
-    # Example
-    ```python
-    # These two lines are equivalent, use the one you prefer
-    value_1 = Value(reward=-5)
-    value_2 = Value(cost=5)
-
-    assert value_1.reward == value_2.reward == -5  # True
-    assert value_1.cost == value_2.cost == 5  # True
-    ```
-    """
-
-    reward: Optional[D.T_value] = None
-    cost: Optional[D.T_value] = None
-
-    def __post_init__(self) -> None:
-        if self.reward is not None:
-            self.cost = self._reward_to_cost(self.reward)
-        elif self.cost is not None:
-            self.reward = self._cost_to_reward(self.cost)
-        else:
-            self.reward = 0
-            self.cost = 0
-
-    def _cost_to_reward(self, cost: D.T_value) -> D.T_value:
-        return -cost
-
-    def _reward_to_cost(self, reward: D.T_value) -> D.T_value:
-        return -reward
-
-
-# EnvironmentOutcome
-@dataclass
-class EnvironmentOutcome(
-    Generic[D.T_observation, D.T_value, D.T_predicate, D.T_info],
-    Castable,
-    ExtendedDataclass,
-):
-    """An environment outcome for an internal transition.
-
-    # Parameters
-    observation: The agent's observation of the current environment.
-    value: The value (reward or cost) returned after previous action.
-    termination: Whether the episode has ended, in which case further step() calls will return undefined results.
-    info: Optional auxiliary diagnostic information (helpful for debugging, and sometimes learning).
-    """
-
-    observation: D.T_observation
-    value: Optional[D.T_value] = None
-    termination: Optional[D.T_predicate] = None
-    info: Optional[D.T_info] = None
-
-    def __post_init__(self) -> None:
-        if self.value is None:
-            self.value = (
-                {k: Value() for k in self.observation}
-                if isinstance(self.observation, dict)
-                else Value()
-            )
-        if self.termination is None:
-            self.termination = (
-                {k: False for k in self.observation}
-                if isinstance(self.observation, dict)
-                else False
-            )
-        if self.info is None:
-            self.info = (
-                {k: None for k in self.observation}
-                if isinstance(self.observation, dict)
-                else None
-            )
-
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        return EnvironmentOutcome(
-            cast(self.observation, src_sub[0], dst_sub[0]),
-            cast(self.value, src_sub[1], dst_sub[1]),
-            cast(self.termination, src_sub[2], dst_sub[2]),
-            cast(self.info, src_sub[3], dst_sub[3]),
-        )
-
-
-# TransitionOutcome
-@dataclass
-class TransitionOutcome(
-    Generic[D.T_state, D.T_value, D.T_predicate, D.T_info], Castable, ExtendedDataclass
-):
-    """A transition outcome.
-
-    # Parameters
-    state: The new state after the transition.
-    value: The value (reward or cost) returned after previous action.
-    termination: Whether the episode has ended, in which case further step() calls will return undefined results.
-    info: Optional auxiliary diagnostic information (helpful for debugging, and sometimes learning).
-    """
-
-    state: D.T_state
-    value: Optional[D.T_value] = None
-    termination: Optional[D.T_predicate] = None
-    info: Optional[D.T_info] = None
-
-    def __post_init__(self) -> None:
-        if self.value is None:
-            self.value = (
-                {k: Value() for k in self.state}
-                if isinstance(self.state, dict)
-                else Value()
-            )
-        if self.termination is None:
-            self.termination = (
-                {k: False for k in self.observation}
-                if isinstance(self.observation, dict)
-                else False
-            )
-
-        if self.info is None:
-            self.info = (
-                {k: None for k in self.state} if isinstance(self.state, dict) else None
-            )
-
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        return TransitionOutcome(
-            cast(self.state, src_sub[0], dst_sub[0]),
-            cast(self.value, src_sub[1], dst_sub[1]),
-            cast(self.termination, src_sub[2], dst_sub[2]),
-            cast(self.info, src_sub[3], dst_sub[3]),
-        )
-
-
-# Memory
-class Memory(Deque[T]):
-    pass
-
-
-# StrDict
-class StrDict(Generic[T], Dict[str, T]):
-    """A dictionary with String keys (e.g. agent names)."""
-
-    pass
-
-
-# Constraint
-class Constraint(Generic[D.T_memory, D.T_event, D.T_state], Castable):
-    """A constraint."""
-
-    def check(
-        self,
-        memory: D.T_memory,
-        action: D.T_event,
-        next_state: Optional[D.T_state] = None,
-    ) -> bool:
-        """Check this constraint.
-
-        !!! tip
-            If this function never depends on the next_state parameter for its computation, it is recommended to
-            indicate it by overriding #Constraint._is_constraint_dependent_on_next_state_() to return False. This
-            information can then be exploited by solvers to avoid computing next state to evaluate the constraint (more
-            efficient).
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-        next_state: The next state in which the transition ends (if needed for the computation).
-
-        # Returns
-        True if the constraint is checked (False otherwise).
-        """
-        raise NotImplementedError
-
-    @functools.lru_cache()
-    def is_constraint_dependent_on_next_state(self) -> bool:
-        """Indicate whether this constraint requires the next_state parameter for its computation (cached).
-
-        By default, #Constraint.is_constraint_dependent_on_next_state() internally
-        calls #Constraint._is_constraint_dependent_on_next_state_() the first time and automatically caches its value to
-        make future calls more efficient (since the returned value is assumed to be constant).
-
-        # Returns
-        True if the constraint computation depends on next_state (False otherwise).
-        """
-        return self._is_constraint_dependent_on_next_state_()
-
-    def _is_constraint_dependent_on_next_state_(self) -> bool:
-        """Indicate whether this constraint requires the next_state parameter for its computation.
-
-        This is a helper function called by default from #Constraint.is_constraint_dependent_on_next_state(), the
-        difference being that the result is not cached here.
-
-        !!! tip
-            The underscore at the end of this function's name is a convention to remind that its result should be
-            constant.
-
-        # Returns
-        True if the constraint computation depends on next_state (False otherwise).
-        """
-        raise NotImplementedError
-
-
-class ImplicitConstraint(Constraint[D.T_memory, D.T_event, D.T_state]):
-    """A constraint formalized implicitly, i.e. by a black-box check() function."""
-
-    def __init__(
-        self,
-        check_function: Callable[[D.T_memory, D.T_event, Optional[D.T_state]], bool],
-        depends_on_next_state: bool = True,
-    ) -> None:
-        """Initialize ImplicitConstraint.
-
-        # Parameters
-        check_function: The check() function to use.
-        depends_on_next_state: Whether the check() function requires the next_state parameter for its computation.
-
-        # Example
-        ```python
-        constraint = ImplicitConstraint(lambda memory, action, next_state: next_state.x % 2 == 0)
-        ```
-        """
-        self._check_function = check_function
-        self._depends_on_next_state = depends_on_next_state
-
-    def check(
-        self,
-        memory: D.T_memory,
-        action: D.T_event,
-        next_state: Optional[D.T_state] = None,
-    ) -> bool:
-        return self._check_function(memory, action, next_state)
-
-    def _is_constraint_dependent_on_next_state_(self) -> bool:
-        return self._depends_on_next_state
-
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        def cast_check_function(memory, action, next_state):
-            cast_memory = cast(memory, dst_sub[0], src_sub[0])
-            cast_action = cast(action, dst_sub[1], src_sub[1])
-            cast_next_state = cast(next_state, dst_sub[2], src_sub[2])
-            return self._check_function(cast_memory, cast_action, cast_next_state)
-
-        return ImplicitConstraint(cast_check_function, self._depends_on_next_state)
-
-
-class BoundConstraint(Constraint[D.T_memory, D.T_event, D.T_state]):
-    """A constraint characterized by an evaluation function, an inequality and a bound.
-
-    # Example
-    A BoundConstraint with inequality '>=' is checked if (and only if) its #BoundConstraint.evaluate() function returns
-    a float greater than or equal to its bound.
-    """
-
-    def __init__(
-        self,
-        evaluate_function: Callable[
-            [D.T_memory, D.T_event, Optional[D.T_state]], float
-        ],
-        inequality: str,
-        bound: float,
-        depends_on_next_state: bool = True,
-    ) -> None:
-        """Initialize BoundConstraint.
-
-        # Parameters
-        evaluate_function: The evaluate() function to use.
-        inequality: A string ('<', '<=', '>' or '>=') describing the constraint inequality.
-        bound: The bound of the constraint.
-        depends_on_next_state: Whether the evaluate() function requires the next_state parameter for its computation.
-
-        # Example
-        ```python
-        constraint = BoundConstraint((lambda memory, action, next_state: next_state.x), '>', 5.)
-        ```
-        """
-        self._evaluate_function = evaluate_function
-        self._inequality = inequality
-        self._bound = bound
-        self._depends_on_next_state = depends_on_next_state
-
-        assert inequality in ["<", "<=", ">", ">="]
-        inequality_functions = {
-            "<": (lambda val, bnd: val < bnd),
-            "<=": (lambda val, bnd: val <= bnd),
-            ">": (lambda val, bnd: val > bnd),
-            ">=": (lambda val, bnd: val >= bnd),
-        }
-        self._check_function = inequality_functions[inequality]
-
-    def check(
-        self,
-        memory: D.T_memory,
-        action: D.T_event,
-        next_state: Optional[D.T_state] = None,
-    ) -> bool:
-        return self._check_function(
-            self.evaluate(memory, action, next_state), self._bound
-        )
-
-    def _is_constraint_dependent_on_next_state_(self) -> bool:
-        return self._depends_on_next_state
-
-    def evaluate(
-        self,
-        memory: D.T_memory,
-        action: D.T_event,
-        next_state: Optional[D.T_state] = None,
-    ) -> float:
-        """Evaluate the left side of this BoundConstraint.
-
-        !!! tip
-            If this function never depends on the next_state parameter for its computation, it is recommended to
-            indicate it by overriding #Constraint._is_constraint_dependent_on_next_state_() to return False. This
-            information can then be exploited by solvers to avoid computing next state to evaluate the constraint (more
-            efficient).
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-        action: The action taken in the given memory (state or history) triggering the transition.
-        next_state: The next state in which the transition ends (if needed for the computation).
-
-        # Returns
-        The float value resulting from the evaluation.
-        """
-        return self._evaluate_function(memory, action, next_state)
-
-    def get_inequality(self) -> str:
-        """Get the string ('<', '<=', '>' or '>=') describing the constraint inequality.
-
-        # Returns
-        The string describing the inequality.
-        """
-        return self._inequality
-
-    def get_bound(self) -> float:
-        """Get the bound of the constraint.
-
-        # Returns
-        The constraint bound.
-        """
-        return self._bound
-
-    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
-        def cast_evaluate_function(memory, action, next_state):
-            cast_memory = cast(memory, dst_sub[0], src_sub[0])
-            cast_action = cast(action, dst_sub[1], src_sub[1])
-            cast_next_state = cast(next_state, dst_sub[2], src_sub[2])
-            return self._evaluate_function(cast_memory, cast_action, cast_next_state)
-
-        return BoundConstraint(
-            cast_evaluate_function,
-            self._inequality,
-            self._bound,
-            self._depends_on_next_state,
-        )
-
-
-SINGLE_AGENT_ID = "agent"
-
-# (auto)cast-related objects/functions
-cast_dict = {
-    (Memory, Union): lambda obj, src, dst: cast(obj[0], src[0], dst[0]),
-    (Union, Memory): lambda obj, src, dst: Memory([cast(obj, src[0], dst[0])]),
-    (Memory, Memory): lambda obj, src, dst: Memory(
-        [cast(x, src[0], dst[0]) for x in obj]
-    ),
-    (StrDict, Union): lambda obj, src, dst: cast(
-        next(iter(obj.values())), src[0], dst[0]
-    ),
-    (Union, StrDict): lambda obj, src, dst: {
-        SINGLE_AGENT_ID: cast(obj, src[0], dst[0])
-    },
-    (StrDict, StrDict): lambda obj, src, dst: {
-        k: cast(v, src[0], dst[0]) for k, v in obj.items()
-    },
-    # (Set, Union): lambda obj, src, dst: cast(next(iter(obj)), src[0], dst[0]),
-    # (Union, Set): lambda obj, src, dst: {cast(obj, src[0], dst[0])},
-    # (Set, Set): lambda obj, src, dst: {cast(x, src[0], dst[0]) for x in obj},
-    (List, Union): lambda obj, src, dst: cast(obj[0], src[0], dst[0]),
-    (Union, List): lambda obj, src, dst: [cast(obj, src[0], dst[0])],
-    (List, List): lambda obj, src, dst: [cast(x, src[0], dst[0]) for x in obj],
-    (Union, Union): lambda obj, src, dst: cast(obj, src[0], dst[0]),
-    (Optional, Optional): lambda obj, src, dst: cast(obj, src[0], dst[0])
-    if obj is not None
-    else None,
-}  # (src_type, dst_type): (obj: src_type, src_sub_hintrees: List[Tree], dst_sub_hintrees: List[Tree]) -> dst_type
-
-default_cast = (
-    lambda obj, src, dst: obj._cast(src, dst) if isinstance(obj, Castable) else obj
-)
-
-
-def parse_hint(obj: object, hint: str, hint_obj: str) -> Tree:
-    # note: hint is assumed to contain no whitespace (which will be true by construction)
-    match = re.match(
-        rf"^(?P<hint_obj>{hint_obj}\.)?(?P<type>\w+)(?:\[(?P<generics>.+)\])?$", hint
-    )
-    groups = match.groupdict()
-    type_ = getattr(obj, groups["type"]) if groups["hint_obj"] else eval(groups["type"])
-    if groups["generics"]:
-        generics = groups["generics"].split(",")
-        if all(
-            g.count("[") == g.count("]") for g in generics
-        ):  # check that the generics split is not at a sub-level
-            sub = [parse_hint(obj, h, hint_obj) for h in generics]
-        else:
-            sub = [parse_hint(obj, groups["generics"], hint_obj)]
-    else:
-        sub = []
-    return Tree(type_, sub)
-
-
-def get_args_dict(func: Callable, args: Tuple, kwargs: Dict) -> Dict:
-    while hasattr(
-        func, "__wrapped__"
-    ):  # get to the core function even if it was decorated
-        func = func.__wrapped__
-    args_names = func.__code__.co_varnames[
-        inspect.ismethod(func) : func.__code__.co_argcount
-    ]
-    return {**dict(zip(args_names, args)), **kwargs}
-
-
-@functools.lru_cache(maxsize=1000)
-def cast_needed(src_hintree: Tree, dst_hintree: Tree) -> bool:
-    # note: src_hintree and dst_hintree are assumed to have the same tree structure (which will be true by construction)
-    src_type = src_hintree.type
-    dst_type = dst_hintree.type
-    if src_type != dst_type and (src_type, dst_type) in cast_dict:
-        return True
-    else:
-        src_sub_hintrees = src_hintree.sub
-        dst_sub_hintrees = dst_hintree.sub
-        return any(
-            cast_needed(src_sub_hintrees[i], dst_sub_hintrees[i])
-            for i in range(len(src_sub_hintrees))
-        )
-
-
-def cast(obj: object, src_hintree: Tree, dst_hintree: Tree):
-    # print('> Cast', obj, src_hintree.type, dst_hintree.type)
-    if cast_needed(src_hintree, dst_hintree):
-        cast_pair = (src_hintree.type, dst_hintree.type)
-        return cast_dict.get(cast_pair, default_cast)(
-            obj, src_hintree.sub, dst_hintree.sub
-        )
-    else:
-        return obj
-
-
-def autocast(func: Callable, src: object, dst: object, hint_obj: str = "D") -> Callable:
-    hints = func.__annotations__
-    cast_args = []
-    src_hintrees = {}
-    dst_hintrees = {}
-    for arg, hint in hints.items():
-        # if hint depends on a hint_obj attribute at least once (e.g. 'D.T_state')
-        if re.search(rf"(?<=\b{hint_obj}\.)\w+", hint):
-            formatted_hint = re.sub(r"\s+", "", hint)
-            src_hintrees[arg] = parse_hint(src, formatted_hint, hint_obj)
-            dst_hintrees[arg] = parse_hint(dst, formatted_hint, hint_obj)
-            if cast_needed(src_hintrees[arg], dst_hintrees[arg]):
-                cast_args.append(arg)
-
-    @functools.wraps(func)
-    def wrapper_autocast(
-        *args, **kwargs
-    ):  # TODO: raise autocast exception when problem inside wrapper?
-        # print('Wrapper used for:', func, src_hintrees, dst_hintrees)
-        args_dict = get_args_dict(func, args, kwargs)
-        cast_args_dict = {
-            k: (cast(v, dst_hintrees[k], src_hintrees[k]) if k in cast_args else v)
-            for k, v in args_dict.items()
-        }
-        result = func(**cast_args_dict)
-        return (
-            cast(result, src_hintrees["return"], dst_hintrees["return"])
-            if "return" in cast_args
-            else result
-        )
-
-    return wrapper_autocast if len(cast_args) > 0 else func
-
-
-def autocast_all(obj: object, src: object, dst: object):
-    for name, f in inspect.getmembers(
-        obj, lambda x: inspect.isfunction(x) or inspect.ismethod(x)
-    ):
-        if getattr(f, "_autocastable", None):
-            setattr(obj, name, autocast(f, src, dst))
-
-
-# autocastable (function decorator)
-def autocastable(func: Callable):
-    func._autocastable = True
-    return func
-
-
-# nocopy (class decorator)
-def nocopy(cls):
-    cls.__copy__ = lambda self: self
-    cls.__deepcopy__ = lambda self, memodict={}: self
-    return cls
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import functools
+import inspect
+import random
+import re
+from dataclasses import asdict, astuple, dataclass, replace
+from typing import (
+    Callable,
+    Deque,
+    Dict,
+    Generic,
+    Iterable,
+    List,
+    Optional,
+    Sequence,
+    Tuple,
+    TypeVar,
+    Union,
+)
+
+__all__ = [
+    "T",
+    "D",
+    "Space",
+    "ImplicitSpace",
+    "EnumerableSpace",
+    "EmptySpace",
+    "SamplableSpace",
+    "SerializableSpace",
+    "Distribution",
+    "ImplicitDistribution",
+    "DiscreteDistribution",
+    "SingleValueDistribution",
+    "Value",
+    "EnvironmentOutcome",
+    "TransitionOutcome",
+    "Memory",
+    "StrDict",
+    "Constraint",
+    "ImplicitConstraint",
+    "BoundConstraint",
+    "autocast_all",
+    "autocastable",
+    "nocopy",
+]
+
+T = TypeVar("T")  # Any type
+
+
+class D:
+    T_state = TypeVar("T_state")  # Type of states
+    T_observation = TypeVar("T_observation")  # Type of observations
+    T_event = TypeVar("T_event")  # Type of events
+    T_value = TypeVar("T_value")  # Type of transition values (rewards or costs)
+    T_predicate = TypeVar("T_predicate")  # Type of logical checks
+    T_info = TypeVar(
+        "T_info"
+    )  # Type of additional information given as part of an environment outcome
+    T_memory = TypeVar("T_memory")
+    T_agent = TypeVar("T_agent")
+    T_concurrency = TypeVar("T_concurrency")
+
+
+# Tree (utility class)
+class Tree:
+    def __init__(self, type_: object, sub: List[Tree] = []):
+        self.type = type_
+        self.sub = sub
+
+
+# Castable (utility class)
+class Castable:
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        raise NotImplementedError
+
+
+# Space
+class Space(Generic[T]):
+    """A space representing a finite or infinite set.
+
+    This class (or any of its descendant) is typically used to specify action, observation or goal spaces.
+    """
+
+    def contains(self, x: T) -> bool:
+        """Check whether x is a valid member of this space.
+
+        # Parameters
+        x: The member to consider.
+
+        # Returns
+        True if x is a valid member of this space (False otherwise).
+        """
+        raise NotImplementedError
+
+    def __contains__(self, item: T) -> bool:
+        return self.contains(item)
+
+
+class ImplicitSpace(Space[T]):
+    """A space formalized implicitly, i.e. by a black-box contains() function."""
+
+    def __init__(self, contains_function: Callable[[T], bool]) -> None:
+        """Initialize ImplicitSpace.
+
+        # Parameters
+        contains_function: The contains() function to use.
+
+        # Example
+        ```python
+        my_space = ImplicitSpace(lambda x: 10 > x['position'] > 5)
+        ```
+        """
+        self.contains_function = contains_function
+
+    def contains(self, x: T) -> bool:
+        return self.contains_function(x)
+
+
+class EnumerableSpace(Space[T]):
+    """A space which elements can be enumerated."""
+
+    def get_elements(self) -> Iterable[T]:
+        """Get the elements of this space.
+
+        # Returns
+        The elements of this space.
+        """
+        raise NotImplementedError
+
+    def contains(self, x: T) -> bool:
+        return x in self.get_elements()
+
+
+class EmptySpace(EnumerableSpace[T]):
+    """An (enumerable) empty space."""
+
+    def get_elements(self) -> Iterable[T]:
+        return ()
+
+
+class SamplableSpace(Space[T]):
+    """A space which can be sampled (uniformly randomly)."""
+
+    def sample(self) -> T:
+        """Uniformly randomly sample a random element of this space.
+
+        # Returns
+        The sampled element.
+        """
+        raise NotImplementedError
+
+
+class SerializableSpace(Space[T]):
+    """A space which can be serialized (to/from JSON)."""
+
+    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
+        """Convert a batch of samples from this space to a JSONable data type.
+
+        # Parameters
+        sample_n: The batch of samples to convert.
+
+        # Returns
+        The resulting JSONable data type.
+        """
+        # By default, assume identity is JSONable
+        return sample_n
+
+    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
+        """Convert a JSONable data type to a batch of samples from this space.
+
+        # Parameters
+        sample_n: The JSONable data type to convert.
+
+        # Returns
+        The resulting batch of samples.
+        """
+        # By default, assume identity is JSONable
+        return sample_n
+
+
+# Distribution
+class Distribution(Generic[T], Castable):
+    """A probability distribution."""
+
+    def sample(self) -> T:
+        """Sample from this distribution.
+
+        # Returns
+        The sampled element.
+        """
+        raise NotImplementedError
+
+
+class ImplicitDistribution(Distribution[T]):
+    """A probability distribution formalized implicitly, i.e. by a black-box sample() function."""
+
+    def __init__(self, sample_function: Callable[[], T]) -> None:
+        """Initialize ImplicitDistribution.
+
+        # Parameters
+        sample_function: The sample() function to use.
+
+        # Example
+        ```python
+        import random
+
+        dice = ImplicitDistribution(lambda: random.randint(1, 6))
+        roll = dice.sample()
+        ```
+        """
+        self._sample_function = sample_function
+
+    def sample(self) -> T:
+        return self._sample_function()
+
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        def cast_sample_function():
+            result = self._sample_function()
+            return cast(result, src_sub[0], dst_sub[0])
+
+        return ImplicitDistribution(cast_sample_function)
+
+
+class DiscreteDistribution(Distribution[T]):
+    """A discrete probability distribution."""
+
+    def __init__(self, values: List[Tuple[T, float]]) -> None:
+        """Initialize DiscreteDistribution.
+
+        !!! tip
+            If the given probabilities do not sum to 1, they are implicitly normalized as such for sampling.
+
+        # Parameters
+        values: The list of (element, probability) pairs.
+
+        # Example
+        ```python
+        game_strategy = DiscreteDistribution([('rock', 0.7), ('paper', 0.1), ('scissors', 0.2)])
+        move = game_strategy.sample()
+        ```
+        """
+        self._values = values
+        unzip_values = list(zip(*values))
+        # TODO: make sure every population member is unique (and if not, aggregate same ones by summing their weights)?
+        self._population = unzip_values[0]
+        self._weights = unzip_values[1]
+
+    def sample(self) -> T:
+        return random.choices(self._population, self._weights)[0]
+
+    def get_values(self) -> List[Tuple[T, float]]:
+        """Get the list of (element, probability) pairs.
+
+        # Returns
+        The (element, probability) pairs.
+        """
+        return self._values
+
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        return DiscreteDistribution(
+            [(cast(e, src_sub[0], dst_sub[0]), p) for e, p in self._values]
+        )
+
+
+class SingleValueDistribution(DiscreteDistribution[T]):
+    """A single value distribution (i.e. Dirac distribution)."""
+
+    def __init__(self, value: T) -> None:
+        """Initialize SingleValueDistribution.
+
+        # Parameters
+        value: The single value of this distribution.
+        """
+        self._value = value
+
+    def sample(self) -> T:
+        return self._value
+
+    def get_values(self) -> List[Tuple[T, float]]:
+        return [(self._value, 1.0)]
+
+    def get_value(self) -> T:
+        """Get the single value of this distribution.
+
+        # Returns
+        The single value of this distribution.
+        """
+        return self._value
+
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        return SingleValueDistribution(cast(self._value, src_sub[0], dst_sub[0]))
+
+
+# ExtendedDataclass (dataclasses can inherit from it to extended their methods with useful utilities)
+class ExtendedDataclass:
+    def asdict(self):
+        """Return the fields of the instance as a new dictionary mapping field names to field values."""
+        return asdict(self)
+
+    def astuple(self):
+        """Return the fields of the instance as a new tuple of field values."""
+        return astuple(self)
+
+    def replace(self, **changes):
+        """Return a new object replacing specified fields with new values."""
+        return replace(self, **changes)
+
+
+# Value
+@dataclass
+class Value(Generic[D.T_value]):
+    """A value (reward or cost).
+
+    !!! warning
+        It is recommended to use either the reward or the cost parameter. If no one is used, a reward/cost of 0 is
+        assumed. If both are used, reward will be considered and cost ignored. In any case, both reward and cost
+        attributes will be defined after initialization.
+
+    # Parameters
+    reward: The optional reward.
+    cost: The optional cost.
+
+    # Example
+    ```python
+    # These two lines are equivalent, use the one you prefer
+    value_1 = Value(reward=-5)
+    value_2 = Value(cost=5)
+
+    assert value_1.reward == value_2.reward == -5  # True
+    assert value_1.cost == value_2.cost == 5  # True
+    ```
+    """
+
+    reward: Optional[D.T_value] = None
+    cost: Optional[D.T_value] = None
+
+    def __post_init__(self) -> None:
+        if self.reward is not None:
+            self.cost = self._reward_to_cost(self.reward)
+        elif self.cost is not None:
+            self.reward = self._cost_to_reward(self.cost)
+        else:
+            self.reward = 0
+            self.cost = 0
+
+    def _cost_to_reward(self, cost: D.T_value) -> D.T_value:
+        return -cost
+
+    def _reward_to_cost(self, reward: D.T_value) -> D.T_value:
+        return -reward
+
+
+# EnvironmentOutcome
+@dataclass
+class EnvironmentOutcome(
+    Generic[D.T_observation, D.T_value, D.T_predicate, D.T_info],
+    Castable,
+    ExtendedDataclass,
+):
+    """An environment outcome for an internal transition.
+
+    # Parameters
+    observation: The agent's observation of the current environment.
+    value: The value (reward or cost) returned after previous action.
+    termination: Whether the episode has ended, in which case further step() calls will return undefined results.
+    info: Optional auxiliary diagnostic information (helpful for debugging, and sometimes learning).
+    """
+
+    observation: D.T_observation
+    value: Optional[D.T_value] = None
+    termination: Optional[D.T_predicate] = None
+    info: Optional[D.T_info] = None
+
+    def __post_init__(self) -> None:
+        if self.value is None:
+            self.value = (
+                {k: Value() for k in self.observation}
+                if isinstance(self.observation, dict)
+                else Value()
+            )
+        if self.termination is None:
+            self.termination = (
+                {k: False for k in self.observation}
+                if isinstance(self.observation, dict)
+                else False
+            )
+        if self.info is None:
+            self.info = (
+                {k: None for k in self.observation}
+                if isinstance(self.observation, dict)
+                else None
+            )
+
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        return EnvironmentOutcome(
+            cast(self.observation, src_sub[0], dst_sub[0]),
+            cast(self.value, src_sub[1], dst_sub[1]),
+            cast(self.termination, src_sub[2], dst_sub[2]),
+            cast(self.info, src_sub[3], dst_sub[3]),
+        )
+
+
+# TransitionOutcome
+@dataclass
+class TransitionOutcome(
+    Generic[D.T_state, D.T_value, D.T_predicate, D.T_info], Castable, ExtendedDataclass
+):
+    """A transition outcome.
+
+    # Parameters
+    state: The new state after the transition.
+    value: The value (reward or cost) returned after previous action.
+    termination: Whether the episode has ended, in which case further step() calls will return undefined results.
+    info: Optional auxiliary diagnostic information (helpful for debugging, and sometimes learning).
+    """
+
+    state: D.T_state
+    value: Optional[D.T_value] = None
+    termination: Optional[D.T_predicate] = None
+    info: Optional[D.T_info] = None
+
+    def __post_init__(self) -> None:
+        if self.value is None:
+            self.value = (
+                {k: Value() for k in self.state}
+                if isinstance(self.state, dict)
+                else Value()
+            )
+        if self.termination is None:
+            self.termination = (
+                {k: False for k in self.observation}
+                if isinstance(self.observation, dict)
+                else False
+            )
+
+        if self.info is None:
+            self.info = (
+                {k: None for k in self.state} if isinstance(self.state, dict) else None
+            )
+
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        return TransitionOutcome(
+            cast(self.state, src_sub[0], dst_sub[0]),
+            cast(self.value, src_sub[1], dst_sub[1]),
+            cast(self.termination, src_sub[2], dst_sub[2]),
+            cast(self.info, src_sub[3], dst_sub[3]),
+        )
+
+
+# Memory
+class Memory(Deque[T]):
+    pass
+
+
+# StrDict
+class StrDict(Generic[T], Dict[str, T]):
+    """A dictionary with String keys (e.g. agent names)."""
+
+    pass
+
+
+# Constraint
+class Constraint(Generic[D.T_memory, D.T_event, D.T_state], Castable):
+    """A constraint."""
+
+    def check(
+        self,
+        memory: D.T_memory,
+        action: D.T_event,
+        next_state: Optional[D.T_state] = None,
+    ) -> bool:
+        """Check this constraint.
+
+        !!! tip
+            If this function never depends on the next_state parameter for its computation, it is recommended to
+            indicate it by overriding #Constraint._is_constraint_dependent_on_next_state_() to return False. This
+            information can then be exploited by solvers to avoid computing next state to evaluate the constraint (more
+            efficient).
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+        next_state: The next state in which the transition ends (if needed for the computation).
+
+        # Returns
+        True if the constraint is checked (False otherwise).
+        """
+        raise NotImplementedError
+
+    @functools.lru_cache()
+    def is_constraint_dependent_on_next_state(self) -> bool:
+        """Indicate whether this constraint requires the next_state parameter for its computation (cached).
+
+        By default, #Constraint.is_constraint_dependent_on_next_state() internally
+        calls #Constraint._is_constraint_dependent_on_next_state_() the first time and automatically caches its value to
+        make future calls more efficient (since the returned value is assumed to be constant).
+
+        # Returns
+        True if the constraint computation depends on next_state (False otherwise).
+        """
+        return self._is_constraint_dependent_on_next_state_()
+
+    def _is_constraint_dependent_on_next_state_(self) -> bool:
+        """Indicate whether this constraint requires the next_state parameter for its computation.
+
+        This is a helper function called by default from #Constraint.is_constraint_dependent_on_next_state(), the
+        difference being that the result is not cached here.
+
+        !!! tip
+            The underscore at the end of this function's name is a convention to remind that its result should be
+            constant.
+
+        # Returns
+        True if the constraint computation depends on next_state (False otherwise).
+        """
+        raise NotImplementedError
+
+
+class ImplicitConstraint(Constraint[D.T_memory, D.T_event, D.T_state]):
+    """A constraint formalized implicitly, i.e. by a black-box check() function."""
+
+    def __init__(
+        self,
+        check_function: Callable[[D.T_memory, D.T_event, Optional[D.T_state]], bool],
+        depends_on_next_state: bool = True,
+    ) -> None:
+        """Initialize ImplicitConstraint.
+
+        # Parameters
+        check_function: The check() function to use.
+        depends_on_next_state: Whether the check() function requires the next_state parameter for its computation.
+
+        # Example
+        ```python
+        constraint = ImplicitConstraint(lambda memory, action, next_state: next_state.x % 2 == 0)
+        ```
+        """
+        self._check_function = check_function
+        self._depends_on_next_state = depends_on_next_state
+
+    def check(
+        self,
+        memory: D.T_memory,
+        action: D.T_event,
+        next_state: Optional[D.T_state] = None,
+    ) -> bool:
+        return self._check_function(memory, action, next_state)
+
+    def _is_constraint_dependent_on_next_state_(self) -> bool:
+        return self._depends_on_next_state
+
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        def cast_check_function(memory, action, next_state):
+            cast_memory = cast(memory, dst_sub[0], src_sub[0])
+            cast_action = cast(action, dst_sub[1], src_sub[1])
+            cast_next_state = cast(next_state, dst_sub[2], src_sub[2])
+            return self._check_function(cast_memory, cast_action, cast_next_state)
+
+        return ImplicitConstraint(cast_check_function, self._depends_on_next_state)
+
+
+class BoundConstraint(Constraint[D.T_memory, D.T_event, D.T_state]):
+    """A constraint characterized by an evaluation function, an inequality and a bound.
+
+    # Example
+    A BoundConstraint with inequality '>=' is checked if (and only if) its #BoundConstraint.evaluate() function returns
+    a float greater than or equal to its bound.
+    """
+
+    def __init__(
+        self,
+        evaluate_function: Callable[
+            [D.T_memory, D.T_event, Optional[D.T_state]], float
+        ],
+        inequality: str,
+        bound: float,
+        depends_on_next_state: bool = True,
+    ) -> None:
+        """Initialize BoundConstraint.
+
+        # Parameters
+        evaluate_function: The evaluate() function to use.
+        inequality: A string ('<', '<=', '>' or '>=') describing the constraint inequality.
+        bound: The bound of the constraint.
+        depends_on_next_state: Whether the evaluate() function requires the next_state parameter for its computation.
+
+        # Example
+        ```python
+        constraint = BoundConstraint((lambda memory, action, next_state: next_state.x), '>', 5.)
+        ```
+        """
+        self._evaluate_function = evaluate_function
+        self._inequality = inequality
+        self._bound = bound
+        self._depends_on_next_state = depends_on_next_state
+
+        assert inequality in ["<", "<=", ">", ">="]
+        inequality_functions = {
+            "<": (lambda val, bnd: val < bnd),
+            "<=": (lambda val, bnd: val <= bnd),
+            ">": (lambda val, bnd: val > bnd),
+            ">=": (lambda val, bnd: val >= bnd),
+        }
+        self._check_function = inequality_functions[inequality]
+
+    def check(
+        self,
+        memory: D.T_memory,
+        action: D.T_event,
+        next_state: Optional[D.T_state] = None,
+    ) -> bool:
+        return self._check_function(
+            self.evaluate(memory, action, next_state), self._bound
+        )
+
+    def _is_constraint_dependent_on_next_state_(self) -> bool:
+        return self._depends_on_next_state
+
+    def evaluate(
+        self,
+        memory: D.T_memory,
+        action: D.T_event,
+        next_state: Optional[D.T_state] = None,
+    ) -> float:
+        """Evaluate the left side of this BoundConstraint.
+
+        !!! tip
+            If this function never depends on the next_state parameter for its computation, it is recommended to
+            indicate it by overriding #Constraint._is_constraint_dependent_on_next_state_() to return False. This
+            information can then be exploited by solvers to avoid computing next state to evaluate the constraint (more
+            efficient).
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+        action: The action taken in the given memory (state or history) triggering the transition.
+        next_state: The next state in which the transition ends (if needed for the computation).
+
+        # Returns
+        The float value resulting from the evaluation.
+        """
+        return self._evaluate_function(memory, action, next_state)
+
+    def get_inequality(self) -> str:
+        """Get the string ('<', '<=', '>' or '>=') describing the constraint inequality.
+
+        # Returns
+        The string describing the inequality.
+        """
+        return self._inequality
+
+    def get_bound(self) -> float:
+        """Get the bound of the constraint.
+
+        # Returns
+        The constraint bound.
+        """
+        return self._bound
+
+    def _cast(self, src_sub: List[Tree], dst_sub: List[Tree]):
+        def cast_evaluate_function(memory, action, next_state):
+            cast_memory = cast(memory, dst_sub[0], src_sub[0])
+            cast_action = cast(action, dst_sub[1], src_sub[1])
+            cast_next_state = cast(next_state, dst_sub[2], src_sub[2])
+            return self._evaluate_function(cast_memory, cast_action, cast_next_state)
+
+        return BoundConstraint(
+            cast_evaluate_function,
+            self._inequality,
+            self._bound,
+            self._depends_on_next_state,
+        )
+
+
+SINGLE_AGENT_ID = "agent"
+
+# (auto)cast-related objects/functions
+cast_dict = {
+    (Memory, Union): lambda obj, src, dst: cast(obj[0], src[0], dst[0]),
+    (Union, Memory): lambda obj, src, dst: Memory([cast(obj, src[0], dst[0])]),
+    (Memory, Memory): lambda obj, src, dst: Memory(
+        [cast(x, src[0], dst[0]) for x in obj]
+    ),
+    (StrDict, Union): lambda obj, src, dst: cast(
+        next(iter(obj.values())), src[0], dst[0]
+    ),
+    (Union, StrDict): lambda obj, src, dst: {
+        SINGLE_AGENT_ID: cast(obj, src[0], dst[0])
+    },
+    (StrDict, StrDict): lambda obj, src, dst: {
+        k: cast(v, src[0], dst[0]) for k, v in obj.items()
+    },
+    # (Set, Union): lambda obj, src, dst: cast(next(iter(obj)), src[0], dst[0]),
+    # (Union, Set): lambda obj, src, dst: {cast(obj, src[0], dst[0])},
+    # (Set, Set): lambda obj, src, dst: {cast(x, src[0], dst[0]) for x in obj},
+    (List, Union): lambda obj, src, dst: cast(obj[0], src[0], dst[0]),
+    (Union, List): lambda obj, src, dst: [cast(obj, src[0], dst[0])],
+    (List, List): lambda obj, src, dst: [cast(x, src[0], dst[0]) for x in obj],
+    (Union, Union): lambda obj, src, dst: cast(obj, src[0], dst[0]),
+    (Optional, Optional): lambda obj, src, dst: cast(obj, src[0], dst[0])
+    if obj is not None
+    else None,
+}  # (src_type, dst_type): (obj: src_type, src_sub_hintrees: List[Tree], dst_sub_hintrees: List[Tree]) -> dst_type
+
+default_cast = (
+    lambda obj, src, dst: obj._cast(src, dst) if isinstance(obj, Castable) else obj
+)
+
+
+def parse_hint(obj: object, hint: str, hint_obj: str) -> Tree:
+    # note: hint is assumed to contain no whitespace (which will be true by construction)
+    match = re.match(
+        rf"^(?P<hint_obj>{hint_obj}\.)?(?P<type>\w+)(?:\[(?P<generics>.+)\])?$", hint
+    )
+    groups = match.groupdict()
+    type_ = getattr(obj, groups["type"]) if groups["hint_obj"] else eval(groups["type"])
+    if groups["generics"]:
+        generics = groups["generics"].split(",")
+        if all(
+            g.count("[") == g.count("]") for g in generics
+        ):  # check that the generics split is not at a sub-level
+            sub = [parse_hint(obj, h, hint_obj) for h in generics]
+        else:
+            sub = [parse_hint(obj, groups["generics"], hint_obj)]
+    else:
+        sub = []
+    return Tree(type_, sub)
+
+
+def get_args_dict(func: Callable, args: Tuple, kwargs: Dict) -> Dict:
+    while hasattr(
+        func, "__wrapped__"
+    ):  # get to the core function even if it was decorated
+        func = func.__wrapped__
+    args_names = func.__code__.co_varnames[
+        inspect.ismethod(func) : func.__code__.co_argcount
+    ]
+    return {**dict(zip(args_names, args)), **kwargs}
+
+
+@functools.lru_cache(maxsize=1000)
+def cast_needed(src_hintree: Tree, dst_hintree: Tree) -> bool:
+    # note: src_hintree and dst_hintree are assumed to have the same tree structure (which will be true by construction)
+    src_type = src_hintree.type
+    dst_type = dst_hintree.type
+    if src_type != dst_type and (src_type, dst_type) in cast_dict:
+        return True
+    else:
+        src_sub_hintrees = src_hintree.sub
+        dst_sub_hintrees = dst_hintree.sub
+        return any(
+            cast_needed(src_sub_hintrees[i], dst_sub_hintrees[i])
+            for i in range(len(src_sub_hintrees))
+        )
+
+
+def cast(obj: object, src_hintree: Tree, dst_hintree: Tree):
+    # print('> Cast', obj, src_hintree.type, dst_hintree.type)
+    if cast_needed(src_hintree, dst_hintree):
+        cast_pair = (src_hintree.type, dst_hintree.type)
+        return cast_dict.get(cast_pair, default_cast)(
+            obj, src_hintree.sub, dst_hintree.sub
+        )
+    else:
+        return obj
+
+
+def autocast(func: Callable, src: object, dst: object, hint_obj: str = "D") -> Callable:
+    hints = func.__annotations__
+    cast_args = []
+    src_hintrees = {}
+    dst_hintrees = {}
+    for arg, hint in hints.items():
+        # if hint depends on a hint_obj attribute at least once (e.g. 'D.T_state')
+        if re.search(rf"(?<=\b{hint_obj}\.)\w+", hint):
+            formatted_hint = re.sub(r"\s+", "", hint)
+            src_hintrees[arg] = parse_hint(src, formatted_hint, hint_obj)
+            dst_hintrees[arg] = parse_hint(dst, formatted_hint, hint_obj)
+            if cast_needed(src_hintrees[arg], dst_hintrees[arg]):
+                cast_args.append(arg)
+
+    @functools.wraps(func)
+    def wrapper_autocast(
+        *args, **kwargs
+    ):  # TODO: raise autocast exception when problem inside wrapper?
+        # print('Wrapper used for:', func, src_hintrees, dst_hintrees)
+        args_dict = get_args_dict(func, args, kwargs)
+        cast_args_dict = {
+            k: (cast(v, dst_hintrees[k], src_hintrees[k]) if k in cast_args else v)
+            for k, v in args_dict.items()
+        }
+        result = func(**cast_args_dict)
+        return (
+            cast(result, src_hintrees["return"], dst_hintrees["return"])
+            if "return" in cast_args
+            else result
+        )
+
+    return wrapper_autocast if len(cast_args) > 0 else func
+
+
+def autocast_all(obj: object, src: object, dst: object):
+    for name, f in inspect.getmembers(
+        obj, lambda x: inspect.isfunction(x) or inspect.ismethod(x)
+    ):
+        if getattr(f, "_autocastable", None):
+            setattr(obj, name, autocast(f, src, dst))
+
+
+# autocastable (function decorator)
+def autocastable(func: Callable):
+    func._autocastable = True
+    return func
+
+
+# nocopy (class decorator)
+def nocopy(cls):
+    cls.__copy__ = lambda self: self
+    cls.__deepcopy__ = lambda self, memodict={}: self
+    return cls
```

## skdecide/domains.py

```diff
@@ -26,15 +26,16 @@
 from skdecide.builders.domain.memory import History, Markovian
 from skdecide.builders.domain.observability import (
     FullyObservable,
     PartiallyObservable,
     TransformedObservable,
 )
 from skdecide.builders.domain.value import PositiveCosts, Rewards
-from skdecide.core import autocast_all
+from skdecide.builders.solver.fromanystatesolvability import FromAnyState
+from skdecide.core import D, autocast_all
 
 if (
     False
 ):  # trick to avoid circular import & IDE error ("Unresolved reference 'Solver'")
     from skdecide.solvers import Solver
 
 __all__ = [
@@ -107,52 +108,14 @@
     T_state = T_state
     T_observation = T_observation
     T_event = T_event
     T_value = T_value
     T_predicate = T_predicate
     T_info = T_info
 
-    @classmethod
-    def solve_with(
-        cls,
-        solver: Solver,
-        domain_factory: Optional[Callable[[], Domain]] = None,
-        load_path: Optional[str] = None,
-    ) -> Solver:
-        """Solve the domain with a new or loaded solver and return it auto-cast to the level of the domain.
-
-        By default, #Solver.check_domain() provides some boilerplate code and internally
-        calls #Solver._check_domain_additional() (which returns True by default but can be overridden  to define
-        specific checks in addition to the "domain requirements"). The boilerplate code automatically checks whether all
-        domain requirements are met.
-
-        # Parameters
-        solver: The solver.
-        domain_factory: A callable with no argument returning the domain to solve (factory is the domain class if None).
-        load_path: The path to restore the solver state from (if None, the solving process will be launched instead).
-
-        # Returns
-        The new solver (auto-cast to the level of the domain).
-        """
-        if domain_factory is None:
-            domain_factory = cls
-        if load_path is not None:
-
-            # TODO: avoid repeating this code somehow (identical in solver.solve(...))? Is factory necessary (vs cls)?
-            def cast_domain_factory():
-                domain = domain_factory()
-                autocast_all(domain, domain, solver.T_domain)
-                return domain
-
-            solver.load(load_path, cast_domain_factory)
-        else:
-            solver.solve(domain_factory)
-        autocast_all(solver, solver.T_domain, cls)
-        return solver
-
 
 # ALTERNATE BASE CLASSES (for typical combinations)
 
 
 class RLDomain(
     Domain,
     SingleAgent,
```

## skdecide/hub/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
```

## skdecide/hub/domain/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
```

## skdecide/hub/domain/flight_planning/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .domain import FlightPlanningDomain, H_Action, State, V_Action, WeatherDate
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .domain import FlightPlanningDomain, H_Action, State, V_Action, WeatherDate
```

## skdecide/hub/domain/flight_planning/domain.py

```diff
@@ -1,1553 +1,1680 @@
-import math
-from argparse import Action
-from enum import Enum
-from math import asin, atan2, cos, radians, sin, sqrt
-from typing import Any, Callable, Optional, Tuple, Union
-
-import matplotlib.pyplot as plt
-import numpy as np
-import pandas as pd
-from openap.extra.aero import atmos
-from openap.extra.aero import bearing as aero_bearing
-from openap.extra.aero import distance, ft, kts, latlon, mach2tas
-from openap.extra.nav import airport
-from openap.fuel import FuelFlow
-from openap.prop import aircraft
-from pygeodesy.ellipsoidalVincenty import LatLon
-
-from skdecide import DeterministicPlanningDomain, ImplicitSpace, Solver, Space, Value
-from skdecide.builders.domain import Renderable, UnrestrictedActions
-from skdecide.hub.domain.flight_planning.flightplanning_utils import (
-    plot_altitude,
-    plot_network,
-    plot_trajectory,
-)
-from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.get_weather_noaa import (
-    get_weather_matrix,
-)
-from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.GenericInterpolator import (
-    GenericWindInterpolator,
-)
-from skdecide.hub.space.gym import EnumSpace, ListSpace, MultiDiscreteSpace
-from skdecide.utils import load_registered_solver
-
-try:
-    from IPython.display import clear_output as ipython_clear_output
-except ImportError:
-    ipython_available = False
-else:
-    ipython_available = True
-
-
-def clear_output(wait=True):
-    if ipython_available:
-        ipython_clear_output(wait=wait)
-
-
-class WeatherDate:
-    day: int
-    month: int
-    year: int
-    forecast: str
-    leapyear: bool
-
-    def __init__(self, day, month, year, forecast="nowcast") -> None:
-
-        self.day = int(day)
-        self.month = int(month)
-        self.year = int(year)
-        self.forecast = forecast
-        self.leapyear = self.year % 400 == 0 or (
-            self.year % 100 != 0 and self.year % 4 == 0
-        )
-
-    def __hash__(self) -> int:
-        return hash((self.day, self.month, self.year, self.forecast))
-
-    def __eq__(self, other: object) -> bool:
-        return (
-            self.day == other.day
-            and self.month == other.month
-            and self.year == other.year
-            and self.forecast == other.forecast
-        )
-
-    def __ne__(self, other: object) -> bool:
-        return (
-            self.day != other.day
-            or self.month != other.month
-            or self.year != other.year
-            or self.forecast != other.forecast
-        )
-
-    def __str__(self) -> str:
-        day = str(self.day)
-        month = str(self.month)
-
-        if len(day) == 1:
-            day = "0" + day
-        if len(month) == 1:
-            month = "0" + month
-
-        return f"[{day} {month} {self.year}, forecast : {self.forecast}]"
-
-    def to_dict(self) -> dict:
-        day = str(self.day)
-        month = str(self.month)
-
-        if len(day) == 1:
-            day = "0" + day
-        if len(month) == 1:
-            month = "0" + month
-
-        return {
-            "year": str(self.year),
-            "month": str(month),
-            "day": str(day),
-            "forecast": self.forecast,
-        }
-
-    def next_day(self):
-        day = self.day
-        month = self.month
-        year = self.year
-        if month == 12 and day == 31:
-            year += 1
-            month = 1
-            day = 1
-
-        elif month in (1, 3, 5, 7, 8, 10) and day == 31:
-            day = 1
-            month += 1
-
-        elif month in (4, 6, 9, 11) and day == 30:
-            day = 1
-            month += 1
-
-        elif month == 2:
-            if (self.leap_year and day == 29) or (not (self.leap_year) and day == 28):
-                day = 1
-                month = 3
-            else:
-                day += 1
-
-        else:
-            day += 1
-
-        return WeatherDate(day, month, year, forecast=self.forecast)
-
-    def previous_day(self):
-        day = self.day
-        month = self.month
-        year = self.year
-        if month == 1 and day == 1:
-            year -= 1
-            month = 12
-            day = 31
-
-        elif month in (5, 7, 10, 12) and day == 1:
-            day = 30
-            month -= 1
-
-        elif month in (2, 4, 6, 8, 9, 11) and day == 1:
-            day = 31
-            month -= 1
-
-        elif month == 3 and day == 1:
-            if self.leap_year:
-                day = 29
-                month = 2
-            else:
-                day = 28
-                month = 2
-
-        else:
-            day -= 1
-
-        return WeatherDate(day, month, year, forecast=self.forecast)
-
-
-class State:
-    """
-    Definition of a aircraft state during the flight plan
-    """
-
-    trajectory: pd.DataFrame
-    pos: Tuple[int, int, int]
-
-    def __init__(self, trajectory, pos):
-        """Initialisation of a state
-
-        Args:
-            trajectory : Trajectory information of the flight
-            pos : Current position in the airways graph
-        """
-        self.trajectory = trajectory
-        self.pos = pos
-        if trajectory is not None:
-            self.mass = trajectory.iloc[-1]["mass"]
-            self.alt = trajectory.iloc[-1]["alt"]
-            self.time = trajectory.iloc[-1]["ts"]
-        else:
-            self.mass = None
-            self.alt = None
-            self.time = None
-
-    def __hash__(self):
-        return hash((self.pos, int(self.mass), self.alt, int(self.time)))
-
-    def __eq__(self, other):
-        return (
-            self.pos == other.pos
-            and int(self.mass) == int(other.mass)
-            and self.alt == other.alt
-            and int(self.time) == int(other.time)
-        )
-
-    def __ne__(self, other):
-        return (
-            self.pos != other.pos
-            or int(self.mass) != int(other.mass)
-            or self.alt != other.alt
-            or int(self.time) != int(other.time)
-        )
-
-    def __str__(self):
-        return f"[{self.trajectory.iloc[-1]['ts']:.2f} \
-            {self.pos} \
-            {self.trajectory.iloc[-1]['alt']:.2f} \
-            {self.trajectory.iloc[-1]['mass']:.2f}]"
-
-
-class H_Action(Enum):
-    """
-    Horizontal action that can be perform by the aircraft
-    """
-
-    up = -1
-    straight = 0
-    down = 1
-
-
-class V_Action(Enum):
-    """
-    Vertical action that can be perform by the aircraft
-    """
-
-    climb = 1
-    cruise = 0
-    descent = -1
-
-
-class D(DeterministicPlanningDomain, UnrestrictedActions, Renderable):
-    T_state = State  # Type of states
-    T_observation = State  # Type of observations
-    T_event = Action  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_predicate = bool  # Type of transition predicates (terminal states)
-    T_info = None  # Type of additional information in environment outcome
-    T_agent = Union  # Type of agent
-
-
-class FlightPlanningDomain(
-    DeterministicPlanningDomain, UnrestrictedActions, Renderable
-):
-    """Automated flight planning domain.
-
-    Domain definition
-    -----------------
-
-    The flight planning domain can be quickly defined as :
-
-    - An origin, as ICAO code of an airport,
-    - A destination, as ICAO code of an airport,
-    - An aircraft type, as a string recognizable by the OpenAP library.
-
-    Airways graph
-    -------------
-
-    A three-dimensional airway graph of waypoints is created. The graph is following the great circle
-    which represents the shortest pass between the origin and the destination.
-    The planner computes a plan by choosing waypoints in the graph, which are represented by 4-dimensionnal states.
-    There is 3 phases in the graph :
-
-    - The climbing phase
-    - The cruise phase
-    - The descent phase
-
-    The flight planning domain allows to choose a number of forward, lateral and vertical waypoints in the graph.
-    It is also possible to choose different width (tiny, small, normal, large, xlarge) which will increase
-    or decrease the graph width.
-
-    State representation
-    --------------------
-
-    Here, the states are represented by 4 features :
-
-    - The position in the graph (x,y,z)
-    - The aircraft mass, which can also represent the fuel consumption (integer)
-    - The altitude (integer)
-    - The time (seconds)
-
-    Wind interpolation
-    ------------------
-
-    The flight planning domain can take in consideration the wind conditions.
-    That interpolation have a major impact on the results, as jet streams are high altitude wind
-    which can increase or decrease the ground speed of the aircraft.
-    It also have an impact on the computation time of a flight plan,
-    as the objective and heuristic function became more complex.
-
-    Objective (or cost) functions
-    -----------------------------
-
-    There is three possible objective functions:
-
-    - Fuel (Default)
-    - Distance
-    - Time
-
-    The chosen objective will represent the cost to go from a state to another. The aim of the algorithm is to minimize the cost.
-
-    Heuristic functions
-    -------------------
-
-    When using an A* algorithm to compute the flight plan, we need to feed it with a heuristic function, which guide the algorithm.
-    For now, there is 5 different (not admissible) heuristic function, depending on `self.heuristic_name`:
-
-    - fuel, which computes the required fuel to get to the goal. It takes in consideration the local wind & speed of the aircraft.
-    - time, which computes the required time to get to the goal. It takes in consideration the local wind & speed of the aircraft.
-    - distance, wich computes the distance to the goal.
-    - lazy_fuel, which propagates the fuel consummed so far.
-    - lazy_time, which propagates the time spent on the flight so far
-    - None : we give a 0 cost value, which will transform the A* algorithm into a Dijkstra-like algorithm.
-
-    Optional features
-    -----------------
-
-    The flight planning domain has several optional features :
-
-    - Fuel loop: this is an optimisation of the loaded fuel for the aircraft.
-      It will run some flights to computes the loaded fuel, using distance objective & heuristic.
-
-    - Constraints definition: you can define constraints such as
-
-        - A time constraint, represented by a time windows
-        - A fuel constraint, represented by the maximum fuel for instance.
-
-    - Slopes: you can define your own climbing & descending slopes which have to be between 10.0 and 25.0.
-
-    """
-
-    T_state = State  # Type of states
-    T_observation = State  # Type of observations
-    T_event = Tuple[H_Action, V_Action]  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_predicate = bool  # Type of transition predicates (terminal states)
-    T_info = None  # Type of additional information in environment outcome
-    T_agent = Union  # Type of agent
-
-    def __init__(
-        self,
-        origin: Union[str, tuple],
-        destination: Union[str, tuple],
-        actype: str,
-        weather_date: WeatherDate = None,
-        wind_interpolator: GenericWindInterpolator = None,
-        objective: str = "fuel",
-        heuristic_name: str = "fuel",
-        constraints=None,
-        nb_forward_points: int = 41,
-        nb_lateral_points: int = 11,
-        nb_vertical_points: int = None,
-        fuel_loaded: float = None,
-        fuel_loop: bool = False,
-        fuel_loop_solver_factory: Optional[Callable[[], Solver]] = None,
-        fuel_loop_tol: float = 1e-3,
-        climbing_slope: float = None,
-        descending_slope: float = None,
-        graph_width: str = None,
-        res_img_dir: str = None,
-        starting_time: float = 3_600.0 * 8.0,
-    ):
-        """Initialisation of a flight planning instance
-
-        Args:
-            origin (Union[str, tuple]):
-                ICAO code of the airport, or a tuple (lat,lon,alt), of the origin of the flight plan. Altitude should be in ft
-            destination (Union[str, tuple]):
-                ICAO code of the airport, or a tuple (lat,lon,alt), of the destination of the flight plan. Altitude should be in ft
-            actype (str):
-                Aircarft type describe in openap datas (https://github.com/junzis/openap/tree/master/openap/data/aircraft)
-            weather_date (WeatherDate, optional):
-                Date for the weather, needed for days management.
-                If None, no wind will be applied.
-            wind_interpolator (GenericWindInterpolator, optional):
-                Wind interpolator for the flight plan. If None, create one from the specified weather_date.
-                The data is either already present locally or be downloaded from https://www.ncei.noaa.gov
-            objective (str, optional):
-                Cost function of the flight plan. It can be either fuel, distance or time. Defaults to "fuel".
-            heuristic_name (str, optional):
-                Heuristic of the flight plan, it will guide the aircraft through the graph. It can be either fuel, distance or time. Defaults to "fuel".
-            constraints (_type_, optional):
-                Constraints dictionnary (keyValues : ['time', 'fuel'] ) to be defined in for the flight plan. Defaults to None.
-            nb_points_forward (int, optional):
-                Number of forward nodes in the graph. Defaults to 41.
-            nb_points_lateral (int, optional):
-                Number of lateral nodes in the graph. Defaults to 11.
-            nb_points_vertical (int, optional):
-                Number of vertical nodes in the graph. Defaults to None.
-            fuel_loaded (float, optional):
-                Fuel loaded in the aricraft for the flight plan. Defaults to None.
-            fuel_loop (bool, optional):
-                Boolean to create a fuel loop to optimize the fuel loaded for the flight. Defaults to False
-            fuel_loop_solver_factory (solver factory, optional):
-                Solver factory used in the fuel loop. Defaults to LazyAstar.
-            climbing_slope (float, optional):
-                Climbing slope of the aircraft, has to be between 10.0 and 25.0. Defaults to None.
-            descending_slope (float, optional):
-                Descending slope of the aircraft, has to be between 10.0 and 25.0. Defaults to None.
-            graph_width (str, optional):
-                Airways graph width, in ["tiny", "small", "normal", "large", "xlarge"]. Defaults to None
-            res_img_dir (str, optional):
-                Directory in which images will be saved. Defaults to None
-            starting_time (float, optional):
-                Start time of the flight, in seconds. Defaults to 8AM (3_600.0 * 8.0)
-        """
-
-        # Initialisation of the origin and the destination
-        if isinstance(origin, str):  # Origin is an airport
-            ap1 = airport(origin)
-            self.lat1, self.lon1, self.alt1 = ap1["lat"], ap1["lon"], ap1["alt"]
-        else:  # Origin is geographic coordinates
-            self.lat1, self.lon1, self.alt1 = origin
-
-        if isinstance(destination, str):  # Destination is an airport
-            ap2 = airport(destination)
-            self.lat2, self.lon2, self.alt2 = ap2["lat"], ap2["lon"], ap2["alt"]
-        else:  # Destination is geographic coordinates
-            self.lat2, self.lon2, self.alt2 = destination
-
-        # We now set altitude in meters according to LatLon
-        self.alt1 *= ft
-        self.alt2 *= ft
-
-        self.start_time = starting_time
-        # Retrieve the aircraft datas in openap library and normalizing meters into ft
-        self.actype = actype
-        self.ac = aircraft(actype)
-
-        self.mach = self.ac["cruise"]["mach"]
-
-        # Initialisation of the objective & heuristic, the constraints and the wind interpolator
-        if heuristic_name in (
-            "distance",
-            "fuel",
-            "lazy_fuel",
-            "time",
-            "lazy_time",
-            None,
-        ):
-            self.heuristic_name = heuristic_name
-        else:
-            self.heuristic_name = "fuel"
-
-        if objective in ("distance", "fuel", "time"):
-            self.objective = objective
-        else:
-            self.objective = "fuel"
-        self.constraints = constraints
-
-        self.weather_date = weather_date
-        self.initial_date = weather_date
-        if wind_interpolator is None:
-            self.wind_interpolator = self.get_wind_interpolator()
-        else:
-            self.wind_interpolator = wind_interpolator
-
-        # Build network between airports
-        if graph_width:
-            all_graph_width = {
-                "tiny": 0.5,
-                "small": 0.75,
-                "normal": 1.0,
-                "large": 1.5,
-                "xlarge": 2.0,
-            }
-            graph_width = all_graph_width[graph_width]
-        else:
-            graph_width = 1.0
-
-        self.nb_forward_points = nb_forward_points
-        self.nb_lateral_points = nb_lateral_points
-
-        if nb_vertical_points:
-            self.nb_vertical_points = nb_vertical_points
-        else:
-            self.nb_vertical_points = (
-                int((self.ac["limits"]["ceiling"] - self.ac["cruise"]["height"]) / 1000)
-                + 1
-            )
-        self.network = self.set_network(
-            LatLon(self.lat1, self.lon1, self.alt1),
-            LatLon(self.lat2, self.lon2, self.alt2),
-            self.nb_forward_points,
-            self.nb_lateral_points,
-            self.nb_vertical_points,
-            descending_slope=descending_slope,
-            climbing_slope=climbing_slope,
-            graph_width=graph_width,
-        )
-
-        self.fuel_loaded = fuel_loaded
-
-        # Initialisation of the flight plan, with the initial state
-        if fuel_loop:
-            if fuel_loop_solver_factory is None:
-                LazyAstar = load_registered_solver("LazyAstar")
-                fuel_loop_solver_factory = lambda: LazyAstar(
-                    heuristic=lambda d, s: d.heuristic(s)
-                )
-            fuel_loaded = fuel_optimisation(
-                origin=origin,
-                destination=destination,
-                actype=self.actype,
-                constraints=constraints,
-                weather_date=weather_date,
-                solver_factory=fuel_loop_solver_factory,
-                fuel_tol=fuel_loop_tol,
-            )
-            # Adding fuel reserve (but we can't put more fuel than maxFuel)
-            fuel_loaded = min(1.1 * fuel_loaded, self.ac["limits"]["MFC"])
-        elif fuel_loaded:
-            self.constraints["fuel"] = (
-                0.97 * fuel_loaded
-            )  # Update of the maximum fuel there is to be used
-        else:
-            fuel_loaded = self.ac["limits"]["MFC"]
-
-        self.fuel_loaded = fuel_loaded
-
-        assert (
-            fuel_loaded <= self.ac["limits"]["MFC"]
-        )  # Ensure fuel loaded <= fuel capacity
-        self.start = State(
-            pd.DataFrame(
-                [
-                    {
-                        "ts": self.start_time,
-                        "lat": self.lat1,
-                        "lon": self.lon1,
-                        "mass": self.ac["limits"]["MTOW"]
-                        - 0.8
-                        * (
-                            self.ac["limits"]["MFC"] - self.fuel_loaded
-                        ),  # Here we compute the weight difference between the fuel loaded and the fuel capacity
-                        "mach": self.mach,
-                        "fuel": 0.0,
-                        "alt": self.alt1 / ft,
-                    }
-                ]
-            ),
-            (0, self.nb_lateral_points // 2, 0),
-        )
-        # Definition of the fuel consumption function
-        self.fuel_flow = FuelFlow(actype).enroute
-        self.res_img_dir = res_img_dir
-        self.cruising = self.alt1 >= self.ac["cruise"]["height"] * 0.98
-
-    # Class functions
-
-    def _get_next_state(self, memory: D.T_state, action: D.T_event) -> D.T_state:
-        """Compute the next state
-
-        Args:
-            memory (D.T_state): The current state
-            action (D.T_event): The action to perform
-
-        Returns:
-            D.T_state: The next state
-        """
-
-        trajectory = memory.trajectory.copy()
-
-        # Set intermediate destination point
-        next_x, next_y, next_z = memory.pos
-
-        next_x += 1
-
-        if action[0] == H_Action.up:
-            next_y += 1
-        if action[0] == H_Action.down:
-            next_y -= 1
-        if action[1] == V_Action.climb:
-            next_z += 1
-        if action[1] == V_Action.descent:
-            next_z -= 1
-
-        # Aircraft stays on the network
-        if (
-            next_x >= self.nb_forward_points
-            or next_y < 0
-            or next_y >= self.nb_lateral_points
-            or next_z < 0
-            or next_z >= self.nb_vertical_points
-        ):
-            return memory
-
-        # Concatenate the two trajectories
-
-        to_lat = self.network[next_x][next_y][next_z].lat
-        to_lon = self.network[next_x][next_y][next_z].lon
-        to_alt = (
-            self.network[next_x][next_y][next_z].height / ft
-        )  # We compute the flight with altitude in ft, whereas the altitude in the network is in meters according to LatLon
-
-        self.cruising = (
-            to_alt >= self.ac["cruise"]["height"] * 0.98
-        )  # Check if the plane will be cruising in the next state
-        trajectory = self.flying(trajectory.tail(1), (to_lat, to_lon, to_alt))
-
-        state = State(
-            pd.concat([memory.trajectory, trajectory], ignore_index=True),
-            (next_x, next_y, next_z),
-        )
-        return state
-
-    def _get_transition_value(
-        self,
-        memory: D.T_state,
-        action: D.T_event,
-        next_state: Optional[D.T_state] = None,
-    ) -> Value[D.T_value]:
-        """
-        Get the value (reward or cost) of a transition.
-        Set cost to distance travelled between points
-
-        Args:
-            memory (D.T_state): The current state
-            action (D.T_event): The action to perform
-            next_state (Optional[D.T_state], optional): The next state. Defaults to None.
-
-        Returns:
-            Value[D.T_value]: Cost to go from memory to next state
-        """
-        assert memory != next_state, "Next state is the same as the current state"
-        if self.objective == "distance":
-            cost = LatLon.distanceTo(
-                LatLon(
-                    memory.trajectory.iloc[-1]["lat"],
-                    memory.trajectory.iloc[-1]["lon"],
-                    memory.trajectory.iloc[-1]["alt"],
-                ),
-                LatLon(
-                    next_state.trajectory.iloc[-1]["lat"],
-                    next_state.trajectory.iloc[-1]["lon"],
-                    next_state.trajectory.iloc[-1]["alt"],
-                ),
-            )
-        elif self.objective == "time" or self.objective == "lazy_time":
-            cost = (
-                next_state.trajectory.iloc[-1]["ts"] - memory.trajectory.iloc[-1]["ts"]
-            )
-        else:
-            cost = (
-                memory.trajectory.iloc[-1]["mass"]
-                - next_state.trajectory.iloc[-1]["mass"]
-            )
-        return Value(cost=cost)
-
-    def _get_initial_state_(self) -> D.T_state:
-        """
-        Get the initial state.
-
-        Set the start position as initial state.
-        """
-        return self.start
-
-    def _get_goals_(self) -> Space[D.T_observation]:
-        """
-        Get the domain goals space (finite or infinite set).
-
-        Set the end position as goal.
-        """
-        return ImplicitSpace(lambda x: x.pos[0] == self.nb_forward_points - 1)
-
-    def _get_terminal_state_time_fuel(self, state: State) -> dict:
-        """
-        Get the domain terminal state information to compare with the constraints
-
-        Args:
-            state (State): terminal state to retrieve the information on fuel and time.
-
-        Returns:
-            dict: dictionnary containing both fuel and time information.
-        """
-        fuel = 0.0
-        for trajectory in state.trajectory.iloc:
-            fuel += trajectory["fuel"]
-
-        if (
-            state.trajectory.iloc[-1]["ts"] < self.start_time
-        ):  # The flight arrives the next day
-            time = 3_600 * 24 - self.start_time + state.trajectory.iloc[-1]["ts"]
-        else:
-            time = state.trajectory.iloc[-1]["ts"] - self.start_time
-
-        return {"time": time, "fuel": fuel}
-
-    def _is_terminal(self, state: State) -> D.T_predicate:
-        """
-        Indicate whether a state is terminal.
-
-        Stop an episode only when goal reached.
-        """
-        return state.pos[0] == self.nb_forward_points - 1
-
-    def _get_applicable_actions_from(self, memory: D.T_state) -> Space[D.T_event]:
-        """
-        Get the applicable actions from a state.
-        """
-        x, y, z = memory.pos
-
-        space = []
-        if x < self.nb_forward_points - 1:
-            space.append((H_Action.straight, V_Action.cruise))
-            if z < self.nb_vertical_points - 1 and self.cruising:
-                space.append((H_Action.straight, V_Action.climb))
-            if z > 0 and self.cruising:
-                space.append((H_Action.straight, V_Action.descent))
-            if y + 1 < self.nb_lateral_points:
-                space.append((H_Action.up, V_Action.cruise))
-                if z < self.nb_vertical_points - 1 and self.cruising:
-                    space.append((H_Action.up, V_Action.climb))
-                if z > 0 and self.cruising:
-                    space.append((H_Action.up, V_Action.descent))
-            if y > 0:
-                space.append((H_Action.down, V_Action.cruise))
-                if z < self.nb_vertical_points - 1 and self.cruising:
-                    space.append((H_Action.down, V_Action.climb))
-                if z > 0 and self.cruising:
-                    space.append((H_Action.down, V_Action.descent))
-
-        return ListSpace(space)
-
-    def _get_action_space_(self) -> Space[D.T_event]:
-        """
-        Define action space.
-        """
-        return EnumSpace((H_Action, V_Action))
-
-    def _get_observation_space_(self) -> Space[D.T_observation]:
-        """
-        Define observation space.
-        """
-        return MultiDiscreteSpace(
-            [self.nb_forward_points, self.nb_lateral_points, self.nb_vertical_points]
-        )
-
-    def _render_from(self, memory: State, **kwargs: Any) -> Any:
-        """
-        Render visually the map.
-
-        Returns:
-            matplotlib figure
-        """
-        return plot_trajectory(
-            self.lat1,
-            self.lon1,
-            self.lat2,
-            self.lon2,
-            memory.trajectory,
-        )
-
-    def heuristic(self, s: D.T_state, heuristic_name: str = None) -> Value[D.T_value]:
-        """
-        Heuristic to be used by search algorithms, depending on the objective and constraints.
-
-        Args:
-            s (D.T_state): Actual state
-            objective (str, optional): Objective function. Defaults to None.
-
-        Returns:
-            Value[D.T_value]: Heuristic value of the state.
-        """
-        if heuristic_name is None:
-            heuristic_name = self.heuristic_name
-
-        pos = s.trajectory.iloc[-1]
-
-        # Compute distance in meters
-        distance_to_goal = LatLon.distanceTo(
-            LatLon(pos["lat"], pos["lon"], height=pos["alt"]),
-            LatLon(self.lat2, self.lon2, height=self.alt2),
-        )
-        distance_to_start = LatLon.distanceTo(
-            LatLon(pos["lat"], pos["lon"], height=pos["alt"]),
-            LatLon(self.lat1, self.lon1, height=self.alt1),
-        )
-
-        if heuristic_name == "distance":
-            cost = distance_to_goal
-
-        elif heuristic_name == "fuel":
-
-            we, wn = 0, 0
-            bearing_degrees = aero_bearing(pos["lat"], pos["lon"], self.lat2, self.lon2)
-
-            if self.wind_interpolator:
-                time = pos["ts"]
-                wind_ms = self.wind_interpolator.interpol_wind_classic(
-                    lat=pos["lat"], longi=pos["lon"], alt=pos["alt"], t=time
-                )
-
-                we, wn = wind_ms[2][0], wind_ms[2][1]  # 0, 300
-            wspd = sqrt(wn * wn + we * we)
-
-            tas = mach2tas(pos["mach"], pos["alt"] * ft)
-
-            gs = compute_gspeed(
-                tas=tas,
-                true_course=radians(bearing_degrees),
-                wind_speed=wspd,
-                wind_direction=3 * math.pi / 2 - atan2(wn, we),
-            )
-
-            cost = ((distance_to_goal / gs)) * (
-                self.fuel_flow(pos["mass"], tas * kts, pos["alt"] * ft)
-            )
-
-        elif heuristic_name == "time":
-            we, wn = 0, 0
-            bearing_degrees = aero_bearing(pos["lat"], pos["lon"], self.lat2, self.lon2)
-
-            if self.wind_interpolator:
-                time = pos["ts"]
-                wind_ms = self.wind_interpolator.interpol_wind_classic(
-                    lat=pos["lat"], longi=pos["lon"], alt=pos["alt"], t=time
-                )
-
-                we, wn = wind_ms[2][0], wind_ms[2][1]  # 0, 300
-            wspd = sqrt(wn * wn + we * we)
-
-            tas = mach2tas(pos["mach"], pos["alt"] * ft)
-
-            gs = compute_gspeed(
-                tas=tas,
-                true_course=radians(bearing_degrees),
-                wind_speed=wspd,
-                wind_direction=3 * math.pi / 2 - atan2(wn, we),
-            )
-
-            cost = distance_to_goal / gs
-
-        elif heuristic_name == "lazy_fuel":
-            fuel_consummed = s.trajectory.iloc[0]["mass"] - pos["mass"]
-            cost = 1.05 * distance_to_goal * (fuel_consummed / distance_to_start)
-
-        elif heuristic_name == "lazy_time":
-            cost = (
-                1.5
-                * distance_to_goal
-                * ((pos["ts"] - s.trajectory.iloc[0]["ts"]) / distance_to_start)
-            )
-        else:
-            cost = 0
-        return Value(cost=cost)
-
-    def set_network(
-        self,
-        p0: LatLon,
-        p1: LatLon,
-        nb_forward_points: int,
-        nb_lateral_points: int,
-        nb_vertical_points: int,
-        climbing_slope: float = None,
-        descending_slope: float = None,
-        graph_width: float = None,
-    ):
-        """
-        Creation of the airway graph.
-
-        Args:
-            p0 : Origin of the flight plan
-            p1 : Destination of the flight plan
-            nb_forward_points (int): Number of forward points in the graph
-            nb_lateral_points (int): Number of lateral points in the graph
-            nb_vertical_points (int): Number of vertical points in the graph
-            climbing_slope (float, optional): Climbing slope of the plane during climbing phase. Defaults to None.
-            descending_slope (float, optional):  Descent slope of the plane during descent phase. Defaults to None.
-            graph_width (float, optional): Graph width of the graph. Defaults to None.
-
-        Returns:
-            A 3D matrix containing for each points its latitude, longitude, altitude between origin & destination.
-        """
-
-        cruise_alt_min = 31_000 * ft  # maybe useful to change this
-        half_forward_points = nb_forward_points // 2
-        half_lateral_points = nb_lateral_points // 2
-        half_vertical_points = nb_vertical_points // 2
-
-        distp = (
-            graph_width * p0.distanceTo(p1) * 0.022
-        )  # meters, around 2.2%*graphwidth of the p0 to p1 distance
-
-        descent_dist = min(
-            300_000
-            * (
-                max(self.ac["cruise"]["height"] - p1.height, 0)
-                / self.ac["cruise"]["height"]
-            ),
-            p0.distanceTo(p1),
-        )  # meters
-
-        climb_dist = 220_000 * (
-            max(self.ac["cruise"]["height"] - p0.height, 0)
-            / self.ac["cruise"]["height"]
-        )  # meters
-
-        total_distance = p0.distanceTo(p1)
-        if total_distance < (climb_dist + descent_dist):
-            climb_dist = total_distance * max(
-                (climb_dist / (climb_dist + descent_dist)) - 0.1, 0
-            )
-            descent_dist = total_distance * max(
-                descent_dist / (climb_dist + descent_dist) - 0.1, 0
-            )
-            possible_altitudes = [cruise_alt_min for k in range(nb_vertical_points)]
-
-        else:
-            possible_altitudes = [
-                (
-                    min(
-                        self.ac["cruise"]["height"]
-                        + 2000 * ft * i
-                        - (self.ac["cruise"]["height"] % 1000),
-                        self.ac["limits"]["ceiling"],
-                    )
-                )
-                for i in range(nb_vertical_points)
-            ]
-        if climbing_slope:
-            climbing_ratio = climbing_slope
-        else:
-            climbing_ratio = (
-                possible_altitudes[0] / climb_dist if climb_dist != 0 else 0
-            )
-        if descending_slope:
-            descending_ratio = descending_slope
-        else:
-            descending_ratio = (
-                possible_altitudes[0] / descent_dist if descent_dist != 0 else 0
-            )
-        # Initialisation of the graph matrix
-        pt = [
-            [
-                [None for k in range(len(possible_altitudes))]
-                for j in range(nb_lateral_points)
-            ]
-            for i in range(nb_forward_points)
-        ]
-
-        # set boundaries
-        for j in range(nb_lateral_points):
-            for k in range(nb_vertical_points):
-                pt[0][j][k] = p0
-                pt[nb_forward_points - 1][j][k] = p1
-
-        # set climb phase
-        i_initial = 1
-        if climbing_ratio != 0:
-            dist = 0
-            alt = p0.height
-            while dist < climb_dist and i_initial != nb_forward_points:
-
-                local_dist = (
-                    pt[i_initial - 1][half_lateral_points][
-                        half_vertical_points
-                    ].distanceTo(p1)
-                ) / (nb_forward_points - i_initial)
-                dist += local_dist
-                alt += int(local_dist * climbing_ratio)
-
-                for k in range(nb_vertical_points):
-                    bearing = pt[i_initial - 1][half_lateral_points][
-                        k
-                    ].initialBearingTo(p1)
-                    pt[i_initial][half_lateral_points][k] = pt[i_initial - 1][
-                        half_lateral_points
-                    ][k].destination(
-                        local_dist, bearing, min(possible_altitudes[0], alt)
-                    )
-                i_initial += 1
-
-        # set last step, descent
-        i_final = 1
-        if descending_ratio != 0:
-            dist = 0
-            alt = p1.height
-
-            while dist < descent_dist and i_final != nb_forward_points - 1:
-                local_dist = (
-                    pt[nb_forward_points - i_final][half_lateral_points][
-                        half_vertical_points
-                    ].distanceTo(p0)
-                ) / (nb_forward_points - i_final)
-                dist += local_dist
-                alt += int(local_dist * descending_ratio)
-
-                for k in range(nb_vertical_points):
-                    bearing = pt[nb_forward_points - i_final][half_lateral_points][
-                        k
-                    ].initialBearingTo(p0)
-                    pt[nb_forward_points - i_final - 1][half_lateral_points][k] = pt[
-                        nb_forward_points - i_final
-                    ][half_lateral_points][k].destination(
-                        local_dist, bearing, min(possible_altitudes[0], alt)
-                    )
-                i_final += 1
-
-        # direct path between end of climbing and beginning of descent
-        for k in range(nb_vertical_points):
-            for i in range(i_initial, nb_forward_points - i_final + 1):
-                bearing = pt[i - 1][half_lateral_points][k].initialBearingTo(p1)
-                total_distance = pt[i - 1][half_lateral_points][k].distanceTo(
-                    pt[nb_forward_points - 2][half_lateral_points][k]
-                )
-                pt[i][half_lateral_points][k] = pt[i - 1][half_lateral_points][
-                    k
-                ].destination(
-                    total_distance / (nb_forward_points - i),
-                    bearing,
-                    height=possible_altitudes[k],
-                )
-
-            bearing = pt[half_forward_points - 1][half_lateral_points][
-                k
-            ].initialBearingTo(pt[half_forward_points + 1][half_lateral_points][k])
-            pt[half_forward_points][nb_lateral_points - 1][k] = pt[half_forward_points][
-                half_lateral_points
-            ][k].destination(
-                distp * half_lateral_points,
-                bearing + 90,
-                height=pt[half_forward_points][half_lateral_points][k].height,
-            )
-            pt[half_forward_points][0][k] = pt[half_forward_points][
-                half_lateral_points
-            ][k].destination(
-                distp * half_lateral_points,
-                bearing - 90,
-                height=pt[half_forward_points][half_lateral_points][k].height,
-            )
-
-        for j in range(1, half_lateral_points + 1):
-            for k in range(len(possible_altitudes)):
-                # +j (left)
-                bearing = pt[half_forward_points][half_lateral_points + j - 1][
-                    k
-                ].initialBearingTo(pt[half_forward_points][nb_lateral_points - 1][k])
-                total_distance = pt[half_forward_points][half_lateral_points + j - 1][
-                    k
-                ].distanceTo(pt[half_forward_points][nb_lateral_points - 1][k])
-                pt[half_forward_points][half_lateral_points + j][k] = pt[
-                    half_forward_points
-                ][half_lateral_points + j - 1][k].destination(
-                    total_distance / (half_lateral_points - j + 1),
-                    bearing,
-                    height=pt[half_forward_points][half_lateral_points][k].height,
-                )
-                # -j (right)
-                bearing = pt[half_forward_points][half_lateral_points - j + 1][
-                    k
-                ].initialBearingTo(pt[half_forward_points][0][k])
-                total_distance = pt[half_forward_points][half_lateral_points - j + 1][
-                    k
-                ].distanceTo(pt[half_forward_points][0][k])
-                pt[half_forward_points][half_lateral_points - j][k] = pt[
-                    half_forward_points
-                ][half_lateral_points - j + 1][k].destination(
-                    total_distance / (half_lateral_points - j + 1),
-                    bearing,
-                    height=pt[half_forward_points][half_lateral_points][k].height,
-                )
-                for i in range(1, i_initial):
-                    alt = pt[i][half_lateral_points][k].height
-                    bearing = pt[i - 1][half_lateral_points + j][k].initialBearingTo(
-                        pt[half_forward_points][half_lateral_points + j][k]
-                    )
-                    total_distance = pt[i - 1][half_lateral_points + j][k].distanceTo(
-                        pt[half_forward_points][half_lateral_points + j][k]
-                    )
-                    pt[i][half_lateral_points + j][k] = pt[i - 1][
-                        half_lateral_points + j
-                    ][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=alt,
-                    )
-
-                    bearing = pt[i - 1][half_lateral_points - j][k].initialBearingTo(
-                        pt[half_forward_points][half_lateral_points - j][k]
-                    )
-                    total_distance = pt[i - 1][half_lateral_points - j][k].distanceTo(
-                        pt[half_forward_points][half_lateral_points - j][k]
-                    )
-                    pt[i][half_lateral_points - j][k] = pt[i - 1][
-                        half_lateral_points - j
-                    ][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=alt,
-                    )
-                for i in range(i_initial, half_forward_points):
-                    # first halp (p0 to np2)
-                    bearing = pt[i - 1][half_lateral_points + j][k].initialBearingTo(
-                        pt[half_forward_points][half_lateral_points + j][k]
-                    )
-                    total_distance = pt[i - 1][half_lateral_points + j][k].distanceTo(
-                        pt[half_forward_points][half_lateral_points + j][k]
-                    )
-                    pt[i][half_lateral_points + j][k] = pt[i - 1][
-                        half_lateral_points + j
-                    ][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=pt[i][half_lateral_points][k].height,
-                    )
-
-                    bearing = pt[i - 1][half_lateral_points - j][k].initialBearingTo(
-                        pt[half_forward_points][half_lateral_points - j][k]
-                    )
-                    total_distance = pt[i - 1][half_lateral_points - j][k].distanceTo(
-                        pt[half_forward_points][half_lateral_points - j][k]
-                    )
-                    pt[i][half_lateral_points - j][k] = pt[i - 1][
-                        half_lateral_points - j
-                    ][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=pt[i][half_lateral_points][k].height,
-                    )
-                for i in range(1, abs(half_forward_points - i_final)):
-                    # second half (np2 to p1)
-                    bearing = pt[half_forward_points + i - 1][half_lateral_points + j][
-                        k
-                    ].initialBearingTo(
-                        pt[nb_forward_points - 1][half_lateral_points + j][k]
-                    )
-                    total_distance = pt[half_forward_points + i - 1][
-                        half_lateral_points + j
-                    ][k].distanceTo(
-                        pt[nb_forward_points - 1][half_lateral_points + j][k]
-                    )
-                    pt[half_forward_points + i][half_lateral_points + j][k] = pt[
-                        half_forward_points + i - 1
-                    ][half_lateral_points + j][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=pt[half_forward_points + i][half_lateral_points][
-                            k
-                        ].height,
-                    )
-
-                    bearing = pt[half_forward_points + i - 1][half_lateral_points - j][
-                        k
-                    ].initialBearingTo(
-                        pt[nb_forward_points - 1][half_lateral_points - j][k]
-                    )
-                    total_distance = pt[half_forward_points + i - 1][
-                        half_lateral_points - j
-                    ][k].distanceTo(
-                        pt[nb_forward_points - 1][half_lateral_points - j][k]
-                    )
-                    pt[half_forward_points + i][half_lateral_points - j][k] = pt[
-                        half_forward_points + i - 1
-                    ][half_lateral_points - j][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=pt[half_forward_points + i][half_lateral_points][
-                            k
-                        ].height,
-                    )
-                for i in range(abs(half_forward_points - i_final), half_forward_points):
-                    alt = pt[half_forward_points + i - 1][half_lateral_points][k].height
-                    bearing = pt[half_forward_points + i - 1][half_lateral_points + j][
-                        k
-                    ].initialBearingTo(
-                        pt[nb_forward_points - 1][half_lateral_points + j][k]
-                    )
-                    total_distance = pt[half_forward_points + i - 1][
-                        half_lateral_points + j
-                    ][k].distanceTo(
-                        pt[nb_forward_points - 1][half_lateral_points + j][k]
-                    )
-                    pt[half_forward_points + i][half_lateral_points + j][k] = pt[
-                        half_forward_points + i - 1
-                    ][half_lateral_points + j][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=alt,
-                    )
-
-                    bearing = pt[half_forward_points + i - 1][half_lateral_points - j][
-                        k
-                    ].initialBearingTo(
-                        pt[nb_forward_points - 1][half_lateral_points - j][k]
-                    )
-                    total_distance = pt[half_forward_points + i - 1][
-                        half_lateral_points - j
-                    ][k].distanceTo(
-                        pt[nb_forward_points - 1][half_lateral_points - j][k]
-                    )
-                    pt[half_forward_points + i][half_lateral_points - j][k] = pt[
-                        half_forward_points + i - 1
-                    ][half_lateral_points - j][k].destination(
-                        total_distance / (half_forward_points - i + 1),
-                        bearing,
-                        height=alt,
-                    )
-
-        return pt
-
-    def get_network(self):
-        return self.network
-
-    def flying(
-        self, from_: pd.DataFrame, to_: Tuple[float, float, int]
-    ) -> pd.DataFrame:
-        """Compute the trajectory of a flying object from a given point to a given point
-
-        Args:
-            from_ (pd.DataFrame): the trajectory of the object so far
-            to_ (Tuple[float, float]): the destination of the object
-
-        Returns:
-            pd.DataFrame: the final trajectory of the object
-        """
-        pos = from_.to_dict("records")[0]
-        alt = to_[2]
-        dist_ = distance(pos["lat"], pos["lon"], to_[0], to_[1], alt)
-        data = []
-        epsilon = 100
-        dt = 600
-        dist = dist_
-        loop = 0
-        while dist > epsilon:
-            bearing_degrees = aero_bearing(pos["lat"], pos["lon"], to_[0], to_[1])
-
-            def heading(position, destination):
-                theta = np.arctan2(
-                    np.sin(np.pi / 180.0 * (destination[1] - position[1]))
-                    * np.cos(np.pi / 180.0 * destination[0]),
-                    np.cos(np.pi / 180.0 * position[0])
-                    * np.sin(np.pi / 180.0 * destination[0])
-                    - np.sin(np.pi / 180.0 * position[0])
-                    * np.cos(np.pi / 180.0 * destination[0])
-                    * np.cos(np.pi / 180.0 * (destination[1] - position[1])),
-                )
-                return theta
-
-            p, _, _ = atmos(alt * ft)
-            isobaric = p / 100
-            we, wn = 0, 0
-            if self.wind_interpolator:
-                time = pos["ts"] % (3_600 * 24)
-                wind_ms = self.wind_interpolator.interpol_wind_classic(
-                    lat=pos["lat"], longi=pos["lon"], alt=alt, t=time
-                )
-                we, wn = wind_ms[2][0], wind_ms[2][1]
-
-            wspd = sqrt(wn * wn + we * we)
-            tas = mach2tas(self.mach, alt * ft)
-            gs = compute_gspeed(
-                tas=tas,
-                true_course=radians(bearing_degrees),
-                wind_speed=wspd,
-                wind_direction=3 * math.pi / 2 - atan2(wn, we),
-            )
-
-            if gs * dt > dist:
-                # Last step. make sure we go to destination.
-                dt = dist / gs
-                ll = to_[0], to_[1]
-            else:
-                ll = latlon(
-                    pos["lat"], pos["lon"], d=gs * dt, brg=bearing_degrees, h=alt * ft
-                )
-
-            pos["fuel"] = dt * self.fuel_flow(
-                pos["mass"],
-                tas / kts,
-                alt * ft,
-                path_angle=(alt - pos["alt"]) / (gs * dt),
-            )
-            mass = pos["mass"] - pos["fuel"]
-
-            if pos["ts"] + dt >= (3_600.0 * 24.0):
-                if self.weather_date:
-                    if self.weather_date == self.initial_date:
-                        self.weather_date = self.weather_date.next_day()
-                        self.wind_interpolator = self.get_wind_interpolator()
-            else:
-                if self.weather_date != self.initial_date:
-                    self.weather_date = self.weather_date.previous_day()
-                    self.wind_interpolator = self.get_wind_interpolator()
-
-            new_row = {
-                "ts": pos["ts"] + dt,
-                "lat": ll[0],
-                "lon": ll[1],
-                "mass": mass,
-                "mach": self.mach,
-                "fuel": pos["fuel"],
-                "alt": alt,  # to be modified
-            }
-
-            # New distance to the next 'checkpoint'
-            dist = distance(
-                new_row["lat"], new_row["lon"], to_[0], to_[1], new_row["alt"]
-            )
-
-            if dist < dist_:
-                data.append(new_row)
-                dist_ = dist
-                pos = data[-1]
-            else:
-                dt = int(dt / 10)
-                print("going in the wrong part.")
-                assert dt > 0
-
-            loop += 1
-
-        return pd.DataFrame(data)
-
-    def get_wind_interpolator(self) -> GenericWindInterpolator:
-        wind_interpolator = None
-        if self.weather_date:
-            w_dict = self.weather_date.to_dict()
-            mat = get_weather_matrix(
-                year=w_dict["year"],
-                month=w_dict["month"],
-                day=w_dict["day"],
-                forecast=w_dict["forecast"],
-                delete_npz_from_local=False,
-                delete_grib_from_local=False,
-            )
-            wind_interpolator = GenericWindInterpolator(file_npz=mat)
-        return wind_interpolator
-
-    def custom_rollout(self, solver, max_steps=100, make_img=True):
-        observation = self.reset()
-
-        solver.reset()
-        clear_output(wait=True)
-
-        # loop until max_steps or goal is reached
-        for i_step in range(1, max_steps + 1):
-
-            # choose action according to solver
-            action = solver.sample_action(observation)
-
-            # get corresponding action
-            outcome = self.step(action)
-            observation = outcome.observation
-
-            print("step ", i_step)
-            print("policy = ", action[0], action[1])
-            print("New state = ", observation.pos)
-            print("Alt = ", observation.alt)
-            print("Mach = ", observation.trajectory.iloc[-1]["mach"])
-            print(observation)
-
-            if make_img:
-                # update image
-                plt.clf()  # clear figure
-                clear_output(wait=True)
-                figure = self.render(observation)
-                # plt.savefig(f'step_{i_step}')
-
-            # final state reached?
-            if self.is_terminal(observation):
-                break
-        if make_img:
-            plt.savefig(f"terminal")
-            plt.clf()
-            clear_output(wait=True)
-            figure = plot_altitude(observation.trajectory)
-            plt.savefig("altitude")
-            plot_network(self)
-        # goal reached?
-        is_goal_reached = self.is_goal(observation)
-
-        terminal_state_constraints = self._get_terminal_state_time_fuel(observation)
-        if is_goal_reached:
-            if self.constraints is not None:
-                if self.constraints["time"] is not None:
-                    if (
-                        self.constraints["time"][1]
-                        >= terminal_state_constraints["time"]
-                    ):
-                        if (
-                            self.constraints["fuel"]
-                            >= terminal_state_constraints["fuel"]
-                        ):
-                            print(f"Goal reached after {i_step} steps!")
-                        else:
-                            print(
-                                f"Goal reached after {i_step} steps, but there is not enough fuel remaining!"
-                            )
-                    else:
-                        print(
-                            f"Goal reached after {i_step} steps, but not in the good timelapse!"
-                        )
-                else:
-                    if self.constraints["fuel"] >= terminal_state_constraints["fuel"]:
-                        print(f"Goal reached after {i_step} steps!")
-                    else:
-                        print(
-                            f"Goal reached after {i_step} steps, but there is not enough fuel remaining!"
-                        )
-            else:
-                if self.ac["limits"]["MFC"] >= terminal_state_constraints["fuel"]:
-                    print(f"Goal reached after {i_step} steps!")
-                else:
-                    print(
-                        f"Goal reached after {i_step} steps, but there is not enough fuel remaining!"
-                    )
-        else:
-            print(f"Goal not reached after {i_step} steps!")
-
-        return terminal_state_constraints, self.constraints
-
-
-def compute_gspeed(
-    tas: float, true_course: float, wind_speed: float, wind_direction: float
-):
-    # Tas : speed in m/s
-    # course : current bearing
-    # wind speed, wind norm in m/s
-    # wind_direction : (3pi/2-arctan(north_component/east_component)) in radian
-    ws = wind_speed
-    wd = wind_direction
-    tc = true_course
-
-    # calculate wind correction angle wca and ground speed gs
-    swc = ws / tas * sin(wd - tc)
-    if abs(swc) >= 1.0:
-        # Wind is to strong
-        gs = tas
-        error = "Wind is too strong"
-    else:
-        wca = asin(swc)  # * 180.0 / pi)
-        gs = tas * sqrt(1 - swc * swc) - ws * cos(wd - tc)
-
-    if gs < 0:
-        # Wind is to strong
-        gs = tas
-        error = "Wind is too strong"
-    else:
-        # Reset possible status message
-        error = ""
-    return gs
-
-
-def fuel_optimisation(
-    origin: Union[str, tuple],
-    destination: Union[str, tuple],
-    actype: str,
-    constraints: dict,
-    weather_date: WeatherDate,
-    solver_factory: Callable[[], Solver],
-    max_steps: int = 100,
-    fuel_tol: float = 1e-3,
-) -> float:
-    """
-    Function to optimise the fuel loaded in the plane, doing multiple fuel loops to approach an optimal
-
-    Args:
-        origin (Union[str, tuple]):
-            ICAO code of the departure airport of th flight plan e.g LFPG for Paris-CDG, or a tuple (lat,lon)
-
-        destination (Union[str, tuple]):
-            ICAO code of the arrival airport of th flight plan e.g LFBO for Toulouse-Blagnac airport, or a tuple (lat,lon)
-
-        actype (str):
-            Aircarft type describe in openap datas (https://github.com/junzis/openap/tree/master/openap/data/aircraft)
-
-        constraints (dict):
-            Constraints that will be defined for the flight plan
-
-        wind_interpolator (GenericWindInterpolator):
-            Define the wind interpolator to use wind informations for the flight plan
-
-        fuel_loaded (float):
-            Fuel loaded in the plane for the flight
-
-        solver_factory:
-            Solver factory used in the fuel loop
-
-        max_steps (int):
-            max steps to use in the internal fuel loop
-
-        fuel_tol (float):
-            tolerance on fuel used to stop the optimization
-
-    Returns:
-        float:
-            Return the quantity of fuel to be loaded in the plane for the flight
-    """
-
-    small_diff = False
-    step = 0
-    new_fuel = constraints["fuel"]
-    while not small_diff:
-        domain_factory = lambda: FlightPlanningDomain(
-            origin=origin,
-            destination=destination,
-            actype=actype,
-            constraints=constraints,
-            weather_date=weather_date,
-            objective="distance",
-            heuristic_name="distance",
-            nb_forward_points=41,
-            nb_lateral_points=11,
-            fuel_loaded=new_fuel,
-            starting_time=0.0,
-        )
-
-        fuel_prec = new_fuel
-        new_fuel = simple_fuel_loop(
-            solver_factory=solver_factory,
-            domain_factory=domain_factory,
-            max_steps=max_steps,
-        )
-        step += 1
-        small_diff = (fuel_prec - new_fuel) <= fuel_tol
-
-    return new_fuel
-
-
-def simple_fuel_loop(solver_factory, domain_factory, max_steps: int = 100) -> float:
-    domain = domain_factory()
-    with solver_factory() as solver:
-        domain.solve_with(solver, domain_factory)
-        observation: State = domain.reset()
-        solver.reset()
-
-        # loop until max_steps or goal is reached
-        for i_step in range(1, max_steps + 1):
-
-            # choose action according to solver
-            action = solver.sample_action(observation)
-
-            # get corresponding action
-            outcome = domain.step(action)
-            observation = outcome.observation
-
-            if domain.is_terminal(observation):
-                break
-
-        # Retrieve fuel for the flight
-        fuel = domain._get_terminal_state_time_fuel(observation)["fuel"]
-
-    return fuel
+import math
+from argparse import Action
+from enum import Enum
+
+# data and math
+from math import asin, atan2, cos, radians, sin, sqrt
+
+# typing
+from typing import Any, Callable, Dict, Optional, Tuple, Type, Union
+
+# plotting
+import matplotlib.pyplot as plt
+import numpy as np
+import pandas as pd
+
+# aircraft performance model
+from openap.extra.aero import bearing as aero_bearing
+from openap.extra.aero import distance, ft, kts, latlon, mach2tas
+from openap.extra.nav import airport
+from openap.prop import aircraft
+from pygeodesy.ellipsoidalVincenty import LatLon
+
+from skdecide import DeterministicPlanningDomain, ImplicitSpace, Solver, Space, Value
+from skdecide.builders.domain import Renderable, UnrestrictedActions
+
+# custom aircraft performance model
+from skdecide.hub.domain.flight_planning.aircraft_performance.base import (
+    AircraftPerformanceModel,
+)
+from skdecide.hub.domain.flight_planning.aircraft_performance.poll_schumann_utils.engine_loader import (
+    load_aircraft_engine_params,
+)
+from skdecide.hub.domain.flight_planning.flightplanning_utils import (
+    plot_full,
+    plot_trajectory,
+)
+from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.get_weather_noaa import (
+    get_weather_matrix,
+)
+from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.GenericInterpolator import (
+    GenericWindInterpolator,
+)
+from skdecide.hub.space.gym import EnumSpace, ListSpace, MultiDiscreteSpace
+from skdecide.utils import load_registered_solver
+
+try:
+    from IPython.display import clear_output as ipython_clear_output
+except ImportError:
+    ipython_available = False
+else:
+    ipython_available = True
+
+
+def clear_output(wait=True):
+    if ipython_available:
+        ipython_clear_output(wait=wait)
+
+
+class WeatherDate:
+    day: int
+    month: int
+    year: int
+    forecast: str
+    leapyear: bool
+
+    def __init__(self, day, month, year, forecast="nowcast") -> None:
+        self.day = int(day)
+        self.month = int(month)
+        self.year = int(year)
+        self.forecast = forecast
+        self.leapyear = self.year % 400 == 0 or (
+            self.year % 100 != 0 and self.year % 4 == 0
+        )
+
+    def __hash__(self) -> int:
+        return hash((self.day, self.month, self.year, self.forecast))
+
+    def __eq__(self, other: object) -> bool:
+        return (
+            self.day == other.day
+            and self.month == other.month
+            and self.year == other.year
+            and self.forecast == other.forecast
+        )
+
+    def __ne__(self, other: object) -> bool:
+        return (
+            self.day != other.day
+            or self.month != other.month
+            or self.year != other.year
+            or self.forecast != other.forecast
+        )
+
+    def __str__(self) -> str:
+        day = str(self.day)
+        month = str(self.month)
+
+        if len(day) == 1:
+            day = "0" + day
+        if len(month) == 1:
+            month = "0" + month
+
+        return f"[{day} {month} {self.year}, forecast : {self.forecast}]"
+
+    def to_dict(self) -> dict:
+        day = str(self.day)
+        month = str(self.month)
+
+        if len(day) == 1:
+            day = "0" + day
+        if len(month) == 1:
+            month = "0" + month
+
+        return {
+            "year": str(self.year),
+            "month": str(month),
+            "day": str(day),
+            "forecast": self.forecast,
+        }
+
+    def next_day(self):
+        day = self.day
+        month = self.month
+        year = self.year
+        if month == 12 and day == 31:
+            year += 1
+            month = 1
+            day = 1
+
+        elif month in (1, 3, 5, 7, 8, 10) and day == 31:
+            day = 1
+            month += 1
+
+        elif month in (4, 6, 9, 11) and day == 30:
+            day = 1
+            month += 1
+
+        elif month == 2:
+            if (self.leap_year and day == 29) or (not (self.leap_year) and day == 28):
+                day = 1
+                month = 3
+            else:
+                day += 1
+
+        else:
+            day += 1
+
+        return WeatherDate(day, month, year, forecast=self.forecast)
+
+    def previous_day(self):
+        day = self.day
+        month = self.month
+        year = self.year
+        if month == 1 and day == 1:
+            year -= 1
+            month = 12
+            day = 31
+
+        elif month in (5, 7, 10, 12) and day == 1:
+            day = 30
+            month -= 1
+
+        elif month in (2, 4, 6, 8, 9, 11) and day == 1:
+            day = 31
+            month -= 1
+
+        elif month == 3 and day == 1:
+            if self.leap_year:
+                day = 29
+                month = 2
+            else:
+                day = 28
+                month = 2
+
+        else:
+            day -= 1
+
+        return WeatherDate(day, month, year, forecast=self.forecast)
+
+
+class State:
+    """
+    Definition of a aircraft state during the flight plan
+    """
+
+    trajectory: pd.DataFrame
+    pos: Tuple[int, int, int]
+
+    def __init__(self, trajectory, pos):
+        """Initialisation of a state
+
+        # Parameters
+            trajectory : Trajectory information of the flight
+            pos : Current position in the airways graph
+        """
+        self.trajectory = trajectory
+        self.pos = pos
+        if trajectory is not None:
+            self.mass = trajectory.iloc[-1]["mass"]
+            self.alt = trajectory.iloc[-1]["alt"]
+            self.time = trajectory.iloc[-1]["ts"]
+        else:
+            self.mass = None
+            self.alt = None
+            self.time = None
+
+    def __hash__(self):
+        # print(self.pos, self.mass, self.alt, self.time)
+        return hash((self.pos, int(self.mass), self.alt, int(self.time)))
+
+    def __eq__(self, other):
+        return (
+            self.pos == other.pos
+            and int(self.mass) == int(other.mass)
+            and self.alt == other.alt
+            and int(self.time) == int(other.time)
+        )
+
+    def __ne__(self, other):
+        return (
+            self.pos != other.pos
+            or int(self.mass) != int(other.mass)
+            or self.alt != other.alt
+            or int(self.time) != int(other.time)
+        )
+
+    def __str__(self):
+        return f"[{self.trajectory.iloc[-1]['ts']:.2f} \
+            {self.pos} \
+            {self.trajectory.iloc[-1]['alt']:.2f} \
+            {self.trajectory.iloc[-1]['mass']:.2f}]"
+
+
+class H_Action(Enum):
+    """
+    Horizontal action that can be perform by the aircraft
+    """
+
+    up = -1
+    straight = 0
+    down = 1
+
+
+class V_Action(Enum):
+    """
+    Vertical action that can be perform by the aircraft
+    """
+
+    climb = 1
+    cruise = 0
+    descent = -1
+
+
+class D(DeterministicPlanningDomain, UnrestrictedActions, Renderable):
+    T_state = State  # Type of states
+    T_observation = State  # Type of observations
+    T_event = Action  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_predicate = bool  # Type of transition predicates (terminal states)
+    T_info = None  # Type of additional information in environment outcome
+    T_agent = Union  # Type of agent
+
+
+class FlightPlanningDomain(
+    DeterministicPlanningDomain, UnrestrictedActions, Renderable
+):
+    """Automated flight planning domain.
+
+    Domain definition
+    -----------------
+
+    The flight planning domain can be quickly defined as :
+
+    - An origin, as ICAO code of an airport,
+    - A destination, as ICAO code of an airport,
+    - An aircraft type, as a string recognizable by the OpenAP library.
+
+    Airways graph
+    -------------
+
+    A three-dimensional airway graph of waypoints is created. The graph is following the great circle
+    which represents the shortest pass between the origin and the destination.
+    The planner computes a plan by choosing waypoints in the graph, which are represented by 4-dimensionnal states.
+    There is 3 phases in the graph :
+
+    - The climbing phase
+    - The cruise phase
+    - The descent phase
+
+    The flight planning domain allows to choose a number of forward, lateral and vertical waypoints in the graph.
+    It is also possible to choose different width (tiny, small, normal, large, xlarge) which will increase
+    or decrease the graph width.
+
+    State representation
+    --------------------
+
+    Here, the states are represented by 4 features :
+
+    - The position in the graph (x,y,z)
+    - The aircraft mass, which can also represent the fuel consumption (integer)
+    - The altitude (integer)
+    - The time (seconds)
+
+    Wind interpolation
+    ------------------
+
+    The flight planning domain can take in consideration the wind conditions.
+    That interpolation have a major impact on the results, as jet streams are high altitude wind
+    which can increase or decrease the ground speed of the aircraft.
+    It also have an impact on the computation time of a flight plan,
+    as the objective and heuristic function became more complex.
+
+    Objective (or cost) functions
+    -----------------------------
+
+    There is three possible objective functions:
+
+    - Fuel (Default)
+    - Distance
+    - Time
+
+    The chosen objective will represent the cost to go from a state to another. The aim of the algorithm is to minimize the cost.
+
+    Heuristic functions
+    -------------------
+
+    When using an A* algorithm to compute the flight plan, we need to feed it with a heuristic function, which guide the algorithm.
+    For now, there is 5 different (not admissible) heuristic function, depending on `self.heuristic_name`:
+
+    - fuel, which computes the required fuel to get to the goal. It takes in consideration the local wind & speed of the aircraft.
+    - time, which computes the required time to get to the goal. It takes in consideration the local wind & speed of the aircraft.
+    - distance, wich computes the distance to the goal.
+    - lazy_fuel, which propagates the fuel consummed so far.
+    - lazy_time, which propagates the time spent on the flight so far
+    - None : we give a 0 cost value, which will transform the A* algorithm into a Dijkstra-like algorithm.
+
+    Aircraft performance models
+    --------------------------
+
+    The flight planning domain can use two possible A/C performance models:
+
+    - OpenAP: the aircraft performance model is based on the OpenAP library.
+    - Poll-Schumann: the aircraft performance model is based on Poll-Schumann equations as stated on the paper: "An estimation
+    method for the fuel burn and other performance characteristics of civil transport aircraft in the cruise" by Poll and Schumann;
+    The Aernautical Journal, 2020.
+
+    Optional features
+    -----------------
+
+    The flight planning domain has several optional features :
+
+    - Fuel loop: this is an optimisation of the loaded fuel for the aircraft.
+      It will run some flights to computes the loaded fuel, using distance objective & heuristic.
+
+    - Constraints definition: you can define constraints such as
+
+        - A time constraint, represented by a time windows
+        - A fuel constraint, represented by the maximum fuel for instance.
+
+    - Slopes: you can define your own climbing & descending slopes which have to be between 10.0 and 25.0.
+
+    """
+
+    T_state = State  # Type of states
+    T_observation = State  # Type of observations
+    T_event = Tuple[H_Action, V_Action]  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_predicate = bool  # Type of transition predicates (terminal states)
+    T_info = None  # Type of additional information in environment outcome
+    T_agent = Union  # Type of agent
+
+    def __init__(
+        self,
+        origin: Union[str, tuple],
+        destination: Union[str, tuple],
+        actype: str,
+        weather_date: WeatherDate = None,
+        wind_interpolator: GenericWindInterpolator = None,
+        objective: str = "fuel",
+        heuristic_name: str = "fuel",
+        perf_model_name: str = "openap",
+        constraints=None,
+        nb_forward_points: int = 41,
+        nb_lateral_points: int = 11,
+        nb_vertical_points: int = None,
+        take_off_weight: int = None,
+        fuel_loaded: float = None,
+        fuel_loop: bool = False,
+        fuel_loop_solver_cls: Optional[Type[Solver]] = None,
+        fuel_loop_solver_kwargs: Optional[Dict[str, Any]] = None,
+        fuel_loop_tol: float = 1e-3,
+        climbing_slope: float = None,
+        descending_slope: float = None,
+        graph_width: str = None,
+        res_img_dir: str = None,
+        starting_time: float = 3_600.0 * 8.0,
+    ):
+        """Initialisation of a flight planning instance
+
+        # Parameters
+            origin (Union[str, tuple]):
+                ICAO code of the airport, or a tuple (lat,lon,alt), of the origin of the flight plan. Altitude should be in ft
+            destination (Union[str, tuple]):
+                ICAO code of the airport, or a tuple (lat,lon,alt), of the destination of the flight plan. Altitude should be in ft
+            actype (str):
+                Aircarft type describe in openap datas (https://github.com/junzis/openap/tree/master/openap/data/aircraft)
+            weather_date (WeatherDate, optional):
+                Date for the weather, needed for days management.
+                If None, no wind will be applied.
+            wind_interpolator (GenericWindInterpolator, optional):
+                Wind interpolator for the flight plan. If None, create one from the specified weather_date.
+                The data is either already present locally or be downloaded from https://www.ncei.noaa.gov
+            objective (str, optional):
+                Cost function of the flight plan. It can be either fuel, distance or time. Defaults to "fuel".
+            heuristic_name (str, optional):
+                Heuristic of the flight plan, it will guide the aircraft through the graph. It can be either fuel, distance or time. Defaults to "fuel".
+            perf_model_name (str, optional):
+                Aircraft performance model used in the flight plan. It can be either openap or PS (Poll-Schumann). Defaults to "openap".
+            constraints (_type_, optional):
+                Constraints dictionnary (keyValues : ['time', 'fuel'] ) to be defined in for the flight plan. Defaults to None.
+            nb_points_forward (int, optional):
+                Number of forward nodes in the graph. Defaults to 41.
+            nb_points_lateral (int, optional):
+                Number of lateral nodes in the graph. Defaults to 11.
+            nb_points_vertical (int, optional):
+                Number of vertical nodes in the graph. Defaults to None.
+            take_off_weight (int, optional):
+                Take off weight of the aircraft. Defaults to None.
+            fuel_loaded (float, optional):
+                Fuel loaded in the aricraft for the flight plan. Defaults to None.
+            fuel_loop (bool, optional):
+                Boolean to create a fuel loop to optimize the fuel loaded for the flight. Defaults to False
+            fuel_loop_solver_cls (type[Solver], optional):
+                Solver class used in the fuel loop. Defaults to LazyAstar.
+            fuel_loop_solver_kwargs (Dict[str, Any], optional):
+                Kwargs to initialize the solver used in the fuel loop.
+            climbing_slope (float, optional):
+                Climbing slope of the aircraft, has to be between 10.0 and 25.0. Defaults to None.
+            descending_slope (float, optional):
+                Descending slope of the aircraft, has to be between 10.0 and 25.0. Defaults to None.
+            graph_width (str, optional):
+                Airways graph width, in ["tiny", "small", "normal", "large", "xlarge"]. Defaults to None
+            res_img_dir (str, optional):
+                Directory in which images will be saved. Defaults to None
+            starting_time (float, optional):
+                Start time of the flight, in seconds. Defaults to 8AM (3_600.0 * 8.0)
+        """
+
+        # Initialisation of the origin and the destination
+        self.origin, self.destination = origin, destination
+        if isinstance(origin, str):  # Origin is an airport
+            ap1 = airport(origin)
+            self.lat1, self.lon1, self.alt1 = ap1["lat"], ap1["lon"], ap1["alt"]
+        else:  # Origin is geographic coordinates
+            self.lat1, self.lon1, self.alt1 = origin
+
+        if isinstance(destination, str):  # Destination is an airport
+            ap2 = airport(destination)
+            self.lat2, self.lon2, self.alt2 = ap2["lat"], ap2["lon"], ap2["alt"]
+        else:  # Destination is geographic coordinates
+            self.lat2, self.lon2, self.alt2 = destination
+
+        self.start_time = starting_time
+        # Retrieve the aircraft datas in openap library
+        self.actype = actype
+        self.ac = aircraft(actype)
+
+        self.mach = self.ac["cruise"]["mach"]
+
+        # Initialisation of the objective & heuristic, the constraints and the wind interpolator
+        if heuristic_name in (
+            "distance",
+            "fuel",
+            "lazy_fuel",
+            "time",
+            "lazy_time",
+            None,
+        ):
+            self.heuristic_name = heuristic_name
+        else:
+            self.heuristic_name = "fuel"
+
+        if objective in ("distance", "fuel", "time"):
+            self.objective = objective
+        else:
+            self.objective = "fuel"
+        self.constraints = constraints
+
+        self.weather_date = weather_date
+        self.initial_date = weather_date
+
+        if wind_interpolator is None:
+            self.weather_interpolator = self.get_weather_interpolator()
+
+        # Build network between airports
+        if graph_width:
+            all_graph_width = {
+                "tiny": 0.5,
+                "small": 0.75,
+                "normal": 1.0,
+                "large": 1.5,
+                "xlarge": 2.0,
+            }
+            graph_width = all_graph_width[graph_width]
+        else:
+            graph_width = 1.0
+
+        self.nb_forward_points = nb_forward_points
+        self.nb_lateral_points = nb_lateral_points
+
+        if nb_vertical_points:
+            self.nb_vertical_points = nb_vertical_points
+        else:
+            self.nb_vertical_points = (
+                int((self.ac["limits"]["ceiling"] - self.ac["cruise"]["height"]) / 1000)
+                + 1
+            )
+        self.network = self.set_network(
+            LatLon(self.lat1, self.lon1, self.alt1 * ft),  # alt ft -> meters
+            LatLon(self.lat2, self.lon2, self.alt2 * ft),  # alt ft -> meters
+            self.nb_forward_points,
+            self.nb_lateral_points,
+            self.nb_vertical_points,
+            descending_slope=descending_slope,
+            climbing_slope=climbing_slope,
+            graph_width=graph_width,
+        )
+
+        self.fuel_loaded = fuel_loaded
+
+        # Initialisation of the flight plan, with the initial state
+        if fuel_loop:
+            if fuel_loop_solver_cls is None:
+                LazyAstar = load_registered_solver("LazyAstar")
+                fuel_loop_solver_cls = LazyAstar
+                fuel_loop_solver_kwargs = dict(heuristic=lambda d, s: d.heuristic(s))
+            elif fuel_loop_solver_kwargs is None:
+                fuel_loop_solver_kwargs = {}
+            fuel_loaded = fuel_optimisation(
+                origin=origin,
+                destination=destination,
+                actype=self.actype,
+                constraints=constraints,
+                weather_date=weather_date,
+                solver_cls=fuel_loop_solver_cls,
+                solver_kwargs=fuel_loop_solver_kwargs,
+                fuel_tol=fuel_loop_tol,
+            )
+            # Adding fuel reserve (but we can't put more fuel than maxFuel)
+            fuel_loaded = min(1.1 * fuel_loaded, self.ac["limits"]["MFC"])
+        elif fuel_loaded:
+            self.constraints["fuel"] = (
+                0.97 * fuel_loaded
+            )  # Update of the maximum fuel there is to be used
+        else:
+            fuel_loaded = self.ac["limits"]["MFC"]
+
+        self.fuel_loaded = fuel_loaded
+
+        assert (
+            fuel_loaded <= self.ac["limits"]["MFC"]
+        )  # Ensure fuel loaded <= fuel capacity
+
+        aircraft_params = load_aircraft_engine_params(actype)
+
+        self.start = State(
+            pd.DataFrame(
+                [
+                    {
+                        "ts": self.start_time,
+                        "lat": self.lat1,
+                        "lon": self.lon1,
+                        "mass": (
+                            aircraft_params["amass_mtow"]
+                            if take_off_weight is None
+                            else take_off_weight
+                            - 0.8 * (self.ac["limits"]["MFC"] - self.fuel_loaded)
+                        ),  # Here we compute the weight difference between the fuel loaded and the fuel capacity
+                        "mach": self.mach,
+                        "fuel": 0.0,
+                        "alt": self.alt1,
+                    }
+                ]
+            ),
+            (0, self.nb_lateral_points // 2, 0),
+        )
+
+        self.perf_model = AircraftPerformanceModel(actype, perf_model_name)
+        self.perf_model_name = perf_model_name
+
+        self.res_img_dir = res_img_dir
+        self.cruising = self.alt1 * ft >= self.ac["cruise"]["height"] * 0.98
+
+    # Class functions
+
+    def _get_next_state(self, memory: D.T_state, action: D.T_event) -> D.T_state:
+        """Compute the next state
+
+        # Parameters
+            memory (D.T_state): The current state
+            action (D.T_event): The action to perform
+
+        # Returns
+            D.T_state: The next state
+        """
+
+        trajectory = memory.trajectory.copy()
+
+        # Set intermediate destination point
+        next_x, next_y, next_z = memory.pos
+
+        next_x += 1
+
+        if action[0] == H_Action.up:
+            next_y += 1
+        if action[0] == H_Action.down:
+            next_y -= 1
+        if action[1] == V_Action.climb:
+            next_z += 1
+        if action[1] == V_Action.descent:
+            next_z -= 1
+
+        # Aircraft stays on the network
+        if (
+            next_x >= self.nb_forward_points
+            or next_y < 0
+            or next_y >= self.nb_lateral_points
+            or next_z < 0
+            or next_z >= self.nb_vertical_points
+        ):
+            return memory
+
+        # Concatenate the two trajectories
+
+        to_lat = self.network[next_x][next_y][next_z].lat
+        to_lon = self.network[next_x][next_y][next_z].lon
+        to_alt = (
+            self.network[next_x][next_y][next_z].height / ft
+        )  # We compute the flight with altitude in ft, whereas the altitude in the network is in meters according to LatLon
+
+        self.cruising = (
+            to_alt * ft >= self.ac["cruise"]["height"] * 0.98
+        )  # Check if the plane will be cruising in the next state
+        trajectory = self.flying(trajectory.tail(1), (to_lat, to_lon, to_alt))
+
+        state = State(
+            pd.concat([memory.trajectory, trajectory], ignore_index=True),
+            (next_x, next_y, next_z),
+        )
+        return state
+
+    def _get_transition_value(
+        self,
+        memory: D.T_state,
+        action: D.T_event,
+        next_state: Optional[D.T_state] = None,
+    ) -> Value[D.T_value]:
+        """
+        Get the value (reward or cost) of a transition.
+        Set cost to distance travelled between points
+
+        # Parameters
+            memory (D.T_state): The current state
+            action (D.T_event): The action to perform
+            next_state (Optional[D.T_state], optional): The next state. Defaults to None.
+
+        # Returns
+            Value[D.T_value]: Cost to go from memory to next state
+        """
+        assert memory != next_state, "Next state is the same as the current state"
+        if self.objective == "distance":
+            cost = LatLon.distanceTo(
+                LatLon(
+                    memory.trajectory.iloc[-1]["lat"],
+                    memory.trajectory.iloc[-1]["lon"],
+                    memory.trajectory.iloc[-1]["alt"] * ft,
+                ),
+                LatLon(
+                    next_state.trajectory.iloc[-1]["lat"],
+                    next_state.trajectory.iloc[-1]["lon"],
+                    next_state.trajectory.iloc[-1]["alt"] * ft,
+                ),
+            )
+        elif self.objective == "time" or self.objective == "lazy_time":
+            cost = (
+                next_state.trajectory.iloc[-1]["ts"] - memory.trajectory.iloc[-1]["ts"]
+            )
+        else:
+            cost = (
+                memory.trajectory.iloc[-1]["mass"]
+                - next_state.trajectory.iloc[-1]["mass"]
+            )
+        return Value(cost=cost)
+
+    def _get_initial_state_(self) -> D.T_state:
+        """
+        Get the initial state.
+
+        Set the start position as initial state.
+        """
+        return self.start
+
+    def _get_goals_(self) -> Space[D.T_observation]:
+        """
+        Get the domain goals space (finite or infinite set).
+
+        Set the end position as goal.
+        """
+        return ImplicitSpace(lambda x: x.pos[0] == self.nb_forward_points - 1)
+
+    def _get_terminal_state_time_fuel(self, state: State) -> dict:
+        """
+        Get the domain terminal state information to compare with the constraints
+
+        # Parameters
+            state (State): terminal state to retrieve the information on fuel and time.
+
+        # Returns
+            dict: dictionnary containing both fuel and time information.
+        """
+        fuel = 0.0
+        for trajectory in state.trajectory.iloc:
+            fuel += trajectory["fuel"]
+
+        if (
+            state.trajectory.iloc[-1]["ts"] < self.start_time
+        ):  # The flight arrives the next day
+            time = 3_600 * 24 - self.start_time + state.trajectory.iloc[-1]["ts"]
+        else:
+            time = state.trajectory.iloc[-1]["ts"] - self.start_time
+
+        return {"time": time, "fuel": fuel}
+
+    def _is_terminal(self, state: State) -> D.T_predicate:
+        """
+        Indicate whether a state is terminal.
+
+        Stop an episode only when goal reached.
+        """
+        return state.pos[0] == self.nb_forward_points - 1
+
+    def _get_applicable_actions_from(self, memory: D.T_state) -> Space[D.T_event]:
+        """
+        Get the applicable actions from a state.
+        """
+        x, y, z = memory.pos
+
+        space = []
+        if x < self.nb_forward_points - 1:
+            space.append((H_Action.straight, V_Action.cruise))
+            if z < self.nb_vertical_points - 1 and self.cruising:
+                space.append((H_Action.straight, V_Action.climb))
+            if z > 0 and self.cruising:
+                space.append((H_Action.straight, V_Action.descent))
+            if y + 1 < self.nb_lateral_points:
+                space.append((H_Action.up, V_Action.cruise))
+                if z < self.nb_vertical_points - 1 and self.cruising:
+                    space.append((H_Action.up, V_Action.climb))
+                if z > 0 and self.cruising:
+                    space.append((H_Action.up, V_Action.descent))
+            if y > 0:
+                space.append((H_Action.down, V_Action.cruise))
+                if z < self.nb_vertical_points - 1 and self.cruising:
+                    space.append((H_Action.down, V_Action.climb))
+                if z > 0 and self.cruising:
+                    space.append((H_Action.down, V_Action.descent))
+
+        return ListSpace(space)
+
+    def _get_action_space_(self) -> Space[D.T_event]:
+        """
+        Define action space.
+        """
+        return EnumSpace((H_Action, V_Action))
+
+    def _get_observation_space_(self) -> Space[D.T_observation]:
+        """
+        Define observation space.
+        """
+        return MultiDiscreteSpace(
+            [self.nb_forward_points, self.nb_lateral_points, self.nb_vertical_points]
+        )
+
+    def _render_from(self, memory: State, **kwargs: Any) -> Any:
+        """
+        Render visually the map.
+
+        # Returns
+            matplotlib figure
+        """
+        return plot_trajectory(
+            self.lat1,
+            self.lon1,
+            self.lat2,
+            self.lon2,
+            memory.trajectory,
+        )
+
+    def heuristic(self, s: D.T_state, heuristic_name: str = None) -> Value[D.T_value]:
+        """
+        Heuristic to be used by search algorithms, depending on the objective and constraints.
+
+        # Parameters
+            s (D.T_state): Actual state
+            objective (str, optional): Objective function. Defaults to None.
+
+        # Returns
+            Value[D.T_value]: Heuristic value of the state.
+        """
+
+        # current position
+        pos = s.trajectory.iloc[-1]
+
+        # parameters
+        lat_to, lon_to, alt_to = self.lat2, self.lon2, self.alt2
+        lat_start, lon_start, alt_start = self.lat1, self.lon1, self.alt1
+
+        if heuristic_name is None:
+            heuristic_name = self.heuristic_name
+
+        # Compute distance in meters
+        distance_to_goal = LatLon.distanceTo(
+            LatLon(pos["lat"], pos["lon"], height=pos["alt"] * ft),  # alt ft -> meters
+            LatLon(lat_to, lon_to, height=alt_to * ft),  # alt ft -> meters
+        )
+        distance_to_start = LatLon.distanceTo(
+            LatLon(pos["lat"], pos["lon"], height=pos["alt"] * ft),  # alt ft -> meters
+            LatLon(lat_start, lon_start, height=alt_start * ft),  # alt ft -> meters
+        )
+
+        if heuristic_name == "distance":
+            cost = distance_to_goal
+
+        elif heuristic_name == "fuel":
+            # bearing of the plane
+            bearing_degrees = aero_bearing(pos["lat"], pos["lon"], lat_to, lon_to)
+
+            # weather computations & A/C speed modification
+            we, wn = 0, 0
+            temp = 273.15
+            if self.weather_interpolator:
+                # wind computations
+                wind_ms = self.weather_interpolator.interpol_wind_classic(
+                    lat=pos["lat"], longi=pos["lon"], alt=pos["alt"], t=pos["ts"]
+                )
+                we, wn = wind_ms[2][0], wind_ms[2][1]  # 0, 300
+
+                # temperature computations
+                temp = self.weather_interpolator.interpol_field(
+                    [pos["ts"], pos["alt"], pos["lat"], pos["lon"]], field="T"
+                )
+
+                # check for NaN values
+                if math.isnan(temp):
+                    print("NaN values in temp")
+
+            wspd = sqrt(wn * wn + we * we)
+
+            tas = mach2tas(pos["mach"], pos["alt"] * ft)  # alt ft -> meters
+
+            gs = compute_gspeed(
+                tas=tas,
+                true_course=radians(bearing_degrees),
+                wind_speed=wspd,
+                wind_direction=3 * math.pi / 2 - atan2(wn, we),
+            )
+
+            # override temp computation
+            values_current = {
+                "mass": pos["mass"],
+                "alt": pos["alt"],
+                "speed": tas / kts,
+                "temp": temp,
+            }
+
+            # compute "time to arrival"
+            dt = distance_to_goal / gs
+
+            if distance_to_goal == 0:
+                return Value(cost=0)
+
+            if self.perf_model_name == "PS":
+                cost = self.perf_model.compute_fuel_consumption(
+                    values_current,
+                    delta_time=dt,
+                    path_angle=math.degrees(
+                        (alt_to - pos["alt"]) * ft / (distance_to_goal)
+                    ),
+                    # approximation for small angles: tan(alpha) ~ alpha
+                )
+            else:
+                cost = self.perf_model.compute_fuel_consumption(
+                    values_current,
+                    delta_time=dt,
+                )
+
+        elif heuristic_name == "time":
+            we, wn = 0, 0
+            bearing_degrees = aero_bearing(pos["lat"], pos["lon"], self.lat2, self.lon2)
+
+            if self.weather_interpolator:
+                wind_ms = self.weather_interpolator.interpol_wind_classic(
+                    lat=pos["lat"], longi=pos["lon"], alt=pos["alt"], t=pos["ts"]
+                )
+
+                we, wn = wind_ms[2][0], wind_ms[2][1]  # 0, 300
+            wspd = sqrt(wn * wn + we * we)
+
+            tas = mach2tas(pos["mach"], pos["alt"] * ft)  # alt ft -> meters
+
+            gs = compute_gspeed(
+                tas=tas,
+                true_course=radians(bearing_degrees),
+                wind_speed=wspd,
+                wind_direction=3 * math.pi / 2 - atan2(wn, we),
+            )
+
+            cost = distance_to_goal / gs
+
+        elif heuristic_name == "lazy_fuel":
+            fuel_consummed = s.trajectory.iloc[0]["mass"] - pos["mass"]
+            cost = (
+                1.05 * distance_to_goal * (fuel_consummed / (distance_to_start + 1e-8))
+            )
+
+        elif heuristic_name == "lazy_time":
+            cost = (
+                1.5
+                * distance_to_goal
+                * (
+                    (pos["ts"] - s.trajectory.iloc[0]["ts"])
+                    / (distance_to_start + 1e-8)
+                )
+            )
+        else:
+            cost = 0
+
+        return Value(cost=cost)
+
+    def set_network(
+        self,
+        p0: LatLon,
+        p1: LatLon,
+        nb_forward_points: int,
+        nb_lateral_points: int,
+        nb_vertical_points: int,
+        climbing_slope: float = None,
+        descending_slope: float = None,
+        graph_width: float = None,
+    ):
+        """
+        Creation of the airway graph.
+
+        # Parameters
+            p0 : Origin of the flight plan
+            p1 : Destination of the flight plan
+            nb_forward_points (int): Number of forward points in the graph
+            nb_lateral_points (int): Number of lateral points in the graph
+            nb_vertical_points (int): Number of vertical points in the graph
+            climbing_slope (float, optional): Climbing slope of the plane during climbing phase. Defaults to None.
+            descending_slope (float, optional):  Descent slope of the plane during descent phase. Defaults to None.
+            graph_width (float, optional): Graph width of the graph. Defaults to None.
+
+        # Returns
+            A 3D matrix containing for each points its latitude, longitude, altitude between origin & destination.
+        """
+
+        cruise_alt_min = 31_000 * ft  # maybe useful to change this
+        half_forward_points = nb_forward_points // 2
+        half_lateral_points = nb_lateral_points // 2
+        half_vertical_points = nb_vertical_points // 2
+
+        distp = (
+            graph_width * p0.distanceTo(p1) * 0.022
+        )  # meters, around 2.2%*graphwidth of the p0 to p1 distance
+
+        descent_dist = min(
+            300_000
+            * (
+                max(self.ac["cruise"]["height"] - p1.height, 0)
+                / self.ac["cruise"]["height"]
+            ),
+            p0.distanceTo(p1),
+        )  # meters
+
+        climb_dist = 220_000 * (
+            max(self.ac["cruise"]["height"] - p0.height, 0)
+            / self.ac["cruise"]["height"]
+        )  # meters
+
+        total_distance = p0.distanceTo(p1)
+        if total_distance < (climb_dist + descent_dist):
+            climb_dist = total_distance * max(
+                (climb_dist / (climb_dist + descent_dist)) - 0.1, 0
+            )
+            descent_dist = total_distance * max(
+                descent_dist / (climb_dist + descent_dist) - 0.1, 0
+            )
+            possible_altitudes = [cruise_alt_min for k in range(nb_vertical_points)]
+
+        else:
+            possible_altitudes = [
+                (
+                    min(
+                        self.ac["cruise"]["height"]
+                        + 2000 * ft * i
+                        - (self.ac["cruise"]["height"] % 1000),
+                        self.ac["limits"]["ceiling"],
+                    )
+                )
+                for i in range(nb_vertical_points)
+            ]
+        if climbing_slope:
+            climbing_ratio = climbing_slope
+        else:
+            climbing_ratio = (
+                possible_altitudes[0] / climb_dist if climb_dist != 0 else 0
+            )
+        if descending_slope:
+            descending_ratio = descending_slope
+        else:
+            descending_ratio = (
+                possible_altitudes[0] / descent_dist if descent_dist != 0 else 0
+            )
+        # Initialisation of the graph matrix
+        pt = [
+            [
+                [None for k in range(len(possible_altitudes))]
+                for j in range(nb_lateral_points)
+            ]
+            for i in range(nb_forward_points)
+        ]
+
+        # set boundaries
+        for j in range(nb_lateral_points):
+            for k in range(nb_vertical_points):
+                pt[0][j][k] = p0
+                pt[nb_forward_points - 1][j][k] = p1
+
+        # set climb phase
+        i_initial = 1
+        if climbing_ratio != 0:
+            dist = 0
+            alt = p0.height
+            while dist < climb_dist and i_initial != nb_forward_points:
+
+                local_dist = (
+                    pt[i_initial - 1][half_lateral_points][
+                        half_vertical_points
+                    ].distanceTo(p1)
+                ) / (nb_forward_points - i_initial)
+                dist += local_dist
+                alt += int(local_dist * climbing_ratio)
+
+                for k in range(nb_vertical_points):
+                    bearing = pt[i_initial - 1][half_lateral_points][
+                        k
+                    ].initialBearingTo(p1)
+                    pt[i_initial][half_lateral_points][k] = pt[i_initial - 1][
+                        half_lateral_points
+                    ][k].destination(
+                        local_dist, bearing, min(possible_altitudes[0], alt)
+                    )
+                i_initial += 1
+
+        # set last step, descent
+        i_final = 1
+        if descending_ratio != 0:
+            dist = 0
+            alt = p1.height
+
+            while dist < descent_dist and i_final != nb_forward_points - 1:
+                local_dist = (
+                    pt[nb_forward_points - i_final][half_lateral_points][
+                        half_vertical_points
+                    ].distanceTo(p0)
+                ) / (nb_forward_points - i_final)
+                dist += local_dist
+                alt += int(local_dist * descending_ratio)
+
+                for k in range(nb_vertical_points):
+                    bearing = pt[nb_forward_points - i_final][half_lateral_points][
+                        k
+                    ].initialBearingTo(p0)
+                    pt[nb_forward_points - i_final - 1][half_lateral_points][k] = pt[
+                        nb_forward_points - i_final
+                    ][half_lateral_points][k].destination(
+                        local_dist, bearing, min(possible_altitudes[0], alt)
+                    )
+                i_final += 1
+
+        # direct path between end of climbing and beginning of descent
+        for k in range(nb_vertical_points):
+            for i in range(i_initial, nb_forward_points - i_final + 1):
+                bearing = pt[i - 1][half_lateral_points][k].initialBearingTo(p1)
+                total_distance = pt[i - 1][half_lateral_points][k].distanceTo(
+                    pt[nb_forward_points - 2][half_lateral_points][k]
+                )
+                pt[i][half_lateral_points][k] = pt[i - 1][half_lateral_points][
+                    k
+                ].destination(
+                    total_distance / (nb_forward_points - i),
+                    bearing,
+                    height=possible_altitudes[k],
+                )
+
+            bearing = pt[half_forward_points - 1][half_lateral_points][
+                k
+            ].initialBearingTo(pt[half_forward_points + 1][half_lateral_points][k])
+            pt[half_forward_points][nb_lateral_points - 1][k] = pt[half_forward_points][
+                half_lateral_points
+            ][k].destination(
+                distp * half_lateral_points,
+                bearing + 90,
+                height=pt[half_forward_points][half_lateral_points][k].height,
+            )
+            pt[half_forward_points][0][k] = pt[half_forward_points][
+                half_lateral_points
+            ][k].destination(
+                distp * half_lateral_points,
+                bearing - 90,
+                height=pt[half_forward_points][half_lateral_points][k].height,
+            )
+
+        for j in range(1, half_lateral_points + 1):
+            for k in range(len(possible_altitudes)):
+                # +j (left)
+                bearing = pt[half_forward_points][half_lateral_points + j - 1][
+                    k
+                ].initialBearingTo(pt[half_forward_points][nb_lateral_points - 1][k])
+                total_distance = pt[half_forward_points][half_lateral_points + j - 1][
+                    k
+                ].distanceTo(pt[half_forward_points][nb_lateral_points - 1][k])
+                pt[half_forward_points][half_lateral_points + j][k] = pt[
+                    half_forward_points
+                ][half_lateral_points + j - 1][k].destination(
+                    total_distance / (half_lateral_points - j + 1),
+                    bearing,
+                    height=pt[half_forward_points][half_lateral_points][k].height,
+                )
+                # -j (right)
+                bearing = pt[half_forward_points][half_lateral_points - j + 1][
+                    k
+                ].initialBearingTo(pt[half_forward_points][0][k])
+                total_distance = pt[half_forward_points][half_lateral_points - j + 1][
+                    k
+                ].distanceTo(pt[half_forward_points][0][k])
+                pt[half_forward_points][half_lateral_points - j][k] = pt[
+                    half_forward_points
+                ][half_lateral_points - j + 1][k].destination(
+                    total_distance / (half_lateral_points - j + 1),
+                    bearing,
+                    height=pt[half_forward_points][half_lateral_points][k].height,
+                )
+                for i in range(1, i_initial):
+                    alt = pt[i][half_lateral_points][k].height
+                    bearing = pt[i - 1][half_lateral_points + j][k].initialBearingTo(
+                        pt[half_forward_points][half_lateral_points + j][k]
+                    )
+                    total_distance = pt[i - 1][half_lateral_points + j][k].distanceTo(
+                        pt[half_forward_points][half_lateral_points + j][k]
+                    )
+                    pt[i][half_lateral_points + j][k] = pt[i - 1][
+                        half_lateral_points + j
+                    ][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=alt,
+                    )
+
+                    bearing = pt[i - 1][half_lateral_points - j][k].initialBearingTo(
+                        pt[half_forward_points][half_lateral_points - j][k]
+                    )
+                    total_distance = pt[i - 1][half_lateral_points - j][k].distanceTo(
+                        pt[half_forward_points][half_lateral_points - j][k]
+                    )
+                    pt[i][half_lateral_points - j][k] = pt[i - 1][
+                        half_lateral_points - j
+                    ][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=alt,
+                    )
+                for i in range(i_initial, half_forward_points):
+                    # first halp (p0 to np2)
+                    bearing = pt[i - 1][half_lateral_points + j][k].initialBearingTo(
+                        pt[half_forward_points][half_lateral_points + j][k]
+                    )
+                    total_distance = pt[i - 1][half_lateral_points + j][k].distanceTo(
+                        pt[half_forward_points][half_lateral_points + j][k]
+                    )
+                    pt[i][half_lateral_points + j][k] = pt[i - 1][
+                        half_lateral_points + j
+                    ][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=pt[i][half_lateral_points][k].height,
+                    )
+
+                    bearing = pt[i - 1][half_lateral_points - j][k].initialBearingTo(
+                        pt[half_forward_points][half_lateral_points - j][k]
+                    )
+                    total_distance = pt[i - 1][half_lateral_points - j][k].distanceTo(
+                        pt[half_forward_points][half_lateral_points - j][k]
+                    )
+                    pt[i][half_lateral_points - j][k] = pt[i - 1][
+                        half_lateral_points - j
+                    ][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=pt[i][half_lateral_points][k].height,
+                    )
+                for i in range(1, abs(half_forward_points - i_final)):
+                    # second half (np2 to p1)
+                    bearing = pt[half_forward_points + i - 1][half_lateral_points + j][
+                        k
+                    ].initialBearingTo(
+                        pt[nb_forward_points - 1][half_lateral_points + j][k]
+                    )
+                    total_distance = pt[half_forward_points + i - 1][
+                        half_lateral_points + j
+                    ][k].distanceTo(
+                        pt[nb_forward_points - 1][half_lateral_points + j][k]
+                    )
+                    pt[half_forward_points + i][half_lateral_points + j][k] = pt[
+                        half_forward_points + i - 1
+                    ][half_lateral_points + j][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=pt[half_forward_points + i][half_lateral_points][
+                            k
+                        ].height,
+                    )
+
+                    bearing = pt[half_forward_points + i - 1][half_lateral_points - j][
+                        k
+                    ].initialBearingTo(
+                        pt[nb_forward_points - 1][half_lateral_points - j][k]
+                    )
+                    total_distance = pt[half_forward_points + i - 1][
+                        half_lateral_points - j
+                    ][k].distanceTo(
+                        pt[nb_forward_points - 1][half_lateral_points - j][k]
+                    )
+                    pt[half_forward_points + i][half_lateral_points - j][k] = pt[
+                        half_forward_points + i - 1
+                    ][half_lateral_points - j][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=pt[half_forward_points + i][half_lateral_points][
+                            k
+                        ].height,
+                    )
+                for i in range(abs(half_forward_points - i_final), half_forward_points):
+                    alt = pt[half_forward_points + i - 1][half_lateral_points][k].height
+                    bearing = pt[half_forward_points + i - 1][half_lateral_points + j][
+                        k
+                    ].initialBearingTo(
+                        pt[nb_forward_points - 1][half_lateral_points + j][k]
+                    )
+                    total_distance = pt[half_forward_points + i - 1][
+                        half_lateral_points + j
+                    ][k].distanceTo(
+                        pt[nb_forward_points - 1][half_lateral_points + j][k]
+                    )
+                    pt[half_forward_points + i][half_lateral_points + j][k] = pt[
+                        half_forward_points + i - 1
+                    ][half_lateral_points + j][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=alt,
+                    )
+
+                    bearing = pt[half_forward_points + i - 1][half_lateral_points - j][
+                        k
+                    ].initialBearingTo(
+                        pt[nb_forward_points - 1][half_lateral_points - j][k]
+                    )
+                    total_distance = pt[half_forward_points + i - 1][
+                        half_lateral_points - j
+                    ][k].distanceTo(
+                        pt[nb_forward_points - 1][half_lateral_points - j][k]
+                    )
+                    pt[half_forward_points + i][half_lateral_points - j][k] = pt[
+                        half_forward_points + i - 1
+                    ][half_lateral_points - j][k].destination(
+                        total_distance / (half_forward_points - i + 1),
+                        bearing,
+                        height=alt,
+                    )
+
+        return pt
+
+    def get_network(self):
+        return self.network
+
+    def flying(
+        self, from_: pd.DataFrame, to_: Tuple[float, float, int]
+    ) -> pd.DataFrame:
+        """Compute the trajectory of a flying object from a given point to a given point
+
+        # Parameters
+            from_ (pd.DataFrame): the trajectory of the object so far
+            to_ (Tuple[float, float]): the destination of the object
+
+        # Returns
+            pd.DataFrame: the final trajectory of the object
+        """
+        pos = from_.to_dict("records")[0]
+
+        lat_to, lon_to, alt_to = to_[0], to_[1], to_[2]
+        dist_ = distance(
+            pos["lat"], pos["lon"], lat_to, lon_to, h=(alt_to - pos["alt"]) * ft
+        )
+
+        data = []
+        epsilon = 100
+        dt = 600
+        dist = dist_
+        loop = 0
+
+        while dist > epsilon:
+            # bearing of the plane
+            bearing_degrees = aero_bearing(pos["lat"], pos["lon"], lat_to, lon_to)
+
+            # wind computations & A/C speed modification
+            we, wn = 0, 0
+            temp = 273.15
+            if self.weather_interpolator:
+                time = pos["ts"] % (3_600 * 24)
+
+                # wind computations
+                wind_ms = self.weather_interpolator.interpol_wind_classic(
+                    lat=pos["lat"], longi=pos["lon"], alt=alt_to, t=time
+                )
+                we, wn = wind_ms[2][0], wind_ms[2][1]
+
+                # temperature computations
+                temp = self.weather_interpolator.interpol_field(
+                    [pos["ts"], pos["alt"], pos["lat"], pos["lon"]], field="T"
+                )
+
+            wspd = sqrt(wn * wn + we * we)
+
+            tas = mach2tas(self.mach, alt_to * ft)  # alt ft -> meters
+
+            gs = compute_gspeed(
+                tas=tas,
+                true_course=radians(bearing_degrees),
+                wind_speed=wspd,
+                wind_direction=3 * math.pi / 2 - atan2(wn, we),
+            )
+
+            if gs * dt > dist:
+                # Last step. make sure we go to destination.
+                dt = dist / gs
+                ll = lat_to, lon_to
+            else:
+                ll = latlon(
+                    pos["lat"],
+                    pos["lon"],
+                    d=gs * dt,
+                    brg=bearing_degrees,
+                    h=alt_to * ft,
+                )
+
+            values_current = {
+                "mass": pos["mass"],
+                "alt": pos["alt"],
+                "speed": tas / kts,
+                "temp": temp,
+            }
+
+            pos["fuel"] = self.perf_model.compute_fuel_consumption(
+                values_current,
+                delta_time=dt,
+                path_angle=math.degrees((alt_to - pos["alt"]) * ft / (gs * dt)),
+                # approximation for small angles: tan(alpha) ~ alpha
+            )
+
+            mass = pos["mass"] - pos["fuel"]
+
+            # get new weather interpolators
+            if pos["ts"] + dt >= (3_600.0 * 24.0):
+                if self.weather_date:
+                    if self.weather_date == self.initial_date:
+                        self.weather_date = self.weather_date.next_day()
+                        self.weather_interpolator = self.get_weather_interpolator()
+            else:
+                if self.weather_date != self.initial_date:
+                    self.weather_date = self.weather_date.previous_day()
+                    self.weather_interpolator = self.get_weather_interpolator()
+
+            new_row = {
+                "ts": (pos["ts"] + dt),
+                "lat": ll[0],
+                "lon": ll[1],
+                "mass": mass,
+                "mach": self.mach,
+                "fuel": pos["fuel"],
+                "alt": alt_to,  # to be modified
+            }
+
+            dist = distance(
+                ll[0],
+                ll[1],
+                lat_to,
+                lon_to,
+                h=(pos["alt"] - alt_to) * ft,  # height difference in m
+            )
+
+            if dist < dist_:
+                data.append(new_row)
+                dist_ = dist
+                pos = data[-1]
+
+            else:
+                dt = int(dt / 10)
+                print("going in the wrong part.")
+                assert dt > 0
+
+            loop += 1
+
+        return pd.DataFrame(data)
+
+    def get_weather_interpolator(self) -> GenericWindInterpolator:
+        weather_interpolator = None
+
+        if self.weather_date:
+            w_dict = self.weather_date.to_dict()
+
+            mat = get_weather_matrix(
+                year=w_dict["year"],
+                month=w_dict["month"],
+                day=w_dict["day"],
+                forecast=w_dict["forecast"],
+                delete_npz_from_local=False,
+                delete_grib_from_local=False,
+            )
+
+            # returns both wind and temperature interpolators
+            weather_interpolator = GenericWindInterpolator(file_npz=mat)
+
+        return weather_interpolator
+
+    def custom_rollout(self, solver, max_steps=100, make_img=True):
+        observation = self.reset()
+
+        solver.reset()
+        clear_output(wait=True)
+
+        # loop until max_steps or goal is reached
+        for i_step in range(1, max_steps + 1):
+
+            # choose action according to solver
+            action = solver.sample_action(observation)
+
+            # get corresponding action
+            outcome = self.step(action)
+            observation = outcome.observation
+
+            # self.observation = observation
+
+            print("step ", i_step)
+            print("policy = ", action[0], action[1])
+            print("New state = ", observation.pos)
+            print("Alt = ", observation.alt)
+            print("Mach = ", observation.trajectory.iloc[-1]["mach"])
+            print(observation)
+
+            # if make_img:
+            #     # update image
+            #     plt.clf()  # clear figure
+            #     clear_output(wait=True)
+            #     figure = self.render(observation)
+            #     # plt.savefig(f'step_{i_step}')
+
+            # final state reached?
+            if self.is_terminal(observation):
+                break
+        if make_img:
+            print("Final state reached")
+            clear_output(wait=True)
+            fig = plot_full(self, observation.trajectory)
+            # plt.savefig(f"full_plot")
+            plt.show()
+            pass
+            # clear_output(wait=True)
+            # plt.title(f'Flight plan - {self.origin} -> {self.destination} \n Model: {self.perf_model_name}, Fuel: {np.round(observation.trajectory["fuel"].sum(), 2)} Kg')
+            # plt.savefig(f"terminal")
+            # plt.show()
+
+            # figure = plot_altitude(observation.trajectory)
+            # plt.savefig("altitude")
+            # plt.show()
+            # figure = plot_mass(observation.trajectory)
+            # plt.savefig("mass")
+            # plt.show()
+            # plot_network(self)
+        # goal reached?
+        is_goal_reached = self.is_goal(observation)
+
+        terminal_state_constraints = self._get_terminal_state_time_fuel(observation)
+        if is_goal_reached:
+            if self.constraints is not None:
+                if self.constraints["time"] is not None:
+                    if (
+                        self.constraints["time"][1]
+                        >= terminal_state_constraints["time"]
+                    ):
+                        if (
+                            self.constraints["fuel"]
+                            >= terminal_state_constraints["fuel"]
+                        ):
+                            print(f"Goal reached after {i_step} steps!")
+                        else:
+                            print(
+                                f"Goal reached after {i_step} steps, but there is not enough fuel remaining!"
+                            )
+                    else:
+                        print(
+                            f"Goal reached after {i_step} steps, but not in the good timelapse!"
+                        )
+                else:
+                    if self.constraints["fuel"] >= terminal_state_constraints["fuel"]:
+                        print(f"Goal reached after {i_step} steps!")
+                    else:
+                        print(
+                            f"Goal reached after {i_step} steps, but there is not enough fuel remaining!"
+                        )
+            else:
+                if self.ac["limits"]["MFC"] >= terminal_state_constraints["fuel"]:
+                    print(f"Goal reached after {i_step} steps!")
+                else:
+                    print(
+                        f"Goal reached after {i_step} steps, but there is not enough fuel remaining!"
+                    )
+        else:
+            print(f"Goal not reached after {i_step} steps!")
+
+        return terminal_state_constraints, self.constraints
+
+
+def compute_gspeed(
+    tas: float, true_course: float, wind_speed: float, wind_direction: float
+):
+    # Tas : speed in m/s
+    # course : current bearing
+    # wind speed, wind norm in m/s
+    # wind_direction : (3pi/2-arctan(north_component/east_component)) in radian
+    ws = wind_speed
+    wd = wind_direction
+    tc = true_course
+
+    # calculate wind correction angle wca and ground speed gs
+    swc = ws / tas * sin(wd - tc)
+    if abs(swc) >= 1.0:
+        # Wind is to strong
+        gs = tas
+        error = "Wind is too strong"
+    else:
+        wca = asin(swc)  # * 180.0 / pi)
+        gs = tas * sqrt(1 - swc * swc) - ws * cos(wd - tc)
+
+    if gs < 0:
+        # Wind is to strong
+        gs = tas
+        error = "Wind is too strong"
+    else:
+        # Reset possible status message
+        error = ""
+    return gs
+
+
+def fuel_optimisation(
+    origin: Union[str, tuple],
+    destination: Union[str, tuple],
+    actype: str,
+    constraints: dict,
+    weather_date: WeatherDate,
+    solver_cls: Type[Solver],
+    solver_kwargs: Dict[str, Any],
+    max_steps: int = 100,
+    fuel_tol: float = 1e-3,
+) -> float:
+    """
+    Function to optimise the fuel loaded in the plane, doing multiple fuel loops to approach an optimal
+
+    # Parameters
+        origin (Union[str, tuple]):
+            ICAO code of the departure airport of th flight plan e.g LFPG for Paris-CDG, or a tuple (lat,lon)
+
+        destination (Union[str, tuple]):
+            ICAO code of the arrival airport of th flight plan e.g LFBO for Toulouse-Blagnac airport, or a tuple (lat,lon)
+
+        actype (str):
+            Aircarft type describe in openap datas (https://github.com/junzis/openap/tree/master/openap/data/aircraft)
+
+        constraints (dict):
+            Constraints that will be defined for the flight plan
+
+        wind_interpolator (GenericWindInterpolator):
+            Define the wind interpolator to use wind informations for the flight plan
+
+        fuel_loaded (float):
+            Fuel loaded in the plane for the flight
+
+        solver_cls (type[Solver]):
+            Solver class used in the fuel loop.
+
+        solver_kwargs (Dict[str, Any]):
+            Kwargs to initialize the solver used in the fuel loop.
+
+        max_steps (int):
+            max steps to use in the internal fuel loop
+
+        fuel_tol (float):
+            tolerance on fuel used to stop the optimization
+
+    # Returns
+        float:
+            Return the quantity of fuel to be loaded in the plane for the flight
+    """
+
+    small_diff = False
+    step = 0
+    new_fuel = constraints["fuel"]
+    while not small_diff:
+        domain_factory = lambda: FlightPlanningDomain(
+            origin=origin,
+            destination=destination,
+            actype=actype,
+            constraints=constraints,
+            weather_date=weather_date,
+            objective="distance",
+            heuristic_name="distance",
+            nb_forward_points=41,
+            nb_lateral_points=11,
+            fuel_loaded=new_fuel,
+            starting_time=0.0,
+        )
+        solver_kwargs = dict(solver_kwargs)
+        solver_kwargs["domain_factory"] = domain_factory
+        solver_factory = lambda: solver_cls(**solver_kwargs)
+        fuel_prec = new_fuel
+        new_fuel = simple_fuel_loop(
+            solver_factory=solver_factory,
+            domain_factory=domain_factory,
+            max_steps=max_steps,
+        )
+        step += 1
+        small_diff = (fuel_prec - new_fuel) <= fuel_tol
+
+    return new_fuel
+
+
+def simple_fuel_loop(solver_factory, domain_factory, max_steps: int = 100) -> float:
+    domain = domain_factory()
+    with solver_factory() as solver:
+        solver.solve()
+        observation: State = domain.reset()
+        solver.reset()
+
+        # loop until max_steps or goal is reached
+        for i_step in range(1, max_steps + 1):
+
+            # choose action according to solver
+            action = solver.sample_action(observation)
+
+            # get corresponding action
+            outcome = domain.step(action)
+            observation = outcome.observation
+
+            if domain.is_terminal(observation):
+                break
+
+        # Retrieve fuel for the flight
+        fuel = domain._get_terminal_state_time_fuel(observation)["fuel"]
+
+    return fuel
```

## skdecide/hub/domain/flight_planning/flightplanning_utils.py

```diff
@@ -1,281 +1,468 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-
-import time
-from copy import deepcopy
-
-import matplotlib.pyplot as plt
-import numpy as np
-import pandas as pd
-from cartopy import crs as ccrs
-from cartopy.feature import BORDERS, LAND, OCEAN
-from matplotlib.figure import Figure
-from openap import aero
-from pygeodesy.ellipsoidalVincenty import LatLon
-
-
-class Timer(object):
-    def __init__(self, name=None):
-        self.name = name
-
-    def __enter__(self):
-        self.tstart = time.time()
-
-    def __exit__(self, type, value, traceback):
-        if self.name:
-            print(
-                "[%s]" % self.name,
-            )
-        print("Elapsed: %s" % (time.time() - self.tstart))
-
-
-def plot_trajectory(lat1, lon1, lat2, lon2, trajectory: pd.DataFrame) -> Figure:
-    """Plot the trajectory of an object
-
-    Args:
-        trajectory (pd.DataFrame): the trajectory of the object
-
-    Returns:
-        Figure: the figure
-    """
-
-    fig = Figure(figsize=(600, 600))
-    fig.canvas.header_visible = False
-    fig.canvas.footer_visible = False
-    fig.canvas.resizable = False
-    fig.set_dpi(1)
-
-    # lon1, lat1 = trajectory.iloc[0]["lon"], trajectory.iloc[0]["lat"]
-    # lon2, lat2 = trajectory.iloc[-1]["lon"], trajectory.iloc[-1]["lat"]
-
-    latmin, latmax = min(lat1, lat2), max(lat1, lat2)
-    lonmin, lonmax = min(lon1, lon2), max(lon1, lon2)
-
-    ax = plt.axes(projection=ccrs.TransverseMercator())
-
-    ax.set_extent([lonmin - 4, lonmax + 4, latmin - 2, latmax + 2])
-    ax.add_feature(OCEAN, facecolor="#d1e0e0", zorder=-1, lw=0)
-    ax.add_feature(LAND, facecolor="#f5f5f5", lw=0)
-    ax.add_feature(BORDERS, lw=0.5, color="gray")
-    ax.gridlines(draw_labels=True, color="gray", alpha=0.5, ls="--")
-    ax.coastlines(resolution="50m", lw=0.5, color="gray")
-
-    # great circle
-    ax.scatter(lon1, lat1, c="darkgreen", transform=ccrs.Geodetic())
-    ax.scatter(lon2, lat2, c="red", transform=ccrs.Geodetic())
-
-    ax.plot(
-        [lon1, lon2],
-        [lat1, lat2],
-        label="Great Circle",
-        color="red",
-        ls="--",
-        transform=ccrs.Geodetic(),
-    )
-
-    # trajectory
-    ax.plot(
-        trajectory.lon,
-        trajectory.lat,
-        color="green",
-        transform=ccrs.Geodetic(),
-        linewidth=2,
-        marker=".",
-        label="Optimal",
-    )
-
-    ax.legend()
-
-    return fig
-
-
-def plot_trajectory_no_map(lat1, lon1, lat2, lon2, trajectory: pd.DataFrame) -> Figure:
-    """Plot the trajectory of an object
-
-    Args:
-        trajectory (pd.DataFrame): the trajectory of the object
-
-    Returns:
-        Figure: the figure
-    """
-
-    fig = Figure(figsize=(600, 600))
-    fig.canvas.header_visible = False
-    fig.canvas.footer_visible = False
-    fig.canvas.resizable = False
-    fig.set_dpi(1)
-
-    latmin, latmax = min(lat1, lat2), max(lat1, lat2)
-    lonmin, lonmax = min(lon1, lon2), max(lon1, lon2)
-
-    fig, ax = plt.subplots(1)
-
-    wind_sample = 30
-    ax.set_xlim([lonmin, lonmax])
-    ax.set_ylim([latmin, latmax])
-    # great circle
-    ax.scatter(lon1, lat1, c="darkgreen")
-    ax.scatter(lon2, lat2, c="red")
-
-    ax.plot(
-        [lon1, lon2],
-        [lat1, lat2],
-        label="Great Circle",
-        color="red",
-        ls="--",
-    )
-
-    # trajectory
-    ax.plot(
-        trajectory.lon,
-        trajectory.lat,
-        color="green",
-        linewidth=2,
-        marker=".",
-        label="Optimal",
-    )
-
-    ax.legend()
-
-    # Save it to a temporary buffer.
-    # buf = BytesIO()
-    # fig.savefig(buf, format="png")
-    # Embed the result in the html output.
-    # data = base64.b64encode(buf.getbuffer()).decode("ascii")
-
-    return fig
-
-
-def plot_altitude(trajectory: pd.DataFrame) -> Figure:
-    fig = plt.Figure()
-    ax = plt.axes()
-    pos = [
-        LatLon(
-            trajectory.iloc[i]["lat"],
-            trajectory.iloc[i]["lon"],
-            trajectory.iloc[i]["alt"],
-        )
-        for i in range(len(trajectory.alt))
-    ]
-    dist = [d.distanceTo(pos[0]) for d in pos]
-    ax.plot(dist, trajectory.alt)
-    return fig
-
-
-def plot_network(domain, dir=None):
-    network = domain.network
-    origin_coord = domain.lat1, domain.lon1, domain.alt1
-    target_coord = domain.lat2, domain.lon2, domain.alt2
-    fig, ax = plt.subplots(1, subplot_kw={"projection": ccrs.PlateCarree()})
-    ax.set_extent(
-        [
-            min(origin_coord[1], target_coord[1]) - 4,
-            max(origin_coord[1], target_coord[1]) + 4,
-            min(origin_coord[0], target_coord[0]) - 2,
-            max(origin_coord[0], target_coord[0]) + 2,
-        ]
-    )
-    ax.add_feature(OCEAN, facecolor="#d1e0e0", zorder=-1, lw=0)
-    ax.add_feature(LAND, facecolor="#f5f5f5", lw=0)
-    ax.add_feature(BORDERS, lw=0.5, color="gray")
-    ax.gridlines(draw_labels=True, color="gray", alpha=0.5, ls="--")
-    ax.coastlines(resolution="50m", lw=0.5, color="gray")
-    ax.scatter(
-        [
-            network[x][x1][x2].lon
-            for x in range(len(network))
-            for x1 in range(len(network[x]))
-            for x2 in range(len(network[x][x1]))
-        ],
-        [
-            network[x][x1][x2].lat
-            for x in range(len(network))
-            for x1 in range(len(network[x]))
-            for x2 in range(len(network[x][x1]))
-        ],
-        transform=ccrs.Geodetic(),
-        s=0.2,
-    )
-
-    if dir:
-        fig.savefig(f"{dir}/network points.png")
-    else:
-        fig.savefig("network points.png")
-
-
-def trajectory_on_map(df, windfield=None, ax=None, wind_sample=4):
-
-    lat1, lon1 = df.lat.iloc[0], df.lon.iloc[0]
-    lat2, lon2 = df.lat.iloc[-1], df.lon.iloc[-1]
-
-    latmin, latmax = min(lat1, lat2), max(lat1, lat2)
-    lonmin, lonmax = min(lon1, lon2), max(lon1, lon2)
-
-    if ax is None:
-        ax = plt.axes(
-            projection=ccrs.TransverseMercator(
-                central_longitude=df.lon.mean(), central_latitude=df.lat.mean()
-            )
-        )
-
-    ax.set_extent([lonmin - 4, lonmax + 4, latmin - 2, latmax + 2])
-    ax.add_feature(OCEAN, facecolor="#d1e0e0", zorder=-1, lw=0)
-    ax.add_feature(LAND, facecolor="#f5f5f5", lw=0)
-    ax.add_feature(BORDERS, lw=0.5, color="gray")
-    ax.gridlines(draw_labels=True, color="gray", alpha=0.5, ls="--")
-    ax.coastlines(resolution="50m", lw=0.5, color="gray")
-
-    if windfield is not None:
-        # get the closed altitude
-        h_max = df.alt.max() * aero.ft
-        fl = int(round(h_max / aero.ft / 100, -1))
-        idx = np.argmin(abs(windfield.h.unique() - h_max))
-        df_wind = (
-            windfield.query(f"h=={windfield.h.unique()[idx]}")
-            .query(f"longitude <= {lonmax + 2}")
-            .query(f"longitude >= {lonmin - 2}")
-            .query(f"latitude <= {latmax + 2}")
-            .query(f"latitude >= {latmin - 2}")
-        )
-
-        ax.barbs(
-            df_wind.longitude.values[::wind_sample],
-            df_wind.latitude.values[::wind_sample],
-            df_wind.u.values[::wind_sample],
-            df_wind.v.values[::wind_sample],
-            transform=ccrs.PlateCarree(),
-            color="k",
-            length=5,
-            lw=0.5,
-            label=f"Wind FL{fl}",
-        )
-
-    # great circle
-    ax.scatter(lon1, lat1, c="darkgreen", transform=ccrs.Geodetic())
-    ax.scatter(lon2, lat2, c="tab:red", transform=ccrs.Geodetic())
-
-    ax.plot(
-        [lon1, lon2],
-        [lat1, lat2],
-        label="Great Circle",
-        color="tab:red",
-        ls="--",
-        transform=ccrs.Geodetic(),
-    )
-
-    # trajectory
-    ax.plot(
-        df.lon,
-        df.lat,
-        color="tab:green",
-        transform=ccrs.Geodetic(),
-        linewidth=2,
-        marker=".",
-        label="Optimal",
-    )
-
-    ax.legend()
-
-    return plt
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+
+import time
+from copy import deepcopy
+
+import matplotlib.gridspec as gridspec
+import matplotlib.pyplot as plt
+import numpy as np
+import pandas as pd
+from cartopy import crs as ccrs
+from cartopy.feature import BORDERS, LAND, OCEAN
+from matplotlib.figure import Figure
+from openap import aero
+from openap.extra.aero import ft, nm
+from pygeodesy.ellipsoidalVincenty import LatLon
+
+
+class Timer(object):
+    def __init__(self, name=None):
+        self.name = name
+
+    def __enter__(self):
+        self.tstart = time.time()
+
+    def __exit__(self, type, value, traceback):
+        if self.name:
+            print(
+                "[%s]" % self.name,
+            )
+        print("Elapsed: %s" % (time.time() - self.tstart))
+
+
+def plot_full(domain, trajectory: pd.DataFrame) -> Figure:
+    network = domain.network
+
+    fig = plt.figure(figsize=(15, 10))
+
+    # define the grid layout
+    gs = gridspec.GridSpec(2, 2, width_ratios=[1, 2])
+
+    # add subplots for the line plots
+    ax1 = fig.add_subplot(gs[0, 0])
+    ax2 = fig.add_subplot(gs[1, 0])
+
+    # values
+    pos = [
+        LatLon(
+            trajectory.iloc[i]["lat"],
+            trajectory.iloc[i]["lon"],
+            trajectory.iloc[i]["alt"] * ft,
+        )
+        for i in range(len(trajectory.alt))
+    ]
+    dist = np.array([d.distanceTo(pos[0]) for d in pos])
+
+    # plot the altitude
+    ax1.plot(dist / nm, trajectory.alt)
+    ax1.set_xlabel("ESAD (nm)")
+    ax1.set_ylabel("Zp (ft)")
+    ax1.set_title("Altitude profile")
+
+    # plot the mass
+    ax2.plot(dist / nm, trajectory.mass)
+    ax2.set_xlabel("ESAD (nm)")
+    ax2.set_ylabel("Mass (Kg)")
+    ax2.set_title("Mass profile")
+
+    # plot the trajectory
+    latmin, latmax = min(trajectory.lat), max(trajectory.lat)
+    lonmin, lonmax = min(trajectory.lon), max(trajectory.lon)
+
+    ax3 = fig.add_subplot(
+        gs[:, 1], projection=ccrs.PlateCarree(central_longitude=trajectory.lon.mean())
+    )
+
+    ax3.set_extent([lonmin - 4, lonmax + 4, latmin - 2, latmax + 2])
+    ax3.add_feature(OCEAN, facecolor="#d1e0e0", zorder=-1, lw=0)
+    ax3.add_feature(LAND, facecolor="#f5f5f5", lw=0)
+    ax3.add_feature(BORDERS, lw=0.5, color="gray")
+    ax3.gridlines(draw_labels=True, color="gray", alpha=0.5, ls="--")
+    ax3.coastlines(resolution="50m", lw=0.5, color="gray")
+
+    # add great circle
+    ax3.scatter(
+        trajectory.lon.iloc[0],
+        trajectory.lat.iloc[0],
+        c="darkgreen",
+        transform=ccrs.Geodetic(),
+    )
+    ax3.scatter(
+        trajectory.lon.iloc[-1],
+        trajectory.lat.iloc[-1],
+        c="red",
+        transform=ccrs.Geodetic(),
+    )
+
+    ax3.plot(
+        [trajectory.lon.iloc[0], trajectory.lon.iloc[-1]],
+        [trajectory.lat.iloc[0], trajectory.lat.iloc[-1]],
+        label="Great Circle",
+        color="red",
+        ls="--",
+        transform=ccrs.Geodetic(),
+    )
+
+    # add trajectory
+    ax3.plot(
+        trajectory.lon,
+        trajectory.lat,
+        color="green",
+        transform=ccrs.Geodetic(),
+        linewidth=2,
+        marker=".",
+        label="skdecide",
+    )
+
+    # add network
+    ax3.scatter(
+        [
+            network[x][x1][x2].lon
+            for x in range(len(network))
+            for x1 in range(len(network[x]))
+            for x2 in range(len(network[x][x1]))
+        ],
+        [
+            network[x][x1][x2].lat
+            for x in range(len(network))
+            for x1 in range(len(network[x]))
+            for x2 in range(len(network[x][x1]))
+        ],
+        transform=ccrs.Geodetic(),
+        s=0.1,
+    )
+
+    ax3.legend()
+
+    # add title to figure
+    fig.suptitle(
+        f'Leg: {domain.origin} -> {domain.destination} \n A/C perf. model: {domain.perf_model_name}; Fuel: {np.round(trajectory["fuel"].sum(), 2)} Kg',
+        fontsize=16,
+    )
+
+    plt.tight_layout()
+
+    return fig
+
+
+def plot_trajectory(lat1, lon1, lat2, lon2, trajectory: pd.DataFrame) -> Figure:
+    """Plot the trajectory of an object
+
+    # Parameters
+        trajectory (pd.DataFrame): the trajectory of the object
+
+    # Returns
+        Figure: the figure
+    """
+
+    fig = Figure(figsize=(600, 600))
+    fig.canvas.header_visible = False
+    fig.canvas.footer_visible = False
+    fig.canvas.resizable = False
+    fig.set_dpi(1)
+
+    # lon1, lat1 = trajectory.iloc[0]["lon"], trajectory.iloc[0]["lat"]
+    # lon2, lat2 = trajectory.iloc[-1]["lon"], trajectory.iloc[-1]["lat"]
+
+    latmin, latmax = min(lat1, lat2), max(lat1, lat2)
+    lonmin, lonmax = min(lon1, lon2), max(lon1, lon2)
+
+    ax = plt.axes(projection=ccrs.TransverseMercator())
+
+    ax.set_extent([lonmin - 4, lonmax + 4, latmin - 2, latmax + 2])
+    ax.add_feature(OCEAN, facecolor="#d1e0e0", zorder=-1, lw=0)
+    ax.add_feature(LAND, facecolor="#f5f5f5", lw=0)
+    ax.add_feature(BORDERS, lw=0.5, color="gray")
+    ax.gridlines(draw_labels=True, color="gray", alpha=0.5, ls="--")
+    ax.coastlines(resolution="50m", lw=0.5, color="gray")
+
+    # great circle
+    ax.scatter(lon1, lat1, c="darkgreen", transform=ccrs.Geodetic())
+    ax.scatter(lon2, lat2, c="red", transform=ccrs.Geodetic())
+
+    ax.plot(
+        [lon1, lon2],
+        [lat1, lat2],
+        label="Great Circle",
+        color="red",
+        ls="--",
+        transform=ccrs.Geodetic(),
+    )
+
+    # trajectory
+    ax.plot(
+        trajectory.lon,
+        trajectory.lat,
+        color="green",
+        transform=ccrs.Geodetic(),
+        linewidth=2,
+        marker=".",
+        label="Optimal",
+    )
+
+    ax.legend()
+
+    return fig
+
+
+def plot_trajectory_no_map(lat1, lon1, lat2, lon2, trajectory: pd.DataFrame) -> Figure:
+    """Plot the trajectory of an object
+
+    # Parameters
+        trajectory (pd.DataFrame): the trajectory of the object
+
+    # Returns
+        Figure: the figure
+    """
+
+    fig = Figure(figsize=(600, 600))
+    fig.canvas.header_visible = False
+    fig.canvas.footer_visible = False
+    fig.canvas.resizable = False
+    fig.set_dpi(1)
+
+    latmin, latmax = min(lat1, lat2), max(lat1, lat2)
+    lonmin, lonmax = min(lon1, lon2), max(lon1, lon2)
+
+    fig, ax = plt.subplots(1)
+
+    wind_sample = 30
+    ax.set_xlim([lonmin, lonmax])
+    ax.set_ylim([latmin, latmax])
+    # great circle
+    ax.scatter(lon1, lat1, c="darkgreen")
+    ax.scatter(lon2, lat2, c="red")
+
+    ax.plot(
+        [lon1, lon2],
+        [lat1, lat2],
+        label="Great Circle",
+        color="red",
+        ls="--",
+    )
+
+    # trajectory
+    ax.plot(
+        trajectory.lon,
+        trajectory.lat,
+        color="green",
+        linewidth=2,
+        marker=".",
+        label="Optimal",
+    )
+
+    ax.legend()
+
+    # Save it to a temporary buffer.
+    # buf = BytesIO()
+    # fig.savefig(buf, format="png")
+    # Embed the result in the html output.
+    # data = base64.b64encode(buf.getbuffer()).decode("ascii")
+
+    return fig
+
+
+def plot_mass(trajectory: pd.DataFrame) -> Figure:
+    fig = plt.Figure()
+    ax = plt.axes()
+    pos = [
+        LatLon(
+            trajectory.iloc[i]["lat"],
+            trajectory.iloc[i]["lon"],
+            trajectory.iloc[i]["alt"],
+        )
+        for i in range(len(trajectory.alt))
+    ]
+    dist = np.array([d.distanceTo(pos[0]) for d in pos])
+
+    ax.plot(dist / nm, trajectory.mass)
+    ax.set_xlabel("ESAD (nm)")
+    ax.set_ylabel("Mass (Kg)")
+
+    return fig
+
+
+def plot_altitude(trajectory: pd.DataFrame) -> Figure:
+    fig = plt.Figure()
+    ax = plt.axes()
+    pos = [
+        LatLon(
+            trajectory.iloc[i]["lat"],
+            trajectory.iloc[i]["lon"],
+            trajectory.iloc[i]["alt"] * ft,
+        )
+        for i in range(len(trajectory.alt))
+    ]
+    dist = np.array([d.distanceTo(pos[0]) for d in pos])
+
+    ax.plot(dist / nm, trajectory.alt)
+    ax.set_xlabel("ESAD (nm)")
+    ax.set_ylabel("Zp (ft)")
+
+    return fig
+
+
+def plot_network(domain, dir=None):
+    network = domain.network
+    origin_coord = domain.lat1, domain.lon1, domain.alt1
+    target_coord = domain.lat2, domain.lon2, domain.alt2
+
+    # fig, ax = plt.subplots(1, subplot_kw={"projection": ccrs.PlateCarree()})
+    fig = plt.figure(figsize=(15, 10))
+
+    # define the grid layout
+    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])
+    ax1 = fig.add_subplot(gs[0], projection=ccrs.PlateCarree())
+    ax2 = fig.add_subplot(gs[1])
+
+    ax1.set_extent(
+        [
+            min(origin_coord[1], target_coord[1]) - 4,
+            max(origin_coord[1], target_coord[1]) + 4,
+            min(origin_coord[0], target_coord[0]) - 2,
+            max(origin_coord[0], target_coord[0]) + 2,
+        ]
+    )
+    ax1.add_feature(OCEAN, facecolor="#d1e0e0", zorder=-1, lw=0)
+    ax1.add_feature(LAND, facecolor="#f5f5f5", lw=0)
+    ax1.add_feature(BORDERS, lw=0.5, color="gray")
+    ax1.gridlines(draw_labels=True, color="gray", alpha=0.5, ls="--")
+    ax1.coastlines(resolution="50m", lw=0.5, color="gray")
+
+    lon_values = [
+        network[x][x1][x2].lon
+        for x in range(len(network))
+        for x1 in range(len(network[x]))
+        for x2 in range(len(network[x][x1]))
+    ]
+    lat_values = [
+        network[x][x1][x2].lat
+        for x in range(len(network))
+        for x1 in range(len(network[x]))
+        for x2 in range(len(network[x][x1]))
+    ]
+    height_values = [
+        network[x][x1][x2].height / ft
+        for x in range(len(network))
+        for x1 in range(len(network[x]))
+        for x2 in range(len(network[x][x1]))
+    ]
+    distance_to_origin = [
+        LatLon(lat_values[i], lon_values[i], height_values[i]).distanceTo(
+            LatLon(origin_coord[0], origin_coord[1], origin_coord[2])
+        )
+        / nm
+        for i in range(len(lon_values))
+    ]
+
+    ax1.scatter(
+        lon_values,
+        lat_values,
+        # transform=ccrs.Geodetic(),
+        s=0.2,
+    )
+
+    ax2.scatter(
+        distance_to_origin,
+        height_values,
+        s=0.2,
+    )
+
+    # scatter airports
+    ax1.scatter(
+        origin_coord[1],
+        origin_coord[0],
+        c="darkgreen",
+        transform=ccrs.Geodetic(),
+        alpha=0.3,
+    )
+    ax1.scatter(
+        target_coord[1], target_coord[0], c="red", transform=ccrs.Geodetic(), alpha=0.3
+    )
+
+    plt.tight_layout()
+    plt.show()
+
+    if dir:
+        fig.savefig(f"{dir}/network points.png")
+    else:
+        fig.savefig("network points.png")
+
+
+def trajectory_on_map(df, windfield=None, ax=None, wind_sample=4):
+
+    lat1, lon1 = df.lat.iloc[0], df.lon.iloc[0]
+    lat2, lon2 = df.lat.iloc[-1], df.lon.iloc[-1]
+
+    latmin, latmax = min(lat1, lat2), max(lat1, lat2)
+    lonmin, lonmax = min(lon1, lon2), max(lon1, lon2)
+
+    if ax is None:
+        ax = plt.axes(
+            projection=ccrs.TransverseMercator(
+                central_longitude=df.lon.mean(), central_latitude=df.lat.mean()
+            )
+        )
+
+    ax.set_extent([lonmin - 4, lonmax + 4, latmin - 2, latmax + 2])
+    ax.add_feature(OCEAN, facecolor="#d1e0e0", zorder=-1, lw=0)
+    ax.add_feature(LAND, facecolor="#f5f5f5", lw=0)
+    ax.add_feature(BORDERS, lw=0.5, color="gray")
+    ax.gridlines(draw_labels=True, color="gray", alpha=0.5, ls="--")
+    ax.coastlines(resolution="50m", lw=0.5, color="gray")
+
+    if windfield is not None:
+        # get the closed altitude
+        h_max = df.alt.max() * aero.ft
+        fl = int(round(h_max / aero.ft / 100, -1))
+        idx = np.argmin(abs(windfield.h.unique() - h_max))
+        df_wind = (
+            windfield.query(f"h=={windfield.h.unique()[idx]}")
+            .query(f"longitude <= {lonmax + 2}")
+            .query(f"longitude >= {lonmin - 2}")
+            .query(f"latitude <= {latmax + 2}")
+            .query(f"latitude >= {latmin - 2}")
+        )
+
+        ax.barbs(
+            df_wind.longitude.values[::wind_sample],
+            df_wind.latitude.values[::wind_sample],
+            df_wind.u.values[::wind_sample],
+            df_wind.v.values[::wind_sample],
+            transform=ccrs.PlateCarree(),
+            color="k",
+            length=5,
+            lw=0.5,
+            label=f"Wind FL{fl}",
+        )
+
+    # great circle
+    ax.scatter(lon1, lat1, c="darkgreen", transform=ccrs.Geodetic())
+    ax.scatter(lon2, lat2, c="tab:red", transform=ccrs.Geodetic())
+
+    ax.plot(
+        [lon1, lon2],
+        [lat1, lat2],
+        label="Great Circle",
+        color="tab:red",
+        ls="--",
+        transform=ccrs.Geodetic(),
+    )
+
+    # trajectory
+    ax.plot(
+        df.lon,
+        df.lat,
+        color="tab:green",
+        transform=ccrs.Geodetic(),
+        linewidth=2,
+        marker=".",
+        label="Optimal",
+    )
+
+    ax.legend()
+
+    return plt
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/common_utils.py

 * *Ordering differences only*

```diff
@@ -1,160 +1,160 @@
-# -*- coding: utf-8 -*-
-"""
-Created on Tue May  3 12:09:06 2016 !!!
-Useful custom functions callable by many part of the projects
-@author: popo
-"""
-import collections
-import math
-import os
-
-import matplotlib.pyplot as plt
-import numpy as np
-
-import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.std_atm as std_atm
-
-
-def tree():
-    return collections.defaultdict(tree)
-
-
-def my_extend(l1, l2):
-    l = l1
-    l.extend(l2)
-    return l
-
-
-def round_float(value, modulo=1000):
-    n = int(round(float(value) / modulo))
-    return n * modulo
-
-
-def round_float_floor(value, modulo=1000):
-    n = int(math.floor(float(value) / modulo))
-    return n * modulo
-
-
-def is_iterable(element):
-    return isinstance(element, collections.Iterable)
-
-
-def convert(val, init="kg/min", target="lb/h"):
-    if init == target:
-        return val
-    if init == "kg/min" and target == "lb/h":
-        lb = 2.20462
-        return val * lb * 60
-    if init == "lb" and target == "kg":
-        lbtokg = 1.0 / 2.20462
-        return lbtokg * val
-    if init == "kg" and target == "lb":
-        kgtolb = 2.20462
-        return kgtolb * val
-    if init == "ft" and target == "m":
-        fttom = 0.3048
-        return val * fttom
-    if init == "m" and target == "ft":
-        mtoft = 1.0 / 0.3048
-        return val * mtoft
-    if init == "ft" and target == "hPa":
-        p0 = 1013.25
-        t0 = 288.15
-        alpha = 0.0065
-        g0 = 9.80665
-        r = 287.853
-        p1 = 226.32
-        t1 = 216.65
-        return np.where(
-            val > 36089,
-            p1 * np.exp(-g0 * (convert(val, "ft", "m") - 11000.0) / (r * t1)),
-            p0 * (1 - alpha / t0 * convert(val, "ft", "m")) ** (g0 / (alpha * r)),
-        )
-    if (init == "pa" or init == "Pa") and target == "ft":
-        return std_atm.press2alt(val, press_units=init.lower(), alt_units=target)
-    if init == "ft" and target == "Pa":
-        return 10.0**2 * convert(val, init="ft", target="hPa")
-    if init == "psia" and target == "Pa":
-        return val * 6894.75728
-    if init == "celsius" and target == "K":
-        return val + 273.15
-    if init == "K" and target == "celsius":
-        return val - 273.15
-    if init == "nm" and target == "km":
-        return 1.852 * val
-    if init == "km" and target == "nm":
-        return val / 1.852
-    if init == "m/s" and target == "kts":
-        return 1.94384 * val
-    if init == "kts" and target == "m/s":
-        return val / 1.94384
-    if init == "kl" and target == "kg":  # kl: kerosene liter
-        return val * 0.8201
-    if init == "kg" and target == "kl":
-        return val / 0.8201
-
-
-def get_regular_interval(l, n=100):
-    """Return a regular array of length n of a sorted iterable
-
-    :param l: A sorted iterable
-    :param n: Number of discrete value we want
-    :return: a sorted regular numpy array from l[0] to l[-1] with n step
-    :rtype: `numpy.array`
-    """
-    return np.linspace(l[0], l[-1], n)
-
-
-def intersect_interval(x, y):
-    """X and Y given by [low_bound, high_bound]"""
-    if len(x) < 2 or len(y) < 2 or x is None or y is None:
-        return []
-    lb = max(min(x), min(y))
-    hb = min(max(x), max(y))
-    return [lb, hb] if hb >= lb else []
-
-
-def convert_str_tuple_to_tuple(str_tuple, conv=int):
-    a = str_tuple.split(",")
-    a[0] = conv(a[0][1:])
-    a[1] = conv(a[1][1:-1])
-    return a[0], a[1]
-
-
-def convert_decimal_hour(hour):
-    seconds = hour * 3600
-    m, s = divmod(seconds, 60)
-    h, m = divmod(m, 60)
-    return "%d:%02d:%02d" % (h, m, s)
-
-
-def get_absolute_path(filename, relative_path):
-    return os.path.abspath(os.path.join(os.path.dirname(filename), relative_path))
-
-
-def get_absolute_path_from_rep(rep_name, relative_path):
-    return os.path.abspath(os.path.join(rep_name, relative_path))
-
-
-def monotonically_increasing(l):
-    return all(x < y for x, y in zip(l, l[1:]))
-
-
-def return_twin_axes(color_list=None, figsize=(10, 10)):
-    if color_list is None:
-        color_list = ["g", "r"]
-    f, ax1 = plt.subplots(1, figsize=figsize)
-    for tl in ax1.get_yticklabels():
-        tl.set_color(color_list[0])
-    ax2 = ax1.twinx()
-    for tl in ax2.get_yticklabels():
-        tl.set_color(color_list[1])
-    return f, ax1, ax2
-
-
-if __name__ == "__main__":
-    print(
-        [
-            (val, convert(val * 100, init="Pa", target="ft"))
-            for val in [1000, 500, 300, 250, 200, 100, 50]
-        ]
-    )
+# -*- coding: utf-8 -*-
+"""
+Created on Tue May  3 12:09:06 2016 !!!
+Useful custom functions callable by many part of the projects
+@author: popo
+"""
+import collections
+import math
+import os
+
+import matplotlib.pyplot as plt
+import numpy as np
+
+import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.std_atm as std_atm
+
+
+def tree():
+    return collections.defaultdict(tree)
+
+
+def my_extend(l1, l2):
+    l = l1
+    l.extend(l2)
+    return l
+
+
+def round_float(value, modulo=1000):
+    n = int(round(float(value) / modulo))
+    return n * modulo
+
+
+def round_float_floor(value, modulo=1000):
+    n = int(math.floor(float(value) / modulo))
+    return n * modulo
+
+
+def is_iterable(element):
+    return isinstance(element, collections.Iterable)
+
+
+def convert(val, init="kg/min", target="lb/h"):
+    if init == target:
+        return val
+    if init == "kg/min" and target == "lb/h":
+        lb = 2.20462
+        return val * lb * 60
+    if init == "lb" and target == "kg":
+        lbtokg = 1.0 / 2.20462
+        return lbtokg * val
+    if init == "kg" and target == "lb":
+        kgtolb = 2.20462
+        return kgtolb * val
+    if init == "ft" and target == "m":
+        fttom = 0.3048
+        return val * fttom
+    if init == "m" and target == "ft":
+        mtoft = 1.0 / 0.3048
+        return val * mtoft
+    if init == "ft" and target == "hPa":
+        p0 = 1013.25
+        t0 = 288.15
+        alpha = 0.0065
+        g0 = 9.80665
+        r = 287.853
+        p1 = 226.32
+        t1 = 216.65
+        return np.where(
+            val > 36089,
+            p1 * np.exp(-g0 * (convert(val, "ft", "m") - 11000.0) / (r * t1)),
+            p0 * (1 - alpha / t0 * convert(val, "ft", "m")) ** (g0 / (alpha * r)),
+        )
+    if (init == "pa" or init == "Pa") and target == "ft":
+        return std_atm.press2alt(val, press_units=init.lower(), alt_units=target)
+    if init == "ft" and target == "Pa":
+        return 10.0**2 * convert(val, init="ft", target="hPa")
+    if init == "psia" and target == "Pa":
+        return val * 6894.75728
+    if init == "celsius" and target == "K":
+        return val + 273.15
+    if init == "K" and target == "celsius":
+        return val - 273.15
+    if init == "nm" and target == "km":
+        return 1.852 * val
+    if init == "km" and target == "nm":
+        return val / 1.852
+    if init == "m/s" and target == "kts":
+        return 1.94384 * val
+    if init == "kts" and target == "m/s":
+        return val / 1.94384
+    if init == "kl" and target == "kg":  # kl: kerosene liter
+        return val * 0.8201
+    if init == "kg" and target == "kl":
+        return val / 0.8201
+
+
+def get_regular_interval(l, n=100):
+    """Return a regular array of length n of a sorted iterable
+
+    :param l: A sorted iterable
+    :param n: Number of discrete value we want
+    :return: a sorted regular numpy array from l[0] to l[-1] with n step
+    :rtype: `numpy.array`
+    """
+    return np.linspace(l[0], l[-1], n)
+
+
+def intersect_interval(x, y):
+    """X and Y given by [low_bound, high_bound]"""
+    if len(x) < 2 or len(y) < 2 or x is None or y is None:
+        return []
+    lb = max(min(x), min(y))
+    hb = min(max(x), max(y))
+    return [lb, hb] if hb >= lb else []
+
+
+def convert_str_tuple_to_tuple(str_tuple, conv=int):
+    a = str_tuple.split(",")
+    a[0] = conv(a[0][1:])
+    a[1] = conv(a[1][1:-1])
+    return a[0], a[1]
+
+
+def convert_decimal_hour(hour):
+    seconds = hour * 3600
+    m, s = divmod(seconds, 60)
+    h, m = divmod(m, 60)
+    return "%d:%02d:%02d" % (h, m, s)
+
+
+def get_absolute_path(filename, relative_path):
+    return os.path.abspath(os.path.join(os.path.dirname(filename), relative_path))
+
+
+def get_absolute_path_from_rep(rep_name, relative_path):
+    return os.path.abspath(os.path.join(rep_name, relative_path))
+
+
+def monotonically_increasing(l):
+    return all(x < y for x, y in zip(l, l[1:]))
+
+
+def return_twin_axes(color_list=None, figsize=(10, 10)):
+    if color_list is None:
+        color_list = ["g", "r"]
+    f, ax1 = plt.subplots(1, figsize=figsize)
+    for tl in ax1.get_yticklabels():
+        tl.set_color(color_list[0])
+    ax2 = ax1.twinx()
+    for tl in ax2.get_yticklabels():
+        tl.set_color(color_list[1])
+    return f, ax1, ax2
+
+
+if __name__ == "__main__":
+    print(
+        [
+            (val, convert(val * 100, init="Pa", target="ft"))
+            for val in [1000, 500, 300, 250, 200, 100, 50]
+        ]
+    )
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/get_weather_noaa.py

```diff
@@ -1,493 +1,494 @@
-import calendar
-import collections
-import datetime as datetime
-import logging
-import os
-import urllib.request as request
-from functools import reduce
-from typing import List, Optional
-
-import numpy as np
-
-from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools import (
-    std_atm as standard_atmosphere,
-)
-from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.GenericInterpolator import (
-    GenericWindInterpolator,
-)
-from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.parser_pygrib import (
-    GribPygribUniqueForecast,
-)
-from skdecide.utils import get_data_home
-
-logger = logging.getLogger(__name__)
-
-
-def tree():
-    return collections.defaultdict(tree)
-
-
-def get_absolute_path(filename, relative_path):
-    return os.path.abspath(os.path.join(os.path.dirname(filename), relative_path))
-
-
-def create_merged_matrix(list_files: List[str], params: Optional[List[str]]):
-    if params is None:
-        params = ["u", "v", "t", "r"]
-
-    def get_params(f, params_to_retrieve):
-        a = GribPygribUniqueForecast(
-            grib_path=os.path.dirname(f), grib_name=os.path.basename(f)
-        )
-        mats = list(
-            map(
-                lambda x: a.getParameterUniqueForecast(parameter=x, levels=None),
-                params_to_retrieve,
-            )
-        )
-        m = {}
-        list(map(lambda x: m.update(x), mats))
-        del a
-        return m
-
-    def merge(list_matrix):
-        merged_matrix = {k: {} for k in list_matrix[0]}
-        for k in merged_matrix:
-            for key in ["longs", "lats", "levels"]:
-                merged_matrix[k][key] = list_matrix[0][k][key]
-            merged_matrix[k]["times"] = []
-            merged_matrix[k]["values"] = []
-        for m in list_matrix:
-            for k in merged_matrix:
-                merged_matrix[k]["times"] += list(m[k]["times"])
-                merged_matrix[k]["values"] += [m[k]["values"][0]]
-        for k in merged_matrix:
-            merged_matrix[k]["times"] = np.array(merged_matrix[k]["times"])
-            merged_matrix[k]["values"] = np.array(merged_matrix[k]["values"])
-        return merged_matrix
-
-    result = merge(
-        list(map(lambda x: get_params(x, params_to_retrieve=params), list_files))
-    )
-    return result
-
-
-def get_weather_matrix(
-    year,
-    month,
-    day,
-    forecast,
-    save_to_npz=True,
-    delete_grib_from_local=True,
-    delete_npz_from_local=False,
-    download_grib=True,
-):
-    """
-    :param year:
-    :param month:
-    :param day:
-    :param forecast:
-    :return:
-    """
-    exportdir_grib = get_absolute_path(
-        __file__,
-        f"{get_data_home()}/weather/grib/"
-        + forecast
-        + "/"
-        + str(year)
-        + str(month)
-        + str(day),
-    )
-    exportdir_npz = get_absolute_path(
-        __file__,
-        f"{get_data_home()}/weather/npz/"
-        + forecast
-        + "/"
-        + str(year)
-        + str(month)
-        + str(day),
-    )
-    if not os.path.exists(exportdir_npz):
-        os.makedirs(exportdir_npz)
-    list_files = [
-        os.path.join(exportdir_npz, x) for x in os.listdir(exportdir_npz) if "npz" in x
-    ]
-    if len(list_files) > 0:
-        # In case you already have an npz locally
-        logger.info("You have the npz on your local computer")
-        p = np.load(list_files[0], allow_pickle=True)
-        if delete_npz_from_local:
-            os.remove(list_files[0])
-        return p
-    # The npz is not on S3 neither locally...
-    if not os.path.exists(exportdir_grib):
-        os.makedirs(exportdir_grib)
-    list_files = [os.path.join(exportdir_grib, x) for x in os.listdir(exportdir_grib)]
-    if len(list_files) >= 4:
-        logger.info("Grib found locally")
-    if len(list_files) == 0:
-        if not download_grib:
-            return {}
-        files, address = UrlGeneratorWithForecastLayer.get_list_of_url_forecast(
-            day=day, month=month, year=year, forecast=forecast
-        )
-        list_files = []
-        for i in range(len(files)):
-            print("Downloading : ", address[i])
-            try:
-                request.urlretrieve(
-                    address[i], filename=os.path.join(exportdir_grib, files[i])
-                )
-                list_files += [os.path.join(exportdir_grib, files[i])]
-            except Exception as e:
-                print(e)
-                pass
-        list_files = [
-            os.path.join(exportdir_grib, x) for x in os.listdir(exportdir_grib)
-        ]
-        if not len(list_files) > 0:
-            return {}
-    matrix = create_merged_matrix(list_files=list_files, params=["u", "v", "t", "r"])
-    if save_to_npz:
-        file_output = os.path.join(
-            exportdir_npz, str(year) + str(month) + str(day) + ".npz"
-        )
-        if not os.path.exists(os.path.dirname(file_output)):
-            if not os.path.dirname(file_output) == "":
-                os.makedirs(os.path.dirname(file_output))
-        np.savez_compressed(file_output, **matrix)
-    if delete_grib_from_local:
-        for l in list_files:
-            os.remove(l)
-    if delete_npz_from_local:
-        os.remove(
-            os.path.join(exportdir_npz, str(year) + str(month) + str(day) + ".npz")
-        )
-    return matrix
-
-
-class UrlGeneratorWithForecastLayer:
-    @staticmethod
-    def forecast_time(x):
-        return x[-13:-9]
-
-    @staticmethod
-    def get_date(x):
-        d = datetime.date(x[-22:-18], x[-18:-16], x[-16:-14])
-        return d
-
-    @staticmethod
-    def get_folder_name(x):
-        return x[-22:-14]
-
-    @staticmethod
-    def get_list_of_url(day, month, year, hours_prediction, hours_from_prediction):
-        files = [
-            "gfs_4_"
-            + year
-            + month
-            + day
-            + "_"
-            + hour_prediction
-            + "_"
-            + hour_from_prediction
-            + ".grb2"
-            for hour_prediction, hour_from_prediction in zip(
-                hours_prediction, hours_from_prediction
-            )
-        ]
-        return files, [
-            "https://www.ncei.noaa.gov/data/global-forecast-system/access/grid-004-0.5-degree/forecast/"
-            + year
-            + month
-            + "/"
-            + year
-            + month
-            + day
-            + "/"
-            + file
-            for file in files
-        ]
-
-    @staticmethod
-    def return_list_of_url():
-        years = ["2016", "2017", "2018"]
-        months = [
-            "01",
-            "02",
-            "03",
-            "04",
-            "05",
-            "06",
-            "07",
-            "08",
-            "09",
-            "10",
-            "11",
-            "12",
-        ]
-        all = [("31", "12", "2015")] + [
-            ("0" + str(d) if d < 10 else str(d), m, y)
-            for y in years
-            for m in months
-            for d in range(1, calendar.monthrange(int(y), int(m))[1] + 1)
-        ]
-        hours_prediction_0 = ["0000", "0000", "0000", "0000"]
-        hours_prediction_6 = ["0600", "0600", "0600", "0600"]
-        hours_prediction_12 = ["1200", "1200", "1200", "1200"]
-        hours_prediction_18 = ["1800", "1800", "1800", "1800"]
-        hours_from_prediction = ["000", "006", "012", "018"]
-        hours_prediction_obs = ["0000", "0600", "1200", "1800"]
-        hours_from_prediction_obs = ["000", "000", "000", "000"]
-        dict_files = {}
-        dict_files["forecast__0000"] = reduce(
-            lambda x, y: [
-                x[0]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
-                )[0],
-                x[1]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
-                )[1],
-            ],
-            all,
-            [[], []],
-        )[0][4:]
-        dict_files["forecast__0600"] = reduce(
-            lambda x, y: [
-                x[0]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
-                )[0],
-                x[1]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
-                )[1],
-            ],
-            all,
-            [[], []],
-        )[0][3:-1]
-        dict_files["forecast__1200"] = reduce(
-            lambda x, y: [
-                x[0]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
-                )[0],
-                x[1]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
-                )[1],
-            ],
-            all,
-            [[], []],
-        )[0][2:-2]
-        dict_files["forecast__1800"] = reduce(
-            lambda x, y: [
-                x[0]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
-                )[0],
-                x[1]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
-                )[1],
-            ],
-            all,
-            [[], []],
-        )[0][1:-3]
-
-        dict_files["nowcast"] = reduce(
-            lambda x, y: [
-                x[0]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_obs, hours_from_prediction_obs
-                )[0],
-                x[1]
-                + UrlGeneratorWithForecastLayer.get_list_of_url(
-                    y[0], y[1], y[2], hours_prediction_obs, hours_from_prediction_obs
-                )[1],
-            ],
-            all,
-            [[], []],
-        )[0][4:]
-        for k in dict_files:
-            print(dict_files[k])
-            print(len(dict_files[k]))
-
-    @staticmethod
-    def get_list_of_url_forecast(day, month, year, forecast):
-        years = [year]
-        months = [month]
-        all = [
-            ("0" + str(d) if d < 10 else str(d), m, y)
-            for y in years
-            for m in months
-            for d in [int(day)]
-        ]
-        if int(day) == 1:
-            if int(month) == 1:
-                add = [("31", "12", str(int(year) - 1))]
-            else:
-                add = [
-                    (
-                        str(calendar.monthrange(int(year), int(month) - 1)[1]),
-                        str(int(month) - 1),
-                        str(year),
-                    )
-                ]
-        else:
-            add = [
-                (
-                    "0" + str(int(day) - 1) if int(day) - 1 < 10 else str(int(day) - 1),
-                    str(month),
-                    str(year),
-                )
-            ]
-        all = add + all
-        hours_prediction_0 = ["0000", "0000", "0000", "0000"]
-        hours_prediction_6 = ["0600", "0600", "0600", "0600"]
-        hours_prediction_12 = ["1200", "1200", "1200", "1200"]
-        hours_prediction_18 = ["1800", "1800", "1800", "1800"]
-        hours_from_prediction = ["000", "006", "012", "018"]
-        hours_prediction_obs = ["0000", "0600", "1200", "1800"]
-        hours_from_prediction_obs = ["000", "000", "000", "000"]
-        if forecast == "forecast__0000":
-            p = reduce(
-                lambda x, y: [
-                    x[0]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
-                    )[0],
-                    x[1]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
-                    )[1],
-                ],
-                all,
-                [[], []],
-            )
-            return p[0][4:], p[1][4:]
-        if forecast == "forecast__0600":
-            p = reduce(
-                lambda x, y: [
-                    x[0]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
-                    )[0],
-                    x[1]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
-                    )[1],
-                ],
-                all,
-                [[], []],
-            )
-            return p[0][3:-1], p[1][3:-1]
-        if forecast == "forecast__1200":
-            p = reduce(
-                lambda x, y: [
-                    x[0]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
-                    )[0],
-                    x[1]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
-                    )[1],
-                ],
-                all,
-                [[], []],
-            )
-            return p[0][2:-2], p[1][2:-2]
-        if forecast == "forecast__1800":
-            p = reduce(
-                lambda x, y: [
-                    x[0]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
-                    )[0],
-                    x[1]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
-                    )[1],
-                ],
-                all,
-                [[], []],
-            )
-            return p[0][1:-3], p[1][1:-3]
-        if forecast == "nowcast":
-            p = reduce(
-                lambda x, y: [
-                    x[0]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0],
-                        y[1],
-                        y[2],
-                        hours_prediction_obs,
-                        hours_from_prediction_obs,
-                    )[0],
-                    x[1]
-                    + UrlGeneratorWithForecastLayer.get_list_of_url(
-                        y[0],
-                        y[1],
-                        y[2],
-                        hours_prediction_obs,
-                        hours_from_prediction_obs,
-                    )[1],
-                ],
-                all,
-                [[], []],
-            )
-            return p[0][4:], p[1][4:]
-
-    @staticmethod
-    def get_ensemble_noaa_forecast(day, month, year, forecast, id_forecast):
-        hours_from_prediction = ["000", "006", "012", "018", "024"]
-        if int(id_forecast) < 10:
-            id_forecast_t = "0" + id_forecast
-        else:
-            id_forecast_t = str(id_forecast)
-        files = [
-            "gens-a_2_"
-            + year
-            + month
-            + day
-            + "_"
-            + forecast
-            + "_"
-            + forc
-            + "_"
-            + id_forecast_t
-            + ".grb2"
-            for forc in hours_from_prediction
-        ]
-        files = [
-            "gens-b_3_"
-            + year
-            + month
-            + day
-            + "_"
-            + forecast
-            + "_"
-            + forc
-            + "_"
-            + id_forecast_t
-            + ".grb2"
-            for forc in hours_from_prediction
-        ]
-        # return files, ['https://nomads.ncdc.noaa.gov/data/gens/' + year + month + '/' + year + month + day + '/' + file
-        #               for file in files]
-        # https: // www.ncei.noaa.gov / thredds / dodsC / model - gefs - 003 / 202009 / 20200923 / gensanl - b_3_20200923_0600_000_20.grb2
-        return files, [
-            "https://www.ncei.noaa.gov/data/global-ensemble-forecast-system/access/1.0-degree-grid/"
-            + year
-            + month
-            + "/"
-            + year
-            + month
-            + day
-            + "/"
-            + file
-            for file in files
-        ]
+import calendar
+import collections
+import datetime as datetime
+import logging
+import os
+import urllib.request as request
+from functools import reduce
+from typing import List, Optional
+
+import numpy as np
+
+from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools import (
+    std_atm as standard_atmosphere,
+)
+from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.GenericInterpolator import (
+    GenericWindInterpolator,
+)
+from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.parser_pygrib import (
+    GribPygribUniqueForecast,
+)
+from skdecide.utils import get_data_home
+
+logger = logging.getLogger(__name__)
+
+
+def tree():
+    return collections.defaultdict(tree)
+
+
+def get_absolute_path(filename, relative_path):
+    return os.path.abspath(os.path.join(os.path.dirname(filename), relative_path))
+
+
+def create_merged_matrix(list_files: List[str], params: Optional[List[str]]):
+    if params is None:
+        params = ["u", "v", "t", "r"]
+
+    def get_params(f, params_to_retrieve):
+        a = GribPygribUniqueForecast(
+            grib_path=os.path.dirname(f), grib_name=os.path.basename(f)
+        )
+        mats = list(
+            map(
+                lambda x: a.getParameterUniqueForecast(parameter=x, levels=None),
+                params_to_retrieve,
+            )
+        )
+        m = {}
+        list(map(lambda x: m.update(x), mats))
+        del a
+        return m
+
+    def merge(list_matrix):
+        merged_matrix = {k: {} for k in list_matrix[0]}
+        for k in merged_matrix:
+            for key in ["longs", "lats", "levels"]:
+                merged_matrix[k][key] = list_matrix[0][k][key]
+            merged_matrix[k]["times"] = []
+            merged_matrix[k]["values"] = []
+        for m in list_matrix:
+            for k in merged_matrix:
+                merged_matrix[k]["times"] += list(m[k]["times"])
+                merged_matrix[k]["values"] += [m[k]["values"][0]]
+        for k in merged_matrix:
+            merged_matrix[k]["times"] = np.array(merged_matrix[k]["times"])
+            merged_matrix[k]["values"] = np.array(merged_matrix[k]["values"])
+        return merged_matrix
+
+    result = merge(
+        list(map(lambda x: get_params(x, params_to_retrieve=params), list_files))
+    )
+    return result
+
+
+def get_weather_matrix(
+    year,
+    month,
+    day,
+    forecast,
+    save_to_npz=True,
+    delete_grib_from_local=True,
+    delete_npz_from_local=False,
+    download_grib=True,
+):
+    """
+    :param year:
+    :param month:
+    :param day:
+    :param forecast:
+    :return:
+    """
+    exportdir_grib = get_absolute_path(
+        __file__,
+        f"{get_data_home()}/weather/grib/"
+        + forecast
+        + "/"
+        + str(year)
+        + str(month)
+        + str(day),
+    )
+    exportdir_npz = get_absolute_path(
+        __file__,
+        f"{get_data_home()}/weather/npz/"
+        + forecast
+        + "/"
+        + str(year)
+        + str(month)
+        + str(day),
+    )
+    if not os.path.exists(exportdir_npz):
+        os.makedirs(exportdir_npz)
+    list_files = [
+        os.path.join(exportdir_npz, x) for x in os.listdir(exportdir_npz) if "npz" in x
+    ]
+    if len(list_files) > 0:
+        # In case you already have an npz locally
+        logger.info("You have the npz on your local computer")
+        p = np.load(list_files[0], allow_pickle=True)
+        if delete_npz_from_local:
+            os.remove(list_files[0])
+        return p
+    # The npz is not on S3 neither locally...
+    if not os.path.exists(exportdir_grib):
+        os.makedirs(exportdir_grib)
+    list_files = [os.path.join(exportdir_grib, x) for x in os.listdir(exportdir_grib)]
+    if len(list_files) >= 4:
+        logger.info("Grib found locally")
+    if len(list_files) == 0:
+        if not download_grib:
+            return {}
+        files, address = UrlGeneratorWithForecastLayer.get_list_of_url_forecast(
+            day=day, month=month, year=year, forecast=forecast
+        )
+        list_files = []
+        for i in range(len(files)):
+            print("Downloading : ", address[i])
+            try:
+                request.urlretrieve(
+                    address[i], filename=os.path.join(exportdir_grib, files[i])
+                )
+                list_files += [os.path.join(exportdir_grib, files[i])]
+            except Exception as e:
+                print(e)
+                pass
+        list_files = [
+            os.path.join(exportdir_grib, x) for x in os.listdir(exportdir_grib)
+        ]
+        if not len(list_files) > 0:
+            return {}
+    matrix = create_merged_matrix(list_files=list_files, params=["u", "v", "t", "r"])
+    if save_to_npz:
+        file_output = os.path.join(
+            exportdir_npz, str(year) + str(month) + str(day) + ".npz"
+        )
+        if not os.path.exists(os.path.dirname(file_output)):
+            if not os.path.dirname(file_output) == "":
+                os.makedirs(os.path.dirname(file_output))
+        np.savez_compressed(file_output, **matrix)
+    if delete_grib_from_local:
+        for l in list_files:
+            os.remove(l)
+    if delete_npz_from_local:
+        os.remove(
+            os.path.join(exportdir_npz, str(year) + str(month) + str(day) + ".npz")
+        )
+
+    return matrix
+
+
+class UrlGeneratorWithForecastLayer:
+    @staticmethod
+    def forecast_time(x):
+        return x[-13:-9]
+
+    @staticmethod
+    def get_date(x):
+        d = datetime.date(x[-22:-18], x[-18:-16], x[-16:-14])
+        return d
+
+    @staticmethod
+    def get_folder_name(x):
+        return x[-22:-14]
+
+    @staticmethod
+    def get_list_of_url(day, month, year, hours_prediction, hours_from_prediction):
+        files = [
+            "gfs_4_"
+            + year
+            + month
+            + day
+            + "_"
+            + hour_prediction
+            + "_"
+            + hour_from_prediction
+            + ".grb2"
+            for hour_prediction, hour_from_prediction in zip(
+                hours_prediction, hours_from_prediction
+            )
+        ]
+        return files, [
+            "https://www.ncei.noaa.gov/data/global-forecast-system/access/grid-004-0.5-degree/forecast/"
+            + year
+            + month
+            + "/"
+            + year
+            + month
+            + day
+            + "/"
+            + file
+            for file in files
+        ]
+
+    @staticmethod
+    def return_list_of_url():
+        years = ["2016", "2017", "2018"]
+        months = [
+            "01",
+            "02",
+            "03",
+            "04",
+            "05",
+            "06",
+            "07",
+            "08",
+            "09",
+            "10",
+            "11",
+            "12",
+        ]
+        all = [("31", "12", "2015")] + [
+            ("0" + str(d) if d < 10 else str(d), m, y)
+            for y in years
+            for m in months
+            for d in range(1, calendar.monthrange(int(y), int(m))[1] + 1)
+        ]
+        hours_prediction_0 = ["0000", "0000", "0000", "0000"]
+        hours_prediction_6 = ["0600", "0600", "0600", "0600"]
+        hours_prediction_12 = ["1200", "1200", "1200", "1200"]
+        hours_prediction_18 = ["1800", "1800", "1800", "1800"]
+        hours_from_prediction = ["000", "006", "012", "018"]
+        hours_prediction_obs = ["0000", "0600", "1200", "1800"]
+        hours_from_prediction_obs = ["000", "000", "000", "000"]
+        dict_files = {}
+        dict_files["forecast__0000"] = reduce(
+            lambda x, y: [
+                x[0]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
+                )[0],
+                x[1]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
+                )[1],
+            ],
+            all,
+            [[], []],
+        )[0][4:]
+        dict_files["forecast__0600"] = reduce(
+            lambda x, y: [
+                x[0]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
+                )[0],
+                x[1]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
+                )[1],
+            ],
+            all,
+            [[], []],
+        )[0][3:-1]
+        dict_files["forecast__1200"] = reduce(
+            lambda x, y: [
+                x[0]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
+                )[0],
+                x[1]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
+                )[1],
+            ],
+            all,
+            [[], []],
+        )[0][2:-2]
+        dict_files["forecast__1800"] = reduce(
+            lambda x, y: [
+                x[0]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
+                )[0],
+                x[1]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
+                )[1],
+            ],
+            all,
+            [[], []],
+        )[0][1:-3]
+
+        dict_files["nowcast"] = reduce(
+            lambda x, y: [
+                x[0]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_obs, hours_from_prediction_obs
+                )[0],
+                x[1]
+                + UrlGeneratorWithForecastLayer.get_list_of_url(
+                    y[0], y[1], y[2], hours_prediction_obs, hours_from_prediction_obs
+                )[1],
+            ],
+            all,
+            [[], []],
+        )[0][4:]
+        for k in dict_files:
+            print(dict_files[k])
+            print(len(dict_files[k]))
+
+    @staticmethod
+    def get_list_of_url_forecast(day, month, year, forecast):
+        years = [year]
+        months = [month]
+        all = [
+            ("0" + str(d) if d < 10 else str(d), m, y)
+            for y in years
+            for m in months
+            for d in [int(day)]
+        ]
+        if int(day) == 1:
+            if int(month) == 1:
+                add = [("31", "12", str(int(year) - 1))]
+            else:
+                add = [
+                    (
+                        str(calendar.monthrange(int(year), int(month) - 1)[1]),
+                        str(int(month) - 1),
+                        str(year),
+                    )
+                ]
+        else:
+            add = [
+                (
+                    "0" + str(int(day) - 1) if int(day) - 1 < 10 else str(int(day) - 1),
+                    str(month),
+                    str(year),
+                )
+            ]
+        all = add + all
+        hours_prediction_0 = ["0000", "0000", "0000", "0000"]
+        hours_prediction_6 = ["0600", "0600", "0600", "0600"]
+        hours_prediction_12 = ["1200", "1200", "1200", "1200"]
+        hours_prediction_18 = ["1800", "1800", "1800", "1800"]
+        hours_from_prediction = ["000", "006", "012", "018"]
+        hours_prediction_obs = ["0000", "0600", "1200", "1800"]
+        hours_from_prediction_obs = ["000", "000", "000", "000"]
+        if forecast == "forecast__0000":
+            p = reduce(
+                lambda x, y: [
+                    x[0]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
+                    )[0],
+                    x[1]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_0, hours_from_prediction
+                    )[1],
+                ],
+                all,
+                [[], []],
+            )
+            return p[0][4:], p[1][4:]
+        if forecast == "forecast__0600":
+            p = reduce(
+                lambda x, y: [
+                    x[0]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
+                    )[0],
+                    x[1]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_6, hours_from_prediction
+                    )[1],
+                ],
+                all,
+                [[], []],
+            )
+            return p[0][3:-1], p[1][3:-1]
+        if forecast == "forecast__1200":
+            p = reduce(
+                lambda x, y: [
+                    x[0]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
+                    )[0],
+                    x[1]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_12, hours_from_prediction
+                    )[1],
+                ],
+                all,
+                [[], []],
+            )
+            return p[0][2:-2], p[1][2:-2]
+        if forecast == "forecast__1800":
+            p = reduce(
+                lambda x, y: [
+                    x[0]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
+                    )[0],
+                    x[1]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0], y[1], y[2], hours_prediction_18, hours_from_prediction
+                    )[1],
+                ],
+                all,
+                [[], []],
+            )
+            return p[0][1:-3], p[1][1:-3]
+        if forecast == "nowcast":
+            p = reduce(
+                lambda x, y: [
+                    x[0]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0],
+                        y[1],
+                        y[2],
+                        hours_prediction_obs,
+                        hours_from_prediction_obs,
+                    )[0],
+                    x[1]
+                    + UrlGeneratorWithForecastLayer.get_list_of_url(
+                        y[0],
+                        y[1],
+                        y[2],
+                        hours_prediction_obs,
+                        hours_from_prediction_obs,
+                    )[1],
+                ],
+                all,
+                [[], []],
+            )
+            return p[0][4:], p[1][4:]
+
+    @staticmethod
+    def get_ensemble_noaa_forecast(day, month, year, forecast, id_forecast):
+        hours_from_prediction = ["000", "006", "012", "018", "024"]
+        if int(id_forecast) < 10:
+            id_forecast_t = "0" + id_forecast
+        else:
+            id_forecast_t = str(id_forecast)
+        files = [
+            "gens-a_2_"
+            + year
+            + month
+            + day
+            + "_"
+            + forecast
+            + "_"
+            + forc
+            + "_"
+            + id_forecast_t
+            + ".grb2"
+            for forc in hours_from_prediction
+        ]
+        files = [
+            "gens-b_3_"
+            + year
+            + month
+            + day
+            + "_"
+            + forecast
+            + "_"
+            + forc
+            + "_"
+            + id_forecast_t
+            + ".grb2"
+            for forc in hours_from_prediction
+        ]
+        # return files, ['https://nomads.ncdc.noaa.gov/data/gens/' + year + month + '/' + year + month + day + '/' + file
+        #               for file in files]
+        # https: // www.ncei.noaa.gov / thredds / dodsC / model - gefs - 003 / 202009 / 20200923 / gensanl - b_3_20200923_0600_000_20.grb2
+        return files, [
+            "https://www.ncei.noaa.gov/data/global-ensemble-forecast-system/access/1.0-degree-grid/"
+            + year
+            + month
+            + "/"
+            + year
+            + month
+            + day
+            + "/"
+            + file
+            for file in files
+        ]
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/GenericInterpolator.py

```diff
@@ -1,622 +1,645 @@
-import os
-from abc import ABC, abstractmethod
-from typing import Union
-
-import cartopy.crs as ccrs
-import matplotlib.pyplot as plt
-import numpy as np
-
-import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.common_utils as Toolbox
-import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.intergrid as intergrid
-import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.std_atm as std_atm
-from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.WeatherInterpolator import (
-    WeatherInterpolator,
-)
-
-
-class GenericInterpolator(ABC):
-    @abstractmethod
-    def interpol_field(self, X, **kwargs):
-        """
-        Interpol one field that is present in interpolators for array of 4d points
-
-        :param X: array of points [time (in s), alt (in ft), lat, long]
-        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
-        :return: array of interpolated values
-        """
-        ...
-
-    @abstractmethod
-    def render(self, ax, **kwargs):
-        ...
-
-
-def guess_axes(
-    values: np.ndarray,
-    lats: np.ndarray,
-    longs: np.ndarray,
-    levels: np.ndarray,
-    times: np.ndarray,
-):
-    ndims = values.ndim
-    shape = values.shape
-    if ndims == 3:
-        in_theory = ["times", "lats", "longs"]
-    if ndims == 4:
-        in_theory = ["times", "levels", "lats", "longs"]
-    if ndims == 5:
-        in_theory = ["times", "levels", "ensemble", "lats", "longs"]
-    d = {"times": times, "levels": levels, "lats": lats, "longs": longs}
-    l = {
-        "times": len(times),
-        "levels": len(levels),
-        "lats": len(lats),
-        "longs": len(longs),
-    }
-    for i in range(ndims):
-        s = shape[i]
-        if in_theory[i] != "ensemble":
-            if s != len(d[in_theory[i]]):
-                candidate = [t for t in l if l[t] == s]
-                if len(candidate) > 0:
-                    in_theory[i] = candidate[0]
-                else:
-                    in_theory[i] = "ensemble"
-                    d["ensemble"] = range(s)
-        else:
-            d["ensemble"] = range(s)
-    return in_theory, [d[x] for x in in_theory]
-
-
-class GenericEnsembleInterpolator(GenericInterpolator):
-    """
-    Class used to store weather data, interpolate and plot weather forecast from .npz files
-    """
-
-    def __init__(
-        self, file_npz, time_cut_index=None, fields=None, time_shift_s=0.0, order=1
-    ):
-        """
-        Stores the weather data and build the interpolators on grid.
-        """
-        # Files Loading
-        self.time_cut_index = time_cut_index
-        self.axes = {}
-        # self._auto_lock = Lock()
-        self.time_shift_s = time_shift_s
-        if isinstance(file_npz, (str, np.lib.npyio.NpzFile)):
-            self.datas = (
-                np.load(file_npz, allow_pickle=True)
-                if isinstance(file_npz, str)
-                else file_npz
-            )
-            if fields is None:
-                fields = self.datas.keys()
-            else:
-                fields = [f for f in fields if f in list(self.datas.keys())]
-            self.datas.allow_pickle = True
-            items = {var: self.datas[var].item() for var in fields}
-            self.lat_dict = {var: items[var]["lats"] for var in items}
-            self.long_dict = {
-                var: items[var]["longs"]
-                if "longs" in items[var]
-                else items[var]["lons"]
-                for var in items
-            }
-            self.levels_dict = {
-                var: items[var]["levels"] if "levels" in items[var] else [200.0]
-                for var in items
-            }
-            self.time_dict = {
-                var: items[var]["times"]
-                if self.time_cut_index is None
-                else items[var]["times"][
-                    : min(self.time_cut_index, len(items[var]["times"]))
-                ]
-                for var in items
-            }
-            if time_shift_s != 0.0:
-                for v in self.time_dict:
-                    self.time_dict[v] += time_shift_s
-            self.values = {var: items[var]["values"] for var in items}
-            if self.time_cut_index is not None:
-                index_cut = min(
-                    self.time_cut_index,
-                    len(self.time_dict[list(self.time_dict.keys())[0]]),
-                )
-                for var in self.values:
-                    self.values[var] = self.values[var][:index_cut, :, :, :]
-        elif isinstance(
-            file_npz, dict
-        ):  # Already loaded data in a dict (directly from parseWeather indeed)
-            self.datas = file_npz
-            if fields is None:
-                fields = self.datas.keys()
-            else:
-                fields = [f for f in fields if f in list(self.datas.keys())]
-            if fields is None:
-                fields = self.datas.keys()
-            else:
-                fields = [f for f in fields if f in list(self.datas.keys())]
-            # self.datas.allow_pickle = True
-            items = {var: self.datas[var] for var in fields}
-            self.lat_dict = {var: items[var]["lats"] for var in fields}
-            self.long_dict = {
-                var: items[var]["longs"]
-                if "longs" in items[var]
-                else items[var]["lons"]
-                for var in fields
-            }
-            self.levels_dict = {
-                var: items[var]["levels"] if "levels" in items[var] else [200.0]
-                for var in fields
-            }
-            self.time_dict = {var: items[var]["times"] for var in fields}
-            if time_shift_s != 0.0:
-                for v in self.time_dict:
-                    self.time_dict[v] += time_shift_s
-            self.values = {var: items[var]["values"] for var in fields}
-            # for var in self.lat_dict:
-            #     print(self.lat_dict[var].shape, "lats")
-            #     print(self.long_dict[var].shape, "long")
-            #     print(self.levels_dict[var].shape, "levels")
-            #     print(self.time_dict[var].shape, "time")
-            #     print(self.values[var].shape, "values")
-
-        one_field = list(self.values.keys())[0]
-        for feat in self.lat_dict:
-            if self.lat_dict[feat][-1] < self.lat_dict[feat][0]:
-                self.lat_dict[feat] = self.lat_dict[feat][::-1]
-                if self.values[feat].ndim == 4:
-                    self.values[feat] = self.values[feat][:, :, ::-1, :]
-                elif self.values[feat].ndim == 5:
-                    self.values[feat] = self.values[feat][:, :, :, ::-1, :]
-        self.interpol_dict = {}
-        for var in self.values:
-            if len(self.levels_dict[var]) == 0 or (len(self.levels_dict[var]) == 1):
-                self.levels_dict[var] = np.array([30000])
-            # print(var, self.values[var].shape)
-            axes = guess_axes(
-                self.values[var],
-                self.lat_dict[var],
-                self.long_dict[var],
-                self.levels_dict[var],
-                self.time_dict[var],
-            )
-            self.axes[var] = axes
-            self.interpol_dict[var] = intergrid.Intergrid(
-                self.values[var],
-                lo=[min(axes[1][i]) for i in range(len(axes[1]))],
-                hi=[max(axes[1][i]) for i in range(len(axes[1]))],
-                maps=axes[1],
-                verbose=False,
-                copy=True,
-                order=order,
-            )
-
-    def add_new_field(self, origin_field, operation, axis, new_field):
-        values = self.values[origin_field]
-        new_values = operation(values, axis=axis)
-        self.lat_dict[new_field] = self.lat_dict[origin_field]
-        self.long_dict[new_field] = self.long_dict[origin_field]
-        self.levels_dict[new_field] = self.levels_dict[origin_field]
-        self.time_dict[new_field] = self.time_dict[origin_field]
-        self.values[new_field] = new_values
-        axes = guess_axes(
-            self.values[new_field],
-            self.lat_dict[new_field],
-            self.long_dict[new_field],
-            self.levels_dict[new_field],
-            self.time_dict[new_field],
-        )
-        self.axes[new_field] = axes
-        self.interpol_dict[new_field] = intergrid.Intergrid(
-            self.values[new_field],
-            lo=[min(axes[1][i]) for i in range(len(axes[1]))],
-            hi=[max(axes[1][i]) for i in range(len(axes[1]))],
-            maps=axes[1],
-            verbose=False,
-            copy=True,
-            order=1,
-        )
-
-    def add_new_field_matrix(self, values, axes_values, new_field):
-        self.values[new_field] = values
-        self.axes[new_field] = axes_values
-        self.interpol_dict[new_field] = intergrid.Intergrid(
-            self.values[new_field],
-            lo=[min(axes_values[i]) for i in range(len(axes_values))],
-            hi=[max(axes_values[i]) for i in range(len(axes_values))],
-            maps=axes_values,
-            verbose=False,
-            copy=True,
-            order=1,
-        )
-
-    def interpol_field(self, X, field="CONVEXION"):
-        """
-        Interpol one field that is present in interpolators for array of 4d points
-
-        :param X: array of points [time (in s), alt (in ft), lat, long], or [time (in s), alt (in ft), id-ensemble,
-                                                                             lat, long]
-        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
-        :return: array of interpolated values
-        """
-        # with self._auto_lock:
-        return self.interpol_dict[field](X)
-
-    def transform_long(self, long):
-        """
-        [Deprecated] should be replaced by modulo function...
-
-        :param long: array of longitudes
-        :return: array of longitude put in positive domain (modulo 360.)
-        """
-        return long
-        # return np.where(long < 0, 360+long, long)
-
-    def plot_field(
-        self,
-        field="issr",
-        alt=35000.0,
-        t: Union[float, np.ndarray] = 0.0,
-        n_lat=180,
-        n_long=720,
-        ax=None,
-    ):
-        # plot the entire interpolate field
-        # p = alt2press(alt)
-        times = [t]
-        n_time = 1
-        if Toolbox.is_iterable(t):
-            times = t
-            n_time = len(t)
-        down_long = min(self.long_dict[field])
-        up_long = max(self.long_dict[field])
-        down_lat = min(self.lat_dict[field])
-        up_lat = max(self.lat_dict[field])
-        if ax is None:
-            fig, ax = plt.subplots(1, figsize=(8, 10))
-            ax = plt.axes(projection=ccrs.PlateCarree())
-            ax.stock_img()
-            m = ax
-        else:
-            m = ax
-        range_lat = np.linspace(down_lat, up_lat, n_lat)
-        range_long = np.linspace(down_long, up_long, n_long)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        range_long = self.transform_long(range_long)
-        if self.values[field].ndim == 4:
-            values = np.array(
-                [
-                    [time, alt, range_lat[i], range_long[j]]
-                    for i in range(n_lat)
-                    for j in range(n_long)
-                    for time in times
-                ]
-            )
-        elif self.values[field].ndim == 3:
-            values = np.array(
-                [
-                    [time, range_lat[i], range_long[j]]
-                    for i in range(n_lat)
-                    for j in range(n_long)
-                    for time in times
-                ]
-            )
-        Ut = np.resize(self.interpol_dict[field](values), (n_lat, n_long, n_time))
-        i = 0
-        cs = m.contourf(
-            x,
-            y,
-            Ut[:, :, i],
-            20,
-            extent=[down_long, up_long, down_lat, up_lat],
-            alpha=0.5,
-            zorder=2,
-        )
-        plt.title("time " + str(times[i]))
-        plt.draw()
-        plt.pause(0.1)
-        for i in range(1, n_time):
-            for coll in cs.collections:
-                plt.gca().collections.remove(coll)
-            cs = m.contourf(
-                x,
-                y,
-                Ut[:, :, i],
-                20,
-                extent=[down_long, up_long, down_lat, up_lat],
-                alpha=0.5,
-                zorder=2,
-            )
-            plt.title("time : " + str(times[i]))
-            plt.draw()
-            plt.pause(1)
-        return m
-
-    def plot_field_5d(
-        self,
-        field="CONVECTION",
-        alt=35000.0,
-        t: Union[float, np.ndarray] = 0.0,
-        n_lat=180,
-        index_forecast=0,
-        n_long=720,
-        ax=None,
-        save=False,
-        folder="",
-        tag_file="weath",
-    ):
-        # plot the entire interpolate field
-        # p = alt2press(alt)
-        times = [t]
-        n_time = 1
-        if Toolbox.is_iterable(t):
-            times = t
-            n_time = len(t)
-        down_long = min(self.long_dict[field])
-        up_long = max(self.long_dict[field])
-        down_lat = min(self.lat_dict[field])
-        up_lat = max(self.lat_dict[field])
-        if ax is None:
-            fig, ax = plt.subplots(1, figsize=(8, 10))
-            ax = plt.axes(projection=ccrs.PlateCarree())
-            ax.stock_img()
-            ax.set_xlim([down_long, up_long])
-            ax.set_ylim([down_lat, up_lat])
-            m = ax
-        else:
-            m = ax
-        range_lat = np.linspace(down_lat, up_lat, n_lat)
-        range_long = np.linspace(down_long, up_long, n_long)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        range_long = self.transform_long(range_long)
-        values = np.array(
-            [
-                [time, alt, index_forecast, range_lat[i], range_long[j]]
-                for i in range(n_lat)
-                for j in range(n_long)
-                for time in times
-            ]
-        )
-
-        Ut = np.resize(self.interpol_dict[field](values), (n_lat, n_long, n_time))
-        i = 0
-        cs = ax.contour(
-            x,
-            y,
-            Ut[:, :, i],
-            extent=[down_long, up_long, down_lat, up_lat],
-            alpha=0.9,
-            zorder=2,
-        )
-        # cs = ax.imshow(Ut[:, :, i],
-        #               extent=[down_long, up_long, down_lat, up_lat])
-        plt.title("time " + str(times[i]))
-        plt.draw()
-        if save:
-            j = 0
-            t = "0" * (4 - len(str(j))) + str(j)
-            plt.savefig(os.path.join(folder, t + "_" + tag_file + ".png"))
-        plt.pause(0.1)
-        for i in range(1, n_time):
-            for coll in cs.collections:
-                plt.gca().collections.remove(coll)
-            ##cs.clear()
-            # cs.set_data(Ut[:, :, i])
-            cs = ax.contour(
-                x,
-                y,
-                Ut[:, :, i],
-                extent=[down_long, up_long, down_lat, up_lat],
-                alpha=0.9,
-                zorder=2,
-            )
-            plt.title("time : " + str(times[i]))
-            plt.draw()
-            if save:
-                j += 1
-                t = "0" * (4 - len(str(j))) + str(j)
-                plt.savefig(os.path.join(folder, t + "_" + tag_file + ".png"))
-            plt.pause(0.1)
-        return m
-
-    def render(self, ax, **kwargs):
-        if ax is None:
-            fig, ax = plt.subplots(1, figsize=(8, 10))
-            ax = plt.axes(projection=ccrs.PlateCarree())
-            ax.stock_img()
-        else:
-            ax = ax
-        keys = list(self.long_dict.keys())
-        longs = self.long_dict[keys[0]]
-        lats = self.lat_dict[keys[0]]
-        dict_params = kwargs.get("kwargs", {})
-        try:
-            ax.imshow(
-                self.values[dict_params["convexion_field"]][
-                    0, 0, dict_params.get("index_forecast", 0), :, :
-                ],
-                cmap="hot",
-                extent=[min(longs), max(longs), min(lats), max(lats)],
-                interpolation="nearest",
-                alpha=0.2,
-            )
-        except:
-            pass
-
-
-class GenericWindInterpolator(GenericEnsembleInterpolator, WeatherInterpolator):
-    """
-    Class used to store weather data, interpolate and plot weather forecast from .npz files
-    """
-
-    def __init__(
-        self, file_npz, time_cut_index=None, fields=None, order_interp=1, time_shift_s=0
-    ):
-        """
-        Stores the weather data and build the interpolators on grid.
-        """
-        super().__init__(
-            file_npz, time_cut_index, fields=fields, time_shift_s=time_shift_s
-        )
-        if "U" not in self.values:
-            ufield = "UGRD"
-            vfield = "VGRD"
-        else:
-            ufield = "U"
-            vfield = "V"
-        self.norm_wind = np.sqrt(
-            np.square(self.values[ufield]) + np.square(self.values[vfield])
-        )
-        self.angle_wind = np.arctan2(self.values[vfield], self.values[ufield])
-        self.interpol_dict["norm-wind"] = intergrid.Intergrid(
-            self.norm_wind,
-            lo=[min(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
-            hi=[max(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
-            maps=self.axes[ufield][1],
-            copy=True,
-            verbose=False,
-            order=1,
-        )
-        self.interpol_dict["argument-wind"] = intergrid.Intergrid(
-            self.angle_wind,
-            lo=[min(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
-            hi=[max(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
-            maps=self.axes[ufield][1],
-            verbose=False,
-            copy=True,
-            order=1,
-        )
-        self.long_dict["norm-wind"] = self.long_dict[ufield]
-        self.lat_dict["argument-wind"] = self.lat_dict[ufield]
-        self.long_dict["argument-wind"] = self.long_dict[ufield]
-        self.lat_dict["norm-wind"] = self.lat_dict[ufield]
-
-    def transform_long(self, long):
-        return long
-
-    def interpol_wind_classic(self, lat, longi, alt=35000.0, t=0.0, index_forecast=0):
-        # with self._auto_lock:
-        p = std_atm.alt2press(alt, alt_units="ft", press_units="hpa")
-        if len(self.axes["U"][1]) == 5:
-            norm = self.interpol_dict["norm-wind"]([t, p, index_forecast, lat, longi])
-            arg = self.interpol_dict["argument-wind"](
-                [t, p, index_forecast, lat, longi]
-            )
-            result = norm * np.array([np.cos(arg), np.sin(arg)])
-            return [norm, arg, result]
-        if len(self.axes["U"][1]) == 4:
-            norm = self.interpol_dict["norm-wind"]([t, p, lat, longi])
-            arg = self.interpol_dict["argument-wind"]([t, p, lat, longi])
-            result = norm * np.array([np.cos(arg), np.sin(arg)])
-            return [norm, arg, result]
-
-    def interpol_wind(self, X):
-        """
-        Interpol wind for an array of 4D points
-
-        :param X: array of points [time (in s), alt (in ft), lat, long]
-        :return: wind vector.
-        """
-        # with self._auto_lock:
-        arg = self.interpol_dict["argument-wind"](X)
-        return self.interpol_dict["norm-wind"](X) * np.array(
-            [[np.cos(arg), np.sin(arg)]]
-        )
-
-    def plot_wind(
-        self,
-        alt=35000.0,
-        down_long=-180.0,
-        up_long=180.0,
-        down_lat=-90.0,
-        up_lat=90.0,
-        t=0.0,
-        n_lat=180,
-        n_long=720,
-        index_forecast=0,
-        plot_wind=False,
-        ax=None,
-    ):
-        """
-        Plot the wind for a given coordinates window for a given altitude and for one time/or range of time
-
-        :param alt: altitude couch to plot (in ft)
-        :param down_long: min longitude
-        :param up_long: max longitude
-        :param down_lat: min latitude
-        :param up_lat: max latitude
-        :param t: value of time step (in second) or list/array of time step (in s)
-        :type t: float or iterable
-        :param n_lat: number of latitude discretized steps
-        :param n_long: number of longitude discretized steps
-        :param plot_wind: plot the vector field
-        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
-        """
-        times = [t]
-        n_time = 1
-        if Toolbox.is_iterable(t):
-            times = t
-            n_time = len(t)
-        if ax is None:
-            fig, ax = plt.subplots(
-                1, 1, figsize=(10, 5), subplot_kw={"projection": ccrs.PlateCarree()}
-            )
-            ax.stock_img()
-        range_lat = np.linspace(down_lat, up_lat, n_lat)
-        range_long = np.linspace(down_long, up_long, n_long)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        range_long = self.transform_long(range_long)
-        values = np.array(
-            [
-                [time, alt, index_forecast, range_lat[i], range_long[j]]
-                for i in range(n_lat)
-                for j in range(n_long)
-                for time in times
-            ]
-        )
-        res = self.interpol_wind(values)
-        Ut = np.resize(res[0, 0, :], (n_lat, n_long, n_time))
-        Vt = np.resize(res[0, 1, :], (n_lat, n_long, n_time))
-        Nt = np.sqrt(np.square(Ut) + np.square(Vt))
-        # Nt = np.reshape(self.interpol_field(values, field='norm-wind'), (n_lat, n_long, n_time))
-
-        i = 0
-        CS = ax.contourf(x, y, Nt[:, :, i], 100, alpha=0.5, zorder=2)
-        if plot_wind:
-            if x.shape[0] > 100:
-                q = ax.quiver(
-                    x[::10, ::10],
-                    y[::10, ::10],
-                    Ut[::10, ::10, i],
-                    Vt[::10, ::10, i],
-                    alpha=0.8,
-                )
-            else:
-                q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
-        plt.title("time : " + str(times[i]))
-        for i in range(1, n_time):
-            for coll in CS.collections:
-                plt.gca().collections.remove(coll)
-            CS = ax.contourf(x, y, Nt[:, :, i], 100, alpha=0.5, zorder=2)
-            if plot_wind:
-                q.remove()
-                if x.shape[0] > 100:
-                    q = ax.quiver(
-                        x[::10, ::10],
-                        y[::10, ::10],
-                        Ut[::10, ::10, i],
-                        Vt[::10, ::10, i],
-                        alpha=0.8,
-                    )
-                else:
-                    q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
-            plt.title("time : " + str(times[i]))
-            plt.draw()
-            plt.pause(0.1)
-        return ax
+import os
+from abc import ABC, abstractmethod
+from typing import Union
+
+import cartopy.crs as ccrs
+import matplotlib.pyplot as plt
+import numpy as np
+
+import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.common_utils as Toolbox
+import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.intergrid as intergrid
+import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.std_atm as std_atm
+from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.common_utils import (
+    convert,
+)
+from skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.WeatherInterpolator import (
+    WeatherInterpolator,
+)
+
+
+class GenericInterpolator(ABC):
+    @abstractmethod
+    def interpol_field(self, X, **kwargs):
+        """
+        Interpol one field that is present in interpolators for array of 4d points
+
+        :param X: array of points [time (in s), alt (in ft), lat, long]
+        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
+        :return: array of interpolated values
+        """
+        ...
+
+    @abstractmethod
+    def render(self, ax, **kwargs):
+        ...
+
+
+def guess_axes(
+    values: np.ndarray,
+    lats: np.ndarray,
+    longs: np.ndarray,
+    levels: np.ndarray,
+    times: np.ndarray,
+):
+    ndims = values.ndim
+    shape = values.shape
+    if ndims == 3:
+        in_theory = ["times", "lats", "longs"]
+    if ndims == 4:
+        in_theory = ["times", "levels", "lats", "longs"]
+    if ndims == 5:
+        in_theory = ["times", "levels", "ensemble", "lats", "longs"]
+    d = {"times": times, "levels": levels, "lats": lats, "longs": longs}
+    l = {
+        "times": len(times),
+        "levels": len(levels),
+        "lats": len(lats),
+        "longs": len(longs),
+    }
+    for i in range(ndims):
+        s = shape[i]
+        if in_theory[i] != "ensemble":
+            if s != len(d[in_theory[i]]):
+                candidate = [t for t in l if l[t] == s]
+                if len(candidate) > 0:
+                    in_theory[i] = candidate[0]
+                else:
+                    in_theory[i] = "ensemble"
+                    d["ensemble"] = range(s)
+        else:
+            d["ensemble"] = range(s)
+    return in_theory, [d[x] for x in in_theory]
+
+
+class GenericEnsembleInterpolator(GenericInterpolator):
+    """
+    Class used to store weather data, interpolate and plot weather forecast from .npz files
+    """
+
+    def __init__(
+        self, file_npz, time_cut_index=None, fields=None, time_shift_s=0.0, order=1
+    ):
+        """
+        Stores the weather data and build the interpolators on grid.
+        """
+        # Files Loading
+        self.time_cut_index = time_cut_index
+        self.axes = {}
+        # self._auto_lock = Lock()
+        self.time_shift_s = time_shift_s
+
+        if isinstance(file_npz, (str, np.lib.npyio.NpzFile)):
+            self.datas = (
+                np.load(file_npz, allow_pickle=True)
+                if isinstance(file_npz, str)
+                else file_npz
+            )
+            if fields is None:
+                fields = self.datas.keys()
+            else:
+                fields = [f for f in fields if f in list(self.datas.keys())]
+
+            self.datas.allow_pickle = True
+            items = {var: self.datas[var].item() for var in fields}
+            self.lat_dict = {var: items[var]["lats"] for var in items}
+            self.long_dict = {
+                var: items[var]["longs"]
+                if "longs" in items[var]
+                else items[var]["lons"]
+                for var in items
+            }
+            self.levels_dict = {
+                var: items[var]["levels"] if "levels" in items[var] else [200.0]
+                for var in items
+            }
+            self.time_dict = {
+                var: items[var]["times"]
+                if self.time_cut_index is None
+                else items[var]["times"][
+                    : min(self.time_cut_index, len(items[var]["times"]))
+                ]
+                for var in items
+            }
+
+            if time_shift_s != 0.0:
+                for v in self.time_dict:
+                    self.time_dict[v] += time_shift_s
+
+            # items: U, V, T, R
+            self.values = {var: items[var]["values"] for var in items}
+
+            if self.time_cut_index is not None:
+                index_cut = min(
+                    self.time_cut_index,
+                    len(self.time_dict[list(self.time_dict.keys())[0]]),
+                )
+                for var in self.values:
+                    self.values[var] = self.values[var][:index_cut, :, :, :]
+        elif isinstance(
+            file_npz, dict
+        ):  # Already loaded data in a dict (directly from parseWeather indeed)
+
+            self.datas = file_npz
+            if fields is None:
+                fields = self.datas.keys()
+            else:
+                fields = [f for f in fields if f in list(self.datas.keys())]
+
+            ### ??? ###
+            # if fields is None:
+            #     fields = self.datas.keys()
+            # else:
+            #     fields = [f for f in fields if f in list(self.datas.keys())]
+
+            # self.datas.allow_pickle = True
+            items = {var: self.datas[var] for var in fields}
+            self.lat_dict = {var: items[var]["lats"] for var in fields}
+            self.long_dict = {
+                var: items[var]["longs"]
+                if "longs" in items[var]
+                else items[var]["lons"]
+                for var in fields
+            }
+            self.levels_dict = {
+                var: items[var]["levels"] if "levels" in items[var] else [200.0]
+                for var in fields
+            }
+
+            self.time_dict = {var: items[var]["times"] for var in fields}
+            if time_shift_s != 0.0:
+                for v in self.time_dict:
+                    self.time_dict[v] += time_shift_s
+            self.values = {var: items[var]["values"] for var in fields}
+            # for var in self.lat_dict:
+            #     print(self.lat_dict[var].shape, "lats")
+            #     print(self.long_dict[var].shape, "long")
+            #     print(self.levels_dict[var].shape, "levels")
+            #     print(self.time_dict[var].shape, "time")
+            #     print(self.values[var].shape, "values")
+
+        # one_field = list(self.values.keys())[0]
+        for feat in self.lat_dict:
+            if self.lat_dict[feat][-1] < self.lat_dict[feat][0]:
+                self.lat_dict[feat] = self.lat_dict[feat][::-1]
+                if self.values[feat].ndim == 4:
+                    self.values[feat] = self.values[feat][:, :, ::-1, :]
+                elif self.values[feat].ndim == 5:
+                    self.values[feat] = self.values[feat][:, :, :, ::-1, :]
+        self.interpol_dict = {}
+
+        for var in self.values:
+            # print(f'Building interpolator for {var}')
+            # print(f'Levels dict: {self.levels_dict[var]}')
+            self.levels_dict[var] = [111, 121]
+            if (len(self.levels_dict[var]) == 0) or (len(self.levels_dict[var]) == 1):
+                self.levels_dict[var] = np.array([30_000])
+
+            axes = guess_axes(
+                self.values[var],
+                self.lat_dict[var],
+                self.long_dict[var],
+                self.levels_dict[var],
+                self.time_dict[var],
+            )
+
+            self.axes[var] = axes
+            self.interpol_dict[var] = intergrid.Intergrid(
+                self.values[var],
+                lo=[min(axes[1][i]) for i in range(len(axes[1]))],
+                hi=[max(axes[1][i]) for i in range(len(axes[1]))],
+                maps=axes[1],
+                verbose=False,
+                copy=True,
+                order=order,
+            )
+
+    def add_new_field(self, origin_field, operation, axis, new_field):
+        values = self.values[origin_field]
+        new_values = operation(values, axis=axis)
+        self.lat_dict[new_field] = self.lat_dict[origin_field]
+        self.long_dict[new_field] = self.long_dict[origin_field]
+        self.levels_dict[new_field] = self.levels_dict[origin_field]
+        self.time_dict[new_field] = self.time_dict[origin_field]
+        self.values[new_field] = new_values
+        axes = guess_axes(
+            self.values[new_field],
+            self.lat_dict[new_field],
+            self.long_dict[new_field],
+            self.levels_dict[new_field],
+            self.time_dict[new_field],
+        )
+        self.axes[new_field] = axes
+        self.interpol_dict[new_field] = intergrid.Intergrid(
+            self.values[new_field],
+            lo=[min(axes[1][i]) for i in range(len(axes[1]))],
+            hi=[max(axes[1][i]) for i in range(len(axes[1]))],
+            maps=axes[1],
+            verbose=False,
+            copy=True,
+            order=1,
+        )
+
+    def add_new_field_matrix(self, values, axes_values, new_field):
+        self.values[new_field] = values
+        self.axes[new_field] = axes_values
+        self.interpol_dict[new_field] = intergrid.Intergrid(
+            self.values[new_field],
+            lo=[min(axes_values[i]) for i in range(len(axes_values))],
+            hi=[max(axes_values[i]) for i in range(len(axes_values))],
+            maps=axes_values,
+            verbose=False,
+            copy=True,
+            order=1,
+        )
+
+    def interpol_field(self, X, field="CONVEXION"):
+        """
+        Interpol one field that is present in interpolators for array of 4d points
+
+        :param X: array of points [time (in s), alt (in ft), lat, long], or [time (in s), alt (in ft), id-ensemble,
+                                                                             lat, long]
+        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
+        :return: array of interpolated values
+        """
+        # with self._auto_lock:
+        return self.interpol_dict[field](X)
+
+    def transform_long(self, long):
+        """
+        [Deprecated] should be replaced by modulo function...
+
+        :param long: array of longitudes
+        :return: array of longitude put in positive domain (modulo 360.)
+        """
+        return long
+        # return np.where(long < 0, 360+long, long)
+
+    def plot_field(
+        self,
+        field="issr",
+        alt=35000.0,
+        t: Union[float, np.ndarray] = 0.0,
+        n_lat=180,
+        n_long=720,
+        ax=None,
+    ):
+        # plot the entire interpolate field
+        # p = alt2press(alt)
+        times = [t]
+        n_time = 1
+        if Toolbox.is_iterable(t):
+            times = t
+            n_time = len(t)
+        down_long = min(self.long_dict[field])
+        up_long = max(self.long_dict[field])
+        down_lat = min(self.lat_dict[field])
+        up_lat = max(self.lat_dict[field])
+        if ax is None:
+            fig, ax = plt.subplots(1, figsize=(8, 10))
+            ax = plt.axes(projection=ccrs.PlateCarree())
+            ax.stock_img()
+            m = ax
+        else:
+            m = ax
+        range_lat = np.linspace(down_lat, up_lat, n_lat)
+        range_long = np.linspace(down_long, up_long, n_long)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        range_long = self.transform_long(range_long)
+        if self.values[field].ndim == 4:
+            values = np.array(
+                [
+                    [time, alt, range_lat[i], range_long[j]]
+                    for i in range(n_lat)
+                    for j in range(n_long)
+                    for time in times
+                ]
+            )
+        elif self.values[field].ndim == 3:
+            values = np.array(
+                [
+                    [time, range_lat[i], range_long[j]]
+                    for i in range(n_lat)
+                    for j in range(n_long)
+                    for time in times
+                ]
+            )
+        Ut = np.resize(self.interpol_dict[field](values), (n_lat, n_long, n_time))
+        i = 0
+        cs = m.contourf(
+            x,
+            y,
+            Ut[:, :, i],
+            20,
+            extent=[down_long, up_long, down_lat, up_lat],
+            alpha=0.5,
+            zorder=2,
+        )
+        plt.title("time " + str(times[i]))
+        plt.draw()
+        plt.pause(0.1)
+        for i in range(1, n_time):
+            for coll in cs.collections:
+                plt.gca().collections.remove(coll)
+            cs = m.contourf(
+                x,
+                y,
+                Ut[:, :, i],
+                20,
+                extent=[down_long, up_long, down_lat, up_lat],
+                alpha=0.5,
+                zorder=2,
+            )
+            plt.title("time : " + str(times[i]))
+            plt.draw()
+            plt.pause(1)
+        return m
+
+    def plot_field_5d(
+        self,
+        field="CONVECTION",
+        alt=35000.0,
+        t: Union[float, np.ndarray] = 0.0,
+        n_lat=180,
+        index_forecast=0,
+        n_long=720,
+        ax=None,
+        save=False,
+        folder="",
+        tag_file="weath",
+    ):
+        # plot the entire interpolate field
+        # p = alt2press(alt)
+        times = [t]
+        n_time = 1
+        if Toolbox.is_iterable(t):
+            times = t
+            n_time = len(t)
+        down_long = min(self.long_dict[field])
+        up_long = max(self.long_dict[field])
+        down_lat = min(self.lat_dict[field])
+        up_lat = max(self.lat_dict[field])
+        if ax is None:
+            fig, ax = plt.subplots(1, figsize=(8, 10))
+            ax = plt.axes(projection=ccrs.PlateCarree())
+            ax.stock_img()
+            ax.set_xlim([down_long, up_long])
+            ax.set_ylim([down_lat, up_lat])
+            m = ax
+        else:
+            m = ax
+        range_lat = np.linspace(down_lat, up_lat, n_lat)
+        range_long = np.linspace(down_long, up_long, n_long)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        range_long = self.transform_long(range_long)
+        values = np.array(
+            [
+                [time, alt, index_forecast, range_lat[i], range_long[j]]
+                for i in range(n_lat)
+                for j in range(n_long)
+                for time in times
+            ]
+        )
+
+        Ut = np.resize(self.interpol_dict[field](values), (n_lat, n_long, n_time))
+        i = 0
+        cs = ax.contour(
+            x,
+            y,
+            Ut[:, :, i],
+            extent=[down_long, up_long, down_lat, up_lat],
+            alpha=0.9,
+            zorder=2,
+        )
+        # cs = ax.imshow(Ut[:, :, i],
+        #               extent=[down_long, up_long, down_lat, up_lat])
+        plt.title("time " + str(times[i]))
+        plt.draw()
+        if save:
+            j = 0
+            t = "0" * (4 - len(str(j))) + str(j)
+            plt.savefig(os.path.join(folder, t + "_" + tag_file + ".png"))
+        plt.pause(0.1)
+        for i in range(1, n_time):
+            for coll in cs.collections:
+                plt.gca().collections.remove(coll)
+            ##cs.clear()
+            # cs.set_data(Ut[:, :, i])
+            cs = ax.contour(
+                x,
+                y,
+                Ut[:, :, i],
+                extent=[down_long, up_long, down_lat, up_lat],
+                alpha=0.9,
+                zorder=2,
+            )
+            plt.title("time : " + str(times[i]))
+            plt.draw()
+            if save:
+                j += 1
+                t = "0" * (4 - len(str(j))) + str(j)
+                plt.savefig(os.path.join(folder, t + "_" + tag_file + ".png"))
+            plt.pause(0.1)
+        return m
+
+    def render(self, ax, **kwargs):
+        if ax is None:
+            fig, ax = plt.subplots(1, figsize=(8, 10))
+            ax = plt.axes(projection=ccrs.PlateCarree())
+            ax.stock_img()
+        else:
+            ax = ax
+        keys = list(self.long_dict.keys())
+        longs = self.long_dict[keys[0]]
+        lats = self.lat_dict[keys[0]]
+        dict_params = kwargs.get("kwargs", {})
+        try:
+            ax.imshow(
+                self.values[dict_params["convexion_field"]][
+                    0, 0, dict_params.get("index_forecast", 0), :, :
+                ],
+                cmap="hot",
+                extent=[min(longs), max(longs), min(lats), max(lats)],
+                interpolation="nearest",
+                alpha=0.2,
+            )
+        except:
+            pass
+
+
+class GenericWindInterpolator(GenericEnsembleInterpolator, WeatherInterpolator):
+    """
+    Class used to store weather data, interpolate and plot weather forecast from .npz files
+    """
+
+    def __init__(
+        self, file_npz, time_cut_index=None, fields=None, order_interp=1, time_shift_s=0
+    ):
+        """
+        Stores the weather data and build the interpolators on grid.
+        """
+        super().__init__(
+            file_npz, time_cut_index, fields=fields, time_shift_s=time_shift_s
+        )
+        if "U" not in self.values:
+            ufield = "UGRD"
+            vfield = "VGRD"
+        else:
+            ufield = "U"
+            vfield = "V"
+        self.norm_wind = np.sqrt(
+            np.square(self.values[ufield]) + np.square(self.values[vfield])
+        )
+        self.angle_wind = np.arctan2(self.values[vfield], self.values[ufield])
+        self.interpol_dict["norm-wind"] = intergrid.Intergrid(
+            self.norm_wind,
+            lo=[min(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
+            hi=[max(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
+            maps=self.axes[ufield][1],
+            copy=True,
+            verbose=False,
+            order=1,
+        )
+        self.interpol_dict["argument-wind"] = intergrid.Intergrid(
+            self.angle_wind,
+            lo=[min(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
+            hi=[max(self.axes[ufield][1][i]) for i in range(len(self.axes[ufield][1]))],
+            maps=self.axes[ufield][1],
+            verbose=False,
+            copy=True,
+            order=1,
+        )
+        self.long_dict["norm-wind"] = self.long_dict[ufield]
+        self.lat_dict["argument-wind"] = self.lat_dict[ufield]
+        self.long_dict["argument-wind"] = self.long_dict[ufield]
+        self.lat_dict["norm-wind"] = self.lat_dict[ufield]
+
+    def transform_long(self, long):
+        return long
+
+    def interpol_wind_classic(self, lat, longi, alt=35000.0, t=0.0, index_forecast=0):
+        # with self._auto_lock:
+        p = std_atm.alt2press(alt, alt_units="ft", press_units="hpa")
+
+        if len(self.axes["U"][1]) == 5:
+            norm = self.interpol_dict["norm-wind"]([t, p, index_forecast, lat, longi])
+            arg = self.interpol_dict["argument-wind"](
+                [t, p, index_forecast, lat, longi]
+            )
+
+            result = norm * np.array([np.cos(arg), np.sin(arg)])
+            return [norm, arg, result]
+
+        if len(self.axes["U"][1]) == 4:
+            norm = self.interpol_dict["norm-wind"]([t, p, lat, longi])
+            arg = self.interpol_dict["argument-wind"]([t, p, lat, longi])
+
+            result = norm * np.array([np.cos(arg), np.sin(arg)])
+            return [norm, arg, result]
+
+    def interpol_wind(self, X):
+        """
+        Interpol wind for an array of 4D points
+
+        :param X: array of points [time (in s), alt (in ft), lat, long]
+        :return: wind vector.
+        """
+        # with self._auto_lock:
+        arg = self.interpol_dict["argument-wind"](X)
+        return self.interpol_dict["norm-wind"](X) * np.array(
+            [[np.cos(arg), np.sin(arg)]]
+        )
+
+    def plot_wind(
+        self,
+        alt=35000.0,
+        down_long=-180.0,
+        up_long=180.0,
+        down_lat=-90.0,
+        up_lat=90.0,
+        t=0.0,
+        n_lat=180,
+        n_long=720,
+        index_forecast=0,
+        plot_wind=False,
+        ax=None,
+    ):
+        """
+        Plot the wind for a given coordinates window for a given altitude and for one time/or range of time
+
+        :param alt: altitude couch to plot (in ft)
+        :param down_long: min longitude
+        :param up_long: max longitude
+        :param down_lat: min latitude
+        :param up_lat: max latitude
+        :param t: value of time step (in second) or list/array of time step (in s)
+        :type t: float or iterable
+        :param n_lat: number of latitude discretized steps
+        :param n_long: number of longitude discretized steps
+        :param plot_wind: plot the vector field
+        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
+        """
+        times = [t]
+        n_time = 1
+        if Toolbox.is_iterable(t):
+            times = t
+            n_time = len(t)
+        if ax is None:
+            fig, ax = plt.subplots(
+                1, 1, figsize=(10, 5), subplot_kw={"projection": ccrs.PlateCarree()}
+            )
+            ax.stock_img()
+        range_lat = np.linspace(down_lat, up_lat, n_lat)
+        range_long = np.linspace(down_long, up_long, n_long)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        range_long = self.transform_long(range_long)
+        values = np.array(
+            [
+                [time, alt, index_forecast, range_lat[i], range_long[j]]
+                for i in range(n_lat)
+                for j in range(n_long)
+                for time in times
+            ]
+        )
+        res = self.interpol_wind(values)
+        Ut = np.resize(res[0, 0, :], (n_lat, n_long, n_time))
+        Vt = np.resize(res[0, 1, :], (n_lat, n_long, n_time))
+        Nt = np.sqrt(np.square(Ut) + np.square(Vt))
+        # Nt = np.reshape(self.interpol_field(values, field='norm-wind'), (n_lat, n_long, n_time))
+
+        i = 0
+        CS = ax.contourf(x, y, Nt[:, :, i], 100, alpha=0.5, zorder=2)
+        if plot_wind:
+            if x.shape[0] > 100:
+                q = ax.quiver(
+                    x[::10, ::10],
+                    y[::10, ::10],
+                    Ut[::10, ::10, i],
+                    Vt[::10, ::10, i],
+                    alpha=0.8,
+                )
+            else:
+                q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
+        plt.title("time : " + str(times[i]))
+        for i in range(1, n_time):
+            for coll in CS.collections:
+                plt.gca().collections.remove(coll)
+            CS = ax.contourf(x, y, Nt[:, :, i], 100, alpha=0.5, zorder=2)
+            if plot_wind:
+                q.remove()
+                if x.shape[0] > 100:
+                    q = ax.quiver(
+                        x[::10, ::10],
+                        y[::10, ::10],
+                        Ut[::10, ::10, i],
+                        Vt[::10, ::10, i],
+                        alpha=0.8,
+                    )
+                else:
+                    q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
+            plt.title("time : " + str(times[i]))
+            plt.draw()
+            plt.pause(0.1)
+        return ax
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/intergrid.py

 * *Ordering differences only*

```diff
@@ -1,245 +1,245 @@
-# -*- coding: utf-8 -*-
-"""
-Created on Mon Apr 18 11:53:11 2016
-
-@author: popo
-"""
-""""http://stackoverflow.com/questions/16217995/fast-interpolation-of-regularly-sampled-3d-data-with-different-intervals-in-x-y/16221098#16221098"""
-""" interpolate data given on an Nd rectangular grid, uniform or non-uniform.
-
-Purpose: extend the fast N-dimensional interpolator
-`scipy.ndimage.map_coordinates` to non-uniform grids, using `np.interp`.
-
-Background: please look at
-http://en.wikipedia.org/wiki/Bilinear_interpolation
-http://stackoverflow.com/questions/6238250/multivariate-spline-interpolation-in-python-scipy
-http://docs.scipy.org/doc/scipy-dev/reference/generated/scipy.ndimage.interpolation.map_coordinates.html
-
-Example
--------
-Say we have rainfall on a 4 x 5 grid of rectangles, lat 52 .. 55 x lon -10 .. -6,
-and want to interpolate (estimate) rainfall at 1000 query points
-in between the grid points.
-
-        # define the grid --
-    griddata = np.loadtxt(...)  # griddata.shape == (4, 5)
-    lo = np.array([ 52, -10 ])  # lowest lat, lowest lon
-    hi = np.array([ 55, -6 ])   # highest lat, highest lon
-
-        # set up an interpolator function "interfunc()" with class Intergrid --
-    interfunc = Intergrid( griddata, lo=lo, hi=hi )
-
-        # generate 1000 random query points, lo <= [lat, lon] <= hi --
-    query_points = lo + np.random.uniform( size=(1000, 2) ) * (hi - lo)
-
-        # get rainfall at the 1000 query points --
-    query_values = interfunc( query_points )  # -> 1000 values
-
-What this does:
-    for each [lat, lon] in query_points:
-        1) find the square of griddata it's in,
-            e.g. [52.5, -8.1] -> [0, 3] [0, 4] [1, 4] [1, 3]
-        2) do bilinear (multilinear) interpolation in that square,
-            using `scipy.ndimage.map_coordinates` .
-Check:
-    interfunc( lo ) -> griddata[0, 0],
-    interfunc( hi ) -> griddata[-1, -1] i.e. griddata[3, 4]
-
-Parameters
-----------
-    griddata: numpy array_like, 2d 3d 4d ...
-    lo, hi: user coordinates of the corners of griddata, 1d array-like, lo < hi
-    maps: a list of `dim` descriptors of piecewise-linear or nonlinear maps,
-        e.g. [[50, 52, 62, 63], None]  # uniformize lat, linear lon
-    copy: make a copy of query_points, default True;
-        copy=False overwrites query_points, runs in less memory
-    verbose: default 1: print a 1-line summary for each call, with run time
-    order=1: see `map_coordinates`
-    prefilter: 0 or False, the default: smoothing B-spline
-              1 or True: exact-fit interpolating spline (IIR, not C-R)
-              1/3: Mitchell-Netravali spline, 1/3 B + 2/3 fit
-        (prefilter is only for order > 1, since order = 1 interpolates)
-
-Non-uniform rectangular grids
------------------------------
-What if our griddata above is at non-uniformly-spaced latitudes,
-say [50, 52, 62, 63] ?  `Intergrid` can "uniformize" these
-before interpolation, like this:
-
-    lo = np.array([ 50, -10 ])
-    hi = np.array([ 63, -6 ])
-    maps = [[50, 52, 62, 63], None]  # uniformize lat, linear lon
-    interfunc = Intergrid( griddata, lo=lo, hi=hi, maps=maps )
-
-This will map (transform, stretch, warp) the lats in query_points column 0
-to array coordinates in the range 0 .. 3, using `np.interp` to do
-piecewise-linear (PWL) mapping:
-    50  51  52  53  54  55  56  57  58  59  60  61  62  63  # lo[0] .. hi[0]
-    0   .5  1   1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2   3
-
-`maps[1] None` says to map the lons in query_points column 1 linearly:
-    -10  -9  -8  -7  -6  # lo[1] .. hi[1]
-    0    1   2   3   4
-
-More doc: https://denis-bz.github.com/docs/intergrid.html
-
-"""
-# split class Gridmap ?
-
-from time import time
-
-# warnings
-import numpy as np
-from scipy.ndimage import map_coordinates, spline_filter
-
-__version__ = "2014-01-15 jan denis"  # 15jan: fix bug in linear scaling
-__author_email__ = "denis-bz-py@t-online.de"  # comments welcome, testcases most welcome
-
-
-class Intergrid:
-    __doc__ = globals()["__doc__"]
-
-    def __init__(
-        self,
-        griddata,
-        lo,
-        hi,
-        maps=[],
-        copy=True,
-        verbose=1,
-        order=1,
-        prefilter=False,
-        mode="nearest",
-        cval="None",
-    ):
-        griddata = np.asanyarray(griddata)
-        dim = griddata.ndim  # - (griddata.shape[-1] == 1)  # ??
-        assert dim >= 2, griddata.shape
-        self.dim = dim
-        if np.isscalar(lo):
-            lo *= np.ones(dim)
-        if np.isscalar(hi):
-            hi *= np.ones(dim)
-        self.loclip = lo = np.asarray_chkfinite(lo).copy()
-        self.hiclip = hi = np.asarray_chkfinite(hi).copy()
-        assert lo.shape == (dim,), lo.shape
-        assert hi.shape == (dim,), hi.shape
-        self.copy = copy
-        self.verbose = verbose
-        self.order = order
-        self.mode = mode
-        self.cval = cval
-        if order > 1 and 0 < prefilter < 1:  # 1/3: Mitchell-Netravali = 1/3 B + 2/3 fit
-            exactfit = spline_filter(griddata)  # see Unser
-            griddata += prefilter * (exactfit - griddata)
-            prefilter = False
-        self.griddata = griddata
-        self.prefilter = prefilter == True
-
-        self.maps = maps
-        self.nmap = 0
-        if len(maps) > 0:
-            assert len(maps) == dim, "maps must have len %d, not %d" % (dim, len(maps))
-            # linear maps (map None): Xcol -= lo *= scale -> [0, n-1]
-            # nonlinear: np.interp e.g. [50 52 62 63] -> [0 1 2 3]
-            self._lo = np.zeros(dim)
-            self._scale = np.ones(dim)
-
-            for j, (map, n, l, h) in enumerate(zip(maps, griddata.shape, lo, hi)):
-                ## print "test: j map n l h:", j, map, n, l, h
-                if map is None or callable(map):
-                    self._lo[j] = l
-                    if h > l:
-                        self._scale[j] = (n - 1) / (h - l)  # _map lo -> 0, hi -> n - 1
-                    else:
-                        self._scale[j] = 0  # h <= l: X[:,j] -> 0
-                    continue
-                self.maps[j] = map = np.asanyarray(map)
-                self.nmap += 1
-                assert len(map) == n, "maps[%d] must have len %d, not %d" % (
-                    j,
-                    n,
-                    len(map),
-                )
-                mlo, mhi = map.min(), map.max()
-                if not (l <= mlo <= mhi <= h):
-                    print(
-                        "Warning: Intergrid maps[%d] min %.3g max %.3g "
-                        "are outside lo %.3g hi %.3g" % (j, mlo, mhi, l, h)
-                    )
-
-    # ...............................................................................
-    def _map_to_uniform_grid(self, X):
-        """clip, map X linear / nonlinear  inplace"""
-        np.clip(X, self.loclip, self.hiclip, out=X)
-        # X nonlinear maps inplace --
-        for j, map in enumerate(self.maps):
-            if map is None:
-                continue
-            if callable(map):
-                X[:, j] = map(X[:, j])  # clip again ?
-            else:
-                # PWL e.g. [50 52 62 63] -> [0 1 2 3] --
-                X[:, j] = np.interp(X[:, j], map, np.arange(len(map)))
-
-            # linear map the rest, inplace (nonlinear _lo 0, _scale 1: noop)
-        if self.nmap < self.dim:
-            X -= self._lo
-            X *= self._scale  # (griddata.shape - 1) / (hi - lo)
-        ## print "test: _map_to_uniform_grid", X.T
-
-    # ...............................................................................
-    def __call__(self, X, out=None):
-        """
-        query_values = Intergrid(...) ( query_points npt x dim )
-        """
-        if self.mode == "constant":
-            b = True
-            for i in range(self.nmap):
-                b = self.loclip[i] <= X[i] <= self.hiclip[i]
-                if not b:
-                    return self.cval
-        X = np.asanyarray(X)
-        assert (
-            X.shape[-1] == self.dim
-        ), "the query array must have %d columns, " "but its shape is %s" % (
-            self.dim,
-            X.shape,
-        )
-        Xdim = X.ndim
-        if Xdim == 1:
-            X = np.asarray([X])  # in a single point -> out scalar
-        if self.copy:
-            X = X.copy()
-        assert X.ndim == 2, X.shape
-        npt = X.shape[0]
-        if out is None:
-            out = np.empty(npt, dtype=self.griddata.dtype)
-        t0 = time()
-        self._map_to_uniform_grid(X)  # X inplace
-        map_coordinates(
-            self.griddata,
-            X.T,
-            order=self.order,
-            prefilter=self.prefilter,
-            mode="nearest",  # outside -> edge
-            # test: mode="constant", cval=np.NaN,
-            output=out,
-        )
-        if self.verbose:
-            print(
-                "Intergrid: %.3g msec  %d points in a %s grid  %d maps  order %d"
-                % (
-                    (time() - t0) * 1000,
-                    npt,
-                    self.griddata.shape,
-                    self.nmap,
-                    self.order,
-                )
-            )
-        return out if Xdim == 2 else out[0]
-
-    at = __call__
-
-
-# end intergrid.py
+# -*- coding: utf-8 -*-
+"""
+Created on Mon Apr 18 11:53:11 2016
+
+@author: popo
+"""
+""""http://stackoverflow.com/questions/16217995/fast-interpolation-of-regularly-sampled-3d-data-with-different-intervals-in-x-y/16221098#16221098"""
+""" interpolate data given on an Nd rectangular grid, uniform or non-uniform.
+
+Purpose: extend the fast N-dimensional interpolator
+`scipy.ndimage.map_coordinates` to non-uniform grids, using `np.interp`.
+
+Background: please look at
+http://en.wikipedia.org/wiki/Bilinear_interpolation
+http://stackoverflow.com/questions/6238250/multivariate-spline-interpolation-in-python-scipy
+http://docs.scipy.org/doc/scipy-dev/reference/generated/scipy.ndimage.interpolation.map_coordinates.html
+
+Example
+-------
+Say we have rainfall on a 4 x 5 grid of rectangles, lat 52 .. 55 x lon -10 .. -6,
+and want to interpolate (estimate) rainfall at 1000 query points
+in between the grid points.
+
+        # define the grid --
+    griddata = np.loadtxt(...)  # griddata.shape == (4, 5)
+    lo = np.array([ 52, -10 ])  # lowest lat, lowest lon
+    hi = np.array([ 55, -6 ])   # highest lat, highest lon
+
+        # set up an interpolator function "interfunc()" with class Intergrid --
+    interfunc = Intergrid( griddata, lo=lo, hi=hi )
+
+        # generate 1000 random query points, lo <= [lat, lon] <= hi --
+    query_points = lo + np.random.uniform( size=(1000, 2) ) * (hi - lo)
+
+        # get rainfall at the 1000 query points --
+    query_values = interfunc( query_points )  # -> 1000 values
+
+What this does:
+    for each [lat, lon] in query_points:
+        1) find the square of griddata it's in,
+            e.g. [52.5, -8.1] -> [0, 3] [0, 4] [1, 4] [1, 3]
+        2) do bilinear (multilinear) interpolation in that square,
+            using `scipy.ndimage.map_coordinates` .
+Check:
+    interfunc( lo ) -> griddata[0, 0],
+    interfunc( hi ) -> griddata[-1, -1] i.e. griddata[3, 4]
+
+Parameters
+----------
+    griddata: numpy array_like, 2d 3d 4d ...
+    lo, hi: user coordinates of the corners of griddata, 1d array-like, lo < hi
+    maps: a list of `dim` descriptors of piecewise-linear or nonlinear maps,
+        e.g. [[50, 52, 62, 63], None]  # uniformize lat, linear lon
+    copy: make a copy of query_points, default True;
+        copy=False overwrites query_points, runs in less memory
+    verbose: default 1: print a 1-line summary for each call, with run time
+    order=1: see `map_coordinates`
+    prefilter: 0 or False, the default: smoothing B-spline
+              1 or True: exact-fit interpolating spline (IIR, not C-R)
+              1/3: Mitchell-Netravali spline, 1/3 B + 2/3 fit
+        (prefilter is only for order > 1, since order = 1 interpolates)
+
+Non-uniform rectangular grids
+-----------------------------
+What if our griddata above is at non-uniformly-spaced latitudes,
+say [50, 52, 62, 63] ?  `Intergrid` can "uniformize" these
+before interpolation, like this:
+
+    lo = np.array([ 50, -10 ])
+    hi = np.array([ 63, -6 ])
+    maps = [[50, 52, 62, 63], None]  # uniformize lat, linear lon
+    interfunc = Intergrid( griddata, lo=lo, hi=hi, maps=maps )
+
+This will map (transform, stretch, warp) the lats in query_points column 0
+to array coordinates in the range 0 .. 3, using `np.interp` to do
+piecewise-linear (PWL) mapping:
+    50  51  52  53  54  55  56  57  58  59  60  61  62  63  # lo[0] .. hi[0]
+    0   .5  1   1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2   3
+
+`maps[1] None` says to map the lons in query_points column 1 linearly:
+    -10  -9  -8  -7  -6  # lo[1] .. hi[1]
+    0    1   2   3   4
+
+More doc: https://denis-bz.github.com/docs/intergrid.html
+
+"""
+# split class Gridmap ?
+
+from time import time
+
+# warnings
+import numpy as np
+from scipy.ndimage import map_coordinates, spline_filter
+
+__version__ = "2014-01-15 jan denis"  # 15jan: fix bug in linear scaling
+__author_email__ = "denis-bz-py@t-online.de"  # comments welcome, testcases most welcome
+
+
+class Intergrid:
+    __doc__ = globals()["__doc__"]
+
+    def __init__(
+        self,
+        griddata,
+        lo,
+        hi,
+        maps=[],
+        copy=True,
+        verbose=1,
+        order=1,
+        prefilter=False,
+        mode="nearest",
+        cval="None",
+    ):
+        griddata = np.asanyarray(griddata)
+        dim = griddata.ndim  # - (griddata.shape[-1] == 1)  # ??
+        assert dim >= 2, griddata.shape
+        self.dim = dim
+        if np.isscalar(lo):
+            lo *= np.ones(dim)
+        if np.isscalar(hi):
+            hi *= np.ones(dim)
+        self.loclip = lo = np.asarray_chkfinite(lo).copy()
+        self.hiclip = hi = np.asarray_chkfinite(hi).copy()
+        assert lo.shape == (dim,), lo.shape
+        assert hi.shape == (dim,), hi.shape
+        self.copy = copy
+        self.verbose = verbose
+        self.order = order
+        self.mode = mode
+        self.cval = cval
+        if order > 1 and 0 < prefilter < 1:  # 1/3: Mitchell-Netravali = 1/3 B + 2/3 fit
+            exactfit = spline_filter(griddata)  # see Unser
+            griddata += prefilter * (exactfit - griddata)
+            prefilter = False
+        self.griddata = griddata
+        self.prefilter = prefilter == True
+
+        self.maps = maps
+        self.nmap = 0
+        if len(maps) > 0:
+            assert len(maps) == dim, "maps must have len %d, not %d" % (dim, len(maps))
+            # linear maps (map None): Xcol -= lo *= scale -> [0, n-1]
+            # nonlinear: np.interp e.g. [50 52 62 63] -> [0 1 2 3]
+            self._lo = np.zeros(dim)
+            self._scale = np.ones(dim)
+
+            for j, (map, n, l, h) in enumerate(zip(maps, griddata.shape, lo, hi)):
+                ## print "test: j map n l h:", j, map, n, l, h
+                if map is None or callable(map):
+                    self._lo[j] = l
+                    if h > l:
+                        self._scale[j] = (n - 1) / (h - l)  # _map lo -> 0, hi -> n - 1
+                    else:
+                        self._scale[j] = 0  # h <= l: X[:,j] -> 0
+                    continue
+                self.maps[j] = map = np.asanyarray(map)
+                self.nmap += 1
+                assert len(map) == n, "maps[%d] must have len %d, not %d" % (
+                    j,
+                    n,
+                    len(map),
+                )
+                mlo, mhi = map.min(), map.max()
+                if not (l <= mlo <= mhi <= h):
+                    print(
+                        "Warning: Intergrid maps[%d] min %.3g max %.3g "
+                        "are outside lo %.3g hi %.3g" % (j, mlo, mhi, l, h)
+                    )
+
+    # ...............................................................................
+    def _map_to_uniform_grid(self, X):
+        """clip, map X linear / nonlinear  inplace"""
+        np.clip(X, self.loclip, self.hiclip, out=X)
+        # X nonlinear maps inplace --
+        for j, map in enumerate(self.maps):
+            if map is None:
+                continue
+            if callable(map):
+                X[:, j] = map(X[:, j])  # clip again ?
+            else:
+                # PWL e.g. [50 52 62 63] -> [0 1 2 3] --
+                X[:, j] = np.interp(X[:, j], map, np.arange(len(map)))
+
+            # linear map the rest, inplace (nonlinear _lo 0, _scale 1: noop)
+        if self.nmap < self.dim:
+            X -= self._lo
+            X *= self._scale  # (griddata.shape - 1) / (hi - lo)
+        ## print "test: _map_to_uniform_grid", X.T
+
+    # ...............................................................................
+    def __call__(self, X, out=None):
+        """
+        query_values = Intergrid(...) ( query_points npt x dim )
+        """
+        if self.mode == "constant":
+            b = True
+            for i in range(self.nmap):
+                b = self.loclip[i] <= X[i] <= self.hiclip[i]
+                if not b:
+                    return self.cval
+        X = np.asanyarray(X)
+        assert (
+            X.shape[-1] == self.dim
+        ), "the query array must have %d columns, " "but its shape is %s" % (
+            self.dim,
+            X.shape,
+        )
+        Xdim = X.ndim
+        if Xdim == 1:
+            X = np.asarray([X])  # in a single point -> out scalar
+        if self.copy:
+            X = X.copy()
+        assert X.ndim == 2, X.shape
+        npt = X.shape[0]
+        if out is None:
+            out = np.empty(npt, dtype=self.griddata.dtype)
+        t0 = time()
+        self._map_to_uniform_grid(X)  # X inplace
+        map_coordinates(
+            self.griddata,
+            X.T,
+            order=self.order,
+            prefilter=self.prefilter,
+            mode="nearest",  # outside -> edge
+            # test: mode="constant", cval=np.NaN,
+            output=out,
+        )
+        if self.verbose:
+            print(
+                "Intergrid: %.3g msec  %d points in a %s grid  %d maps  order %d"
+                % (
+                    (time() - t0) * 1000,
+                    npt,
+                    self.griddata.shape,
+                    self.nmap,
+                    self.order,
+                )
+            )
+        return out if Xdim == 2 else out[0]
+
+    at = __call__
+
+
+# end intergrid.py
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/WeatherInterpolator.py

```diff
@@ -1,627 +1,639 @@
-from abc import ABC, abstractmethod
-
-import cartopy.crs as ccrs
-import matplotlib.pyplot as plt
-import numpy as np
-
-import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.common_utils as Toolbox
-import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.intergrid as intergrid
-
-
-class WeatherInterpolator(ABC):
-    @abstractmethod
-    def interpol_wind(self, X):
-        """
-        Interpol wind for an array of 4D points
-
-        :param X: array of points [time (in s), alt (in ft), lat, long]
-        :return: wind vector.
-        """
-        ...
-
-    @abstractmethod
-    def interpol_field(self, X, field="temperature"):
-        """
-        Interpol one field that is present in interpolators for array of 4d points
-
-        :param X: array of points [time (in s), alt (in ft), lat, long]
-        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
-        :return: array of interpolated values
-        """
-        ...
-
-    @abstractmethod
-    def interpol_wind_classic(self, lat, longi, alt, **kwargs):
-        """
-        Interpolate the wind.
-        :param lat: latitude in degree
-        :param longi: longitude in degree
-        :param alt: altitude in feet
-        :param kwargs: other parameters for the given weather data underlying. example : id of the ensemble forecast.
-        :return:
-        """
-        ...
-
-    @abstractmethod
-    def render(self, ax, **kwargs):
-        ...
-
-
-class WeatherForecastInterpolator(WeatherInterpolator):
-    """
-    Class used to store weather data, interpolate and plot weather forecast from .npz files
-    """
-
-    def __init__(self, file_npz, time_cut_index=None, order_interp=1):
-        """
-        Stores the weather data and build the interpolators on grid.
-        """
-        # Files Loading
-        self.time_cut_index = time_cut_index
-        if isinstance(file_npz, (str, np.lib.npyio.NpzFile)):
-            self.datas = np.load(file_npz) if isinstance(file_npz, str) else file_npz
-            self.lat_dict = {
-                var: self.datas[var].item()["lats"] for var in self.datas.keys()
-            }
-            self.long_dict = {
-                var: self.datas[var].item()["longs"] for var in self.datas.keys()
-            }
-            self.alt_dict = {
-                var: self.datas[var].item()["feets"] for var in self.datas.keys()
-            }
-            self.time_dict = {
-                var: self.datas[var].item()["times"]
-                if self.time_cut_index is None
-                else self.datas[var].item()["times"][
-                    : min(self.time_cut_index, len(self.datas[var].item()["times"]))
-                ]
-                for var in self.datas.keys()
-            }
-            # Data Extraction
-            self.u_wind = self.datas["UGRD"].item()["values"]
-            self.v_wind = self.datas["VGRD"].item()["values"]
-            self.humidity = self.datas["RH"].item()["values"]
-            self.temperature = self.datas["TMP"].item()["values"]
-            if self.time_cut_index is not None:
-                index_cut = min(
-                    self.time_cut_index,
-                    len(self.time_dict[list(self.time_dict.keys())[0]]),
-                )
-                self.u_wind = self.u_wind[:index_cut, :, :, :]
-                self.v_wind = self.v_wind[:index_cut, :, :, :]
-                self.humidity = self.humidity[:index_cut, :, :, :]
-                self.temperature = self.temperature[:index_cut, :, :, :]
-        elif isinstance(
-            file_npz, dict
-        ):  # Already loaded data in a dict (directly from parseWeather indeed)
-            self.datas = file_npz
-            self.lat_dict = {var: self.datas[var]["lats"] for var in self.datas.keys()}
-            self.long_dict = {
-                var: self.datas[var]["longs"] for var in self.datas.keys()
-            }
-            self.alt_dict = {var: self.datas[var]["feets"] for var in self.datas.keys()}
-            self.time_dict = {
-                var: self.datas[var]["times"] for var in self.datas.keys()
-            }
-            # Data Extraction
-            self.u_wind = self.datas["UGRD"]["values"]
-            self.v_wind = self.datas["VGRD"]["values"]
-            self.humidity = self.datas["RH"]["values"]
-            self.temperature = self.datas["TMP"]["values"]
-        for feat in self.lat_dict:
-            if self.lat_dict[feat][-1] < self.lat_dict[feat][0]:
-                self.lat_dict[feat] = self.lat_dict[feat][::-1]
-                if feat == "UGRD":
-                    self.u_wind = self.u_wind[:, :, ::-1, :]
-                elif feat == "VGRD":
-                    self.v_wind = self.v_wind[:, :, ::-1, :]
-                elif feat == "RH":
-                    self.humidity = self.humidity[:, :, ::-1, :]
-                elif feat == "TMP":
-                    self.temperature = self.temperature[:, :, ::-1, :]
-        self.norm_wind = np.sqrt(np.square(self.u_wind) + np.square(self.v_wind))
-        self.angle_wind = np.arctan2(self.v_wind, self.u_wind)
-        self.interpol_dict = {}
-        self.interpol_dict["wind"] = {
-            "norm": intergrid.Intergrid(
-                self.norm_wind,
-                lo=[
-                    min(self.time_dict["UGRD"]),
-                    min(self.alt_dict["UGRD"]),
-                    min(self.lat_dict["UGRD"]),
-                    min(self.long_dict["UGRD"]),
-                ],
-                hi=[
-                    max(self.time_dict["UGRD"]),
-                    max(self.alt_dict["UGRD"]),
-                    max(self.lat_dict["UGRD"]),
-                    max(self.long_dict["UGRD"]),
-                ],
-                maps=[
-                    self.time_dict["UGRD"],
-                    self.alt_dict["UGRD"],
-                    self.lat_dict["UGRD"],
-                    self.long_dict["UGRD"],
-                ],
-                verbose=False,
-                order=order_interp,
-            ),
-            "argument": intergrid.Intergrid(
-                self.angle_wind,
-                lo=[
-                    min(self.time_dict["UGRD"]),
-                    min(self.alt_dict["UGRD"]),
-                    min(self.lat_dict["UGRD"]),
-                    min(self.long_dict["UGRD"]),
-                ],
-                hi=[
-                    max(self.time_dict["UGRD"]),
-                    max(self.alt_dict["UGRD"]),
-                    max(self.lat_dict["UGRD"]),
-                    max(self.long_dict["UGRD"]),
-                ],
-                maps=[
-                    self.time_dict["UGRD"],
-                    self.alt_dict["UGRD"],
-                    self.lat_dict["UGRD"],
-                    self.long_dict["UGRD"],
-                ],
-                verbose=False,
-                order=order_interp,
-            ),
-        }
-        self.interpol_dict["humidity"] = intergrid.Intergrid(
-            self.humidity,
-            lo=[
-                min(self.time_dict["RH"]),
-                min(self.alt_dict["RH"]),
-                min(self.lat_dict["RH"]),
-                min(self.long_dict["RH"]),
-            ],
-            hi=[
-                max(self.time_dict["RH"]),
-                max(self.alt_dict["RH"]),
-                max(self.lat_dict["RH"]),
-                max(self.long_dict["RH"]),
-            ],
-            maps=[
-                self.time_dict["RH"],
-                self.alt_dict["RH"],
-                self.lat_dict["RH"],
-                self.long_dict["RH"],
-            ],
-            verbose=False,
-            order=order_interp,
-        )
-        self.interpol_dict["temperature"] = intergrid.Intergrid(
-            self.temperature,
-            lo=[
-                min(self.time_dict["TMP"]),
-                min(self.alt_dict["TMP"]),
-                min(self.lat_dict["TMP"]),
-                min(self.long_dict["TMP"]),
-            ],
-            hi=[
-                max(self.time_dict["TMP"]),
-                max(self.alt_dict["TMP"]),
-                max(self.lat_dict["TMP"]),
-                max(self.long_dict["TMP"]),
-            ],
-            maps=[
-                self.time_dict["TMP"],
-                self.alt_dict["TMP"],
-                self.lat_dict["TMP"],
-                self.long_dict["TMP"],
-            ],
-            verbose=False,
-            order=order_interp,
-        )
-
-    def interpol_wind_classic(self, lat, longi, alt=35000.0, t=0.0, **kwargs):
-        """
-        Interpol the wind in one 4D point
-
-        :param lat: latitude
-        :param longi: longitude
-        :param alt: altitude (in ft)
-        :param t: time in second
-        :return: [wind strength, direction, wind wector]
-        """
-        if longi < 0:
-            longi += 360.0
-        norm = self.interpol_dict["wind"]["norm"]([t, alt, lat, longi])
-        arg = self.interpol_dict["wind"]["argument"]([t, alt, lat, longi])
-        result = norm * np.array([np.cos(arg), np.sin(arg)])
-        return [norm, arg, result]
-
-    def interpol_wind(self, X):
-        """
-        Interpol wind for an array of 4D points
-
-        :param X: array of points [time (in s), alt (in ft), lat, long]
-        :return: wind vector.
-        """
-        arg = self.interpol_dict["wind"]["argument"](X)
-        return self.interpol_dict["wind"]["norm"](X) * np.array(
-            [[np.cos(arg), np.sin(arg)]]
-        )
-
-    def interpol_field(self, X, field="temperature"):
-        """
-        Interpol one field that is present in interpolators for array of 4d points
-
-        :param X: array of points [time (in s), alt (in ft), lat, long]
-        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
-        :return: array of interpolated values
-        """
-        return self.interpol_dict[field](X)
-
-    def transform_long(self, long):
-        """
-        [Deprecated] should be replaced by modulo function...
-
-        :param long: array of longitudes
-        :return: array of longitude put in positive domain (modulo 360.)
-        """
-        return np.where(long < 0, 360 + long, long)
-
-    def plot_wind(
-        self,
-        alt=35000.0,
-        down_long=-180.0,
-        up_long=180.0,
-        down_lat=-90.0,
-        up_lat=90.0,
-        t=0.0,
-        n_lat=180,
-        n_long=720,
-        plot_wind=False,
-        ax=None,
-    ):
-        """
-        Plot the wind for a given coordinates window for a given altitude and for one time/or range of time
-
-        :param alt: altitude couch to plot (in ft)
-        :param down_long: min longitude
-        :param up_long: max longitude
-        :param down_lat: min latitude
-        :param up_lat: max latitude
-        :param t: value of time step (in second) or list/array of time step (in s)
-        :type t: float or iterable
-        :param n_lat: number of latitude discretized steps
-        :param n_long: number of longitude discretized steps
-        :param plot_wind: plot the vector field
-        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
-        """
-        times = [t]
-        n_time = 1
-        if Toolbox.is_iterable(t):
-            times = t
-            n_time = len(t)
-        if ax is None:
-            fig, ax = plt.subplots(
-                1, 1, figsize=(10, 5), subplot_kw={"projection": ccrs.PlateCarree()}
-            )
-            ax.stock_img()
-        range_lat = np.linspace(down_lat, up_lat, n_lat)
-        range_long = np.linspace(down_long, up_long, n_long)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        range_long = self.transform_long(range_long)
-        values = np.array(
-            [
-                [time, alt, range_lat[i], range_long[j]]
-                for i in range(n_lat)
-                for j in range(n_long)
-                for time in times
-            ]
-        )
-        res = self.interpol_wind(values)
-        Ut = np.resize(res[0, 0, :], (n_lat, n_long, n_time))
-        Vt = np.resize(res[0, 1, :], (n_lat, n_long, n_time))
-        Nt = np.sqrt(np.square(Ut) + np.square(Vt))
-        # Nt = self.interpol_field(values, field="norw-wind")
-
-        i = 0
-        CS = ax.contourf(x, y, Nt[:, :, i], 20, alpha=0.5, zorder=2)
-        if plot_wind:
-            if x.shape[0] > 100:
-                q = ax.quiver(
-                    x[::10, ::10],
-                    y[::10, ::10],
-                    Ut[::10, ::10, i],
-                    Vt[::10, ::10, i],
-                    alpha=0.8,
-                )
-            else:
-                q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
-        plt.title("time : " + str(times[i]))
-        for i in range(1, n_time):
-            for coll in CS.collections:
-                plt.gca().collections.remove(coll)
-            CS = ax.contourf(x, y, Nt[:, :, i], 20, alpha=0.5, zorder=2)
-            if plot_wind:
-                q.remove()
-                if x.shape[0] > 100:
-                    q = ax.quiver(
-                        x[::10, ::10],
-                        y[::10, ::10],
-                        Ut[::10, ::10, i],
-                        Vt[::10, ::10, i],
-                        alpha=0.8,
-                    )
-                else:
-                    q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
-            plt.title("time : " + str(times[i]))
-            plt.draw()
-            plt.pause(0.1)
-        return ax
-
-    def plot_wind_noised(
-        self,
-        alt=35000.0,
-        down_long=-180.0,
-        up_long=180.0,
-        down_lat=-90.0,
-        up_lat=90.0,
-        t=0.0,
-        n_lat=180,
-        n_long=720,
-        plot_wind=False,
-        mean_noised_norm=1.05,
-        scale_noised_norm=0.01,
-        mean_noised_arg=0.1,
-        scale_noised_arg=0.01,
-        ax=None,
-    ):
-        """
-        Plot the wind for a given coordinates window for a given altitude and for one time/or range of time
-
-        :param alt: altitude couch to plot (in ft)
-        :param down_long: min longitude
-        :param up_long: max longitude
-        :param down_lat: min latitude
-        :param up_lat: max latitude
-        :param t: value of time step (in second) or list/array of time step (in s)
-        :type t: float or iterable
-        :param n_lat: number of latitude discretized steps
-        :param n_long: number of longitude discretized steps
-        :param plot_wind: plot the vector field
-        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
-        """
-        times = [t]
-        n_time = 1
-        if Toolbox.is_iterable(t):
-            times = t
-            n_time = len(t)
-        if ax is None:
-            fig, ax = plt.subplots(
-                1, 1, figsize=(10, 5), subplot_kw={"projection": ccrs.PlateCarree()}
-            )
-            ax.stock_img()
-        range_lat = np.linspace(down_lat, up_lat, n_lat)
-        range_long = np.linspace(down_long, up_long, n_long)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        range_long = self.transform_long(range_long)
-        values = np.array(
-            [
-                [time, alt, range_lat[i], range_long[j]]
-                for i in range(n_lat)
-                for j in range(n_long)
-                for time in times
-            ]
-        )
-
-        arg = self.interpol_dict["wind"]["argument"](values)
-        norm = self.interpol_dict["wind"]["norm"](values)
-        noised_norm = np.random.normal(
-            mean_noised_norm, scale=scale_noised_norm, size=norm.shape
-        )
-        norm = noised_norm * norm
-        noised_arg = np.random.normal(
-            mean_noised_arg, scale=scale_noised_arg, size=arg.shape
-        )
-
-        res_noised = norm * np.array(
-            [[np.cos(arg + noised_arg), np.sin(arg + noised_arg)]]
-        )
-        res = self.interpol_wind(values)
-        Ut_noised = np.resize(res_noised[0, 0, :], (n_lat, n_long, n_time))
-        Vt_noised = np.resize(res_noised[0, 1, :], (n_lat, n_long, n_time))
-        Nt_noised = np.sqrt(np.square(Ut_noised) + np.square(Vt_noised))
-        Ut = np.resize(res[0, 0, :], (n_lat, n_long, n_time))
-        Vt = np.resize(res[0, 1, :], (n_lat, n_long, n_time))
-        Nt = np.sqrt(np.square(Ut - Ut_noised) + np.square(Vt - Vt_noised))
-        i = 0
-        # CS = ax.contourf(x, y, Nt[:, :, i], 20, alpha=0.5, zorder=2)
-        if plot_wind:
-            if x.shape[0] > 100:
-                q = ax.quiver(
-                    x[::10, ::10],
-                    y[::10, ::10],
-                    Ut_noised[::10, ::10, i],
-                    Vt_noised[::10, ::10, i],
-                    alpha=0.8,
-                )
-            else:
-                q = ax.quiver(
-                    x,
-                    y,
-                    Ut_noised[:, :, i] - Ut[:, :, i],
-                    Vt_noised[:, :, i] - Vt[:, :, i],
-                    alpha=0.8,
-                )
-        plt.title("time : " + str(times[i]))
-        for i in range(1, n_time):
-            for coll in CS.collections:
-                plt.gca().collections.remove(coll)
-            CS = ax.contourf(x, y, Nt_noised[:, :, i], 20, alpha=0.5, zorder=2)
-            if plot_wind:
-                q.remove()
-                if x.shape[0] > 100:
-                    q = ax.quiver(
-                        x[::10, ::10],
-                        y[::10, ::10],
-                        Ut_noised[::10, ::10, i],
-                        Vt_noised[::10, ::10, i],
-                        alpha=0.8,
-                    )
-                else:
-                    q = ax.quiver(
-                        x, y, Ut_noised[:, :, i], Vt_noised[:, :, i], alpha=0.8
-                    )
-            plt.title("time : " + str(times[i]))
-            plt.draw()
-            plt.pause(0.1)
-        return ax
-
-    def plot_matrix_wind(self, index_alt=10, index_time=0, ax=None):
-        """
-        [Deprecated]
-
-        Plot the wind matrix directly (no interpolation contrary
-        to :func:`BEN3_G.Contrails.WeatherForecastInterpolator.plot_wind`
-        """
-        down_long = -180.0
-        up_long = 180.0
-        down_lat = -90.0
-        up_lat = 90.0
-        if ax is None:
-            fig, ax = plt.subplots(1, figsize=(8, 10))
-            ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180.0))
-            ax.stock_img()
-            m = ax
-        else:
-            m = ax
-        range_lat = np.linspace(down_lat, up_lat, 1000)
-        range_long = np.linspace(down_long, up_long, 1000)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        norm = np.sqrt(
-            np.square(self.temperature[index_time, index_alt, :, :])
-            + np.square(self.temperature[index_time, index_alt, :, :])
-        )
-        ax.imshow(
-            norm,
-            cmap="hot",
-            interpolation="nearest",
-            extent=[-180.0, 180.0, -90.0, 90.0],
-            alpha=0.5,
-        )
-        # plt.gca().invert_yaxis()
-        # ax.colorbar()
-
-    def plot_matrix_wind_noised(self, index_alt=10, index_time=0, ax=None):
-        """
-        [Deprecated]
-
-        Plot the wind matrix directly (no interpolation contrary
-        to :func:`BEN3_G.Contrails.WeatherForecastInterpolator.plot_wind`
-        """
-        down_long = -180.0
-        up_long = 180.0
-        down_lat = -90.0
-        up_lat = 90.0
-        if ax is None:
-            fig, ax = plt.subplots(1, figsize=(8, 10))
-            ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180.0))
-            ax.stock_img()
-            m = ax
-        else:
-            m = ax
-        range_lat = np.linspace(down_lat, up_lat, 1000)
-        range_long = np.linspace(down_long, up_long, 1000)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        norm = np.sqrt(
-            np.square(self.u_wind[index_time, index_alt, ::-1, :])
-            + np.square(self.v_wind[index_time, index_alt, ::-1, :])
-        )
-        ax.imshow(
-            norm,
-            cmap="hot",
-            interpolation="nearest",
-            extent=[-180.0, 180.0, 90.0, -90.0],
-            alpha=0.5,
-        )
-        plt.gca().invert_yaxis()
-        ax.colorbar()
-
-    def plot_field(
-        self, field="issr", alt=35000.0, t=0.0, n_lat=180, n_long=720, ax=None
-    ):
-        """
-        Plot a field for a given altitude and for one time/or range of time
-
-        :param alt: altitude couch to plot (in ft)
-        :param t: value of time step (in second) or list/array of time step (in s)
-        :param n_lat: number of latitude discretized steps
-        :param n_long: number of longitude discretized steps
-        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
-        """
-        # plot the entire interpolate field
-        # p = alt2press(alt)
-        p = alt
-        times = [t]
-        n_time = 1
-        if Toolbox.is_iterable(t):
-            times = t
-            n_time = len(t)
-
-        down_long = -180.0
-        up_long = 180.0
-        down_lat = -90.0
-        up_lat = 90.0
-        if ax is None:
-            fig, ax = plt.subplots(1, figsize=(8, 10))
-            ax = plt.axes(projection=ccrs.PlateCarree())
-            ax.stock_img()
-            m = ax
-        else:
-            m = ax
-        range_lat = np.linspace(down_lat, up_lat, n_lat)
-        range_long = np.linspace(down_long, up_long, n_long)
-        XX, YY = np.meshgrid(range_long, range_lat)
-        x, y = XX, YY
-        range_long = self.transform_long(range_long)
-        Ut = np.zeros((n_lat, n_long))
-        values = np.array(
-            [
-                [time, alt, range_lat[i], range_long[j]]
-                for i in range(0, n_lat)
-                for j in range(0, n_long)
-                for time in times
-            ]
-        )
-        Ut = np.resize(self.interpol_dict[field](values), (n_lat, n_long, n_time))
-        i = 0
-        cs = ax.contour(
-            x,
-            y,
-            Ut[:, :, i],
-            extent=[down_long, up_long, down_lat, up_lat],
-            alpha=0.9,
-            zorder=2,
-        )
-        plt.title("time " + str(times[i]))
-        plt.draw()
-        plt.pause(0.1)
-        for i in range(1, n_time):
-            for coll in cs.collections:
-                plt.gca().collections.remove(coll)
-            cs = ax.contour(
-                x,
-                y,
-                Ut[:, :, i],
-                extent=[down_long, up_long, down_lat, up_lat],
-                alpha=0.9,
-                zorder=2,
-            )
-            plt.title("time : " + str(times[i]))
-            plt.draw()
-            plt.pause(1)
-        return m
-
-    def render(self, ax, **kwargs):
-        self.plot_matrix_wind(index_alt=0, index_time=0, ax=ax)
+from abc import ABC, abstractmethod
+
+import cartopy.crs as ccrs
+import matplotlib.pyplot as plt
+import numpy as np
+
+import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.common_utils as Toolbox
+import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.intergrid as intergrid
+
+
+class WeatherInterpolator(ABC):
+    @abstractmethod
+    def interpol_wind(self, X):
+        """
+        Interpol wind for an array of 4D points
+
+        :param X: array of points [time (in s), alt (in ft), lat, long]
+        :return: wind vector.
+        """
+        ...
+
+    @abstractmethod
+    def interpol_field(self, X, field="temperature"):
+        """
+        Interpol one field that is present in interpolators for array of 4d points
+
+        :param X: array of points [time (in s), alt (in ft), lat, long]
+        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
+        :return: array of interpolated values
+        """
+        ...
+
+    @abstractmethod
+    def interpol_wind_classic(self, lat, longi, alt, **kwargs):
+        """
+        Interpolate the wind.
+        :param lat: latitude in degree
+        :param longi: longitude in degree
+        :param alt: altitude in feet
+        :param kwargs: other parameters for the given weather data underlying. example : id of the ensemble forecast.
+        :return:
+        """
+        ...
+
+    @abstractmethod
+    def render(self, ax, **kwargs):
+        ...
+
+
+class WeatherForecastInterpolator(WeatherInterpolator):
+    """
+    Class used to store weather data, interpolate and plot weather forecast from .npz files
+    """
+
+    def __init__(self, file_npz, time_cut_index=None, order_interp=1):
+        """
+        Stores the weather data and build the interpolators on grid.
+        """
+        # Files Loading
+        self.time_cut_index = time_cut_index
+        if isinstance(file_npz, (str, np.lib.npyio.NpzFile)):
+            self.datas = np.load(file_npz) if isinstance(file_npz, str) else file_npz
+
+            self.lat_dict = {
+                var: self.datas[var].item()["lats"] for var in self.datas.keys()
+            }
+            self.long_dict = {
+                var: self.datas[var].item()["longs"] for var in self.datas.keys()
+            }
+            self.alt_dict = {
+                var: self.datas[var].item()["levels"] for var in self.datas.keys()
+            }
+            self.time_dict = {
+                var: self.datas[var].item()["times"]
+                if self.time_cut_index is None
+                else self.datas[var].item()["times"][
+                    : min(self.time_cut_index, len(self.datas[var].item()["times"]))
+                ]
+                for var in self.datas.keys()
+            }
+            # Data Extraction
+            # self.u_wind = self.datas["U"].item()["values"]
+            # self.v_wind = self.datas["V"].item()["values"]
+            self.humidity = self.datas["R"].item()["values"]
+            self.temperature = self.datas["T"].item()["values"]
+
+            if self.time_cut_index is not None:
+                index_cut = min(
+                    self.time_cut_index,
+                    len(self.time_dict[list(self.time_dict.keys())[0]]),
+                )
+                # self.u_wind = self.u_wind[:index_cut, :, :, :]
+                # self.v_wind = self.v_wind[:index_cut, :, :, :]
+                self.humidity = self.humidity[:index_cut, :, :, :]
+                self.temperature = self.temperature[:index_cut, :, :, :]
+        elif isinstance(
+            file_npz, dict
+        ):  # Already loaded data in a dict (directly from parseWeather indeed)
+
+            self.datas = file_npz
+            self.lat_dict = {var: self.datas[var]["lats"] for var in self.datas.keys()}
+            self.long_dict = {
+                var: self.datas[var]["longs"] for var in self.datas.keys()
+            }
+            self.alt_dict = {
+                var: self.datas[var]["levels"] for var in self.datas.keys()
+            }
+            self.time_dict = {
+                var: self.datas[var]["times"] for var in self.datas.keys()
+            }
+            # Data Extraction
+            # self.u_wind = self.datas["U"]["values"]
+            # self.v_wind = self.datas["V"]["values"]
+            self.humidity = self.datas["R"]["values"]
+            self.temperature = self.datas["T"]["values"]
+
+        for feat in self.lat_dict:
+            if self.lat_dict[feat][-1] < self.lat_dict[feat][0]:
+                self.lat_dict[feat] = self.lat_dict[feat][::-1]
+                # if feat == "U":
+                #     self.u_wind = self.u_wind[:, :, ::-1, :]
+                # elif feat == "V":
+                #     self.v_wind = self.v_wind[:, :, ::-1, :]
+                if feat == "R":
+                    self.humidity = self.humidity[:, :, ::-1, :]
+                elif feat == "T":
+                    self.temperature = self.temperature[:, :, ::-1, :]
+
+        # self.norm_wind = np.sqrt(np.square(self.u_wind) + np.square(self.v_wind))
+        # self.angle_wind = np.arctan2(self.v_wind, self.u_wind)
+
+        self.interpol_dict = {}
+        # self.interpol_dict["wind"] = {
+        #     "norm": intergrid.Intergrid(
+        #         self.norm_wind,
+        #         lo=[
+        #             min(self.time_dict["U"]),
+        #             min(self.alt_dict["U"]),
+        #             min(self.lat_dict["U"]),
+        #             min(self.long_dict["U"]),
+        #         ],
+        #         hi=[
+        #             max(self.time_dict["U"]),
+        #             max(self.alt_dict["U"]),
+        #             max(self.lat_dict["U"]),
+        #             max(self.long_dict["U"]),
+        #         ],
+        #         maps=[
+        #             self.time_dict["U"],
+        #             self.alt_dict["U"],
+        #             self.lat_dict["U"],
+        #             self.long_dict["U"],
+        #         ],
+        #         verbose=False,
+        #         order=order_interp,
+        #     ),
+
+        #     "argument": intergrid.Intergrid(
+        #         self.angle_wind,
+        #         lo=[
+        #             min(self.time_dict["U"]),
+        #             min(self.alt_dict["U"]),
+        #             min(self.lat_dict["U"]),
+        #             min(self.long_dict["U"]),
+        #         ],
+        #         hi=[
+        #             max(self.time_dict["U"]),
+        #             max(self.alt_dict["U"]),
+        #             max(self.lat_dict["U"]),
+        #             max(self.long_dict["U"]),
+        #         ],
+        #         maps=[
+        #             self.time_dict["U"],
+        #             self.alt_dict["U"],
+        #             self.lat_dict["U"],
+        #             self.long_dict["U"],
+        #         ],
+        #         verbose=False,
+        #         order=order_interp,
+        #     ),
+        # }
+        self.interpol_dict["humidity"] = intergrid.Intergrid(
+            self.humidity,
+            lo=[
+                min(self.time_dict["R"]),
+                min(self.alt_dict["R"]),
+                min(self.lat_dict["R"]),
+                min(self.long_dict["R"]),
+            ],
+            hi=[
+                max(self.time_dict["R"]),
+                max(self.alt_dict["R"]),
+                max(self.lat_dict["R"]),
+                max(self.long_dict["R"]),
+            ],
+            maps=[
+                self.time_dict["R"],
+                self.alt_dict["R"],
+                self.lat_dict["R"],
+                self.long_dict["R"],
+            ],
+            verbose=False,
+            order=order_interp,
+        )
+        self.interpol_dict["temperature"] = intergrid.Intergrid(
+            self.temperature,
+            lo=[
+                min(self.time_dict["T"]),
+                min(self.alt_dict["T"]),
+                min(self.lat_dict["T"]),
+                min(self.long_dict["T"]),
+            ],
+            hi=[
+                max(self.time_dict["T"]),
+                max(self.alt_dict["T"]),
+                max(self.lat_dict["T"]),
+                max(self.long_dict["T"]),
+            ],
+            maps=[
+                self.time_dict["T"],
+                self.alt_dict["T"],
+                self.lat_dict["T"],
+                self.long_dict["T"],
+            ],
+            verbose=False,
+            order=order_interp,
+        )
+
+    def interpol_wind_classic(self, lat, longi, alt=35000.0, t=0.0, **kwargs):
+        """
+        Interpol the wind in one 4D point
+
+        :param lat: latitude
+        :param longi: longitude
+        :param alt: altitude (in ft)
+        :param t: time in second
+        :return: [wind strength, direction, wind wector]
+        """
+        pass
+        # if longi < 0:
+        #     longi += 360.0
+        # norm = self.interpol_dict["wind"]["norm"]([t, alt, lat, longi])
+        # arg = self.interpol_dict["wind"]["argument"]([t, alt, lat, longi])
+        # result = norm * np.array([np.cos(arg), np.sin(arg)])
+        # return [norm, arg, result]
+
+    def interpol_wind(self, X):
+        """
+        Interpol wind for an array of 4D points
+
+        :param X: array of points [time (in s), alt (in ft), lat, long]
+        :return: wind vector.
+        """
+        pass
+        # arg = self.interpol_dict["wind"]["argument"](X)
+        # return self.interpol_dict["wind"]["norm"](X) * np.array(
+        #     [[np.cos(arg), np.sin(arg)]]
+        # )
+
+    def interpol_field(self, X, field="temperature"):
+        """
+        Interpol one field that is present in interpolators for array of 4d points
+
+        :param X: array of points [time (in s), alt (in ft), lat, long]
+        :param field: field of weather data to interpolate (could be 'temperature' or 'humidity'
+        :return: array of interpolated values
+        """
+        return self.interpol_dict[field](X)
+
+    def transform_long(self, long):
+        """
+        [Deprecated] should be replaced by modulo function...
+
+        :param long: array of longitudes
+        :return: array of longitude put in positive domain (modulo 360.)
+        """
+        return np.where(long < 0, 360 + long, long)
+
+    def plot_wind(
+        self,
+        alt=35000.0,
+        down_long=-180.0,
+        up_long=180.0,
+        down_lat=-90.0,
+        up_lat=90.0,
+        t=0.0,
+        n_lat=180,
+        n_long=720,
+        plot_wind=False,
+        ax=None,
+    ):
+        """
+        Plot the wind for a given coordinates window for a given altitude and for one time/or range of time
+
+        :param alt: altitude couch to plot (in ft)
+        :param down_long: min longitude
+        :param up_long: max longitude
+        :param down_lat: min latitude
+        :param up_lat: max latitude
+        :param t: value of time step (in second) or list/array of time step (in s)
+        :type t: float or iterable
+        :param n_lat: number of latitude discretized steps
+        :param n_long: number of longitude discretized steps
+        :param plot_wind: plot the vector field
+        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
+        """
+        times = [t]
+        n_time = 1
+        if Toolbox.is_iterable(t):
+            times = t
+            n_time = len(t)
+        if ax is None:
+            fig, ax = plt.subplots(
+                1, 1, figsize=(10, 5), subplot_kw={"projection": ccrs.PlateCarree()}
+            )
+            ax.stock_img()
+        range_lat = np.linspace(down_lat, up_lat, n_lat)
+        range_long = np.linspace(down_long, up_long, n_long)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        range_long = self.transform_long(range_long)
+        values = np.array(
+            [
+                [time, alt, range_lat[i], range_long[j]]
+                for i in range(n_lat)
+                for j in range(n_long)
+                for time in times
+            ]
+        )
+        res = self.interpol_wind(values)
+        Ut = np.resize(res[0, 0, :], (n_lat, n_long, n_time))
+        Vt = np.resize(res[0, 1, :], (n_lat, n_long, n_time))
+        Nt = np.sqrt(np.square(Ut) + np.square(Vt))
+        # Nt = self.interpol_field(values, field="norw-wind")
+
+        i = 0
+        CS = ax.contourf(x, y, Nt[:, :, i], 20, alpha=0.5, zorder=2)
+        if plot_wind:
+            if x.shape[0] > 100:
+                q = ax.quiver(
+                    x[::10, ::10],
+                    y[::10, ::10],
+                    Ut[::10, ::10, i],
+                    Vt[::10, ::10, i],
+                    alpha=0.8,
+                )
+            else:
+                q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
+        plt.title("time : " + str(times[i]))
+        for i in range(1, n_time):
+            for coll in CS.collections:
+                plt.gca().collections.remove(coll)
+            CS = ax.contourf(x, y, Nt[:, :, i], 20, alpha=0.5, zorder=2)
+            if plot_wind:
+                q.remove()
+                if x.shape[0] > 100:
+                    q = ax.quiver(
+                        x[::10, ::10],
+                        y[::10, ::10],
+                        Ut[::10, ::10, i],
+                        Vt[::10, ::10, i],
+                        alpha=0.8,
+                    )
+                else:
+                    q = ax.quiver(x, y, Ut[:, :, i], Vt[:, :, i], alpha=0.8)
+            plt.title("time : " + str(times[i]))
+            plt.draw()
+            plt.pause(0.1)
+        return ax
+
+    def plot_wind_noised(
+        self,
+        alt=35000.0,
+        down_long=-180.0,
+        up_long=180.0,
+        down_lat=-90.0,
+        up_lat=90.0,
+        t=0.0,
+        n_lat=180,
+        n_long=720,
+        plot_wind=False,
+        mean_noised_norm=1.05,
+        scale_noised_norm=0.01,
+        mean_noised_arg=0.1,
+        scale_noised_arg=0.01,
+        ax=None,
+    ):
+        """
+        Plot the wind for a given coordinates window for a given altitude and for one time/or range of time
+
+        :param alt: altitude couch to plot (in ft)
+        :param down_long: min longitude
+        :param up_long: max longitude
+        :param down_lat: min latitude
+        :param up_lat: max latitude
+        :param t: value of time step (in second) or list/array of time step (in s)
+        :type t: float or iterable
+        :param n_lat: number of latitude discretized steps
+        :param n_long: number of longitude discretized steps
+        :param plot_wind: plot the vector field
+        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
+        """
+        times = [t]
+        n_time = 1
+        if Toolbox.is_iterable(t):
+            times = t
+            n_time = len(t)
+        if ax is None:
+            fig, ax = plt.subplots(
+                1, 1, figsize=(10, 5), subplot_kw={"projection": ccrs.PlateCarree()}
+            )
+            ax.stock_img()
+        range_lat = np.linspace(down_lat, up_lat, n_lat)
+        range_long = np.linspace(down_long, up_long, n_long)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        range_long = self.transform_long(range_long)
+        values = np.array(
+            [
+                [time, alt, range_lat[i], range_long[j]]
+                for i in range(n_lat)
+                for j in range(n_long)
+                for time in times
+            ]
+        )
+
+        arg = self.interpol_dict["wind"]["argument"](values)
+        norm = self.interpol_dict["wind"]["norm"](values)
+        noised_norm = np.random.normal(
+            mean_noised_norm, scale=scale_noised_norm, size=norm.shape
+        )
+        norm = noised_norm * norm
+        noised_arg = np.random.normal(
+            mean_noised_arg, scale=scale_noised_arg, size=arg.shape
+        )
+
+        res_noised = norm * np.array(
+            [[np.cos(arg + noised_arg), np.sin(arg + noised_arg)]]
+        )
+        res = self.interpol_wind(values)
+        Ut_noised = np.resize(res_noised[0, 0, :], (n_lat, n_long, n_time))
+        Vt_noised = np.resize(res_noised[0, 1, :], (n_lat, n_long, n_time))
+        Nt_noised = np.sqrt(np.square(Ut_noised) + np.square(Vt_noised))
+        Ut = np.resize(res[0, 0, :], (n_lat, n_long, n_time))
+        Vt = np.resize(res[0, 1, :], (n_lat, n_long, n_time))
+        Nt = np.sqrt(np.square(Ut - Ut_noised) + np.square(Vt - Vt_noised))
+        i = 0
+        # CS = ax.contourf(x, y, Nt[:, :, i], 20, alpha=0.5, zorder=2)
+        if plot_wind:
+            if x.shape[0] > 100:
+                q = ax.quiver(
+                    x[::10, ::10],
+                    y[::10, ::10],
+                    Ut_noised[::10, ::10, i],
+                    Vt_noised[::10, ::10, i],
+                    alpha=0.8,
+                )
+            else:
+                q = ax.quiver(
+                    x,
+                    y,
+                    Ut_noised[:, :, i] - Ut[:, :, i],
+                    Vt_noised[:, :, i] - Vt[:, :, i],
+                    alpha=0.8,
+                )
+        plt.title("time : " + str(times[i]))
+        for i in range(1, n_time):
+            for coll in CS.collections:
+                plt.gca().collections.remove(coll)
+            CS = ax.contourf(x, y, Nt_noised[:, :, i], 20, alpha=0.5, zorder=2)
+            if plot_wind:
+                q.remove()
+                if x.shape[0] > 100:
+                    q = ax.quiver(
+                        x[::10, ::10],
+                        y[::10, ::10],
+                        Ut_noised[::10, ::10, i],
+                        Vt_noised[::10, ::10, i],
+                        alpha=0.8,
+                    )
+                else:
+                    q = ax.quiver(
+                        x, y, Ut_noised[:, :, i], Vt_noised[:, :, i], alpha=0.8
+                    )
+            plt.title("time : " + str(times[i]))
+            plt.draw()
+            plt.pause(0.1)
+        return ax
+
+    def plot_matrix_wind(self, index_alt=10, index_time=0, ax=None):
+        """
+        [Deprecated]
+
+        Plot the wind matrix directly (no interpolation contrary
+        to :func:`BEN3_G.Contrails.WeatherForecastInterpolator.plot_wind`
+        """
+        down_long = -180.0
+        up_long = 180.0
+        down_lat = -90.0
+        up_lat = 90.0
+        if ax is None:
+            fig, ax = plt.subplots(1, figsize=(8, 10))
+            ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180.0))
+            ax.stock_img()
+            m = ax
+        else:
+            m = ax
+        range_lat = np.linspace(down_lat, up_lat, 1000)
+        range_long = np.linspace(down_long, up_long, 1000)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        norm = np.sqrt(
+            np.square(self.temperature[index_time, index_alt, :, :])
+            + np.square(self.temperature[index_time, index_alt, :, :])
+        )
+        ax.imshow(
+            norm,
+            cmap="hot",
+            interpolation="nearest",
+            extent=[-180.0, 180.0, -90.0, 90.0],
+            alpha=0.5,
+        )
+        # plt.gca().invert_yaxis()
+        # ax.colorbar()
+
+    def plot_matrix_wind_noised(self, index_alt=10, index_time=0, ax=None):
+        """
+        [Deprecated]
+
+        Plot the wind matrix directly (no interpolation contrary
+        to :func:`BEN3_G.Contrails.WeatherForecastInterpolator.plot_wind`
+        """
+        down_long = -180.0
+        up_long = 180.0
+        down_lat = -90.0
+        up_lat = 90.0
+        if ax is None:
+            fig, ax = plt.subplots(1, figsize=(8, 10))
+            ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180.0))
+            ax.stock_img()
+            m = ax
+        else:
+            m = ax
+        range_lat = np.linspace(down_lat, up_lat, 1000)
+        range_long = np.linspace(down_long, up_long, 1000)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        norm = np.sqrt(
+            np.square(self.u_wind[index_time, index_alt, ::-1, :])
+            + np.square(self.v_wind[index_time, index_alt, ::-1, :])
+        )
+        ax.imshow(
+            norm,
+            cmap="hot",
+            interpolation="nearest",
+            extent=[-180.0, 180.0, 90.0, -90.0],
+            alpha=0.5,
+        )
+        plt.gca().invert_yaxis()
+        ax.colorbar()
+
+    def plot_field(
+        self, field="issr", alt=35000.0, t=0.0, n_lat=180, n_long=720, ax=None
+    ):
+        """
+        Plot a field for a given altitude and for one time/or range of time
+
+        :param alt: altitude couch to plot (in ft)
+        :param t: value of time step (in second) or list/array of time step (in s)
+        :param n_lat: number of latitude discretized steps
+        :param n_long: number of longitude discretized steps
+        :param ax: Ax object where to plot the wind (possibily a precomputed basemap or classic ax object)
+        """
+        # plot the entire interpolate field
+        # p = alt2press(alt)
+        p = alt
+        times = [t]
+        n_time = 1
+        if Toolbox.is_iterable(t):
+            times = t
+            n_time = len(t)
+
+        down_long = -180.0
+        up_long = 180.0
+        down_lat = -90.0
+        up_lat = 90.0
+        if ax is None:
+            fig, ax = plt.subplots(1, figsize=(8, 10))
+            ax = plt.axes(projection=ccrs.PlateCarree())
+            ax.stock_img()
+            m = ax
+        else:
+            m = ax
+        range_lat = np.linspace(down_lat, up_lat, n_lat)
+        range_long = np.linspace(down_long, up_long, n_long)
+        XX, YY = np.meshgrid(range_long, range_lat)
+        x, y = XX, YY
+        range_long = self.transform_long(range_long)
+        Ut = np.zeros((n_lat, n_long))
+        values = np.array(
+            [
+                [time, alt, range_lat[i], range_long[j]]
+                for i in range(0, n_lat)
+                for j in range(0, n_long)
+                for time in times
+            ]
+        )
+        Ut = np.resize(self.interpol_dict[field](values), (n_lat, n_long, n_time))
+        i = 0
+        cs = ax.contour(
+            x,
+            y,
+            Ut[:, :, i],
+            extent=[down_long, up_long, down_lat, up_lat],
+            alpha=0.9,
+            zorder=2,
+        )
+        plt.title("time " + str(times[i]))
+        plt.draw()
+        plt.pause(0.1)
+        for i in range(1, n_time):
+            for coll in cs.collections:
+                plt.gca().collections.remove(coll)
+            cs = ax.contour(
+                x,
+                y,
+                Ut[:, :, i],
+                extent=[down_long, up_long, down_lat, up_lat],
+                alpha=0.9,
+                zorder=2,
+            )
+            plt.title("time : " + str(times[i]))
+            plt.draw()
+            plt.pause(1)
+        return m
+
+    def render(self, ax, **kwargs):
+        pass
+        # self.plot_matrix_wind(index_alt=0, index_time=0, ax=ax)
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/parser_pygrib.py

```diff
@@ -1,581 +1,580 @@
-import datetime
-import os
-import sys
-
-import numpy as np
-import pygrib
-import pytz
-
-
-def computeTimeStamps(dates, times, steps):
-    """
-    This method computes the time stamp from dates, times and step from forecast.
-
-    :param dates: List of dates with the following format YYYYMMDD.
-    :type dates: list
-    :param times: List of forecast time provided as integers.
-    :type times: list
-    :param steps: List of forecast steps provided as integers.
-    :type steps: list
-    :return: List of timestamps as datetimes.
-    :rtype: list
-    """
-    timestamps = set()
-    for date in dates:
-        date_string = "{0:-08d}".format(date)
-        for time in times:
-            hour = int(time / 100)
-            date_object = datetime.datetime(
-                year=int(date_string[0:4]),
-                month=int(date_string[4:6]),
-                day=int(date_string[6:8]),
-                hour=hour,
-                minute=0,
-                second=0,
-                tzinfo=pytz.utc,
-            )
-            for step in steps:
-                forecast_datetime = date_object + datetime.timedelta(hours=int(step))
-                # forecast_datetime = forecast_datetime.replace(tzinfo=pytz.utc)
-                # forecast_datetime.timestamp()
-                timestamps.add(forecast_datetime.timestamp())
-    return list(timestamps)
-
-
-def computeTimeStamp(date, time, step):
-    """
-    This method computes a single time stamp value from a forecast date, time and step.
-
-    :param date: date with the following format YYYYMMDD.
-    :type date: int
-    :param time: forecast time value.
-    :type time: int
-    :param step: forecast step value.
-    :type step: int
-    :return: timestamp
-    :rtype: datetime.datetime
-    """
-    date_string = "{0:-08d}".format(date)
-    hour = int(time / 100)
-    date_object = datetime.datetime(
-        year=int(date_string[0:4]),
-        month=int(date_string[4:6]),
-        day=int(date_string[6:8]),
-        hour=hour,
-        minute=0,
-        second=0,
-        tzinfo=pytz.utc,
-    )
-    forecast_datetime = date_object + datetime.timedelta(hours=int(step))
-    # forecast_datetime.replace(tzinfo=pytz.utc)
-    return datetime.datetime.timestamp(forecast_datetime)
-
-
-def flip_matrix(matrix):
-    """
-    Method to flip reverse the order of the elements in the latitude axis of an array.
-
-    :param matrix: Dictionary with the matrix to perform the flip.
-    :type matrix: dict
-    :return: Dictionary with the flipped matrix.
-    :rtype: dict
-    """
-    for var in matrix:
-        if matrix[var]["lats"][-1] < matrix[var]["lats"][0]:
-            matrix[var]["lats"] = matrix[var]["lats"][::-1]
-            matrix[var]["values"] = np.flip(
-                matrix[var]["values"], matrix[var]["values"].ndim - 2
-            )
-
-
-class GribPygribUniqueForecast(object):
-    """
-    This class transforms a grib file into a dictionary containing the values of desired parameters. It allows the
-    extraction of just one variable or set of variables corresponding to: CAT, Windshear, Icing, Wind uncertainty and
-    convection. It is based on Pygrib library.
-
-    """
-
-    def __init__(
-        self, grib_path, grib_name, selected_forecast_dates=None, selected_levels=None
-    ):
-        """
-        Initialization.
-
-        :param grib_path: Grib file path.
-        :type grib_path: str
-        :param grib_name: Grib file name.
-        :type grib_name: str
-        :param selected_forecast_dates: List of selected forecast dates.
-        :type selected_forecast_dates: list
-        :param selected_levels: List of selected levels.
-        :type selected_levels: list
-        """
-
-        # open grib file with pygrib
-        gribs = pygrib.open(os.path.join(grib_path, grib_name))
-        self.gribs = gribs
-
-        # save latitudes and longitudes
-        latlons = gribs[1].latlons()
-        latitudes = latlons[0][:, 0]
-        longitudes = latlons[1][0, :]
-        self.latitudes = latitudes
-        self.longitudes = longitudes
-
-        # save dates times steps and levels
-        dates = set()
-        times = set()
-        steps = set()
-        levels = set()
-        members = set()
-        parameters_full_names = set()
-        parameters_short_names = set()
-        forecast_dates = set()
-        for grib in gribs:
-            dates.add(grib.date)
-            times.add(grib.dataTime)
-            # in some sfc forecast grib.stepRange[0]is e.g.: 0-3 this is not a valid step
-            # print(dates)
-            # print(times)
-            # print(grib.analDate)
-            # print(grib.validDate)
-            date = grib.validDate.replace(tzinfo=pytz.utc)
-            forecast_dates.add(date.timestamp())
-            # print(datetime.datetime.fromtimestamp(date.timestamp(), tz=pytz.utc))
-            try:
-                int(grib.stepRange)
-                # print(grib.stepRange)
-                steps.add(grib.stepRange)
-            except:
-                # do nothgin
-                continue
-            levels.add(grib.level)
-            # members.add(grib.perturbationNumber - 1)
-            parameters_full_names.add(grib.parameterName)
-            parameters_short_names.add(grib.shortName)
-        self.dates = list(dates)
-        self.times = list(times)
-        self.steps = list(steps)
-        # check if grib has the content supported by GribPygrib object.
-        if len(self.dates) > 1 or len(self.times) > 1:
-            sys.exit(
-                "Not supported by GribPygrib dates or times len is greater than 1. dates{0} times:{1}".format(
-                    self.dates, self.times
-                )
-            )
-        self.forecast_dates = sorted(list(forecast_dates))
-        self.levels = sorted(list(levels))
-        self.members = sorted(list(members))
-        self.parameters_full_names = list(parameters_full_names)
-        self.parameters_short_names = list(parameters_short_names)
-        self.num_forecast = len(dates) * len(times) * len(steps)
-        self.timestamps = sorted(computeTimeStamps(dates, times, steps))
-
-        # evaluate selected variables to be able to specify pl and/or forecast dates
-        if selected_forecast_dates is None:
-            self.selected_forecast_dates = self.timestamps
-        else:
-            self.selected_forecast_dates = selected_forecast_dates
-
-        if selected_levels is None:
-            self.selected_levels = self.levels
-        else:
-            self.selected_levels = selected_levels
-
-        # create list to later use index property
-        self.selected_forecast_dates = list(self.selected_forecast_dates)
-        self.selected_levels = list(self.selected_levels)
-
-    def isParameterInGrib(self, parameter):
-        """
-        Method to check if a parameter is in the grib file.
-
-        :param parameter: Parameter that needs to be checked.
-        :type parameter: str
-        :return: True if is in grib, False otherwise.
-        :rtype: bool
-        """
-        result = False
-        if parameter in self.parameters_short_names:
-            result = True
-        return result
-
-    # Generic function to collect parameter values
-    # ============================================
-    def getParameterUniqueForecast(self, parameter, levels=None):
-        gribs = self.gribs
-        merged_matrix_dict = {parameter.upper(): {}}
-        merged_matrix_dict[parameter.upper()]["values"] = []
-        merged_matrix_dict[parameter.upper()]["longs"] = []
-        merged_matrix_dict[parameter.upper()]["lats"] = []
-        merged_matrix_dict[parameter.upper()]["times"] = []
-        if levels is None:
-            levels = self.selected_levels
-        coordinates = [
-            ("t", self.selected_forecast_dates),
-            ("pl", levels),
-            ("lat", self.latitudes),
-            ("lon", self.longitudes),
-        ]
-        axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
-        nan_array = np.empty(axis_sizes)
-        nan_array.fill(np.NaN)
-        merged_matrix_dict[parameter.upper()]["values"] = nan_array
-        gribs.rewind()
-        for grib in gribs:
-            ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
-            if (
-                (grib.shortName == parameter)
-                and (ts in self.selected_forecast_dates)
-                and (grib.level in levels)
-            ):
-                index_time = self.selected_forecast_dates.index(ts)
-                if levels is None:
-                    index_level = 0
-                else:
-                    index_level = levels.index(grib.level)
-                merged_matrix_dict[parameter.upper()]["values"][
-                    index_time, index_level, :, :
-                ] = np.array(grib.values)
-        merged_matrix_dict[parameter.upper()]["times"] = np.array(
-            self.selected_forecast_dates
-        )
-        merged_matrix_dict[parameter.upper()]["levels"] = np.array(levels)
-        merged_matrix_dict[parameter.upper()]["longs"] = np.array(self.longitudes)
-        merged_matrix_dict[parameter.upper()]["lats"] = np.array(self.latitudes)
-        return merged_matrix_dict
-
-    # parameters needed in convection
-    # ===============================
-    def getTTs(self):
-        """
-        This function gets the parameter 'totalx': Total totals index (K).
-        It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary with the array containing parameter 'totalx'.
-        :rtype: dict
-        """
-        return self.getParameters(["totalx"])
-
-    def getCPs(self):
-        """
-        This function gets the parameter 'cp': Convective precipitation.
-        It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary with the array containing parameter 'cp'.
-        :rtype: dict
-        """
-        return self.getParameters(["cp"])
-
-    # parameters needed in icing
-    # ==========================
-    def getTemps(self):
-        """
-        This function gets the parameter 't': Temperature (K).
-        It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary with the array containing parameter 't'.
-        :rtype: dict
-        """
-        return self.getParameters(["t"], self.levels)
-
-    def getRelativeHumidity(self):
-        """
-        This function gets the parameter 'r': Relative humidity (%).
-        It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary with the array containing parameter 'r'.
-        :rtype: dict
-        """
-        return self.getParameters(["r"], self.levels)
-
-    def getOmega(self):
-        """
-        This function gets the parameter 'w': Vertical velocity (Pa/s).
-        It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary with the array containing parameter 'w'.
-        :rtype: dict
-        """
-        return self.getParameters(["w"], self.levels)
-
-    # parameters needed in wind_uncertainty
-    # =====================================
-    def getUs(self):
-        """
-        This function gets the parameter 'u': U component of wind (m/s).
-        It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary with the array containing parameter 'u'.
-        :rtype: dict
-        """
-        return self.getParameters(["u"], self.levels)
-
-    def getVs(self):
-        """
-        This function gets the parameter 'v': V component of wind (m/s).
-        It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary with the array containing parameter 'v'.
-        :rtype: dict
-        """
-        return self.getParameters(["v"], self.levels)
-
-    # Generic function to collect parameter values
-    # ============================================
-    def getParameter(self, parameter, level=None):
-        gribs = self.gribs
-        merged_matrix_dict = {parameter.upper(): {}}
-        merged_matrix_dict[parameter.upper()]["values"] = []
-        merged_matrix_dict[parameter.upper()]["longs"] = []
-        merged_matrix_dict[parameter.upper()]["lats"] = []
-        merged_matrix_dict[parameter.upper()]["times"] = []
-
-        if level is None:
-            coordinates = [
-                ("t", self.selected_forecast_dates),
-                ("pl", [-9999]),
-                ("ens_n", self.members),
-                ("lat", self.latitudes),
-                ("lon", self.longitudes),
-            ]
-            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
-            nan_array = np.empty(axis_sizes)
-            nan_array.fill(np.NaN)
-            merged_matrix_dict[parameter.upper()]["values"] = nan_array
-            gribs.rewind()
-            for grib in gribs:
-                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
-                if (grib.shortName == parameter) and (
-                    ts in self.selected_forecast_dates
-                ):
-                    index_time = self.selected_forecast_dates.index(ts)
-                    index_level = 0
-                    index_members = self.members.index(grib.perturbationNumber - 1)
-                    merged_matrix_dict[parameter.upper()]["values"][
-                        index_time, index_level, index_members, :, :
-                    ] = np.array(grib.values)
-        else:
-            coordinates = [
-                ("t", self.selected_forecast_dates),
-                ("pl", self.selected_levels),
-                ("ens_n", self.members),
-                ("lat", self.latitudes),
-                ("lon", self.longitudes),
-            ]
-            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
-            nan_array = np.empty(axis_sizes)
-            nan_array.fill(np.NaN)
-            merged_matrix_dict[parameter.upper()]["values"] = nan_array
-            gribs.rewind()
-            for grib in gribs:
-                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
-                if (
-                    (grib.shortName == parameter)
-                    and (ts in self.selected_forecast_dates)
-                    and (grib.level in self.selected_levels)
-                ):
-                    index_time = self.selected_forecast_dates.index(ts)
-                    index_level = self.selected_levels.index(grib.level)
-                    index_members = self.members.index(grib.perturbationNumber - 1)
-                    merged_matrix_dict[parameter.upper()]["values"][
-                        index_time, index_level, index_members, :, :
-                    ] = np.array(grib.values)
-        merged_matrix_dict[parameter.upper()]["times"] = np.array(
-            self.selected_forecast_dates
-        )
-        merged_matrix_dict[parameter.upper()]["levels"] = np.array(self.selected_levels)
-        merged_matrix_dict[parameter.upper()]["longs"] = np.array(self.longitudes)
-        merged_matrix_dict[parameter.upper()]["lats"] = np.array(self.latitudes)
-
-        return merged_matrix_dict
-
-    def getParameters(self, parameters, level=None):
-        """
-        This method returns a dictionary in which each key corresponds to a different parameter from *parameters*. The
-        associated value is another dictionary with keys: 'values' (array with the parameter values), 'longs'
-        (array of longitudes), 'lats' (array of latitudes), 'levels' (array with the pressure levels) and 'times'
-        (array of times).
-
-        :param parameters: Parameters to get from the grib file.
-        :type parameters: list
-        :param level: List of pressure levels.
-        :type level: list
-        :return: Dictionary with arrays corresponding to the values of the different parameters.
-        :rtype: dict
-        """
-        gribs = self.gribs
-        for var in parameters:
-            merged_matrix_dict = {var.upper(): {}}
-            merged_matrix_dict[var.upper()]["values"] = []
-            merged_matrix_dict[var.upper()]["longs"] = []
-            merged_matrix_dict[var.upper()]["lats"] = []
-            merged_matrix_dict[var.upper()]["times"] = []
-
-        if level is None:
-            coordinates = [
-                ("t", self.selected_forecast_dates),
-                ("pl", [-9999]),
-                ("ens_n", self.members),
-                ("lat", self.latitudes),
-                ("lon", self.longitudes),
-            ]
-            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
-            nan_array = np.empty(axis_sizes)
-            nan_array.fill(np.NaN)
-            for var in parameters:
-                merged_matrix_dict[var.upper()]["values"] = nan_array
-            gribs.rewind()
-            for grib in gribs:
-                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
-                if (grib.shortName in parameters) and (
-                    ts in self.selected_forecast_dates
-                ):
-                    index_time = self.selected_forecast_dates.index(ts)
-                    index_level = 0
-                    index_members = self.members.index(grib.perturbationNumber - 1)
-                    merged_matrix_dict[grib.shortName.upper()]["values"][
-                        index_time, index_level, index_members, :, :
-                    ] = np.array(grib.values)
-        else:
-            coordinates = [
-                ("t", self.selected_timestamps),
-                ("pl", self.selected_levels),
-                ("ens_n", self.members),
-                ("lat", self.latitudes),
-                ("lon", self.longitudes),
-            ]
-            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
-            nan_array = np.empty(axis_sizes)
-            nan_array.fill(np.NaN)
-            for var in parameters:
-                merged_matrix_dict[var.upper()]["values"] = nan_array
-            gribs.rewind()
-            for grib in gribs:
-                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
-                if (
-                    (grib.shortName in parameters)
-                    and (ts in self.selected_forecast_dates)
-                    and (grib.level in self.selected_levels)
-                ):
-                    index_time = self.selected_forecast_dates.index(ts)
-                    index_level = self.selected_levels.index(grib.level)
-                    index_members = self.members.index(grib.perturbationNumber - 1)
-                    merged_matrix_dict[grib.shortName.upper()]["values"][
-                        index_time, index_level, index_members, :, :
-                    ] = np.array(grib.values)
-
-        for var in parameters:
-            merged_matrix_dict[var.upper()]["times"] = np.array(
-                self.selected_forecast_dates
-            )
-            merged_matrix_dict[var.upper()]["levels"] = np.array(self.levels)
-            merged_matrix_dict[var.upper()]["longs"] = np.array(self.longitudes)
-            merged_matrix_dict[var.upper()]["lats"] = np.array(self.latitudes)
-
-        return merged_matrix_dict
-
-    def get_grib_cat_xarray(self):
-        """
-        This method gets the parameters used in CAT calculations: 'u' (U component of wind), 'v' (V component of wind)
-        and 'z' (Geopotential). It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of parameters 'u', 'v' and 'z'.
-        :rtype: dict
-        """
-        parameters = ["u", "v", "z"]
-        levels = self.levels
-        return self.getParameters(parameters, levels)
-
-    def get_grib_convection_xarray(self):
-        """
-        This method gets the parameters used in Convection calculations: 'totalx' (Total totals index), 'cp'
-        (convective precipitation). It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of parameters 'totalx' and 'cp'.
-        :rtype: dict
-        """
-        parameters = ["totalx", "cp"]
-        return self.getParameters(parameters)
-
-    def get_grib_icing_xarray(self):
-        """
-        This method gets the parameters used in Icing calculations: 't' (Temperature), 'r' (Relative humidity)
-        and 'w' (Vertical velocity). It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of parameters 't', 'r' and 'w'.
-        :rtype: dict
-        """
-        parameters = ["t", "r", "w"]
-        levels = self.levels
-        return self.getParameters(parameters, levels)
-
-    def get_grib_wind_uncertainty_xarray(self):
-        """
-        This method gets the parameters used in Wind Uncertainty calculations: 'u' (U component of wind), 'v' (
-        V component of wind) and 't' (Temperature). It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of parameters 'u', 'v' and 't'.
-        :rtype: dict
-        """
-        parameters = ["u", "v", "t"]
-        levels = self.levels
-        return self.getParameters(parameters, levels)
-
-    def get_grib_windshear_xarray(self):
-        """
-        This method gets the parameters used in Windshear calculations: 'u' (U component of wind), 'v' (V component of wind)
-        and 'z' (Geopotential). It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of parameters 'u', 'v' and 'z'.
-        :rtype: dict
-        """
-        parameters = ["u", "v", "z"]
-        levels = self.levels
-        return self.getParameters(parameters, levels)
-
-    def get_grib_all_parameters_pl(self):
-        """
-        This method gets all the parameters used in PL calculations. It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of all the parameters.
-        :rtype: dict
-        """
-        parameters = self.parameters_short_names
-        levels = self.levels
-        return self.getParameters(parameters, levels)
-
-    def get_grib_all_parameters_sfc(self):
-        """
-        This method gets all the parameters used in SFC calculations. It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of all the parameters.
-        :rtype: dict
-        """
-        parameters = self.parameters_short_names
-        return self.getParameters(parameters)
-
-    def get_grib_all_parameters_donuts_pl(self):
-        """
-        This method gets the parameters used in DONUT'S PL calculations : 'u' (U component of wind), 'v'
-        (V component of wind), 'z' (Geopotential), 't' (Temperature), 'r' (Relative humidity)
-        and 'w' (Vertical velocity) . It makes use of the method :func:`getParameters`.
-
-        :return: Dictionary containing values of parameters 'u', 'v', 'z', 't', 'r' and 'w'.
-        :rtype: dict
-        """
-        parameters = ["u", "v", "z", "t", "r", "w"]
-        levels = self.levels
-        return self.getParameters(parameters, levels)
-
-    def get_grib_all_parameters_donuts_sfc(self):
-        """
-        This method gets the parameters used in DONUT'S SFC calculations : 'totalx' (totals total index) and 'cp'
-        (convective precipitation). It makes use of the method :func:`getParameters`.
-
-        :return:  Dictionary containing values of parameters 'totalx' and 'cp'.
-        :rtype: dict
-        """
-        parameters = ["totalx", "cp"]
-        return self.getParameters(parameters)
+import datetime
+import os
+import sys
+
+import numpy as np
+import pygrib
+import pytz
+
+
+def computeTimeStamps(dates, times, steps):
+    """
+    This method computes the time stamp from dates, times and step from forecast.
+
+    :param dates: List of dates with the following format YYYYMMDD.
+    :type dates: list
+    :param times: List of forecast time provided as integers.
+    :type times: list
+    :param steps: List of forecast steps provided as integers.
+    :type steps: list
+    :return: List of timestamps as datetimes.
+    :rtype: list
+    """
+    timestamps = set()
+    for date in dates:
+        date_string = "{0:-08d}".format(date)
+        for time in times:
+            hour = int(time / 100)
+            date_object = datetime.datetime(
+                year=int(date_string[0:4]),
+                month=int(date_string[4:6]),
+                day=int(date_string[6:8]),
+                hour=hour,
+                minute=0,
+                second=0,
+                tzinfo=pytz.utc,
+            )
+            for step in steps:
+                forecast_datetime = date_object + datetime.timedelta(hours=int(step))
+                # forecast_datetime = forecast_datetime.replace(tzinfo=pytz.utc)
+                # forecast_datetime.timestamp()
+                timestamps.add(forecast_datetime.timestamp())
+    return list(timestamps)
+
+
+def computeTimeStamp(date, time, step):
+    """
+    This method computes a single time stamp value from a forecast date, time and step.
+
+    :param date: date with the following format YYYYMMDD.
+    :type date: int
+    :param time: forecast time value.
+    :type time: int
+    :param step: forecast step value.
+    :type step: int
+    :return: timestamp
+    :rtype: datetime.datetime
+    """
+    date_string = "{0:-08d}".format(date)
+    hour = int(time / 100)
+    date_object = datetime.datetime(
+        year=int(date_string[0:4]),
+        month=int(date_string[4:6]),
+        day=int(date_string[6:8]),
+        hour=hour,
+        minute=0,
+        second=0,
+        tzinfo=pytz.utc,
+    )
+    forecast_datetime = date_object + datetime.timedelta(hours=int(step))
+    # forecast_datetime.replace(tzinfo=pytz.utc)
+    return datetime.datetime.timestamp(forecast_datetime)
+
+
+def flip_matrix(matrix):
+    """
+    Method to flip reverse the order of the elements in the latitude axis of an array.
+
+    :param matrix: Dictionary with the matrix to perform the flip.
+    :type matrix: dict
+    :return: Dictionary with the flipped matrix.
+    :rtype: dict
+    """
+    for var in matrix:
+        if matrix[var]["lats"][-1] < matrix[var]["lats"][0]:
+            matrix[var]["lats"] = matrix[var]["lats"][::-1]
+            matrix[var]["values"] = np.flip(
+                matrix[var]["values"], matrix[var]["values"].ndim - 2
+            )
+
+
+class GribPygribUniqueForecast(object):
+    """
+    This class transforms a grib file into a dictionary containing the values of desired parameters. It allows the
+    extraction of just one variable or set of variables corresponding to: CAT, Windshear, Icing, Wind uncertainty and
+    convection. It is based on Pygrib library.
+
+    """
+
+    def __init__(
+        self, grib_path, grib_name, selected_forecast_dates=None, selected_levels=None
+    ):
+        """
+        Initialization.
+
+        :param grib_path: Grib file path.
+        :type grib_path: str
+        :param grib_name: Grib file name.
+        :type grib_name: str
+        :param selected_forecast_dates: List of selected forecast dates.
+        :type selected_forecast_dates: list
+        :param selected_levels: List of selected levels.
+        :type selected_levels: list
+        """
+
+        # open grib file with pygrib
+        gribs = pygrib.open(os.path.join(grib_path, grib_name))
+        self.gribs = gribs
+
+        # save latitudes and longitudes
+        latlons = gribs[1].latlons()
+        latitudes = latlons[0][:, 0]
+        longitudes = latlons[1][0, :]
+        self.latitudes = latitudes
+        self.longitudes = longitudes
+
+        # save dates times steps and levels
+        dates = set()
+        times = set()
+        steps = set()
+        levels = set()
+        members = set()
+        parameters_full_names = set()
+        parameters_short_names = set()
+        forecast_dates = set()
+        for grib in gribs:
+            # filter levels that are not isobaricInhPa
+            if not (grib.typeOfLevel == "isobaricInhPa"):
+                continue
+
+            dates.add(grib.date)
+            times.add(grib.dataTime)
+            date = grib.validDate.replace(tzinfo=pytz.utc)
+            forecast_dates.add(date.timestamp())
+
+            try:
+                int(grib.stepRange)
+                steps.add(grib.stepRange)
+            except:
+                # do nothgin
+                continue
+            levels.add(grib.level)
+
+            # members.add(grib.perturbationNumber - 1)
+            parameters_full_names.add(grib.parameterName)
+            parameters_short_names.add(grib.shortName)
+        self.dates = list(dates)
+        self.times = list(times)
+        self.steps = list(steps)
+        # check if grib has the content supported by GribPygrib object.
+        if len(self.dates) > 1 or len(self.times) > 1:
+            sys.exit(
+                "Not supported by GribPygrib dates or times len is greater than 1. dates{0} times:{1}".format(
+                    self.dates, self.times
+                )
+            )
+        self.forecast_dates = sorted(list(forecast_dates))
+        self.levels = sorted(list(levels))
+        self.members = sorted(list(members))
+        self.parameters_full_names = list(parameters_full_names)
+        self.parameters_short_names = list(parameters_short_names)
+        self.num_forecast = len(dates) * len(times) * len(steps)
+        self.timestamps = sorted(computeTimeStamps(dates, times, steps))
+
+        # evaluate selected variables to be able to specify pl and/or forecast dates
+        if selected_forecast_dates is None:
+            self.selected_forecast_dates = self.timestamps
+        else:
+            self.selected_forecast_dates = selected_forecast_dates
+
+        if selected_levels is None:
+            self.selected_levels = self.levels
+        else:
+            self.selected_levels = selected_levels
+
+        # create list to later use index property
+        self.selected_forecast_dates = list(self.selected_forecast_dates)
+        self.selected_levels = list(self.selected_levels)
+
+    def isParameterInGrib(self, parameter):
+        """
+        Method to check if a parameter is in the grib file.
+
+        :param parameter: Parameter that needs to be checked.
+        :type parameter: str
+        :return: True if is in grib, False otherwise.
+        :rtype: bool
+        """
+        result = False
+        if parameter in self.parameters_short_names:
+            result = True
+        return result
+
+    # Generic function to collect parameter values
+    # ============================================
+    def getParameterUniqueForecast(self, parameter, levels=None):
+        gribs = self.gribs
+        merged_matrix_dict = {parameter.upper(): {}}
+        merged_matrix_dict[parameter.upper()]["values"] = []
+        merged_matrix_dict[parameter.upper()]["longs"] = []
+        merged_matrix_dict[parameter.upper()]["lats"] = []
+        merged_matrix_dict[parameter.upper()]["times"] = []
+        if levels is None:
+            levels = self.selected_levels
+        coordinates = [
+            ("t", self.selected_forecast_dates),
+            ("pl", levels),
+            ("lat", self.latitudes),
+            ("lon", self.longitudes),
+        ]
+        axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
+        nan_array = np.empty(axis_sizes)
+        nan_array.fill(np.NaN)
+        merged_matrix_dict[parameter.upper()]["values"] = nan_array
+        gribs.rewind()
+        for grib in gribs:
+            ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
+            if (
+                (grib.shortName == parameter)
+                and (ts in self.selected_forecast_dates)
+                and (grib.level in levels)
+            ):
+                index_time = self.selected_forecast_dates.index(ts)
+                if levels is None:
+                    index_level = 0
+                else:
+                    index_level = levels.index(grib.level)
+                merged_matrix_dict[parameter.upper()]["values"][
+                    index_time, index_level, :, :
+                ] = np.array(grib.values)
+        merged_matrix_dict[parameter.upper()]["times"] = np.array(
+            self.selected_forecast_dates
+        )
+        merged_matrix_dict[parameter.upper()]["levels"] = np.array(levels)
+        merged_matrix_dict[parameter.upper()]["longs"] = np.array(self.longitudes)
+        merged_matrix_dict[parameter.upper()]["lats"] = np.array(self.latitudes)
+        return merged_matrix_dict
+
+    # parameters needed in convection
+    # ===============================
+    def getTTs(self):
+        """
+        This function gets the parameter 'totalx': Total totals index (K).
+        It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary with the array containing parameter 'totalx'.
+        :rtype: dict
+        """
+        return self.getParameters(["totalx"])
+
+    def getCPs(self):
+        """
+        This function gets the parameter 'cp': Convective precipitation.
+        It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary with the array containing parameter 'cp'.
+        :rtype: dict
+        """
+        return self.getParameters(["cp"])
+
+    # parameters needed in icing
+    # ==========================
+    def getTemps(self):
+        """
+        This function gets the parameter 't': Temperature (K).
+        It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary with the array containing parameter 't'.
+        :rtype: dict
+        """
+        return self.getParameters(["t"], self.levels)
+
+    def getRelativeHumidity(self):
+        """
+        This function gets the parameter 'r': Relative humidity (%).
+        It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary with the array containing parameter 'r'.
+        :rtype: dict
+        """
+        return self.getParameters(["r"], self.levels)
+
+    def getOmega(self):
+        """
+        This function gets the parameter 'w': Vertical velocity (Pa/s).
+        It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary with the array containing parameter 'w'.
+        :rtype: dict
+        """
+        return self.getParameters(["w"], self.levels)
+
+    # parameters needed in wind_uncertainty
+    # =====================================
+    def getUs(self):
+        """
+        This function gets the parameter 'u': U component of wind (m/s).
+        It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary with the array containing parameter 'u'.
+        :rtype: dict
+        """
+        return self.getParameters(["u"], self.levels)
+
+    def getVs(self):
+        """
+        This function gets the parameter 'v': V component of wind (m/s).
+        It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary with the array containing parameter 'v'.
+        :rtype: dict
+        """
+        return self.getParameters(["v"], self.levels)
+
+    # Generic function to collect parameter values
+    # ============================================
+    def getParameter(self, parameter, level=None):
+        gribs = self.gribs
+        merged_matrix_dict = {parameter.upper(): {}}
+        merged_matrix_dict[parameter.upper()]["values"] = []
+        merged_matrix_dict[parameter.upper()]["longs"] = []
+        merged_matrix_dict[parameter.upper()]["lats"] = []
+        merged_matrix_dict[parameter.upper()]["times"] = []
+
+        if level is None:
+            coordinates = [
+                ("t", self.selected_forecast_dates),
+                ("pl", [-9999]),
+                ("ens_n", self.members),
+                ("lat", self.latitudes),
+                ("lon", self.longitudes),
+            ]
+            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
+            nan_array = np.empty(axis_sizes)
+            nan_array.fill(np.NaN)
+            merged_matrix_dict[parameter.upper()]["values"] = nan_array
+            gribs.rewind()
+            for grib in gribs:
+                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
+                if (grib.shortName == parameter) and (
+                    ts in self.selected_forecast_dates
+                ):
+                    index_time = self.selected_forecast_dates.index(ts)
+                    index_level = 0
+                    index_members = self.members.index(grib.perturbationNumber - 1)
+                    merged_matrix_dict[parameter.upper()]["values"][
+                        index_time, index_level, index_members, :, :
+                    ] = np.array(grib.values)
+        else:
+            coordinates = [
+                ("t", self.selected_forecast_dates),
+                ("pl", self.selected_levels),
+                ("ens_n", self.members),
+                ("lat", self.latitudes),
+                ("lon", self.longitudes),
+            ]
+            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
+            nan_array = np.empty(axis_sizes)
+            nan_array.fill(np.NaN)
+            merged_matrix_dict[parameter.upper()]["values"] = nan_array
+            gribs.rewind()
+            for grib in gribs:
+                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
+                if (
+                    (grib.shortName == parameter)
+                    and (ts in self.selected_forecast_dates)
+                    and (grib.level in self.selected_levels)
+                ):
+                    index_time = self.selected_forecast_dates.index(ts)
+                    index_level = self.selected_levels.index(grib.level)
+                    index_members = self.members.index(grib.perturbationNumber - 1)
+                    merged_matrix_dict[parameter.upper()]["values"][
+                        index_time, index_level, index_members, :, :
+                    ] = np.array(grib.values)
+        merged_matrix_dict[parameter.upper()]["times"] = np.array(
+            self.selected_forecast_dates
+        )
+        merged_matrix_dict[parameter.upper()]["levels"] = np.array(self.selected_levels)
+        merged_matrix_dict[parameter.upper()]["longs"] = np.array(self.longitudes)
+        merged_matrix_dict[parameter.upper()]["lats"] = np.array(self.latitudes)
+
+        return merged_matrix_dict
+
+    def getParameters(self, parameters, level=None):
+        """
+        This method returns a dictionary in which each key corresponds to a different parameter from *parameters*. The
+        associated value is another dictionary with keys: 'values' (array with the parameter values), 'longs'
+        (array of longitudes), 'lats' (array of latitudes), 'levels' (array with the pressure levels) and 'times'
+        (array of times).
+
+        :param parameters: Parameters to get from the grib file.
+        :type parameters: list
+        :param level: List of pressure levels.
+        :type level: list
+        :return: Dictionary with arrays corresponding to the values of the different parameters.
+        :rtype: dict
+        """
+        gribs = self.gribs
+        for var in parameters:
+            merged_matrix_dict = {var.upper(): {}}
+            merged_matrix_dict[var.upper()]["values"] = []
+            merged_matrix_dict[var.upper()]["longs"] = []
+            merged_matrix_dict[var.upper()]["lats"] = []
+            merged_matrix_dict[var.upper()]["times"] = []
+
+        if level is None:
+            coordinates = [
+                ("t", self.selected_forecast_dates),
+                ("pl", [-9999]),
+                ("ens_n", self.members),
+                ("lat", self.latitudes),
+                ("lon", self.longitudes),
+            ]
+            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
+            nan_array = np.empty(axis_sizes)
+            nan_array.fill(np.NaN)
+            for var in parameters:
+                merged_matrix_dict[var.upper()]["values"] = nan_array
+            gribs.rewind()
+            for grib in gribs:
+                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
+                if (grib.shortName in parameters) and (
+                    ts in self.selected_forecast_dates
+                ):
+                    index_time = self.selected_forecast_dates.index(ts)
+                    index_level = 0
+                    index_members = self.members.index(grib.perturbationNumber - 1)
+                    merged_matrix_dict[grib.shortName.upper()]["values"][
+                        index_time, index_level, index_members, :, :
+                    ] = np.array(grib.values)
+        else:
+            coordinates = [
+                ("t", self.selected_timestamps),
+                ("pl", self.selected_levels),
+                ("ens_n", self.members),
+                ("lat", self.latitudes),
+                ("lon", self.longitudes),
+            ]
+            axis_sizes = [len(c_values) for (c_name, c_values) in coordinates]
+            nan_array = np.empty(axis_sizes)
+            nan_array.fill(np.NaN)
+            for var in parameters:
+                merged_matrix_dict[var.upper()]["values"] = nan_array
+            gribs.rewind()
+            for grib in gribs:
+                ts = computeTimeStamp(grib.date, grib.dataTime, grib.stepRange)
+                if (
+                    (grib.shortName in parameters)
+                    and (ts in self.selected_forecast_dates)
+                    and (grib.level in self.selected_levels)
+                ):
+                    index_time = self.selected_forecast_dates.index(ts)
+                    index_level = self.selected_levels.index(grib.level)
+                    index_members = self.members.index(grib.perturbationNumber - 1)
+                    merged_matrix_dict[grib.shortName.upper()]["values"][
+                        index_time, index_level, index_members, :, :
+                    ] = np.array(grib.values)
+
+        for var in parameters:
+            merged_matrix_dict[var.upper()]["times"] = np.array(
+                self.selected_forecast_dates
+            )
+            merged_matrix_dict[var.upper()]["levels"] = np.array(self.levels)
+            merged_matrix_dict[var.upper()]["longs"] = np.array(self.longitudes)
+            merged_matrix_dict[var.upper()]["lats"] = np.array(self.latitudes)
+
+        return merged_matrix_dict
+
+    def get_grib_cat_xarray(self):
+        """
+        This method gets the parameters used in CAT calculations: 'u' (U component of wind), 'v' (V component of wind)
+        and 'z' (Geopotential). It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of parameters 'u', 'v' and 'z'.
+        :rtype: dict
+        """
+        parameters = ["u", "v", "z"]
+        levels = self.levels
+        return self.getParameters(parameters, levels)
+
+    def get_grib_convection_xarray(self):
+        """
+        This method gets the parameters used in Convection calculations: 'totalx' (Total totals index), 'cp'
+        (convective precipitation). It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of parameters 'totalx' and 'cp'.
+        :rtype: dict
+        """
+        parameters = ["totalx", "cp"]
+        return self.getParameters(parameters)
+
+    def get_grib_icing_xarray(self):
+        """
+        This method gets the parameters used in Icing calculations: 't' (Temperature), 'r' (Relative humidity)
+        and 'w' (Vertical velocity). It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of parameters 't', 'r' and 'w'.
+        :rtype: dict
+        """
+        parameters = ["t", "r", "w"]
+        levels = self.levels
+        return self.getParameters(parameters, levels)
+
+    def get_grib_wind_uncertainty_xarray(self):
+        """
+        This method gets the parameters used in Wind Uncertainty calculations: 'u' (U component of wind), 'v' (
+        V component of wind) and 't' (Temperature). It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of parameters 'u', 'v' and 't'.
+        :rtype: dict
+        """
+        parameters = ["u", "v", "t"]
+        levels = self.levels
+        return self.getParameters(parameters, levels)
+
+    def get_grib_windshear_xarray(self):
+        """
+        This method gets the parameters used in Windshear calculations: 'u' (U component of wind), 'v' (V component of wind)
+        and 'z' (Geopotential). It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of parameters 'u', 'v' and 'z'.
+        :rtype: dict
+        """
+        parameters = ["u", "v", "z"]
+        levels = self.levels
+        return self.getParameters(parameters, levels)
+
+    def get_grib_all_parameters_pl(self):
+        """
+        This method gets all the parameters used in PL calculations. It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of all the parameters.
+        :rtype: dict
+        """
+        parameters = self.parameters_short_names
+        levels = self.levels
+        return self.getParameters(parameters, levels)
+
+    def get_grib_all_parameters_sfc(self):
+        """
+        This method gets all the parameters used in SFC calculations. It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of all the parameters.
+        :rtype: dict
+        """
+        parameters = self.parameters_short_names
+        return self.getParameters(parameters)
+
+    def get_grib_all_parameters_donuts_pl(self):
+        """
+        This method gets the parameters used in DONUT'S PL calculations : 'u' (U component of wind), 'v'
+        (V component of wind), 'z' (Geopotential), 't' (Temperature), 'r' (Relative humidity)
+        and 'w' (Vertical velocity) . It makes use of the method :func:`getParameters`.
+
+        :return: Dictionary containing values of parameters 'u', 'v', 'z', 't', 'r' and 'w'.
+        :rtype: dict
+        """
+        parameters = ["u", "v", "z", "t", "r", "w"]
+        levels = self.levels
+        return self.getParameters(parameters, levels)
+
+    def get_grib_all_parameters_donuts_sfc(self):
+        """
+        This method gets the parameters used in DONUT'S SFC calculations : 'totalx' (totals total index) and 'cp'
+        (convective precipitation). It makes use of the method :func:`getParameters`.
+
+        :return:  Dictionary containing values of parameters 'totalx' and 'cp'.
+        :rtype: dict
+        """
+        parameters = ["totalx", "cp"]
+        return self.getParameters(parameters)
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/std_atm.py

 * *Ordering differences only*

```diff
@@ -1,1272 +1,1272 @@
-#!/usr/bin/python
-# -*- coding: utf-8 -*-
-
-# #############################################################################
-# Copyright (c) 2008, Kevin Horton
-# All rights reserved.
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-# *
-#     * Redistributions of source code must retain the above copyright
-#       notice, this list of conditions and the following disclaimer.
-#     * Redistributions in binary form must reproduce the above copyright
-#       notice, this list of conditions and the following disclaimer in the
-#       documentation and/or other materials provided with the distribution.
-#     * The name of Kevin Horton may not be used to endorse or promote products
-#       derived from this software without specific prior written permission.
-# *
-# THIS SOFTWARE IS PROVIDED BY KEVIN HORTON ``AS IS'' AND ANY EXPRESS OR
-# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
-# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
-# EVENT SHALL KEVIN HORTON BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
-# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
-# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
-# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
-# OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
-# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-# #############################################################################
-#
-# version 0.16, 06 May 2007
-#
-# Version History:
-# vers     date     Notes
-#  0.1   14 May 06  First release.
-#
-# 0.11   17 May 06  Cleaned up documentation.
-#
-# 0.12   24 May 06  Added temp2speed_of_sound function.
-#
-# 0.13   02 Jun 06  Added temp2isa and isa2temp functions.
-#
-# 0.14   22 Apr 07  Added density altitude vs temperature functions
-#
-# 0.15   29 Apr 07  Broke out sat_press and dry_press as public functions.
-#
-# 0.16   05 May 07  Reworked to use default units from default_units module.
-# #############################################################################
-#
-# To Do: 1. Done.
-#
-#        2. Done.
-#
-#        3. Done.
-#
-#        4. Won't do.
-#
-#        5. Add temp2temp_ratio, press2press_ratio and density2density_ratio.
-#
-#        6. Done.
-#
-#        7. Add tests for all functions to test/test_std_atm.py
-#           Tests to add:
-#           dry_press
-#           density_alt_table ? (probably won't make a test for this)
-#
-#        8. Review code to catch duplicated code blocks in different functions.
-#           Move these blocks to internal functions.
-#
-#        9. Review API for all public functions for consistency of units, etc.
-#
-# Done:  1. consider replacing calculations by constants where possible.  See
-#           http://jcoppens.com/globo/teoria/atm_est.en.php
-#
-#           Tested replacing calculations by constants in press2alt.  The
-#           perf improvement was only about 15%.  Probably not worth the trouble.
-#           Better to keep the pedigree of the equations visible.
-#
-#        2. Validate against published data.  Created unittests using data:
-#           http://www.sworld.com.au/steven/space/atmosphere/
-#
-#        3. Added relative humidity to density altitude calc.  See:
-#           http://wahiduddin.net/calc/density_altitude.htm
-#
-#        4. Change formulae to use pressure in pa, not in HG.  Won't do.
-#           Instead, changed to use default units specified in default_units.py
-#
-#        6. Added functions:
-#           isa2temp
-#           temp2isa
-#
-#        7. Added tests for functions:
-#           pressure_alt
-#           sat_press
-#           density_alt2temp
-# #############################################################################
-
-"""Calculate standard atmosphere parametres.
-
-Calculates standard atmosphere parametres, using the 1976 International
-Standard Atmosphere.  The default units for the input and output are defined
-in default_units.py
-
-All altitudes are geopotential altitudes (i.e. it is assumed that there is
-no variation with altitude of the acceleration due to gravity).
-
-Works up to 84.852 km (278,386 ft) altitude.
-
-"""
-
-import locale as L
-import math as M
-
-import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.unit_conversion as U
-
-try:
-    from default_units import *
-except ImportError:
-    default_area_units = "ft**2"
-    default_power_units = "hp"
-    default_speed_units = "kt"
-    default_temp_units = "C"
-    default_weight_units = "lb"
-    default_press_units = "in HG"
-    default_density_units = "lb/ft**3"
-    default_length_units = "ft"
-    default_alt_units = default_length_units
-    default_avgas_units = "lb"
-
-try:
-    L.setlocale(L.LC_ALL, "en_US")
-except:
-    pass
-
-g = 9.80665  # Acceleration of gravity at 45.542 deg latitude, m/s**s
-Rd = 287.05307  # Gas constant for dry air, J/kg K
-
-# conditions starting at sea level, in a region with temperature gradient
-
-T0 = 288.15  # Temperature at sea level, degrees K
-L0 = -6.5  # Temperature lapse rate, at sea level deg K/km
-P0 = 29.9213  # Pressure at sea level, in HG
-Rho0 = 1.2250  # Density at sea level, kg/m**3
-
-# conditions starting at 11 km, in an isothermal region
-
-T11 = T0 + 11 * L0  # Temperature at 11,000 m, degrees K
-PR11 = (T11 / T0) ** ((-1000 * g) / (Rd * L0))  # pressure ratio at 11,000 m
-P11 = PR11 * P0
-Rho11 = (Rho0 * PR11) * (T0 / T11)
-
-# conditions starting at 20 km, in a region with temperature gradient
-
-T20 = T11
-PR20 = PR11 * M.exp(((-1000 * g) * (20 - 11)) / (Rd * T11))
-L20 = 1  # temperature lapse rate, starting at 20,000 m, deg K/km
-P20 = PR20 * P0
-Rho20 = (Rho0 * PR20) * (T0 / T20)
-
-# conditions starting at 32 km, in a region with temperature gradient
-
-T32 = 228.65  # Temperature at 32 km, degrees K
-PR32 = PR20 * (T32 / T20) ** ((-1000 * g) / (Rd * L20))
-
-# PR32 = PR20 * M.exp((-1000 * g) * (32 - 20)/(R * T20))
-
-L32 = 2.8  # temperature lapse rate, starting at 32,000 m, deg K/km
-P32 = PR32 * P0
-Rho32 = (Rho0 * PR32) * (T0 / T32)
-
-# conditions starting at 47 km, in an isothermal region
-
-T47 = 270.65
-PR47 = PR32 * (T47 / T32) ** ((-1000 * g) / (Rd * L32))
-P47 = PR47 * P0
-Rho47 = (Rho0 * PR47) * (T0 / T47)
-
-# conditions starting at 51 km, in a region with temperature gradient
-
-T51 = 270.65  # Temperature at 51 km, degrees K
-PR51 = PR47 * M.exp(((-1000 * g) * (51 - 47)) / (Rd * T47))
-L51 = -2.8  # temperature lapse rate, starting at 51,000 m, deg K/km
-P51 = PR51 * P0
-Rho51 = (Rho0 * PR51) * (T0 / T51)
-
-# conditions starting at 71 km, in a region with temperature gradient
-
-T71 = 214.65  # Temperature at 71 km, degrees K
-PR71 = PR51 * (T71 / T51) ** ((-1000 * g) / (Rd * L51))
-L71 = -2.0  # temperature lapse rate, starting at 71,000 m, deg K/km
-P71 = PR71 * P0
-Rho71 = (Rho0 * PR71) * (T0 / T71)
-
-# temp_units_list = ['C', 'F', 'K', 'R']
-
-# #############################################################################
-#
-# Altitude to temperature
-#
-# #############################################################################
-
-
-def alt2temp(H, alt_units=default_alt_units, temp_units=default_temp_units):
-    """Return the standard temperature for the specified altitude.  Altitude
-    units may be feet ('ft'), metres ('m'), statute miles, ('sm') or
-    nautical miles ('nm').  Temperature units may be degrees C, F, K or R
-    ('C', 'F', 'K' or 'R')
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the standard temperature (in default temperature units) at
-    5,000 (default altitude units):
-    >>> alt2temp(5000)
-    5.0939999999999941
-
-    Calculate the standard temperature in deg F at sea level:
-    >>> alt2temp(0, temp_units = 'F')
-    59.0
-
-    Calculate the standard temperature in deg K at 11,000 m:
-    >>> alt2temp(11000, alt_units = 'm', temp_units = 'K')
-    216.64999999999998
-
-    Calculate the standard temperature at 11 statute miles in deg R:
-    >>> alt2temp(11, alt_units = 'sm', temp_units = 'R')
-    389.96999999999997
-
-    The input value may be an expression:
-    >>> alt2temp(11 * 5280, temp_units = 'R')
-    389.96999999999997
-
-    """
-
-    # Validated to 84000 m
-    # uses meters and degrees K for the internal calculations
-
-    # function tested in tests/test_std_atm.py
-
-    H = U.len_conv(H, from_units=alt_units, to_units="km")
-
-    if H <= 11:
-        temp = T0 + H * L0
-    elif H <= 20:
-        temp = T11
-    elif H <= 32:
-        temp = T20 + (H - 20) * L20
-    elif H <= 47:
-        temp = T32 + (H - 32) * L32
-    elif H <= 51:
-        temp = T47
-    elif H <= 71:
-        temp = T51 + (H - 51) * L51
-    elif H <= 84.852:
-        temp = T71 + (H - 71) * L71
-    else:
-        raise ValueError(
-            "This function is only implemented for altitudes of 84.852 km and below."
-        )
-
-    return U.temp_conv(temp, to_units=temp_units, from_units="K")
-
-
-def alt2temp_ratio(H, alt_units=default_alt_units):
-    """
-    Return the temperature ratio (temperature / standard temperature for
-    sea level).  The altitude is specified in feet ('ft'), metres ('m'),
-    statute miles, ('sm') or nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the temperature ratio at 8,000 (default altitude units)
-    >>> alt2temp_ratio(8000)
-    0.94499531494013533
-
-    Calculate the temperature ratio at 8,000 m.
-    >>> alt2temp_ratio(8000, alt_units = 'm')
-    0.81953843484296374
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    return alt2temp(H, alt_units, temp_units="K") / T0
-
-
-# #############################################################################
-#
-# ISA deviation to temperature
-#
-# #############################################################################
-
-
-def isa2temp(
-    ISA_dev,
-    altitude,
-    temp_units=default_temp_units,
-    alt_units=default_alt_units,
-):
-    """
-    Return the temperature that is a specified amount warmer or cooler
-    than the standard temperature for the altitude.
-
-    The temperature may be in deg C, F, K or R.
-
-    The altitude may be in feet ('ft'), metres ('m'), kilometres ('km'),
-    statute miles, ('sm') or nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Determine the temperature that is 10 deg (default temperature units) warmer
-    than the standard temperature at 8,000 (default altitude units):
-    >>> isa2temp(10, 8000)
-    9.1503999999999905
-
-    Determine the temperature that is 25 degrees K cooler than the standard
-    temperature at 2000 m.
-    >>> isa2temp(-25, 2000, temp_units = 'K', alt_units = 'm')
-    250.14999999999998
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    temp = ISA_dev + alt2temp(altitude, alt_units, temp_units)
-
-    return temp
-
-
-# #############################################################################
-#
-# temperature to ISA deviation
-#
-# #############################################################################
-
-
-def temp2isa(
-    temp,
-    altitude,
-    temp_units=default_temp_units,
-    alt_units=default_alt_units,
-):
-    """
-    Return the amount that the specified temperature is warmer or cooler
-    than the standard temperature for the altitude.
-
-    The temperature may be in deg C, F, K or R.
-
-    The altitude may be in feet ('ft'), metres ('m'), kilometres ('km'),
-    statute miles, ('sm') or nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Determine the ISA deviation for a temperature of 30 deg (default
-    temperature units) at an altitude of 2000 (default altitude units):
-    >>> temp2isa(30, 2000)
-    18.962400000000002
-
-    Determine the ISA deviation in degrees F for a temperature of 45 deg F
-    at an altitude of 1000 m:
-    >>> temp2isa(45, 1000, temp_units = 'F', alt_units = 'm')
-    -2.2999999999999972
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    std_temp = alt2temp(altitude, alt_units, temp_units)
-    ISA_dev = temp - std_temp
-
-    return ISA_dev
-
-
-# #############################################################################
-#
-# Altitude to pressure and pressure ratio
-#
-# #############################################################################
-
-
-def _alt2press_ratio_gradient(
-    H,
-    Hb,
-    Pb,
-    Tb,
-    L,
-):
-
-    # eqn from USAF TPS PEC binder, page PS1-31
-
-    return (Pb / P0) * (1 + (L / Tb) * (H - Hb)) ** ((-1000 * g) / (Rd * L))
-
-
-def _alt2press_ratio_isothermal(
-    H,
-    Hb,
-    Pb,
-    Tb,
-):
-
-    # eqn from USAF TPS PEC binder, page PS1-26
-
-    return (Pb / P0) * M.exp((-1 * (H - Hb)) * ((1000 * g) / (Rd * Tb)))
-
-
-def alt2press_ratio(H, alt_units=default_alt_units):
-    """
-    Return the pressure ratio (atmospheric pressure / standard pressure
-    for sea level).  The altitude is specified in feet ('ft'), metres ('m'),
-    statute miles, ('sm') or nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the pressure ratio at 5000 (default altitude units):
-    >>> alt2press_ratio(5000)
-    0.8320481158727735
-
-    Calculate the pressure ratio at 1000 m:
-    >>> alt2press_ratio(1000, alt_units = 'm')
-    0.88699304638887044
-
-    The functions are only implemented at altitudes of 84.852 km and lower.
-    >>> alt2press_ratio(90, alt_units = 'km')
-    Traceback (most recent call last):
-      File '<stdin>', line 1, in ?
-      File './std_atm.py', line 189, in alt2press_ratio
-    if H <= 20:
-    ValueError: This function is only implemented for altitudes of 84.852 km and below.
-    """
-
-    # uses meters and degrees K for the internal calculations
-
-    # function tested in tests/test_std_atm.py
-
-    H = U.len_conv(H, from_units=alt_units, to_units="km")
-
-    if H <= 11:
-        return _alt2press_ratio_gradient(H, 0, P0, T0, L0)
-    if H <= 20:
-        return _alt2press_ratio_isothermal(H, 11, P11, T11)
-    if H <= 32:
-        return _alt2press_ratio_gradient(H, 20, P20, T20, L20)
-    if H <= 47:
-        return _alt2press_ratio_gradient(H, 32, P32, T32, L32)
-    if H <= 51:
-        return _alt2press_ratio_isothermal(H, 47, P47, T47)
-    if H <= 71:
-        return _alt2press_ratio_gradient(H, 51, P51, T51, L51)
-    if H <= 84.852:
-        return _alt2press_ratio_gradient(H, 71, P71, T71, L71)
-    else:
-        raise ValueError(
-            "This function is only implemented for altitudes of 84.852 km and below."
-        )
-
-
-def alt2press(H, alt_units=default_alt_units, press_units=default_press_units):
-    """
-    Return the atmospheric pressure for a given altitude, with the
-    altitude in feet ('ft'), metres ('m'), statute miles, ('sm') or nautical
-    miles ('nm'), and the pressure in inches of HG ('in HG'), mm of HG
-    ('mm HG'), psi, lb per sq. ft ('psf'), pa, hpa or mb.
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the pressure in inches of mercury at 5,000 (default altitude
-    units):
-    >>> alt2press(5000)
-    24.895961289464015
-
-    Calculate the pressure in pounds per square foot at 10,000 (default
-    altitude units):
-    >>> alt2press(10000, press_units = 'psf')
-    1455.3301392981359
-
-    Calculate the pressure in pascal at 20 km:
-    >>> alt2press(20, press_units = 'pa', alt_units = 'km')
-    5474.8827144576408
-    """
-
-    # uses meters, inches of HG and degrees K for the internal calculations
-
-    # function tested in tests/test_std_atm.py
-
-    H = U.len_conv(H, from_units=alt_units, to_units="m")
-
-    press = P0 * alt2press_ratio(H, alt_units="m")
-    press = U.press_conv(press, from_units="in HG", to_units=press_units)
-
-    return press
-
-
-# #############################################################################
-#
-# Pressure altitude from barometric altitude and altimeter setting
-#
-# #############################################################################
-
-
-def pressure_alt(H, alt_setting, alt_units=default_alt_units):
-    """
-    Return the pressure altitude, given the barometric altitude and the
-    altimeter setting.
-
-    Altimeter setting may have units of inches of HG, or hpa or mb.  If the
-    altimeter setting value is less than 35, the units are assumed to be
-    in HG, otherwise they are assumed to be hpa.  The altimeter setting must
-    be in the range of 25 to 35 inches of mercury.
-
-    The altitude may have units of feet ('ft'), metres ('m'), statute miles,
-    ('sm') or nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the pressure altitude for 1,000 (default altitude units)
-    barometric altitude with altimeter setting of 30.92 in HG:
-    >>> pressure_alt(1000, 30.92)
-    88.612734282205338
-
-    Calculate the pressure altitude for 1,000 (default altitude units)
-    barometric altitude with altimeter setting of 1008 mb:
-    >>> pressure_alt(1000, 1008)
-    1143.6503495627171
-
-    Calculate the pressure altitude in metres for 304.8 m barometric
-    altitude with altimeter setting of 1008 mb:
-    >>> pressure_alt(304.8, 1008, alt_units = 'm')
-    348.58462654671621
-    """
-
-    H = U.len_conv(H, from_units=alt_units, to_units="ft")
-    if alt_setting > 35:
-        alt_setting = U.press_conv(alt_setting, from_units="hpa", to_units="in HG")
-    if alt_setting < 25 or alt_setting > 35:
-        raise ValueError("Altimeter setting out of range.")
-    HP = H + 145442.2 * (1 - (alt_setting / P0) ** 0.190261)
-    HP = U.len_conv(HP, from_units="ft", to_units=alt_units)
-    return HP
-
-
-def QNH(
-    HP,
-    H,
-    alt_units=default_alt_units,
-    alt_setting_units="in HG",
-):
-    """
-    Return the altimeter setting, given the pressure altitude (HP) and the
-    barometric altitude (H).
-    """
-
-    HP = U.len_conv(HP, from_units=alt_units, to_units="ft")
-    H = U.len_conv(H, from_units=alt_units, to_units="ft")
-    QNH = P0 * (1 - (HP - H) / 145442.2) ** 5.255594
-    QNH = U.press_conv(QNH, from_units="in HG", to_units=alt_setting_units)
-
-    return QNH
-
-
-# #############################################################################
-#
-# Altitude to density and density ratio
-#
-# #############################################################################
-
-
-def alt2density_ratio(H, alt_units=default_alt_units):
-    """
-    Return the density ratio (atmospheric density / standard density
-    for sea level).  The altitude is specified in feet ('ft'), metres ('m'),
-    statute miles, ('sm') or nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the density ratio at 7,500 (default altitude units):
-    >>> alt2density_ratio(7500)
-    0.79825819881753035
-
-    Calculate the density ratio at 2 km:
-    >>> alt2density_ratio(2, alt_units = 'km')
-    0.8216246960994622
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    return alt2press_ratio(H, alt_units) / alt2temp_ratio(H, alt_units)
-
-
-def alt2density(H, alt_units=default_alt_units, density_units=default_density_units):
-    """
-    Return the density given the pressure altitude.  The altitude is
-    specified in feet ('ft'), metres ('m'), statute miles, ('sm') or
-    nautical miles ('nm').
-
-    The desired density units are specified as 'lb/ft**3', 'slug/ft**3' or
-    'kg/m**3'.
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the density in lb / ft cubed at 7,500 (default altitude units):
-    >>> alt2density(7500)
-    0.061046199847730374
-
-    Calculate the density in slugs / ft cubed at 5,000 (default altitude units):
-    >>> alt2density(5000, density_units = 'slug/ft**3')
-    0.0020480982157718704
-
-    Calculate the density in kg / m cubed at 0 (default altitude units:
-    >>> alt2density(0, density_units = 'kg/m**3')
-    1.2250000000000001
-
-    Calculate the density in kg / m cubed at 81,000 m:
-    >>> alt2density(81000, density_units = 'kg/m**3', alt_units = 'm')
-    1.3320480184052337e-05
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    # get density in kg/m**3
-
-    density = Rho0 * alt2density_ratio(H, alt_units)
-    return U.density_conv(density, from_units="kg/m**3", to_units=density_units)
-
-
-# #############################################################################
-#
-# Density to altitude and density ratio to altitude
-#
-# #############################################################################
-
-
-def _density2alt_gradient(
-    Rho,
-    Rhob,
-    Hb,
-    Tb,
-    L,
-):
-
-    return Hb + (Tb / L) * ((Rho / Rhob) ** (-1 / ((1000 * g) / (Rd * L) + 1)) - 1)
-
-
-def _density2alt_isothermal(
-    Rho,
-    Rhob,
-    Hb,
-    Tb,
-):
-
-    return Hb - ((Rd * Tb) * M.log(Rho / Rhob)) / (1000 * g)
-
-
-def density2alt(Rho, density_units=default_density_units, alt_units=default_alt_units):
-    """
-    Return the altitude corresponding to the specified density, with
-    density in 'lb/ft**3', 'slug/ft**3' or 'kg/m**3'.
-
-    The altitude is specified in feet ('ft'), metres ('m'), statute miles,
-    ('sm') or nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the altitude in default altitude units where the density is
-    0.056475 in default density units:
-    >>> density2alt(.056475)
-    9999.8040934937271
-
-    Calculate the altitude in metres where the density is 0.018012 kg / m
-    cubed:
-    >>> density2alt(.018012, alt_units = 'm', density_units = 'kg/m**3')
-    29999.978688508152
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    Rho = U.density_conv(Rho, from_units=density_units, to_units="kg/m**3")
-
-    if Rho > Rho11:
-        H = _density2alt_gradient(Rho, Rho0, 0, T0, L0)
-    elif Rho > Rho20:
-        H = _density2alt_isothermal(Rho, Rho11, 11, T11)
-    elif Rho > Rho32:
-        H = _density2alt_gradient(Rho, Rho20, 20, T20, L20)
-    elif Rho > Rho47:
-        H = _density2alt_gradient(Rho, Rho32, 32, T32, L32)
-    elif Rho > Rho51:
-        H = _density2alt_isothermal(Rho, Rho47, 47, T47)
-    elif Rho > Rho71:
-        H = _density2alt_gradient(Rho, Rho51, 51, T51, L51)
-    else:
-        H = _density2alt_gradient(Rho, Rho71, 71, T71, L71)
-
-    if H > 84.852:
-        raise ValueError(
-            "This function is only implemented for altitudes of 84.852 km and below."
-        )
-
-    return U.len_conv(H, from_units="km", to_units=alt_units)
-
-
-def density_ratio2alt(DR, alt_units=default_alt_units):
-    """
-    Return the altitude for the specified density ratio. The altitude is in
-    feet ('ft'), metres ('m'), statute miles, ('sm') or nautical miles
-    ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the altitude in default altitude units where the density ratio is
-    1:
-    >>> density_ratio2alt(1)
-    0.0
-
-    Calculate the altitude in feet where the density ratio is 0.5:
-    >>> density_ratio2alt(.5)
-    21859.50324995652
-
-    Calculate the altitude in km where the density ratio is 0.1
-    >>> density_ratio2alt(.1, alt_units = 'km')
-    17.9048674520646
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    D = DR * Rho0
-    return density2alt(D, alt_units=alt_units, density_units="kg/m**3")
-
-
-# #############################################################################
-#
-# Density Altitude
-#
-# #############################################################################
-
-
-def density_alt(
-    H,
-    T,
-    alt_setting=P0,
-    DP="FALSE",
-    RH=0.0,
-    alt_units=default_alt_units,
-    temp_units=default_temp_units,
-):
-    """
-    Return density altitude, given the pressure altitude and the
-    temperature with altitudes in units of feet ('ft'), metres ('m'),
-    statute miles, ('sm') or nautical miles ('nm'), and temperature in units
-    of deg C, F, K or R ('C', 'F', 'K' or 'R').
-
-    Mandatory parametres:
-    H = altitude
-    T = temperature
-
-    Optional parametres:
-    alt_setting = altimeter setting (defaults to 29.9213 if not provided
-    DP = dew point
-    RH = relative humidity
-    alt_units = units for the altitude.  'ft', 'm', or 'km'.
-    temp_units = units for the temperature and dew point.  'C', 'F', 'K'
-                 or 'R'.
-
-    The altimeter setting units are assumed to be inches of HG, unless the
-    value is greater than 35.  In this case the units are assumed to be mb.
-
-    If the dew point or relative humidity are not specified, the air is
-    assumed to be completely dry.  If both the dew point and relative humidity
-    are specified, the relative humidity value is ignored.
-
-    If the units are not specified, the units in default_units.py are used.
-
-    The method is from: http://wahiduddin.net/calc/density_altitude.htm
-
-    Examples:
-
-    Calculate the density altitude in default altitude units for a pressure
-    altitude of 7000 default altitude units and a temperature of 15 deg
-    (default temperature units).  The altimeter setting is not specified, so it
-    defaults to standard pressure of 29.9213 in HG or 1013.25 mb:
-    >>> density_alt(7000, 15)
-    8595.3465863232504
-
-    Calculate the density altitude in default altitude units for a pressure
-    altitude of 7000 default altitude units and a temperature of 85 deg F.
-    The altimeter setting is not specified, so it defaults to standard pressure
-    of 29.9213 in HG or 1013.25 mb.  The dew point and relative humidity are
-    not specified, so the air is assumed to be dry:
-    >>> density_alt(7000, 85, temp_units = 'F')
-    10159.10696106757
-
-    Calculate the density altitude in default altitude units for a pressure
-    altitude of 7000 default altitude units, an altimeter setting of 29.80 and
-    a temperature of 85 deg F and a dew point of 55 deg F:
-    >>> density_alt(7000, 85, 29.80, 55, temp_units = 'F')
-    10522.776013011618
-
-    Calculate the density altitude in metres for a pressure altitude of
-    2000 m, an altimeter setting of 1010 mb,  a temperature of 15 deg (default
-    temperature units) and a relative humidity of 50%:
-    >>> density_alt(2000, 15, 1010, alt_units = 'm', RH = 0.5)
-    2529.8230634449737
-
-    The dew point may be specified in one of two ways: as the fourth
-    argument on the command line, or via the keyword argument DP.
-    >>> density_alt(2000, 15, 1010, alt_units = 'm', DP = 5)
-    2530.7528237990618
-
-    The relative humidity must be in the range of 0 to 1:
-    >>> density_alt(2000, 15, 1010, alt_units = 'm', RH = 1.1)
-    Traceback (most recent call last):
-      File '<stdin>', line 1, in ?
-      File 'std_atm.py', line 533, in density_alt
-    raise ValueError, 'The relative humidity must be in the range of 0 to 1.'
-    ValueError: The relative humidity must be in the range of 0 to 1.
-    """
-
-    Rv = 461.495  # gas constant for water vapour
-
-    # saturated vapour pressure
-
-    if DP == "FALSE" and RH == 0:
-        Pv = 0
-    else:
-        Pv = sat_press(T, DP, RH, temp_units, press_units="pa")
-
-    # dry air pressure
-
-    Pd = dry_press(
-        H, Pv, alt_setting=alt_setting, alt_units=alt_units, press_units="pa"
-    )
-
-    T = U.temp_conv(T, from_units=temp_units, to_units="K")
-    D = Pd / (Rd * T) + Pv / (Rv * T)
-
-    DR = D / Rho0
-
-    return density_ratio2alt(DR, alt_units)
-
-
-def _sat_press(T):
-    """
-    Return the saturation pressure in mb of the water vapour, given
-    temperature in deg C.  Equation from:
-    http://wahiduddin.net/calc/density_altitude.htm
-    """
-
-    eso = 6.1078
-    c0 = 0.99999683
-    c1 = -0.90826951e-2
-    c2 = 0.78736169e-4
-    c3 = -0.61117958e-6
-    c4 = 0.43884187e-8
-    c5 = -0.29883885e-10
-    c6 = 0.21874425e-12
-    c7 = -0.17892321e-14
-    c8 = 0.11112018e-16
-    c9 = -0.30994571e-19
-
-    p = c0 + T * (
-        c1
-        + T
-        * (
-            c2
-            + T * (c3 + T * (c4 + T * (c5 + T * (c6 + T * (c7 + T * (c8 + T * c9))))))
-        )
-    )
-    sat_press = eso / p**8
-    return sat_press
-
-
-def sat_press(
-    T="FALSE",
-    DP="FALSE",
-    RH=0.0,
-    temp_units=default_temp_units,
-    press_units=default_press_units,
-):
-    """
-    Return the saturated vapour pressure of water.  Either the dew point, or
-    the temperature and the relative humidity must be specified.  If both the
-    dew point and relative humidity are specified, the relative humidity value
-    is ignored.
-
-    If the temperature and dew point are both specified, the dew point cannot
-    be greater than the temperature:
-
-    If the units are not specified, the units in default_units.py are used.
-
-    >>> sat_press(T=10, DP=11)
-    Traceback (most recent call last):
-      File '<stdin>', line 1, in <module>
-      File 'std_atm.py', line 795, in sat_press
-        raise ValueError, 'The dew point cannot be greater than the temperature.'
-    ValueError: The dew point cannot be greater than the temperature.
-
-    Dew point is 11 deg (default temperature units).  Find the water vapour
-    pressure in default pressure units:
-    >>> sat_press(DP=11)
-    0.38741015927568667
-
-    Dew point is 65 deg F.  Find the water vapour pressure in default pressure units:
-    >>> sat_press(DP=65, temp_units = 'F')
-    0.62207710701956165
-
-    Dew point is 212 deg F (the boiling point of water at sea level).
-    Find the water vapour pressure in lb per sq. inch:
-    >>> sat_press(DP=212, temp_units = 'F', press_units = 'psi')
-    14.696764873564959
-
-    Temperature is 30 deg C.  Find the water vapour pressure in default pressure units:
-    for 50% relative humidity:
-    >>> sat_press(T=30, RH = 0.5)
-    0.62647666996057927
-    """
-
-    if DP != "FALSE":
-
-        # use dew point method
-
-        if T != "FALSE":
-            if DP > T:
-                raise ValueError(
-                    "The dew point cannot be greater than the temperature."
-                )
-
-        DP = U.temp_conv(DP, from_units=temp_units, to_units="C")
-
-        # calculate vapour pressure
-
-        Pv = _sat_press(DP) * 100
-    else:
-
-        if RH == "FALSE":
-            raise ValueError(
-                "Either DP (dew point) or RH (relative humidity) must be specified."
-            )
-
-        # relative humidity is specified
-        # confirm relative humidity is in range
-
-        if RH < 0 or RH > 1:
-            raise ValueError("The relative humidity must be in the range of 0 to 1.")
-
-        if T == "FALSE":
-            raise ValueError(
-                "If the relative humidity is specified, the temperature must also be specified."
-            )
-
-        T = U.temp_conv(T, from_units=temp_units, to_units="C")
-
-        Pv = _sat_press(T) * 100
-        Pv *= RH
-
-    Pv = U.press_conv(Pv, from_units="pa", to_units=press_units)
-
-    return Pv
-
-
-def dry_press(
-    H,
-    Pv,
-    alt_setting=P0,
-    alt_units=default_alt_units,
-    press_units=default_press_units,
-):
-    """
-    Returns dry air pressure, i.e. the total air pressure, less the water
-    vapour pressure.
-    """
-
-    HP = pressure_alt(H, alt_setting, alt_units=alt_units)
-    P = alt2press(HP, press_units=press_units, alt_units=alt_units)
-    Pd = P - Pv
-
-    return Pd
-
-
-def density_alt2temp(
-    density_alt_seek,
-    press_alt,
-    alt_units=default_alt_units,
-    temp_units=default_temp_units,
-):
-    """
-    Return temperature to achieve a desired density altitude.
-
-    If the units are not specified, the units in default_units.py are used.
-    """
-
-    low = -100  # initial lower guess
-    high = 100  # initial upper guess
-
-    # confirm initial low and high are OK:
-
-    da_low = density_alt(press_alt, low, alt_units=alt_units)
-    if da_low > density_alt_seek:
-        raise ValueError("Initial low guess too high.")
-
-    da_high = density_alt(press_alt, high, alt_units=alt_units)
-    if da_high < density_alt_seek:
-        raise ValueError("Initial high guess too low.")
-
-    guess = (low + high) / 2.0
-    da_guess = density_alt(press_alt, guess, alt_units=alt_units)
-
-    # keep iterating until da is within 1 ft of desired value
-
-    while M.fabs(da_guess - density_alt_seek) > 1:
-        if da_guess > density_alt_seek:
-            high = guess
-        else:
-            low = guess
-
-        guess = (low + high) / 2.0
-        da_guess = density_alt(press_alt, guess, alt_units=alt_units)
-
-    guess = U.temp_conv(guess, from_units="C", to_units=temp_units)
-
-    return guess
-
-
-def density_alt_table(
-    density_alt_seek,
-    alt_range=2000,
-    alt_inc=100,
-    alt_units=default_alt_units,
-    temp_units=default_temp_units,
-    multi_units=False,
-    file="",
-    format="text",
-):
-    """
-    Return a text or html table of required temperature vs pressure altitude.
-
-    If the units are not specified, the units in default_units.py are used.
-    """
-
-    line_buffer = []
-    if format == "text":
-        line_buffer.append("Pressure altitudes and temperatures for a density ")
-        line_buffer.append("altitude of " + str(density_alt_seek) + " " + alt_units)
-        line_buffer.append("(assuming dry air)\n")
-        if multi_units:
-            line_buffer.append(" Pressure    Temp      Temp")
-            line_buffer.append(" Altitude")
-            line_buffer.append("   (" + alt_units + ")     (deg C)   (deg F)")
-        else:
-            line_buffer.append(" Pressure    Temp")
-            line_buffer.append(" Altitude")
-            line_buffer.append("   (" + alt_units + ")     (deg " + temp_units + ")")
-    elif format == "html":
-        print("creating html")
-    else:
-        raise ValueError('Invalid format.  Must be either "text" or "html"')
-
-    if multi_units:
-        for alt in range(
-            max(density_alt_seek - alt_range / 2.0, 0),
-            density_alt_seek + alt_range / 2.0 + alt_inc,
-            alt_inc,
-        ):
-            temp_c = density_alt2temp(density_alt_seek, alt, alt_units=alt_units)
-            temp_f = U.temp_conv(temp_c, from_units="C", to_units="F")
-            alt_str = L.format("%.*f", (0, alt), grouping=True)
-            temp_c_str = "%.1f" % temp_c
-            temp_f_str = "%.1f" % temp_f
-            line_buffer.append(
-                alt_str.rjust(6) + temp_c_str.rjust(11) + temp_f_str.rjust(10)
-            )
-    else:
-        for alt in range(
-            max(density_alt_seek - alt_range / 2.0, 0),
-            density_alt_seek + alt_range / 2.0 + alt_inc,
-            alt_inc,
-        ):
-            alt_str = L.format("%.*f", (0, alt), grouping=True)
-            temp_str = "%.1f" % density_alt2temp(
-                density_alt_seek, alt, temp_units=temp_units, alt_units=alt_units
-            )
-            line_buffer.append(alt_str.rjust(6) + temp_str.rjust(11))
-
-    if file != "":
-        OUT = open(file, "w")
-        for line in line_buffer:
-            OUT.write(line + "\n")
-
-        print("file selected")
-    else:
-        return "\n".join(line_buffer)
-
-
-# #############################################################################
-#
-# Pressure to altitude and pressure ratio to altitude
-#
-# #############################################################################
-
-
-def _press2alt_gradient(
-    P,
-    Pb,
-    Hb,
-    Tb,
-    L,
-):
-
-    return Hb + (Tb / L) * ((P / Pb) ** (((-1 * Rd) * L) / (1000 * g)) - 1)
-
-
-def _press2alt_isothermal(
-    P,
-    Pb,
-    Hb,
-    Tb,
-):
-
-    return Hb - ((Rd * Tb) * M.log(P / Pb)) / (1000 * g)
-
-
-def press2alt(P, press_units=default_press_units, alt_units=default_alt_units):
-    """
-    Return the altitude corresponding to the specified pressure, with
-    pressure in inches of HG, mm of HG, psi, psf (lb per sq. ft), pa, hpa or
-    mb.
-
-    The altitude is in units of feet ('ft'), metres ('m'), statute miles,
-    ('sm') or nautical miles ('nm')
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the pressure altitude in feet for a pressure of 31.0185 inches
-    of HG:
-    >>> press2alt(31.0185)
-    -999.98992888235091
-
-    Calculate the pressure altitude in feet for a pressure of
-    1455.33 lb sq. ft:
-    >>> press2alt(1455.33, press_units = 'psf')
-    10000.002466564831
-
-    Calculate the pressure altitude in metres for a pressure of
-    90.3415 mm HG:
-    >>> press2alt(90.3415, press_units = 'mm HG', alt_units = 'm')
-    15000.025465320754
-
-    Calculate the pressure altitude in metres for a pressure of
-    1171.86 pascal:
-    >>> press2alt(1171.86, press_units = 'pa', alt_units = 'm')
-    30000.029510365184
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    P = U.press_conv(P, from_units=press_units, to_units="in HG")
-
-    if P > P11:
-        H = _press2alt_gradient(P, P0, 0, T0, L0)
-    elif P > P20:
-        H = _press2alt_isothermal(P, P11, 11, T11)
-    elif P > P32:
-        H = _press2alt_gradient(P, P20, 20, T20, L20)
-    elif P > P47:
-        H = _press2alt_gradient(P, P32, 32, T32, L32)
-    elif P > P51:
-        H = _press2alt_isothermal(P, P47, 47, T47)
-    elif P > P71:
-        H = _press2alt_gradient(P, P51, 51, T51, L51)
-    else:
-        H = _press2alt_gradient(P, P71, 71, T71, L71)
-
-    if H > 84.852:
-        raise ValueError(
-            "This function is only implemented for altitudes of 84.852 km and below."
-        )
-
-    return U.len_conv(H, from_units="km", to_units=alt_units)
-
-
-def press_ratio2alt(PR, alt_units=default_alt_units):
-    """
-    Return the pressure ratio for the specified altitude.  The altitude is
-    specified in feet ('ft'), metres ('m'), statute miles, ('sm') or
-    nautical miles ('nm').
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Calculate the altitude in feet where the pressure ratio is 0.5:
-    >>> press_ratio2alt(.5)
-    17969.990746028907
-
-    Calculate the altitude in metres where the pressure ratio is 0.1:
-    >>> press_ratio2alt(.1, alt_units = 'm')
-    16096.249927559489
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    P = PR * P0
-    return press2alt(P, alt_units=alt_units)
-
-
-# #############################################################################
-#
-# Temperature to speed of sound
-#
-# #############################################################################
-
-
-def temp2speed_of_sound(
-    temp, temp_units=default_temp_units, speed_units=default_speed_units
-):
-    """
-    Return the speed of sound, given the air temperature.
-
-    The temperature units may be deg C, F, K or R ('C', 'F', 'K' or 'R').
-
-    The speed units may be 'kt', 'mph', 'km/h', 'm/s' and 'ft/s'.
-
-    If the units are not specified, the units in default_units.py are used.
-
-    Examples:
-
-    Determine speed of sound in knots at 15 deg (default temperature units):
-    >>> temp2speed_of_sound(15)
-    661.47882487301808
-
-    Determine speed of sound in mph at 120 deg F:
-    >>> temp2speed_of_sound(120, speed_units = 'mph', temp_units = 'F')
-    804.73500154991291
-    """
-
-    # function tested in tests/test_std_atm.py
-
-    temp = U.temp_conv(temp, from_units=temp_units, to_units="K")
-
-    speed_of_sound = M.sqrt((1.4 * Rd) * temp)
-    speed_of_sound = U.speed_conv(
-        speed_of_sound, from_units="m/s", to_units=speed_units
-    )
-
-    return speed_of_sound
-
-
-if __name__ == "__main__":
-
-    # run doctest to check the validity of the examples in the doc strings.
-
-    import doctest
-    import sys
-
-    doctest.testmod(sys.modules[__name__])
+#!/usr/bin/python
+# -*- coding: utf-8 -*-
+
+# #############################################################################
+# Copyright (c) 2008, Kevin Horton
+# All rights reserved.
+# Redistribution and use in source and binary forms, with or without
+# modification, are permitted provided that the following conditions are met:
+# *
+#     * Redistributions of source code must retain the above copyright
+#       notice, this list of conditions and the following disclaimer.
+#     * Redistributions in binary form must reproduce the above copyright
+#       notice, this list of conditions and the following disclaimer in the
+#       documentation and/or other materials provided with the distribution.
+#     * The name of Kevin Horton may not be used to endorse or promote products
+#       derived from this software without specific prior written permission.
+# *
+# THIS SOFTWARE IS PROVIDED BY KEVIN HORTON ``AS IS'' AND ANY EXPRESS OR
+# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
+# EVENT SHALL KEVIN HORTON BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
+# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+# OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
+# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+# #############################################################################
+#
+# version 0.16, 06 May 2007
+#
+# Version History:
+# vers     date     Notes
+#  0.1   14 May 06  First release.
+#
+# 0.11   17 May 06  Cleaned up documentation.
+#
+# 0.12   24 May 06  Added temp2speed_of_sound function.
+#
+# 0.13   02 Jun 06  Added temp2isa and isa2temp functions.
+#
+# 0.14   22 Apr 07  Added density altitude vs temperature functions
+#
+# 0.15   29 Apr 07  Broke out sat_press and dry_press as public functions.
+#
+# 0.16   05 May 07  Reworked to use default units from default_units module.
+# #############################################################################
+#
+# To Do: 1. Done.
+#
+#        2. Done.
+#
+#        3. Done.
+#
+#        4. Won't do.
+#
+#        5. Add temp2temp_ratio, press2press_ratio and density2density_ratio.
+#
+#        6. Done.
+#
+#        7. Add tests for all functions to test/test_std_atm.py
+#           Tests to add:
+#           dry_press
+#           density_alt_table ? (probably won't make a test for this)
+#
+#        8. Review code to catch duplicated code blocks in different functions.
+#           Move these blocks to internal functions.
+#
+#        9. Review API for all public functions for consistency of units, etc.
+#
+# Done:  1. consider replacing calculations by constants where possible.  See
+#           http://jcoppens.com/globo/teoria/atm_est.en.php
+#
+#           Tested replacing calculations by constants in press2alt.  The
+#           perf improvement was only about 15%.  Probably not worth the trouble.
+#           Better to keep the pedigree of the equations visible.
+#
+#        2. Validate against published data.  Created unittests using data:
+#           http://www.sworld.com.au/steven/space/atmosphere/
+#
+#        3. Added relative humidity to density altitude calc.  See:
+#           http://wahiduddin.net/calc/density_altitude.htm
+#
+#        4. Change formulae to use pressure in pa, not in HG.  Won't do.
+#           Instead, changed to use default units specified in default_units.py
+#
+#        6. Added functions:
+#           isa2temp
+#           temp2isa
+#
+#        7. Added tests for functions:
+#           pressure_alt
+#           sat_press
+#           density_alt2temp
+# #############################################################################
+
+"""Calculate standard atmosphere parametres.
+
+Calculates standard atmosphere parametres, using the 1976 International
+Standard Atmosphere.  The default units for the input and output are defined
+in default_units.py
+
+All altitudes are geopotential altitudes (i.e. it is assumed that there is
+no variation with altitude of the acceleration due to gravity).
+
+Works up to 84.852 km (278,386 ft) altitude.
+
+"""
+
+import locale as L
+import math as M
+
+import skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.unit_conversion as U
+
+try:
+    from default_units import *
+except ImportError:
+    default_area_units = "ft**2"
+    default_power_units = "hp"
+    default_speed_units = "kt"
+    default_temp_units = "C"
+    default_weight_units = "lb"
+    default_press_units = "in HG"
+    default_density_units = "lb/ft**3"
+    default_length_units = "ft"
+    default_alt_units = default_length_units
+    default_avgas_units = "lb"
+
+try:
+    L.setlocale(L.LC_ALL, "en_US")
+except:
+    pass
+
+g = 9.80665  # Acceleration of gravity at 45.542 deg latitude, m/s**s
+Rd = 287.05307  # Gas constant for dry air, J/kg K
+
+# conditions starting at sea level, in a region with temperature gradient
+
+T0 = 288.15  # Temperature at sea level, degrees K
+L0 = -6.5  # Temperature lapse rate, at sea level deg K/km
+P0 = 29.9213  # Pressure at sea level, in HG
+Rho0 = 1.2250  # Density at sea level, kg/m**3
+
+# conditions starting at 11 km, in an isothermal region
+
+T11 = T0 + 11 * L0  # Temperature at 11,000 m, degrees K
+PR11 = (T11 / T0) ** ((-1000 * g) / (Rd * L0))  # pressure ratio at 11,000 m
+P11 = PR11 * P0
+Rho11 = (Rho0 * PR11) * (T0 / T11)
+
+# conditions starting at 20 km, in a region with temperature gradient
+
+T20 = T11
+PR20 = PR11 * M.exp(((-1000 * g) * (20 - 11)) / (Rd * T11))
+L20 = 1  # temperature lapse rate, starting at 20,000 m, deg K/km
+P20 = PR20 * P0
+Rho20 = (Rho0 * PR20) * (T0 / T20)
+
+# conditions starting at 32 km, in a region with temperature gradient
+
+T32 = 228.65  # Temperature at 32 km, degrees K
+PR32 = PR20 * (T32 / T20) ** ((-1000 * g) / (Rd * L20))
+
+# PR32 = PR20 * M.exp((-1000 * g) * (32 - 20)/(R * T20))
+
+L32 = 2.8  # temperature lapse rate, starting at 32,000 m, deg K/km
+P32 = PR32 * P0
+Rho32 = (Rho0 * PR32) * (T0 / T32)
+
+# conditions starting at 47 km, in an isothermal region
+
+T47 = 270.65
+PR47 = PR32 * (T47 / T32) ** ((-1000 * g) / (Rd * L32))
+P47 = PR47 * P0
+Rho47 = (Rho0 * PR47) * (T0 / T47)
+
+# conditions starting at 51 km, in a region with temperature gradient
+
+T51 = 270.65  # Temperature at 51 km, degrees K
+PR51 = PR47 * M.exp(((-1000 * g) * (51 - 47)) / (Rd * T47))
+L51 = -2.8  # temperature lapse rate, starting at 51,000 m, deg K/km
+P51 = PR51 * P0
+Rho51 = (Rho0 * PR51) * (T0 / T51)
+
+# conditions starting at 71 km, in a region with temperature gradient
+
+T71 = 214.65  # Temperature at 71 km, degrees K
+PR71 = PR51 * (T71 / T51) ** ((-1000 * g) / (Rd * L51))
+L71 = -2.0  # temperature lapse rate, starting at 71,000 m, deg K/km
+P71 = PR71 * P0
+Rho71 = (Rho0 * PR71) * (T0 / T71)
+
+# temp_units_list = ['C', 'F', 'K', 'R']
+
+# #############################################################################
+#
+# Altitude to temperature
+#
+# #############################################################################
+
+
+def alt2temp(H, alt_units=default_alt_units, temp_units=default_temp_units):
+    """Return the standard temperature for the specified altitude.  Altitude
+    units may be feet ('ft'), metres ('m'), statute miles, ('sm') or
+    nautical miles ('nm').  Temperature units may be degrees C, F, K or R
+    ('C', 'F', 'K' or 'R')
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the standard temperature (in default temperature units) at
+    5,000 (default altitude units):
+    >>> alt2temp(5000)
+    5.0939999999999941
+
+    Calculate the standard temperature in deg F at sea level:
+    >>> alt2temp(0, temp_units = 'F')
+    59.0
+
+    Calculate the standard temperature in deg K at 11,000 m:
+    >>> alt2temp(11000, alt_units = 'm', temp_units = 'K')
+    216.64999999999998
+
+    Calculate the standard temperature at 11 statute miles in deg R:
+    >>> alt2temp(11, alt_units = 'sm', temp_units = 'R')
+    389.96999999999997
+
+    The input value may be an expression:
+    >>> alt2temp(11 * 5280, temp_units = 'R')
+    389.96999999999997
+
+    """
+
+    # Validated to 84000 m
+    # uses meters and degrees K for the internal calculations
+
+    # function tested in tests/test_std_atm.py
+
+    H = U.len_conv(H, from_units=alt_units, to_units="km")
+
+    if H <= 11:
+        temp = T0 + H * L0
+    elif H <= 20:
+        temp = T11
+    elif H <= 32:
+        temp = T20 + (H - 20) * L20
+    elif H <= 47:
+        temp = T32 + (H - 32) * L32
+    elif H <= 51:
+        temp = T47
+    elif H <= 71:
+        temp = T51 + (H - 51) * L51
+    elif H <= 84.852:
+        temp = T71 + (H - 71) * L71
+    else:
+        raise ValueError(
+            "This function is only implemented for altitudes of 84.852 km and below."
+        )
+
+    return U.temp_conv(temp, to_units=temp_units, from_units="K")
+
+
+def alt2temp_ratio(H, alt_units=default_alt_units):
+    """
+    Return the temperature ratio (temperature / standard temperature for
+    sea level).  The altitude is specified in feet ('ft'), metres ('m'),
+    statute miles, ('sm') or nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the temperature ratio at 8,000 (default altitude units)
+    >>> alt2temp_ratio(8000)
+    0.94499531494013533
+
+    Calculate the temperature ratio at 8,000 m.
+    >>> alt2temp_ratio(8000, alt_units = 'm')
+    0.81953843484296374
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    return alt2temp(H, alt_units, temp_units="K") / T0
+
+
+# #############################################################################
+#
+# ISA deviation to temperature
+#
+# #############################################################################
+
+
+def isa2temp(
+    ISA_dev,
+    altitude,
+    temp_units=default_temp_units,
+    alt_units=default_alt_units,
+):
+    """
+    Return the temperature that is a specified amount warmer or cooler
+    than the standard temperature for the altitude.
+
+    The temperature may be in deg C, F, K or R.
+
+    The altitude may be in feet ('ft'), metres ('m'), kilometres ('km'),
+    statute miles, ('sm') or nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Determine the temperature that is 10 deg (default temperature units) warmer
+    than the standard temperature at 8,000 (default altitude units):
+    >>> isa2temp(10, 8000)
+    9.1503999999999905
+
+    Determine the temperature that is 25 degrees K cooler than the standard
+    temperature at 2000 m.
+    >>> isa2temp(-25, 2000, temp_units = 'K', alt_units = 'm')
+    250.14999999999998
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    temp = ISA_dev + alt2temp(altitude, alt_units, temp_units)
+
+    return temp
+
+
+# #############################################################################
+#
+# temperature to ISA deviation
+#
+# #############################################################################
+
+
+def temp2isa(
+    temp,
+    altitude,
+    temp_units=default_temp_units,
+    alt_units=default_alt_units,
+):
+    """
+    Return the amount that the specified temperature is warmer or cooler
+    than the standard temperature for the altitude.
+
+    The temperature may be in deg C, F, K or R.
+
+    The altitude may be in feet ('ft'), metres ('m'), kilometres ('km'),
+    statute miles, ('sm') or nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Determine the ISA deviation for a temperature of 30 deg (default
+    temperature units) at an altitude of 2000 (default altitude units):
+    >>> temp2isa(30, 2000)
+    18.962400000000002
+
+    Determine the ISA deviation in degrees F for a temperature of 45 deg F
+    at an altitude of 1000 m:
+    >>> temp2isa(45, 1000, temp_units = 'F', alt_units = 'm')
+    -2.2999999999999972
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    std_temp = alt2temp(altitude, alt_units, temp_units)
+    ISA_dev = temp - std_temp
+
+    return ISA_dev
+
+
+# #############################################################################
+#
+# Altitude to pressure and pressure ratio
+#
+# #############################################################################
+
+
+def _alt2press_ratio_gradient(
+    H,
+    Hb,
+    Pb,
+    Tb,
+    L,
+):
+
+    # eqn from USAF TPS PEC binder, page PS1-31
+
+    return (Pb / P0) * (1 + (L / Tb) * (H - Hb)) ** ((-1000 * g) / (Rd * L))
+
+
+def _alt2press_ratio_isothermal(
+    H,
+    Hb,
+    Pb,
+    Tb,
+):
+
+    # eqn from USAF TPS PEC binder, page PS1-26
+
+    return (Pb / P0) * M.exp((-1 * (H - Hb)) * ((1000 * g) / (Rd * Tb)))
+
+
+def alt2press_ratio(H, alt_units=default_alt_units):
+    """
+    Return the pressure ratio (atmospheric pressure / standard pressure
+    for sea level).  The altitude is specified in feet ('ft'), metres ('m'),
+    statute miles, ('sm') or nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the pressure ratio at 5000 (default altitude units):
+    >>> alt2press_ratio(5000)
+    0.8320481158727735
+
+    Calculate the pressure ratio at 1000 m:
+    >>> alt2press_ratio(1000, alt_units = 'm')
+    0.88699304638887044
+
+    The functions are only implemented at altitudes of 84.852 km and lower.
+    >>> alt2press_ratio(90, alt_units = 'km')
+    Traceback (most recent call last):
+      File '<stdin>', line 1, in ?
+      File './std_atm.py', line 189, in alt2press_ratio
+    if H <= 20:
+    ValueError: This function is only implemented for altitudes of 84.852 km and below.
+    """
+
+    # uses meters and degrees K for the internal calculations
+
+    # function tested in tests/test_std_atm.py
+
+    H = U.len_conv(H, from_units=alt_units, to_units="km")
+
+    if H <= 11:
+        return _alt2press_ratio_gradient(H, 0, P0, T0, L0)
+    if H <= 20:
+        return _alt2press_ratio_isothermal(H, 11, P11, T11)
+    if H <= 32:
+        return _alt2press_ratio_gradient(H, 20, P20, T20, L20)
+    if H <= 47:
+        return _alt2press_ratio_gradient(H, 32, P32, T32, L32)
+    if H <= 51:
+        return _alt2press_ratio_isothermal(H, 47, P47, T47)
+    if H <= 71:
+        return _alt2press_ratio_gradient(H, 51, P51, T51, L51)
+    if H <= 84.852:
+        return _alt2press_ratio_gradient(H, 71, P71, T71, L71)
+    else:
+        raise ValueError(
+            "This function is only implemented for altitudes of 84.852 km and below."
+        )
+
+
+def alt2press(H, alt_units=default_alt_units, press_units=default_press_units):
+    """
+    Return the atmospheric pressure for a given altitude, with the
+    altitude in feet ('ft'), metres ('m'), statute miles, ('sm') or nautical
+    miles ('nm'), and the pressure in inches of HG ('in HG'), mm of HG
+    ('mm HG'), psi, lb per sq. ft ('psf'), pa, hpa or mb.
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the pressure in inches of mercury at 5,000 (default altitude
+    units):
+    >>> alt2press(5000)
+    24.895961289464015
+
+    Calculate the pressure in pounds per square foot at 10,000 (default
+    altitude units):
+    >>> alt2press(10000, press_units = 'psf')
+    1455.3301392981359
+
+    Calculate the pressure in pascal at 20 km:
+    >>> alt2press(20, press_units = 'pa', alt_units = 'km')
+    5474.8827144576408
+    """
+
+    # uses meters, inches of HG and degrees K for the internal calculations
+
+    # function tested in tests/test_std_atm.py
+
+    H = U.len_conv(H, from_units=alt_units, to_units="m")
+
+    press = P0 * alt2press_ratio(H, alt_units="m")
+    press = U.press_conv(press, from_units="in HG", to_units=press_units)
+
+    return press
+
+
+# #############################################################################
+#
+# Pressure altitude from barometric altitude and altimeter setting
+#
+# #############################################################################
+
+
+def pressure_alt(H, alt_setting, alt_units=default_alt_units):
+    """
+    Return the pressure altitude, given the barometric altitude and the
+    altimeter setting.
+
+    Altimeter setting may have units of inches of HG, or hpa or mb.  If the
+    altimeter setting value is less than 35, the units are assumed to be
+    in HG, otherwise they are assumed to be hpa.  The altimeter setting must
+    be in the range of 25 to 35 inches of mercury.
+
+    The altitude may have units of feet ('ft'), metres ('m'), statute miles,
+    ('sm') or nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the pressure altitude for 1,000 (default altitude units)
+    barometric altitude with altimeter setting of 30.92 in HG:
+    >>> pressure_alt(1000, 30.92)
+    88.612734282205338
+
+    Calculate the pressure altitude for 1,000 (default altitude units)
+    barometric altitude with altimeter setting of 1008 mb:
+    >>> pressure_alt(1000, 1008)
+    1143.6503495627171
+
+    Calculate the pressure altitude in metres for 304.8 m barometric
+    altitude with altimeter setting of 1008 mb:
+    >>> pressure_alt(304.8, 1008, alt_units = 'm')
+    348.58462654671621
+    """
+
+    H = U.len_conv(H, from_units=alt_units, to_units="ft")
+    if alt_setting > 35:
+        alt_setting = U.press_conv(alt_setting, from_units="hpa", to_units="in HG")
+    if alt_setting < 25 or alt_setting > 35:
+        raise ValueError("Altimeter setting out of range.")
+    HP = H + 145442.2 * (1 - (alt_setting / P0) ** 0.190261)
+    HP = U.len_conv(HP, from_units="ft", to_units=alt_units)
+    return HP
+
+
+def QNH(
+    HP,
+    H,
+    alt_units=default_alt_units,
+    alt_setting_units="in HG",
+):
+    """
+    Return the altimeter setting, given the pressure altitude (HP) and the
+    barometric altitude (H).
+    """
+
+    HP = U.len_conv(HP, from_units=alt_units, to_units="ft")
+    H = U.len_conv(H, from_units=alt_units, to_units="ft")
+    QNH = P0 * (1 - (HP - H) / 145442.2) ** 5.255594
+    QNH = U.press_conv(QNH, from_units="in HG", to_units=alt_setting_units)
+
+    return QNH
+
+
+# #############################################################################
+#
+# Altitude to density and density ratio
+#
+# #############################################################################
+
+
+def alt2density_ratio(H, alt_units=default_alt_units):
+    """
+    Return the density ratio (atmospheric density / standard density
+    for sea level).  The altitude is specified in feet ('ft'), metres ('m'),
+    statute miles, ('sm') or nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the density ratio at 7,500 (default altitude units):
+    >>> alt2density_ratio(7500)
+    0.79825819881753035
+
+    Calculate the density ratio at 2 km:
+    >>> alt2density_ratio(2, alt_units = 'km')
+    0.8216246960994622
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    return alt2press_ratio(H, alt_units) / alt2temp_ratio(H, alt_units)
+
+
+def alt2density(H, alt_units=default_alt_units, density_units=default_density_units):
+    """
+    Return the density given the pressure altitude.  The altitude is
+    specified in feet ('ft'), metres ('m'), statute miles, ('sm') or
+    nautical miles ('nm').
+
+    The desired density units are specified as 'lb/ft**3', 'slug/ft**3' or
+    'kg/m**3'.
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the density in lb / ft cubed at 7,500 (default altitude units):
+    >>> alt2density(7500)
+    0.061046199847730374
+
+    Calculate the density in slugs / ft cubed at 5,000 (default altitude units):
+    >>> alt2density(5000, density_units = 'slug/ft**3')
+    0.0020480982157718704
+
+    Calculate the density in kg / m cubed at 0 (default altitude units:
+    >>> alt2density(0, density_units = 'kg/m**3')
+    1.2250000000000001
+
+    Calculate the density in kg / m cubed at 81,000 m:
+    >>> alt2density(81000, density_units = 'kg/m**3', alt_units = 'm')
+    1.3320480184052337e-05
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    # get density in kg/m**3
+
+    density = Rho0 * alt2density_ratio(H, alt_units)
+    return U.density_conv(density, from_units="kg/m**3", to_units=density_units)
+
+
+# #############################################################################
+#
+# Density to altitude and density ratio to altitude
+#
+# #############################################################################
+
+
+def _density2alt_gradient(
+    Rho,
+    Rhob,
+    Hb,
+    Tb,
+    L,
+):
+
+    return Hb + (Tb / L) * ((Rho / Rhob) ** (-1 / ((1000 * g) / (Rd * L) + 1)) - 1)
+
+
+def _density2alt_isothermal(
+    Rho,
+    Rhob,
+    Hb,
+    Tb,
+):
+
+    return Hb - ((Rd * Tb) * M.log(Rho / Rhob)) / (1000 * g)
+
+
+def density2alt(Rho, density_units=default_density_units, alt_units=default_alt_units):
+    """
+    Return the altitude corresponding to the specified density, with
+    density in 'lb/ft**3', 'slug/ft**3' or 'kg/m**3'.
+
+    The altitude is specified in feet ('ft'), metres ('m'), statute miles,
+    ('sm') or nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the altitude in default altitude units where the density is
+    0.056475 in default density units:
+    >>> density2alt(.056475)
+    9999.8040934937271
+
+    Calculate the altitude in metres where the density is 0.018012 kg / m
+    cubed:
+    >>> density2alt(.018012, alt_units = 'm', density_units = 'kg/m**3')
+    29999.978688508152
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    Rho = U.density_conv(Rho, from_units=density_units, to_units="kg/m**3")
+
+    if Rho > Rho11:
+        H = _density2alt_gradient(Rho, Rho0, 0, T0, L0)
+    elif Rho > Rho20:
+        H = _density2alt_isothermal(Rho, Rho11, 11, T11)
+    elif Rho > Rho32:
+        H = _density2alt_gradient(Rho, Rho20, 20, T20, L20)
+    elif Rho > Rho47:
+        H = _density2alt_gradient(Rho, Rho32, 32, T32, L32)
+    elif Rho > Rho51:
+        H = _density2alt_isothermal(Rho, Rho47, 47, T47)
+    elif Rho > Rho71:
+        H = _density2alt_gradient(Rho, Rho51, 51, T51, L51)
+    else:
+        H = _density2alt_gradient(Rho, Rho71, 71, T71, L71)
+
+    if H > 84.852:
+        raise ValueError(
+            "This function is only implemented for altitudes of 84.852 km and below."
+        )
+
+    return U.len_conv(H, from_units="km", to_units=alt_units)
+
+
+def density_ratio2alt(DR, alt_units=default_alt_units):
+    """
+    Return the altitude for the specified density ratio. The altitude is in
+    feet ('ft'), metres ('m'), statute miles, ('sm') or nautical miles
+    ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the altitude in default altitude units where the density ratio is
+    1:
+    >>> density_ratio2alt(1)
+    0.0
+
+    Calculate the altitude in feet where the density ratio is 0.5:
+    >>> density_ratio2alt(.5)
+    21859.50324995652
+
+    Calculate the altitude in km where the density ratio is 0.1
+    >>> density_ratio2alt(.1, alt_units = 'km')
+    17.9048674520646
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    D = DR * Rho0
+    return density2alt(D, alt_units=alt_units, density_units="kg/m**3")
+
+
+# #############################################################################
+#
+# Density Altitude
+#
+# #############################################################################
+
+
+def density_alt(
+    H,
+    T,
+    alt_setting=P0,
+    DP="FALSE",
+    RH=0.0,
+    alt_units=default_alt_units,
+    temp_units=default_temp_units,
+):
+    """
+    Return density altitude, given the pressure altitude and the
+    temperature with altitudes in units of feet ('ft'), metres ('m'),
+    statute miles, ('sm') or nautical miles ('nm'), and temperature in units
+    of deg C, F, K or R ('C', 'F', 'K' or 'R').
+
+    Mandatory parametres:
+    H = altitude
+    T = temperature
+
+    Optional parametres:
+    alt_setting = altimeter setting (defaults to 29.9213 if not provided
+    DP = dew point
+    RH = relative humidity
+    alt_units = units for the altitude.  'ft', 'm', or 'km'.
+    temp_units = units for the temperature and dew point.  'C', 'F', 'K'
+                 or 'R'.
+
+    The altimeter setting units are assumed to be inches of HG, unless the
+    value is greater than 35.  In this case the units are assumed to be mb.
+
+    If the dew point or relative humidity are not specified, the air is
+    assumed to be completely dry.  If both the dew point and relative humidity
+    are specified, the relative humidity value is ignored.
+
+    If the units are not specified, the units in default_units.py are used.
+
+    The method is from: http://wahiduddin.net/calc/density_altitude.htm
+
+    Examples:
+
+    Calculate the density altitude in default altitude units for a pressure
+    altitude of 7000 default altitude units and a temperature of 15 deg
+    (default temperature units).  The altimeter setting is not specified, so it
+    defaults to standard pressure of 29.9213 in HG or 1013.25 mb:
+    >>> density_alt(7000, 15)
+    8595.3465863232504
+
+    Calculate the density altitude in default altitude units for a pressure
+    altitude of 7000 default altitude units and a temperature of 85 deg F.
+    The altimeter setting is not specified, so it defaults to standard pressure
+    of 29.9213 in HG or 1013.25 mb.  The dew point and relative humidity are
+    not specified, so the air is assumed to be dry:
+    >>> density_alt(7000, 85, temp_units = 'F')
+    10159.10696106757
+
+    Calculate the density altitude in default altitude units for a pressure
+    altitude of 7000 default altitude units, an altimeter setting of 29.80 and
+    a temperature of 85 deg F and a dew point of 55 deg F:
+    >>> density_alt(7000, 85, 29.80, 55, temp_units = 'F')
+    10522.776013011618
+
+    Calculate the density altitude in metres for a pressure altitude of
+    2000 m, an altimeter setting of 1010 mb,  a temperature of 15 deg (default
+    temperature units) and a relative humidity of 50%:
+    >>> density_alt(2000, 15, 1010, alt_units = 'm', RH = 0.5)
+    2529.8230634449737
+
+    The dew point may be specified in one of two ways: as the fourth
+    argument on the command line, or via the keyword argument DP.
+    >>> density_alt(2000, 15, 1010, alt_units = 'm', DP = 5)
+    2530.7528237990618
+
+    The relative humidity must be in the range of 0 to 1:
+    >>> density_alt(2000, 15, 1010, alt_units = 'm', RH = 1.1)
+    Traceback (most recent call last):
+      File '<stdin>', line 1, in ?
+      File 'std_atm.py', line 533, in density_alt
+    raise ValueError, 'The relative humidity must be in the range of 0 to 1.'
+    ValueError: The relative humidity must be in the range of 0 to 1.
+    """
+
+    Rv = 461.495  # gas constant for water vapour
+
+    # saturated vapour pressure
+
+    if DP == "FALSE" and RH == 0:
+        Pv = 0
+    else:
+        Pv = sat_press(T, DP, RH, temp_units, press_units="pa")
+
+    # dry air pressure
+
+    Pd = dry_press(
+        H, Pv, alt_setting=alt_setting, alt_units=alt_units, press_units="pa"
+    )
+
+    T = U.temp_conv(T, from_units=temp_units, to_units="K")
+    D = Pd / (Rd * T) + Pv / (Rv * T)
+
+    DR = D / Rho0
+
+    return density_ratio2alt(DR, alt_units)
+
+
+def _sat_press(T):
+    """
+    Return the saturation pressure in mb of the water vapour, given
+    temperature in deg C.  Equation from:
+    http://wahiduddin.net/calc/density_altitude.htm
+    """
+
+    eso = 6.1078
+    c0 = 0.99999683
+    c1 = -0.90826951e-2
+    c2 = 0.78736169e-4
+    c3 = -0.61117958e-6
+    c4 = 0.43884187e-8
+    c5 = -0.29883885e-10
+    c6 = 0.21874425e-12
+    c7 = -0.17892321e-14
+    c8 = 0.11112018e-16
+    c9 = -0.30994571e-19
+
+    p = c0 + T * (
+        c1
+        + T
+        * (
+            c2
+            + T * (c3 + T * (c4 + T * (c5 + T * (c6 + T * (c7 + T * (c8 + T * c9))))))
+        )
+    )
+    sat_press = eso / p**8
+    return sat_press
+
+
+def sat_press(
+    T="FALSE",
+    DP="FALSE",
+    RH=0.0,
+    temp_units=default_temp_units,
+    press_units=default_press_units,
+):
+    """
+    Return the saturated vapour pressure of water.  Either the dew point, or
+    the temperature and the relative humidity must be specified.  If both the
+    dew point and relative humidity are specified, the relative humidity value
+    is ignored.
+
+    If the temperature and dew point are both specified, the dew point cannot
+    be greater than the temperature:
+
+    If the units are not specified, the units in default_units.py are used.
+
+    >>> sat_press(T=10, DP=11)
+    Traceback (most recent call last):
+      File '<stdin>', line 1, in <module>
+      File 'std_atm.py', line 795, in sat_press
+        raise ValueError, 'The dew point cannot be greater than the temperature.'
+    ValueError: The dew point cannot be greater than the temperature.
+
+    Dew point is 11 deg (default temperature units).  Find the water vapour
+    pressure in default pressure units:
+    >>> sat_press(DP=11)
+    0.38741015927568667
+
+    Dew point is 65 deg F.  Find the water vapour pressure in default pressure units:
+    >>> sat_press(DP=65, temp_units = 'F')
+    0.62207710701956165
+
+    Dew point is 212 deg F (the boiling point of water at sea level).
+    Find the water vapour pressure in lb per sq. inch:
+    >>> sat_press(DP=212, temp_units = 'F', press_units = 'psi')
+    14.696764873564959
+
+    Temperature is 30 deg C.  Find the water vapour pressure in default pressure units:
+    for 50% relative humidity:
+    >>> sat_press(T=30, RH = 0.5)
+    0.62647666996057927
+    """
+
+    if DP != "FALSE":
+
+        # use dew point method
+
+        if T != "FALSE":
+            if DP > T:
+                raise ValueError(
+                    "The dew point cannot be greater than the temperature."
+                )
+
+        DP = U.temp_conv(DP, from_units=temp_units, to_units="C")
+
+        # calculate vapour pressure
+
+        Pv = _sat_press(DP) * 100
+    else:
+
+        if RH == "FALSE":
+            raise ValueError(
+                "Either DP (dew point) or RH (relative humidity) must be specified."
+            )
+
+        # relative humidity is specified
+        # confirm relative humidity is in range
+
+        if RH < 0 or RH > 1:
+            raise ValueError("The relative humidity must be in the range of 0 to 1.")
+
+        if T == "FALSE":
+            raise ValueError(
+                "If the relative humidity is specified, the temperature must also be specified."
+            )
+
+        T = U.temp_conv(T, from_units=temp_units, to_units="C")
+
+        Pv = _sat_press(T) * 100
+        Pv *= RH
+
+    Pv = U.press_conv(Pv, from_units="pa", to_units=press_units)
+
+    return Pv
+
+
+def dry_press(
+    H,
+    Pv,
+    alt_setting=P0,
+    alt_units=default_alt_units,
+    press_units=default_press_units,
+):
+    """
+    Returns dry air pressure, i.e. the total air pressure, less the water
+    vapour pressure.
+    """
+
+    HP = pressure_alt(H, alt_setting, alt_units=alt_units)
+    P = alt2press(HP, press_units=press_units, alt_units=alt_units)
+    Pd = P - Pv
+
+    return Pd
+
+
+def density_alt2temp(
+    density_alt_seek,
+    press_alt,
+    alt_units=default_alt_units,
+    temp_units=default_temp_units,
+):
+    """
+    Return temperature to achieve a desired density altitude.
+
+    If the units are not specified, the units in default_units.py are used.
+    """
+
+    low = -100  # initial lower guess
+    high = 100  # initial upper guess
+
+    # confirm initial low and high are OK:
+
+    da_low = density_alt(press_alt, low, alt_units=alt_units)
+    if da_low > density_alt_seek:
+        raise ValueError("Initial low guess too high.")
+
+    da_high = density_alt(press_alt, high, alt_units=alt_units)
+    if da_high < density_alt_seek:
+        raise ValueError("Initial high guess too low.")
+
+    guess = (low + high) / 2.0
+    da_guess = density_alt(press_alt, guess, alt_units=alt_units)
+
+    # keep iterating until da is within 1 ft of desired value
+
+    while M.fabs(da_guess - density_alt_seek) > 1:
+        if da_guess > density_alt_seek:
+            high = guess
+        else:
+            low = guess
+
+        guess = (low + high) / 2.0
+        da_guess = density_alt(press_alt, guess, alt_units=alt_units)
+
+    guess = U.temp_conv(guess, from_units="C", to_units=temp_units)
+
+    return guess
+
+
+def density_alt_table(
+    density_alt_seek,
+    alt_range=2000,
+    alt_inc=100,
+    alt_units=default_alt_units,
+    temp_units=default_temp_units,
+    multi_units=False,
+    file="",
+    format="text",
+):
+    """
+    Return a text or html table of required temperature vs pressure altitude.
+
+    If the units are not specified, the units in default_units.py are used.
+    """
+
+    line_buffer = []
+    if format == "text":
+        line_buffer.append("Pressure altitudes and temperatures for a density ")
+        line_buffer.append("altitude of " + str(density_alt_seek) + " " + alt_units)
+        line_buffer.append("(assuming dry air)\n")
+        if multi_units:
+            line_buffer.append(" Pressure    Temp      Temp")
+            line_buffer.append(" Altitude")
+            line_buffer.append("   (" + alt_units + ")     (deg C)   (deg F)")
+        else:
+            line_buffer.append(" Pressure    Temp")
+            line_buffer.append(" Altitude")
+            line_buffer.append("   (" + alt_units + ")     (deg " + temp_units + ")")
+    elif format == "html":
+        print("creating html")
+    else:
+        raise ValueError('Invalid format.  Must be either "text" or "html"')
+
+    if multi_units:
+        for alt in range(
+            max(density_alt_seek - alt_range / 2.0, 0),
+            density_alt_seek + alt_range / 2.0 + alt_inc,
+            alt_inc,
+        ):
+            temp_c = density_alt2temp(density_alt_seek, alt, alt_units=alt_units)
+            temp_f = U.temp_conv(temp_c, from_units="C", to_units="F")
+            alt_str = L.format("%.*f", (0, alt), grouping=True)
+            temp_c_str = "%.1f" % temp_c
+            temp_f_str = "%.1f" % temp_f
+            line_buffer.append(
+                alt_str.rjust(6) + temp_c_str.rjust(11) + temp_f_str.rjust(10)
+            )
+    else:
+        for alt in range(
+            max(density_alt_seek - alt_range / 2.0, 0),
+            density_alt_seek + alt_range / 2.0 + alt_inc,
+            alt_inc,
+        ):
+            alt_str = L.format("%.*f", (0, alt), grouping=True)
+            temp_str = "%.1f" % density_alt2temp(
+                density_alt_seek, alt, temp_units=temp_units, alt_units=alt_units
+            )
+            line_buffer.append(alt_str.rjust(6) + temp_str.rjust(11))
+
+    if file != "":
+        OUT = open(file, "w")
+        for line in line_buffer:
+            OUT.write(line + "\n")
+
+        print("file selected")
+    else:
+        return "\n".join(line_buffer)
+
+
+# #############################################################################
+#
+# Pressure to altitude and pressure ratio to altitude
+#
+# #############################################################################
+
+
+def _press2alt_gradient(
+    P,
+    Pb,
+    Hb,
+    Tb,
+    L,
+):
+
+    return Hb + (Tb / L) * ((P / Pb) ** (((-1 * Rd) * L) / (1000 * g)) - 1)
+
+
+def _press2alt_isothermal(
+    P,
+    Pb,
+    Hb,
+    Tb,
+):
+
+    return Hb - ((Rd * Tb) * M.log(P / Pb)) / (1000 * g)
+
+
+def press2alt(P, press_units=default_press_units, alt_units=default_alt_units):
+    """
+    Return the altitude corresponding to the specified pressure, with
+    pressure in inches of HG, mm of HG, psi, psf (lb per sq. ft), pa, hpa or
+    mb.
+
+    The altitude is in units of feet ('ft'), metres ('m'), statute miles,
+    ('sm') or nautical miles ('nm')
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the pressure altitude in feet for a pressure of 31.0185 inches
+    of HG:
+    >>> press2alt(31.0185)
+    -999.98992888235091
+
+    Calculate the pressure altitude in feet for a pressure of
+    1455.33 lb sq. ft:
+    >>> press2alt(1455.33, press_units = 'psf')
+    10000.002466564831
+
+    Calculate the pressure altitude in metres for a pressure of
+    90.3415 mm HG:
+    >>> press2alt(90.3415, press_units = 'mm HG', alt_units = 'm')
+    15000.025465320754
+
+    Calculate the pressure altitude in metres for a pressure of
+    1171.86 pascal:
+    >>> press2alt(1171.86, press_units = 'pa', alt_units = 'm')
+    30000.029510365184
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    P = U.press_conv(P, from_units=press_units, to_units="in HG")
+
+    if P > P11:
+        H = _press2alt_gradient(P, P0, 0, T0, L0)
+    elif P > P20:
+        H = _press2alt_isothermal(P, P11, 11, T11)
+    elif P > P32:
+        H = _press2alt_gradient(P, P20, 20, T20, L20)
+    elif P > P47:
+        H = _press2alt_gradient(P, P32, 32, T32, L32)
+    elif P > P51:
+        H = _press2alt_isothermal(P, P47, 47, T47)
+    elif P > P71:
+        H = _press2alt_gradient(P, P51, 51, T51, L51)
+    else:
+        H = _press2alt_gradient(P, P71, 71, T71, L71)
+
+    if H > 84.852:
+        raise ValueError(
+            "This function is only implemented for altitudes of 84.852 km and below."
+        )
+
+    return U.len_conv(H, from_units="km", to_units=alt_units)
+
+
+def press_ratio2alt(PR, alt_units=default_alt_units):
+    """
+    Return the pressure ratio for the specified altitude.  The altitude is
+    specified in feet ('ft'), metres ('m'), statute miles, ('sm') or
+    nautical miles ('nm').
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Calculate the altitude in feet where the pressure ratio is 0.5:
+    >>> press_ratio2alt(.5)
+    17969.990746028907
+
+    Calculate the altitude in metres where the pressure ratio is 0.1:
+    >>> press_ratio2alt(.1, alt_units = 'm')
+    16096.249927559489
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    P = PR * P0
+    return press2alt(P, alt_units=alt_units)
+
+
+# #############################################################################
+#
+# Temperature to speed of sound
+#
+# #############################################################################
+
+
+def temp2speed_of_sound(
+    temp, temp_units=default_temp_units, speed_units=default_speed_units
+):
+    """
+    Return the speed of sound, given the air temperature.
+
+    The temperature units may be deg C, F, K or R ('C', 'F', 'K' or 'R').
+
+    The speed units may be 'kt', 'mph', 'km/h', 'm/s' and 'ft/s'.
+
+    If the units are not specified, the units in default_units.py are used.
+
+    Examples:
+
+    Determine speed of sound in knots at 15 deg (default temperature units):
+    >>> temp2speed_of_sound(15)
+    661.47882487301808
+
+    Determine speed of sound in mph at 120 deg F:
+    >>> temp2speed_of_sound(120, speed_units = 'mph', temp_units = 'F')
+    804.73500154991291
+    """
+
+    # function tested in tests/test_std_atm.py
+
+    temp = U.temp_conv(temp, from_units=temp_units, to_units="K")
+
+    speed_of_sound = M.sqrt((1.4 * Rd) * temp)
+    speed_of_sound = U.speed_conv(
+        speed_of_sound, from_units="m/s", to_units=speed_units
+    )
+
+    return speed_of_sound
+
+
+if __name__ == "__main__":
+
+    # run doctest to check the validity of the examples in the doc strings.
+
+    import doctest
+    import sys
+
+    doctest.testmod(sys.modules[__name__])
```

## skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/unit_conversion.py

```diff
@@ -1,709 +1,712 @@
-#!/usr/bin/python
-# -*- coding: utf-8 -*-
-
-# #############################################################################
-# Copyright (c) 2008, Kevin Horton
-# All rights reserved.
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-# *
-#     * Redistributions of source code must retain the above copyright
-#       notice, this list of conditions and the following disclaimer.
-#     * Redistributions in binary form must reproduce the above copyright
-#       notice, this list of conditions and the following disclaimer in the
-#       documentation and/or other materials provided with the distribution.
-#     * The name of Kevin Horton may not be used to endorse or promote products
-#       derived from this software without specific prior written permission.
-# *
-# THIS SOFTWARE IS PROVIDED BY KEVIN HORTON ``AS IS'' AND ANY EXPRESS OR
-# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
-# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
-# EVENT SHALL KEVIN HORTON BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
-# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
-# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
-# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
-# OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
-# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-# #############################################################################
-#
-# version 0.22, 25 Apr 2008
-#
-# Version History:
-# vers     date     Notes
-#  0.1   14 May 06  First release. Only has the unit conversions needed
-#                   for the std_atm module:
-#                   temperature, pressure, length and density.
-#
-# 0.11              Added speed conversion
-#
-# 0.20   06 May 07  Reworked to use default units from default_units module
-#
-# 0.21   24 Mar 08  Added fuel temperature to avgas_conv
-#
-# 0.22   25 Apr 08  Corrected error in unit validation in press_conv()
-# #############################################################################
-
-"""
-Convert between various units.
-"""
-
-try:
-    from default_units import *
-except ImportError:
-    default_area_units = "ft**2"
-    default_power_units = "hp"
-    default_speed_units = "kt"
-    default_temp_units = "C"
-    default_weight_units = "lb"
-    default_press_units = "in HG"
-    default_density_units = "lb/ft**3"
-    default_length_units = "ft"
-    default_alt_units = default_length_units
-    default_avgas_units = "lb"
-    default_vol_units = "ft**3"
-
-
-def area_conv(A, from_units=default_area_units, to_units=default_area_units):
-    """
-    Convert area values between ft**2, in**2, m**2, km**2, sm**2 and nm**2.
-
-    The incoming value is first converted to ft**2, then it is converted to
-    desired return value.
-
-
-    The units default to those specified in default_units.py
-
-    Examples:
-
-    Convert 1 ft**2 to inches**2, with ft**2 already defined as the default
-    units:
-    >>> area_conv(1, to_units = 'in**2')
-    144.0
-
-    Convert 288 square inches to square feet, with ft**2 already defined as the default
-    units:
-    >>> area_conv(288, from_units = 'in**2')
-    2.0
-
-    Convert 10 square metres to square inches:
-    >>> area_conv(1000, from_units = 'm**2', to_units = 'in**2')
-    1550003.1000061999
-    """
-
-    if from_units == "ft**2":
-        pass
-    elif from_units == "in**2":
-        A /= 144.0
-    elif from_units == "m**2":
-        A /= 0.3048**2
-    elif from_units == "km**2":
-        A /= 0.0003048**2
-    elif from_units == "sm**2":
-        A *= 5280.0**2
-    elif from_units == "nm**2":
-        A *= (1852 / 0.3048) ** 2
-    else:
-        raise ValueError(
-            'from_units must be "ft**2" or "in**2" or "m**2" or "km**2" or "sm**2" (square statute miles) or "nm**2" (square nautical miles).'
-        )
-
-    if to_units == "ft**2":
-        return A
-    elif to_units == "in**2":
-        return A * 144.0
-    elif to_units == "m**2":
-        return A * 0.3048**2
-    elif to_units == "km**2":
-        return A * 0.0003048**2
-    elif to_units == "sm**2":
-        return A / 5280.0**2
-    elif to_units == "nm**2":
-        return A * (0.3048 / 1852) ** 2
-    else:
-        raise ValueError(
-            'from_units must be "ft**2" or "in**2" or "m**2" or "km**2" or "sm**2" (square statute miles) or "nm**2" (square nautical miles).'
-        )
-
-
-def density_conv(D, from_units, to_units):
-    """
-    Convert density values between kg/m**3, slug/ft**3 and lb/ft**3.
-
-    The incoming value is first converted to kg/m**3, then it is converted
-    to desired return value.
-
-    There are no default units. Both the from_units and the to_units must
-    be specified.
-
-    Example:
-
-    Convert 1.225 kg per metre cubed to lb per foot cubed:
-    >>> density_conv(1.225, from_units = 'kg/m**3', to_units = 'lb/ft**3')
-    0.076474253491112101
-
-    """
-
-    if from_units == "kg/m**3":
-        pass
-    elif from_units == "slug/ft**3":
-        D *= 515.37882
-    elif from_units == "lb/ft**3":
-        D *= 16.018463
-    else:
-        raise ValueError(
-            'from_units must be one of "kg/m**3", "slug/ft**3" and "lb/ft**3".'
-        )
-
-    if to_units == "kg/m**3":
-        return D
-    elif to_units == "slug/ft**3":
-        return D / 515.37882
-    elif to_units == "lb/ft**3":
-        return D / 16.018463
-    else:
-        raise ValueError(
-            'to_units must be one of "kg/m**3", "slug/ft**3" and "lb/ft**3".'
-        )
-
-
-def force_conv(F, from_units=default_weight_units, to_units=default_weight_units):
-    """
-    Convert force values between lb and N.
-
-    The incoming value is first converted to N, then it is converted to the
-    desired return value.
-    """
-
-    if from_units == "N":
-        pass
-    elif from_units == "lb":
-        F *= 4.4482216
-    else:
-        raise ValueError('from_units must be one of "lb" or "N".')
-
-    if to_units == "N":
-        pass
-    elif to_units == "lb":
-        F /= 4.4482216
-    else:
-        raise ValueError('to_units must be one of "lb" or "N".')
-
-    return F
-
-
-def len_conv(L, from_units=default_length_units, to_units=default_length_units):
-    """
-    Convert length values between ft, in, m, km, sm and nm.
-
-    The incoming value is first converted to ft, then it is converted to
-    desired return value.
-
-    The units default to those specified in default_units.py
-
-    Examples:
-
-    Convert 5280 ft to statute miles, with feet already defined as the default
-    units:
-    >>> len_conv(5280, to_units = 'sm')
-    1.0
-
-    Convert 1 nautical mile to feet, with feet already defined as the default
-    units:
-    >>> len_conv(1, from_units = 'nm')
-    6076.1154855643044
-
-    Convert 1000 metres to kilometres:
-    >>> len_conv(1000, from_units = 'm', to_units = 'km')
-    0.99999999999999989
-    """
-
-    if from_units == "ft":
-        pass
-    elif from_units == "m":
-        L /= 0.3048
-    elif from_units == "km":
-        L /= 0.0003048
-    elif from_units == "sm":
-        L *= 5280.0
-    elif from_units == "nm":
-        L *= 1852 / 0.3048
-    elif from_units == "in":
-        L /= 12.0
-    else:
-        raise ValueError(
-            'from_units must be "ft", "in", "m", "km", "sm" (statute miles) or "nm" (nautical miles).'
-        )
-
-    if to_units == "ft":
-        return L
-    elif to_units == "m":
-        return L * 0.3048
-    elif to_units == "km":
-        return L * 0.0003048
-    elif to_units == "sm":
-        return L / 5280.0
-    elif to_units == "nm":
-        return (L * 0.3048) / 1852
-    elif to_units == "in":
-        return L * 12.0
-    else:
-        raise ValueError(
-            'from_units must be "ft", "in", "m", "km", "sm" (statute miles) or "nm" (nautical miles).'
-        )
-
-
-def power_conv(P, from_units=default_power_units, to_units=default_power_units):
-    """
-    Convert power values between horsepower, ft-lb/mn,  ft-lb/s, watts,
-    kilowatts, BTU/hr and BTU/mn.
-
-    The incoming value is first converted to hp, then it is converted to the
-    desired return value.
-    The units default to those specified in default_units.py
-
-    """
-
-    if from_units == "hp":
-        pass
-    elif from_units == "ft-lb/mn":
-        P /= 33000.0
-    elif from_units == "ft-lb/s":
-        P /= 550.0
-    elif from_units == "W":
-        P /= 745.69987
-    elif from_units == "kW":
-        P /= 0.74569987
-    # elif from_units == 'BTU/hr':
-    #     P /= 2544.4332
-    # elif from_units == 'BTU/mn':
-    #     P /= 42.407227
-    else:
-        raise ValueError(
-            'from_units must be "hp", "ft-lb/mn", "ft-lb/s", "W" (watts), "kW" (kilowatts), "BTU/hr", or "BTU/mn".'
-        )
-
-    if to_units == "hp":
-        return P
-    elif to_units == "ft-lb/mn":
-        return P * 33000.0
-    elif to_units == "ft-lb/s":
-        return P * 550.0
-    elif to_units == "W":
-        return P * 745.69987
-    elif to_units == "kW":
-        return P * 0.74569987
-    # elif to_units == 'BTU/hr':
-    #     return P * 2544.4332
-    # elif to_units == 'BTU/mn':
-    #     return P * 42.407227
-    else:
-        raise ValueError(
-            'to_units must be "hp", "ft-lb/mn", "ft-lb/s", "W" (watts), "kW" (kilowatts), "BTU/hr", or "BTU/mn".'
-        )
-
-
-def press_conv(P, from_units=default_press_units, to_units=default_press_units):
-    """
-    Convert pressure values between inches of HG, mm of HG, psi, lb/ft^2,
-    hpa and mb.
-
-    The incoming value is first converted to Pa, then it is converted to
-    desired return value.
-    The units default to those specified in default_units.py
-
-
-    Examples:
-
-    Convert 1013.25 hpa to default pressure units:
-    >>> press_conv(1013.25, from_units = 'hpa')
-    29.921331923765198
-
-    Convert 29.9213 default pressure units to mm of HG:
-    >>> press_conv(29.9213, to_units = 'mm HG')
-    760.00128931459176
-
-    Convert 2116.22 lb per sq. ft to lb per sq. inch:
-    >>> press_conv(2116.22, from_units = 'psf', to_units = 'psi')
-    14.695973160069311
-    """
-
-    if from_units == "in HG":
-        P *= 3386.38  # from NASA Reference Publication 1046
-    elif from_units == "mm HG":
-        P *= 133.322  # derived from NASA Reference Publication 1046 value
-    elif from_units == "psi":
-        P *= 6894.757  # derived from NASA Reference Publication 1046 value
-    elif from_units == "psf" or from_units == "lb/ft**2":
-
-        P *= 47.88026  # from NASA Reference Publication 1046
-    elif from_units == "hpa" or from_units == "mb":
-        P *= 100.0
-    elif from_units == "pa":
-        pass
-    else:
-        raise ValueError(
-            'from_units must be "in HG", "mm HG", "psi", "psf" (lb per sq. ft), "hpa", "mb" or "pa".'
-        )
-
-    if to_units == "in HG":
-        return P / 3386.38
-    elif to_units == "mm HG":
-        return P / 133.322
-    elif to_units == "psi":
-        return P / 6894.757
-    elif to_units == "psf" or to_units == "lb/ft**2":
-        return P / 47.88026
-    elif to_units == "hpa" or to_units == "mb":
-        return P / 100.0
-    elif to_units == "pa":
-        return P
-    else:
-        raise ValueError(
-            'to_units must be "in HG", "mm HG", "psi", "psf" (lb per sq. ft), "pa", "hpa" or "mb".'
-        )
-
-
-def speed_conv(S, from_units=default_speed_units, to_units=default_speed_units):
-    """
-    Convert speed values between kt, mph, km/h, m/s and ft/s.
-
-    The incoming value is first converted to kt, then it is converted to
-    desired return value.
-    The units default to those specified in default_units.py
-
-
-    Example:
-
-    Convert 230 mph  to kt:
-    >>> speed_conv(230, from_units = 'mph', to_units = 'kt')
-    199.86453563714903
-
-    """
-
-    if from_units == "kt":
-        pass
-    elif from_units == "mph":
-        S *= len_conv(1, from_units="sm", to_units="nm")
-    elif from_units == "km/h":
-        S *= len_conv(1, from_units="km", to_units="nm")
-    elif from_units == "m/s":
-        S *= len_conv(1, from_units="m", to_units="nm") * 3600.0
-    elif from_units == "ft/s":
-        S *= len_conv(1, from_units=default_length_units, to_units="nm") * 3600.0
-    else:
-        raise ValueError(
-            'from_units must be one of "kt", "mph", "km/h", "m/s" and "ft/s".'
-        )
-
-    if to_units == "kt":
-        return S
-    elif to_units == "mph":
-        S *= len_conv(1, from_units="nm", to_units="sm")
-        return S
-    elif to_units == "km/h":
-        S *= len_conv(1, from_units="nm", to_units="km")
-        return S
-    elif to_units == "m/s":
-        S *= len_conv(1, from_units="nm", to_units="m")
-        return S / 3600.0
-    elif to_units == "ft/s":
-        S *= len_conv(1, from_units="nm", to_units=default_length_units)
-        return S / 3600.0
-    else:
-        raise ValueError(
-            'to_units must be one of "kt", "mph", "km/h", "m/s" and "ft/s".'
-        )
-
-
-def temp_conv(T, from_units=default_temp_units, to_units=default_temp_units):
-    """
-    Convert absolute temperature values between deg C, F, K and R.
-
-    This function should not be used for relative temperature conversions,
-    i.e. temperature differences.
-
-    The incoming value is first converted to deg K, then it is converted to
-    desired return value.
-    The units default to those specified in default_units.py
-
-
-    Examples:
-
-    Convert 32 deg F to deg C, with deg C as the default units:
-    >>> temp_conv(32, from_units = 'F')
-    0.0
-
-    Convert 100 deg C to deg F, with deg C as the default units:
-    >>> temp_conv(100, to_units = 'F')
-    212.0
-
-    Convert 59 deg F to deg K
-    >>> temp_conv(59, from_units = 'F', to_units = 'K')
-    288.14999999999998
-    """
-
-    if from_units == "C":
-        T += 273.15
-    elif from_units == "F":
-        T = ((T - 32) * 5.0) / 9.0 + 273.15
-    elif from_units == "K":
-        pass
-    elif from_units == "R":
-        T *= 5.0 / 9.0
-    else:
-        raise ValueError('from_units must be one of "C", "F", "K" or "R".')
-
-    if to_units == "C":
-        return T - 273.15
-    elif to_units == "F":
-        return (T - 273.15) * 1.8 + 32
-    elif to_units == "K":
-        return T
-    elif to_units == "R":
-        return T * 1.8
-    else:
-        raise ValueError('to_units must be one of "C", "F", "K" or "R".')
-
-
-def vol_conv(V, from_units=default_vol_units, to_units=default_vol_units):
-    """
-    Convert volume values between USG, ImpGal (Imperial gallons), l (litres), ft**3, in**3, m**3, km**3, sm**3 and nm**3.
-
-    The incoming value is first converted to ft**3, then it is converted to
-    desired return value.
-
-
-    The units default to those specified in default_units.py
-
-    Examples:
-
-    Convert 1 cubic foot to US gallons, with cubic feet already defined as
-    the default units:
-    >>> vol_conv(1, to_units = 'USG')
-    7.4805194804946105
-
-    Convert 1 Imperial gallon to cubic feet, with cubic feet already defined
-    as the default units:
-    >>> vol_conv(1, from_units = 'ImpGal')
-    0.16054365323600001
-
-    Convert 10 US gallon to litres:
-    >>> vol_conv(10, from_units = 'USG', to_units = 'l')
-    37.854117840125852
-    """
-
-    if from_units == "ft**3":
-        pass
-    elif from_units == "in**3":
-        V /= 12.0**3
-    elif from_units == "m**3":
-        V /= 0.3048**3
-    elif from_units == "km**3":
-        V /= 0.0003048**3
-    elif from_units == "sm**3":
-        V *= 5280.0**3
-    elif from_units == "nm**3":
-        V *= (1852 / 0.3048) ** 3
-    elif from_units == "USG":
-        V *= 0.133680555556
-    elif from_units == "ImpGal":
-        V *= 0.160543653236
-    elif from_units == "l":
-        V /= 3.048**3
-    else:
-        raise ValueError(
-            'from_units must be "ft**3", "in**3", "USG", "ImpGal", "l", "m**3", "km**3", "sm**3" (cubic statute miles) or "nm**3" (cubic nautical miles).'
-        )
-
-    if to_units == "ft**3":
-        return V
-    elif to_units == "in**3":
-        return V * 12.0**3
-    elif to_units == "m**3":
-        return V * 0.3048**3
-    elif to_units == "km**3":
-        return V * 0.0003048**3
-    elif to_units == "sm**3":
-        return V / 5280.0**3
-    elif to_units == "nm**3":
-        return V * (0.3048 / 1852) ** 3
-    elif to_units == "USG":
-        return V / 0.133680555556
-    elif to_units == "ImpGal":
-        return V / 0.160543653236
-    elif to_units == "l":
-        return V * 3.048**3
-    else:
-        raise ValueError(
-            'to_units must be "ft**3", "in**3", "USG", "ImpGal", "l", "m**3", "km**3", "sm**3" (cubic statute miles) or "nm**3" (cubic nautical miles).'
-        )
-
-
-def wt_conv(W, from_units=default_weight_units, to_units=default_weight_units):
-    """
-    Convert weight values between lb and kg.
-
-    Purists will yell that lb is a unit of weight, and kg is a unit of mass.
-    Get over it.
-
-    The incoming value is first converted to kg, then it is converted to the
-    desired return value.
-
-    The units default to those specified in default_units.py
-
-
-    """
-
-    if from_units == "kg":
-        pass
-    elif from_units == "lb":
-        W *= 0.453592
-    else:
-        raise ValueError('from_units must be one of "lb" or "kg".')
-
-    if to_units == "kg":
-        pass
-    elif to_units == "lb":
-        W *= 2.204622622
-    else:
-        raise ValueError('to_units must be one of "lb" or "kg".')
-
-    return W
-
-
-def avgas_conv(
-    AG,
-    from_units=default_avgas_units,
-    to_units=default_avgas_units,
-    temp=15,
-    temp_units="C",
-    grade="nominal",
-):
-    """
-    Convert aviation gasoline between units of lb, US Gallon (USG),
-    Imperial Gallon (Imp Gal), litres (l) and kg, assuming nominal
-    density for aviation gasoline of 6.01 lb per USG.
-
-    The units default to those specified in default_units.py
-
-    Note: it was difficult to find authoritative values for aviation gasoline
-    density.  Conventional wisdom is that aviation gasoline has a density of
-    6 lb/USG.  The Canada Flight Supplement provides densities of:
-    temp      density     density    density
-    (deg C)   (lb/USG)  (lb/ImpGal)  (lb/l)
-    -40         6.41       7.68       1.69
-    -20         6.26       7.50       1.65
-      0         6.12       7.33       1.62
-     15         6.01       7.20       1.59
-     30         5.90       7.07       1.56
-
-    However, the Canada Flight Supplement does not provide a source for its
-    density data.  And, the values for the different volume units are not
-    completly consistent, as they don't vary by exactly the correct factor.
-    For example, if the density at 15 deg C is 6.01 lb/USG, we would expect
-    the density in lb/ImpGal to be 7.22, (given that 1 ImpGal = 1.201 USG)
-    yet the Canada Flight Supplement has 7.20.
-
-    The only authoritative source for aviation gasoline density that was
-    found on the web was the \"Air BP Handbook of Products\" on the British
-    Petroleum (BP) web site:
-
-    <http://www.bp.com/liveassets/bp_internet/aviation/air_bp/STAGING/local_assets/downloads_pdfs/a/air_bp_products_handbook_04004_1.pdf>
-
-    It provides the following density data valid at 15 deg C (the BP document
-    only provides density in kg/m**3 - the density in lb/USG were calculated
-    by Kevin Horton):
-    Avgas    density     density
-    Type    (kg/m**3)    (lb/USG)
-    80       690          5.76
-    100      695          5.80
-    100LL    715          5.97
-
-    The available aviation gasoline specifications do not appear to define an
-    allowable density range.  They do define allowable ranges for various
-    parametres of the distillation process - the density of the final product
-    will vary depending on where in the allowable range the refinery is run.
-    Thus there will be some variation in density from refinery to refinery.
-
-    This function uses the 15 deg C density values provided by BP, with the
-    variation with temperature provided in the Canada Flight Supplement.
-
-    The grade may be specified as \"80\", \"100\" or \"100LL\".  It defaults to
-    \"100LL\" if it is not specified.
-
-    The temperature defaults to 15 deg C if it is not specified.
-    """
-
-    lb_per_USG_15_nom = (
-        6.01  # nominal density at 15 deg C from Canada Flight Supplement
-    )
-    slope = (
-        -0.007256
-    )  # change in density per deg C based on data from Canada Flight Supplement
-
-    lb_per_USG = lb_per_USG_15_nom * (
-        1
-        + (slope * (temp_conv(temp, from_units=temp_units, to_units="C") - 15))
-        / lb_per_USG_15_nom
-    )  # density corrected for temperature, using nominal density value
-
-    if grade == "nominal":
-        grade_density = lb_per_USG_15_nom
-    elif grade == "100LL":
-        grade_density = 5.967
-    elif str(grade) == "100":
-        grade_density = 5.801
-    elif str(grade) == "80":
-        grade_density = 5.7583
-    else:
-        raise ValueError(
-            'grade must be one of "nominal", "80", "100" or "100LL", with a default of "100LL"'
-        )
-
-    # Correct the density if the grade is other than nominal.
-    # If the grade actually is nominal, we are multiplying by 1 / 1
-
-    lb_per_USG *= grade_density / lb_per_USG_15_nom
-
-    if from_units == "lb":
-        pass
-    elif from_units == "USG":
-        AG *= lb_per_USG
-    elif from_units == "ImpGal":
-        AG *= vol_conv(lb_per_USG, from_units="ImpGal", to_units="USG")
-    elif from_units == "kg":
-        AG = wt_conv(AG, from_units="kg")
-    elif from_units == "l":
-        AG *= vol_conv(lb_per_USG, from_units="l", to_units="USG")
-    else:
-        raise ValueError(
-            'from_units must be one of "lb", "USG", "Imp Gal", "l", or "kg".'
-        )
-
-    if to_units == "lb":
-        pass
-    elif to_units == "USG":
-        AG /= lb_per_USG
-    elif to_units == "ImpGal":
-        AG /= vol_conv(lb_per_USG, from_units="ImpGal", to_units="USG")
-    elif to_units == "kg":
-        AG = wt_conv(AG, to_units="kg")
-    elif to_units == "l":
-        AG /= vol_conv(lb_per_USG, from_units="l", to_units="USG")
-    else:
-        raise ValueError(
-            'from_units must be one of "lb", "USG", "Imp Gal", "l", or "kg".'
-        )
-
-    return AG
-
-
-if __name__ == "__main__":
-
-    # run doctest to check the validity of the examples in the doc strings.
-
-    import doctest
-    import sys
-
-    doctest.testmod(sys.modules[__name__])
+#!/usr/bin/python
+# -*- coding: utf-8 -*-
+
+# #############################################################################
+# Copyright (c) 2008, Kevin Horton
+# All rights reserved.
+# Redistribution and use in source and binary forms, with or without
+# modification, are permitted provided that the following conditions are met:
+# *
+#     * Redistributions of source code must retain the above copyright
+#       notice, this list of conditions and the following disclaimer.
+#     * Redistributions in binary form must reproduce the above copyright
+#       notice, this list of conditions and the following disclaimer in the
+#       documentation and/or other materials provided with the distribution.
+#     * The name of Kevin Horton may not be used to endorse or promote products
+#       derived from this software without specific prior written permission.
+# *
+# THIS SOFTWARE IS PROVIDED BY KEVIN HORTON ``AS IS'' AND ANY EXPRESS OR
+# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
+# EVENT SHALL KEVIN HORTON BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
+# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+# OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
+# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+# #############################################################################
+#
+# version 0.22, 25 Apr 2008
+#
+# Version History:
+# vers     date     Notes
+#  0.1   14 May 06  First release. Only has the unit conversions needed
+#                   for the std_atm module:
+#                   temperature, pressure, length and density.
+#
+# 0.11              Added speed conversion
+#
+# 0.20   06 May 07  Reworked to use default units from default_units module
+#
+# 0.21   24 Mar 08  Added fuel temperature to avgas_conv
+#
+# 0.22   25 Apr 08  Corrected error in unit validation in press_conv()
+# #############################################################################
+
+import numpy as np
+
+"""
+Convert between various units.
+"""
+
+try:
+    from default_units import *
+except ImportError:
+    default_area_units = "ft**2"
+    default_power_units = "hp"
+    default_speed_units = "kt"
+    default_temp_units = "C"
+    default_weight_units = "lb"
+    default_press_units = "in HG"
+    default_density_units = "lb/ft**3"
+    default_length_units = "ft"
+    default_alt_units = default_length_units
+    default_avgas_units = "lb"
+    default_vol_units = "ft**3"
+
+
+def area_conv(A, from_units=default_area_units, to_units=default_area_units):
+    """
+    Convert area values between ft**2, in**2, m**2, km**2, sm**2 and nm**2.
+
+    The incoming value is first converted to ft**2, then it is converted to
+    desired return value.
+
+
+    The units default to those specified in default_units.py
+
+    Examples:
+
+    Convert 1 ft**2 to inches**2, with ft**2 already defined as the default
+    units:
+    >>> area_conv(1, to_units = 'in**2')
+    144.0
+
+    Convert 288 square inches to square feet, with ft**2 already defined as the default
+    units:
+    >>> area_conv(288, from_units = 'in**2')
+    2.0
+
+    Convert 10 square metres to square inches:
+    >>> area_conv(1000, from_units = 'm**2', to_units = 'in**2')
+    1550003.1000061999
+    """
+
+    if from_units == "ft**2":
+        pass
+    elif from_units == "in**2":
+        A /= 144.0
+    elif from_units == "m**2":
+        A /= 0.3048**2
+    elif from_units == "km**2":
+        A /= 0.0003048**2
+    elif from_units == "sm**2":
+        A *= 5280.0**2
+    elif from_units == "nm**2":
+        A *= (1852 / 0.3048) ** 2
+    else:
+        raise ValueError(
+            'from_units must be "ft**2" or "in**2" or "m**2" or "km**2" or "sm**2" (square statute miles) or "nm**2" (square nautical miles).'
+        )
+
+    if to_units == "ft**2":
+        return A
+    elif to_units == "in**2":
+        return A * 144.0
+    elif to_units == "m**2":
+        return A * 0.3048**2
+    elif to_units == "km**2":
+        return A * 0.0003048**2
+    elif to_units == "sm**2":
+        return A / 5280.0**2
+    elif to_units == "nm**2":
+        return A * (0.3048 / 1852) ** 2
+    else:
+        raise ValueError(
+            'from_units must be "ft**2" or "in**2" or "m**2" or "km**2" or "sm**2" (square statute miles) or "nm**2" (square nautical miles).'
+        )
+
+
+def density_conv(D, from_units, to_units):
+    """
+    Convert density values between kg/m**3, slug/ft**3 and lb/ft**3.
+
+    The incoming value is first converted to kg/m**3, then it is converted
+    to desired return value.
+
+    There are no default units. Both the from_units and the to_units must
+    be specified.
+
+    Example:
+
+    Convert 1.225 kg per metre cubed to lb per foot cubed:
+    >>> density_conv(1.225, from_units = 'kg/m**3', to_units = 'lb/ft**3')
+    0.076474253491112101
+
+    """
+
+    if from_units == "kg/m**3":
+        pass
+    elif from_units == "slug/ft**3":
+        D *= 515.37882
+    elif from_units == "lb/ft**3":
+        D *= 16.018463
+    else:
+        raise ValueError(
+            'from_units must be one of "kg/m**3", "slug/ft**3" and "lb/ft**3".'
+        )
+
+    if to_units == "kg/m**3":
+        return D
+    elif to_units == "slug/ft**3":
+        return D / 515.37882
+    elif to_units == "lb/ft**3":
+        return D / 16.018463
+    else:
+        raise ValueError(
+            'to_units must be one of "kg/m**3", "slug/ft**3" and "lb/ft**3".'
+        )
+
+
+def force_conv(F, from_units=default_weight_units, to_units=default_weight_units):
+    """
+    Convert force values between lb and N.
+
+    The incoming value is first converted to N, then it is converted to the
+    desired return value.
+    """
+
+    if from_units == "N":
+        pass
+    elif from_units == "lb":
+        F *= 4.4482216
+    else:
+        raise ValueError('from_units must be one of "lb" or "N".')
+
+    if to_units == "N":
+        pass
+    elif to_units == "lb":
+        F /= 4.4482216
+    else:
+        raise ValueError('to_units must be one of "lb" or "N".')
+
+    return F
+
+
+def len_conv(L, from_units=default_length_units, to_units=default_length_units):
+    """
+    Convert length values between ft, in, m, km, sm and nm.
+
+    The incoming value is first converted to ft, then it is converted to
+    desired return value.
+
+    The units default to those specified in default_units.py
+
+    Examples:
+
+    Convert 5280 ft to statute miles, with feet already defined as the default
+    units:
+    >>> len_conv(5280, to_units = 'sm')
+    1.0
+
+    Convert 1 nautical mile to feet, with feet already defined as the default
+    units:
+    >>> len_conv(1, from_units = 'nm')
+    6076.1154855643044
+
+    Convert 1000 metres to kilometres:
+    >>> len_conv(1000, from_units = 'm', to_units = 'km')
+    0.99999999999999989
+    """
+
+    if from_units == "ft":
+        pass
+    elif from_units == "m":
+        L /= 0.3048
+    elif from_units == "km":
+        L /= 0.0003048
+    elif from_units == "sm":
+        L *= 5280.0
+    elif from_units == "nm":
+        L *= 1852 / 0.3048
+    elif from_units == "in":
+        L /= 12.0
+    else:
+        raise ValueError(
+            'from_units must be "ft", "in", "m", "km", "sm" (statute miles) or "nm" (nautical miles).'
+        )
+
+    if to_units == "ft":
+        return L
+    elif to_units == "m":
+        return L * 0.3048
+    elif to_units == "km":
+        return L * 0.0003048
+    elif to_units == "sm":
+        return L / 5280.0
+    elif to_units == "nm":
+        return (L * 0.3048) / 1852
+    elif to_units == "in":
+        return L * 12.0
+    else:
+        raise ValueError(
+            'from_units must be "ft", "in", "m", "km", "sm" (statute miles) or "nm" (nautical miles).'
+        )
+
+
+def power_conv(P, from_units=default_power_units, to_units=default_power_units):
+    """
+    Convert power values between horsepower, ft-lb/mn,  ft-lb/s, watts,
+    kilowatts, BTU/hr and BTU/mn.
+
+    The incoming value is first converted to hp, then it is converted to the
+    desired return value.
+    The units default to those specified in default_units.py
+
+    """
+
+    if from_units == "hp":
+        pass
+    elif from_units == "ft-lb/mn":
+        P /= 33000.0
+    elif from_units == "ft-lb/s":
+        P /= 550.0
+    elif from_units == "W":
+        P /= 745.69987
+    elif from_units == "kW":
+        P /= 0.74569987
+    # elif from_units == 'BTU/hr':
+    #     P /= 2544.4332
+    # elif from_units == 'BTU/mn':
+    #     P /= 42.407227
+    else:
+        raise ValueError(
+            'from_units must be "hp", "ft-lb/mn", "ft-lb/s", "W" (watts), "kW" (kilowatts), "BTU/hr", or "BTU/mn".'
+        )
+
+    if to_units == "hp":
+        return P
+    elif to_units == "ft-lb/mn":
+        return P * 33000.0
+    elif to_units == "ft-lb/s":
+        return P * 550.0
+    elif to_units == "W":
+        return P * 745.69987
+    elif to_units == "kW":
+        return P * 0.74569987
+    # elif to_units == 'BTU/hr':
+    #     return P * 2544.4332
+    # elif to_units == 'BTU/mn':
+    #     return P * 42.407227
+    else:
+        raise ValueError(
+            'to_units must be "hp", "ft-lb/mn", "ft-lb/s", "W" (watts), "kW" (kilowatts), "BTU/hr", or "BTU/mn".'
+        )
+
+
+@np.vectorize
+def press_conv(P, from_units=default_press_units, to_units=default_press_units):
+    """
+    Convert pressure values between inches of HG, mm of HG, psi, lb/ft^2,
+    hpa and mb.
+
+    The incoming value is first converted to Pa, then it is converted to
+    desired return value.
+    The units default to those specified in default_units.py
+
+
+    Examples:
+
+    Convert 1013.25 hpa to default pressure units:
+    >>> press_conv(1013.25, from_units = 'hpa')
+    29.921331923765198
+
+    Convert 29.9213 default pressure units to mm of HG:
+    >>> press_conv(29.9213, to_units = 'mm HG')
+    760.00128931459176
+
+    Convert 2116.22 lb per sq. ft to lb per sq. inch:
+    >>> press_conv(2116.22, from_units = 'psf', to_units = 'psi')
+    14.695973160069311
+    """
+
+    if from_units == "in HG":
+        P *= 3386.38  # from NASA Reference Publication 1046
+    elif from_units == "mm HG":
+        P *= 133.322  # derived from NASA Reference Publication 1046 value
+    elif from_units == "psi":
+        P *= 6894.757  # derived from NASA Reference Publication 1046 value
+    elif from_units == "psf" or from_units == "lb/ft**2":
+
+        P *= 47.88026  # from NASA Reference Publication 1046
+    elif from_units == "hpa" or from_units == "mb":
+        P *= 100.0
+    elif from_units == "pa":
+        pass
+    else:
+        raise ValueError(
+            'from_units must be "in HG", "mm HG", "psi", "psf" (lb per sq. ft), "hpa", "mb" or "pa".'
+        )
+
+    if to_units == "in HG":
+        return P / 3386.38
+    elif to_units == "mm HG":
+        return P / 133.322
+    elif to_units == "psi":
+        return P / 6894.757
+    elif to_units == "psf" or to_units == "lb/ft**2":
+        return P / 47.88026
+    elif to_units == "hpa" or to_units == "mb":
+        return P / 100.0
+    elif to_units == "pa":
+        return P
+    else:
+        raise ValueError(
+            'to_units must be "in HG", "mm HG", "psi", "psf" (lb per sq. ft), "pa", "hpa" or "mb".'
+        )
+
+
+def speed_conv(S, from_units=default_speed_units, to_units=default_speed_units):
+    """
+    Convert speed values between kt, mph, km/h, m/s and ft/s.
+
+    The incoming value is first converted to kt, then it is converted to
+    desired return value.
+    The units default to those specified in default_units.py
+
+
+    Example:
+
+    Convert 230 mph  to kt:
+    >>> speed_conv(230, from_units = 'mph', to_units = 'kt')
+    199.86453563714903
+
+    """
+
+    if from_units == "kt":
+        pass
+    elif from_units == "mph":
+        S *= len_conv(1, from_units="sm", to_units="nm")
+    elif from_units == "km/h":
+        S *= len_conv(1, from_units="km", to_units="nm")
+    elif from_units == "m/s":
+        S *= len_conv(1, from_units="m", to_units="nm") * 3600.0
+    elif from_units == "ft/s":
+        S *= len_conv(1, from_units=default_length_units, to_units="nm") * 3600.0
+    else:
+        raise ValueError(
+            'from_units must be one of "kt", "mph", "km/h", "m/s" and "ft/s".'
+        )
+
+    if to_units == "kt":
+        return S
+    elif to_units == "mph":
+        S *= len_conv(1, from_units="nm", to_units="sm")
+        return S
+    elif to_units == "km/h":
+        S *= len_conv(1, from_units="nm", to_units="km")
+        return S
+    elif to_units == "m/s":
+        S *= len_conv(1, from_units="nm", to_units="m")
+        return S / 3600.0
+    elif to_units == "ft/s":
+        S *= len_conv(1, from_units="nm", to_units=default_length_units)
+        return S / 3600.0
+    else:
+        raise ValueError(
+            'to_units must be one of "kt", "mph", "km/h", "m/s" and "ft/s".'
+        )
+
+
+def temp_conv(T, from_units=default_temp_units, to_units=default_temp_units):
+    """
+    Convert absolute temperature values between deg C, F, K and R.
+
+    This function should not be used for relative temperature conversions,
+    i.e. temperature differences.
+
+    The incoming value is first converted to deg K, then it is converted to
+    desired return value.
+    The units default to those specified in default_units.py
+
+
+    Examples:
+
+    Convert 32 deg F to deg C, with deg C as the default units:
+    >>> temp_conv(32, from_units = 'F')
+    0.0
+
+    Convert 100 deg C to deg F, with deg C as the default units:
+    >>> temp_conv(100, to_units = 'F')
+    212.0
+
+    Convert 59 deg F to deg K
+    >>> temp_conv(59, from_units = 'F', to_units = 'K')
+    288.14999999999998
+    """
+
+    if from_units == "C":
+        T += 273.15
+    elif from_units == "F":
+        T = ((T - 32) * 5.0) / 9.0 + 273.15
+    elif from_units == "K":
+        pass
+    elif from_units == "R":
+        T *= 5.0 / 9.0
+    else:
+        raise ValueError('from_units must be one of "C", "F", "K" or "R".')
+
+    if to_units == "C":
+        return T - 273.15
+    elif to_units == "F":
+        return (T - 273.15) * 1.8 + 32
+    elif to_units == "K":
+        return T
+    elif to_units == "R":
+        return T * 1.8
+    else:
+        raise ValueError('to_units must be one of "C", "F", "K" or "R".')
+
+
+def vol_conv(V, from_units=default_vol_units, to_units=default_vol_units):
+    """
+    Convert volume values between USG, ImpGal (Imperial gallons), l (litres), ft**3, in**3, m**3, km**3, sm**3 and nm**3.
+
+    The incoming value is first converted to ft**3, then it is converted to
+    desired return value.
+
+
+    The units default to those specified in default_units.py
+
+    Examples:
+
+    Convert 1 cubic foot to US gallons, with cubic feet already defined as
+    the default units:
+    >>> vol_conv(1, to_units = 'USG')
+    7.4805194804946105
+
+    Convert 1 Imperial gallon to cubic feet, with cubic feet already defined
+    as the default units:
+    >>> vol_conv(1, from_units = 'ImpGal')
+    0.16054365323600001
+
+    Convert 10 US gallon to litres:
+    >>> vol_conv(10, from_units = 'USG', to_units = 'l')
+    37.854117840125852
+    """
+
+    if from_units == "ft**3":
+        pass
+    elif from_units == "in**3":
+        V /= 12.0**3
+    elif from_units == "m**3":
+        V /= 0.3048**3
+    elif from_units == "km**3":
+        V /= 0.0003048**3
+    elif from_units == "sm**3":
+        V *= 5280.0**3
+    elif from_units == "nm**3":
+        V *= (1852 / 0.3048) ** 3
+    elif from_units == "USG":
+        V *= 0.133680555556
+    elif from_units == "ImpGal":
+        V *= 0.160543653236
+    elif from_units == "l":
+        V /= 3.048**3
+    else:
+        raise ValueError(
+            'from_units must be "ft**3", "in**3", "USG", "ImpGal", "l", "m**3", "km**3", "sm**3" (cubic statute miles) or "nm**3" (cubic nautical miles).'
+        )
+
+    if to_units == "ft**3":
+        return V
+    elif to_units == "in**3":
+        return V * 12.0**3
+    elif to_units == "m**3":
+        return V * 0.3048**3
+    elif to_units == "km**3":
+        return V * 0.0003048**3
+    elif to_units == "sm**3":
+        return V / 5280.0**3
+    elif to_units == "nm**3":
+        return V * (0.3048 / 1852) ** 3
+    elif to_units == "USG":
+        return V / 0.133680555556
+    elif to_units == "ImpGal":
+        return V / 0.160543653236
+    elif to_units == "l":
+        return V * 3.048**3
+    else:
+        raise ValueError(
+            'to_units must be "ft**3", "in**3", "USG", "ImpGal", "l", "m**3", "km**3", "sm**3" (cubic statute miles) or "nm**3" (cubic nautical miles).'
+        )
+
+
+def wt_conv(W, from_units=default_weight_units, to_units=default_weight_units):
+    """
+    Convert weight values between lb and kg.
+
+    Purists will yell that lb is a unit of weight, and kg is a unit of mass.
+    Get over it.
+
+    The incoming value is first converted to kg, then it is converted to the
+    desired return value.
+
+    The units default to those specified in default_units.py
+
+
+    """
+
+    if from_units == "kg":
+        pass
+    elif from_units == "lb":
+        W *= 0.453592
+    else:
+        raise ValueError('from_units must be one of "lb" or "kg".')
+
+    if to_units == "kg":
+        pass
+    elif to_units == "lb":
+        W *= 2.204622622
+    else:
+        raise ValueError('to_units must be one of "lb" or "kg".')
+
+    return W
+
+
+def avgas_conv(
+    AG,
+    from_units=default_avgas_units,
+    to_units=default_avgas_units,
+    temp=15,
+    temp_units="C",
+    grade="nominal",
+):
+    """
+    Convert aviation gasoline between units of lb, US Gallon (USG),
+    Imperial Gallon (Imp Gal), litres (l) and kg, assuming nominal
+    density for aviation gasoline of 6.01 lb per USG.
+
+    The units default to those specified in default_units.py
+
+    Note: it was difficult to find authoritative values for aviation gasoline
+    density.  Conventional wisdom is that aviation gasoline has a density of
+    6 lb/USG.  The Canada Flight Supplement provides densities of:
+    temp      density     density    density
+    (deg C)   (lb/USG)  (lb/ImpGal)  (lb/l)
+    -40         6.41       7.68       1.69
+    -20         6.26       7.50       1.65
+      0         6.12       7.33       1.62
+     15         6.01       7.20       1.59
+     30         5.90       7.07       1.56
+
+    However, the Canada Flight Supplement does not provide a source for its
+    density data.  And, the values for the different volume units are not
+    completly consistent, as they don't vary by exactly the correct factor.
+    For example, if the density at 15 deg C is 6.01 lb/USG, we would expect
+    the density in lb/ImpGal to be 7.22, (given that 1 ImpGal = 1.201 USG)
+    yet the Canada Flight Supplement has 7.20.
+
+    The only authoritative source for aviation gasoline density that was
+    found on the web was the \"Air BP Handbook of Products\" on the British
+    Petroleum (BP) web site:
+
+    <http://www.bp.com/liveassets/bp_internet/aviation/air_bp/STAGING/local_assets/downloads_pdfs/a/air_bp_products_handbook_04004_1.pdf>
+
+    It provides the following density data valid at 15 deg C (the BP document
+    only provides density in kg/m**3 - the density in lb/USG were calculated
+    by Kevin Horton):
+    Avgas    density     density
+    Type    (kg/m**3)    (lb/USG)
+    80       690          5.76
+    100      695          5.80
+    100LL    715          5.97
+
+    The available aviation gasoline specifications do not appear to define an
+    allowable density range.  They do define allowable ranges for various
+    parametres of the distillation process - the density of the final product
+    will vary depending on where in the allowable range the refinery is run.
+    Thus there will be some variation in density from refinery to refinery.
+
+    This function uses the 15 deg C density values provided by BP, with the
+    variation with temperature provided in the Canada Flight Supplement.
+
+    The grade may be specified as \"80\", \"100\" or \"100LL\".  It defaults to
+    \"100LL\" if it is not specified.
+
+    The temperature defaults to 15 deg C if it is not specified.
+    """
+
+    lb_per_USG_15_nom = (
+        6.01  # nominal density at 15 deg C from Canada Flight Supplement
+    )
+    slope = (
+        -0.007256
+    )  # change in density per deg C based on data from Canada Flight Supplement
+
+    lb_per_USG = lb_per_USG_15_nom * (
+        1
+        + (slope * (temp_conv(temp, from_units=temp_units, to_units="C") - 15))
+        / lb_per_USG_15_nom
+    )  # density corrected for temperature, using nominal density value
+
+    if grade == "nominal":
+        grade_density = lb_per_USG_15_nom
+    elif grade == "100LL":
+        grade_density = 5.967
+    elif str(grade) == "100":
+        grade_density = 5.801
+    elif str(grade) == "80":
+        grade_density = 5.7583
+    else:
+        raise ValueError(
+            'grade must be one of "nominal", "80", "100" or "100LL", with a default of "100LL"'
+        )
+
+    # Correct the density if the grade is other than nominal.
+    # If the grade actually is nominal, we are multiplying by 1 / 1
+
+    lb_per_USG *= grade_density / lb_per_USG_15_nom
+
+    if from_units == "lb":
+        pass
+    elif from_units == "USG":
+        AG *= lb_per_USG
+    elif from_units == "ImpGal":
+        AG *= vol_conv(lb_per_USG, from_units="ImpGal", to_units="USG")
+    elif from_units == "kg":
+        AG = wt_conv(AG, from_units="kg")
+    elif from_units == "l":
+        AG *= vol_conv(lb_per_USG, from_units="l", to_units="USG")
+    else:
+        raise ValueError(
+            'from_units must be one of "lb", "USG", "Imp Gal", "l", or "kg".'
+        )
+
+    if to_units == "lb":
+        pass
+    elif to_units == "USG":
+        AG /= lb_per_USG
+    elif to_units == "ImpGal":
+        AG /= vol_conv(lb_per_USG, from_units="ImpGal", to_units="USG")
+    elif to_units == "kg":
+        AG = wt_conv(AG, to_units="kg")
+    elif to_units == "l":
+        AG /= vol_conv(lb_per_USG, from_units="l", to_units="USG")
+    else:
+        raise ValueError(
+            'from_units must be one of "lb", "USG", "Imp Gal", "l", or "kg".'
+        )
+
+    return AG
+
+
+if __name__ == "__main__":
+
+    # run doctest to check the validity of the examples in the doc strings.
+
+    import doctest
+    import sys
+
+    doctest.testmod(sys.modules[__name__])
```

## skdecide/hub/domain/gym/__init__.py

 * *Ordering differences only*

```diff
@@ -1,17 +1,17 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .gym import (
-    AsGymnasiumEnv,
-    AsLegacyGymV21Env,
-    CostDeterministicGymDomain,
-    DeterministicGymDomain,
-    DeterministicInitializedGymDomain,
-    GymDiscreteActionDomain,
-    GymDomain,
-    GymDomainHashable,
-    GymDomainStateProxy,
-    GymPlanningDomain,
-    GymWidthDomain,
-)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .gym import (
+    AsGymnasiumEnv,
+    AsLegacyGymV21Env,
+    CostDeterministicGymDomain,
+    DeterministicGymDomain,
+    DeterministicInitializedGymDomain,
+    GymDiscreteActionDomain,
+    GymDomain,
+    GymDomainHashable,
+    GymDomainStateProxy,
+    GymPlanningDomain,
+    GymWidthDomain,
+)
```

## skdecide/hub/domain/gym/gym.py

```diff
@@ -1,1240 +1,1242 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-# TODO: support OpenAI GoalEnv
-from __future__ import annotations
-
-import bisect
-import random
-import struct
-from collections import OrderedDict
-from copy import deepcopy
-from itertools import product
-from math import pi, tan
-from typing import Any, Callable, List, Optional
-
-import gymnasium as gym
-import numpy as np
-from gymnasium.wrappers.compatibility import EnvCompatibility, LegacyEnv
-
-from skdecide import Domain, ImplicitSpace, Space, TransitionOutcome, Value
-from skdecide.builders.domain import (
-    DeterministicInitialized,
-    DeterministicTransitions,
-    FullyObservable,
-    Goals,
-    Initializable,
-    Markovian,
-    Memoryless,
-    PositiveCosts,
-    Renderable,
-    Rewards,
-    Sequential,
-    SingleAgent,
-    UnrestrictedActions,
-)
-from skdecide.hub.space.gym import GymSpace, ListSpace
-
-
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    UnrestrictedActions,
-    Initializable,
-    Memoryless,
-    FullyObservable,
-    Renderable,
-    Rewards,
-):
-    pass
-
-
-# TODO: update with latest Gym Env spec (with seed)
-class GymDomain(D):
-    """This class wraps a gymnasium environment (gym.env) as a scikit-decide domain.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, gym_env: gym.Env) -> None:
-        """Initialize GymDomain.
-
-        # Parameters
-        gym_env: The Gym environment (gym.env) to wrap.
-        """
-        self._gym_env = gym_env
-
-    def _state_reset(self) -> D.T_state:
-        return self._gym_env.reset()[0]
-
-    def _state_step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        obs, reward, terminated, truncated, info = self._gym_env.step(action)
-        if truncated:
-            info["TimeLimit.truncated"] = True
-        return TransitionOutcome(
-            state=obs, value=Value(reward=reward), termination=terminated, info=info
-        )
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        return GymSpace(self._gym_env.action_space)
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        return GymSpace(self._gym_env.observation_space)
-
-    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
-        return self._gym_env.render()
-
-    def close(self):
-        return self._gym_env.close()
-
-    def unwrapped(self):
-        """Unwrap the Gym environment (gym.env) and return it.
-
-        # Returns
-        The original Gym environment.
-        """
-        return self._gym_env
-
-
-class GymDomainStateProxy:
-    def __init__(self, state, context=None):
-        self._state = state
-        self._context = context
-
-    def __hash__(self):
-        return hash(tuple(self.flatten(self._state)))
-
-    def __eq__(self, other):
-        return self.flatten(self._state) == self.flatten(other._state)
-
-    def __str__(self):
-        return self._state.__str__()
-
-    def __repr__(self):
-        return self._state.__repr__()
-
-    def flatten(self, e):
-        if isinstance(e, np.ndarray):
-            return [e.item(c) for c in range(e.size)]
-        elif isinstance(e, tuple):
-            return [tt for t in e for tt in self.flatten(t)]
-        elif isinstance(e, dict):
-            return [tt for k, v in e.items() for tt in self.flatten(v)]
-        else:
-            return [e]
-
-
-# class GymDomainActionProxy :
-#     def __hash__(self):
-#         return str(self).__hash__()
-
-#     def __eq__(self, other):
-#         return str(self).__eq__(str(other))
-
-#     def __str__(self):
-#         return self.__str__()
-
-
-class GymDomainHashable(GymDomain):
-    """This class wraps a gymnasium environment (gym.env) as a scikit-decide domain
-       using hashable states and actions.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, gym_env: gym.Env) -> None:
-        """Initialize GymDomain.
-
-        # Parameters
-        gym_env: The Gym environment (gym.env) to wrap.
-        """
-        super().__init__(gym_env)
-
-    def _state_reset(self) -> D.T_state:
-        return GymDomainStateProxy(super()._state_reset())
-
-    def _state_step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        outcome = super()._state_step(action)
-        outcome.state = GymDomainStateProxy(outcome.state)
-        return outcome
-
-
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    UnrestrictedActions,
-    DeterministicInitialized,
-    Memoryless,
-    FullyObservable,
-    Renderable,
-    Rewards,
-):
-    pass
-
-
-class DeterministicInitializedGymDomain(D):
-    """This class wraps a gymnasium environment (gym.env) as a scikit-decide domain
-       with a deterministic initial state (i.e. reset the domain to the initial
-       state returned by the first reset)
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(
-        self,
-        gym_env: gym.Env,
-        set_state: Callable[[gym.Env, D.T_memory[D.T_state]], None] = None,
-        get_state: Callable[[gym.Env], D.T_memory[D.T_state]] = None,
-    ) -> None:
-        """Initialize GymDomain.
-
-        # Parameters
-        gym_env: The Gym environment (gym.env) to wrap.
-        set_state: Function to call to set the state of the gym environment.
-                   If None, default behavior is to deepcopy the environment when changing state
-        get_state: Function to call to get the state of the gym environment.
-                   If None, default behavior is to deepcopy the environment when changing state
-        """
-        self._gym_env = gym_env
-        self._set_state = set_state
-        self._get_state = get_state
-        self._init_env = None
-        self._initial_state = None
-        self._initial_env_state = None
-
-    def set_memory(self, state: D.T_state) -> None:
-        self._initial_state = state
-        self._memory = self._init_memory(self._initial_state)
-        if self._set_state is not None and self._get_state is not None:
-            self._initial_env_state = state._context
-            self._set_state(self._gym_env, self._initial_env_state)
-        else:
-            self._init_env = state._context
-            self._gym_env = deepcopy(self._init_env)
-
-    def _state_reset(self) -> D.T_state:
-        if self._initial_state is None:
-            self._initial_state = GymDomainStateProxy(
-                state=self._gym_env.reset()[0], context=None
-            )
-            if self._set_state is not None and self._get_state is not None:
-                self._initial_env_state = self._get_state(self._gym_env)
-                self._initial_state._context = self._initial_env_state
-            else:
-                self._init_env = deepcopy(self._gym_env)
-                self._initial_state._context = self._init_env
-        else:
-            if self._set_state is not None and self._get_state is not None:
-                self._set_state(self._gym_env, self._initial_env_state)
-            else:
-                self._gym_env = deepcopy(self._init_env)
-        return self._initial_state
-
-    def _state_step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-        obs, reward, terminated, truncated, info = self._gym_env.step(action)
-        if truncated:
-            info["TimeLimit.truncated"] = True
-        if self._set_state is not None and self._get_state is not None:
-            state = GymDomainStateProxy(state=obs, context=self._initial_env_state)
-        else:
-            state = GymDomainStateProxy(state=obs, context=self._init_env)
-        return TransitionOutcome(
-            state=state, value=Value(reward=reward), termination=terminated, info=info
-        )
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        return GymSpace(self._gym_env.action_space)
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        return GymSpace(self._gym_env.observation_space)
-
-    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
-        render = self._gym_env.render()
-        if self._set_state is None or self._get_state is None:
-            self._gym_env.close()  # avoid deepcopy errors
-        return render
-
-    def close(self):
-        return self._gym_env.close()
-
-    def unwrapped(self):
-        """Unwrap the Gym environment (gym.env) and return it.
-
-        # Returns
-        The original Gym environment.
-        """
-        return self._gym_env
-
-
-class GymWidthDomain:
-    """This class wraps a gymnasium environment as a domain
-        usable by width-based solving algorithm (e.g. IW)
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, continuous_feature_fidelity: int = 1) -> None:
-        """Initialize GymWidthDomain.
-
-        # Parameters
-        continuous_feature_fidelity: Number of integers to represent a continuous feature
-                                     in the interval-based feature abstraction (higher is more precise)
-        """
-        self._continuous_feature_fidelity = continuous_feature_fidelity
-        self._feature_increments = []
-        self._init_continuous_state_variables = []
-        self._elliptical_features = None
-
-    def _reset_features(self):
-        self._init_continuous_state_variables = []
-        self._feature_increments = []
-
-    class BEE1Node:
-        def __init__(self, ref):
-            self.reference = ref
-            self.increments = [0]
-            self.children = []
-
-    def _init_bee1_features(self, space, state):
-        if isinstance(space, gym.spaces.box.Box):
-            for cell_id in range(state.size):
-                cell = state.item(cell_id)
-                self._init_continuous_state_variables.append(cell)
-                # positive increments list for each fidelity level
-                self._feature_increments.append(GymWidthDomain.BEE1Node(cell))
-                # negative increments list for each fidelity level
-                self._feature_increments.append(GymWidthDomain.BEE1Node(cell))
-        elif isinstance(space, gym.spaces.tuple.Tuple):
-            for s in range(len(space.spaces)):
-                self._init_bee1_features(space.spaces[s], state[s])
-        elif isinstance(space, gym.spaces.dict.Dict):
-            for k, s in space.spaces:
-                self._init_bee1_features(s, state[k])
-        else:
-            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
-
-    def bee1_features(self, state):
-        """Return a numpy vector of ints representing the current 'cumulated layer' of each state variable"""
-        state = state._state if isinstance(state, GymDomainStateProxy) else state
-        if len(self._feature_increments) == 0:
-            self._init_bee1_features(self._gym_env.observation_space, state)
-        return self._bee1_features(self._gym_env.observation_space, state, 0)[1]
-
-    def _bee1_features(self, space, element, start):
-        if isinstance(space, gym.spaces.box.Box):
-            features = []
-            index = start
-            for cell_id in range(element.size):
-                cell = element.item(cell_id)
-                cf = []
-                if cell > self._init_continuous_state_variables[index]:
-                    node = self._feature_increments[2 * index]
-                    sign = 1
-                else:
-                    node = self._feature_increments[2 * index + 1]
-                    sign = -1
-                for f in range(self._continuous_feature_fidelity):
-                    i = bisect.bisect_left(
-                        node.increments, sign * (cell - node.reference)
-                    )
-                    cf.append(sign * i)
-                    if i >= len(node.increments):
-                        node.increments.append(sign * (cell - node.reference))
-                        node.children.append(
-                            GymWidthDomain.BEE1Node(
-                                node.reference + (sign * node.increments[i - 1])
-                            )
-                        )
-                        for ff in range(f + 1, self._continuous_feature_fidelity):
-                            cf.append(0)
-                        break
-                    elif i > 0:
-                        node = node.children[i - 1]
-                features += cf
-                index += 1
-            return index, features
-        elif isinstance(space, gym.spaces.discrete.Discrete):
-            return start, [element]
-        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
-            return start, [e for e in element]
-        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
-            return start, [e for e in element]
-        elif isinstance(space, gym.spaces.tuple.Tuple):
-            index = start
-            features = []
-            for i in range(len(space.spaces)):
-                index, l = self._bee1_features(space.spaces[i], element[i], index)
-                features += l
-            return index, features
-        elif isinstance(space, gym.spaces.dict.Dict):
-            index = start
-            features = []
-            for k in space.spaces.keys():
-                index, l = self._bee1_features(space.spaces[k], element[k], index)
-                features += l
-            return index, features
-        else:
-            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
-
-    class BEE2Node:
-        def __init__(self):
-            self.I = []
-            self.llb = None
-            self.gub = None
-            self.children = []
-
-        def eval(self, x, level=0):
-            if len(self.I) == 0:
-                self.I = [(x, x)]
-                self.children = [GymWidthDomain.BEE2Node()]
-                self.llb = x
-                self.gub = x
-                return tuple([0] + [-1 for k in range(level)])
-            if x < self.llb:
-                self.I += [(x, self.llb)]
-                self.children += [GymWidthDomain.BEE2Node()]
-                self.llb = x
-                return tuple([len(self.I) - 1] + [-1 for k in range(level)])
-            elif x > self.gub:
-                self.I += [(self.gub, x)]
-                self.children += [GymWidthDomain.BEE2Node()]
-                self.gub = x
-                return tuple([len(self.I) - 1] + [-1 for k in range(level)])
-            else:
-                # we need to search
-                for k, i_k in enumerate(self.I):
-                    if i_k[0] <= x <= i_k[1]:
-                        sub = []
-                        if level > 0:
-                            sub = self.children[k].eval(x, level - 1)
-                        return tuple([k] + list(sub))
-                        # return k
-            raise RuntimeError("Should never get here!")
-
-        def __repr__(self):
-            return "[I={}, llb={}, gub={}]".format(self.I, self.llb, self.gub)
-
-    def _init_bee2_features(self, space, state):
-        if isinstance(space, gym.spaces.box.Box):
-            for cell_id in range(state.size):
-                cell = state.item(cell_id)
-                self._init_continuous_state_variables.append(cell)
-                self._feature_increments.append(GymWidthDomain.BEE2Node())
-                self._feature_increments[-1].eval(cell)
-        elif isinstance(space, gym.spaces.tuple.Tuple):
-            for s in range(len(space.spaces)):
-                self._init_bee2_features(space.spaces[s], state[s])
-        elif isinstance(space, gym.spaces.dict.Dict):
-            for k, s in space.spaces:
-                self._init_bee2_features(s, state[k])
-        else:
-            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
-
-    def bee2_features(self, state):
-        """Return a numpy vector of ints representing the current 'cumulated layer' of each state variable"""
-        state = state._state if isinstance(state, GymDomainStateProxy) else state
-        if len(self._feature_increments) == 0:
-            self._init_bee2_features(self._gym_env.observation_space, state)
-        return self._bee2_features(self._gym_env.observation_space, state, 0)[1]
-
-    def _bee2_features(self, space, element, start):
-        if isinstance(space, gym.spaces.box.Box):
-            features = []
-            index = start
-            for cell_id in range(element.size):
-                cell = element.item(cell_id)
-                features += self._feature_increments[index].eval(
-                    cell, self._continuous_feature_fidelity - 1
-                )
-                index += 1
-            return index, features
-        elif isinstance(space, gym.spaces.discrete.Discrete):
-            return start, [element]
-        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
-            return start, [e for e in element]
-        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
-            return start, [e for e in element]
-        elif isinstance(space, gym.spaces.tuple.Tuple):
-            index = start
-            features = []
-            for i in range(len(space.spaces)):
-                index, l = self._bee2_features(space.spaces[i], element[i], index)
-                features += l
-            return index, features
-        elif isinstance(space, gym.spaces.dict.Dict):
-            index = start
-            features = []
-            for k in space.spaces.keys():
-                index, l = self._bee2_features(space.spaces[k], element[k], index)
-                features += l
-            return index, features
-        else:
-            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
-
-    def nb_of_binary_features(self) -> int:
-        """Return the size of the bit vector encoding an observation"""
-        return len(
-            self._binary_features(
-                self._gym_env.observation_space,
-                self._gym_env.observation_space.sample(),
-            )
-        )
-
-    def binary_features(self, memory: D.T_memory[D.T_state]) -> List[bool]:
-        """Transform state in a bit vector and call f on each true value of this vector
-
-        # Parameters
-        memory: The Gym state (in observation_space) to binarize
-
-        Return a list of booleans representing the binary representation of each state variable
-        """
-        memory = memory._state if isinstance(memory, GymDomainStateProxy) else memory
-        return self._binary_features(self._gym_env.observation_space, memory)
-
-    def _binary_features(self, space: gym.spaces.Space, element: Any) -> List[bool]:
-        if isinstance(space, gym.spaces.box.Box):
-            features = []
-            # compute the size of the bit vector encoding the largest float
-            maxlen = len(
-                bin(struct.unpack("!i", struct.pack("!f", float("inf")))[0])[2:]
-            )
-            for cell in np.nditer(element):
-                # convert float to string of 1s and 0s
-                float_bin = bin(struct.unpack("!i", struct.pack("!f", cell))[0])
-                # the sign of the float is encoded in the first bit in our translation
-                if float_bin[0] == "-":
-                    features.append(True)
-                    float_bin = float_bin[3:]
-                else:
-                    features.append(False)
-                    float_bin = float_bin[2:]
-                # add 0s at the beginning of the string so that all elements are encoded with the same number of bits
-                # that depends on the size of the bit vector encoding the largest float
-                float_bin = ("0" * (maxlen - len(float_bin))) + float_bin
-                for b in float_bin:
-                    features.append(b == "1")
-            return features
-        elif isinstance(space, gym.spaces.discrete.Discrete):
-            features = []
-            # convert int to string of 1s and 0s
-            int_bin = bin(element)[2:]
-            # add 0s at the beginning of the string so that all elements are encoded with the same number of bits
-            # that depends on the discrete space's highest element which is space.n - 1
-            int_bin = ("0" * (len(bin(space.n - 1)[2:]) - len(int_bin))) + int_bin
-            for b in int_bin:
-                features.append(b == "1")
-            return features
-        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
-            features = []
-            # look at the previous test case for the logics of translating each element of the vector to a bit string
-            for i in range(len(space.nvec)):
-                int_bin = bin(element[i])[2:]
-                int_bin = (
-                    "0" * (len(bin(space.nvec[i] - 1)[2:]) - len(int_bin))
-                ) + int_bin
-                for b in int_bin:
-                    features.append(b == "1")
-            return features
-        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
-            features = []
-            for b in element:
-                features.append(bool(b))
-            return features
-        elif isinstance(space, gym.spaces.tuple.Tuple):
-            features = []
-            for i in range(len(space.spaces)):
-                l = self._binary_features(space.spaces[i], element[i])
-                features += l
-            return features
-        elif isinstance(space, gym.spaces.dict.Dict):
-            features = []
-            for k, v in space.spaces:
-                l = self._binary_features(v, element[k])
-                features += l
-            return features
-        else:
-            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
-
-    class EllipticalMapping2D:
-        def __init__(self, input, _x0, _xG, bands):
-            self.input = input
-            self.x0 = _x0
-            self.xG = _xG
-            self.projected_goal = np.array(
-                [self.xG[self.input[0]], self.xG[self.input[1]]]
-            )
-            self.bands = bands
-
-        def evaluate(self, state):
-            projected_state = np.array([state[self.input[0]], state[self.input[1]]])
-            c = np.linalg.norm(projected_state - self.projected_goal)
-            for k, v in enumerate(self.bands):
-                if c > v:
-                    return len(self.bands) - k
-            return 0
-
-    def init_elliptical_features(
-        self, x0: D.T_memory[D.T_state], xG: D.T_memory[D.T_state]
-    ):
-        v0 = np.array(self._get_variables(self._gym_env.observation_space, x0))
-        vG = np.array(self._get_variables(self._gym_env.observation_space, xG))
-        d = xG.shape[0]  # column vector
-        self._elliptical_features = []
-        for i in range(d):
-            for j in range(i + 1, d):
-                input = (i, j)
-                c = np.linalg.norm(np.array([v0[i], v0[j]]) - np.array([vG[i], vG[j]]))
-                bands = []
-                num_levels = 10.0 * max(np.log10(c), 1.0)
-                delta_c = c / float(num_levels)
-                c_k = c
-                while c_k > delta_c:
-                    bands += [c_k]
-                    c_k -= delta_c
-                if len(bands) == 0:
-                    bands += [c_k]
-                self._elliptical_features += [
-                    self.EllipticalMapping2D(input, v0, vG, bands)
-                ]
-
-    def elliptical_features(self, state: D.T_memory[D.T_state]):
-        state = state._state if isinstance(state, GymDomainStateProxy) else state
-        vS = np.array(self._get_variables(self._gym_env.observation_space, state))
-        return [f.evaluate(vS) for f in self._elliptical_features]
-
-    def _get_variables(self, space: gym.spaces.Space, element: Any) -> List:
-        if isinstance(space, gym.spaces.box.Box):
-            var = []
-            for cell in np.nditer(element):
-                var.append(cell)
-            return var
-        elif isinstance(space, gym.spaces.discrete.Discrete):
-            return [element]
-        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
-            return [e for e in element]
-        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
-            return [e for e in element]
-        elif isinstance(space, gym.spaces.tuple.Tuple):
-            var = []
-            for i in range(len(space.spaces)):
-                l = self._get_variables(space.spaces[i], element[i])
-                var += l
-            return var
-        elif isinstance(space, gym.spaces.dict.Dict):
-            var = []
-            for k in space.spaces.keys():
-                index, l = self._get_variables(space.spaces[k], element[k])
-                var += l
-            return var
-        else:
-            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
-
-
-class GymDiscreteActionDomain(UnrestrictedActions):
-    """This class wraps a gymnasium environment as a domain
-        usable by a solver that requires enumerable applicable action sets
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(
-        self, discretization_factor: int = 10, branching_factor: int = None
-    ) -> None:
-        """Initialize GymDiscreteActionDomain.
-
-        # Parameters
-        discretization_factor: Number of discretized action variable values per continuous action variable
-        branching_factor: if not None, sample branching_factor actions from the resulting list of discretized actions
-        """
-        self._discretization_factor = discretization_factor
-        self._branching_factor = branching_factor
-        self._applicable_actions = self._discretize_action_space(
-            self.get_action_space()._gym_space
-        )
-        if (
-            self._branching_factor is not None
-            and len(self._applicable_actions.get_elements()) > self._branching_factor
-        ):
-            self._applicable_actions = ListSpace(
-                random.sample(
-                    self._applicable_actions.get_elements(), self._branching_factor
-                )
-            )
-
-    def _get_applicable_actions_from(
-        self, memory: D.T_memory[D.T_state]
-    ) -> D.T_agent[Space[D.T_event]]:
-        return self._applicable_actions
-
-    def _discretize_action_space(
-        self, action_space: gym.spaces.Space
-    ) -> D.T_agent[Space[D.T_event]]:
-        if isinstance(action_space, gym.spaces.box.Box):
-            ticks = []
-
-            unbounded = ~action_space.bounded_below & ~action_space.bounded_above
-            upp_bounded = ~action_space.bounded_below & action_space.bounded_above
-            low_bounded = action_space.bounded_below & ~action_space.bounded_above
-            bounded = action_space.bounded_below & action_space.bounded_above
-
-            it = np.nditer(action_space.low, flags=["multi_index"])
-            for _ in it:
-                index = it.multi_index
-
-                if unbounded[index]:
-                    l = [
-                        tan(0.5 * pi * x)
-                        for x in np.linspace(-1, 1, self._discretization_factor + 2)[
-                            1:-1
-                        ]
-                    ]
-                elif upp_bounded[index]:
-                    l = [
-                        action_space.high[index] + tan(0.5 * pi * x)
-                        for x in np.linspace(
-                            -1, 0, self._discretization_factor + 1, endpoint=True
-                        )[1:]
-                    ]
-                elif low_bounded[index]:
-                    l = [
-                        action_space.low[index] + tan(0.5 * pi * x)
-                        for x in np.linspace(
-                            0, 1, self._discretization_factor + 1, endpoint=True
-                        )[:-1]
-                    ]
-                elif bounded[index]:
-                    l = np.linspace(
-                        action_space.low[index],
-                        action_space.high[index],
-                        self._discretization_factor,
-                    )
-                else:
-                    raise ValueError("Invalid case")
-
-                ticks.append(l)
-
-            return ListSpace(
-                np.reshape(np.array(x, dtype=action_space.dtype), action_space.shape)
-                for x in product(*ticks)
-            )
-
-        elif isinstance(action_space, gym.spaces.discrete.Discrete):
-            return ListSpace(
-                np.int64(i + action_space.start) for i in range(action_space.n)
-            )
-
-        elif isinstance(action_space, gym.spaces.multi_discrete.MultiDiscrete):
-            ticks = []
-            it = np.nditer(action_space.nvec, flags=["multi_index"])
-            for _ in it:
-                index = it.multi_index
-                ticks.append(range(action_space.nvec[index]))
-
-            return ListSpace(
-                np.reshape(np.array(x, dtype=action_space.dtype), action_space.shape)
-                for x in product(*ticks)
-            )
-
-        elif isinstance(action_space, gym.spaces.multi_binary.MultiBinary):
-            ticks = [range(2)] * int(np.prod(action_space.shape))
-
-            return ListSpace(
-                np.reshape(np.array(x, dtype=action_space.dtype), action_space.shape)
-                for x in product(*ticks)
-            )
-
-        elif isinstance(action_space, gym.spaces.tuple.Tuple):
-            generate = lambda d: (
-                (
-                    (e,) + g
-                    for e in self._discretize_action_space(
-                        action_space.spaces[d]
-                    ).get_elements()
-                    for g in generate(d + 1)
-                )
-                if d < len(action_space.spaces) - 1
-                else (
-                    (e,)
-                    for e in self._discretize_action_space(
-                        action_space.spaces[d]
-                    ).get_elements()
-                )
-            )
-            return ListSpace(generate(0))
-
-        elif isinstance(action_space, gym.spaces.dict.Dict):
-            dkeys = list(action_space.spaces.keys())
-            generate = lambda d: (
-                (
-                    (e,) + g
-                    for e in self._discretize_action_space(
-                        action_space.spaces[dkeys[d]]
-                    ).get_elements()
-                    for g in generate(d + 1)
-                )
-                if d < len(action_space.spaces) - 1
-                else (
-                    (e,)
-                    for e in self._discretize_action_space(
-                        action_space.spaces[dkeys[d]]
-                    ).get_elements()
-                )
-            )
-            return ListSpace(
-                OrderedDict(zip(dkeys, dvalues)) for dvalues in generate(0)
-            )
-        else:
-            raise RuntimeError(
-                "Unknown Gym space element of type " + str(type(action_space))
-            )
-
-
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    DeterministicTransitions,
-    UnrestrictedActions,
-    DeterministicInitialized,
-    Markovian,
-    FullyObservable,
-    Renderable,
-    Rewards,
-):  # TODO: replace Rewards by PositiveCosts??
-    pass
-
-
-def check_equality_state(st1, st2):
-    return (isinstance(st1, np.ndarray) and np.array_equal(st1, st2)) or (
-        not isinstance(st1, np.ndarray) and st1 == st2
-    )
-
-
-class DeterministicGymDomain(D):
-    """This class wraps a deterministic gymnasium environment (gym.env) as a scikit-decide domain.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(
-        self,
-        gym_env: gym.Env,
-        set_state: Callable[[gym.Env, D.T_memory[D.T_state]], None] = None,
-        get_state: Callable[[gym.Env], D.T_memory[D.T_state]] = None,
-    ) -> None:
-        """Initialize DeterministicGymDomain.
-
-        # Parameters
-        gym_env: The deterministic Gym environment (gym.env) to wrap.
-        set_state: Function to call to set the state of the gym environment.
-                   If None, default behavior is to deepcopy the environment when changing state
-        get_state: Function to call to get the state of the gym environment.
-                   If None, default behavior is to deepcopy the environment when changing state
-        """
-        self._gym_env = gym_env
-        self._set_state = set_state
-        self._get_state = get_state
-        self._init_env = None
-
-    def _get_initial_state_(self) -> D.T_state:
-        initial_state = self._gym_env.reset()[0]
-        return GymDomainStateProxy(
-            state=initial_state,
-            context=[
-                self._gym_env,
-                None,
-                None,
-                None,
-                self._get_state(self._gym_env)
-                if (self._get_state is not None and self._set_state is not None)
-                else None,
-            ],
-        )
-
-    def _get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        env = memory._context[0]
-        if self._set_state is None or self._get_state is None:
-            env = deepcopy(env)
-        elif not check_equality_state(memory._context[4], self._get_state(env)):
-            self._set_state(env, memory._context[4])
-        self._gym_env = env  # Just in case the simulation environment would be different from the planner's environment...
-        obs, reward, terminated, truncated, info = env.step(action)
-        if truncated:
-            info["TimeLimit.truncated"] = True
-        outcome = TransitionOutcome(
-            state=obs, value=Value(reward=reward), termination=terminated, info=info
-        )
-        # print('Transition:', str(memory._state), ' -> ', str(action), ' -> ', str(outcome.state))
-        return GymDomainStateProxy(
-            state=outcome.state,
-            context=[
-                env,
-                memory._state,
-                action,
-                outcome,
-                self._get_state(env)
-                if (self._get_state is not None and self._set_state is not None)
-                else None,
-            ],
-        )
-
-    def _get_transition_value(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-        next_state: Optional[D.T_state] = None,
-    ) -> D.T_agent[Value[D.T_value]]:
-        last_memory, last_action, outcome = next_state._context[1:4]
-        # assert (self._are_same(self._gym_env.observation_space, memory._state, last_memory) and
-        #         self._are_same(self._gym_env.action_space, action, last_action))
-        return outcome.value
-
-    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
-        outcome = state._context[3]
-        return outcome.termination if outcome is not None else False
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        return GymSpace(self._gym_env.action_space)
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        return GymSpace(self._gym_env.observation_space)
-
-    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
-        # gym_env.render() can modify the environment
-        # and generate deepcopy errors later in _get_next_state
-        # thus we use a copy of the env to render it instead.
-        gym_env_for_rendering = deepcopy(self._gym_env)
-        render = gym_env_for_rendering.render()
-        return render
-
-    def close(self):
-        return self._gym_env.close()
-
-    def unwrapped(self):
-        """Unwrap the deterministic Gym environment (gym.env) and return it.
-
-        # Returns
-        The original Gym environment.
-        """
-        return self._gym_env
-
-    def _are_same(self, space: gym.spaces.Space, e1: Any, e2: Any):
-        assert e1.__class__ == e2.__class__
-        if isinstance(space, gym.spaces.box.Box):
-            return (e1 == e2).all()
-        elif isinstance(space, gym.spaces.discrete.Discrete):
-            return e1 == e2
-        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
-            return (e1 == e2).all()
-        elif isinstance(space, gym.spaces.tuple.Tuple):
-            assert len(e1) == len(e2) == len(space)
-            for i in range(len(space)):
-                if not self._are_same(space[i], e1[i], e2[i]):
-                    return False
-            return True
-        elif isinstance(space, gym.spaces.dict.Dict):
-            assert e1.keys() == e2.keys() == space.keys()
-            for k in space.keys():
-                if not self._are_same(space[k], e1[k], e2[k]):
-                    return False
-            return True
-        else:
-            raise RuntimeError("Unknown Gym space of type " + str(type(space)))
-
-
-class CostDeterministicGymDomain(DeterministicGymDomain, PositiveCosts):
-    pass
-
-
-class GymPlanningDomain(CostDeterministicGymDomain, Goals):
-    """This class wraps a cost-based deterministic gymnasium environment as a domain
-        usable by a classical planner
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(
-        self,
-        gym_env: gym.Env,
-        set_state: Callable[[gym.Env, D.T_memory[D.T_state]], None] = None,
-        get_state: Callable[[gym.Env], D.T_memory[D.T_state]] = None,
-        termination_is_goal: bool = False,
-        max_depth: int = 50,
-    ) -> None:
-        """Initialize GymPlanningDomain.
-
-        # Parameters
-        gym_env: The deterministic Gym environment (gym.env) to wrap.
-        set_state: Function to call to set the state of the gym environment.
-                   If None, default behavior is to deepcopy the environment when changing state
-        get_state: Function to call to get the state of the gym environment.
-                   If None, default behavior is to deepcopy the environment when changing state
-        termination_is_goal: True if the termination condition is a goal (and not a dead-end)
-        max_depth: maximum depth of states to explore from the initial state
-        """
-        super().__init__(gym_env, set_state, get_state)
-        self._termination_is_goal = termination_is_goal
-        self._max_depth = max_depth
-        self._initial_state = None
-        self._current_depth = 0
-        self._restarting_from_initial_state = False
-
-    def _get_initial_state_(self) -> D.T_state:
-        initial_state = super()._get_initial_state_()
-        initial_state._context.append(0)  # Depth
-        initial_state._context.append(0)  # Accumulated reward
-        self._initial_state = initial_state
-        self._current_depth = 0
-        return initial_state
-
-    def _get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        if (
-            self._initial_state is None
-        ):  # the solver's domain does not use _get_initial_state_() but gets its initial state from the rollout env shipped with the state context
-            self._initial_state = memory
-        if self._are_same(
-            self._gym_env.observation_space, memory._state, self._initial_state._state
-        ):
-            self._restart_from_initial_state()
-        else:
-            self._restarting_from_initial_state = False
-        next_state = super()._get_next_state(memory, action)
-        next_state._context.append(memory._context[5] + 1)
-        next_state._context.append(
-            memory._context[6] + memory._context[3].value.reward
-            if memory._context[3] is not None
-            else memory._context[6]
-        )
-        if memory._context[5] + 1 > self._current_depth:
-            self._current_depth = memory._context[5] + 1
-            print("Current depth:", str(self._current_depth), "/", str(self._max_depth))
-        return next_state
-
-    def _restart_from_initial_state(self):
-        # following test is mandatory since we restart from the initial state
-        # when expanding each action of the initial state
-        # and we want to do it only once
-        if not self._restarting_from_initial_state:
-            self._current_depth = 0
-            if isinstance(self, GymWidthDomain):
-                self._reset_features()
-            self._restarting_from_initial_state = True
-
-    def _get_goals_(self):
-        return ImplicitSpace(
-            lambda observation: (
-                (observation._context[5] >= self._max_depth)
-                or (
-                    self._termination_is_goal
-                    and (
-                        observation._context[3].termination
-                        if observation._context[3] is not None
-                        else False
-                    )
-                )
-            )
-        )
-
-
-class AsLegacyGymV21Env(LegacyEnv):
-    """This class wraps a scikit-decide domain as a legacy OpenAI Gym v0.21 environment.
-
-    !!! warning
-        The scikit-decide domain to wrap should inherit #UnrestrictedActionDomain since gymnasium environments usually assume
-        that all their actions are always applicable.
-
-    An gymnasium environment encapsulates an environment with arbitrary behind-the-scenes dynamics. An environment can
-    be partially or fully observed.
-
-    The main API methods that users of this class need to know are:
-
-    - step
-    - reset
-    - render
-    - close
-    - seed
-
-    And set the following attributes:
-
-    - action_space: The Space object corresponding to valid actions.
-    - observation_space: The Space object corresponding to valid observations.
-    - reward_range: A tuple corresponding to the min and max possible rewards.
-
-    !!! tip
-        A default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range. The methods are
-        accessed publicly as "step", "reset", etc.. The non-underscored versions are wrapper methods to which
-        functionality may be added over time.
-    """
-
-    def __init__(self, domain: Domain, unwrap_spaces: bool = True) -> None:
-        """Initialize AsGymEnv.
-
-        # Parameters
-        domain: The scikit-decide domain to wrap as a gymnasium environment.
-        unwrap_spaces: Boolean specifying whether the action & observation spaces should be unwrapped.
-        """
-        self._domain = domain
-        self._unwrap_spaces = unwrap_spaces
-        if unwrap_spaces:
-            self.observation_space = domain.get_observation_space().unwrapped()
-            self.action_space = (
-                domain.get_action_space().unwrapped()
-            )  # assumes all actions are always applicable
-        else:
-            self.observation_space = domain.get_observation_space()
-            self.action_space = (
-                domain.get_action_space()
-            )  # assumes all actions are always applicable
-
-    def step(self, action):
-        """Run one timestep of the environment's dynamics. When end of episode is reached, you are responsible for
-        calling `reset()` to reset this environment's state.
-
-        Accepts an action and returns a tuple (observation, reward, done, info).
-
-        # Parameters
-        action (object): An action provided by the environment.
-
-        # Returns
-        A tuple with following elements:
-
-        - observation (object): The agent's observation of the current environment.
-        - reward (float) : The amount of reward returned after previous action.
-        - done (boolean): Whether the episode ended, in which case further step() calls will return undefined results.
-        - info (dict): Contains auxiliary diagnostic information (helpful for debugging, and sometimes learning).
-        """
-        action = next(iter(self._domain.get_action_space().from_unwrapped([action])))
-        outcome = self._domain.step(action)
-        outcome_observation = next(
-            iter(
-                self._domain.get_observation_space().to_unwrapped([outcome.observation])
-            )
-        )
-        # Some solvers dealing with gymnasium environments crash when info is None (e.g. baselines solver)
-        outcome_info = outcome.info if outcome.info is not None else {}
-        return (
-            outcome_observation,
-            outcome.value.reward,
-            outcome.termination,
-            outcome_info,
-        )
-
-    def reset(self):
-        """Reset the state of the environment and returns an initial observation.
-
-        # Returns
-        observation (object): The initial observation of the space.
-        """
-        return next(
-            iter(
-                self._domain.get_observation_space().to_unwrapped(
-                    [self._domain.reset()]
-                )
-            )
-        )
-
-    def render(self, mode="human"):
-        """Render the environment.
-
-        The set of supported modes varies per environment. (And some environments do not support rendering at all.) By
-        convention, if mode is:
-
-        - human: Render to the current display or terminal and return nothing. Usually for human consumption.
-        - rgb_array: Return an numpy.ndarray with shape (x, y, 3), representing RGB values for an x-by-y pixel image,
-        suitable for turning into a video.
-        - ansi: Return a string (str) or StringIO.StringIO containing a terminal-style text representation. The text can
-        include newlines and ANSI escape sequences (e.g. for colors).
-
-        !!! tip
-            Make sure that your class's metadata 'render.modes' key includes he list of supported modes. It's
-            recommended to call super() in implementations to use the functionality of this method.
-
-        # Parameters
-        mode (str): The mode to render with.
-        close (bool): Close all open renderings.
-
-        # Example
-        ```python
-        class MyEnv(Env):
-            metadata = {'render.modes': ['human', 'rgb_array']}
-
-            def render(self, mode='human'):
-                if mode == 'rgb_array':
-                    return np.array(...) # return RGB frame suitable for video
-                elif mode is 'human':
-                    ... # pop up a window and render
-                else:
-                    super(MyEnv, self).render(mode=mode) # just raise an exception
-        ```
-        """
-        return self._domain.render(mode=mode)
-
-    def close(self):
-        """Override close in your subclass to perform any necessary cleanup.
-
-        Environments will automatically close() themselves when garbage collected or when the program exits.
-        """
-        # check that the method "close" exists before calling it (for instance the maze domain does not have one).
-        close_meth = getattr(self._domain, "close", None)
-        if callable(close_meth):
-            return close_meth()
-
-    def unwrapped(self):
-        """Unwrap the scikit-decide domain and return it.
-
-        # Returns
-        The original scikit-decide domain.
-        """
-        return self._domain
-
-
-class AsGymnasiumEnv(EnvCompatibility):
-    """This class wraps a scikit-decide domain as a gymnasium environment."""
-
-    def __init__(
-        self,
-        domain: Domain,
-        unwrap_spaces: bool = True,
-        render_mode: Optional[str] = None,
-    ) -> None:
-        legacy_env = AsLegacyGymV21Env(domain=domain, unwrap_spaces=unwrap_spaces)
-        super().__init__(old_env=legacy_env, render_mode=render_mode)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+# TODO: support OpenAI GoalEnv
+from __future__ import annotations
+
+import bisect
+import random
+import struct
+from collections import OrderedDict
+from copy import deepcopy
+from itertools import product
+from math import pi, tan
+from typing import Any, Callable, List, Optional
+
+import gymnasium as gym
+import numpy as np
+from gymnasium.wrappers.compatibility import EnvCompatibility, LegacyEnv
+
+from skdecide import Domain, ImplicitSpace, Space, TransitionOutcome, Value
+from skdecide.builders.domain import (
+    DeterministicInitialized,
+    DeterministicTransitions,
+    FullyObservable,
+    Goals,
+    Initializable,
+    Markovian,
+    PositiveCosts,
+    Renderable,
+    Rewards,
+    Sequential,
+    SingleAgent,
+    UnrestrictedActions,
+)
+from skdecide.hub.space.gym import GymSpace, ListSpace
+
+
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    UnrestrictedActions,
+    Initializable,
+    Markovian,
+    FullyObservable,
+    Renderable,
+    Rewards,
+):
+    pass
+
+
+# TODO: update with latest Gym Env spec (with seed)
+class GymDomain(D):
+    """This class wraps a gymnasium environment (gym.env) as a scikit-decide domain.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, gym_env: gym.Env) -> None:
+        """Initialize GymDomain.
+
+        # Parameters
+        gym_env: The Gym environment (gym.env) to wrap.
+        """
+        self._gym_env = gym_env
+
+    def _state_reset(self) -> D.T_state:
+        return self._gym_env.reset()[0]
+
+    def _state_step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        obs, reward, terminated, truncated, info = self._gym_env.step(action)
+        if truncated:
+            info["TimeLimit.truncated"] = True
+        return TransitionOutcome(
+            state=obs, value=Value(reward=reward), termination=terminated, info=info
+        )
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        return GymSpace(self._gym_env.action_space)
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        return GymSpace(self._gym_env.observation_space)
+
+    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
+        return self._gym_env.render()
+
+    def close(self):
+        return self._gym_env.close()
+
+    def unwrapped(self):
+        """Unwrap the Gym environment (gym.env) and return it.
+
+        # Returns
+        The original Gym environment.
+        """
+        return self._gym_env
+
+
+class GymDomainStateProxy:
+    def __init__(self, state, context=None):
+        self._state = state
+        self._context = context
+
+    def __hash__(self):
+        return hash(tuple(self.flatten(self._state)))
+
+    def __eq__(self, other):
+        return self.flatten(self._state) == self.flatten(other._state)
+
+    def __str__(self):
+        return self._state.__str__()
+
+    def __repr__(self):
+        return self._state.__repr__()
+
+    def flatten(self, e):
+        if isinstance(e, np.ndarray):
+            return [e.item(c) for c in range(e.size)]
+        elif isinstance(e, tuple):
+            return [tt for t in e for tt in self.flatten(t)]
+        elif isinstance(e, dict):
+            return [tt for k, v in e.items() for tt in self.flatten(v)]
+        else:
+            return [e]
+
+
+# class GymDomainActionProxy :
+#     def __hash__(self):
+#         return str(self).__hash__()
+
+#     def __eq__(self, other):
+#         return str(self).__eq__(str(other))
+
+#     def __str__(self):
+#         return self.__str__()
+
+
+class GymDomainHashable(GymDomain):
+    """This class wraps a gymnasium environment (gym.env) as a scikit-decide domain
+       using hashable states and actions.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, gym_env: gym.Env) -> None:
+        """Initialize GymDomain.
+
+        # Parameters
+        gym_env: The Gym environment (gym.env) to wrap.
+        """
+        super().__init__(gym_env)
+
+    def _state_reset(self) -> D.T_state:
+        return GymDomainStateProxy(super()._state_reset())
+
+    def _state_step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        outcome = super()._state_step(action)
+        outcome.state = GymDomainStateProxy(outcome.state)
+        return outcome
+
+
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    UnrestrictedActions,
+    DeterministicInitialized,
+    Markovian,
+    FullyObservable,
+    Renderable,
+    Rewards,
+):
+    pass
+
+
+class DeterministicInitializedGymDomain(D):
+    """This class wraps a gymnasium environment (gym.env) as a scikit-decide domain
+       with a deterministic initial state (i.e. reset the domain to the initial
+       state returned by the first reset)
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(
+        self,
+        gym_env: gym.Env,
+        set_state: Callable[[gym.Env, D.T_memory[D.T_state]], None] = None,
+        get_state: Callable[[gym.Env], D.T_memory[D.T_state]] = None,
+    ) -> None:
+        """Initialize GymDomain.
+
+        # Parameters
+        gym_env: The Gym environment (gym.env) to wrap.
+        set_state: Function to call to set the state of the gym environment.
+                   If None, default behavior is to deepcopy the environment when changing state
+        get_state: Function to call to get the state of the gym environment.
+                   If None, default behavior is to deepcopy the environment when changing state
+        """
+        self._gym_env = gym_env
+        self._set_state = set_state
+        self._get_state = get_state
+        self._init_env = None
+        self._initial_state = None
+        self._initial_env_state = None
+
+    def set_memory(self, state: D.T_state) -> None:
+        self._initial_state = state
+        self._memory = self._init_memory(self._initial_state)
+        if self._set_state is not None and self._get_state is not None:
+            self._initial_env_state = state._context
+            self._set_state(self._gym_env, self._initial_env_state)
+        else:
+            self._init_env = state._context
+            self._gym_env = deepcopy(self._init_env)
+
+    def _state_reset(self) -> D.T_state:
+        if self._initial_state is None:
+            self._initial_state = GymDomainStateProxy(
+                state=self._gym_env.reset()[0], context=None
+            )
+            if self._set_state is not None and self._get_state is not None:
+                self._initial_env_state = self._get_state(self._gym_env)
+                self._initial_state._context = self._initial_env_state
+            else:
+                self._init_env = deepcopy(self._gym_env)
+                self._initial_state._context = self._init_env
+        else:
+            if self._set_state is not None and self._get_state is not None:
+                self._set_state(self._gym_env, self._initial_env_state)
+            else:
+                self._gym_env = deepcopy(self._init_env)
+        return self._initial_state
+
+    def _state_step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+        obs, reward, terminated, truncated, info = self._gym_env.step(action)
+        if truncated:
+            info["TimeLimit.truncated"] = True
+        if self._set_state is not None and self._get_state is not None:
+            state = GymDomainStateProxy(state=obs, context=self._initial_env_state)
+        else:
+            state = GymDomainStateProxy(state=obs, context=self._init_env)
+        return TransitionOutcome(
+            state=state, value=Value(reward=reward), termination=terminated, info=info
+        )
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        return GymSpace(self._gym_env.action_space)
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        return GymSpace(self._gym_env.observation_space)
+
+    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
+        render = self._gym_env.render()
+        if self._set_state is None or self._get_state is None:
+            self._gym_env.close()  # avoid deepcopy errors
+        return render
+
+    def close(self):
+        return self._gym_env.close()
+
+    def unwrapped(self):
+        """Unwrap the Gym environment (gym.env) and return it.
+
+        # Returns
+        The original Gym environment.
+        """
+        return self._gym_env
+
+
+class GymWidthDomain:
+    """This class wraps a gymnasium environment as a domain
+        usable by width-based solving algorithm (e.g. IW)
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, continuous_feature_fidelity: int = 1) -> None:
+        """Initialize GymWidthDomain.
+
+        # Parameters
+        continuous_feature_fidelity: Number of integers to represent a continuous feature
+                                     in the interval-based feature abstraction (higher is more precise)
+        """
+        self._continuous_feature_fidelity = continuous_feature_fidelity
+        self._feature_increments = []
+        self._init_continuous_state_variables = []
+        self._elliptical_features = None
+
+    def _reset_features(self):
+        self._init_continuous_state_variables = []
+        self._feature_increments = []
+
+    class BEE1Node:
+        def __init__(self, ref):
+            self.reference = ref
+            self.increments = [0]
+            self.children = []
+
+    def _init_bee1_features(self, space, state):
+        if isinstance(space, gym.spaces.box.Box):
+            for cell_id in range(state.size):
+                cell = state.item(cell_id)
+                self._init_continuous_state_variables.append(cell)
+                # positive increments list for each fidelity level
+                self._feature_increments.append(GymWidthDomain.BEE1Node(cell))
+                # negative increments list for each fidelity level
+                self._feature_increments.append(GymWidthDomain.BEE1Node(cell))
+        elif isinstance(space, gym.spaces.tuple.Tuple):
+            for s in range(len(space.spaces)):
+                self._init_bee1_features(space.spaces[s], state[s])
+        elif isinstance(space, gym.spaces.dict.Dict):
+            for k, s in space.spaces:
+                self._init_bee1_features(s, state[k])
+        else:
+            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
+
+    def bee1_features(self, state):
+        """Return a numpy vector of ints representing the current 'cumulated layer' of each state variable"""
+        state = state._state if isinstance(state, GymDomainStateProxy) else state
+        if len(self._feature_increments) == 0:
+            self._init_bee1_features(self._gym_env.observation_space, state)
+        return self._bee1_features(self._gym_env.observation_space, state, 0)[1]
+
+    def _bee1_features(self, space, element, start):
+        if isinstance(space, gym.spaces.box.Box):
+            features = []
+            index = start
+            for cell_id in range(element.size):
+                cell = element.item(cell_id)
+                cf = []
+                if cell > self._init_continuous_state_variables[index]:
+                    node = self._feature_increments[2 * index]
+                    sign = 1
+                else:
+                    node = self._feature_increments[2 * index + 1]
+                    sign = -1
+                for f in range(self._continuous_feature_fidelity):
+                    i = bisect.bisect_left(
+                        node.increments, sign * (cell - node.reference)
+                    )
+                    cf.append(sign * i)
+                    if i >= len(node.increments):
+                        node.increments.append(sign * (cell - node.reference))
+                        node.children.append(
+                            GymWidthDomain.BEE1Node(
+                                node.reference + (sign * node.increments[i - 1])
+                            )
+                        )
+                        for ff in range(f + 1, self._continuous_feature_fidelity):
+                            cf.append(0)
+                        break
+                    elif i > 0:
+                        node = node.children[i - 1]
+                features += cf
+                index += 1
+            return index, features
+        elif isinstance(space, gym.spaces.discrete.Discrete):
+            return start, [element]
+        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
+            return start, [e for e in element]
+        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
+            return start, [e for e in element]
+        elif isinstance(space, gym.spaces.tuple.Tuple):
+            index = start
+            features = []
+            for i in range(len(space.spaces)):
+                index, l = self._bee1_features(space.spaces[i], element[i], index)
+                features += l
+            return index, features
+        elif isinstance(space, gym.spaces.dict.Dict):
+            index = start
+            features = []
+            for k in space.spaces.keys():
+                index, l = self._bee1_features(space.spaces[k], element[k], index)
+                features += l
+            return index, features
+        else:
+            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
+
+    class BEE2Node:
+        def __init__(self):
+            self.I = []
+            self.llb = None
+            self.gub = None
+            self.children = []
+
+        def eval(self, x, level=0):
+            if len(self.I) == 0:
+                self.I = [(x, x)]
+                self.children = [GymWidthDomain.BEE2Node()]
+                self.llb = x
+                self.gub = x
+                return tuple([0] + [-1 for k in range(level)])
+            if x < self.llb:
+                self.I += [(x, self.llb)]
+                self.children += [GymWidthDomain.BEE2Node()]
+                self.llb = x
+                return tuple([len(self.I) - 1] + [-1 for k in range(level)])
+            elif x > self.gub:
+                self.I += [(self.gub, x)]
+                self.children += [GymWidthDomain.BEE2Node()]
+                self.gub = x
+                return tuple([len(self.I) - 1] + [-1 for k in range(level)])
+            else:
+                # we need to search
+                for k, i_k in enumerate(self.I):
+                    if i_k[0] <= x <= i_k[1]:
+                        sub = []
+                        if level > 0:
+                            sub = self.children[k].eval(x, level - 1)
+                        return tuple([k] + list(sub))
+                        # return k
+            raise RuntimeError("Should never get here!")
+
+        def __repr__(self):
+            return "[I={}, llb={}, gub={}]".format(self.I, self.llb, self.gub)
+
+    def _init_bee2_features(self, space, state):
+        if isinstance(space, gym.spaces.box.Box):
+            for cell_id in range(state.size):
+                cell = state.item(cell_id)
+                self._init_continuous_state_variables.append(cell)
+                self._feature_increments.append(GymWidthDomain.BEE2Node())
+                self._feature_increments[-1].eval(cell)
+        elif isinstance(space, gym.spaces.tuple.Tuple):
+            for s in range(len(space.spaces)):
+                self._init_bee2_features(space.spaces[s], state[s])
+        elif isinstance(space, gym.spaces.dict.Dict):
+            for k, s in space.spaces:
+                self._init_bee2_features(s, state[k])
+        else:
+            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
+
+    def bee2_features(self, state):
+        """Return a numpy vector of ints representing the current 'cumulated layer' of each state variable"""
+        state = state._state if isinstance(state, GymDomainStateProxy) else state
+        if len(self._feature_increments) == 0:
+            self._init_bee2_features(self._gym_env.observation_space, state)
+        return self._bee2_features(self._gym_env.observation_space, state, 0)[1]
+
+    def _bee2_features(self, space, element, start):
+        if isinstance(space, gym.spaces.box.Box):
+            features = []
+            index = start
+            for cell_id in range(element.size):
+                cell = element.item(cell_id)
+                features += self._feature_increments[index].eval(
+                    cell, self._continuous_feature_fidelity - 1
+                )
+                index += 1
+            return index, features
+        elif isinstance(space, gym.spaces.discrete.Discrete):
+            return start, [element]
+        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
+            return start, [e for e in element]
+        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
+            return start, [e for e in element]
+        elif isinstance(space, gym.spaces.tuple.Tuple):
+            index = start
+            features = []
+            for i in range(len(space.spaces)):
+                index, l = self._bee2_features(space.spaces[i], element[i], index)
+                features += l
+            return index, features
+        elif isinstance(space, gym.spaces.dict.Dict):
+            index = start
+            features = []
+            for k in space.spaces.keys():
+                index, l = self._bee2_features(space.spaces[k], element[k], index)
+                features += l
+            return index, features
+        else:
+            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
+
+    def nb_of_binary_features(self) -> int:
+        """Return the size of the bit vector encoding an observation"""
+        return len(
+            self._binary_features(
+                self._gym_env.observation_space,
+                self._gym_env.observation_space.sample(),
+            )
+        )
+
+    def binary_features(self, memory: D.T_memory[D.T_state]) -> List[bool]:
+        """Transform state in a bit vector and call f on each true value of this vector
+
+        # Parameters
+        memory: The Gym state (in observation_space) to binarize
+
+        Return a list of booleans representing the binary representation of each state variable
+        """
+        memory = memory._state if isinstance(memory, GymDomainStateProxy) else memory
+        return self._binary_features(self._gym_env.observation_space, memory)
+
+    def _binary_features(self, space: gym.spaces.Space, element: Any) -> List[bool]:
+        if isinstance(space, gym.spaces.box.Box):
+            features = []
+            # compute the size of the bit vector encoding the largest float
+            maxlen = len(
+                bin(struct.unpack("!i", struct.pack("!f", float("inf")))[0])[2:]
+            )
+            for cell in np.nditer(element):
+                # convert float to string of 1s and 0s
+                float_bin = bin(struct.unpack("!i", struct.pack("!f", cell))[0])
+                # the sign of the float is encoded in the first bit in our translation
+                if float_bin[0] == "-":
+                    features.append(True)
+                    float_bin = float_bin[3:]
+                else:
+                    features.append(False)
+                    float_bin = float_bin[2:]
+                # add 0s at the beginning of the string so that all elements are encoded with the same number of bits
+                # that depends on the size of the bit vector encoding the largest float
+                float_bin = ("0" * (maxlen - len(float_bin))) + float_bin
+                for b in float_bin:
+                    features.append(b == "1")
+            return features
+        elif isinstance(space, gym.spaces.discrete.Discrete):
+            features = []
+            # convert int to string of 1s and 0s
+            int_bin = bin(element)[2:]
+            # add 0s at the beginning of the string so that all elements are encoded with the same number of bits
+            # that depends on the discrete space's highest element which is space.n - 1
+            int_bin = ("0" * (len(bin(space.n - 1)[2:]) - len(int_bin))) + int_bin
+            for b in int_bin:
+                features.append(b == "1")
+            return features
+        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
+            features = []
+            # look at the previous test case for the logics of translating each element of the vector to a bit string
+            for i in range(len(space.nvec)):
+                int_bin = bin(element[i])[2:]
+                int_bin = (
+                    "0" * (len(bin(space.nvec[i] - 1)[2:]) - len(int_bin))
+                ) + int_bin
+                for b in int_bin:
+                    features.append(b == "1")
+            return features
+        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
+            features = []
+            for b in element:
+                features.append(bool(b))
+            return features
+        elif isinstance(space, gym.spaces.tuple.Tuple):
+            features = []
+            for i in range(len(space.spaces)):
+                l = self._binary_features(space.spaces[i], element[i])
+                features += l
+            return features
+        elif isinstance(space, gym.spaces.dict.Dict):
+            features = []
+            for k, v in space.spaces:
+                l = self._binary_features(v, element[k])
+                features += l
+            return features
+        else:
+            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
+
+    class EllipticalMapping2D:
+        def __init__(self, input, _x0, _xG, bands):
+            self.input = input
+            self.x0 = _x0
+            self.xG = _xG
+            self.projected_goal = np.array(
+                [self.xG[self.input[0]], self.xG[self.input[1]]]
+            )
+            self.bands = bands
+
+        def evaluate(self, state):
+            projected_state = np.array([state[self.input[0]], state[self.input[1]]])
+            c = np.linalg.norm(projected_state - self.projected_goal)
+            for k, v in enumerate(self.bands):
+                if c > v:
+                    return len(self.bands) - k
+            return 0
+
+    def init_elliptical_features(
+        self, x0: D.T_memory[D.T_state], xG: D.T_memory[D.T_state]
+    ):
+        v0 = np.array(self._get_variables(self._gym_env.observation_space, x0))
+        vG = np.array(self._get_variables(self._gym_env.observation_space, xG))
+        d = xG.shape[0]  # column vector
+        self._elliptical_features = []
+        for i in range(d):
+            for j in range(i + 1, d):
+                input = (i, j)
+                c = np.linalg.norm(np.array([v0[i], v0[j]]) - np.array([vG[i], vG[j]]))
+                bands = []
+                num_levels = 10.0 * max(np.log10(c), 1.0)
+                delta_c = c / float(num_levels)
+                c_k = c
+                while c_k > delta_c:
+                    bands += [c_k]
+                    c_k -= delta_c
+                if len(bands) == 0:
+                    bands += [c_k]
+                self._elliptical_features += [
+                    self.EllipticalMapping2D(input, v0, vG, bands)
+                ]
+
+    def elliptical_features(self, state: D.T_memory[D.T_state]):
+        state = state._state if isinstance(state, GymDomainStateProxy) else state
+        vS = np.array(self._get_variables(self._gym_env.observation_space, state))
+        return [f.evaluate(vS) for f in self._elliptical_features]
+
+    def _get_variables(self, space: gym.spaces.Space, element: Any) -> List:
+        if isinstance(space, gym.spaces.box.Box):
+            var = []
+            for cell in np.nditer(element):
+                var.append(cell)
+            return var
+        elif isinstance(space, gym.spaces.discrete.Discrete):
+            return [element]
+        elif isinstance(space, gym.spaces.multi_discrete.MultiDiscrete):
+            return [e for e in element]
+        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
+            return [e for e in element]
+        elif isinstance(space, gym.spaces.tuple.Tuple):
+            var = []
+            for i in range(len(space.spaces)):
+                l = self._get_variables(space.spaces[i], element[i])
+                var += l
+            return var
+        elif isinstance(space, gym.spaces.dict.Dict):
+            var = []
+            for k in space.spaces.keys():
+                index, l = self._get_variables(space.spaces[k], element[k])
+                var += l
+            return var
+        else:
+            raise RuntimeError("Unknown Gym space element of type " + str(type(space)))
+
+
+class GymDiscreteActionDomain(UnrestrictedActions):
+    """This class wraps a gymnasium environment as a domain
+        usable by a solver that requires enumerable applicable action sets
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(
+        self, discretization_factor: int = 10, branching_factor: int = None
+    ) -> None:
+        """Initialize GymDiscreteActionDomain.
+
+        # Parameters
+        discretization_factor: Number of discretized action variable values per continuous action variable
+        branching_factor: if not None, sample branching_factor actions from the resulting list of discretized actions
+        """
+        self._discretization_factor = discretization_factor
+        self._branching_factor = branching_factor
+        self._applicable_actions = self._discretize_action_space(
+            self.get_action_space()._gym_space
+        )
+        if (
+            self._branching_factor is not None
+            and len(self._applicable_actions.get_elements()) > self._branching_factor
+        ):
+            self._applicable_actions = ListSpace(
+                random.sample(
+                    self._applicable_actions.get_elements(), self._branching_factor
+                )
+            )
+
+    def _get_applicable_actions_from(
+        self, memory: D.T_memory[D.T_state]
+    ) -> D.T_agent[Space[D.T_event]]:
+        return self._applicable_actions
+
+    def _discretize_action_space(
+        self, action_space: gym.spaces.Space
+    ) -> D.T_agent[Space[D.T_event]]:
+        if isinstance(action_space, gym.spaces.box.Box):
+            ticks = []
+
+            unbounded = ~action_space.bounded_below & ~action_space.bounded_above
+            upp_bounded = ~action_space.bounded_below & action_space.bounded_above
+            low_bounded = action_space.bounded_below & ~action_space.bounded_above
+            bounded = action_space.bounded_below & action_space.bounded_above
+
+            it = np.nditer(action_space.low, flags=["multi_index"])
+            for _ in it:
+                index = it.multi_index
+
+                if unbounded[index]:
+                    l = [
+                        tan(0.5 * pi * x)
+                        for x in np.linspace(-1, 1, self._discretization_factor + 2)[
+                            1:-1
+                        ]
+                    ]
+                elif upp_bounded[index]:
+                    l = [
+                        action_space.high[index] + tan(0.5 * pi * x)
+                        for x in np.linspace(
+                            -1, 0, self._discretization_factor + 1, endpoint=True
+                        )[1:]
+                    ]
+                elif low_bounded[index]:
+                    l = [
+                        action_space.low[index] + tan(0.5 * pi * x)
+                        for x in np.linspace(
+                            0, 1, self._discretization_factor + 1, endpoint=True
+                        )[:-1]
+                    ]
+                elif bounded[index]:
+                    l = np.linspace(
+                        action_space.low[index],
+                        action_space.high[index],
+                        self._discretization_factor,
+                    )
+                else:
+                    raise ValueError("Invalid case")
+
+                ticks.append(l)
+
+            return ListSpace(
+                np.reshape(np.array(x, dtype=action_space.dtype), action_space.shape)
+                for x in product(*ticks)
+            )
+
+        elif isinstance(action_space, gym.spaces.discrete.Discrete):
+            return ListSpace(
+                np.int64(i + action_space.start) for i in range(action_space.n)
+            )
+
+        elif isinstance(action_space, gym.spaces.multi_discrete.MultiDiscrete):
+            ticks = []
+            it = np.nditer(action_space.nvec, flags=["multi_index"])
+            for _ in it:
+                index = it.multi_index
+                ticks.append(range(action_space.nvec[index]))
+
+            return ListSpace(
+                np.reshape(np.array(x, dtype=action_space.dtype), action_space.shape)
+                for x in product(*ticks)
+            )
+
+        elif isinstance(action_space, gym.spaces.multi_binary.MultiBinary):
+            ticks = [range(2)] * int(np.prod(action_space.shape))
+
+            return ListSpace(
+                np.reshape(np.array(x, dtype=action_space.dtype), action_space.shape)
+                for x in product(*ticks)
+            )
+
+        elif isinstance(action_space, gym.spaces.tuple.Tuple):
+            generate = lambda d: (
+                (
+                    (e,) + g
+                    for e in self._discretize_action_space(
+                        action_space.spaces[d]
+                    ).get_elements()
+                    for g in generate(d + 1)
+                )
+                if d < len(action_space.spaces) - 1
+                else (
+                    (e,)
+                    for e in self._discretize_action_space(
+                        action_space.spaces[d]
+                    ).get_elements()
+                )
+            )
+            return ListSpace(generate(0))
+
+        elif isinstance(action_space, gym.spaces.dict.Dict):
+            dkeys = list(action_space.spaces.keys())
+            generate = lambda d: (
+                (
+                    (e,) + g
+                    for e in self._discretize_action_space(
+                        action_space.spaces[dkeys[d]]
+                    ).get_elements()
+                    for g in generate(d + 1)
+                )
+                if d < len(action_space.spaces) - 1
+                else (
+                    (e,)
+                    for e in self._discretize_action_space(
+                        action_space.spaces[dkeys[d]]
+                    ).get_elements()
+                )
+            )
+            return ListSpace(
+                OrderedDict(zip(dkeys, dvalues)) for dvalues in generate(0)
+            )
+        else:
+            raise RuntimeError(
+                "Unknown Gym space element of type " + str(type(action_space))
+            )
+
+
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    DeterministicTransitions,
+    UnrestrictedActions,
+    DeterministicInitialized,
+    Markovian,
+    FullyObservable,
+    Renderable,
+    Rewards,
+):  # TODO: replace Rewards by PositiveCosts??
+    pass
+
+
+def check_equality_state(st1, st2):
+    return (isinstance(st1, np.ndarray) and np.array_equal(st1, st2)) or (
+        not isinstance(st1, np.ndarray) and st1 == st2
+    )
+
+
+class DeterministicGymDomain(D):
+    """This class wraps a deterministic gymnasium environment (gym.env) as a scikit-decide domain.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(
+        self,
+        gym_env: gym.Env,
+        set_state: Callable[[gym.Env, D.T_memory[D.T_state]], None] = None,
+        get_state: Callable[[gym.Env], D.T_memory[D.T_state]] = None,
+    ) -> None:
+        """Initialize DeterministicGymDomain.
+
+        # Parameters
+        gym_env: The deterministic Gym environment (gym.env) to wrap.
+        set_state: Function to call to set the state of the gym environment.
+                   If None, default behavior is to deepcopy the environment when changing state
+        get_state: Function to call to get the state of the gym environment.
+                   If None, default behavior is to deepcopy the environment when changing state
+        """
+        self._gym_env = gym_env
+        self._set_state = set_state
+        self._get_state = get_state
+        self._init_env = None
+
+    def _get_initial_state_(self) -> D.T_state:
+        initial_state = self._gym_env.reset()[0]
+        return GymDomainStateProxy(
+            state=initial_state,
+            context=[
+                self._gym_env,
+                None,
+                None,
+                None,
+                self._get_state(self._gym_env)
+                if (self._get_state is not None and self._set_state is not None)
+                else None,
+            ],
+        )
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        env = memory._context[0]
+        if self._set_state is None or self._get_state is None:
+            env = deepcopy(env)
+        elif not check_equality_state(memory._context[4], self._get_state(env)):
+            self._set_state(env, memory._context[4])
+        self._gym_env = env  # Just in case the simulation environment would be different from the planner's environment...
+        obs, reward, terminated, truncated, info = env.step(action)
+        if truncated:
+            info["TimeLimit.truncated"] = True
+        outcome = TransitionOutcome(
+            state=obs, value=Value(reward=reward), termination=terminated, info=info
+        )
+        # print('Transition:', str(memory._state), ' -> ', str(action), ' -> ', str(outcome.state))
+        return GymDomainStateProxy(
+            state=outcome.state,
+            context=[
+                env,
+                memory._state,
+                action,
+                outcome,
+                self._get_state(env)
+                if (self._get_state is not None and self._set_state is not None)
+                else None,
+            ],
+        )
+
+    def _get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_state] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+        last_memory, last_action, outcome = next_state._context[1:4]
+        # assert (self._are_same(self._gym_env.observation_space, memory._state, last_memory) and
+        #         self._are_same(self._gym_env.action_space, action, last_action))
+        return outcome.value
+
+    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
+        outcome = state._context[3]
+        return outcome.termination if outcome is not None else False
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        return GymSpace(self._gym_env.action_space)
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        return GymSpace(self._gym_env.observation_space)
+
+    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
+        # gym_env.render() can modify the environment
+        # and generate deepcopy errors later in _get_next_state
+        # thus we use a copy of the env to render it instead.
+        if self._set_state is None or self._get_state is None:
+            gym_env_for_rendering = deepcopy(self._gym_env)
+            render = gym_env_for_rendering.render()
+            return render
+        else:
+            self._gym_env.render()
+
+    def close(self):
+        return self._gym_env.close()
+
+    def unwrapped(self):
+        """Unwrap the deterministic Gym environment (gym.env) and return it.
+
+        # Returns
+        The original Gym environment.
+        """
+        return self._gym_env
+
+    def _are_same(self, space: gym.spaces.Space, e1: Any, e2: Any):
+        assert e1.__class__ == e2.__class__
+        if isinstance(space, gym.spaces.box.Box):
+            return (e1 == e2).all()
+        elif isinstance(space, gym.spaces.discrete.Discrete):
+            return e1 == e2
+        elif isinstance(space, gym.spaces.multi_binary.MultiBinary):
+            return (e1 == e2).all()
+        elif isinstance(space, gym.spaces.tuple.Tuple):
+            assert len(e1) == len(e2) == len(space)
+            for i in range(len(space)):
+                if not self._are_same(space[i], e1[i], e2[i]):
+                    return False
+            return True
+        elif isinstance(space, gym.spaces.dict.Dict):
+            assert e1.keys() == e2.keys() == space.keys()
+            for k in space.keys():
+                if not self._are_same(space[k], e1[k], e2[k]):
+                    return False
+            return True
+        else:
+            raise RuntimeError("Unknown Gym space of type " + str(type(space)))
+
+
+class CostDeterministicGymDomain(DeterministicGymDomain, PositiveCosts):
+    pass
+
+
+class GymPlanningDomain(CostDeterministicGymDomain, Goals):
+    """This class wraps a cost-based deterministic gymnasium environment as a domain
+        usable by a classical planner
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(
+        self,
+        gym_env: gym.Env,
+        set_state: Callable[[gym.Env, D.T_memory[D.T_state]], None] = None,
+        get_state: Callable[[gym.Env], D.T_memory[D.T_state]] = None,
+        termination_is_goal: bool = False,
+        max_depth: int = 50,
+    ) -> None:
+        """Initialize GymPlanningDomain.
+
+        # Parameters
+        gym_env: The deterministic Gym environment (gym.env) to wrap.
+        set_state: Function to call to set the state of the gym environment.
+                   If None, default behavior is to deepcopy the environment when changing state
+        get_state: Function to call to get the state of the gym environment.
+                   If None, default behavior is to deepcopy the environment when changing state
+        termination_is_goal: True if the termination condition is a goal (and not a dead-end)
+        max_depth: maximum depth of states to explore from the initial state
+        """
+        super().__init__(gym_env, set_state, get_state)
+        self._termination_is_goal = termination_is_goal
+        self._max_depth = max_depth
+        self._initial_state = None
+        self._current_depth = 0
+        self._restarting_from_initial_state = False
+
+    def _get_initial_state_(self) -> D.T_state:
+        initial_state = super()._get_initial_state_()
+        initial_state._context.append(0)  # Depth
+        initial_state._context.append(0)  # Accumulated reward
+        self._initial_state = initial_state
+        self._current_depth = 0
+        return initial_state
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        if (
+            self._initial_state is None
+        ):  # the solver's domain does not use _get_initial_state_() but gets its initial state from the rollout env shipped with the state context
+            self._initial_state = memory
+        if self._are_same(
+            self._gym_env.observation_space, memory._state, self._initial_state._state
+        ):
+            self._restart_from_initial_state()
+        else:
+            self._restarting_from_initial_state = False
+        next_state = super()._get_next_state(memory, action)
+        next_state._context.append(memory._context[5] + 1)
+        next_state._context.append(
+            memory._context[6] + memory._context[3].value.reward
+            if memory._context[3] is not None
+            else memory._context[6]
+        )
+        if memory._context[5] + 1 > self._current_depth:
+            self._current_depth = memory._context[5] + 1
+            print("Current depth:", str(self._current_depth), "/", str(self._max_depth))
+        return next_state
+
+    def _restart_from_initial_state(self):
+        # following test is mandatory since we restart from the initial state
+        # when expanding each action of the initial state
+        # and we want to do it only once
+        if not self._restarting_from_initial_state:
+            self._current_depth = 0
+            if isinstance(self, GymWidthDomain):
+                self._reset_features()
+            self._restarting_from_initial_state = True
+
+    def _get_goals_(self):
+        return ImplicitSpace(
+            lambda observation: (
+                (observation._context[5] >= self._max_depth)
+                or (
+                    self._termination_is_goal
+                    and (
+                        observation._context[3].termination
+                        if observation._context[3] is not None
+                        else False
+                    )
+                )
+            )
+        )
+
+
+class AsLegacyGymV21Env(LegacyEnv):
+    """This class wraps a scikit-decide domain as a legacy OpenAI Gym v0.21 environment.
+
+    !!! warning
+        The scikit-decide domain to wrap should inherit #UnrestrictedActionDomain since gymnasium environments usually assume
+        that all their actions are always applicable.
+
+    An gymnasium environment encapsulates an environment with arbitrary behind-the-scenes dynamics. An environment can
+    be partially or fully observed.
+
+    The main API methods that users of this class need to know are:
+
+    - step
+    - reset
+    - render
+    - close
+    - seed
+
+    And set the following attributes:
+
+    - action_space: The Space object corresponding to valid actions.
+    - observation_space: The Space object corresponding to valid observations.
+    - reward_range: A tuple corresponding to the min and max possible rewards.
+
+    !!! tip
+        A default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range. The methods are
+        accessed publicly as "step", "reset", etc.. The non-underscored versions are wrapper methods to which
+        functionality may be added over time.
+    """
+
+    def __init__(self, domain: Domain, unwrap_spaces: bool = True) -> None:
+        """Initialize AsGymEnv.
+
+        # Parameters
+        domain: The scikit-decide domain to wrap as a gymnasium environment.
+        unwrap_spaces: Boolean specifying whether the action & observation spaces should be unwrapped.
+        """
+        self._domain = domain
+        self._unwrap_spaces = unwrap_spaces
+        if unwrap_spaces:
+            self.observation_space = domain.get_observation_space().unwrapped()
+            self.action_space = (
+                domain.get_action_space().unwrapped()
+            )  # assumes all actions are always applicable
+        else:
+            self.observation_space = domain.get_observation_space()
+            self.action_space = (
+                domain.get_action_space()
+            )  # assumes all actions are always applicable
+
+    def step(self, action):
+        """Run one timestep of the environment's dynamics. When end of episode is reached, you are responsible for
+        calling `reset()` to reset this environment's state.
+
+        Accepts an action and returns a tuple (observation, reward, done, info).
+
+        # Parameters
+        action (object): An action provided by the environment.
+
+        # Returns
+        A tuple with following elements:
+
+        - observation (object): The agent's observation of the current environment.
+        - reward (float) : The amount of reward returned after previous action.
+        - done (boolean): Whether the episode ended, in which case further step() calls will return undefined results.
+        - info (dict): Contains auxiliary diagnostic information (helpful for debugging, and sometimes learning).
+        """
+        action = next(iter(self._domain.get_action_space().from_unwrapped([action])))
+        outcome = self._domain.step(action)
+        outcome_observation = next(
+            iter(
+                self._domain.get_observation_space().to_unwrapped([outcome.observation])
+            )
+        )
+        # Some solvers dealing with gymnasium environments crash when info is None (e.g. baselines solver)
+        outcome_info = outcome.info if outcome.info is not None else {}
+        return (
+            outcome_observation,
+            outcome.value.reward,
+            outcome.termination,
+            outcome_info,
+        )
+
+    def reset(self):
+        """Reset the state of the environment and returns an initial observation.
+
+        # Returns
+        observation (object): The initial observation of the space.
+        """
+        return next(
+            iter(
+                self._domain.get_observation_space().to_unwrapped(
+                    [self._domain.reset()]
+                )
+            )
+        )
+
+    def render(self, mode="human"):
+        """Render the environment.
+
+        The set of supported modes varies per environment. (And some environments do not support rendering at all.) By
+        convention, if mode is:
+
+        - human: Render to the current display or terminal and return nothing. Usually for human consumption.
+        - rgb_array: Return an numpy.ndarray with shape (x, y, 3), representing RGB values for an x-by-y pixel image,
+        suitable for turning into a video.
+        - ansi: Return a string (str) or StringIO.StringIO containing a terminal-style text representation. The text can
+        include newlines and ANSI escape sequences (e.g. for colors).
+
+        !!! tip
+            Make sure that your class's metadata 'render.modes' key includes he list of supported modes. It's
+            recommended to call super() in implementations to use the functionality of this method.
+
+        # Parameters
+        mode (str): The mode to render with.
+        close (bool): Close all open renderings.
+
+        # Example
+        ```python
+        class MyEnv(Env):
+            metadata = {'render.modes': ['human', 'rgb_array']}
+
+            def render(self, mode='human'):
+                if mode == 'rgb_array':
+                    return np.array(...) # return RGB frame suitable for video
+                elif mode is 'human':
+                    ... # pop up a window and render
+                else:
+                    super(MyEnv, self).render(mode=mode) # just raise an exception
+        ```
+        """
+        return self._domain.render(mode=mode)
+
+    def close(self):
+        """Override close in your subclass to perform any necessary cleanup.
+
+        Environments will automatically close() themselves when garbage collected or when the program exits.
+        """
+        # check that the method "close" exists before calling it (for instance the maze domain does not have one).
+        close_meth = getattr(self._domain, "close", None)
+        if callable(close_meth):
+            return close_meth()
+
+    def unwrapped(self):
+        """Unwrap the scikit-decide domain and return it.
+
+        # Returns
+        The original scikit-decide domain.
+        """
+        return self._domain
+
+
+class AsGymnasiumEnv(EnvCompatibility):
+    """This class wraps a scikit-decide domain as a gymnasium environment."""
+
+    def __init__(
+        self,
+        domain: Domain,
+        unwrap_spaces: bool = True,
+        render_mode: Optional[str] = None,
+    ) -> None:
+        legacy_env = AsLegacyGymV21Env(domain=domain, unwrap_spaces=unwrap_spaces)
+        super().__init__(old_env=legacy_env, render_mode=render_mode)
```

## skdecide/hub/domain/mastermind/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .mastermind import MasterMind
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .mastermind import MasterMind
```

## skdecide/hub/domain/mastermind/mastermind.py

 * *Ordering differences only*

```diff
@@ -1,146 +1,146 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-# Original code by Patrik Haslum
-from __future__ import annotations
-
-from typing import NamedTuple, Optional, Tuple
-
-from skdecide import DiscreteDistribution, Distribution, GoalPOMDPDomain, Space, Value
-from skdecide.builders.domain import (
-    DeterministicTransitions,
-    TransformedObservable,
-    UnrestrictedActions,
-)
-from skdecide.hub.space.gym import ListSpace, MultiDiscreteSpace
-
-Row = Tuple[int]  # a row of code pegs (solution or guess)
-
-
-class Score(NamedTuple):
-    total_bulls: int
-    total_cows: int
-
-
-class State(NamedTuple):
-    solution: Row
-    score: Score
-
-
-class D(
-    GoalPOMDPDomain,
-    DeterministicTransitions,
-    UnrestrictedActions,
-    TransformedObservable,
-):
-    T_state = State  # Type of states
-    T_observation = Score  # Type of observations
-    T_event = Row  # Type of events (a row guess in this case)
-    T_value = int  # Type of transition values (costs)
-    T_predicate = bool  # Type of logical checks
-    T_info = (
-        None  # Type of additional information given as part of an environment outcome
-    )
-
-
-class MasterMind(D):
-    def __init__(self, n_colours=2, n_positions=2):
-        self._n_colours = n_colours
-        self._n_positions = n_positions
-        self._h_solutions = self._list_hidden_solutions()
-
-    def _get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        # Input is a state and an action; output is a next state.
-        if (
-            action is None
-        ):  # TODO: handle this option on algo side rather than domain; here action should never be None
-            return memory
-        else:
-            return State(memory.solution, self._calc_score(memory, action))
-
-    def _get_transition_value(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-        next_state: Optional[D.T_state] = None,
-    ) -> D.T_agent[Value[D.T_value]]:
-        return Value(cost=1)
-
-    # Overridden to help some solvers compute more efficiently (not mandatory, but good practice)
-    def _is_transition_value_dependent_on_next_state_(self) -> bool:
-        return False
-
-    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
-        return self._is_goal(state.score)
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        # Return the possible actions (guesses) as an enumerable space
-        return ListSpace(self._h_solutions)
-
-    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
-        # Return the space of goal OBSERVATIONS
-        return ListSpace([Score(total_bulls=self._n_positions, total_cows=0)])
-
-    def _get_initial_state_distribution_(self) -> Distribution[D.T_state]:
-        # Return a uniform distribution over all initial states
-        n = len(self._h_solutions)
-        return DiscreteDistribution(
-            [(State(solution=s, score=Score(0, 0)), 1 / n) for s in self._h_solutions]
-        )
-
-    def _get_observation(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> D.T_agent[D.T_observation]:
-        # `action` is the last applied action (or None if the state is an initial state)
-        # `state` is the state to observe (that resulted from applying the action)
-        if action is None:
-            return Score(0, 0)
-        return self._calc_score(state, action)
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        return MultiDiscreteSpace(
-            nvec=[self._n_positions + 1, self._n_positions + 1], element_class=Score
-        )
-
-    def _list_hidden_solutions(self):
-        """Return a list of all possible hidden solutions (n_colours ** n_positions)."""
-        h_solutions = [tuple()]
-        for i in range(self._n_positions):
-            h_solutions = [
-                s + (c,) for s in h_solutions for c in range(self._n_colours)
-            ]
-        return h_solutions
-
-    def _calc_score(self, state, guess):
-        """Compute the score of a guess."""
-        solution = state.solution
-        bulls = [False for _ in range(len(guess))]
-        for i in range(len(guess)):
-            if guess[i] == solution[i]:
-                bulls[i] = True
-        cows = [False for _ in range(len(guess))]
-        for i in range(len(guess)):
-            if guess[i] != solution[i]:
-                for j in range(len(guess)):
-                    if guess[i] == solution[j] and not bulls[j] and not cows[j]:
-                        cows[j] = True
-                        break
-        return Score(total_bulls=sum(bulls), total_cows=sum(cows))
-
-
-if __name__ == "__main__":
-    from skdecide.utils import rollout
-
-    domain = MasterMind(3, 3)
-    rollout(
-        domain,
-        max_steps=1000,
-        outcome_formatter=lambda o: f"{o.observation} - cost: {o.value.cost:.2f}",
-    )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+# Original code by Patrik Haslum
+from __future__ import annotations
+
+from typing import NamedTuple, Optional, Tuple
+
+from skdecide import DiscreteDistribution, Distribution, GoalPOMDPDomain, Space, Value
+from skdecide.builders.domain import (
+    DeterministicTransitions,
+    TransformedObservable,
+    UnrestrictedActions,
+)
+from skdecide.hub.space.gym import ListSpace, MultiDiscreteSpace
+
+Row = Tuple[int]  # a row of code pegs (solution or guess)
+
+
+class Score(NamedTuple):
+    total_bulls: int
+    total_cows: int
+
+
+class State(NamedTuple):
+    solution: Row
+    score: Score
+
+
+class D(
+    GoalPOMDPDomain,
+    DeterministicTransitions,
+    UnrestrictedActions,
+    TransformedObservable,
+):
+    T_state = State  # Type of states
+    T_observation = Score  # Type of observations
+    T_event = Row  # Type of events (a row guess in this case)
+    T_value = int  # Type of transition values (costs)
+    T_predicate = bool  # Type of logical checks
+    T_info = (
+        None  # Type of additional information given as part of an environment outcome
+    )
+
+
+class MasterMind(D):
+    def __init__(self, n_colours=2, n_positions=2):
+        self._n_colours = n_colours
+        self._n_positions = n_positions
+        self._h_solutions = self._list_hidden_solutions()
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        # Input is a state and an action; output is a next state.
+        if (
+            action is None
+        ):  # TODO: handle this option on algo side rather than domain; here action should never be None
+            return memory
+        else:
+            return State(memory.solution, self._calc_score(memory, action))
+
+    def _get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_state] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+        return Value(cost=1)
+
+    # Overridden to help some solvers compute more efficiently (not mandatory, but good practice)
+    def _is_transition_value_dependent_on_next_state_(self) -> bool:
+        return False
+
+    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
+        return self._is_goal(state.score)
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        # Return the possible actions (guesses) as an enumerable space
+        return ListSpace(self._h_solutions)
+
+    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
+        # Return the space of goal OBSERVATIONS
+        return ListSpace([Score(total_bulls=self._n_positions, total_cows=0)])
+
+    def _get_initial_state_distribution_(self) -> Distribution[D.T_state]:
+        # Return a uniform distribution over all initial states
+        n = len(self._h_solutions)
+        return DiscreteDistribution(
+            [(State(solution=s, score=Score(0, 0)), 1 / n) for s in self._h_solutions]
+        )
+
+    def _get_observation(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> D.T_agent[D.T_observation]:
+        # `action` is the last applied action (or None if the state is an initial state)
+        # `state` is the state to observe (that resulted from applying the action)
+        if action is None:
+            return Score(0, 0)
+        return self._calc_score(state, action)
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        return MultiDiscreteSpace(
+            nvec=[self._n_positions + 1, self._n_positions + 1], element_class=Score
+        )
+
+    def _list_hidden_solutions(self):
+        """Return a list of all possible hidden solutions (n_colours ** n_positions)."""
+        h_solutions = [tuple()]
+        for i in range(self._n_positions):
+            h_solutions = [
+                s + (c,) for s in h_solutions for c in range(self._n_colours)
+            ]
+        return h_solutions
+
+    def _calc_score(self, state, guess):
+        """Compute the score of a guess."""
+        solution = state.solution
+        bulls = [False for _ in range(len(guess))]
+        for i in range(len(guess)):
+            if guess[i] == solution[i]:
+                bulls[i] = True
+        cows = [False for _ in range(len(guess))]
+        for i in range(len(guess)):
+            if guess[i] != solution[i]:
+                for j in range(len(guess)):
+                    if guess[i] == solution[j] and not bulls[j] and not cows[j]:
+                        cows[j] = True
+                        break
+        return Score(total_bulls=sum(bulls), total_cows=sum(cows))
+
+
+if __name__ == "__main__":
+    from skdecide.utils import rollout
+
+    domain = MasterMind(3, 3)
+    rollout(
+        domain,
+        max_steps=1000,
+        outcome_formatter=lambda o: f"{o.observation} - cost: {o.value.cost:.2f}",
+    )
```

## skdecide/hub/domain/maze/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .maze import Maze
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .maze import Maze
```

## skdecide/hub/domain/maze/maze.py

 * *Ordering differences only*

```diff
@@ -1,164 +1,164 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from copy import deepcopy
-from enum import Enum
-from typing import Any, NamedTuple, Optional
-
-import matplotlib.pyplot as plt
-
-from skdecide import DeterministicPlanningDomain, Space, Value
-from skdecide.builders.domain import Renderable, UnrestrictedActions
-from skdecide.hub.space.gym import EnumSpace, ListSpace, MultiDiscreteSpace
-
-DEFAULT_MAZE = """
-+-+-+-+-+o+-+-+-+-+-+
-|   |             | |
-+ + + +-+-+-+ +-+ + +
-| | |   |   | | |   |
-+ +-+-+ +-+ + + + +-+
-| |   |   | |   |   |
-+ + + + + + + +-+ +-+
-|   |   |   | |     |
-+-+-+-+-+-+-+-+ +-+ +
-|             |   | |
-+ +-+-+-+-+ + +-+-+ +
-|   |       |       |
-+ + + +-+ +-+ +-+-+-+
-| | |   |     |     |
-+ +-+-+ + +-+ + +-+ +
-| |     | | | |   | |
-+-+ +-+ + + + +-+ + +
-|   |   |   |   | | |
-+ +-+ +-+-+-+-+ + + +
-|   |       |     | |
-+-+-+-+-+-+x+-+-+-+-+
-"""
-
-
-class State(NamedTuple):
-    x: int
-    y: int
-
-
-class Action(Enum):
-    up = 0
-    down = 1
-    left = 2
-    right = 3
-
-
-class D(DeterministicPlanningDomain, UnrestrictedActions, Renderable):
-    T_state = State  # Type of states
-    T_observation = T_state  # Type of observations
-    T_event = Action  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_predicate = bool  # Type of logical checks
-    T_info = (
-        None  # Type of additional information given as part of an environment outcome
-    )
-
-
-class Maze(D):
-    def __init__(self, maze_str: str = DEFAULT_MAZE):
-        maze = []
-        for y, line in enumerate(maze_str.strip().split("\n")):
-            line = line.rstrip()
-            row = []
-            for x, c in enumerate(line):
-                if c in {" ", "o", "x"}:
-                    row.append(1)  # spaces are 1s
-                    if c == "o":
-                        self._start = State(x, y)
-                    if c == "x":
-                        self._goal = State(x, y)
-                else:
-                    row.append(0)  # walls are 0s
-            maze.append(row)
-        # self._render_maze = deepcopy(self._maze)
-        self._maze = maze
-        self._num_cols = len(maze[0])
-        self._num_rows = len(maze)
-        self._ax = None
-        self._image = None
-
-    def _get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        if action == Action.left:
-            next_state = State(memory.x - 1, memory.y)
-        if action == Action.right:
-            next_state = State(memory.x + 1, memory.y)
-        if action == Action.up:
-            next_state = State(memory.x, memory.y - 1)
-        if action == Action.down:
-            next_state = State(memory.x, memory.y + 1)
-
-        # If candidate next state is valid
-        if (
-            0 <= next_state.x < self._num_cols
-            and 0 <= next_state.y < self._num_rows
-            and self._maze[next_state.y][next_state.x] == 1
-        ):
-            return next_state
-        else:
-            return memory
-
-    def _get_transition_value(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-        next_state: Optional[D.T_state] = None,
-    ) -> D.T_agent[Value[D.T_value]]:
-        if next_state.x == memory.x and next_state.y == memory.y:
-            cost = 2  # big penalty when hitting a wall
-        else:
-            cost = abs(next_state.x - memory.x) + abs(
-                next_state.y - memory.y
-            )  # every move costs 1
-
-        return Value(cost=cost)
-
-    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
-        return self._is_goal(state)
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        return EnumSpace(Action)
-
-    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
-        return ListSpace([self._goal])
-
-    def _get_initial_state_(self) -> D.T_state:
-        return self._start
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        return MultiDiscreteSpace(
-            nvec=[self._num_cols, self._num_rows], element_class=State
-        )
-
-    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
-        if self._ax is None:
-            # fig = plt.gcf()
-            fig, ax = plt.subplots(1)
-            # ax = plt.axes()
-            ax.set_aspect("equal")  # set the x and y axes to the same scale
-            plt.xticks([])  # remove the tick marks by setting to an empty list
-            plt.yticks([])  # remove the tick marks by setting to an empty list
-            ax.invert_yaxis()  # invert the y-axis so the first row of data is at the top
-            self._ax = ax
-            plt.ion()
-        maze = deepcopy(self._maze)
-        maze[self._goal.y][self._goal.x] = 0.7
-        maze[memory.y][memory.x] = 0.3
-        if self._image is None:
-            self._image = self._ax.imshow(maze)
-        else:
-            self._image.set_data(maze)
-        # self._ax.pcolormesh(maze)
-        # plt.draw()
-        plt.pause(0.001)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from copy import deepcopy
+from enum import Enum
+from typing import Any, NamedTuple, Optional
+
+import matplotlib.pyplot as plt
+
+from skdecide import DeterministicPlanningDomain, Space, Value
+from skdecide.builders.domain import Renderable, UnrestrictedActions
+from skdecide.hub.space.gym import EnumSpace, ListSpace, MultiDiscreteSpace
+
+DEFAULT_MAZE = """
++-+-+-+-+o+-+-+-+-+-+
+|   |             | |
++ + + +-+-+-+ +-+ + +
+| | |   |   | | |   |
++ +-+-+ +-+ + + + +-+
+| |   |   | |   |   |
++ + + + + + + +-+ +-+
+|   |   |   | |     |
++-+-+-+-+-+-+-+ +-+ +
+|             |   | |
++ +-+-+-+-+ + +-+-+ +
+|   |       |       |
++ + + +-+ +-+ +-+-+-+
+| | |   |     |     |
++ +-+-+ + +-+ + +-+ +
+| |     | | | |   | |
++-+ +-+ + + + +-+ + +
+|   |   |   |   | | |
++ +-+ +-+-+-+-+ + + +
+|   |       |     | |
++-+-+-+-+-+x+-+-+-+-+
+"""
+
+
+class State(NamedTuple):
+    x: int
+    y: int
+
+
+class Action(Enum):
+    up = 0
+    down = 1
+    left = 2
+    right = 3
+
+
+class D(DeterministicPlanningDomain, UnrestrictedActions, Renderable):
+    T_state = State  # Type of states
+    T_observation = T_state  # Type of observations
+    T_event = Action  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_predicate = bool  # Type of logical checks
+    T_info = (
+        None  # Type of additional information given as part of an environment outcome
+    )
+
+
+class Maze(D):
+    def __init__(self, maze_str: str = DEFAULT_MAZE):
+        maze = []
+        for y, line in enumerate(maze_str.strip().split("\n")):
+            line = line.rstrip()
+            row = []
+            for x, c in enumerate(line):
+                if c in {" ", "o", "x"}:
+                    row.append(1)  # spaces are 1s
+                    if c == "o":
+                        self._start = State(x, y)
+                    if c == "x":
+                        self._goal = State(x, y)
+                else:
+                    row.append(0)  # walls are 0s
+            maze.append(row)
+        # self._render_maze = deepcopy(self._maze)
+        self._maze = maze
+        self._num_cols = len(maze[0])
+        self._num_rows = len(maze)
+        self._ax = None
+        self._image = None
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        if action == Action.left:
+            next_state = State(memory.x - 1, memory.y)
+        if action == Action.right:
+            next_state = State(memory.x + 1, memory.y)
+        if action == Action.up:
+            next_state = State(memory.x, memory.y - 1)
+        if action == Action.down:
+            next_state = State(memory.x, memory.y + 1)
+
+        # If candidate next state is valid
+        if (
+            0 <= next_state.x < self._num_cols
+            and 0 <= next_state.y < self._num_rows
+            and self._maze[next_state.y][next_state.x] == 1
+        ):
+            return next_state
+        else:
+            return memory
+
+    def _get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_state] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+        if next_state.x == memory.x and next_state.y == memory.y:
+            cost = 2  # big penalty when hitting a wall
+        else:
+            cost = abs(next_state.x - memory.x) + abs(
+                next_state.y - memory.y
+            )  # every move costs 1
+
+        return Value(cost=cost)
+
+    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
+        return self._is_goal(state)
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        return EnumSpace(Action)
+
+    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
+        return ListSpace([self._goal])
+
+    def _get_initial_state_(self) -> D.T_state:
+        return self._start
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        return MultiDiscreteSpace(
+            nvec=[self._num_cols, self._num_rows], element_class=State
+        )
+
+    def _render_from(self, memory: D.T_memory[D.T_state], **kwargs: Any) -> Any:
+        if self._ax is None:
+            # fig = plt.gcf()
+            fig, ax = plt.subplots(1)
+            # ax = plt.axes()
+            ax.set_aspect("equal")  # set the x and y axes to the same scale
+            plt.xticks([])  # remove the tick marks by setting to an empty list
+            plt.yticks([])  # remove the tick marks by setting to an empty list
+            ax.invert_yaxis()  # invert the y-axis so the first row of data is at the top
+            self._ax = ax
+            plt.ion()
+        maze = deepcopy(self._maze)
+        maze[self._goal.y][self._goal.x] = 0.7
+        maze[memory.y][memory.x] = 0.3
+        if self._image is None:
+            self._image = self._ax.imshow(maze)
+        else:
+            self._image.set_data(maze)
+        # self._ax.pcolormesh(maze)
+        # plt.draw()
+        plt.pause(0.001)
```

## skdecide/hub/domain/rcpsp/__init__.py

 * *Ordering differences only*

```diff
@@ -1,14 +1,14 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .rcpsp_sk import (
-    MRCPSP,
-    MSRCPSP,
-    RCPSP,
-    MRCPSPCalendar,
-    MSRCPSPCalendar,
-    RCPSPCalendar,
-    SMRCPSPCalendar,
-    Stochastic_RCPSP,
-)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .rcpsp_sk import (
+    MRCPSP,
+    MSRCPSP,
+    RCPSP,
+    MRCPSPCalendar,
+    MSRCPSPCalendar,
+    RCPSPCalendar,
+    SMRCPSPCalendar,
+    Stochastic_RCPSP,
+)
```

## skdecide/hub/domain/rcpsp/rcpsp_sk.py

```diff
@@ -1,652 +1,753 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Dict, List, Optional, Set, Union
-
-from skdecide import DiscreteDistribution, Distribution
-from skdecide.builders.domain.scheduling.modes import (
-    ConstantModeConsumption,
-    ModeConsumption,
-)
-from skdecide.builders.domain.scheduling.scheduling_domains import (
-    MultiModeMultiSkillRCPSP,
-    MultiModeMultiSkillRCPSPCalendar,
-    MultiModeRCPSP,
-    MultiModeRCPSP_Stochastic_Durations,
-    MultiModeRCPSPCalendar,
-    MultiModeRCPSPCalendar_Stochastic_Durations,
-    SchedulingObjectiveEnum,
-    SingleMode,
-)
-
-
-class D(MultiModeRCPSP):
-    pass
-
-
-class MRCPSP(D):
-    def __init__(
-        self,
-        resource_names: List[str] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
-        successors: Dict[int, List[int]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, int] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        self.resource_names = resource_names
-        self.task_ids = task_ids
-        self.tasks_mode = tasks_mode
-        # transform the "mode_details" dict that we largely used in DO in the good format.
-        self.task_mode_dict = {}
-        self.duration_dict = {}
-        for task in self.tasks_mode:
-            self.task_mode_dict[task] = {}
-            self.duration_dict[task] = {}
-            for mode in self.tasks_mode[task]:
-                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
-                for r in self.tasks_mode[task][mode]:
-                    if r in self.resource_names:
-                        self.task_mode_dict[task][mode].mode_details[r] = [
-                            self.tasks_mode[task][mode][r]
-                        ]
-                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
-        self.successors = successors
-        self.max_horizon = max_horizon
-        self.resource_availability = resource_availability
-        self.resource_renewable = resource_renewable
-        self.initialize_domain()
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        return self.task_mode_dict
-
-    def _get_resource_renewability(self) -> Dict[str, bool]:
-        return self.resource_renewable
-
-    def _get_max_horizon(self) -> int:
-        return self.max_horizon
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        return self.successors
-
-    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        return self.task_ids
-
-    def _get_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        return self.duration_dict[task][mode]
-
-    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        return self.resource_availability[resource]
-
-    def _get_resource_types_names(self) -> List[str]:
-        return self.resource_names
-
-    def _get_objectives(self) -> List[int]:
-        return [SchedulingObjectiveEnum.MAKESPAN]
-
-
-class D(MultiModeRCPSPCalendar):
-    pass
-
-
-class MRCPSPCalendar(D):
-    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        return self.resource_availability[resource][time]
-
-    def __init__(
-        self,
-        resource_names: List[str] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
-        successors: Dict[int, List[int]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, List[int]] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        self.resource_names = resource_names
-        self.task_ids = task_ids
-        self.tasks_mode = tasks_mode
-        # transform the "mode_details" dict that we largely used in DO in the good format.
-        self.task_mode_dict = {}
-        self.duration_dict = {}
-        for task in self.tasks_mode:
-            self.task_mode_dict[task] = {}
-            self.duration_dict[task] = {}
-            for mode in self.tasks_mode[task]:
-                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
-                for r in self.tasks_mode[task][mode]:
-                    if r in self.resource_names:
-                        self.task_mode_dict[task][mode].mode_details[r] = [
-                            self.tasks_mode[task][mode][r]
-                        ]
-                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
-        self.successors = successors
-        self.max_horizon = max_horizon
-        self.resource_availability = resource_availability
-        self.original_resource_availability = {
-            r: max(self.resource_availability[r]) for r in self.resource_availability
-        }
-
-        self.resource_renewable = resource_renewable
-        self.initialize_domain()
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        return self.task_mode_dict
-
-    def _get_resource_renewability(self) -> Dict[str, bool]:
-        return self.resource_renewable
-
-    def _get_max_horizon(self) -> int:
-        return self.max_horizon
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        return self.successors
-
-    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        return self.task_ids
-
-    def _get_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        return self.duration_dict[task][mode]
-
-    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        return self.original_resource_availability[resource]
-
-    def _get_resource_types_names(self) -> List[str]:
-        return self.resource_names
-
-    def _get_objectives(self) -> List[int]:
-        return [SchedulingObjectiveEnum.MAKESPAN]
-
-
-class RCPSP(MRCPSP, SingleMode):
-    def __init__(
-        self,
-        resource_names: List[str] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
-        successors: Dict[int, List[int]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, int] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        MRCPSP.__init__(
-            self,
-            resource_names=resource_names,
-            task_ids=task_ids,
-            tasks_mode=tasks_mode,
-            successors=successors,
-            max_horizon=max_horizon,
-            resource_availability=resource_availability,
-            resource_renewable=resource_renewable,
-        )
-        self.tasks_modes_rcpsp = {
-            t: self.task_mode_dict[t][1] for t in self.task_mode_dict
-        }
-
-    def _get_tasks_mode(self) -> Dict[int, ModeConsumption]:
-        return self.tasks_modes_rcpsp
-
-
-class RCPSPCalendar(MRCPSPCalendar, SingleMode):
-    def __init__(
-        self,
-        resource_names: List[str] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
-        successors: Dict[int, List[int]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, List[int]] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        MRCPSPCalendar.__init__(
-            self,
-            resource_names=resource_names,
-            task_ids=task_ids,
-            tasks_mode=tasks_mode,
-            successors=successors,
-            max_horizon=max_horizon,
-            resource_availability=resource_availability,
-            resource_renewable=resource_renewable,
-        )
-        self.tasks_modes_rcpsp = {
-            t: self.task_mode_dict[t][1] for t in self.task_mode_dict
-        }
-
-    def _get_tasks_mode(self) -> Dict[int, ModeConsumption]:
-        return self.tasks_modes_rcpsp
-
-
-class Stochastic_RCPSP(MultiModeRCPSP_Stochastic_Durations):
-    def _get_max_horizon(self) -> int:
-        return self.max_horizon
-
-    def _get_objectives(self) -> List[SchedulingObjectiveEnum]:
-        return [SchedulingObjectiveEnum.MAKESPAN]
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        return self.successors
-
-    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        return self.task_ids
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        return self.task_mode_dict
-
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> Distribution:
-        return self.duration_distribution[task][mode]
-
-    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        return self.resource_availability[resource]
-
-    def _get_resource_types_names(self) -> List[str]:
-        return self.resource_names
-
-    def __init__(
-        self,
-        resource_names: List[str] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, ModeConsumption]] = None,  # ressource
-        duration_distribution: Dict[int, Dict[int, DiscreteDistribution]] = None,
-        successors: Dict[int, List[int]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, int] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        self.resource_names = resource_names
-        self.task_ids = task_ids
-        self.tasks_mode = tasks_mode
-        # transform the "mode_details" dict that we largely used in DO in the good format.
-        self.task_mode_dict = self.tasks_mode
-        self.duration_distribution = duration_distribution
-        self.successors = successors
-        self.max_horizon = max_horizon
-        self.resource_availability = resource_availability
-        self.resource_renewable = resource_renewable
-        self.initialize_domain()
-
-
-def build_stochastic_from_deterministic(rcpsp: MRCPSP, task_to_noise: Set[int] = None):
-    if task_to_noise is None:
-        task_to_noise = set(rcpsp.get_tasks_ids())
-    duration_distribution = {}
-    for task_id in rcpsp.get_tasks_ids():
-        duration_distribution[task_id] = {}
-        for mode in rcpsp.get_task_modes(task_id=task_id):
-            duration = rcpsp.get_task_duration(task=task_id, mode=mode)
-            if duration == 0 or task_id not in task_to_noise:
-                distrib = DiscreteDistribution(values=[(duration, 1)])
-            else:
-                n = 10
-                distrib = DiscreteDistribution(
-                    values=[
-                        (max(1, duration + i), 1 / (2 * n + 1))
-                        for i in range(-n, n + 1)
-                    ]
-                )
-            duration_distribution[task_id][mode] = distrib
-
-    return Stochastic_RCPSP(
-        resource_names=rcpsp.get_resource_types_names(),
-        task_ids=rcpsp.get_tasks_ids(),
-        tasks_mode=rcpsp.get_tasks_modes(),  # ressource
-        duration_distribution=duration_distribution,
-        successors=rcpsp.successors,
-        max_horizon=rcpsp.max_horizon * 2,
-        resource_availability=rcpsp.resource_availability,
-        resource_renewable=rcpsp.resource_renewable,
-    )
-
-
-def build_n_determinist_from_stochastic(srcpsp: Stochastic_RCPSP, nb_instance: int):
-    instances = []
-    for i in range(nb_instance):
-        modes = srcpsp.get_tasks_modes()
-        modes_for_rcpsp = {
-            task: {
-                mode: {
-                    r: modes[task][mode].get_resource_need_at_time(r, 0)
-                    for r in modes[task][mode].get_ressource_names()
-                }
-                for mode in modes[task]
-            }
-            for task in modes
-        }
-        for t in modes_for_rcpsp:
-            for m in modes_for_rcpsp[t]:
-                duration = srcpsp.sample_task_duration(task=t, mode=m)
-                modes_for_rcpsp[t][m]["duration"] = duration
-
-        resource_availability_dict = {}
-        for r in srcpsp.get_resource_types_names():
-            resource_availability_dict[r] = srcpsp.get_original_quantity_resource(r)
-
-        instances += [
-            MRCPSP(
-                resource_names=srcpsp.get_resource_types_names(),
-                task_ids=srcpsp.get_tasks_ids(),
-                tasks_mode=modes_for_rcpsp,  # ressource
-                successors=srcpsp.successors,
-                # max_horizon=srcpsp.max_horizon,
-                max_horizon=srcpsp.get_max_horizon(),
-                # resource_availability=srcpsp.resource_availability,
-                resource_availability=resource_availability_dict,
-                resource_renewable=srcpsp.get_resource_renewability()
-                # resource_renewable=srcpsp.resource_renewable
-            )
-        ]
-    return instances
-
-
-class D(MultiModeRCPSPCalendar_Stochastic_Durations):
-    pass
-
-
-class SMRCPSPCalendar(D):
-    def _get_task_duration_distribution(
-        self,
-        task: int,
-        mode: Optional[int] = 1,
-        progress_from: Optional[float] = 0.0,
-        multivariate_settings: Optional[Dict[str, int]] = None,
-    ) -> Distribution:
-        return self.duration_distribution[task][mode]
-
-    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        return self.resource_availability[resource][time]
-
-    def __init__(
-        self,
-        resource_names: List[str] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
-        successors: Dict[int, List[int]] = None,
-        duration_distribution: Dict[int, Dict[int, DiscreteDistribution]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, List[int]] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        self.resource_names = resource_names
-        self.task_ids = task_ids
-        self.tasks_mode = tasks_mode
-        # transform the "mode_details" dict that we largely used in DO in the good format.
-        self.task_mode_dict = {}
-        self.duration_dict = {}
-        for task in self.tasks_mode:
-            self.task_mode_dict[task] = {}
-            self.duration_dict[task] = {}
-            for mode in self.tasks_mode[task]:
-                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
-                for r in self.tasks_mode[task][mode]:
-                    if r in self.resource_names:
-                        self.task_mode_dict[task][mode].mode_details[r] = [
-                            self.tasks_mode[task][mode][r]
-                        ]
-                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
-        self.successors = successors
-        self.max_horizon = max_horizon
-        self.resource_availability = resource_availability
-        self.resource_renewable = resource_renewable
-        self.duration_distribution = duration_distribution
-        self.initialize_domain()
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        return self.task_mode_dict
-
-    def _get_resource_renewability(self) -> Dict[str, bool]:
-        return self.resource_renewable
-
-    def _get_max_horizon(self) -> int:
-        return self.max_horizon
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        return self.successors
-
-    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        return self.task_ids
-
-    def _get_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        return self.duration_dict[task][mode]
-
-    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        # return self.resource_availability[resource]
-        return self.original_resource_availability[resource]
-
-    def _get_resource_types_names(self) -> List[str]:
-        return self.resource_names
-
-    def _get_objectives(self) -> List[int]:
-        return [SchedulingObjectiveEnum.MAKESPAN]
-
-
-class D(MultiModeMultiSkillRCPSP):
-    pass
-
-
-class MSRCPSP(D):
-    def __init__(
-        self,
-        skills_names: List[str] = None,
-        resource_unit_names: List[str] = None,
-        resource_type_names: List[str] = None,
-        resource_skills: Dict[str, Dict[str, Any]] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
-        successors: Dict[int, List[int]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, int] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        self.skills_set = set(skills_names)
-        self.resource_unit_names = resource_unit_names
-        self.resource_type_names = resource_type_names
-        self.resource_skills = resource_skills
-        self.task_ids = task_ids
-        self.tasks_mode = tasks_mode
-        # transform the "mode_details" dict that we largely used in DO in the good format.
-        self.task_mode_dict = {}
-        self.task_skills_dict = {}
-        self.duration_dict = {}
-        for task in self.tasks_mode:
-            self.task_mode_dict[task] = {}
-            self.task_skills_dict[task] = {}
-            self.duration_dict[task] = {}
-            for mode in self.tasks_mode[task]:
-                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
-                self.task_skills_dict[task][mode] = {}
-                for r in self.tasks_mode[task][mode]:
-                    if r in self.resource_type_names:
-                        self.task_mode_dict[task][mode].mode_details[r] = [
-                            self.tasks_mode[task][mode][r]
-                        ]
-                    if r in self.skills_set:
-                        self.task_skills_dict[task][mode][r] = self.tasks_mode[task][
-                            mode
-                        ][r]
-                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
-        self.successors = successors
-        self.max_horizon = max_horizon
-        self.resource_availability = resource_availability
-        self.resource_renewable = resource_renewable
-        self.initialize_domain()
-
-    def _get_resource_units_names(self) -> List[str]:
-        """Return the names (string) of all resource units as a list."""
-        return self.resource_unit_names
-
-    def _get_resource_types_names(self) -> List[str]:
-        return self.resource_type_names
-
-    def _get_resource_type_for_unit(self) -> Dict[str, str]:
-        """Return a dictionary where the key is a resource unit name and the value a resource type name.
-        An empty dictionary can be used if there are no resource unit matching a resource type."""
-        return None
-
-    def get_max_horizon(self) -> int:
-        return self.max_horizon
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        return self.task_mode_dict
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        return self.successors
-
-    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        return self.task_ids
-
-    def _get_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        return self.duration_dict[task][mode]
-
-    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        return self.resource_availability[resource]
-
-    def _get_resource_renewability(self) -> Dict[str, bool]:
-        return self.resource_renewable
-
-    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
-        return self.resource_skills
-
-    def _get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
-        return self.task_skills_dict
-
-    def _get_objectives(self) -> List[int]:
-        return [SchedulingObjectiveEnum.MAKESPAN]
-
-
-class D(MultiModeMultiSkillRCPSPCalendar):
-    pass
-
-
-class MSRCPSPCalendar(D):
-    def _get_max_horizon(self) -> int:
-        return self.max_horizon
-
-    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
-        return self.resource_availability[resource][time]
-
-    def __init__(
-        self,
-        skills_names: List[str] = None,
-        resource_unit_names: List[str] = None,
-        resource_type_names: List[str] = None,
-        resource_skills: Dict[str, Dict[str, Any]] = None,
-        task_ids: List[int] = None,
-        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
-        successors: Dict[int, List[int]] = None,
-        max_horizon: int = None,
-        resource_availability: Dict[str, List[int]] = None,
-        resource_renewable: Dict[str, bool] = None,
-    ):
-        self.skills_set = set(skills_names)
-        self.resource_unit_names = resource_unit_names
-        self.resource_type_names = resource_type_names
-        self.resource_skills = resource_skills
-        self.task_ids = task_ids
-        self.tasks_mode = tasks_mode
-        # transform the "mode_details" dict that we largely used in DO in the good format.
-        self.task_mode_dict = {}
-        self.task_skills_dict = {}
-        self.duration_dict = {}
-        for task in self.tasks_mode:
-            self.task_mode_dict[task] = {}
-            self.task_skills_dict[task] = {}
-            self.duration_dict[task] = {}
-            for mode in self.tasks_mode[task]:
-                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
-                self.task_skills_dict[task][mode] = {}
-                for r in self.tasks_mode[task][mode]:
-                    if r in self.resource_type_names:
-                        self.task_mode_dict[task][mode].mode_details[r] = [
-                            self.tasks_mode[task][mode][r]
-                        ]
-                    if r in self.skills_set:
-                        self.task_skills_dict[task][mode][r] = self.tasks_mode[task][
-                            mode
-                        ][r]
-                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
-        self.successors = successors
-        self.max_horizon = max_horizon
-        self.resource_availability = resource_availability
-        self.resource_renewable = resource_renewable
-        self.initialize_domain()
-
-    def _get_resource_units_names(self) -> List[str]:
-        """Return the names (string) of all resource units as a list."""
-        return self.resource_unit_names
-
-    def _get_resource_types_names(self) -> List[str]:
-        return self.resource_type_names
-
-    def _get_resource_type_for_unit(self) -> Dict[str, str]:
-        """Return a dictionary where the key is a resource unit name and the value a resource type name.
-        An empty dictionary can be used if there are no resource unit matching a resource type."""
-        return None
-
-    def get_max_horizon(self) -> int:
-        return self.max_horizon
-
-    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
-        return self.task_mode_dict
-
-    def _get_successors(self) -> Dict[int, List[int]]:
-        return self.successors
-
-    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
-        return self.task_ids
-
-    def _get_task_duration(
-        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
-    ) -> int:
-        return self.duration_dict[task][mode]
-
-    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
-        return self.resource_availability[resource]
-
-    def _get_resource_renewability(self) -> Dict[str, bool]:
-        return self.resource_renewable
-
-    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
-        return self.resource_skills
-
-    def _get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
-        return self.task_skills_dict
-
-    def _get_objectives(self) -> List[int]:
-        return [SchedulingObjectiveEnum.MAKESPAN]
-
-
-if __name__ == "__main__":
-    from skdecide.hub.domain.rcpsp.rcpsp_sk_parser import load_domain
-
-    domain = load_domain()
-    state = domain.get_initial_state()
-    print("Initial state : ", state)
-    actions = domain.get_applicable_actions(state)
-    print([str(action) for action in actions.get_elements()])
-    action = actions.get_elements()[0]
-    new_state = domain.get_next_state(state, action)
-    print("New state ", new_state)
-    actions = domain.get_applicable_actions(new_state)
-    print("New actions : ", [str(action) for action in actions.get_elements()])
-    action = actions.get_elements()[0]
-    print(action)
-    new_state = domain.get_next_state(new_state, action)
-    print("New state :", new_state)
-    print("_is_terminal: ", domain._is_terminal(state))
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Dict, List, Optional, Set, Union
+
+from skdecide import DiscreteDistribution, Distribution
+from skdecide.builders.domain.scheduling.modes import (
+    ConstantModeConsumption,
+    ModeConsumption,
+)
+from skdecide.builders.domain.scheduling.scheduling_domains import (
+    MultiModeMultiSkillRCPSP,
+    MultiModeMultiSkillRCPSPCalendar,
+    MultiModeRCPSP,
+    MultiModeRCPSP_Stochastic_Durations,
+    MultiModeRCPSPCalendar,
+    MultiModeRCPSPCalendar_Stochastic_Durations,
+    SchedulingObjectiveEnum,
+    SingleMode,
+)
+
+
+class D(MultiModeRCPSP):
+    pass
+
+
+class MRCPSP(D):
+    """Multimode RCPSP domain
+
+    # Attributes
+     resource_names: list of resource names
+    task_ids: list of tasks ids
+    tasks_mode: dictionary giving details of resource consumption and duration for each tasks/modes :
+      format is the following : {task_id: {mode_1: {"duration": 2, "res_1": 1}, mode_2: {"duration": 3, "res_2": 2}}}
+    successors: dictionary of precedence constraint:
+      format is the following {task_id: List[task_id]}, where the values are the list of successor task of a given task_id
+    max_horizon: the max horizon for scheduling
+    resource_availability: for each resource, gives its (constant) capacity
+    resource_renewable: for each resource, indicates if it's renewable or not
+    """
+
+    def __init__(
+        self,
+        resource_names: List[str] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
+        successors: Dict[int, List[int]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, int] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        self.resource_names = resource_names
+        self.task_ids = task_ids
+        self.tasks_mode = tasks_mode
+        # transform the "mode_details" dict that we largely used in DO in the good format.
+        self.task_mode_dict = {}
+        self.duration_dict = {}
+        for task in self.tasks_mode:
+            self.task_mode_dict[task] = {}
+            self.duration_dict[task] = {}
+            for mode in self.tasks_mode[task]:
+                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
+                for r in self.tasks_mode[task][mode]:
+                    if r in self.resource_names:
+                        self.task_mode_dict[task][mode].mode_details[r] = [
+                            self.tasks_mode[task][mode][r]
+                        ]
+                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
+        self.successors = successors
+        self.max_horizon = max_horizon
+        self.resource_availability = resource_availability
+        self.resource_renewable = resource_renewable
+        self.initialize_domain()
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        return self.task_mode_dict
+
+    def _get_resource_renewability(self) -> Dict[str, bool]:
+        return self.resource_renewable
+
+    def _get_max_horizon(self) -> int:
+        return self.max_horizon
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        return self.successors
+
+    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        return self.task_ids
+
+    def _get_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        return self.duration_dict[task][mode]
+
+    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        return self.resource_availability[resource]
+
+    def _get_resource_types_names(self) -> List[str]:
+        return self.resource_names
+
+    def _get_objectives(self) -> List[int]:
+        return [SchedulingObjectiveEnum.MAKESPAN]
+
+
+class D(MultiModeRCPSPCalendar):
+    pass
+
+
+class MRCPSPCalendar(D):
+    """Multimode RCPSP with calendars domain
+
+    # Attributes
+    resource_names: list of resource names
+    task_ids: list of tasks ids
+    tasks_mode: dictionary giving details of resource consumption and duration for each tasks/modes :
+      format is the following : {task_id: {mode_1: {"duration": 2, "res_1": 1}, mode_2: {"duration": 3, "res_2": 2}}}
+    successors: dictionary of precedence constraint:
+      format is the following {task_id: List[task_id]}, where the values are the list of successor task of a given task_id
+    max_horizon: the max horizon for scheduling
+    resource_availability: for each resource, gives its capacity through time as a list of integer
+    resource_renewable: for each resource, indicates if it's renewable or not
+    """
+
+    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        return self.resource_availability[resource][time]
+
+    def __init__(
+        self,
+        resource_names: List[str] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
+        successors: Dict[int, List[int]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, List[int]] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        self.resource_names = resource_names
+        self.task_ids = task_ids
+        self.tasks_mode = tasks_mode
+        # transform the "mode_details" dict that we largely used in DO in the good format.
+        self.task_mode_dict = {}
+        self.duration_dict = {}
+        for task in self.tasks_mode:
+            self.task_mode_dict[task] = {}
+            self.duration_dict[task] = {}
+            for mode in self.tasks_mode[task]:
+                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
+                for r in self.tasks_mode[task][mode]:
+                    if r in self.resource_names:
+                        self.task_mode_dict[task][mode].mode_details[r] = [
+                            self.tasks_mode[task][mode][r]
+                        ]
+                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
+        self.successors = successors
+        self.max_horizon = max_horizon
+        self.resource_availability = resource_availability
+        self.original_resource_availability = {
+            r: max(self.resource_availability[r]) for r in self.resource_availability
+        }
+
+        self.resource_renewable = resource_renewable
+        self.initialize_domain()
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        return self.task_mode_dict
+
+    def _get_resource_renewability(self) -> Dict[str, bool]:
+        return self.resource_renewable
+
+    def _get_max_horizon(self) -> int:
+        return self.max_horizon
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        return self.successors
+
+    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        return self.task_ids
+
+    def _get_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        return self.duration_dict[task][mode]
+
+    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        return self.original_resource_availability[resource]
+
+    def _get_resource_types_names(self) -> List[str]:
+        return self.resource_names
+
+    def _get_objectives(self) -> List[int]:
+        return [SchedulingObjectiveEnum.MAKESPAN]
+
+
+class RCPSP(MRCPSP, SingleMode):
+    """Monomode RCPSP domain
+
+    # Attributes
+    resource_names: list of resource names
+    task_ids: list of tasks ids
+    tasks_mode: dictionary giving details of resource consumption and duration for each tasks :
+      format is the following : {task_id: {1: {"duration": 2, "res_1": 1}}, only 1 mode in this template
+    successors: dictionary of precedence constraint:
+      format is the following {task_id: List[task_id]}, where the values are the list of successor task of a given task_id
+    max_horizon: the max horizon for scheduling
+    resource_availability: for each resource, gives its constant capacity
+    resource_renewable: for each resource, indicates if it's renewable or not
+    """
+
+    def __init__(
+        self,
+        resource_names: List[str] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
+        successors: Dict[int, List[int]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, int] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        MRCPSP.__init__(
+            self,
+            resource_names=resource_names,
+            task_ids=task_ids,
+            tasks_mode=tasks_mode,
+            successors=successors,
+            max_horizon=max_horizon,
+            resource_availability=resource_availability,
+            resource_renewable=resource_renewable,
+        )
+        self.tasks_modes_rcpsp = {
+            t: self.task_mode_dict[t][1] for t in self.task_mode_dict
+        }
+
+    def _get_tasks_mode(self) -> Dict[int, ModeConsumption]:
+        return self.tasks_modes_rcpsp
+
+
+class RCPSPCalendar(MRCPSPCalendar, SingleMode):
+    """Monomode RCPSP with calendars domain
+
+    # Attributes
+    resource_names: list of resource names
+    task_ids: list of tasks ids
+    tasks_mode: dictionary giving details of resource consumption and duration for each tasks :
+      format is the following : {task_id: {1: {"duration": 2, "res_1": 1}}, only 1 mode in this template
+    successors: dictionary of precedence constraint:
+      format is the following {task_id: List[task_id]}, where the values are the list of successor task of a given task_id
+    max_horizon: the max horizon for scheduling
+    resource_availability: for each resource, gives its capacity through time
+    resource_renewable: for each resource, indicates if it's renewable or not
+    """
+
+    def __init__(
+        self,
+        resource_names: List[str] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
+        successors: Dict[int, List[int]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, List[int]] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        MRCPSPCalendar.__init__(
+            self,
+            resource_names=resource_names,
+            task_ids=task_ids,
+            tasks_mode=tasks_mode,
+            successors=successors,
+            max_horizon=max_horizon,
+            resource_availability=resource_availability,
+            resource_renewable=resource_renewable,
+        )
+        self.tasks_modes_rcpsp = {
+            t: self.task_mode_dict[t][1] for t in self.task_mode_dict
+        }
+
+    def _get_tasks_mode(self) -> Dict[int, ModeConsumption]:
+        return self.tasks_modes_rcpsp
+
+
+class Stochastic_RCPSP(MultiModeRCPSP_Stochastic_Durations):
+    """Stochastic RCPSP
+
+    # Attributes
+    resource_names: list of resource names
+    task_ids: list of tasks ids
+    tasks_mode: dictionary giving details of resource consumption and duration for each tasks :
+      format is the following : {task_id: {1: {"res_1": 1}, 2: {"res_1": 2}}
+    duration_distribution: dictionary giving distribution of task duration function of mode.
+    successors: dictionary of precedence constraint:
+      format is the following {task_id: List[task_id]}, where the values are the list of successor task of a given task_id
+    max_horizon: the max horizon for scheduling
+    resource_availability: for each resource, gives its constant capacity
+    resource_renewable: for each resource, indicates if it's renewable or not
+    """
+
+    def _get_max_horizon(self) -> int:
+        return self.max_horizon
+
+    def _get_objectives(self) -> List[SchedulingObjectiveEnum]:
+        return [SchedulingObjectiveEnum.MAKESPAN]
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        return self.successors
+
+    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        return self.task_ids
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        return self.task_mode_dict
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> Distribution:
+        return self.duration_distribution[task][mode]
+
+    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        return self.resource_availability[resource]
+
+    def _get_resource_types_names(self) -> List[str]:
+        return self.resource_names
+
+    def __init__(
+        self,
+        resource_names: List[str] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, ModeConsumption]] = None,
+        duration_distribution: Dict[int, Dict[int, DiscreteDistribution]] = None,
+        successors: Dict[int, List[int]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, int] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        self.resource_names = resource_names
+        self.task_ids = task_ids
+        self.tasks_mode = tasks_mode
+        # transform the "mode_details" dict that we largely used in DO in the good format.
+        self.task_mode_dict = self.tasks_mode
+        self.duration_distribution = duration_distribution
+        self.successors = successors
+        self.max_horizon = max_horizon
+        self.resource_availability = resource_availability
+        self.resource_renewable = resource_renewable
+        self.initialize_domain()
+
+
+def build_stochastic_from_deterministic(rcpsp: MRCPSP, task_to_noise: Set[int] = None):
+    if task_to_noise is None:
+        task_to_noise = set(rcpsp.get_tasks_ids())
+    duration_distribution = {}
+    for task_id in rcpsp.get_tasks_ids():
+        duration_distribution[task_id] = {}
+        for mode in rcpsp.get_task_modes(task_id=task_id):
+            duration = rcpsp.get_task_duration(task=task_id, mode=mode)
+            if duration == 0 or task_id not in task_to_noise:
+                distrib = DiscreteDistribution(values=[(duration, 1)])
+            else:
+                n = 10
+                distrib = DiscreteDistribution(
+                    values=[
+                        (max(1, duration + i), 1 / (2 * n + 1))
+                        for i in range(-n, n + 1)
+                    ]
+                )
+            duration_distribution[task_id][mode] = distrib
+
+    return Stochastic_RCPSP(
+        resource_names=rcpsp.get_resource_types_names(),
+        task_ids=rcpsp.get_tasks_ids(),
+        tasks_mode=rcpsp.get_tasks_modes(),  # ressource
+        duration_distribution=duration_distribution,
+        successors=rcpsp.successors,
+        max_horizon=rcpsp.max_horizon * 2,
+        resource_availability=rcpsp.resource_availability,
+        resource_renewable=rcpsp.resource_renewable,
+    )
+
+
+def build_n_determinist_from_stochastic(srcpsp: Stochastic_RCPSP, nb_instance: int):
+    instances = []
+    for i in range(nb_instance):
+        modes = srcpsp.get_tasks_modes()
+        modes_for_rcpsp = {
+            task: {
+                mode: {
+                    r: modes[task][mode].get_resource_need_at_time(r, 0)
+                    for r in modes[task][mode].get_ressource_names()
+                }
+                for mode in modes[task]
+            }
+            for task in modes
+        }
+        for t in modes_for_rcpsp:
+            for m in modes_for_rcpsp[t]:
+                duration = srcpsp.sample_task_duration(task=t, mode=m)
+                modes_for_rcpsp[t][m]["duration"] = duration
+
+        resource_availability_dict = {}
+        for r in srcpsp.get_resource_types_names():
+            resource_availability_dict[r] = srcpsp.get_original_quantity_resource(r)
+
+        instances += [
+            MRCPSP(
+                resource_names=srcpsp.get_resource_types_names(),
+                task_ids=srcpsp.get_tasks_ids(),
+                tasks_mode=modes_for_rcpsp,  # ressource
+                successors=srcpsp.successors,
+                # max_horizon=srcpsp.max_horizon,
+                max_horizon=srcpsp.get_max_horizon(),
+                # resource_availability=srcpsp.resource_availability,
+                resource_availability=resource_availability_dict,
+                resource_renewable=srcpsp.get_resource_renewability()
+                # resource_renewable=srcpsp.resource_renewable
+            )
+        ]
+    return instances
+
+
+class D(MultiModeRCPSPCalendar_Stochastic_Durations):
+    pass
+
+
+class SMRCPSPCalendar(D):
+    """Stochastic RCPSP With calendars domain
+
+    # Attributes
+    resource_names: list of resource names
+    task_ids: list of tasks ids
+    tasks_mode: dictionary giving details of resource consumption and duration for each tasks :
+      format is the following : {task_id: {1: {"res_1": 1}, 2: {"res_1": 2}}
+    duration_distribution: dictionary giving distribution of task duration function of mode.
+    successors: dictionary of precedence constraint:
+      format is the following {task_id: List[task_id]}, where the values are the list of successor task of a given task_id
+    max_horizon: the max horizon for scheduling
+    resource_availability: for each resource, gives its variable capacity
+    resource_renewable: for each resource, indicates if it's renewable or not
+    """
+
+    def _get_task_duration_distribution(
+        self,
+        task: int,
+        mode: Optional[int] = 1,
+        progress_from: Optional[float] = 0.0,
+        multivariate_settings: Optional[Dict[str, int]] = None,
+    ) -> Distribution:
+        return self.duration_distribution[task][mode]
+
+    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        return self.resource_availability[resource][time]
+
+    def __init__(
+        self,
+        resource_names: List[str] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
+        successors: Dict[int, List[int]] = None,
+        duration_distribution: Dict[int, Dict[int, DiscreteDistribution]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, List[int]] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        self.resource_names = resource_names
+        self.task_ids = task_ids
+        self.tasks_mode = tasks_mode
+        # transform the "mode_details" dict that we largely used in DO in the good format.
+        self.task_mode_dict = {}
+        self.duration_dict = {}
+        for task in self.tasks_mode:
+            self.task_mode_dict[task] = {}
+            self.duration_dict[task] = {}
+            for mode in self.tasks_mode[task]:
+                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
+                for r in self.tasks_mode[task][mode]:
+                    if r in self.resource_names:
+                        self.task_mode_dict[task][mode].mode_details[r] = [
+                            self.tasks_mode[task][mode][r]
+                        ]
+                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
+        self.successors = successors
+        self.max_horizon = max_horizon
+        self.resource_availability = resource_availability
+        self.resource_renewable = resource_renewable
+        self.duration_distribution = duration_distribution
+        self.initialize_domain()
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        return self.task_mode_dict
+
+    def _get_resource_renewability(self) -> Dict[str, bool]:
+        return self.resource_renewable
+
+    def _get_max_horizon(self) -> int:
+        return self.max_horizon
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        return self.successors
+
+    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        return self.task_ids
+
+    def _get_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        return self.duration_dict[task][mode]
+
+    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        # return self.resource_availability[resource]
+        return self.original_resource_availability[resource]
+
+    def _get_resource_types_names(self) -> List[str]:
+        return self.resource_names
+
+    def _get_objectives(self) -> List[int]:
+        return [SchedulingObjectiveEnum.MAKESPAN]
+
+
+class D(MultiModeMultiSkillRCPSP):
+    pass
+
+
+class MSRCPSP(D):
+    """Multi-skill RCPSP domain
+
+    # Attributes
+    skills_names: list of skills id
+    resource_unit_names: list of unitary skilled resource
+    resource_type_names: list of cumulative resource
+    resource_skills: for each resource_unit and skills store the skill level
+    others : see classical RCPSP doc
+    """
+
+    def __init__(
+        self,
+        skills_names: List[str] = None,
+        resource_unit_names: List[str] = None,
+        resource_type_names: List[str] = None,
+        resource_skills: Dict[str, Dict[str, Any]] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
+        successors: Dict[int, List[int]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, int] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        self.skills_set = set(skills_names)
+        self.resource_unit_names = resource_unit_names
+        self.resource_type_names = resource_type_names
+        self.resource_skills = resource_skills
+        self.task_ids = task_ids
+        self.tasks_mode = tasks_mode
+        # transform the "mode_details" dict that we largely used in DO in the good format.
+        self.task_mode_dict = {}
+        self.task_skills_dict = {}
+        self.duration_dict = {}
+        for task in self.tasks_mode:
+            self.task_mode_dict[task] = {}
+            self.task_skills_dict[task] = {}
+            self.duration_dict[task] = {}
+            for mode in self.tasks_mode[task]:
+                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
+                self.task_skills_dict[task][mode] = {}
+                for r in self.tasks_mode[task][mode]:
+                    if r in self.resource_type_names:
+                        self.task_mode_dict[task][mode].mode_details[r] = [
+                            self.tasks_mode[task][mode][r]
+                        ]
+                    if r in self.skills_set:
+                        self.task_skills_dict[task][mode][r] = self.tasks_mode[task][
+                            mode
+                        ][r]
+                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
+        self.successors = successors
+        self.max_horizon = max_horizon
+        self.resource_availability = resource_availability
+        self.resource_renewable = resource_renewable
+        self.initialize_domain()
+
+    def _get_resource_units_names(self) -> List[str]:
+        """Return the names (string) of all resource units as a list."""
+        return self.resource_unit_names
+
+    def _get_resource_types_names(self) -> List[str]:
+        return self.resource_type_names
+
+    def _get_resource_type_for_unit(self) -> Dict[str, str]:
+        """Return a dictionary where the key is a resource unit name and the value a resource type name.
+        An empty dictionary can be used if there are no resource unit matching a resource type."""
+        return None
+
+    def get_max_horizon(self) -> int:
+        return self.max_horizon
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        return self.task_mode_dict
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        return self.successors
+
+    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        return self.task_ids
+
+    def _get_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        return self.duration_dict[task][mode]
+
+    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        return self.resource_availability[resource]
+
+    def _get_resource_renewability(self) -> Dict[str, bool]:
+        return self.resource_renewable
+
+    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
+        return self.resource_skills
+
+    def _get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
+        return self.task_skills_dict
+
+    def _get_objectives(self) -> List[int]:
+        return [SchedulingObjectiveEnum.MAKESPAN]
+
+
+class D(MultiModeMultiSkillRCPSPCalendar):
+    pass
+
+
+class MSRCPSPCalendar(D):
+    """
+    Multi-skill RCPSP with calendars domain
+    Defined the same as classical MSRCPSP but with variable resource availability.
+    """
+
+    def _get_max_horizon(self) -> int:
+        return self.max_horizon
+
+    def _get_quantity_resource(self, resource: str, time: int, **kwargs) -> int:
+        return self.resource_availability[resource][time]
+
+    def __init__(
+        self,
+        skills_names: List[str] = None,
+        resource_unit_names: List[str] = None,
+        resource_type_names: List[str] = None,
+        resource_skills: Dict[str, Dict[str, Any]] = None,
+        task_ids: List[int] = None,
+        tasks_mode: Dict[int, Dict[int, Dict[str, int]]] = None,
+        successors: Dict[int, List[int]] = None,
+        max_horizon: int = None,
+        resource_availability: Dict[str, List[int]] = None,
+        resource_renewable: Dict[str, bool] = None,
+    ):
+        self.skills_set = set(skills_names)
+        self.resource_unit_names = resource_unit_names
+        self.resource_type_names = resource_type_names
+        self.resource_skills = resource_skills
+        self.task_ids = task_ids
+        self.tasks_mode = tasks_mode
+        # transform the "mode_details" dict that we largely used in DO in the good format.
+        self.task_mode_dict = {}
+        self.task_skills_dict = {}
+        self.duration_dict = {}
+        for task in self.tasks_mode:
+            self.task_mode_dict[task] = {}
+            self.task_skills_dict[task] = {}
+            self.duration_dict[task] = {}
+            for mode in self.tasks_mode[task]:
+                self.task_mode_dict[task][mode] = ConstantModeConsumption({})
+                self.task_skills_dict[task][mode] = {}
+                for r in self.tasks_mode[task][mode]:
+                    if r in self.resource_type_names:
+                        self.task_mode_dict[task][mode].mode_details[r] = [
+                            self.tasks_mode[task][mode][r]
+                        ]
+                    if r in self.skills_set:
+                        self.task_skills_dict[task][mode][r] = self.tasks_mode[task][
+                            mode
+                        ][r]
+                self.duration_dict[task][mode] = self.tasks_mode[task][mode]["duration"]
+        self.successors = successors
+        self.max_horizon = max_horizon
+        self.resource_availability = resource_availability
+        self.resource_renewable = resource_renewable
+        self.initialize_domain()
+
+    def _get_resource_units_names(self) -> List[str]:
+        """Return the names (string) of all resource units as a list."""
+        return self.resource_unit_names
+
+    def _get_resource_types_names(self) -> List[str]:
+        return self.resource_type_names
+
+    def _get_resource_type_for_unit(self) -> Dict[str, str]:
+        """Return a dictionary where the key is a resource unit name and the value a resource type name.
+        An empty dictionary can be used if there are no resource unit matching a resource type."""
+        return None
+
+    def get_max_horizon(self) -> int:
+        return self.max_horizon
+
+    def _get_tasks_modes(self) -> Dict[int, Dict[int, ModeConsumption]]:
+        return self.task_mode_dict
+
+    def _get_successors(self) -> Dict[int, List[int]]:
+        return self.successors
+
+    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:
+        return self.task_ids
+
+    def _get_task_duration(
+        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0
+    ) -> int:
+        return self.duration_dict[task][mode]
+
+    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:
+        return self.resource_availability[resource]
+
+    def _get_resource_renewability(self) -> Dict[str, bool]:
+        return self.resource_renewable
+
+    def _get_all_resources_skills(self) -> Dict[str, Dict[str, Any]]:
+        return self.resource_skills
+
+    def _get_all_tasks_skills(self) -> Dict[int, Dict[int, Dict[str, Any]]]:
+        return self.task_skills_dict
+
+    def _get_objectives(self) -> List[int]:
+        return [SchedulingObjectiveEnum.MAKESPAN]
+
+
+if __name__ == "__main__":
+    from skdecide.hub.domain.rcpsp.rcpsp_sk_parser import load_domain
+
+    domain = load_domain()
+    state = domain.get_initial_state()
+    print("Initial state : ", state)
+    actions = domain.get_applicable_actions(state)
+    print([str(action) for action in actions.get_elements()])
+    action = actions.get_elements()[0]
+    new_state = domain.get_next_state(state, action)
+    print("New state ", new_state)
+    actions = domain.get_applicable_actions(new_state)
+    print("New actions : ", [str(action) for action in actions.get_elements()])
+    action = actions.get_elements()[0]
+    print(action)
+    new_state = domain.get_next_state(new_state, action)
+    print("New state :", new_state)
+    print("_is_terminal: ", domain._is_terminal(state))
```

## skdecide/hub/domain/rcpsp/rcpsp_sk_parser.py

```diff
@@ -1,91 +1,92 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-# Load rcpsp domains from psplib files.
-# You need the discrete optimisation library to be able to use those.
-from typing import Union
-
-from skdecide.hub.domain.rcpsp.rcpsp_sk import MSRCPSP
-
-
-def load_domain(file_path):
-    from discrete_optimization.rcpsp.rcpsp_model import RCPSPModel
-    from discrete_optimization.rcpsp.rcpsp_parser import parse_file
-
-    from skdecide.hub.domain.rcpsp.rcpsp_sk import MRCPSP, RCPSP
-
-    rcpsp_model: RCPSPModel = parse_file(file_path)
-    if not rcpsp_model.is_rcpsp_multimode():
-        my_domain = RCPSP(
-            resource_names=rcpsp_model.resources_list,
-            task_ids=sorted(rcpsp_model.mode_details.keys()),
-            tasks_mode=rcpsp_model.mode_details,
-            successors=rcpsp_model.successors,
-            max_horizon=rcpsp_model.horizon,
-            resource_availability=rcpsp_model.resources,
-            resource_renewable={
-                r: r not in rcpsp_model.non_renewable_resources
-                for r in rcpsp_model.resources_list
-            },
-        )
-    else:
-        my_domain = MRCPSP(
-            resource_names=rcpsp_model.resources_list,
-            task_ids=sorted(rcpsp_model.mode_details.keys()),
-            tasks_mode=rcpsp_model.mode_details,
-            successors=rcpsp_model.successors,
-            max_horizon=rcpsp_model.horizon,
-            resource_availability=rcpsp_model.resources,
-            resource_renewable={
-                r: r not in rcpsp_model.non_renewable_resources
-                for r in rcpsp_model.resources_list
-            },
-        )
-
-    return my_domain
-
-
-def load_multiskill_domain(file_path):
-    from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill_parser import (
-        parse_file,
-    )
-
-    model_msrcpsp, new_tame_to_original_task_id = parse_file(
-        file_path, max_horizon=2000
-    )
-    resource_type_names = list(model_msrcpsp.resources_list)
-    resource_skills = {r: {} for r in resource_type_names}
-    resource_availability = {
-        r: model_msrcpsp.resources_availability[r][0]
-        for r in model_msrcpsp.resources_availability
-    }
-    resource_renewable = {
-        r: r not in model_msrcpsp.non_renewable_resources
-        for r in model_msrcpsp.resources_list
-    }
-    resource_unit_names = []
-    for employee in model_msrcpsp.employees:
-        resource_unit_names += ["employee-" + str(employee)]
-        resource_skills[resource_unit_names[-1]] = {}
-        resource_availability[resource_unit_names[-1]] = 1
-        resource_renewable[resource_unit_names[-1]] = True
-        for s in model_msrcpsp.employees[employee].dict_skill:
-            resource_skills[resource_unit_names[-1]][s] = (
-                model_msrcpsp.employees[employee].dict_skill[s].skill_value
-            )
-
-    return MSRCPSP(
-        skills_names=list(model_msrcpsp.skills_set),
-        resource_unit_names=resource_unit_names,
-        resource_type_names=resource_type_names,
-        resource_skills=resource_skills,
-        task_ids=sorted(model_msrcpsp.mode_details.keys()),
-        tasks_mode=model_msrcpsp.mode_details,
-        successors=model_msrcpsp.successors,
-        max_horizon=model_msrcpsp.horizon,
-        resource_availability=resource_availability,
-        resource_renewable=resource_renewable,
-    )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+# Load rcpsp domains from psplib files.
+# You need the discrete optimisation library to be able to use those.
+from typing import Union
+
+from skdecide.hub.domain.rcpsp.rcpsp_sk import MSRCPSP
+
+
+def load_domain(file_path):
+    """"""
+    from discrete_optimization.rcpsp.rcpsp_model import RCPSPModel
+    from discrete_optimization.rcpsp.rcpsp_parser import parse_file
+
+    from skdecide.hub.domain.rcpsp.rcpsp_sk import MRCPSP, RCPSP
+
+    rcpsp_model: RCPSPModel = parse_file(file_path)
+    if not rcpsp_model.is_rcpsp_multimode():
+        my_domain = RCPSP(
+            resource_names=rcpsp_model.resources_list,
+            task_ids=sorted(rcpsp_model.mode_details.keys()),
+            tasks_mode=rcpsp_model.mode_details,
+            successors=rcpsp_model.successors,
+            max_horizon=rcpsp_model.horizon,
+            resource_availability=rcpsp_model.resources,
+            resource_renewable={
+                r: r not in rcpsp_model.non_renewable_resources
+                for r in rcpsp_model.resources_list
+            },
+        )
+    else:
+        my_domain = MRCPSP(
+            resource_names=rcpsp_model.resources_list,
+            task_ids=sorted(rcpsp_model.mode_details.keys()),
+            tasks_mode=rcpsp_model.mode_details,
+            successors=rcpsp_model.successors,
+            max_horizon=rcpsp_model.horizon,
+            resource_availability=rcpsp_model.resources,
+            resource_renewable={
+                r: r not in rcpsp_model.non_renewable_resources
+                for r in rcpsp_model.resources_list
+            },
+        )
+
+    return my_domain
+
+
+def load_multiskill_domain(file_path):
+    from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill_parser import (
+        parse_file,
+    )
+
+    model_msrcpsp, new_tame_to_original_task_id = parse_file(
+        file_path, max_horizon=2000
+    )
+    resource_type_names = list(model_msrcpsp.resources_list)
+    resource_skills = {r: {} for r in resource_type_names}
+    resource_availability = {
+        r: model_msrcpsp.resources_availability[r][0]
+        for r in model_msrcpsp.resources_availability
+    }
+    resource_renewable = {
+        r: r not in model_msrcpsp.non_renewable_resources
+        for r in model_msrcpsp.resources_list
+    }
+    resource_unit_names = []
+    for employee in model_msrcpsp.employees:
+        resource_unit_names += ["employee-" + str(employee)]
+        resource_skills[resource_unit_names[-1]] = {}
+        resource_availability[resource_unit_names[-1]] = 1
+        resource_renewable[resource_unit_names[-1]] = True
+        for s in model_msrcpsp.employees[employee].dict_skill:
+            resource_skills[resource_unit_names[-1]][s] = (
+                model_msrcpsp.employees[employee].dict_skill[s].skill_value
+            )
+
+    return MSRCPSP(
+        skills_names=list(model_msrcpsp.skills_set),
+        resource_unit_names=resource_unit_names,
+        resource_type_names=resource_type_names,
+        resource_skills=resource_skills,
+        task_ids=sorted(model_msrcpsp.mode_details.keys()),
+        tasks_mode=model_msrcpsp.mode_details,
+        successors=model_msrcpsp.successors,
+        max_horizon=model_msrcpsp.horizon,
+        resource_availability=resource_availability,
+        resource_renewable=resource_renewable,
+    )
```

## skdecide/hub/domain/rock_paper_scissors/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .rock_paper_scissors import RockPaperScissors
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .rock_paper_scissors import RockPaperScissors
```

## skdecide/hub/domain/rock_paper_scissors/rock_paper_scissors.py

 * *Ordering differences only*

```diff
@@ -1,105 +1,105 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from enum import Enum
-from typing import NamedTuple, Optional
-
-from skdecide import Domain, Space, TransitionOutcome, Value
-from skdecide.builders.domain import *
-from skdecide.hub.space.gym import EnumSpace
-
-
-class Move(Enum):
-    rock = 0
-    paper = 1
-    scissors = 2
-
-
-class State(NamedTuple):
-    num_move: int
-
-
-class D(
-    Domain,
-    MultiAgent,
-    Sequential,
-    Environment,
-    UnrestrictedActions,
-    Initializable,
-    Markovian,
-    TransformedObservable,
-    Rewards,
-):
-    T_state = State  # Type of states
-    T_observation = Move  # Type of observations
-    T_event = Move  # Type of events
-    T_value = int  # Type of transition values (rewards or costs)
-    T_predicate = bool  # Type of logical checks
-    T_info = (
-        None  # Type of additional information given as part of an environment outcome
-    )
-
-
-class RockPaperScissors(D):
-    def __init__(self, max_moves: int = 10):
-        self._max_moves = max_moves
-
-    def get_agents(self):
-        return {"player1", "player2"}
-
-    def _state_step(
-        self, action: D.T_agent[D.T_concurrency[D.T_event]]
-    ) -> TransitionOutcome[
-        D.T_state,
-        D.T_agent[Value[D.T_value]],
-        D.T_agent[D.T_predicate],
-        D.T_agent[D.T_info],
-    ]:
-
-        # Get players' moves
-        move1, move2 = action["player1"], action["player2"]
-
-        # Compute rewards
-        r1, r2 = {
-            (Move.rock, Move.rock): (0, 0),
-            (Move.rock, Move.paper): (-1, 1),
-            (Move.rock, Move.scissors): (1, -1),
-            (Move.paper, Move.rock): (1, -1),
-            (Move.paper, Move.paper): (0, 0),
-            (Move.paper, Move.scissors): (-1, 1),
-            (Move.scissors, Move.rock): (-1, 1),
-            (Move.scissors, Move.paper): (1, -1),
-            (Move.scissors, Move.scissors): (0, 0),
-        }[move1, move2]
-
-        # Compute num_move increment
-        last_state = self._memory
-        num_move = last_state.num_move + 1
-
-        return TransitionOutcome(
-            state=State(num_move=num_move),
-            value={"player1": Value(reward=r1), "player2": Value(reward=r2)},
-            termination={k: (num_move >= self._max_moves) for k in self.get_agents()},
-        )
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        return {"player1": EnumSpace(Move), "player2": EnumSpace(Move)}
-
-    def _state_reset(self) -> D.T_state:
-        return State(num_move=0)
-
-    def _get_observation(
-        self,
-        state: D.T_state,
-        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    ) -> D.T_agent[D.T_observation]:
-        # The observation is simply the last opponent move (or Move.rock initially by default)
-        obs1 = action["player2"] if action is not None else Move.rock
-        obs2 = action["player1"] if action is not None else Move.rock
-        return {"player1": obs1, "player2": obs2}
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        return {"player1": EnumSpace(Move), "player2": EnumSpace(Move)}
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from enum import Enum
+from typing import NamedTuple, Optional
+
+from skdecide import Domain, Space, TransitionOutcome, Value
+from skdecide.builders.domain import *
+from skdecide.hub.space.gym import EnumSpace
+
+
+class Move(Enum):
+    rock = 0
+    paper = 1
+    scissors = 2
+
+
+class State(NamedTuple):
+    num_move: int
+
+
+class D(
+    Domain,
+    MultiAgent,
+    Sequential,
+    Environment,
+    UnrestrictedActions,
+    Initializable,
+    Markovian,
+    TransformedObservable,
+    Rewards,
+):
+    T_state = State  # Type of states
+    T_observation = Move  # Type of observations
+    T_event = Move  # Type of events
+    T_value = int  # Type of transition values (rewards or costs)
+    T_predicate = bool  # Type of logical checks
+    T_info = (
+        None  # Type of additional information given as part of an environment outcome
+    )
+
+
+class RockPaperScissors(D):
+    def __init__(self, max_moves: int = 10):
+        self._max_moves = max_moves
+
+    def get_agents(self):
+        return {"player1", "player2"}
+
+    def _state_step(
+        self, action: D.T_agent[D.T_concurrency[D.T_event]]
+    ) -> TransitionOutcome[
+        D.T_state,
+        D.T_agent[Value[D.T_value]],
+        D.T_agent[D.T_predicate],
+        D.T_agent[D.T_info],
+    ]:
+
+        # Get players' moves
+        move1, move2 = action["player1"], action["player2"]
+
+        # Compute rewards
+        r1, r2 = {
+            (Move.rock, Move.rock): (0, 0),
+            (Move.rock, Move.paper): (-1, 1),
+            (Move.rock, Move.scissors): (1, -1),
+            (Move.paper, Move.rock): (1, -1),
+            (Move.paper, Move.paper): (0, 0),
+            (Move.paper, Move.scissors): (-1, 1),
+            (Move.scissors, Move.rock): (-1, 1),
+            (Move.scissors, Move.paper): (1, -1),
+            (Move.scissors, Move.scissors): (0, 0),
+        }[move1, move2]
+
+        # Compute num_move increment
+        last_state = self._memory
+        num_move = last_state.num_move + 1
+
+        return TransitionOutcome(
+            state=State(num_move=num_move),
+            value={"player1": Value(reward=r1), "player2": Value(reward=r2)},
+            termination={k: (num_move >= self._max_moves) for k in self.get_agents()},
+        )
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        return {"player1": EnumSpace(Move), "player2": EnumSpace(Move)}
+
+    def _state_reset(self) -> D.T_state:
+        return State(num_move=0)
+
+    def _get_observation(
+        self,
+        state: D.T_state,
+        action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    ) -> D.T_agent[D.T_observation]:
+        # The observation is simply the last opponent move (or Move.rock initially by default)
+        obs1 = action["player2"] if action is not None else Move.rock
+        obs2 = action["player1"] if action is not None else Move.rock
+        return {"player1": obs1, "player2": obs2}
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        return {"player1": EnumSpace(Move), "player2": EnumSpace(Move)}
```

## skdecide/hub/domain/simple_grid_world/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .simple_grid_world import SimpleGridWorld
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .simple_grid_world import SimpleGridWorld
```

## skdecide/hub/domain/simple_grid_world/simple_grid_world.py

 * *Ordering differences only*

```diff
@@ -1,89 +1,89 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from enum import Enum
-from typing import NamedTuple, Optional
-
-from skdecide import DeterministicPlanningDomain, Space, Value
-from skdecide.builders.domain import UnrestrictedActions
-from skdecide.hub.space.gym import EnumSpace, ListSpace, MultiDiscreteSpace
-
-
-class State(NamedTuple):
-    x: int
-    y: int
-
-
-class Action(Enum):
-    up = 0
-    down = 1
-    left = 2
-    right = 3
-
-
-class D(DeterministicPlanningDomain, UnrestrictedActions):
-    T_state = State  # Type of states
-    T_observation = T_state  # Type of observations
-    T_event = Action  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_predicate = bool  # Type of logical checks
-    T_info = (
-        None  # Type of additional information given as part of an environment outcome
-    )
-
-
-class SimpleGridWorld(D):
-    def __init__(self, num_cols=10, num_rows=10):
-        self.num_cols = num_cols
-        self.num_rows = num_rows
-
-    def _get_next_state(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-    ) -> D.T_state:
-        if action == Action.left:
-            next_state = State(max(memory.x - 1, 0), memory.y)
-        if action == Action.right:
-            next_state = State(min(memory.x + 1, self.num_cols - 1), memory.y)
-        if action == Action.up:
-            next_state = State(memory.x, max(memory.y - 1, 0))
-        if action == Action.down:
-            next_state = State(memory.x, min(memory.y + 1, self.num_rows - 1))
-
-        return next_state
-
-    def _get_transition_value(
-        self,
-        memory: D.T_memory[D.T_state],
-        action: D.T_agent[D.T_concurrency[D.T_event]],
-        next_state: Optional[D.T_state] = None,
-    ) -> D.T_agent[Value[D.T_value]]:
-        if next_state.x == memory.x and next_state.y == memory.y:
-            cost = 2  # big penalty when hitting a wall
-        else:
-            cost = abs(next_state.x - memory.x) + abs(
-                next_state.y - memory.y
-            )  # every move costs 1
-
-        return Value(cost=cost)
-
-    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
-        return self._is_goal(state)
-
-    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
-        return EnumSpace(Action)
-
-    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
-        return ListSpace([State(x=self.num_cols - 1, y=self.num_rows - 1)])
-
-    def _get_initial_state_(self) -> D.T_state:
-        return State(x=0, y=0)
-
-    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
-        return MultiDiscreteSpace(
-            nvec=[self.num_cols, self.num_rows], element_class=State
-        )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from enum import Enum
+from typing import NamedTuple, Optional
+
+from skdecide import DeterministicPlanningDomain, Space, Value
+from skdecide.builders.domain import UnrestrictedActions
+from skdecide.hub.space.gym import EnumSpace, ListSpace, MultiDiscreteSpace
+
+
+class State(NamedTuple):
+    x: int
+    y: int
+
+
+class Action(Enum):
+    up = 0
+    down = 1
+    left = 2
+    right = 3
+
+
+class D(DeterministicPlanningDomain, UnrestrictedActions):
+    T_state = State  # Type of states
+    T_observation = T_state  # Type of observations
+    T_event = Action  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_predicate = bool  # Type of logical checks
+    T_info = (
+        None  # Type of additional information given as part of an environment outcome
+    )
+
+
+class SimpleGridWorld(D):
+    def __init__(self, num_cols=10, num_rows=10):
+        self.num_cols = num_cols
+        self.num_rows = num_rows
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_state:
+        if action == Action.left:
+            next_state = State(max(memory.x - 1, 0), memory.y)
+        if action == Action.right:
+            next_state = State(min(memory.x + 1, self.num_cols - 1), memory.y)
+        if action == Action.up:
+            next_state = State(memory.x, max(memory.y - 1, 0))
+        if action == Action.down:
+            next_state = State(memory.x, min(memory.y + 1, self.num_rows - 1))
+
+        return next_state
+
+    def _get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_state] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+        if next_state.x == memory.x and next_state.y == memory.y:
+            cost = 2  # big penalty when hitting a wall
+        else:
+            cost = abs(next_state.x - memory.x) + abs(
+                next_state.y - memory.y
+            )  # every move costs 1
+
+        return Value(cost=cost)
+
+    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:
+        return self._is_goal(state)
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        return EnumSpace(Action)
+
+    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
+        return ListSpace([State(x=self.num_cols - 1, y=self.num_rows - 1)])
+
+    def _get_initial_state_(self) -> D.T_state:
+        return State(x=0, y=0)
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        return MultiDiscreteSpace(
+            nvec=[self.num_cols, self.num_rows], element_class=State
+        )
```

## skdecide/hub/domain/up/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .up import SkUPAction, SkUPState, UPDomain
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .up import SkUPAction, SkUPState, UPDomain
```

## skdecide/hub/domain/up/up.py

```diff
@@ -1,551 +1,572 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from typing import Dict, List, Optional, Tuple, Union
-
-import numpy as np
-import unified_planning as up
-from numpy.typing import ArrayLike
-from unified_planning.engines.compilers.grounder import GrounderHelper
-from unified_planning.engines.sequential_simulator import (
-    UPSequentialSimulator,
-    evaluate_quality_metric,
-)
-from unified_planning.exceptions import UPValueError
-from unified_planning.model import FNode, InstantaneousAction, Problem, UPState
-from unified_planning.model.metrics import (
-    MaximizeExpressionOnFinalState,
-    Oversubscription,
-    TemporalOversubscription,
-)
-from unified_planning.plans import ActionInstance
-from unified_planning.shortcuts import Bool, FluentExp, Int, ObjectExp, Real
-
-from skdecide.core import EmptySpace, ImplicitSpace, Space, Value
-from skdecide.domains import DeterministicPlanningDomain
-from skdecide.hub.space.gym import ListSpace, SetSpace
-from skdecide.hub.space.gym.gym import BoxSpace, DictSpace, DiscreteSpace, GymSpace
-from skdecide.utils import logger
-
-
-class SkUPState:
-    def __init__(self, up_state: UPState):
-        self._up_state = up_state
-
-    @property
-    def up_state(self):
-        return self._up_state
-
-    def __hash__(self):
-        fs = set()
-        ci = self._up_state
-        while ci is not None:
-            fs.update(
-                (fn, v)
-                for fn, v in ci._values.items()
-                if fn.fluent().name != "total-cost"
-            )
-            ci = ci._father
-        return hash(frozenset(fs))
-
-    def __eq__(self, other):
-        sd = {}
-        ci = self._up_state
-        while ci is not None:
-            sd.update(
-                {
-                    fn: v
-                    for fn, v in ci._values.items()
-                    if fn.fluent().name != "total-cost"
-                }
-            )
-            ci = ci._father
-        od = {}
-        ci = other._up_state
-        while ci is not None:
-            od.update(
-                {
-                    fn: v
-                    for fn, v in ci._values.items()
-                    if fn.fluent().name != "total-cost"
-                }
-            )
-            ci = ci._father
-        return sd == od
-
-    def __repr__(self) -> str:
-        return repr(self._up_state)
-
-    def __str__(self) -> str:
-        return str(self._up_state)
-
-
-class SkUPAction:
-    def __init__(
-        self,
-        up_action: Union[InstantaneousAction, ActionInstance],
-        ungrounded_action: InstantaneousAction = None,
-        orig_params: Tuple[FNode, ...] = None,
-    ):
-        if not isinstance(up_action, (InstantaneousAction, ActionInstance)):
-            raise RuntimeError(
-                f"SkUPAction: action {up_action} must be an instance of either InstantaneousAction or ActionInstance"
-            )
-        self._up_action = up_action
-        self._ungrounded_action = ungrounded_action
-        self._orig_params = orig_params
-
-    @property
-    def up_action(self) -> InstantaneousAction:
-        return (
-            self._ungrounded_action
-            if self._ungrounded_action is not None
-            else self._up_action
-            if isinstance(self._up_action, InstantaneousAction)
-            else self._up_action.action
-        )
-
-    @property
-    def up_parameters(
-        self,
-    ) -> Union[List[up.model.parameter.Parameter], Tuple[up.model.FNode, ...]]:
-        return (
-            self._orig_params
-            if self._orig_params is not None
-            else self._up_action.parameters
-            if isinstance(self._up_action, InstantaneousAction)
-            else self._up_action.actual_parameters
-        )
-
-    def __hash__(self):
-        return (
-            hash(self._up_action)
-            if isinstance(self._up_action, InstantaneousAction)
-            else hash(
-                tuple([self._up_action.action, self._up_action.actual_parameters])
-            )
-        )
-
-    def __eq__(self, other):
-        return (
-            self._up_action == other._up_action
-            if isinstance(self._up_action, InstantaneousAction)
-            else tuple([self._up_action.action, self._up_action.actual_parameters])
-            == tuple([other._up_action.action, other._up_action.actual_parameters])
-        )
-
-    def __repr__(self) -> str:
-        return repr(self._up_action)
-
-    def __str__(self) -> str:
-        return str(self._up_action)
-
-
-class D(DeterministicPlanningDomain):
-    T_state = Union[SkUPState, DictSpace, BoxSpace]  # Type of states
-    T_observation = T_state  # Type of observations
-    T_event = SkUPAction  # Type of events
-    T_value = float  # Type of transition values (rewards or costs)
-    T_info = None  # Type of additional information in environment outcome
-
-
-class UPDomain(D):
-    """This class wraps Unified Planning problem as a scikit-decide domain.
-
-    !!! warning
-        Using this class requires unified_planning to be installed.
-    """
-
-    def __init__(
-        self,
-        problem: Problem,
-        fluent_domains: Dict[FNode, Tuple[Union[int, float], Union[int, float]]] = None,
-        state_encoding: str = "native",
-        action_encoding: str = "native",
-        **simulator_params,
-    ):
-        """Initialize UPDomain.
-
-        # Parameters
-        problem: The Unified Planning problem (Problem) to wrap.
-        fluent_domains: Dictionary of min and max fluent values by fluent represented as a Unified Planning's FNode (must be provided only if get_observation_space() is used)
-        state_encoding: Encoding of the state (observation) which must be one of "native", "dictionary" or "vector" (warning: if action_masking is "vector" then the state automatically becomes a dictionary which separates the action masking vector from the real state as defined here)
-        action_encoding: Encoding of the action which must be either "native" or "int"
-        simulator_params: Optional parameters to pass to the UP sequential simulator
-        """
-        self._problem = problem
-        # We might be in a different process from the one where the UP problem was created
-        # thus we must set the global environment to the one of the UP problem
-        up.environment.GLOBAL_ENVIRONMENT = self._problem._env
-        self._simulator = UPSequentialSimulator(
-            self._problem, error_on_failed_checks=True, **simulator_params
-        )
-        self._simulator_params = simulator_params
-        try:
-            self._total_cost = FluentExp(self._problem.fluent("total-cost"))
-        except UPValueError:
-            self._total_cost = None
-        self._transition_costs = {}
-        self._fluent_domains = fluent_domains
-        self._state_encoding = state_encoding
-        self._action_encoding = action_encoding
-        self._action_space = None  # not computed by default
-        self._observation_space = None  # not computed by default
-        self._fnodes_variables_map = None
-        self._fnodes_vars_ordering = None
-        self._states_up2np = None
-        self._states_np2up = None
-        self._actions_up2np = None
-        self._actions_np2up = None
-        if self._state_encoding != "native":
-            if self._state_encoding not in ["dictionary", "vector"]:
-                raise RuntimeError(
-                    "State encoding must be one of 'native', 'dictionary' or 'vector'"
-                )
-            self._init_state_encoding_()
-        if self._action_encoding != "native":
-            if self._action_encoding != "int":
-                raise RuntimeError("Action encoding must be either 'native' or 'int'")
-            self._init_action_encoding_()
-
-    def _init_state_encoding_(self):
-        def fnode_lower_bound(fn):
-            if fn.fluent().type.lower_bound is not None:
-                return fn.fluent().type.lower_bound
-            elif self._fluent_domains is not None and fn in self._fluent_domains:
-                return self._fluent_domains[fn][0]
-            else:
-                raise RuntimeError(
-                    f"Lower bound not provided for fluent expression {fn}"
-                )
-
-        def fnode_upper_bound(fn):
-            if fn.fluent().type.upper_bound is not None:
-                return fn.fluent().type.upper_bound
-            elif self._fluent_domains is not None and fn in self._fluent_domains:
-                return self._fluent_domains[fn][1]
-            else:
-                raise RuntimeError(
-                    f"Upper bound not provided for fluent expression {fn}"
-                )
-
-        self._fnodes_variables_map = {}
-        self._fnodes_vars_ordering = []
-        self._states_up2np = {}
-        self._states_np2up = {}
-        init_state = self._simulator.get_initial_state()
-        static_fluents = self._problem.get_static_fluents()
-        ci = init_state
-        while ci is not None:
-            for fn in ci._values.keys():
-                if (
-                    fn.fluent() not in static_fluents
-                    and fn.fluent().name != "total-cost"
-                ):
-                    self._fnodes_vars_ordering.append(fn)
-                    if fn.fluent().type.is_bool_type():
-                        self._fnodes_variables_map[fn] = (
-                            0,
-                            1,
-                            lambda b_fnode: int(b_fnode.constant_value()),
-                            lambda i_int: Bool(bool(i_int)),
-                        )
-                    elif fn.fluent().type.is_int_type():
-                        lb = int(fnode_lower_bound(fn))
-                        ub = int(fnode_upper_bound(fn))
-                        self._fnodes_variables_map[fn] = (
-                            (
-                                0,
-                                ub - lb + 1,
-                                lambda i_fnode, lb=lb: i_fnode.constant_value() - lb,
-                                lambda i_int, lb=lb: Int(i_int + lb),
-                            )
-                            if self._state_encoding == "dictionary"
-                            else (
-                                lb,
-                                ub,
-                                lambda i_fnode: int(i_fnode.constant_value()),
-                                lambda i_int: Int(i_int),
-                            )
-                        )
-                    elif fn.fluent().type.is_real_type():
-                        self._fnodes_variables_map[fn] = (
-                            float(fnode_lower_bound(fn)),
-                            float(fnode_upper_bound(fn)),
-                            lambda x_fnode: float(x_fnode.constant_value()),
-                            lambda x_float: Real(x_float),
-                        )
-                    elif fn.fluent().type.is_user_type():
-                        co = list(self._problem.objects(fn.fluent().type))
-                        o2i = {o: i for i, o in enumerate(co)}
-                        self._fnodes_variables_map[fn] = (
-                            0,
-                            len(co),
-                            lambda o_fnode, o2i=o2i: o2i[o_fnode.object()],
-                            lambda i_int, i2o=co: ObjectExp(i2o[i_int]),
-                        )
-                    elif fn.fluent().type.is_time_type():
-                        raise RuntimeError("Time types not handled by UPDomain")
-            ci = ci._father
-
-    def _convert_to_skup_state_(self, state):
-        if self._state_encoding == "native":
-            return state
-        elif self._state_encoding == "dictionary":
-            kstate = frozenset(state.items())
-            if kstate in self._states_np2up:
-                return self._states_np2up[kstate]
-            else:
-                values = {}
-                for fn, s in state.items():
-                    values[fn] = self._fnodes_variables_map[fn][3](s)
-                skup_state = SkUPState(UPState(values))
-                self._states_up2np[skup_state] = state
-                self._states_np2up[kstate] = skup_state
-                return skup_state
-        elif self._state_encoding == "vector":
-            kstate = tuple(state.flatten())
-            if kstate in self._states_np2up:
-                return self._states_np2up[kstate]
-            else:
-                values = {}
-                for i, fn in enumerate(self._fnodes_vars_ordering):
-                    values[fn] = self._fnodes_variables_map[fn][3](state.item(i))
-                skup_state = SkUPState(UPState(values))
-                self._states_up2np[skup_state] = state
-                self._states_np2up[kstate] = skup_state
-                return skup_state
-        else:
-            return None
-
-    def _convert_from_skup_state_(self, skup_state: SkUPState):
-        if self._state_encoding == "native":
-            return skup_state
-        elif self._state_encoding == "dictionary":
-            if skup_state in self._states_up2np:
-                return self._states_up2np[skup_state]
-            else:
-                state = {}
-                ci = skup_state._up_state
-                while ci is not None:
-                    for fn, val in ci._values.items():
-                        if fn in self._fnodes_variables_map:
-                            state[fn] = self._fnodes_variables_map[fn][2](val)
-                    ci = ci._father
-                self._states_np2up[frozenset(state.items())] = skup_state
-                self._states_up2np[skup_state] = state
-                return state
-        elif self._state_encoding == "vector":
-            if skup_state in self._states_up2np:
-                return self._states_up2np[skup_state]
-            else:
-                state = []
-                any_real = False
-                for fn in self._fnodes_vars_ordering:
-                    ci = skup_state._up_state
-                    while ci is not None:
-                        if fn in ci._values:
-                            state.append(
-                                self._fnodes_variables_map[fn][2](ci._values[fn])
-                            )
-                            break
-                        ci = ci._father
-                    any_real = any_real or fn.fluent().type.is_real_type()
-                state = np.array(state, dtype=np.float32 if any_real else np.int32)
-                self._states_np2up[tuple(state.flatten())] = skup_state
-                self._states_up2np[skup_state] = state
-                return state
-        else:
-            return None
-
-    def _init_action_encoding_(self):
-        # For actions, the numpy encoding is just an int
-        self._actions_np2up = [
-            SkUPAction(a[2], ungrounded_action=a[0], orig_params=a[1])
-            for a in GrounderHelper(self._problem).get_grounded_actions()
-            if a[2] is not None
-        ]
-        self._actions_up2np = {a: i for i, a in enumerate(self._actions_np2up)}
-
-    def _convert_to_skup_action_(self, action):
-        if self._action_encoding == "native":
-            return action
-        elif self._action_encoding == "int":
-            return self._actions_np2up[int(action)]
-        else:
-            return None
-
-    def _convert_from_skup_action_(self, skup_action: SkUPAction):
-        if self._action_encoding == "native":
-            return skup_action
-        elif self._action_encoding == "int":
-            return self._actions_map[skup_action]
-        else:
-            return None
-
-    def _get_next_state(self, memory: D.T_state, action: D.T_event) -> D.T_state:
-        state = self._convert_to_skup_state_(memory)
-        act = self._convert_to_skup_action_(action)
-        if self._total_cost is not None:
-            cost = state.up_state.get_value(self._total_cost).constant_value()
-        next_state = SkUPState(
-            self._simulator.apply(state.up_state, act.up_action, act.up_parameters)
-        )
-        if self._total_cost is not None:
-            cost = (
-                next_state.up_state.get_value(self._total_cost).constant_value() - cost
-            )
-            self._transition_costs[tuple([state, act, next_state])] = cost
-        next_state = self._convert_from_skup_state_(next_state)
-        return next_state
-
-    def _get_transition_value(
-        self,
-        memory: D.T_state,
-        action: D.T_event,
-        next_state: Optional[D.T_state] = None,
-    ) -> Value[D.T_value]:
-        if self._total_cost is not None:
-            transition = tuple(
-                [
-                    self._convert_to_skup_state_(memory),
-                    self._convert_to_skup_action_(action),
-                    self._convert_to_skup_state_(next_state),
-                ]
-            )
-            if transition in self._transition_costs:
-                return Value(cost=self._transition_costs[transition])
-        if len(self._problem.quality_metrics) > 0:
-            transition_cost = 0
-            state = self._convert_to_skup_state_(memory)
-            act = self._convert_to_skup_action_(action)
-            nstate = self._convert_to_skup_state_(next_state)
-            for qm in self._problem.quality_metrics:
-                metric = evaluate_quality_metric(
-                    self._simulator,
-                    qm,
-                    0,
-                    state.up_state,
-                    act.up_action,
-                    act.up_parameters,
-                    nstate.up_state,
-                )
-                if isinstance(
-                    qm,
-                    (
-                        MaximizeExpressionOnFinalState,
-                        Oversubscription,
-                        TemporalOversubscription,
-                    ),
-                ):
-                    transition_cost += -metric
-                else:
-                    transition_cost += metric
-            return Value(cost=transition_cost)
-        else:
-            logger.warning(
-                "UPDomain: requesting transition value whereas the 'total-cost' fluent or UP quality metrics are not defined will return NaN"
-            )
-            return Value(cost=float("Nan"))
-
-    def _is_terminal(self, memory: D.T_state) -> D.T_predicate:
-        state = self._convert_to_skup_state_(memory)
-        return self._simulator.is_goal(state.up_state)
-
-    def _get_action_space_(self) -> GymSpace[D.T_event]:
-        if self._action_space is None:
-            if self._action_encoding == "native":
-                # By default we don't initialize action encoding for actions
-                # since it is not highly expected that the action space will
-                # be requested from the user in "native" action encoding mode
-                if self._actions_np2up is None:
-                    self._init_action_encoding_()
-                self._action_space = ListSpace(self._actions_np2up)
-            elif self._action_encoding == "int":
-                self._action_space = DiscreteSpace(len(self._actions_np2up))
-            else:
-                return None
-        return self._action_space
-
-    def _get_applicable_actions_from(self, memory: D.T_state) -> GymSpace[D.T_event]:
-        state = self._convert_to_skup_state_(memory)
-        applicable_actions = [
-            SkUPAction(
-                self._simulator._ground_action(action, params),
-                ungrounded_action=action,
-                orig_params=params,
-            )
-            for action, params in self._simulator.get_applicable_actions(state.up_state)
-        ]
-        if self._action_encoding == "native":
-            # SetSpace requires to be non empty
-            return (
-                SetSpace(applicable_actions)
-                if len(applicable_actions) > 0
-                else EmptySpace()
-            )
-        elif self._action_encoding == "int":
-            # SetSpace requires to be non empty
-            return (
-                SetSpace([self._actions_up2np[a] for a in applicable_actions])
-                if len(applicable_actions) > 0
-                else EmptySpace()
-            )
-        else:
-            return None
-
-    def _get_goals_(self) -> Space[D.T_observation]:
-        return ImplicitSpace(lambda s: self._is_terminal(s))
-
-    def _get_initial_state_(self) -> D.T_state:
-        init_state = self._convert_from_skup_state_(
-            SkUPState(self._simulator.get_initial_state())
-        )
-        return init_state
-
-    def _get_observation_space_(self) -> GymSpace[D.T_observation]:
-        if self._observation_space is None:
-            if self._state_encoding == "native":
-                raise RuntimeError(
-                    "Observation space defined only for state encoding 'dictionary' or 'vector'"
-                )
-            elif self._state_encoding == "dictionary":
-                self._observation_space = DictSpace(
-                    {
-                        repr(fn): DiscreteSpace(2)
-                        if fn.fluent().type.is_bool_type()
-                        else DiscreteSpace(v[1])
-                        if fn.fluent().type.is_int_type()
-                        else BoxSpace(v[0], v[1])
-                        if fn.fluent().type.is_real_type()
-                        else DiscreteSpace(v[1])
-                        if fn.fluent().type.is_user_type()
-                        else None
-                        for fn, v in self._fnodes_variables_map.items()
-                    }
-                )
-            elif self._state_encoding == "vector":
-                self._observation_space = BoxSpace(
-                    low=np.array(
-                        [
-                            self._fnodes_variables_map[fn][0]
-                            for fn in self._fnodes_vars_ordering
-                        ]
-                    ),
-                    high=np.array(
-                        [
-                            self._fnodes_variables_map[fn][1]
-                            for fn in self._fnodes_vars_ordering
-                        ]
-                    ),
-                    dtype=np.float32
-                    if any(
-                        fn.fluent().type.is_real_type()
-                        for fn in self._fnodes_vars_ordering
-                    )
-                    else np.int32,
-                )
-            else:
-                return None
-        return self._observation_space
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from typing import Dict, List, Optional, Tuple, Union
+
+import numpy as np
+import unified_planning as up
+from numpy.typing import ArrayLike
+from unified_planning.engines.compilers.grounder import GrounderHelper
+from unified_planning.engines.sequential_simulator import (
+    UPSequentialSimulator,
+    evaluate_quality_metric,
+)
+from unified_planning.exceptions import UPValueError
+from unified_planning.model import FNode, InstantaneousAction, Problem, UPState
+from unified_planning.model.metrics import (
+    MaximizeExpressionOnFinalState,
+    Oversubscription,
+    TemporalOversubscription,
+)
+from unified_planning.plans import ActionInstance
+from unified_planning.shortcuts import Bool, FluentExp, Int, ObjectExp, Real
+
+from skdecide.core import EmptySpace, ImplicitSpace, Space, Value
+from skdecide.domains import DeterministicPlanningDomain
+from skdecide.hub.space.gym import ListSpace, SetSpace
+from skdecide.hub.space.gym.gym import BoxSpace, DictSpace, DiscreteSpace, GymSpace
+from skdecide.utils import logger
+
+
+class SkUPState:
+    def __init__(self, up_state: UPState):
+        self._up_state = up_state
+
+    @property
+    def up_state(self):
+        return self._up_state
+
+    def __hash__(self):
+        fs = set()
+        ci = self._up_state
+        while ci is not None:
+            fs.update(
+                (fn, v)
+                for fn, v in ci._values.items()
+                if fn.fluent().name != "total-cost"
+            )
+            ci = ci._father
+        return hash(frozenset(fs))
+
+    def __eq__(self, other):
+        sd = {}
+        ci = self._up_state
+        while ci is not None:
+            sd.update(
+                {
+                    fn: v
+                    for fn, v in ci._values.items()
+                    if fn.fluent().name != "total-cost"
+                }
+            )
+            ci = ci._father
+        od = {}
+        ci = other._up_state
+        while ci is not None:
+            od.update(
+                {
+                    fn: v
+                    for fn, v in ci._values.items()
+                    if fn.fluent().name != "total-cost"
+                }
+            )
+            ci = ci._father
+        return sd == od
+
+    def __repr__(self) -> str:
+        return repr(self._up_state)
+
+    def __str__(self) -> str:
+        return str(self._up_state)
+
+
+class SkUPAction:
+    def __init__(
+        self,
+        up_action: Union[InstantaneousAction, ActionInstance],
+        ungrounded_action: InstantaneousAction = None,
+        orig_params: Tuple[FNode, ...] = None,
+    ):
+        if not isinstance(up_action, (InstantaneousAction, ActionInstance)):
+            raise RuntimeError(
+                f"SkUPAction: action {up_action} must be an instance of either InstantaneousAction or ActionInstance"
+            )
+        self._up_action = up_action
+        self._ungrounded_action = ungrounded_action
+        self._orig_params = orig_params
+
+    @property
+    def up_action(self) -> InstantaneousAction:
+        return (
+            self._ungrounded_action
+            if self._ungrounded_action is not None
+            else (
+                self._up_action
+                if isinstance(self._up_action, InstantaneousAction)
+                else self._up_action.action
+            )
+        )
+
+    @property
+    def up_parameters(
+        self,
+    ) -> Union[List[up.model.parameter.Parameter], Tuple[up.model.FNode, ...]]:
+        return (
+            self._orig_params
+            if self._orig_params is not None
+            else (
+                self._up_action.parameters
+                if isinstance(self._up_action, InstantaneousAction)
+                else self._up_action.actual_parameters
+            )
+        )
+
+    def __hash__(self):
+        return (
+            hash(self._up_action)
+            if isinstance(self._up_action, InstantaneousAction)
+            else hash(
+                tuple([self._up_action.action, self._up_action.actual_parameters])
+            )
+        )
+
+    def __eq__(self, other):
+        return (
+            self._up_action == other._up_action
+            if isinstance(self._up_action, InstantaneousAction)
+            else tuple([self._up_action.action, self._up_action.actual_parameters])
+            == tuple([other._up_action.action, other._up_action.actual_parameters])
+        )
+
+    def __repr__(self) -> str:
+        return repr(self._up_action)
+
+    def __str__(self) -> str:
+        return str(self._up_action)
+
+
+class D(DeterministicPlanningDomain):
+    T_state = Union[SkUPState, Dict, ArrayLike]  # Type of states
+    T_observation = T_state  # Type of observations
+    T_event = SkUPAction  # Type of events
+    T_value = float  # Type of transition values (rewards or costs)
+    T_info = None  # Type of additional information in environment outcome
+
+
+class UPDomain(D):
+    """This class wraps Unified Planning problem as a scikit-decide domain.
+
+    !!! warning
+        Using this class requires unified_planning to be installed.
+    """
+
+    def __init__(
+        self,
+        problem: Problem,
+        fluent_domains: Dict[FNode, Tuple[Union[int, float], Union[int, float]]] = None,
+        state_encoding: str = "native",
+        action_encoding: str = "native",
+        **simulator_params,
+    ):
+        """Initialize UPDomain.
+
+        # Parameters
+        problem: The Unified Planning problem (Problem) to wrap.
+        fluent_domains: Dictionary of min and max fluent values by fluent represented as a Unified Planning's FNode (must be provided only if get_observation_space() is used)
+        state_encoding: Encoding of the state (observation) which must be one of "native", "dictionary" or "vector" (warning: if action_masking is "vector" then the state automatically becomes a dictionary which separates the action masking vector from the real state as defined here)
+        action_encoding: Encoding of the action which must be either "native" or "int"
+        simulator_params: Optional parameters to pass to the UP sequential simulator
+        """
+        self._problem = problem
+        # We might be in a different process from the one where the UP problem was created
+        # thus we must set the global environment to the one of the UP problem
+        up.environment.GLOBAL_ENVIRONMENT = self._problem._env
+        self._simulator = UPSequentialSimulator(
+            self._problem, error_on_failed_checks=True, **simulator_params
+        )
+        self._simulator_params = simulator_params
+        self._grounder = GrounderHelper(self._problem)
+        try:
+            self._total_cost = FluentExp(self._problem.fluent("total-cost"))
+        except UPValueError:
+            self._total_cost = None
+        self._transition_costs = {}
+        self._fluent_domains = fluent_domains
+        self._state_encoding = state_encoding
+        self._action_encoding = action_encoding
+        self._action_space = None  # not computed by default
+        self._observation_space = None  # not computed by default
+        self._fnodes_variables_map = None
+        self._fnodes_vars_ordering = None
+        self._states_up2np = None
+        self._states_np2up = None
+        self._actions_up2np = None
+        self._actions_np2up = None
+        if self._state_encoding != "native":
+            if self._state_encoding not in ["dictionary", "vector"]:
+                raise RuntimeError(
+                    "State encoding must be one of 'native', 'dictionary' or 'vector'"
+                )
+            self._init_state_encoding_()
+        if self._action_encoding != "native":
+            if self._action_encoding != "int":
+                raise RuntimeError("Action encoding must be either 'native' or 'int'")
+            self._init_action_encoding_()
+
+    def _init_state_encoding_(self):
+        def fnode_lower_bound(fn):
+            if fn.fluent().type.lower_bound is not None:
+                return fn.fluent().type.lower_bound
+            elif self._fluent_domains is not None and fn in self._fluent_domains:
+                return self._fluent_domains[fn][0]
+            else:
+                raise RuntimeError(
+                    f"Lower bound not provided for fluent expression {fn}"
+                )
+
+        def fnode_upper_bound(fn):
+            if fn.fluent().type.upper_bound is not None:
+                return fn.fluent().type.upper_bound
+            elif self._fluent_domains is not None and fn in self._fluent_domains:
+                return self._fluent_domains[fn][1]
+            else:
+                raise RuntimeError(
+                    f"Upper bound not provided for fluent expression {fn}"
+                )
+
+        self._fnodes_variables_map = {}
+        self._fnodes_vars_ordering = []
+        self._states_up2np = {}
+        self._states_np2up = {}
+        init_state = self._simulator.get_initial_state()
+        static_fluents = self._problem.get_static_fluents()
+        ci = init_state
+        while ci is not None:
+            for fn in ci._values.keys():
+                if (
+                    fn.fluent() not in static_fluents
+                    and fn.fluent().name != "total-cost"
+                ):
+                    self._fnodes_vars_ordering.append(fn)
+                    if fn.fluent().type.is_bool_type():
+                        self._fnodes_variables_map[fn] = (
+                            0,
+                            1,
+                            lambda b_fnode: int(b_fnode.constant_value()),
+                            lambda i_int: Bool(bool(i_int)),
+                        )
+                    elif fn.fluent().type.is_int_type():
+                        lb = int(fnode_lower_bound(fn))
+                        ub = int(fnode_upper_bound(fn))
+                        self._fnodes_variables_map[fn] = (
+                            (
+                                0,
+                                ub - lb + 1,
+                                lambda i_fnode, lb=lb: i_fnode.constant_value() - lb,
+                                lambda i_int, lb=lb: Int(i_int + lb),
+                            )
+                            if self._state_encoding == "dictionary"
+                            else (
+                                lb,
+                                ub,
+                                lambda i_fnode: int(i_fnode.constant_value()),
+                                lambda i_int: Int(i_int),
+                            )
+                        )
+                    elif fn.fluent().type.is_real_type():
+                        self._fnodes_variables_map[fn] = (
+                            float(fnode_lower_bound(fn)),
+                            float(fnode_upper_bound(fn)),
+                            lambda x_fnode: float(x_fnode.constant_value()),
+                            lambda x_float: Real(x_float),
+                        )
+                    elif fn.fluent().type.is_user_type():
+                        co = list(self._problem.objects(fn.fluent().type))
+                        o2i = {o: i for i, o in enumerate(co)}
+                        self._fnodes_variables_map[fn] = (
+                            0,
+                            len(co),
+                            lambda o_fnode, o2i=o2i: o2i[o_fnode.object()],
+                            lambda i_int, i2o=co: ObjectExp(i2o[i_int]),
+                        )
+                    elif fn.fluent().type.is_time_type():
+                        raise RuntimeError("Time types not handled by UPDomain")
+            ci = ci._father
+
+    def _convert_to_skup_state_(self, state):
+        if self._state_encoding == "native":
+            return state
+        elif self._state_encoding == "dictionary":
+            kstate = frozenset(state.items())
+            if kstate in self._states_np2up:
+                return self._states_np2up[kstate]
+            else:
+                values = {}
+                for fn, s in state.items():
+                    values[fn] = self._fnodes_variables_map[fn][3](s)
+                skup_state = SkUPState(UPState(values))
+                self._states_up2np[skup_state] = state
+                self._states_np2up[kstate] = skup_state
+                return skup_state
+        elif self._state_encoding == "vector":
+            kstate = tuple(state.flatten())
+            if kstate in self._states_np2up:
+                return self._states_np2up[kstate]
+            else:
+                values = {}
+                for i, fn in enumerate(self._fnodes_vars_ordering):
+                    values[fn] = self._fnodes_variables_map[fn][3](state.item(i))
+                skup_state = SkUPState(UPState(values))
+                self._states_up2np[skup_state] = state
+                self._states_np2up[kstate] = skup_state
+                return skup_state
+        else:
+            return None
+
+    def _convert_from_skup_state_(self, skup_state: SkUPState):
+        if self._state_encoding == "native":
+            return skup_state
+        elif self._state_encoding == "dictionary":
+            if skup_state in self._states_up2np:
+                return self._states_up2np[skup_state]
+            else:
+                state = {}
+                ci = skup_state._up_state
+                while ci is not None:
+                    for fn, val in ci._values.items():
+                        if fn in self._fnodes_variables_map:
+                            state[fn] = self._fnodes_variables_map[fn][2](val)
+                    ci = ci._father
+                self._states_np2up[frozenset(state.items())] = skup_state
+                self._states_up2np[skup_state] = state
+                return state
+        elif self._state_encoding == "vector":
+            if skup_state in self._states_up2np:
+                return self._states_up2np[skup_state]
+            else:
+                state = []
+                any_real = False
+                for fn in self._fnodes_vars_ordering:
+                    ci = skup_state._up_state
+                    while ci is not None:
+                        if fn in ci._values:
+                            state.append(
+                                self._fnodes_variables_map[fn][2](ci._values[fn])
+                            )
+                            break
+                        ci = ci._father
+                    any_real = any_real or fn.fluent().type.is_real_type()
+                state = np.array(state, dtype=np.float32 if any_real else np.int32)
+                self._states_np2up[tuple(state.flatten())] = skup_state
+                self._states_up2np[skup_state] = state
+                return state
+        else:
+            return None
+
+    def _init_action_encoding_(self):
+        # For actions, the numpy encoding is just an int
+        self._actions_np2up = [
+            SkUPAction(a[2], ungrounded_action=a[0], orig_params=a[1])
+            for a in self._grounder.get_grounded_actions()
+            if a[2] is not None
+        ]
+        self._actions_up2np = {a: i for i, a in enumerate(self._actions_np2up)}
+
+    def _convert_to_skup_action_(self, action):
+        if self._action_encoding == "native":
+            return action
+        elif self._action_encoding == "int":
+            return self._actions_np2up[int(action)]
+        else:
+            return None
+
+    def _convert_from_skup_action_(self, skup_action: SkUPAction):
+        if self._action_encoding == "native":
+            return skup_action
+        elif self._action_encoding == "int":
+            return self._actions_map[skup_action]
+        else:
+            return None
+
+    def _get_next_state(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+    ) -> D.T_memory[D.T_state]:
+        state = self._convert_to_skup_state_(memory)
+        act = self._convert_to_skup_action_(action)
+        if self._total_cost is not None:
+            cost = state.up_state.get_value(self._total_cost).constant_value()
+        next_state = SkUPState(
+            self._simulator.apply(state.up_state, act.up_action, act.up_parameters)
+        )
+        if self._total_cost is not None:
+            cost = (
+                next_state.up_state.get_value(self._total_cost).constant_value() - cost
+            )
+            self._transition_costs[tuple([state, act, next_state])] = cost
+        next_state = self._convert_from_skup_state_(next_state)
+        return next_state
+
+    def _get_transition_value(
+        self,
+        memory: D.T_memory[D.T_state],
+        action: D.T_agent[D.T_concurrency[D.T_event]],
+        next_state: Optional[D.T_memory[D.T_state]] = None,
+    ) -> D.T_agent[Value[D.T_value]]:
+        if self._total_cost is not None:
+            transition = tuple(
+                [
+                    self._convert_to_skup_state_(memory),
+                    self._convert_to_skup_action_(action),
+                    self._convert_to_skup_state_(next_state),
+                ]
+            )
+            if transition in self._transition_costs:
+                return Value(cost=self._transition_costs[transition])
+        if len(self._problem.quality_metrics) > 0:
+            transition_cost = 0
+            state = self._convert_to_skup_state_(memory)
+            act = self._convert_to_skup_action_(action)
+            nstate = self._convert_to_skup_state_(next_state)
+            for qm in self._problem.quality_metrics:
+                metric = evaluate_quality_metric(
+                    self._simulator,
+                    qm,
+                    0,
+                    state.up_state,
+                    act.up_action,
+                    act.up_parameters,
+                    nstate.up_state,
+                )
+                if isinstance(
+                    qm,
+                    (
+                        MaximizeExpressionOnFinalState,
+                        Oversubscription,
+                        TemporalOversubscription,
+                    ),
+                ):
+                    transition_cost += -metric
+                else:
+                    transition_cost += metric
+            return Value(cost=transition_cost)
+        else:
+            logger.warning(
+                "UPDomain: requesting transition value whereas the 'total-cost' fluent or UP quality metrics are not defined will return NaN"
+            )
+            return Value(cost=float("Nan"))
+
+    def _is_terminal(self, memory: D.T_state) -> D.T_agent[D.T_predicate]:
+        state = self._convert_to_skup_state_(memory)
+        return self._simulator.is_goal(state.up_state)
+
+    def _get_action_space_(self) -> D.T_agent[Space[D.T_event]]:
+        if self._action_space is None:
+            if self._action_encoding == "native":
+                # By default we don't initialize action encoding for actions
+                # since it is not highly expected that the action space will
+                # be requested from the user in "native" action encoding mode
+                if self._actions_np2up is None:
+                    self._init_action_encoding_()
+                self._action_space = ListSpace(self._actions_np2up)
+            elif self._action_encoding == "int":
+                self._action_space = DiscreteSpace(len(self._actions_np2up))
+            else:
+                return None
+        return self._action_space
+
+    def _get_applicable_actions_from(
+        self, memory: D.T_state
+    ) -> D.T_agent[Space[D.T_event]]:
+        state = self._convert_to_skup_state_(memory)
+        applicable_actions = [
+            SkUPAction(
+                self._grounder.ground_action(action, params),
+                ungrounded_action=action,
+                orig_params=params,
+            )
+            for action, params in self._simulator.get_applicable_actions(state.up_state)
+        ]
+        if self._action_encoding == "native":
+            # SetSpace requires to be non empty
+            return (
+                SetSpace(applicable_actions)
+                if len(applicable_actions) > 0
+                else EmptySpace()
+            )
+        elif self._action_encoding == "int":
+            # SetSpace requires to be non empty
+            return (
+                SetSpace([self._actions_up2np[a] for a in applicable_actions])
+                if len(applicable_actions) > 0
+                else EmptySpace()
+            )
+        else:
+            return None
+
+    def _get_goals_(self) -> D.T_agent[Space[D.T_observation]]:
+        return ImplicitSpace(lambda s: self._is_terminal(s))
+
+    def _get_initial_state_(self) -> D.T_state:
+        init_state = self._convert_from_skup_state_(
+            SkUPState(self._simulator.get_initial_state())
+        )
+        return init_state
+
+    def _get_observation_space_(self) -> D.T_agent[Space[D.T_observation]]:
+        if self._observation_space is None:
+            if self._state_encoding == "native":
+                raise RuntimeError(
+                    "Observation space defined only for state encoding 'dictionary' or 'vector'"
+                )
+            elif self._state_encoding == "dictionary":
+                self._observation_space = DictSpace(
+                    {
+                        repr(fn): (
+                            DiscreteSpace(2)
+                            if fn.fluent().type.is_bool_type()
+                            else (
+                                DiscreteSpace(v[1])
+                                if fn.fluent().type.is_int_type()
+                                else (
+                                    BoxSpace(v[0], v[1])
+                                    if fn.fluent().type.is_real_type()
+                                    else (
+                                        DiscreteSpace(v[1])
+                                        if fn.fluent().type.is_user_type()
+                                        else None
+                                    )
+                                )
+                            )
+                        )
+                        for fn, v in self._fnodes_variables_map.items()
+                    }
+                )
+            elif self._state_encoding == "vector":
+                self._observation_space = BoxSpace(
+                    low=np.array(
+                        [
+                            self._fnodes_variables_map[fn][0]
+                            for fn in self._fnodes_vars_ordering
+                        ]
+                    ),
+                    high=np.array(
+                        [
+                            self._fnodes_variables_map[fn][1]
+                            for fn in self._fnodes_vars_ordering
+                        ]
+                    ),
+                    dtype=(
+                        np.float32
+                        if any(
+                            fn.fluent().type.is_real_type()
+                            for fn in self._fnodes_vars_ordering
+                        )
+                        else np.int32
+                    ),
+                )
+            else:
+                return None
+        return self._observation_space
```

## skdecide/hub/solver/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
```

## skdecide/hub/solver/aostar/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .aostar import AOstar
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .aostar import AOstar
```

## skdecide/hub/solver/aostar/aostar.py

```diff
@@ -1,133 +1,293 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import os
-import sys
-from typing import Callable, Optional
-
-from skdecide import Domain, Solver, hub
-from skdecide.builders.domain import (
-    Actions,
-    EnumerableTransitions,
-    FullyObservable,
-    Goals,
-    Markovian,
-    PositiveCosts,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
-from skdecide.core import Value
-
-record_sys_path = sys.path
-skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
-if skdecide_cpp_extension_lib_path not in sys.path:
-    sys.path.append(skdecide_cpp_extension_lib_path)
-
-try:
-
-    from __skdecide_hub_cpp import _AOStarSolver_ as aostar_solver
-
-    # TODO: remove Markovian req?
-    class D(
-        Domain,
-        SingleAgent,
-        Sequential,
-        EnumerableTransitions,
-        Actions,
-        Goals,
-        Markovian,
-        FullyObservable,
-        PositiveCosts,
-    ):
-        pass
-
-    class AOstar(ParallelSolver, Solver, DeterministicPolicies, Utilities):
-        T_domain = D
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            heuristic: Optional[
-                Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
-            ] = None,
-            discount: float = 1.0,
-            max_tip_expanions: int = 1,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            detect_cycles: bool = False,
-            debug_logs: bool = False,
-        ) -> None:
-            ParallelSolver.__init__(
-                self,
-                domain_factory=domain_factory,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-            )
-            self._solver = None
-            self._discount = discount
-            self._max_tip_expansions = max_tip_expanions
-            self._detect_cycles = detect_cycles
-            self._debug_logs = debug_logs
-            if heuristic is None:
-                self._heuristic = lambda d, s: Value(cost=0)
-            else:
-                self._heuristic = heuristic
-            self._lambdas = [self._heuristic]
-            self._ipc_notify = True
-
-        def close(self):
-            """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
-            """
-            if self._parallel:
-                self._solver.close()
-            ParallelSolver.close(self)
-
-        def _init_solve(self, domain_factory: Callable[[], Domain]) -> None:
-            self._domain_factory = domain_factory
-            self._solver = aostar_solver(
-                domain=self.get_domain(),
-                goal_checker=lambda d, s: d.is_goal(s),
-                heuristic=lambda d, s: self._heuristic(d, s)
-                if not self._parallel
-                else d.call(None, 0, s),
-                discount=self._discount,
-                max_tip_expansions=self._max_tip_expansions,
-                detect_cycles=self._detect_cycles,
-                parallel=self._parallel,
-                debug_logs=self._debug_logs,
-            )
-            self._solver.clear()
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
-
-        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-            self._solver.solve(memory)
-
-        def _is_solution_defined_for(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> bool:
-            return self._solver.is_solution_defined_for(observation)
-
-        def _get_next_action(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if not self._is_solution_defined_for(observation):
-                self._solve_from(observation)
-            return self._solver.get_next_action(observation)
-
-        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-            return self._solver.get_utility(observation)
-
-except ImportError:
-    sys.path = record_sys_path
-    print(
-        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
-    )
-    raise
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import os
+import sys
+from typing import Callable, Dict, Optional, Set, Tuple
+
+from skdecide import Domain, Solver, hub
+from skdecide.builders.domain import (
+    Actions,
+    EnumerableTransitions,
+    FullyObservable,
+    Goals,
+    Markovian,
+    PositiveCosts,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
+from skdecide.core import Value
+
+record_sys_path = sys.path
+skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
+if skdecide_cpp_extension_lib_path not in sys.path:
+    sys.path.append(skdecide_cpp_extension_lib_path)
+
+try:
+
+    from __skdecide_hub_cpp import _AOStarSolver_ as aostar_solver
+
+    # TODO: remove Markovian req?
+    class D(
+        Domain,
+        SingleAgent,
+        Sequential,
+        EnumerableTransitions,
+        Actions,
+        Goals,
+        Markovian,
+        FullyObservable,
+        PositiveCosts,
+    ):
+        pass
+
+    class AOstar(
+        ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState
+    ):
+        """This is the skdecide implementation of the AO* algorithm for searching
+        cost-minimal policies in additive AND/OR graphs with admissible heuristics
+        as described in "Principles of Artificial Intelligence" by Nilsson, N. (1980)
+        """
+
+        T_domain = D
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], Domain],
+            heuristic: Optional[
+                Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
+            ] = lambda d, s: Value(cost=0),
+            discount: float = 1.0,
+            max_tip_expansions: int = 1,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            detect_cycles: bool = False,
+            callback: Callable[[AOstar], bool] = lambda slv: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a AOstar solver instance
+
+            # Parameters
+            domain_factory (Callable[[], Domain]): The lambda function to create a domain instance.
+            heuristic (Optional[ Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]] ], optional):
+                Lambda function taking as arguments the domain and a state object,
+                and returning the heuristic estimate from the state to the goal.
+                Defaults to (lambda d, s: Value(cost=0)).
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            max_tip_expansions (int, optional): Maximum number of states to extract from the
+                priority queue at each iteration before recomputing the policy graph. Defaults to 1.
+            parallel (bool, optional): Parallelize the generation of state-action transitions
+                on different processes using duplicated domains (True) or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            detect_cycles (bool, optional): Boolean indicating whether cycles in the search graph
+                should be automatically detected (true) or not (false), knowing that the
+                AO* algorithm is not meant to work with graph cycles into which it might be
+                infinitely trapped. Defaults to False.
+            callback (Callable[[AOstar], bool], optional): Lambda function called before popping
+                the next state from the priority queue, taking as arguments the solver and the domain,
+                and returning true if the solver must be stopped. Defaults to (lambda slv: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be
+                logged (True) or not (False). Defaults to False.
+            """
+            ParallelSolver.__init__(
+                self,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+            )
+            Solver.__init__(self, domain_factory=domain_factory)
+            self._solver = None
+            self._discount = discount
+            self._max_tip_expansions = max_tip_expansions
+            self._detect_cycles = detect_cycles
+            self._heuristic = heuristic
+            self._lambdas = [self._heuristic]
+            self._callback = callback
+            self._verbose = verbose
+            self._ipc_notify = True
+
+        def close(self):
+            """Joins the parallel domains' processes.
+
+            !!! warning
+                Not calling this method (or not using the 'with' context statement)
+                results in the solver forever waiting for the domain processes to exit.
+
+            """
+            if self._parallel:
+                self._solver.close()
+            ParallelSolver.close(self)
+
+        def _init_solve(self) -> None:
+            self._solver = aostar_solver(
+                solver=self,
+                domain=self.get_domain(),
+                goal_checker=lambda d, s: d.is_goal(s),
+                heuristic=(
+                    (lambda d, s: self._heuristic(d, s))
+                    if not self._parallel
+                    else (lambda d, s: d.call(None, 0, s))
+                ),
+                discount=self._discount,
+                max_tip_expansions=self._max_tip_expansions,
+                detect_cycles=self._detect_cycles,
+                parallel=self._parallel,
+                callback=self._callback,
+                verbose=self._verbose,
+            )
+            self._solver.clear()
+
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
+
+        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the AO* algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): State from which AO* graph traversals
+                are performed (root of the search graph)
+            """
+            self._solver.solve(memory)
+
+        def _is_solution_defined_for(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> bool:
+            """Indicates whether the solution policy is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if the state has been explored and an action is defined in this state,
+                False otherwise
+            """
+            return self._solver.is_solution_defined_for(observation)
+
+        def _get_next_action(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed action in terms of best Q-value in a given state.
+                The solver is run from `observation` if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `AOstar.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed action
+            """
+            if not self._is_solution_defined_for(observation):
+                self._solve_from(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
+
+        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the best Q-value in a given state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `AOstar.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the best Q-value is requested
+
+            # Returns
+            D.T_value: Minimum Q-value of the given state over the applicable actions in this state
+            """
+            return self._solver.get_utility(observation)
+
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
+
+        def get_explored_states(self) -> Set[D.T_agent[D.T_observation]]:
+            """Get the set of states present in the search graph (i.e. the graph's
+                state nodes minus the nodes' encapsulation and their children)
+
+            # Returns
+            Set[D.T_agent[D.T_observation]]: Set of states present in the search graph
+            """
+            return self._solver.get_explored_states()
+
+        def get_nb_tip_states(self) -> int:
+            """Get the number of states present in the priority queue (i.e. those
+                explored states that have not been yet expanded)
+
+            # Returns
+            int: Number of states present in the priority queue
+            """
+            return self._solver.get_nb_tip_states()
+
+        def get_top_tip_state(self) -> D.T_agent[D.T_observation]:
+            """Get the top tip state, i.e. the tip state with the lowest value function
+
+            !!! warning
+                Returns None if the priority queue is empty
+
+            # Returns
+            D.T_agent[D.T_observation]: Next tip state to be expanded by the algorithm
+            """
+            return self._solver.get_top_tip_state()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
+        def get_policy(
+            self,
+        ) -> Dict[
+            D.T_agent[D.T_observation],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value],
+        ]:
+            """Get the (partial) solution policy defined for the states for which
+                the Q-value has been updated at least once (which is optimal for
+                the states reachable by the policy from the root solving state)
+
+            !!! warning
+                Only defined over the states reachable from the root solving state
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value], ]:
+                Mapping from states to pairs of action and best Q-value
+            """
+            return self._solver.get_policy()
+
+except ImportError:
+    sys.path = record_sys_path
+    print(
+        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
+    )
+    raise
```

## skdecide/hub/solver/ars/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .ars import AugmentedRandomSearch
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .ars import AugmentedRandomSearch
```

## skdecide/hub/solver/ars/ars.py

```diff
@@ -69,27 +69,47 @@
     for x in c:
         if isinstance(x, str) or not isinstance(x, Iterable):
             yield x
         else:
             yield from flatten(x)
 
 
-class AugmentedRandomSearch(Solver, Policies, Restorable):
+class AugmentedRandomSearch(Solver, Policies):
+    """Augmented Random Search solver."""
+
     T_domain = D
 
     def __init__(
         self,
+        domain_factory: Callable[[], Domain],
         n_epochs=1000,
         epoch_size=1000,
         directions=10,
         top_directions=3,
         learning_rate=0.02,
         policy_noise=0.03,
         reward_maximization=True,
+        callback: Callable[[AugmentedRandomSearch], bool] = lambda solver: False,
     ) -> None:
+        """
+
+        # Parameters
+        domain_factory
+        n_epochs
+        epoch_size
+        directions
+        top_directions
+        learning_rate
+        policy_noise
+        reward_maximization
+        callback: function called at each solver epoch. If returning true, the solve process stops.
+
+        """
+        self.callback = callback
+        Solver.__init__(self, domain_factory=domain_factory)
         self.env = None
         self.n_epochs = n_epochs
         self.learning_rate = learning_rate
         self.epoch_size = epoch_size
         self.directions = directions
         self.top_directions = top_directions
         self.policy = None
@@ -154,17 +174,16 @@
                 perturbations += self.generate_perturbations(element)
             return perturbations
         if isinstance(space, gym.spaces.Discrete):
             return 2 * np.random.random_integers(space.n) / space.n - 1
         else:
             return 2 * np.random.random_sample() - 1
 
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-
-        self.env = domain_factory()
+    def _solve(self) -> None:
+        self.env = self._domain_factory()
         np.random.seed(0)
         input_size = self.get_dimension_space(
             self.env.get_observation_space().unwrapped()
         )
         output_size = self.get_dimension_space(self.env.get_action_space().unwrapped())
 
         self.policy = np.zeros((output_size, input_size))
@@ -212,18 +231,24 @@
                 (positive_rewards[k], negative_rewards[k], deltas[k]) for k in order
             ]
 
             # Updating our policy
             self.update_policy(rollouts, sigma_r)
 
             # Printing the final reward of the policy after the update
-            reward_evaluation = self.explore(normalizer)
-            print("Step:", step, "Reward:", reward_evaluation, "Policy", self.policy)
+            self.reward_evaluation = self.explore(normalizer)
+            print(
+                "Step:", step, "Reward:", self.reward_evaluation, "Policy", self.policy
+            )
+
+            # Stopping because of user's callback?
+            if self.callback(self):
+                break
 
-        print("Final Reward:", reward_evaluation, "Policy", self.policy)
+        print("Final Reward:", self.reward_evaluation, "Policy", self.policy)
 
     def _sample_action(
         self, observation: D.T_agent[D.T_observation]
     ) -> D.T_agent[D.T_concurrency[D.T_event]]:
 
         # print('observation', observation, 'Policy', self.policy)
         action = self.policy.dot(
```

## skdecide/hub/solver/astar/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .astar import Astar
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .astar import Astar
```

## skdecide/hub/solver/astar/astar.py

```diff
@@ -2,28 +2,33 @@
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from __future__ import annotations
 
 import os
 import sys
-from typing import Callable, Optional
+from typing import Callable, Dict, List, Optional, Set, Tuple
 
 from skdecide import Domain, Solver, hub
 from skdecide.builders.domain import (
     Actions,
     DeterministicTransitions,
     FullyObservable,
     Goals,
     Markovian,
     PositiveCosts,
     Sequential,
     SingleAgent,
 )
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
 from skdecide.core import Value
 
 record_sys_path = sys.path
 skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
 if skdecide_cpp_extension_lib_path not in sys.path:
     sys.path.append(skdecide_cpp_extension_lib_path)
 
@@ -41,84 +46,257 @@
         Goals,
         Markovian,
         FullyObservable,
         PositiveCosts,
     ):
         pass
 
-    class Astar(ParallelSolver, Solver, DeterministicPolicies, Utilities):
+    class Astar(ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState):
+        """This is the skdecide implementation of the A* algorithm for searching
+        cost-minimal plans in additive OR graphs with admissible heuristics
+        as described in "A Formal Basis for the Heuristic Determination of Minimum
+        Cost Paths"  Hart, P. E.; Nilsson, N.J.; Raphael, B. (1968)
+        """
+
         T_domain = D
 
         def __init__(
             self,
-            domain_factory: Callable[[], Domain] = None,
+            domain_factory: Callable[[], Domain],
             heuristic: Optional[
                 Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
-            ] = None,
+            ] = lambda d, s: Value(cost=0),
             parallel: bool = False,
             shared_memory_proxy=None,
-            debug_logs: bool = False,
+            callback: Callable[[Astar], bool] = lambda slv: False,
+            verbose: bool = False,
         ) -> None:
+            """Construct a Astar solver instance
+
+            # Parameters
+            domain_factory (Callable[[], Domain], optional): The lambda function to create a domain instance.
+            heuristic (Optional[ Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]] ], optional):
+                Lambda function taking as arguments the domain and a state object,
+                and returning the heuristic estimate from the state to the goal.
+                Defaults to (lambda d, s: Value(cost=0)).
+            parallel (bool, optional): Parallelize the generation of state-action transitions
+                on different processes using duplicated domains (True) or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[AOstar], bool], optional): Lambda function called before popping
+                the next state from the (priority) open queue, taking as arguments the solver and the domain,
+                and returning true if the solver must be stopped. Defaults to (lambda slv: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be
+                logged (True) or not (False). Defaults to False.
+            """
             ParallelSolver.__init__(
                 self,
-                domain_factory=domain_factory,
                 parallel=parallel,
                 shared_memory_proxy=shared_memory_proxy,
             )
+            Solver.__init__(self, domain_factory=domain_factory)
             self._solver = None
-            self._debug_logs = debug_logs
-            if heuristic is None:
-                self._heuristic = lambda d, s: Value(cost=0)
-            else:
-                self._heuristic = heuristic
+            self._heuristic = heuristic
             self._lambdas = [self._heuristic]
+            self._callback = callback
+            self._verbose = verbose
             self._ipc_notify = True
 
         def close(self):
             """Joins the parallel domains' processes.
             Not calling this method (or not using the 'with' context statement)
             results in the solver forever waiting for the domain processes to exit.
             """
             if self._parallel:
                 self._solver.close()
             ParallelSolver.close(self)
 
-        def _init_solve(self, domain_factory: Callable[[], Domain]) -> None:
-            self._domain_factory = domain_factory
+        def _init_solve(self) -> None:
             self._solver = astar_solver(
+                solver=self,
                 domain=self.get_domain(),
                 goal_checker=lambda d, s: d.is_goal(s),
-                heuristic=lambda d, s: self._heuristic(d, s)
-                if not self._parallel
-                else d.call(None, 0, s),
+                heuristic=(
+                    (lambda d, s: self._heuristic(d, s))
+                    if not self._parallel
+                    else (lambda d, s: d.call(None, 0, s))
+                ),
                 parallel=self._parallel,
-                debug_logs=self._debug_logs,
+                callback=self._callback,
+                verbose=self._verbose,
             )
             self._solver.clear()
 
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
 
         def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the A* algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): State from which A* graph traversals
+                are performed (root of the search graph)
+            """
             self._solver.solve(memory)
 
         def _is_solution_defined_for(
             self, observation: D.T_agent[D.T_observation]
         ) -> bool:
+            """Indicates whether the solution policy (potentially built from merging
+                several previously computed plans) is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if a plan that goes through the state has been previously computed,
+                False otherwise
+            """
             return self._solver.is_solution_defined_for(observation)
 
         def _get_next_action(
             self, observation: D.T_agent[D.T_observation]
         ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed action in terms of minimum cost-to-go in a given state.
+                The solver is run from `observation` if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `Astar.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed action
+            """
             if not self._is_solution_defined_for(observation):
                 self._solve_from(observation)
-            return self._solver.get_next_action(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
 
         def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the minimum cost-to-go in a given state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `Astar.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the minimum cost-to-go is requested
+
+            # Returns
+            D.T_value: Minimum cost-to-go of the given state over the applicable actions in this state
+            """
             return self._solver.get_utility(observation)
 
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
+
+        def get_explored_states(self) -> Set[D.T_agent[D.T_observation]]:
+            """Get the set of states present in the search graph (i.e. the graph's
+                state nodes minus the nodes' encapsulation and their neighbors)
+
+            # Returns
+            Set[D.T_agent[D.T_observation]]: Set of states present in the search graph
+            """
+            return self._solver.get_explored_states()
+
+        def get_nb_tip_states(self) -> int:
+            """Get the number of states present in the priority queue (i.e. those
+                explored states that have not been yet closed by A*)
+
+            # Returns
+            int: Number of states present in the (priority) open queue
+            """
+            return self._solver.get_nb_tip_states()
+
+        def get_top_tip_state(self) -> D.T_agent[D.T_observation]:
+            """Get the top tip state, i.e. the tip state with the lowest f-score
+
+            !!! warning
+                Returns None if the priority queue is empty
+
+            # Returns
+            D.T_agent[D.T_observation]: Next tip state to be closed by A*
+            """
+            return self._solver.get_top_tip_state()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
+        def get_plan(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> List[
+            Tuple[
+                D.T_agent[D.T_observation],
+                D.T_agent[D.T_concurrency[D.T_event]],
+                D.T_value,
+            ]
+        ]:
+            """Get the solution plan starting in a given state
+
+            !!! warning
+                Returns an empty list if no plan has been previously computed that goes
+                through the given state.
+                Throws a runtime exception if a state cycle is detected in the plan
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which a solution plan
+                to a goal state is requested
+
+            # Returns
+            List[ Tuple[ D.T_agent[D.T_observation], D.T_agent[D.T_concurrency[D.T_event]], D.T_value, ] ]:
+                Sequence of tuples of state, action and transition cost (computed as the
+                difference of g-scores between this state and the next one) visited
+                along the execution of the plan
+            """
+            return self._solver.get_plan(observation)
+
+        def get_policy(
+            self,
+        ) -> Dict[
+            D.T_agent[D.T_observation],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value],
+        ]:
+            """Get the (partial) solution policy defined for the states for which
+                a solution plan that goes through them has been previously computed at
+                least once
+
+            !!! warning
+                Only defined over the states reachable from the root solving state
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value], ]:
+                Mapping from states to pairs of action and minimum cost-to-go
+            """
+            return self._solver.get_policy()
+
 except ImportError:
     sys.path = record_sys_path
     print(
         'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
     )
     raise
```

## skdecide/hub/solver/bfws/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .bfws import BFWS
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .bfws import BFWS
```

## skdecide/hub/solver/bfws/bfws.py

```diff
@@ -1,137 +1,313 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import os
-import sys
-from typing import Any, Callable
-
-from skdecide import Domain, Solver, hub
-from skdecide.builders.domain import (
-    Actions,
-    DeterministicInitialized,
-    DeterministicTransitions,
-    FullyObservable,
-    Markovian,
-    Rewards,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
-from skdecide.core import Value
-
-record_sys_path = sys.path
-skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
-if skdecide_cpp_extension_lib_path not in sys.path:
-    sys.path.append(skdecide_cpp_extension_lib_path)
-
-try:
-
-    from __skdecide_hub_cpp import _BFWSSolver_ as bfws_solver
-
-    class D(
-        Domain,
-        SingleAgent,
-        Sequential,
-        DeterministicTransitions,
-        Actions,
-        DeterministicInitialized,
-        Markovian,
-        FullyObservable,
-        Rewards,
-    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
-        pass
-
-    class BFWS(ParallelSolver, Solver, DeterministicPolicies, Utilities):
-        T_domain = D
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            state_features: Callable[[Domain, D.T_state], Any],
-            heuristic: Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]],
-            termination_checker: Callable[
-                [Domain, D.T_state], D.T_agent[D.T_predicate]
-            ],
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-        ) -> None:
-            ParallelSolver.__init__(
-                self,
-                domain_factory=domain_factory,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-            )
-            self._solver = None
-            self._domain = None
-            self._state_features = state_features
-            self._termination_checker = termination_checker
-            self._debug_logs = debug_logs
-            if heuristic is None:
-                self._heuristic = lambda d, s: Value(cost=0)
-            else:
-                self._heuristic = heuristic
-            self._lambdas = [
-                self._state_features,
-                self._heuristic,
-                self._termination_checker,
-            ]
-            self._ipc_notify = True
-
-        def close(self):
-            """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
-            """
-            if self._parallel:
-                self._solver.close()
-            ParallelSolver.close(self)
-
-        def _init_solve(self, domain_factory: Callable[[], D]) -> None:
-            self._domain_factory = domain_factory
-            self._solver = bfws_solver(
-                domain=self.get_domain(),
-                state_features=lambda d, s: self._state_features(d, s)
-                if not self._parallel
-                else d.call(None, 0, s),
-                heuristic=lambda d, s: self._heuristic(d, s)
-                if not self._parallel
-                else d.call(None, 1, s),
-                termination_checker=lambda d, s: self._termination_checker(d, s)
-                if not self._parallel
-                else d.call(None, 2, s),
-                parallel=self._parallel,
-                debug_logs=self._debug_logs,
-            )
-            self._solver.clear()
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
-
-        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-            self._solver.solve(memory)
-
-        def _is_solution_defined_for(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> bool:
-            return self._solver.is_solution_defined_for(observation)
-
-        def _get_next_action(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if not self._is_solution_defined_for(observation):
-                self._solve_from(observation)
-            return self._solver.get_next_action(observation)
-
-        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-            return self._solver.get_utility(observation)
-
-except ImportError:
-    sys.path = record_sys_path
-    print(
-        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
-    )
-    raise
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import os
+import sys
+from typing import Any, Callable, Dict, List, Set, Tuple
+
+from skdecide import Domain, Solver, hub
+from skdecide.builders.domain import (
+    Actions,
+    DeterministicInitialized,
+    DeterministicTransitions,
+    FullyObservable,
+    Markovian,
+    Rewards,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
+from skdecide.core import Value
+
+record_sys_path = sys.path
+skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
+if skdecide_cpp_extension_lib_path not in sys.path:
+    sys.path.append(skdecide_cpp_extension_lib_path)
+
+try:
+
+    from __skdecide_hub_cpp import _BFWSSolver_ as bfws_solver
+
+    class D(
+        Domain,
+        SingleAgent,
+        Sequential,
+        DeterministicTransitions,
+        Actions,
+        DeterministicInitialized,
+        Markovian,
+        FullyObservable,
+        Rewards,
+    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
+        pass
+
+    class BFWS(ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState):
+        """This is the skdecide implementation Best First Width Search from
+        "Best-First Width Search: Exploration and Exploitation in Classical Planning"
+        by Nir Lipovetzky and Hector Geffner (2017)
+        """
+
+        T_domain = D
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], Domain],
+            state_features: Callable[[Domain, D.T_state], Any],
+            heuristic: Callable[
+                [Domain, D.T_state], D.T_agent[Value[D.T_value]]
+            ] = lambda d, s: Value(cost=0),
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[[BFWS], bool] = lambda slv: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a BFWS solver instance
+
+            # Parameters
+            domain_factory (Callable[[], Domain]): The lambda function to create a domain instance.
+            state_features (Callable[[Domain, D.T_state], Any]): State feature vector
+                used to compute the novelty measure
+            heuristic (Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]):
+                Lambda function taking as arguments the domain and a state object,
+                and returning the heuristic estimate from the state to the goal.
+                Defaults to (lambda d, s: Value(cost=0)).
+            parallel (bool, optional): Parallelize the generation of state-action transitions
+                on different processes using duplicated domains (True) or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[BFWS], bool], optional): Lambda function called before popping
+                the next state from the (priority) open queue, taking as arguments the solver and the domain,
+                and returning true if the solver must be stopped. Defaults to (lambda slv: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be
+                logged (True) or not (False). Defaults to False.
+            """
+            ParallelSolver.__init__(
+                self,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+            )
+            Solver.__init__(self, domain_factory=domain_factory)
+            self._solver = None
+            self._domain = None
+            self._state_features = state_features
+            self._heuristic = heuristic
+            self._lambdas = [
+                self._state_features,
+                self._heuristic,
+            ]
+            self._callback = callback
+            self._verbose = verbose
+            self._ipc_notify = True
+
+        def close(self):
+            """Joins the parallel domains' processes.
+            Not calling this method (or not using the 'with' context statement)
+            results in the solver forever waiting for the domain processes to exit.
+            """
+            if self._parallel:
+                self._solver.close()
+            ParallelSolver.close(self)
+
+        def _init_solve(self) -> None:
+            self._solver = bfws_solver(
+                solver=self,
+                domain=self.get_domain(),
+                goal_checker=lambda d, s: d.is_goal(s),
+                state_features=(
+                    (lambda d, s: self._state_features(d, s))
+                    if not self._parallel
+                    else (lambda d, s: d.call(None, 0, s))
+                ),
+                heuristic=(
+                    (lambda d, s: self._heuristic(d, s))
+                    if not self._parallel
+                    else (lambda d, s: d.call(None, 1, s))
+                ),
+                parallel=self._parallel,
+                callback=self._callback,
+                verbose=self._verbose,
+            )
+            self._solver.clear()
+
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
+
+        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the BFWS algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): State from which BFWS graph traversals
+                are performed (root of the search graph)
+            """
+            self._solver.solve(memory)
+
+        def _is_solution_defined_for(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> bool:
+            """Indicates whether the solution policy (potentially built from merging
+                several previously computed plans) is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if a plan that goes through the state has been previously computed,
+                False otherwise
+            """
+            return self._solver.is_solution_defined_for(observation)
+
+        def _get_next_action(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed action in terms of minimum cost-to-go in a given state.
+                The solver is run from `observation` if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `BFWS.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed action
+            """
+            if not self._is_solution_defined_for(observation):
+                self._solve_from(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
+
+        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the minimum cost-to-go in a given state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `BFWS.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the minimum cost-to-go is requested
+
+            # Returns
+            D.T_value: Minimum cost-to-go of the given state over the applicable actions in this state
+            """
+            return self._solver.get_utility(observation)
+
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
+
+        def get_explored_states(self) -> Set[D.T_agent[D.T_observation]]:
+            """Get the set of states present in the search graph (i.e. the graph's
+                state nodes minus the nodes' encapsulation and their neighbors)
+
+            # Returns
+            Set[D.T_agent[D.T_observation]]: Set of states present in the search graph
+            """
+            return self._solver.get_explored_states()
+
+        def get_nb_tip_states(self) -> int:
+            """Get the number of states present in the priority queue (i.e. those
+                explored states that have not been yet closed by BFWS)
+
+            # Returns
+            int: Number of states present in the (priority) open queue
+            """
+            return self._solver.get_nb_tip_states()
+
+        def get_top_tip_state(self) -> D.T_agent[D.T_observation]:
+            """Get the top tip state, i.e. the tip state with the lowest f-score
+
+            !!! warning
+                Returns None if the priority queue is empty
+
+            # Returns
+            D.T_agent[D.T_observation]: Next tip state to be closed by BFWS
+            """
+            return self._solver.get_top_tip_state()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
+        def get_plan(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> List[
+            Tuple[
+                D.T_agent[D.T_observation],
+                D.T_agent[D.T_concurrency[D.T_event]],
+                D.T_value,
+            ]
+        ]:
+            """Get the solution plan starting in a given state
+
+            !!! warning
+                Returns an empty list if no plan has been previously computed that goes
+                through the given state.
+                Throws a runtime exception if a state cycle is detected in the plan
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which a solution plan
+                to a goal state is requested
+
+            # Returns
+            List[ Tuple[ D.T_agent[D.T_observation], D.T_agent[D.T_concurrency[D.T_event]], D.T_value, ] ]:
+                Sequence of tuples of state, action and transition cost (computed as the
+                difference of g-scores between this state and the next one) visited
+                along the execution of the plan
+            """
+            return self._solver.get_plan(observation)
+
+        def get_policy(
+            self,
+        ) -> Dict[
+            D.T_agent[D.T_observation],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value],
+        ]:
+            """Get the (partial) solution policy defined for the states for which
+                a solution plan that goes through them has been previously computed at
+                least once
+
+            !!! warning
+                Only defined over the states reachable from the root solving state
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value], ]:
+                Mapping from states to pairs of action and minimum cost-to-go
+            """
+            return self._solver.get_policy()
+
+except ImportError:
+    sys.path = record_sys_path
+    print(
+        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
+    )
+    raise
```

## skdecide/hub/solver/cgp/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .cgp import CGPWrapper as CGP
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .cgp import CGPWrapper as CGP
```

## skdecide/hub/solver/cgp/cgp.py

```diff
@@ -1,411 +1,435 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from collections.abc import Iterable
-from typing import Callable
-
-import gymnasium as gym
-import numpy as np
-
-from skdecide import Domain, Solver
-from skdecide.builders.domain import (
-    Environment,
-    History,
-    Initializable,
-    PartiallyObservable,
-    Rewards,
-    Sequential,
-    SingleAgent,
-    UnrestrictedActions,
-)
-from skdecide.builders.solver import DeterministicPolicies, Restorable
-from skdecide.hub.space.gym import GymSpace
-
-from .pycgp.cgpes import CGP, CGPES, Evaluator
-from .pycgp.cgpfunctions import (
-    f_abs,
-    f_acos,
-    f_aminus,
-    f_asin,
-    f_atan,
-    f_ceil,
-    f_exp,
-    f_floor,
-    f_gt,
-    f_inv,
-    f_max,
-    f_min,
-    f_mult,
-    f_one,
-    f_pow,
-    f_round,
-    f_sqrt,
-    f_sqrtxy,
-    f_squared,
-    f_sum,
-    f_zero,
-)
-
-
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    Environment,
-    UnrestrictedActions,
-    Initializable,
-    History,
-    PartiallyObservable,
-    Rewards,
-):
-    pass
-
-
-def change_interval(x, inmin, inmax, outmin, outmax):
-    # redefine interval if min, max are set to +-infinity by the GYM environment
-    # TODO: maybe we could reject those environments in the future.
-    if inmin == -np.inf:
-        inmin = -1
-    if inmax == np.inf:
-        inmax = 1
-    # making sure x is in the interval
-    x = max(inmin, min(inmax, x))
-    # normalizing x between 0 and 1
-    x = (x - inmin) / (inmax - inmin)
-    # denormalizing between outmin and outmax
-    return x * (outmax - outmin) + outmin
-
-
-def change_float_to_int_interval(x, inmin, inmax, outdiscmin, outdiscmax):
-    x = change_interval(x, inmin, inmax, 0, 1)
-    if x == 1:
-        return outdiscmax
-    else:
-        return int(x * (outdiscmax - outdiscmin + 1) + outdiscmin)
-
-
-def flatten(c):
-    """
-    Generator flattening the structure
-
-    >>> list(flatten([2, [2, "test", [4,5, [7], [2, [6, 2, 6, [6], 4]], 6]]]))
-    [2, 2, "test", 4, 5, 7, 2, 6, 2, 6, 6, 4, 6]
-    """
-    for x in c:
-        if isinstance(x, str) or not isinstance(x, Iterable):
-            yield x
-        else:
-            yield from flatten(x)
-
-
-def norm_and_flatten(vals, types):
-    """
-    Flatten and normalise according to AIGYM type (BOX, DISCRETE, TUPLE)
-    :param vals: a np array structure
-    :param types: the gym type corresponding to the vals arrays
-    :return: a flatten array with normalised vals
-    """
-
-    if not isinstance(types, Iterable) and not isinstance(types, gym.spaces.Tuple):
-        types = [types]
-    if not isinstance(vals, Iterable) and not isinstance(vals, gym.spaces.Tuple):
-        vals = [vals]
-
-    flat_vals = list(flatten(vals))
-    index = 0
-    for i in range(len(types)):
-        t = types[i]
-        if isinstance(t, gym.spaces.Box):
-            lows = list(flatten(t.low))
-            highs = list(flatten(t.high))
-            for j in range(len(lows)):
-                flat_vals[index] = change_interval(
-                    flat_vals[index], lows[j], highs[j], -1, 1
-                )
-                index += 1
-        elif isinstance(t, gym.spaces.Discrete):
-            flat_vals[index] = change_interval(flat_vals[index], 0, t.n - 1, -1, 1)
-            index += 1
-        else:
-            raise ValueError("Unsupported type ", str(t))
-    return flat_vals
-
-
-def norm(vals, types):
-    """
-    Normalise according to AIGYM type (BOX, DISCRETE, TUPLE)
-    :param vals: a np array structure
-    :param types: the gym type corresponding to the vals arrays
-    :return: array with normalised vals
-    """
-
-    temp_vals = list(vals)
-    temp_types = types
-    if not isinstance(types, gym.spaces.Tuple):
-        temp_types = [types]
-        temp_vals = [temp_vals]
-
-    for i in range(len(temp_types)):
-        t = temp_types[i]
-        if isinstance(t, gym.spaces.Box):
-            lows = list(flatten(t.low))
-            highs = list(flatten(t.high))
-            for j in range(len(lows)):
-                temp_vals[i][j] = change_interval(
-                    temp_vals[i][j], lows[j], highs[j], -1, 1
-                )
-        elif isinstance(t, gym.spaces.Discrete):
-            temp_vals[i] = change_interval(temp_vals[i], 0, t.n - 1, -1, 1)
-        else:
-            raise ValueError("Unsupported type ", str(t))
-
-    if not isinstance(types, gym.spaces.Tuple):
-        temp_vals = temp_vals[0]
-
-    return temp_vals
-
-
-def denorm(vals, types):
-    """
-    Denormalize values according to AIGYM types (BOX, DISCRETE, TUPLE)
-    :param vals: an array of [-1,1] normalised values
-    :param types: the gym types corresponding to vals
-    :return: the same vals array with denormalised values
-    """
-    if not isinstance(types, Iterable) and not isinstance(types, gym.spaces.Tuple):
-        types = [types]
-    if not isinstance(vals, Iterable) and not isinstance(vals, gym.spaces.Tuple):
-        vals = [vals]
-    out = []
-    index = 0
-    for i in range(len(types)):
-        t = types[i]
-        if isinstance(t, gym.spaces.Box):
-            out_temp = []
-            for j in range(len(t.low)):
-                out_temp += [change_interval(vals[index], -1, 1, t.low[j], t.high[j])]
-                index += 1
-            out += out_temp
-        elif isinstance(t, gym.spaces.Discrete):
-            out += [change_float_to_int_interval(vals[index], -1, 1, 0, t.n - 1)]
-            index += 1
-        else:
-            raise ValueError("Unsupported type ", str(t))
-    # burk
-    if len(types) == 1 and not isinstance(types[0], gym.spaces.Box):
-        return out[0]
-    else:
-        return out
-
-
-class CGPWrapper(Solver, DeterministicPolicies):
-    T_domain = D
-
-    def __init__(
-        self,
-        folder_name,
-        library=None,
-        col=100,
-        row=1,
-        nb_ind=4,
-        mutation_rate_nodes=0.1,
-        mutation_rate_outputs=0.3,
-        n_cpus=1,
-        n_it=1000000,
-        genome=None,
-        verbose=True,
-    ):
-
-        if library is None:
-            library = self._get_default_function_lib()
-
-        self._library = library
-        self._folder_name = folder_name
-        self._col = col
-        self._row = row
-        self._nb_ind = nb_ind
-        self._mutation_rate_nodes = mutation_rate_nodes
-        self._mutation_rate_outputs = mutation_rate_outputs
-        self._n_cpus = n_cpus
-        self._n_it = n_it
-        self._genome = genome
-        self._verbose = verbose
-
-    @classmethod
-    def _check_domain_additional(cls, domain: D) -> bool:
-        """
-        CGP manage all kind of gym types, BOX, DISCRETE and TUPLE as well
-        """
-        action_space = domain.get_action_space().unwrapped()
-        observation_space = domain.get_observation_space().unwrapped()
-
-        if not isinstance(action_space, Iterable) and not isinstance(
-            action_space, gym.spaces.Tuple
-        ):
-            action_space = [action_space]
-        if not isinstance(observation_space, Iterable) and not isinstance(
-            observation_space, gym.spaces.Tuple
-        ):
-            observation_space = [observation_space]
-
-        flat_action_space = list(flatten(action_space))
-        flat_observation_space = list(flatten(observation_space))
-
-        print(flat_action_space)
-        print(flat_observation_space)
-
-        valide_action_space = True
-        for x in flat_action_space:
-            valide_action_space = isinstance(
-                x, (gym.spaces.Tuple, gym.spaces.Discrete, gym.spaces.Box)
-            )
-
-        validate_observation_space = True
-        for x in flat_observation_space:
-            validate_observation_space = isinstance(
-                x, (gym.spaces.Tuple, gym.spaces.Discrete, gym.spaces.Box)
-            )
-
-        return valide_action_space and validate_observation_space
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        domain = domain_factory()
-
-        evaluator = SkDecideEvaluator(domain)
-        if self._genome is None:
-            a = domain.get_action_space().sample()
-            b = domain.get_observation_space().sample()
-            if isinstance(a, Iterable) or isinstance(a, gym.spaces.Tuple):
-                num_outputs = len(a)
-            else:
-                num_outputs = 1
-            if isinstance(b, Iterable) or isinstance(b, gym.spaces.Tuple):
-                num_inputs = len(b)
-            else:
-                num_inputs = 1
-            cgpFather = CGP.random(
-                num_inputs, num_outputs, self._col, self._row, self._library, 1.0
-            )
-        else:
-            cgpFather = CGP.load_from_file(self._genome, self._library)
-
-        if self._verbose:
-            print(cgpFather.genome)
-
-        es = CGPES(
-            self._nb_ind,
-            self._mutation_rate_nodes,
-            self._mutation_rate_outputs,
-            cgpFather,
-            evaluator,
-            self._folder_name,
-            self._n_cpus,
-            verbose=self._verbose,
-        )
-        es.run(self._n_it)
-
-        self._domain = domain
-        self._es = es
-        self._evaluator = evaluator
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-
-        return denorm(
-            self._es.father.run(
-                norm_and_flatten(
-                    observation, self._domain.get_observation_space().unwrapped()
-                )
-            ),
-            self._domain.get_action_space().unwrapped(),
-        )
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
-
-    def _get_default_function_lib(self):
-        return [
-            CGP.CGPFunc(f_sum, "sum", 2),
-            CGP.CGPFunc(f_aminus, "aminus", 2),
-            CGP.CGPFunc(f_mult, "mult", 2),
-            CGP.CGPFunc(f_exp, "exp", 2),
-            CGP.CGPFunc(f_abs, "abs", 1),
-            CGP.CGPFunc(f_sqrt, "sqrt", 1),
-            CGP.CGPFunc(f_sqrtxy, "sqrtxy", 2),
-            CGP.CGPFunc(f_squared, "squared", 1),
-            CGP.CGPFunc(f_pow, "pow", 2),
-            CGP.CGPFunc(f_one, "one", 0),
-            CGP.CGPFunc(f_zero, "zero", 0),
-            CGP.CGPFunc(f_inv, "inv", 1),
-            CGP.CGPFunc(f_gt, "gt", 2),
-            CGP.CGPFunc(f_asin, "asin", 1),
-            CGP.CGPFunc(f_acos, "acos", 1),
-            CGP.CGPFunc(f_atan, "atan", 1),
-            CGP.CGPFunc(f_min, "min", 2),
-            CGP.CGPFunc(f_max, "max", 2),
-            CGP.CGPFunc(f_round, "round", 1),
-            CGP.CGPFunc(f_floor, "floor", 1),
-            CGP.CGPFunc(f_ceil, "ceil", 1),
-        ]
-
-
-class SkDecideEvaluator(Evaluator):
-    def __init__(self, domain, it_max=10000, ep_max=1):
-        super().__init__()
-        self.it_max = it_max
-        self.ep_max = ep_max
-        self.domain = domain
-
-        # def get_mins_maxs(space):
-        #     if not isinstance(space, gym.spaces.Tuple):
-        #         space = tuple([space])
-        #     mins = []
-        #     maxs = []
-        #     for box in space:
-        #         mins += list(box.low)
-        #         maxs += list(box.high)
-        #     return np.array(mins), np.array(maxs)
-
-        # self.obs_mins, self.obs_maxs = get_mins_maxs(domain.get_observation_space().unwrapped())
-        # #self.act_mins, self.act_maxs = 0,2#get_mins_maxs(domain.get_action_space().unwrapped())
-
-    def evaluate(self, cgp, it, verbose=False):
-        fitnesses = np.zeros(self.ep_max)
-        for e in range(self.ep_max):
-            end = False
-            fit = 0
-            states = self.domain.reset()
-            step = 0
-            while not end and step < self.it_max:
-                actions = denorm(
-                    cgp.run(
-                        norm_and_flatten(
-                            states, self.domain.get_observation_space().unwrapped()
-                        )
-                    ),
-                    self.domain.get_action_space().unwrapped(),
-                )
-                states, transition_value, end, _ = self.domain.step(actions).astuple()
-                reward = transition_value[0]  # TODO: correct Gym wrapper
-
-                if verbose:
-                    print(states, "=>", actions)
-
-                fit += reward
-                step += 1
-            fitnesses[e] = fit
-        np.sort(fitnesses)
-        fit = 0
-        sum_e = 0
-        for e in range(self.ep_max):
-            fit += fitnesses[e] * (e + 1)
-            sum_e += e + 1
-
-        return fit / sum_e
-
-    def clone(self):
-        return SkDecideEvaluator(self.domain, self.it_max, self.ep_max)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from collections.abc import Iterable
+from typing import Callable
+
+import gymnasium as gym
+import numpy as np
+
+from skdecide import Domain, Solver
+from skdecide.builders.domain import (
+    Environment,
+    History,
+    Initializable,
+    PartiallyObservable,
+    Rewards,
+    Sequential,
+    SingleAgent,
+    UnrestrictedActions,
+)
+from skdecide.builders.solver import DeterministicPolicies
+
+from .pycgp.cgpes import CGP, CGPES, Evaluator
+from .pycgp.cgpfunctions import (
+    f_abs,
+    f_acos,
+    f_aminus,
+    f_asin,
+    f_atan,
+    f_ceil,
+    f_exp,
+    f_floor,
+    f_gt,
+    f_inv,
+    f_max,
+    f_min,
+    f_mult,
+    f_one,
+    f_pow,
+    f_round,
+    f_sqrt,
+    f_sqrtxy,
+    f_squared,
+    f_sum,
+    f_zero,
+)
+
+
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    Environment,
+    UnrestrictedActions,
+    Initializable,
+    History,
+    PartiallyObservable,
+    Rewards,
+):
+    pass
+
+
+def change_interval(x, inmin, inmax, outmin, outmax):
+    # redefine interval if min, max are set to +-infinity by the GYM environment
+    # TODO: maybe we could reject those environments in the future.
+    if inmin == -np.inf:
+        inmin = -1
+    if inmax == np.inf:
+        inmax = 1
+    # making sure x is in the interval
+    x = max(inmin, min(inmax, x))
+    # normalizing x between 0 and 1
+    x = (x - inmin) / (inmax - inmin)
+    # denormalizing between outmin and outmax
+    return x * (outmax - outmin) + outmin
+
+
+def change_float_to_int_interval(x, inmin, inmax, outdiscmin, outdiscmax):
+    x = change_interval(x, inmin, inmax, 0, 1)
+    if x == 1:
+        return outdiscmax
+    else:
+        return int(x * (outdiscmax - outdiscmin + 1) + outdiscmin)
+
+
+def flatten(c):
+    """
+    Generator flattening the structure
+
+    >>> list(flatten([2, [2, "test", [4,5, [7], [2, [6, 2, 6, [6], 4]], 6]]]))
+    [2, 2, "test", 4, 5, 7, 2, 6, 2, 6, 6, 4, 6]
+    """
+    for x in c:
+        if isinstance(x, str) or not isinstance(x, Iterable):
+            yield x
+        else:
+            yield from flatten(x)
+
+
+def norm_and_flatten(vals, types):
+    """
+    Flatten and normalise according to AIGYM type (BOX, DISCRETE, TUPLE)
+    :param vals: a np array structure
+    :param types: the gym type corresponding to the vals arrays
+    :return: a flatten array with normalised vals
+    """
+
+    if not isinstance(types, Iterable) and not isinstance(types, gym.spaces.Tuple):
+        types = [types]
+    if not isinstance(vals, Iterable) and not isinstance(vals, gym.spaces.Tuple):
+        vals = [vals]
+
+    flat_vals = list(flatten(vals))
+    index = 0
+    for i in range(len(types)):
+        t = types[i]
+        if isinstance(t, gym.spaces.Box):
+            lows = list(flatten(t.low))
+            highs = list(flatten(t.high))
+            for j in range(len(lows)):
+                flat_vals[index] = change_interval(
+                    flat_vals[index], lows[j], highs[j], -1, 1
+                )
+                index += 1
+        elif isinstance(t, gym.spaces.Discrete):
+            flat_vals[index] = change_interval(flat_vals[index], 0, t.n - 1, -1, 1)
+            index += 1
+        else:
+            raise ValueError("Unsupported type ", str(t))
+    return flat_vals
+
+
+def norm(vals, types):
+    """
+    Normalise according to AIGYM type (BOX, DISCRETE, TUPLE)
+    :param vals: a np array structure
+    :param types: the gym type corresponding to the vals arrays
+    :return: array with normalised vals
+    """
+
+    temp_vals = list(vals)
+    temp_types = types
+    if not isinstance(types, gym.spaces.Tuple):
+        temp_types = [types]
+        temp_vals = [temp_vals]
+
+    for i in range(len(temp_types)):
+        t = temp_types[i]
+        if isinstance(t, gym.spaces.Box):
+            lows = list(flatten(t.low))
+            highs = list(flatten(t.high))
+            for j in range(len(lows)):
+                temp_vals[i][j] = change_interval(
+                    temp_vals[i][j], lows[j], highs[j], -1, 1
+                )
+        elif isinstance(t, gym.spaces.Discrete):
+            temp_vals[i] = change_interval(temp_vals[i], 0, t.n - 1, -1, 1)
+        else:
+            raise ValueError("Unsupported type ", str(t))
+
+    if not isinstance(types, gym.spaces.Tuple):
+        temp_vals = temp_vals[0]
+
+    return temp_vals
+
+
+def denorm(vals, types):
+    """
+    Denormalize values according to AIGYM types (BOX, DISCRETE, TUPLE)
+    :param vals: an array of [-1,1] normalised values
+    :param types: the gym types corresponding to vals
+    :return: the same vals array with denormalised values
+    """
+    if not isinstance(types, Iterable) and not isinstance(types, gym.spaces.Tuple):
+        types = [types]
+    if not isinstance(vals, Iterable) and not isinstance(vals, gym.spaces.Tuple):
+        vals = [vals]
+    out = []
+    index = 0
+    for i in range(len(types)):
+        t = types[i]
+        if isinstance(t, gym.spaces.Box):
+            out_temp = []
+            for j in range(len(t.low)):
+                out_temp += [change_interval(vals[index], -1, 1, t.low[j], t.high[j])]
+                index += 1
+            out += out_temp
+        elif isinstance(t, gym.spaces.Discrete):
+            out += [change_float_to_int_interval(vals[index], -1, 1, 0, t.n - 1)]
+            index += 1
+        else:
+            raise ValueError("Unsupported type ", str(t))
+    # burk
+    if len(types) == 1 and not isinstance(types[0], gym.spaces.Box):
+        return out[0]
+    else:
+        return out
+
+
+class CGPWrapper(Solver, DeterministicPolicies):
+    """Cartesian Genetic Programming solver."""
+
+    T_domain = D
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        folder_name,
+        library=None,
+        col=100,
+        row=1,
+        nb_ind=4,
+        mutation_rate_nodes=0.1,
+        mutation_rate_outputs=0.3,
+        n_cpus=1,
+        n_it=1000000,
+        genome=None,
+        verbose=True,
+        callback: Callable[[CGPWrapper], bool] = lambda solver: False,
+    ):
+        """
+
+        # Parameters
+        domain_factory
+        folder_name
+        library
+        col
+        row
+        nb_ind
+        mutation_rate_nodes
+        mutation_rate_outputs
+        n_cpus
+        n_it
+        genome
+        verbose
+        callback: function called at each solver iteration. If returning true, the solve process stops.
+
+        """
+        Solver.__init__(self, domain_factory=domain_factory)
+        self.callback = callback
+        if library is None:
+            library = self._get_default_function_lib()
+
+        self._library = library
+        self._folder_name = folder_name
+        self._col = col
+        self._row = row
+        self._nb_ind = nb_ind
+        self._mutation_rate_nodes = mutation_rate_nodes
+        self._mutation_rate_outputs = mutation_rate_outputs
+        self._n_cpus = n_cpus
+        self._n_it = n_it
+        self._genome = genome
+        self._verbose = verbose
+
+    @classmethod
+    def _check_domain_additional(cls, domain: D) -> bool:
+        """
+        CGP manage all kind of gym types, BOX, DISCRETE and TUPLE as well
+        """
+        action_space = domain.get_action_space().unwrapped()
+        observation_space = domain.get_observation_space().unwrapped()
+
+        if not isinstance(action_space, Iterable) and not isinstance(
+            action_space, gym.spaces.Tuple
+        ):
+            action_space = [action_space]
+        if not isinstance(observation_space, Iterable) and not isinstance(
+            observation_space, gym.spaces.Tuple
+        ):
+            observation_space = [observation_space]
+
+        flat_action_space = list(flatten(action_space))
+        flat_observation_space = list(flatten(observation_space))
+
+        print(flat_action_space)
+        print(flat_observation_space)
+
+        valide_action_space = True
+        for x in flat_action_space:
+            valide_action_space = isinstance(
+                x, (gym.spaces.Tuple, gym.spaces.Discrete, gym.spaces.Box)
+            )
+
+        validate_observation_space = True
+        for x in flat_observation_space:
+            validate_observation_space = isinstance(
+                x, (gym.spaces.Tuple, gym.spaces.Discrete, gym.spaces.Box)
+            )
+
+        return valide_action_space and validate_observation_space
+
+    def _solve(self) -> None:
+        domain = self._domain_factory()
+
+        evaluator = SkDecideEvaluator(domain)
+        if self._genome is None:
+            a = domain.get_action_space().sample()
+            b = domain.get_observation_space().sample()
+            if isinstance(a, Iterable) or isinstance(a, gym.spaces.Tuple):
+                num_outputs = len(a)
+            else:
+                num_outputs = 1
+            if isinstance(b, Iterable) or isinstance(b, gym.spaces.Tuple):
+                num_inputs = len(b)
+            else:
+                num_inputs = 1
+            cgpFather = CGP.random(
+                num_inputs, num_outputs, self._col, self._row, self._library, 1.0
+            )
+        else:
+            cgpFather = CGP.load_from_file(self._genome, self._library)
+
+        if self._verbose:
+            print(cgpFather.genome)
+
+        es = CGPES(
+            num_offsprings=self._nb_ind,
+            mutation_rate_nodes=self._mutation_rate_nodes,
+            mutation_rate_outputs=self._mutation_rate_outputs,
+            father=cgpFather,
+            evaluator=evaluator,
+            folder=self._folder_name,
+            num_cpus=self._n_cpus,
+            verbose=self._verbose,
+            callback=self.callback,
+            cgpwrapper=self,
+        )
+        self._domain = domain
+        self._es = es
+        self._evaluator = evaluator
+
+        es.run(self._n_it)
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+
+        return denorm(
+            self._es.father.run(
+                norm_and_flatten(
+                    observation, self._domain.get_observation_space().unwrapped()
+                )
+            ),
+            self._domain.get_action_space().unwrapped(),
+        )
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
+
+    def _get_default_function_lib(self):
+        return [
+            CGP.CGPFunc(f_sum, "sum", 2),
+            CGP.CGPFunc(f_aminus, "aminus", 2),
+            CGP.CGPFunc(f_mult, "mult", 2),
+            CGP.CGPFunc(f_exp, "exp", 2),
+            CGP.CGPFunc(f_abs, "abs", 1),
+            CGP.CGPFunc(f_sqrt, "sqrt", 1),
+            CGP.CGPFunc(f_sqrtxy, "sqrtxy", 2),
+            CGP.CGPFunc(f_squared, "squared", 1),
+            CGP.CGPFunc(f_pow, "pow", 2),
+            CGP.CGPFunc(f_one, "one", 0),
+            CGP.CGPFunc(f_zero, "zero", 0),
+            CGP.CGPFunc(f_inv, "inv", 1),
+            CGP.CGPFunc(f_gt, "gt", 2),
+            CGP.CGPFunc(f_asin, "asin", 1),
+            CGP.CGPFunc(f_acos, "acos", 1),
+            CGP.CGPFunc(f_atan, "atan", 1),
+            CGP.CGPFunc(f_min, "min", 2),
+            CGP.CGPFunc(f_max, "max", 2),
+            CGP.CGPFunc(f_round, "round", 1),
+            CGP.CGPFunc(f_floor, "floor", 1),
+            CGP.CGPFunc(f_ceil, "ceil", 1),
+        ]
+
+
+class SkDecideEvaluator(Evaluator):
+    def __init__(self, domain, it_max=10000, ep_max=1):
+        super().__init__()
+        self.it_max = it_max
+        self.ep_max = ep_max
+        self.domain = domain
+
+        # def get_mins_maxs(space):
+        #     if not isinstance(space, gym.spaces.Tuple):
+        #         space = tuple([space])
+        #     mins = []
+        #     maxs = []
+        #     for box in space:
+        #         mins += list(box.low)
+        #         maxs += list(box.high)
+        #     return np.array(mins), np.array(maxs)
+
+        # self.obs_mins, self.obs_maxs = get_mins_maxs(domain.get_observation_space().unwrapped())
+        # #self.act_mins, self.act_maxs = 0,2#get_mins_maxs(domain.get_action_space().unwrapped())
+
+    def evaluate(self, cgp, it, verbose=False):
+        fitnesses = np.zeros(self.ep_max)
+        for e in range(self.ep_max):
+            end = False
+            fit = 0
+            states = self.domain.reset()
+            step = 0
+            while not end and step < self.it_max:
+                actions = denorm(
+                    cgp.run(
+                        norm_and_flatten(
+                            states, self.domain.get_observation_space().unwrapped()
+                        )
+                    ),
+                    self.domain.get_action_space().unwrapped(),
+                )
+                states, transition_value, end, _ = self.domain.step(actions).astuple()
+                reward = transition_value[0]  # TODO: correct Gym wrapper
+
+                if verbose:
+                    print(states, "=>", actions)
+
+                fit += reward
+                step += 1
+            fitnesses[e] = fit
+        np.sort(fitnesses)
+        fit = 0
+        sum_e = 0
+        for e in range(self.ep_max):
+            fit += fitnesses[e] * (e + 1)
+            sum_e += e + 1
+
+        return fit / sum_e
+
+    def clone(self):
+        return SkDecideEvaluator(self.domain, self.it_max, self.ep_max)
```

## skdecide/hub/solver/cgp/pycgp/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
```

## skdecide/hub/solver/cgp/pycgp/cgp.py

 * *Ordering differences only*

```diff
@@ -1,350 +1,350 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-import random as rnd
-import sys
-
-import numpy as np
-
-
-class CGP:
-    class CGPFunc:
-        def __init__(self, f, name, arity):
-            self.function = f
-            self.name = name
-            self.arity = arity
-
-    class CGPNode:
-        def __init__(self, args, f):
-            self.args = args
-            self.function = f
-
-    def __init__(
-        self,
-        genome,
-        num_inputs,
-        num_outputs,
-        num_cols,
-        num_rows,
-        library,
-        recurrency_distance=1.0,
-    ):
-        self.genome = genome.copy()
-        self.num_inputs = num_inputs
-        self.num_outputs = num_outputs
-        self.num_cols = num_cols
-        self.num_rows = num_rows
-        self.max_graph_length = num_cols * num_rows
-        self.library = library
-        self.max_arity = 0
-        self.recurrency_distance = recurrency_distance
-        for f in self.library:
-            self.max_arity = np.maximum(self.max_arity, f.arity)
-        self.graph_created = False
-
-    def create_graph(self):
-        self.to_evaluate = np.zeros(self.max_graph_length, dtype=bool)
-        self.node_output = np.zeros(
-            self.max_graph_length + self.num_inputs, dtype=np.float64
-        )
-        self.nodes_used = []
-        self.output_genes = np.zeros(self.num_outputs, dtype=np.int_)
-        self.nodes = np.empty(0, dtype=self.CGPNode)
-        for i in range(0, self.num_outputs):
-            self.output_genes[i] = self.genome[len(self.genome) - self.num_outputs + i]
-        i = 0
-        # building node list
-        while i < len(self.genome) - self.num_outputs:
-            f = self.genome[i]
-            args = np.empty(0, dtype=int)
-            for j in range(self.max_arity):
-                args = np.append(args, self.genome[i + j + 1])
-            i += self.max_arity + 1
-            self.nodes = np.append(self.nodes, self.CGPNode(args, f))
-        self.node_to_evaluate()
-        self.graph_created = True
-
-    def node_to_evaluate(self):
-        p = 0
-        while p < self.num_outputs:
-            if self.output_genes[p] - self.num_inputs >= 0:
-                self.to_evaluate[self.output_genes[p] - self.num_inputs] = True
-            p = p + 1
-        p = self.max_graph_length - 1
-        while p >= 0:
-            if self.to_evaluate[p]:
-                for i in range(0, len(self.nodes[p].args)):
-                    arg = self.nodes[p].args[i]
-                    if arg - self.num_inputs >= 0:
-                        self.to_evaluate[arg - self.num_inputs] = True
-                self.nodes_used.append(p)
-            p = p - 1
-        self.nodes_used = np.array(self.nodes_used)
-
-    def load_input_data(self, input_data):
-        for p in range(self.num_inputs):
-            self.node_output[p] = input_data[p]
-
-    def compute_graph(self):
-        self.node_output_old = self.node_output.copy()
-        p = len(self.nodes_used) - 1
-        while p >= 0:
-            args = np.zeros(self.max_arity)
-            for i in range(0, self.max_arity):
-                args[i] = self.node_output_old[self.nodes[self.nodes_used[p]].args[i]]
-            f = self.library[self.nodes[self.nodes_used[p]].function].function
-            self.node_output[self.nodes_used[p] + self.num_inputs] = f(args)
-
-            if (
-                self.node_output[self.nodes_used[p] + self.num_inputs]
-                != self.node_output[self.nodes_used[p] + self.num_inputs]
-            ):
-                print(
-                    self.library[self.nodes[self.nodes_used[p]].function].name,
-                    " returned NaN with ",
-                    args,
-                )
-            if (
-                self.node_output[self.nodes_used[p] + self.num_inputs] < -1.0
-                or self.node_output[self.nodes_used[p] + self.num_inputs] > 1.0
-            ):
-                print(
-                    self.library[self.nodes[self.nodes_used[p]].function].name,
-                    " returned ",
-                    self.node_output[self.nodes_used[p] + self.num_inputs],
-                    " with ",
-                    args,
-                )
-
-            p = p - 1
-
-    def run(self, inputData):
-        if not self.graph_created:
-            self.create_graph()
-
-        self.load_input_data(inputData)
-        self.compute_graph()
-        return self.read_output()
-
-    def read_output(self):
-        output = np.zeros(self.num_outputs)
-        for p in range(0, self.num_outputs):
-            output[p] = self.node_output[self.output_genes[p]]
-        return output
-
-    def clone(self):
-        return CGP(
-            self.genome,
-            self.num_inputs,
-            self.num_outputs,
-            self.num_cols,
-            self.num_rows,
-            self.library,
-        )
-
-    def mutate(self, num_mutationss):
-        for i in range(0, num_mutationss):
-            index = rnd.randint(0, len(self.genome) - 1)
-            if index < self.num_cols * self.num_rows * (self.max_arity + 1):
-                # this is an internal node
-                if index % (self.max_arity + 1) == 0:
-                    # mutate function
-                    self.genome[index] = rnd.randint(0, len(self.library) - 1)
-                else:
-                    # mutate connection
-                    self.genome[index] = rnd.randint(
-                        0,
-                        self.num_inputs
-                        + (int(index / (self.max_arity + 1)) - 1) * self.num_rows,
-                    )
-            else:
-                # this is an output node
-                self.genome[index] = rnd.randint(
-                    0, self.num_inputs + self.num_cols * self.num_rows - 1
-                )
-
-    def mutate_per_gene(self, mutation_rate_nodes, mutation_rate_outputs):
-        for index in range(0, len(self.genome)):
-            if index < self.num_cols * self.num_rows * (self.max_arity + 1):
-                # this is an internal node
-                if rnd.random() < mutation_rate_nodes:
-                    if index % (self.max_arity + 1) == 0:
-                        # mutate function
-                        self.genome[index] = rnd.randint(0, len(self.library) - 1)
-                    else:
-                        # mutate connection
-                        self.genome[index] = rnd.randint(
-                            0,
-                            min(
-                                self.max_graph_length + self.num_inputs - 1,
-                                (
-                                    self.num_inputs
-                                    + (int(index / (self.max_arity + 1)) - 1)
-                                    * self.num_rows
-                                )
-                                * self.recurrency_distance,
-                            ),
-                        )
-                        # self.genome[index] = rnd.randint(0, self.num_inputs + (int(index / (self.max_arity + 1)) - 1) * self.num_rows)
-            else:
-                # this is an output node
-                if rnd.random() < mutation_rate_outputs:
-                    # this is an output node
-                    self.genome[index] = rnd.randint(
-                        0, self.num_inputs + self.num_cols * self.num_rows - 1
-                    )
-
-    def to_dot(self, file_name, input_names, output_names):
-        if not self.graph_created:
-            self.create_graph()
-        out = open(file_name, "w")
-        out.write("digraph cgp {\n")
-        out.write('\tsize = "4,4";\n')
-        self.dot_rec_visited_nodes = np.empty(1)
-        for i in range(self.num_outputs):
-            out.write("\t" + output_names[i] + " [shape=oval];\n")
-            self._write_dot_from_gene(
-                output_names[i], self.output_genes[i], out, 0, input_names, output_names
-            )
-        out.write("}")
-        out.close()
-
-    def _write_dot_from_gene(self, to_name, pos, out, a, input_names, output_names):
-        if pos < self.num_inputs:
-            out.write("\t" + input_names[pos] + " [shape=polygon,sides=6];\n")
-            out.write(
-                "\t"
-                + input_names[pos]
-                + " -> "
-                + to_name
-                + ' [label="'
-                + str(a)
-                + '"];\n'
-            )
-            self.dot_rec_visited_nodes = np.append(self.dot_rec_visited_nodes, [pos])
-        else:
-            pos -= self.num_inputs
-            out.write(
-                "\t"
-                + self.library[self.nodes[pos].function].name
-                + "_"
-                + str(pos)
-                + " -> "
-                + to_name
-                + ' [label="'
-                + str(a)
-                + '"];\n'
-            )
-            if pos + self.num_inputs not in self.dot_rec_visited_nodes:
-                out.write(
-                    "\t"
-                    + self.library[self.nodes[pos].function].name
-                    + "_"
-                    + str(pos)
-                    + " [shape=none];\n"
-                )
-                for a in range(self.library[self.nodes[pos].function].arity):
-                    self._write_dot_from_gene(
-                        self.library[self.nodes[pos].function].name + "_" + str(pos),
-                        self.nodes[pos].args[a],
-                        out,
-                        a,
-                        input_names,
-                        output_names,
-                    )
-            self.dot_rec_visited_nodes = np.append(
-                self.dot_rec_visited_nodes, [pos + self.num_inputs]
-            )
-
-    def to_function_string(self, input_names, output_names):
-        if not self.graph_created:
-            self.create_graph()
-        for o in range(self.num_outputs):
-            print(output_names[o] + " = ", end="")
-            self._write_from_gene(self.output_genes[o], input_names, output_names)
-            print(";")
-            print("")
-
-    def _write_from_gene(self, pos, input_names, output_names):
-        if pos < self.num_inputs:
-            print(input_names[pos], end="")
-        else:
-            pos -= self.num_inputs
-            print(self.library[self.nodes[pos].function].name + "(", end="")
-            for a in range(self.library[self.nodes[pos].function].arity):
-                # print(' ', end='')
-                self._write_from_gene(
-                    self.nodes[pos].args[a], input_names, output_names
-                )
-                if a != self.library[self.nodes[pos].function].arity - 1:
-                    print(", ", end="")
-                # else:
-                # 	print(')', end='')
-            print(")", end="")
-
-    @classmethod
-    def random(
-        cls, num_inputs, num_outputs, num_cols, num_rows, library, recurrency_distance
-    ):
-        max_arity = 0
-        for f in library:
-            max_arity = np.maximum(max_arity, f.arity)
-        genome = np.zeros(
-            num_cols * num_rows * (max_arity + 1) + num_outputs, dtype=int
-        )
-        gPos = 0
-        for c in range(0, num_cols):
-            for r in range(0, num_rows):
-                genome[gPos] = rnd.randint(0, len(library) - 1)
-                for a in range(max_arity):
-                    genome[gPos + a + 1] = rnd.randint(0, num_inputs + c * num_rows - 1)
-                gPos = gPos + max_arity + 1
-        for o in range(0, num_outputs):
-            genome[gPos] = rnd.randint(0, num_inputs + num_cols * num_rows - 1)
-            gPos = gPos + 1
-        return CGP(
-            genome,
-            num_inputs,
-            num_outputs,
-            num_cols,
-            num_rows,
-            library,
-            recurrency_distance,
-        )
-
-    def save(self, file_name):
-        out = open(file_name, "w")
-        out.write(str(self.num_inputs) + " ")
-        out.write(str(self.num_outputs) + " ")
-        out.write(str(self.num_cols) + " ")
-        out.write(str(self.num_rows) + "\n")
-        for g in self.genome:
-            out.write(str(g) + " ")
-        out.write("\n")
-        for f in self.library:
-            out.write(f.name + " ")
-        out.close()
-
-    @classmethod
-    def load_from_file(cls, file_name, library):
-        inp = open(file_name, "r")
-        pams = inp.readline().split()
-        genes = inp.readline().split()
-        funcs = inp.readline().split()
-        inp.close()
-        params = np.empty(0, dtype=int)
-        for p in pams:
-            params = np.append(params, int(p))
-        genome = np.empty(0, dtype=int)
-        for g in genes:
-            genome = np.append(genome, int(g))
-        return CGP(genome, params[0], params[1], params[2], params[3], library)
-
-    @classmethod
-    def test(cls, num):
-        c = CGP.random(2, 1, 2, 2, 2)
-        for i in range(0, num):
-            c.mutate(1)
-            print(c.genome)
-            print(c.run([1, 2]))
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+import random as rnd
+import sys
+
+import numpy as np
+
+
+class CGP:
+    class CGPFunc:
+        def __init__(self, f, name, arity):
+            self.function = f
+            self.name = name
+            self.arity = arity
+
+    class CGPNode:
+        def __init__(self, args, f):
+            self.args = args
+            self.function = f
+
+    def __init__(
+        self,
+        genome,
+        num_inputs,
+        num_outputs,
+        num_cols,
+        num_rows,
+        library,
+        recurrency_distance=1.0,
+    ):
+        self.genome = genome.copy()
+        self.num_inputs = num_inputs
+        self.num_outputs = num_outputs
+        self.num_cols = num_cols
+        self.num_rows = num_rows
+        self.max_graph_length = num_cols * num_rows
+        self.library = library
+        self.max_arity = 0
+        self.recurrency_distance = recurrency_distance
+        for f in self.library:
+            self.max_arity = np.maximum(self.max_arity, f.arity)
+        self.graph_created = False
+
+    def create_graph(self):
+        self.to_evaluate = np.zeros(self.max_graph_length, dtype=bool)
+        self.node_output = np.zeros(
+            self.max_graph_length + self.num_inputs, dtype=np.float64
+        )
+        self.nodes_used = []
+        self.output_genes = np.zeros(self.num_outputs, dtype=np.int_)
+        self.nodes = np.empty(0, dtype=self.CGPNode)
+        for i in range(0, self.num_outputs):
+            self.output_genes[i] = self.genome[len(self.genome) - self.num_outputs + i]
+        i = 0
+        # building node list
+        while i < len(self.genome) - self.num_outputs:
+            f = self.genome[i]
+            args = np.empty(0, dtype=int)
+            for j in range(self.max_arity):
+                args = np.append(args, self.genome[i + j + 1])
+            i += self.max_arity + 1
+            self.nodes = np.append(self.nodes, self.CGPNode(args, f))
+        self.node_to_evaluate()
+        self.graph_created = True
+
+    def node_to_evaluate(self):
+        p = 0
+        while p < self.num_outputs:
+            if self.output_genes[p] - self.num_inputs >= 0:
+                self.to_evaluate[self.output_genes[p] - self.num_inputs] = True
+            p = p + 1
+        p = self.max_graph_length - 1
+        while p >= 0:
+            if self.to_evaluate[p]:
+                for i in range(0, len(self.nodes[p].args)):
+                    arg = self.nodes[p].args[i]
+                    if arg - self.num_inputs >= 0:
+                        self.to_evaluate[arg - self.num_inputs] = True
+                self.nodes_used.append(p)
+            p = p - 1
+        self.nodes_used = np.array(self.nodes_used)
+
+    def load_input_data(self, input_data):
+        for p in range(self.num_inputs):
+            self.node_output[p] = input_data[p]
+
+    def compute_graph(self):
+        self.node_output_old = self.node_output.copy()
+        p = len(self.nodes_used) - 1
+        while p >= 0:
+            args = np.zeros(self.max_arity)
+            for i in range(0, self.max_arity):
+                args[i] = self.node_output_old[self.nodes[self.nodes_used[p]].args[i]]
+            f = self.library[self.nodes[self.nodes_used[p]].function].function
+            self.node_output[self.nodes_used[p] + self.num_inputs] = f(args)
+
+            if (
+                self.node_output[self.nodes_used[p] + self.num_inputs]
+                != self.node_output[self.nodes_used[p] + self.num_inputs]
+            ):
+                print(
+                    self.library[self.nodes[self.nodes_used[p]].function].name,
+                    " returned NaN with ",
+                    args,
+                )
+            if (
+                self.node_output[self.nodes_used[p] + self.num_inputs] < -1.0
+                or self.node_output[self.nodes_used[p] + self.num_inputs] > 1.0
+            ):
+                print(
+                    self.library[self.nodes[self.nodes_used[p]].function].name,
+                    " returned ",
+                    self.node_output[self.nodes_used[p] + self.num_inputs],
+                    " with ",
+                    args,
+                )
+
+            p = p - 1
+
+    def run(self, inputData):
+        if not self.graph_created:
+            self.create_graph()
+
+        self.load_input_data(inputData)
+        self.compute_graph()
+        return self.read_output()
+
+    def read_output(self):
+        output = np.zeros(self.num_outputs)
+        for p in range(0, self.num_outputs):
+            output[p] = self.node_output[self.output_genes[p]]
+        return output
+
+    def clone(self):
+        return CGP(
+            self.genome,
+            self.num_inputs,
+            self.num_outputs,
+            self.num_cols,
+            self.num_rows,
+            self.library,
+        )
+
+    def mutate(self, num_mutationss):
+        for i in range(0, num_mutationss):
+            index = rnd.randint(0, len(self.genome) - 1)
+            if index < self.num_cols * self.num_rows * (self.max_arity + 1):
+                # this is an internal node
+                if index % (self.max_arity + 1) == 0:
+                    # mutate function
+                    self.genome[index] = rnd.randint(0, len(self.library) - 1)
+                else:
+                    # mutate connection
+                    self.genome[index] = rnd.randint(
+                        0,
+                        self.num_inputs
+                        + (int(index / (self.max_arity + 1)) - 1) * self.num_rows,
+                    )
+            else:
+                # this is an output node
+                self.genome[index] = rnd.randint(
+                    0, self.num_inputs + self.num_cols * self.num_rows - 1
+                )
+
+    def mutate_per_gene(self, mutation_rate_nodes, mutation_rate_outputs):
+        for index in range(0, len(self.genome)):
+            if index < self.num_cols * self.num_rows * (self.max_arity + 1):
+                # this is an internal node
+                if rnd.random() < mutation_rate_nodes:
+                    if index % (self.max_arity + 1) == 0:
+                        # mutate function
+                        self.genome[index] = rnd.randint(0, len(self.library) - 1)
+                    else:
+                        # mutate connection
+                        self.genome[index] = rnd.randint(
+                            0,
+                            min(
+                                self.max_graph_length + self.num_inputs - 1,
+                                (
+                                    self.num_inputs
+                                    + (int(index / (self.max_arity + 1)) - 1)
+                                    * self.num_rows
+                                )
+                                * self.recurrency_distance,
+                            ),
+                        )
+                        # self.genome[index] = rnd.randint(0, self.num_inputs + (int(index / (self.max_arity + 1)) - 1) * self.num_rows)
+            else:
+                # this is an output node
+                if rnd.random() < mutation_rate_outputs:
+                    # this is an output node
+                    self.genome[index] = rnd.randint(
+                        0, self.num_inputs + self.num_cols * self.num_rows - 1
+                    )
+
+    def to_dot(self, file_name, input_names, output_names):
+        if not self.graph_created:
+            self.create_graph()
+        out = open(file_name, "w")
+        out.write("digraph cgp {\n")
+        out.write('\tsize = "4,4";\n')
+        self.dot_rec_visited_nodes = np.empty(1)
+        for i in range(self.num_outputs):
+            out.write("\t" + output_names[i] + " [shape=oval];\n")
+            self._write_dot_from_gene(
+                output_names[i], self.output_genes[i], out, 0, input_names, output_names
+            )
+        out.write("}")
+        out.close()
+
+    def _write_dot_from_gene(self, to_name, pos, out, a, input_names, output_names):
+        if pos < self.num_inputs:
+            out.write("\t" + input_names[pos] + " [shape=polygon,sides=6];\n")
+            out.write(
+                "\t"
+                + input_names[pos]
+                + " -> "
+                + to_name
+                + ' [label="'
+                + str(a)
+                + '"];\n'
+            )
+            self.dot_rec_visited_nodes = np.append(self.dot_rec_visited_nodes, [pos])
+        else:
+            pos -= self.num_inputs
+            out.write(
+                "\t"
+                + self.library[self.nodes[pos].function].name
+                + "_"
+                + str(pos)
+                + " -> "
+                + to_name
+                + ' [label="'
+                + str(a)
+                + '"];\n'
+            )
+            if pos + self.num_inputs not in self.dot_rec_visited_nodes:
+                out.write(
+                    "\t"
+                    + self.library[self.nodes[pos].function].name
+                    + "_"
+                    + str(pos)
+                    + " [shape=none];\n"
+                )
+                for a in range(self.library[self.nodes[pos].function].arity):
+                    self._write_dot_from_gene(
+                        self.library[self.nodes[pos].function].name + "_" + str(pos),
+                        self.nodes[pos].args[a],
+                        out,
+                        a,
+                        input_names,
+                        output_names,
+                    )
+            self.dot_rec_visited_nodes = np.append(
+                self.dot_rec_visited_nodes, [pos + self.num_inputs]
+            )
+
+    def to_function_string(self, input_names, output_names):
+        if not self.graph_created:
+            self.create_graph()
+        for o in range(self.num_outputs):
+            print(output_names[o] + " = ", end="")
+            self._write_from_gene(self.output_genes[o], input_names, output_names)
+            print(";")
+            print("")
+
+    def _write_from_gene(self, pos, input_names, output_names):
+        if pos < self.num_inputs:
+            print(input_names[pos], end="")
+        else:
+            pos -= self.num_inputs
+            print(self.library[self.nodes[pos].function].name + "(", end="")
+            for a in range(self.library[self.nodes[pos].function].arity):
+                # print(' ', end='')
+                self._write_from_gene(
+                    self.nodes[pos].args[a], input_names, output_names
+                )
+                if a != self.library[self.nodes[pos].function].arity - 1:
+                    print(", ", end="")
+                # else:
+                # 	print(')', end='')
+            print(")", end="")
+
+    @classmethod
+    def random(
+        cls, num_inputs, num_outputs, num_cols, num_rows, library, recurrency_distance
+    ):
+        max_arity = 0
+        for f in library:
+            max_arity = np.maximum(max_arity, f.arity)
+        genome = np.zeros(
+            num_cols * num_rows * (max_arity + 1) + num_outputs, dtype=int
+        )
+        gPos = 0
+        for c in range(0, num_cols):
+            for r in range(0, num_rows):
+                genome[gPos] = rnd.randint(0, len(library) - 1)
+                for a in range(max_arity):
+                    genome[gPos + a + 1] = rnd.randint(0, num_inputs + c * num_rows - 1)
+                gPos = gPos + max_arity + 1
+        for o in range(0, num_outputs):
+            genome[gPos] = rnd.randint(0, num_inputs + num_cols * num_rows - 1)
+            gPos = gPos + 1
+        return CGP(
+            genome,
+            num_inputs,
+            num_outputs,
+            num_cols,
+            num_rows,
+            library,
+            recurrency_distance,
+        )
+
+    def save(self, file_name):
+        out = open(file_name, "w")
+        out.write(str(self.num_inputs) + " ")
+        out.write(str(self.num_outputs) + " ")
+        out.write(str(self.num_cols) + " ")
+        out.write(str(self.num_rows) + "\n")
+        for g in self.genome:
+            out.write(str(g) + " ")
+        out.write("\n")
+        for f in self.library:
+            out.write(f.name + " ")
+        out.close()
+
+    @classmethod
+    def load_from_file(cls, file_name, library):
+        inp = open(file_name, "r")
+        pams = inp.readline().split()
+        genes = inp.readline().split()
+        funcs = inp.readline().split()
+        inp.close()
+        params = np.empty(0, dtype=int)
+        for p in pams:
+            params = np.append(params, int(p))
+        genome = np.empty(0, dtype=int)
+        for g in genes:
+            genome = np.append(genome, int(g))
+        return CGP(genome, params[0], params[1], params[2], params[3], library)
+
+    @classmethod
+    def test(cls, num):
+        c = CGP.random(2, 1, 2, 2, 2)
+        for i in range(0, num):
+            c.mutate(1)
+            print(c.genome)
+            print(c.run([1, 2]))
```

## skdecide/hub/solver/cgp/pycgp/cgpes.py

```diff
@@ -1,118 +1,131 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-import os
-
-import numpy as np
-from joblib import Parallel, delayed
-
-from .cgp import CGP
-from .evaluator import Evaluator
-
-
-class CGPES:
-    def __init__(
-        self,
-        num_offsprings,
-        mutation_rate_nodes,
-        mutation_rate_outputs,
-        father,
-        evaluator,
-        folder="genomes",
-        num_cpus=1,
-        verbose=True,
-    ):
-        self.num_offsprings = num_offsprings
-        self.mutation_rate_nodes = mutation_rate_nodes
-        self.mutation_rate_outputs = mutation_rate_outputs
-        self.father = father
-        # self.num_mutations = int(len(self.father.genome) * self.mutation_rate)
-        self.evaluator = evaluator
-        self.num_cpus = num_cpus
-        self.folder = folder
-        self.verbose = verbose
-        if self.num_cpus > 1:
-            self.evaluator_pool = []
-            for i in range(self.num_offsprings):
-                self.evaluator_pool.append(self.evaluator.clone())
-
-    def run(self, num_iteration):
-        if not os.path.isdir(self.folder):
-            os.mkdir(self.folder)
-        self.logfile = open(self.folder + "/out.txt", "w")
-        self.current_fitness = self.evaluator.evaluate(self.father, 0)
-        self.father.save(
-            self.folder + "/cgp_genome_0_" + str(self.current_fitness) + ".txt"
-        )
-        self.offsprings = np.empty(self.num_offsprings, dtype=CGP)
-        self.offspring_fitnesses = np.zeros(self.num_offsprings, dtype=float)
-        for self.it in range(1, num_iteration + 1):
-            # generate offsprings
-            if self.num_cpus == 1:
-                for i in range(0, self.num_offsprings):
-                    self.offsprings[i] = self.father.clone()
-                    # self.offsprings[i].mutate(self.num_mutations)
-                    self.offsprings[i].mutate_per_gene(
-                        self.mutation_rate_nodes, self.mutation_rate_outputs
-                    )
-                    self.offspring_fitnesses[i] = self.evaluator.evaluate(
-                        self.offsprings[i], self.it
-                    )
-            else:
-                for i in range(self.num_offsprings):
-                    self.offsprings[i] = self.father.clone()
-                    # self.offsprings[i].mutate(self.num_mutations)
-                    self.offsprings[i].mutate_per_gene(
-                        self.mutation_rate_nodes, self.mutation_rate_outputs
-                    )
-
-                def offspring_eval_task(offspring_id):
-                    return self.evaluator_pool[offspring_id].evaluate(
-                        self.offsprings[offspring_id], self.it
-                    )
-
-                self.offspring_fitnesses = Parallel(n_jobs=self.num_cpus)(
-                    delayed(offspring_eval_task)(i) for i in range(self.num_offsprings)
-                )
-            # get the best fitness
-            best_offspring = np.argmax(self.offspring_fitnesses)
-            # compare to father
-            self.father_was_updated = False
-            if self.offspring_fitnesses[best_offspring] >= self.current_fitness:
-                self.current_fitness = self.offspring_fitnesses[best_offspring]
-                self.father = self.offsprings[best_offspring]
-                self.father_was_updated = True
-            # display stats
-            if self.verbose:
-                print(
-                    self.it,
-                    "\t",
-                    self.current_fitness,
-                    "\t",
-                    self.father_was_updated,
-                    "\t",
-                    self.offspring_fitnesses,
-                )
-                print("====================================================")
-            self.logfile.write(
-                str(self.it)
-                + "\t"
-                + str(self.current_fitness)
-                + "\t"
-                + str(self.father_was_updated)
-                + "\t"
-                + str(self.offspring_fitnesses)
-                + "\n"
-            )
-            self.logfile.flush()
-            if self.father_was_updated:
-                # print(self.father.genome)
-                self.father.save(
-                    self.folder
-                    + "/cgp_genome_"
-                    + str(self.it)
-                    + "_"
-                    + str(self.current_fitness)
-                    + ".txt"
-                )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations  # allow using CGPWrapper in annotations
+
+import os
+from typing import TYPE_CHECKING, Callable
+
+import numpy as np
+from joblib import Parallel, delayed
+
+from .cgp import CGP
+from .evaluator import Evaluator
+
+if TYPE_CHECKING:  # avoids circular imports
+    from ..cgp import CGPWrapper
+
+
+class CGPES:
+    def __init__(
+        self,
+        num_offsprings,
+        mutation_rate_nodes,
+        mutation_rate_outputs,
+        father,
+        evaluator,
+        cgpwrapper: CGPWrapper,
+        callback: Callable[[CGPWrapper], bool],
+        folder="genomes",
+        num_cpus=1,
+        verbose=True,
+    ):
+        self.callback = callback
+        self.cgpwrapper = cgpwrapper
+        self.num_offsprings = num_offsprings
+        self.mutation_rate_nodes = mutation_rate_nodes
+        self.mutation_rate_outputs = mutation_rate_outputs
+        self.father = father
+        # self.num_mutations = int(len(self.father.genome) * self.mutation_rate)
+        self.evaluator = evaluator
+        self.num_cpus = num_cpus
+        self.folder = folder
+        self.verbose = verbose
+        if self.num_cpus > 1:
+            self.evaluator_pool = []
+            for i in range(self.num_offsprings):
+                self.evaluator_pool.append(self.evaluator.clone())
+
+    def run(self, num_iteration):
+        if not os.path.isdir(self.folder):
+            os.mkdir(self.folder)
+        self.logfile = open(self.folder + "/out.txt", "w")
+        self.current_fitness = self.evaluator.evaluate(self.father, 0)
+        self.father.save(
+            self.folder + "/cgp_genome_0_" + str(self.current_fitness) + ".txt"
+        )
+        self.offsprings = np.empty(self.num_offsprings, dtype=CGP)
+        self.offspring_fitnesses = np.zeros(self.num_offsprings, dtype=float)
+        for self.it in range(1, num_iteration + 1):
+            # generate offsprings
+            if self.num_cpus == 1:
+                for i in range(0, self.num_offsprings):
+                    self.offsprings[i] = self.father.clone()
+                    # self.offsprings[i].mutate(self.num_mutations)
+                    self.offsprings[i].mutate_per_gene(
+                        self.mutation_rate_nodes, self.mutation_rate_outputs
+                    )
+                    self.offspring_fitnesses[i] = self.evaluator.evaluate(
+                        self.offsprings[i], self.it
+                    )
+            else:
+                for i in range(self.num_offsprings):
+                    self.offsprings[i] = self.father.clone()
+                    # self.offsprings[i].mutate(self.num_mutations)
+                    self.offsprings[i].mutate_per_gene(
+                        self.mutation_rate_nodes, self.mutation_rate_outputs
+                    )
+
+                def offspring_eval_task(offspring_id):
+                    return self.evaluator_pool[offspring_id].evaluate(
+                        self.offsprings[offspring_id], self.it
+                    )
+
+                self.offspring_fitnesses = Parallel(n_jobs=self.num_cpus)(
+                    delayed(offspring_eval_task)(i) for i in range(self.num_offsprings)
+                )
+            # get the best fitness
+            best_offspring = np.argmax(self.offspring_fitnesses)
+            # compare to father
+            self.father_was_updated = False
+            if self.offspring_fitnesses[best_offspring] >= self.current_fitness:
+                self.current_fitness = self.offspring_fitnesses[best_offspring]
+                self.father = self.offsprings[best_offspring]
+                self.father_was_updated = True
+            # display stats
+            if self.verbose:
+                print(
+                    self.it,
+                    "\t",
+                    self.current_fitness,
+                    "\t",
+                    self.father_was_updated,
+                    "\t",
+                    self.offspring_fitnesses,
+                )
+                print("====================================================")
+            self.logfile.write(
+                str(self.it)
+                + "\t"
+                + str(self.current_fitness)
+                + "\t"
+                + str(self.father_was_updated)
+                + "\t"
+                + str(self.offspring_fitnesses)
+                + "\n"
+            )
+            self.logfile.flush()
+            if self.father_was_updated:
+                # print(self.father.genome)
+                self.father.save(
+                    self.folder
+                    + "/cgp_genome_"
+                    + str(self.it)
+                    + "_"
+                    + str(self.current_fitness)
+                    + ".txt"
+                )
+            # Stopping because of user's callback?
+            if self.callback(self.cgpwrapper):
+                break
```

## skdecide/hub/solver/cgp/pycgp/cgpfunctions.py

 * *Ordering differences only*

```diff
@@ -1,94 +1,94 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-import math
-
-import numpy as np
-
-
-def f_sum(args):
-    return 0.5 * (args[0] + args[1])
-
-
-def f_aminus(args):
-    return 0.5 * (abs(args[0] - args[1]))
-
-
-def f_mult(args):
-    return args[0] * args[1]
-
-
-def f_exp(args):
-    return (np.exp(args[0]) - 1.0) / (np.exp(1.0) - 1.0)
-
-
-def f_abs(args):
-    return abs(args[0])
-
-
-def f_sqrt(args):
-    return np.sqrt(abs(args[0]))
-
-
-def f_sqrtxy(args):
-    return np.sqrt(args[0] * args[0] + args[1] * args[1]) / np.sqrt(2.0)
-
-
-def f_squared(args):
-    return args[0] * args[0]
-
-
-def f_pow(args):
-    return pow(abs(args[0]), abs(args[1]))
-
-
-def f_one(args):
-    return 1.0
-
-
-def f_zero(args):
-    return 0.0
-
-
-def f_inv(args):
-    if args[0] != 0.0:
-        return args[0] / abs(args[0])
-    else:
-        return 0.0
-
-
-def f_gt(args):
-    return float(args[0] > args[1])
-
-
-def f_acos(args):
-    return math.acos(args[0]) / np.pi
-
-
-def f_asin(args):
-    return 2.0 * math.asin(args[0]) / np.pi
-
-
-def f_atan(args):
-    return 4.0 * math.atan(args[0]) / np.pi
-
-
-def f_min(args):
-    return np.min(args)
-
-
-def f_max(args):
-    return np.max(args)
-
-
-def f_round(args):
-    return round(args[0])
-
-
-def f_floor(args):
-    return math.floor(args[0])
-
-
-def f_ceil(args):
-    return math.ceil(args[0])
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+import math
+
+import numpy as np
+
+
+def f_sum(args):
+    return 0.5 * (args[0] + args[1])
+
+
+def f_aminus(args):
+    return 0.5 * (abs(args[0] - args[1]))
+
+
+def f_mult(args):
+    return args[0] * args[1]
+
+
+def f_exp(args):
+    return (np.exp(args[0]) - 1.0) / (np.exp(1.0) - 1.0)
+
+
+def f_abs(args):
+    return abs(args[0])
+
+
+def f_sqrt(args):
+    return np.sqrt(abs(args[0]))
+
+
+def f_sqrtxy(args):
+    return np.sqrt(args[0] * args[0] + args[1] * args[1]) / np.sqrt(2.0)
+
+
+def f_squared(args):
+    return args[0] * args[0]
+
+
+def f_pow(args):
+    return pow(abs(args[0]), abs(args[1]))
+
+
+def f_one(args):
+    return 1.0
+
+
+def f_zero(args):
+    return 0.0
+
+
+def f_inv(args):
+    if args[0] != 0.0:
+        return args[0] / abs(args[0])
+    else:
+        return 0.0
+
+
+def f_gt(args):
+    return float(args[0] > args[1])
+
+
+def f_acos(args):
+    return math.acos(args[0]) / np.pi
+
+
+def f_asin(args):
+    return 2.0 * math.asin(args[0]) / np.pi
+
+
+def f_atan(args):
+    return 4.0 * math.atan(args[0]) / np.pi
+
+
+def f_min(args):
+    return np.min(args)
+
+
+def f_max(args):
+    return np.max(args)
+
+
+def f_round(args):
+    return round(args[0])
+
+
+def f_floor(args):
+    return math.floor(args[0])
+
+
+def f_ceil(args):
+    return math.ceil(args[0])
```

## skdecide/hub/solver/cgp/pycgp/evaluator.py

 * *Ordering differences only*

```diff
@@ -1,13 +1,13 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .cgp import CGP
-
-
-class Evaluator:
-    def evaluate(self, cgp, it):
-        raise NotImplementedError("evaluation method not implemented")
-
-    def clone(self):
-        raise NotImplementedError("clone method not implemented")
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .cgp import CGP
+
+
+class Evaluator:
+    def evaluate(self, cgp, it):
+        raise NotImplementedError("evaluation method not implemented")
+
+    def clone(self):
+        raise NotImplementedError("clone method not implemented")
```

## skdecide/hub/solver/do_solver/__init__.py

```diff
@@ -1,5 +1,17 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .do_solver_scheduling import DOSolver
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .do_solver_scheduling import DOSolver
+from .gphh import (
+    GPHH,
+    EvaluationGPHH,
+    FeatureEnum,
+    FixedPermutationPolicy,
+    GPHHPolicy,
+    ParametersGPHH,
+    PermutationDistance,
+    PoolAggregationMethod,
+    PooledGPHHPolicy,
+)
+from .sgs_policies import BasePolicyMethod, PolicyMethodParams, PolicyRCPSP
```

## skdecide/hub/solver/do_solver/do_solver_scheduling.py

```diff
@@ -1,235 +1,303 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from enum import Enum
-from typing import Any, Callable, Dict, Union
-
-from discrete_optimization.rcpsp.rcpsp_model import RCPSPModel, RCPSPSolution
-from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill import (
-    MS_RCPSPModel,
-    MS_RCPSPSolution,
-    MS_RCPSPSolution_Variant,
-)
-
-from skdecide.builders.domain.scheduling.scheduling_domains import SchedulingDomain
-from skdecide.hub.solver.do_solver.sk_to_do_binding import build_do_domain
-from skdecide.hub.solver.sgs_policies.sgs_policies import (
-    BasePolicyMethod,
-    PolicyMethodParams,
-    PolicyRCPSP,
-)
-from skdecide.solvers import DeterministicPolicies, Solver
-
-
-class D(SchedulingDomain):
-    pass
-
-
-class SolvingMethod(Enum):
-    PILE = 0
-    GA = 1
-    LS = 2
-    LP = 3
-    CP = 4
-    LNS_LP = 5
-    LNS_CP = 6
-    LNS_CP_CALENDAR = 7
-    # New algorithm, similar to lns, adding iterativelyu constraint to fulfill calendar constraints..
-
-
-def build_solver(solving_method: SolvingMethod, do_domain):
-    if isinstance(do_domain, RCPSPModel):
-        from discrete_optimization.rcpsp.rcpsp_solvers import (
-            look_for_solver,
-            solvers_map,
-        )
-
-        available = look_for_solver(do_domain)
-        solving_method_to_str = {
-            SolvingMethod.PILE: "greedy",
-            SolvingMethod.GA: "ga",
-            SolvingMethod.LS: "ls",
-            SolvingMethod.LP: "lp",
-            SolvingMethod.CP: "cp",
-            SolvingMethod.LNS_LP: "lns-lp",
-            SolvingMethod.LNS_CP: "lns-cp",
-            SolvingMethod.LNS_CP_CALENDAR: "lns-cp-calendar",
-        }
-        smap = [
-            (av, solvers_map[av])
-            for av in available
-            if solvers_map[av][0] == solving_method_to_str[solving_method]
-        ]
-        if len(smap) > 0:
-            return smap[0]
-    if isinstance(do_domain, MS_RCPSPModel):
-        from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill_solvers import (
-            look_for_solver,
-            solvers_map,
-        )
-
-        available = look_for_solver(do_domain)
-        solving_method_to_str = {
-            SolvingMethod.PILE: "greedy",
-            SolvingMethod.GA: "ga",
-            SolvingMethod.LS: "ls",
-            SolvingMethod.LP: "lp",
-            SolvingMethod.CP: "cp",
-            SolvingMethod.LNS_LP: "lns-lp",
-            SolvingMethod.LNS_CP: "lns-cp",
-            SolvingMethod.LNS_CP_CALENDAR: "lns-cp-calendar",
-        }
-
-        smap = [
-            (av, solvers_map[av])
-            for av in available
-            if solvers_map[av][0] == solving_method_to_str[solving_method]
-        ]
-
-        if len(smap) > 0:
-            return smap[0]
-
-    return None
-
-
-def from_solution_to_policy(
-    solution: Union[RCPSPSolution, MS_RCPSPSolution, MS_RCPSPSolution_Variant],
-    domain,
-    policy_method_params: PolicyMethodParams,
-):
-    permutation_task = None
-    modes_dictionnary = None
-    schedule = None
-    resource_allocation = None
-    resource_allocation_priority = None
-    if isinstance(solution, RCPSPSolution):
-        permutation_task = sorted(
-            solution.rcpsp_schedule,
-            key=lambda x: (solution.rcpsp_schedule[x]["start_time"], x),
-        )
-        schedule = solution.rcpsp_schedule
-        modes_dictionnary = {}
-        # set modes for start and end (dummy) jobs
-        modes_dictionnary[1] = 1
-        modes_dictionnary[solution.problem.n_jobs_non_dummy + 2] = 1
-        for i in range(len(solution.rcpsp_modes)):
-            modes_dictionnary[i + 2] = solution.rcpsp_modes[i]
-    elif isinstance(solution, MS_RCPSPSolution):
-        permutation_task = sorted(
-            solution.schedule, key=lambda x: (solution.schedule[x]["start_time"], x)
-        )
-        schedule = solution.schedule
-        employees = sorted(domain.get_resource_units_names())
-        resource_allocation = {
-            task: [
-                employees[i] for i in solution.employee_usage[task].keys()
-            ]  # warning here...
-            for task in solution.employee_usage
-        }
-        if isinstance(solution, MS_RCPSPSolution_Variant):
-            resource_allocation_priority = solution.priority_worker_per_task
-            modes_dictionnary = {}
-            # set modes for start and end (dummy) jobs
-            modes_dictionnary[1] = 1
-            modes_dictionnary[solution.problem.n_jobs_non_dummy + 2] = 1
-            for i in range(len(solution.modes_vector)):
-                modes_dictionnary[i + 2] = solution.modes_vector[i]
-        else:
-            modes_dictionnary = solution.modes
-
-    return PolicyRCPSP(
-        domain=domain,
-        policy_method_params=policy_method_params,
-        permutation_task=permutation_task,
-        modes_dictionnary=modes_dictionnary,
-        schedule=schedule,
-        resource_allocation=resource_allocation,
-        resource_allocation_priority=resource_allocation_priority,
-    )
-
-
-class DOSolver(Solver, DeterministicPolicies):
-    T_domain = D
-
-    def __init__(
-        self,
-        policy_method_params: PolicyMethodParams,
-        method: SolvingMethod = SolvingMethod.PILE,
-        dict_params: Dict[Any, Any] = None,
-    ):
-        self.method = method
-        self.policy_method_params = policy_method_params
-        self.dict_params = dict_params
-        if self.dict_params is None:
-            self.dict_params = {}
-
-    def get_available_methods(self, domain: SchedulingDomain):
-        do_domain = build_do_domain(domain)
-        if isinstance(do_domain, (MS_RCPSPModel)):
-            from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill_solvers import (
-                look_for_solver,
-                solvers_map,
-            )
-
-            available = look_for_solver(do_domain)
-        elif isinstance(do_domain, RCPSPModel):
-            from discrete_optimization.rcpsp.rcpsp_solvers import (
-                look_for_solver,
-                solvers_map,
-            )
-
-            available = look_for_solver(do_domain)
-        smap = [(av, solvers_map[av]) for av in available]
-
-        return smap
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self.domain = domain_factory()
-        self.do_domain = build_do_domain(self.domain)
-        solvers = build_solver(solving_method=self.method, do_domain=self.do_domain)
-        solver_class = solvers[0]
-        key, params = solvers[1]
-        for k in params:
-            if k not in self.dict_params:
-                self.dict_params[k] = params[k]
-
-        self.solver = solver_class(self.do_domain, **self.dict_params)
-
-        if hasattr(self.solver, "init_model") and callable(self.solver.init_model):
-            self.solver.init_model(**self.dict_params)
-
-        result_storage = self.solver.solve(**self.dict_params)
-        best_solution: RCPSPSolution = result_storage.get_best_solution()
-
-        assert best_solution is not None
-
-        fits = self.do_domain.evaluate(best_solution)
-
-        self.best_solution = best_solution
-
-        self.policy_object = from_solution_to_policy(
-            solution=best_solution,
-            domain=self.domain,
-            policy_method_params=self.policy_method_params,
-        )
-
-    def get_external_policy(self) -> PolicyRCPSP:
-        return self.policy_object
-
-    def compute_external_policy(self, policy_method_params: PolicyMethodParams):
-        return from_solution_to_policy(
-            solution=self.best_solution,
-            domain=self.domain,
-            policy_method_params=policy_method_params,
-        )
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        return self.policy_object.get_next_action(observation=observation)
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return self.policy_object.is_policy_defined_for(observation=observation)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from copy import deepcopy
+from enum import Enum
+from typing import Any, Callable, Dict, Optional, Tuple, Type, Union
+
+from discrete_optimization.generic_tools.callbacks.callback import Callback
+from discrete_optimization.generic_tools.do_problem import Problem
+from discrete_optimization.generic_tools.do_solver import SolverDO
+from discrete_optimization.generic_tools.result_storage.result_storage import (
+    ResultStorage,
+)
+from discrete_optimization.rcpsp.rcpsp_model import RCPSPModel, RCPSPSolution
+from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill import (
+    MS_RCPSPModel,
+    MS_RCPSPSolution,
+    MS_RCPSPSolution_Variant,
+)
+
+from skdecide import Domain
+from skdecide.builders.domain.scheduling.scheduling_domains import SchedulingDomain
+from skdecide.hub.solver.do_solver.sgs_policies import PolicyMethodParams, PolicyRCPSP
+from skdecide.hub.solver.do_solver.sk_to_do_binding import build_do_domain
+from skdecide.solvers import DeterministicPolicies, Solver
+
+
+class D(SchedulingDomain):
+    pass
+
+
+class SolvingMethod(Enum):
+    """Type of discrete-optimization algorithm to use"""
+
+    PILE = "greedy"
+    GA = "ga"
+    LS = "ls"
+    LP = "lp"
+    CP = "cp"
+    LNS_LP = "lns-lp"
+    LNS_CP = "lns-scheduling"
+
+
+SolvingMethod.PILE.__doc__ = "solve scheduling problem with greedy queue method"
+SolvingMethod.GA.__doc__ = "solve scheduling problem with genetic algorithm"
+SolvingMethod.LS.__doc__ = "solve scheduling problem with local search algorithm (hill climber or simulated annealing)"
+SolvingMethod.LP.__doc__ = "solve scheduling problem with linear programming solver"
+SolvingMethod.CP.__doc__ = "solve scheduling problem with constraint programming solver"
+SolvingMethod.LNS_LP.__doc__ = (
+    "solve scheduling problem with large neighborhood search + LP solver"
+)
+SolvingMethod.LNS_CP.__doc__ = (
+    "solve scheduling problem with large neighborhood search + CP solver"
+)
+
+
+def build_solver(
+    solving_method: Optional[SolvingMethod],
+    solver_type: Optional[Type[SolverDO]],
+    do_domain: Problem,
+) -> Tuple[Type[SolverDO], Dict[str, Any]]:
+    """Build the discrete-optimization solver for a given solving method
+
+    # Parameters
+    solving_method: method of the solver (enum)
+    solver_type: potentially a solver class already specified by the do_solver
+    do_domain: discrete-opt problem to solve.
+
+    # Returns
+    A class of do-solver, associated with some default parameters to be passed to its constructor and solve function
+    (and potentially init_model function)
+    """
+    if isinstance(do_domain, RCPSPModel):
+        from discrete_optimization.rcpsp.rcpsp_solvers import (
+            look_for_solver,
+            solvers_map,
+        )
+
+        do_domain_cls = RCPSPModel
+    elif isinstance(do_domain, MS_RCPSPModel):
+        from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill_solvers import (
+            look_for_solver,
+            solvers_map,
+        )
+
+        do_domain_cls = MS_RCPSPModel
+    else:
+        raise ValueError("do_domain should be either a RCPSPModel or a MS_RCPSPModel.")
+    available = look_for_solver(do_domain)
+    if solver_type is not None:
+        if solver_type in solvers_map:
+            return solver_type, solvers_map[solver_type][1]
+        else:
+            return solver_type, {}
+    smap = [
+        (av, solvers_map[av])
+        for av in available
+        if solvers_map[av][0] == solving_method.value
+    ]
+    if len(smap) > 0:
+        return smap[0][0], smap[0][1][1]
+    else:
+        raise ValueError(
+            f"solving_method {solving_method} not available for {do_domain_cls}."
+        )
+
+
+def from_solution_to_policy(
+    solution: Union[RCPSPSolution, MS_RCPSPSolution, MS_RCPSPSolution_Variant],
+    domain: SchedulingDomain,
+    policy_method_params: PolicyMethodParams,
+) -> PolicyRCPSP:
+    """Create a PolicyRCPSP object (a skdecide policy) from a scheduling solution
+    from the discrete-optimization library."""
+    permutation_task = None
+    modes_dictionnary = None
+    schedule = None
+    resource_allocation = None
+    resource_allocation_priority = None
+    if isinstance(solution, RCPSPSolution):
+        permutation_task = sorted(
+            solution.rcpsp_schedule,
+            key=lambda x: (solution.rcpsp_schedule[x]["start_time"], x),
+        )
+        schedule = solution.rcpsp_schedule
+        modes_dictionnary = {}
+        # set modes for start and end (dummy) jobs
+        modes_dictionnary[1] = 1
+        modes_dictionnary[solution.problem.n_jobs_non_dummy + 2] = 1
+        for i in range(len(solution.rcpsp_modes)):
+            modes_dictionnary[i + 2] = solution.rcpsp_modes[i]
+    elif isinstance(solution, MS_RCPSPSolution):
+        permutation_task = sorted(
+            solution.schedule, key=lambda x: (solution.schedule[x]["start_time"], x)
+        )
+        schedule = solution.schedule
+        employees = sorted(domain.get_resource_units_names())
+        resource_allocation = {
+            task: [
+                employees[i] for i in solution.employee_usage[task].keys()
+            ]  # warning here...
+            for task in solution.employee_usage
+        }
+        if isinstance(solution, MS_RCPSPSolution_Variant):
+            resource_allocation_priority = solution.priority_worker_per_task
+            modes_dictionnary = {}
+            # set modes for start and end (dummy) jobs
+            modes_dictionnary[1] = 1
+            modes_dictionnary[solution.problem.n_jobs_non_dummy + 2] = 1
+            for i in range(len(solution.modes_vector)):
+                modes_dictionnary[i + 2] = solution.modes_vector[i]
+        else:
+            modes_dictionnary = solution.modes
+
+    return PolicyRCPSP(
+        domain=domain,
+        policy_method_params=policy_method_params,
+        permutation_task=permutation_task,
+        modes_dictionnary=modes_dictionnary,
+        schedule=schedule,
+        resource_allocation=resource_allocation,
+        resource_allocation_priority=resource_allocation_priority,
+    )
+
+
+class DOSolver(Solver, DeterministicPolicies):
+    """Wrapper of discrete-optimization solvers for scheduling problems
+
+    # Attributes
+    - policy_method_params:  params for the returned policy.
+    - method: method of the discrete-optim solver used
+    - solver_type: direct method class of do solver (will be used instead of method if solver_type is not None)
+    - dict_params: specific params passed to the do-solver
+    - callback: scikit-decide callback to be called inside do-solver when relevant.
+    """
+
+    T_domain = D
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        policy_method_params: PolicyMethodParams,
+        method: Optional[SolvingMethod] = None,
+        do_solver_type: Optional[Type[SolverDO]] = None,
+        dict_params: Optional[Dict[Any, Any]] = None,
+        callback: Callable[[DOSolver], bool] = lambda solver: False,
+    ):
+        Solver.__init__(self, domain_factory=domain_factory)
+        self.callback = callback
+        self.method = method
+        self.do_solver_type = do_solver_type
+        self.policy_method_params = policy_method_params
+        self.dict_params = dict_params
+        if self.dict_params is None:
+            self.dict_params = {}
+
+    def get_available_methods(self, domain: SchedulingDomain):
+        do_domain = build_do_domain(domain)
+        if isinstance(do_domain, (MS_RCPSPModel)):
+            from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill_solvers import (
+                look_for_solver,
+                solvers_map,
+            )
+
+            available = look_for_solver(do_domain)
+        elif isinstance(do_domain, RCPSPModel):
+            from discrete_optimization.rcpsp.rcpsp_solvers import (
+                look_for_solver,
+                solvers_map,
+            )
+
+            available = look_for_solver(do_domain)
+        smap = [(av, solvers_map[av]) for av in available]
+
+        return smap
+
+    def _solve(self) -> None:
+        self.domain = self._domain_factory()
+        self.do_domain = build_do_domain(self.domain)
+        solvers = build_solver(
+            solving_method=self.method,
+            solver_type=self.do_solver_type,
+            do_domain=self.do_domain,
+        )
+        solver_class = solvers[0]
+        params = solvers[1]
+        for k in params:
+            if k not in self.dict_params:
+                self.dict_params[k] = params[k]
+
+        # callbacks
+        callbacks = [_DOCallback(callback=self.callback, solver=self)]
+        copy_dict_params = deepcopy(self.dict_params)
+        if "callbacks" in copy_dict_params:
+            callbacks = callbacks + copy_dict_params.pop("callbacks")
+
+        self.solver = solver_class(self.do_domain, **copy_dict_params)
+
+        if hasattr(self.solver, "init_model") and callable(self.solver.init_model):
+            self.solver.init_model(**copy_dict_params)
+
+        result_storage = self.solver.solve(callbacks=callbacks, **copy_dict_params)
+        best_solution: RCPSPSolution = result_storage.get_best_solution()
+
+        assert best_solution is not None
+
+        fits = self.do_domain.evaluate(best_solution)
+
+        self.best_solution = best_solution
+
+        self.policy_object = from_solution_to_policy(
+            solution=best_solution,
+            domain=self.domain,
+            policy_method_params=self.policy_method_params,
+        )
+
+    def get_external_policy(self) -> PolicyRCPSP:
+        return self.policy_object
+
+    def compute_external_policy(self, policy_method_params: PolicyMethodParams):
+        return from_solution_to_policy(
+            solution=self.best_solution,
+            domain=self.domain,
+            policy_method_params=policy_method_params,
+        )
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        return self.policy_object.get_next_action(observation=observation)
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return self.policy_object.is_policy_defined_for(observation=observation)
+
+
+class _DOCallback(Callback):
+    def __init__(
+        self,
+        callback: Callable[[DOSolver], bool],
+        solver: DOSolver,
+    ):
+        self.solver = solver
+        self.callback = callback
+
+    def on_step_end(
+        self, step: int, res: ResultStorage, solver: SolverDO
+    ) -> Optional[bool]:
+        """Called at the end of an optimization step.
+
+        # Parameters
+            step: index of step
+            res: current result storage
+            solver: solvers using the callback
+
+        # Returns
+            If `True`, the optimization process is stopped, else it goes on.
+
+        """
+        stopping = self.callback(self.solver)
+        return stopping
```

## skdecide/hub/solver/do_solver/sk_to_do_binding.py

```diff
@@ -1,419 +1,429 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Union
-
-from discrete_optimization.rcpsp.rcpsp_model import RCPSPModel, RCPSPSolution
-from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill import (
-    Employee,
-    MS_RCPSPModel,
-    MS_RCPSPModel_Variant,
-    SkillDetail,
-)
-
-from skdecide.builders.domain.scheduling.scheduling_domains import (
-    MultiModeMultiSkillRCPSP,
-    MultiModeMultiSkillRCPSPCalendar,
-    MultiModeRCPSP,
-    MultiModeRCPSPCalendar,
-    MultiModeRCPSPWithCost,
-    SchedulingDomain,
-    SingleModeRCPSP,
-    SingleModeRCPSP_Stochastic_Durations,
-    SingleModeRCPSPCalendar,
-    State,
-)
-from skdecide.hub.domain.rcpsp.rcpsp_sk import (
-    MRCPSP,
-    MSRCPSP,
-    RCPSP,
-    MRCPSPCalendar,
-    MSRCPSPCalendar,
-)
-
-
-def from_last_state_to_solution(state: State, domain: SchedulingDomain):
-    modes = [state.tasks_mode.get(j, 1) for j in sorted(domain.get_tasks_ids())]
-    modes = modes[1:-1]
-    schedule = {
-        p.value.id: {"start_time": p.value.start, "end_time": p.value.end}
-        for p in state.tasks_complete_details
-    }
-    return RCPSPSolution(
-        problem=build_do_domain(domain),
-        rcpsp_permutation=None,
-        rcpsp_modes=modes,
-        rcpsp_schedule=schedule,
-    )
-
-
-def build_do_domain(
-    scheduling_domain: Union[
-        SingleModeRCPSP,
-        SingleModeRCPSPCalendar,
-        MultiModeRCPSP,
-        MultiModeRCPSPWithCost,
-        MultiModeRCPSPCalendar,
-        MultiModeMultiSkillRCPSP,
-        MultiModeMultiSkillRCPSPCalendar,
-        SingleModeRCPSP_Stochastic_Durations,
-    ]
-):
-    if isinstance(scheduling_domain, SingleModeRCPSP):
-        modes_details = scheduling_domain.get_tasks_modes().copy()
-        mode_details_do = {}
-        for task in modes_details:
-            mode_details_do[task] = {}
-            for mode in modes_details[task]:
-                mode_details_do[task][mode] = {}
-                for r in modes_details[task][mode].get_ressource_names():
-                    mode_details_do[task][mode][r] = modes_details[task][
-                        mode
-                    ].get_resource_need_at_time(
-                        r, time=0
-                    )  # should be constant anyway
-                mode_details_do[task][mode][
-                    "duration"
-                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
-        return RCPSPModel(
-            resources={
-                r: scheduling_domain.get_original_quantity_resource(r)
-                for r in scheduling_domain.get_resource_types_names()
-            },
-            non_renewable_resources=[
-                r
-                for r in scheduling_domain.get_resource_renewability()
-                if not scheduling_domain.get_resource_renewability()[r]
-            ],
-            mode_details=mode_details_do,
-            successors=scheduling_domain.get_successors(),
-            horizon=scheduling_domain.get_max_horizon(),
-            horizon_multiplier=1,
-        )
-    if isinstance(scheduling_domain, SingleModeRCPSP_Stochastic_Durations):
-        modes_details = scheduling_domain.get_tasks_modes().copy()
-        mode_details_do = {}
-        for task in modes_details:
-            mode_details_do[task] = {}
-            for mode in modes_details[task]:
-                mode_details_do[task][mode] = {}
-                for r in modes_details[task][mode].get_ressource_names():
-                    mode_details_do[task][mode][r] = modes_details[task][
-                        mode
-                    ].get_resource_need_at_time(
-                        r, time=0
-                    )  # should be constant anyway
-                mode_details_do[task][mode][
-                    "duration"
-                ] = scheduling_domain.sample_task_duration(task=task, mode=mode)
-        return RCPSPModel(
-            resources={
-                r: scheduling_domain.get_original_quantity_resource(r)
-                for r in scheduling_domain.get_resource_types_names()
-            },
-            non_renewable_resources=[
-                r
-                for r in scheduling_domain.get_resource_renewability()
-                if not scheduling_domain.get_resource_renewability()[r]
-            ],
-            mode_details=mode_details_do,
-            successors=scheduling_domain.get_successors(),
-            horizon=scheduling_domain.get_max_horizon(),
-            horizon_multiplier=1,
-        )
-    if isinstance(scheduling_domain, (MultiModeRCPSP, MultiModeRCPSPWithCost)):
-        modes_details = scheduling_domain.get_tasks_modes().copy()
-        mode_details_do = {}
-        for task in modes_details:
-            mode_details_do[task] = {}
-            for mode in modes_details[task]:
-                mode_details_do[task][mode] = {}
-                for r in modes_details[task][mode].get_ressource_names():
-                    mode_details_do[task][mode][r] = modes_details[task][
-                        mode
-                    ].get_resource_need_at_time(
-                        r, time=0
-                    )  # should be constant anyway
-                mode_details_do[task][mode][
-                    "duration"
-                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
-        return RCPSPModel(
-            resources={
-                r: scheduling_domain.get_original_quantity_resource(r)
-                for r in scheduling_domain.get_resource_types_names()
-            },
-            non_renewable_resources=[
-                r
-                for r in scheduling_domain.get_resource_renewability()
-                if not scheduling_domain.get_resource_renewability()[r]
-            ],
-            mode_details=mode_details_do,
-            successors=scheduling_domain.get_successors(),
-            horizon=scheduling_domain.get_max_horizon(),
-            horizon_multiplier=1,
-        )
-    if isinstance(scheduling_domain, (MultiModeRCPSPCalendar, SingleModeRCPSPCalendar)):
-        modes_details = scheduling_domain.get_tasks_modes().copy()
-        mode_details_do = {}
-        for task in modes_details:
-            mode_details_do[task] = {}
-            for mode in modes_details[task]:
-                mode_details_do[task][mode] = {}
-                for r in modes_details[task][mode].get_ressource_names():
-                    mode_details_do[task][mode][r] = modes_details[task][
-                        mode
-                    ].get_resource_need_at_time(
-                        r, time=0
-                    )  # should be constant anyway
-                mode_details_do[task][mode][
-                    "duration"
-                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
-        horizon = scheduling_domain.get_max_horizon()
-        return RCPSPModel(
-            resources={
-                r: [
-                    scheduling_domain.get_quantity_resource(r, time=t)
-                    for t in range(horizon)
-                ]
-                for r in scheduling_domain.get_resource_types_names()
-            },
-            non_renewable_resources=[
-                r
-                for r in scheduling_domain.get_resource_renewability()
-                if not scheduling_domain.get_resource_renewability()[r]
-            ],
-            mode_details=mode_details_do,
-            successors=scheduling_domain.get_successors(),
-            horizon=scheduling_domain.get_max_horizon(),
-            horizon_multiplier=1,
-        )
-    if isinstance(
-        scheduling_domain, (MultiModeMultiSkillRCPSP, MultiModeMultiSkillRCPSPCalendar)
-    ):
-        modes_details = scheduling_domain.get_tasks_modes().copy()
-        skills_set = set()
-        mode_details_do = {}
-        for task in modes_details:
-            mode_details_do[task] = {}
-            for mode in modes_details[task]:
-                mode_details_do[task][mode] = {}
-                for r in modes_details[task][mode].get_ressource_names():
-                    mode_details_do[task][mode][r] = modes_details[task][
-                        mode
-                    ].get_resource_need_at_time(
-                        r, time=0
-                    )  # should be constant anyway
-                skills = scheduling_domain.get_skills_of_task(task=task, mode=mode)
-                for s in skills:
-                    mode_details_do[task][mode][s] = skills[s]
-                    skills_set.add(s)
-                mode_details_do[task][mode][
-                    "duration"
-                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
-        horizon = scheduling_domain.get_max_horizon()
-        employees_dict = {}
-        employees = scheduling_domain.get_resource_units_names()
-        sorted_employees = sorted(employees)
-        for employee, i in zip(sorted_employees, range(len(sorted_employees))):
-            skills = scheduling_domain.get_skills_of_resource(resource=employee)
-            skills_details = {
-                r: SkillDetail(skill_value=skills[r], efficiency_ratio=0, experience=0)
-                for r in skills
-            }
-            employees_dict[i] = Employee(
-                dict_skill=skills_details,
-                calendar_employee=[
-                    bool(scheduling_domain.get_quantity_resource(employee, time=t))
-                    for t in range(horizon + 1)
-                ],
-            )
-
-        return MS_RCPSPModel_Variant(
-            skills_set=scheduling_domain.get_skills_names(),
-            resources_set=set(scheduling_domain.get_resource_types_names()),
-            non_renewable_resources=set(
-                [
-                    r
-                    for r in scheduling_domain.get_resource_renewability()
-                    if not scheduling_domain.get_resource_renewability()[r]
-                ]
-            ),
-            resources_availability={
-                r: [
-                    scheduling_domain.get_quantity_resource(r, time=t)
-                    for t in range(horizon + 1)
-                ]
-                for r in scheduling_domain.get_resource_types_names()
-            },
-            employees=employees_dict,
-            employees_availability=[
-                sum(
-                    [
-                        scheduling_domain.get_quantity_resource(employee, time=t)
-                        for employee in employees
-                    ]
-                )
-                for t in range(horizon + 1)
-            ],
-            mode_details=mode_details_do,
-            successors=scheduling_domain.get_successors(),
-            horizon=horizon,
-            horizon_multiplier=1,
-            sink_task=max(scheduling_domain.get_tasks_ids()),
-            source_task=min(scheduling_domain.get_tasks_ids()),
-            one_unit_per_task_max=False,
-        )
-        # TODO : for imopse this should be True
-
-
-def build_sk_domain(
-    rcpsp_do_domain: Union[MS_RCPSPModel, RCPSPModel],
-    varying_ressource: bool = False,
-):
-    if (
-        isinstance(rcpsp_do_domain, RCPSPModel)
-        and rcpsp_do_domain.is_varying_resource()
-    ):
-        if varying_ressource:
-            my_domain = MRCPSPCalendar(
-                resource_names=rcpsp_do_domain.resources_list,
-                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
-                tasks_mode=rcpsp_do_domain.mode_details,
-                successors=rcpsp_do_domain.successors,
-                max_horizon=rcpsp_do_domain.horizon,
-                resource_availability=rcpsp_do_domain.resources,
-                resource_renewable={
-                    r: r not in rcpsp_do_domain.non_renewable_resources
-                    for r in rcpsp_do_domain.resources_list
-                },
-            )
-            return my_domain
-        # Even if the DO domain is a calendar one... ignore it.
-        else:
-            my_domain = MRCPSP(
-                resource_names=rcpsp_do_domain.resources_list,
-                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
-                tasks_mode=rcpsp_do_domain.mode_details,
-                successors=rcpsp_do_domain.successors,
-                max_horizon=rcpsp_do_domain.horizon,
-                resource_availability={
-                    r: max(rcpsp_do_domain.resources[r])
-                    for r in rcpsp_do_domain.resources
-                },
-                resource_renewable={
-                    r: r not in rcpsp_do_domain.non_renewable_resources
-                    for r in rcpsp_do_domain.resources_list
-                },
-            )
-        return my_domain
-
-    if (
-        isinstance(rcpsp_do_domain, RCPSPModel)
-        and not rcpsp_do_domain.is_rcpsp_multimode()
-    ):
-        my_domain = RCPSP(
-            resource_names=rcpsp_do_domain.resources_list,
-            task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
-            tasks_mode=rcpsp_do_domain.mode_details,
-            successors=rcpsp_do_domain.successors,
-            max_horizon=rcpsp_do_domain.horizon,
-            resource_availability=rcpsp_do_domain.resources,
-            resource_renewable={
-                r: r not in rcpsp_do_domain.non_renewable_resources
-                for r in rcpsp_do_domain.resources_list
-            },
-        )
-        return my_domain
-
-    elif (
-        isinstance(rcpsp_do_domain, RCPSPModel) and rcpsp_do_domain.is_rcpsp_multimode()
-    ):
-        my_domain = MRCPSP(
-            resource_names=rcpsp_do_domain.resources_list,
-            task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
-            tasks_mode=rcpsp_do_domain.mode_details,
-            successors=rcpsp_do_domain.successors,
-            max_horizon=rcpsp_do_domain.horizon,
-            resource_availability=rcpsp_do_domain.resources,
-            resource_renewable={
-                r: r not in rcpsp_do_domain.non_renewable_resources
-                for r in rcpsp_do_domain.resources_list
-            },
-        )
-        return my_domain
-
-    elif isinstance(rcpsp_do_domain, MS_RCPSPModel):
-        if not varying_ressource:
-            resource_type_names = list(rcpsp_do_domain.resources_list)
-            resource_skills = {r: {} for r in resource_type_names}
-            resource_availability = {
-                r: rcpsp_do_domain.resources_availability[r][0]
-                for r in rcpsp_do_domain.resources_availability
-            }
-            resource_renewable = {
-                r: r not in rcpsp_do_domain.non_renewable_resources
-                for r in rcpsp_do_domain.resources_list
-            }
-            resource_unit_names = []
-            for employee in rcpsp_do_domain.employees:
-                resource_unit_names += [str(employee)]
-                resource_skills[resource_unit_names[-1]] = {}
-                resource_availability[resource_unit_names[-1]] = 1
-                resource_renewable[resource_unit_names[-1]] = True
-                for s in rcpsp_do_domain.employees[employee].dict_skill:
-                    resource_skills[resource_unit_names[-1]][s] = (
-                        rcpsp_do_domain.employees[employee].dict_skill[s].skill_value
-                    )
-
-            return MSRCPSP(
-                skills_names=list(rcpsp_do_domain.skills_set),
-                resource_unit_names=resource_unit_names,
-                resource_type_names=resource_type_names,
-                resource_skills=resource_skills,
-                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
-                tasks_mode=rcpsp_do_domain.mode_details,
-                successors=rcpsp_do_domain.successors,
-                max_horizon=rcpsp_do_domain.horizon,
-                resource_availability=resource_availability,
-                resource_renewable=resource_renewable,
-            )
-        else:
-            resource_type_names = list(rcpsp_do_domain.resources_list)
-            resource_skills = {r: {} for r in resource_type_names}
-            resource_availability = {
-                r: rcpsp_do_domain.resources_availability[r]
-                for r in rcpsp_do_domain.resources_availability
-            }
-            resource_renewable = {
-                r: r not in rcpsp_do_domain.non_renewable_resources
-                for r in rcpsp_do_domain.resources_list
-            }
-            resource_unit_names = []
-            for employee in rcpsp_do_domain.employees:
-                resource_unit_names += [str(employee)]
-                resource_skills[resource_unit_names[-1]] = {}
-                resource_availability[resource_unit_names[-1]] = [
-                    1 if x else 0
-                    for x in rcpsp_do_domain.employees[employee].calendar_employee
-                ]
-                resource_renewable[resource_unit_names[-1]] = True
-                for s in rcpsp_do_domain.employees[employee].dict_skill:
-                    resource_skills[resource_unit_names[-1]][s] = (
-                        rcpsp_do_domain.employees[employee].dict_skill[s].skill_value
-                    )
-
-            return MSRCPSPCalendar(
-                skills_names=list(rcpsp_do_domain.skills_set),
-                resource_unit_names=resource_unit_names,
-                resource_type_names=resource_type_names,
-                resource_skills=resource_skills,
-                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
-                tasks_mode=rcpsp_do_domain.mode_details,
-                successors=rcpsp_do_domain.successors,
-                max_horizon=rcpsp_do_domain.horizon,
-                resource_availability=resource_availability,
-                resource_renewable=resource_renewable,
-            )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Union
+
+from discrete_optimization.rcpsp.rcpsp_model import RCPSPModel, RCPSPSolution
+from discrete_optimization.rcpsp_multiskill.rcpsp_multiskill import (
+    Employee,
+    MS_RCPSPModel,
+    MS_RCPSPModel_Variant,
+    SkillDetail,
+)
+
+from skdecide.builders.domain.scheduling.scheduling_domains import (
+    MultiModeMultiSkillRCPSP,
+    MultiModeMultiSkillRCPSPCalendar,
+    MultiModeRCPSP,
+    MultiModeRCPSPCalendar,
+    MultiModeRCPSPWithCost,
+    SchedulingDomain,
+    SingleModeRCPSP,
+    SingleModeRCPSP_Stochastic_Durations,
+    SingleModeRCPSPCalendar,
+    State,
+)
+from skdecide.hub.domain.rcpsp.rcpsp_sk import (
+    MRCPSP,
+    MSRCPSP,
+    RCPSP,
+    MRCPSPCalendar,
+    MSRCPSPCalendar,
+)
+
+
+def from_last_state_to_solution(
+    state: State, domain: SchedulingDomain
+) -> RCPSPSolution:
+    """Transform a scheduling state into a RCPSPSolution
+    This function reads the schedule from the state object and transform it back to a discrete-optimization solution
+    object.
+    """
+    modes = [state.tasks_mode.get(j, 1) for j in sorted(domain.get_tasks_ids())]
+    modes = modes[1:-1]
+    schedule = {
+        p.value.id: {"start_time": p.value.start, "end_time": p.value.end}
+        for p in state.tasks_complete_details
+    }
+    return RCPSPSolution(
+        problem=build_do_domain(domain),
+        rcpsp_permutation=None,
+        rcpsp_modes=modes,
+        rcpsp_schedule=schedule,
+    )
+
+
+def build_do_domain(
+    scheduling_domain: Union[
+        SingleModeRCPSP,
+        SingleModeRCPSPCalendar,
+        MultiModeRCPSP,
+        MultiModeRCPSPWithCost,
+        MultiModeRCPSPCalendar,
+        MultiModeMultiSkillRCPSP,
+        MultiModeMultiSkillRCPSPCalendar,
+        SingleModeRCPSP_Stochastic_Durations,
+    ]
+) -> Union[RCPSPModel, MS_RCPSPModel]:
+    """Transform the scheduling domain (from scikit-decide) into a discrete-optimization problem.
+
+    This only works for scheduling template given in the type docstring.
+    """
+    if isinstance(scheduling_domain, SingleModeRCPSP):
+        modes_details = scheduling_domain.get_tasks_modes().copy()
+        mode_details_do = {}
+        for task in modes_details:
+            mode_details_do[task] = {}
+            for mode in modes_details[task]:
+                mode_details_do[task][mode] = {}
+                for r in modes_details[task][mode].get_ressource_names():
+                    mode_details_do[task][mode][r] = modes_details[task][
+                        mode
+                    ].get_resource_need_at_time(
+                        r, time=0
+                    )  # should be constant anyway
+                mode_details_do[task][mode][
+                    "duration"
+                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
+        return RCPSPModel(
+            resources={
+                r: scheduling_domain.get_original_quantity_resource(r)
+                for r in scheduling_domain.get_resource_types_names()
+            },
+            non_renewable_resources=[
+                r
+                for r in scheduling_domain.get_resource_renewability()
+                if not scheduling_domain.get_resource_renewability()[r]
+            ],
+            mode_details=mode_details_do,
+            successors=scheduling_domain.get_successors(),
+            horizon=scheduling_domain.get_max_horizon(),
+            horizon_multiplier=1,
+        )
+    if isinstance(scheduling_domain, SingleModeRCPSP_Stochastic_Durations):
+        modes_details = scheduling_domain.get_tasks_modes().copy()
+        mode_details_do = {}
+        for task in modes_details:
+            mode_details_do[task] = {}
+            for mode in modes_details[task]:
+                mode_details_do[task][mode] = {}
+                for r in modes_details[task][mode].get_ressource_names():
+                    mode_details_do[task][mode][r] = modes_details[task][
+                        mode
+                    ].get_resource_need_at_time(
+                        r, time=0
+                    )  # should be constant anyway
+                mode_details_do[task][mode][
+                    "duration"
+                ] = scheduling_domain.sample_task_duration(task=task, mode=mode)
+        return RCPSPModel(
+            resources={
+                r: scheduling_domain.get_original_quantity_resource(r)
+                for r in scheduling_domain.get_resource_types_names()
+            },
+            non_renewable_resources=[
+                r
+                for r in scheduling_domain.get_resource_renewability()
+                if not scheduling_domain.get_resource_renewability()[r]
+            ],
+            mode_details=mode_details_do,
+            successors=scheduling_domain.get_successors(),
+            horizon=scheduling_domain.get_max_horizon(),
+            horizon_multiplier=1,
+        )
+    if isinstance(scheduling_domain, (MultiModeRCPSP, MultiModeRCPSPWithCost)):
+        modes_details = scheduling_domain.get_tasks_modes().copy()
+        mode_details_do = {}
+        for task in modes_details:
+            mode_details_do[task] = {}
+            for mode in modes_details[task]:
+                mode_details_do[task][mode] = {}
+                for r in modes_details[task][mode].get_ressource_names():
+                    mode_details_do[task][mode][r] = modes_details[task][
+                        mode
+                    ].get_resource_need_at_time(
+                        r, time=0
+                    )  # should be constant anyway
+                mode_details_do[task][mode][
+                    "duration"
+                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
+        return RCPSPModel(
+            resources={
+                r: scheduling_domain.get_original_quantity_resource(r)
+                for r in scheduling_domain.get_resource_types_names()
+            },
+            non_renewable_resources=[
+                r
+                for r in scheduling_domain.get_resource_renewability()
+                if not scheduling_domain.get_resource_renewability()[r]
+            ],
+            mode_details=mode_details_do,
+            successors=scheduling_domain.get_successors(),
+            horizon=scheduling_domain.get_max_horizon(),
+            horizon_multiplier=1,
+        )
+    if isinstance(scheduling_domain, (MultiModeRCPSPCalendar, SingleModeRCPSPCalendar)):
+        modes_details = scheduling_domain.get_tasks_modes().copy()
+        mode_details_do = {}
+        for task in modes_details:
+            mode_details_do[task] = {}
+            for mode in modes_details[task]:
+                mode_details_do[task][mode] = {}
+                for r in modes_details[task][mode].get_ressource_names():
+                    mode_details_do[task][mode][r] = modes_details[task][
+                        mode
+                    ].get_resource_need_at_time(
+                        r, time=0
+                    )  # should be constant anyway
+                mode_details_do[task][mode][
+                    "duration"
+                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
+        horizon = scheduling_domain.get_max_horizon()
+        return RCPSPModel(
+            resources={
+                r: [
+                    scheduling_domain.get_quantity_resource(r, time=t)
+                    for t in range(horizon)
+                ]
+                for r in scheduling_domain.get_resource_types_names()
+            },
+            non_renewable_resources=[
+                r
+                for r in scheduling_domain.get_resource_renewability()
+                if not scheduling_domain.get_resource_renewability()[r]
+            ],
+            mode_details=mode_details_do,
+            successors=scheduling_domain.get_successors(),
+            horizon=scheduling_domain.get_max_horizon(),
+            horizon_multiplier=1,
+        )
+    if isinstance(
+        scheduling_domain, (MultiModeMultiSkillRCPSP, MultiModeMultiSkillRCPSPCalendar)
+    ):
+        modes_details = scheduling_domain.get_tasks_modes().copy()
+        skills_set = set()
+        mode_details_do = {}
+        for task in modes_details:
+            mode_details_do[task] = {}
+            for mode in modes_details[task]:
+                mode_details_do[task][mode] = {}
+                for r in modes_details[task][mode].get_ressource_names():
+                    mode_details_do[task][mode][r] = modes_details[task][
+                        mode
+                    ].get_resource_need_at_time(
+                        r, time=0
+                    )  # should be constant anyway
+                skills = scheduling_domain.get_skills_of_task(task=task, mode=mode)
+                for s in skills:
+                    mode_details_do[task][mode][s] = skills[s]
+                    skills_set.add(s)
+                mode_details_do[task][mode][
+                    "duration"
+                ] = scheduling_domain.get_task_duration(task=task, mode=mode)
+        horizon = scheduling_domain.get_max_horizon()
+        employees_dict = {}
+        employees = scheduling_domain.get_resource_units_names()
+        sorted_employees = sorted(employees)
+        for employee, i in zip(sorted_employees, range(len(sorted_employees))):
+            skills = scheduling_domain.get_skills_of_resource(resource=employee)
+            skills_details = {
+                r: SkillDetail(skill_value=skills[r], efficiency_ratio=0, experience=0)
+                for r in skills
+            }
+            employees_dict[i] = Employee(
+                dict_skill=skills_details,
+                calendar_employee=[
+                    bool(scheduling_domain.get_quantity_resource(employee, time=t))
+                    for t in range(horizon + 1)
+                ],
+            )
+
+        return MS_RCPSPModel_Variant(
+            skills_set=scheduling_domain.get_skills_names(),
+            resources_set=set(scheduling_domain.get_resource_types_names()),
+            non_renewable_resources=set(
+                [
+                    r
+                    for r in scheduling_domain.get_resource_renewability()
+                    if not scheduling_domain.get_resource_renewability()[r]
+                ]
+            ),
+            resources_availability={
+                r: [
+                    scheduling_domain.get_quantity_resource(r, time=t)
+                    for t in range(horizon + 1)
+                ]
+                for r in scheduling_domain.get_resource_types_names()
+            },
+            employees=employees_dict,
+            employees_availability=[
+                sum(
+                    [
+                        scheduling_domain.get_quantity_resource(employee, time=t)
+                        for employee in employees
+                    ]
+                )
+                for t in range(horizon + 1)
+            ],
+            mode_details=mode_details_do,
+            successors=scheduling_domain.get_successors(),
+            horizon=horizon,
+            horizon_multiplier=1,
+            sink_task=max(scheduling_domain.get_tasks_ids()),
+            source_task=min(scheduling_domain.get_tasks_ids()),
+            one_unit_per_task_max=False,
+        )
+
+
+def build_sk_domain(
+    rcpsp_do_domain: Union[MS_RCPSPModel, RCPSPModel],
+    varying_ressource: bool = False,
+) -> Union[RCPSP, MSRCPSP, MRCPSP, MSRCPSPCalendar]:
+    """Build a scheduling domain (scikit-decide) from a discrete-optimization problem"""
+    if (
+        isinstance(rcpsp_do_domain, RCPSPModel)
+        and rcpsp_do_domain.is_varying_resource()
+    ):
+        if varying_ressource:
+            my_domain = MRCPSPCalendar(
+                resource_names=rcpsp_do_domain.resources_list,
+                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
+                tasks_mode=rcpsp_do_domain.mode_details,
+                successors=rcpsp_do_domain.successors,
+                max_horizon=rcpsp_do_domain.horizon,
+                resource_availability=rcpsp_do_domain.resources,
+                resource_renewable={
+                    r: r not in rcpsp_do_domain.non_renewable_resources
+                    for r in rcpsp_do_domain.resources_list
+                },
+            )
+            return my_domain
+        # Even if the DO domain is a calendar one... ignore it.
+        else:
+            my_domain = MRCPSP(
+                resource_names=rcpsp_do_domain.resources_list,
+                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
+                tasks_mode=rcpsp_do_domain.mode_details,
+                successors=rcpsp_do_domain.successors,
+                max_horizon=rcpsp_do_domain.horizon,
+                resource_availability={
+                    r: max(rcpsp_do_domain.resources[r])
+                    for r in rcpsp_do_domain.resources
+                },
+                resource_renewable={
+                    r: r not in rcpsp_do_domain.non_renewable_resources
+                    for r in rcpsp_do_domain.resources_list
+                },
+            )
+        return my_domain
+
+    if (
+        isinstance(rcpsp_do_domain, RCPSPModel)
+        and not rcpsp_do_domain.is_rcpsp_multimode()
+    ):
+        my_domain = RCPSP(
+            resource_names=rcpsp_do_domain.resources_list,
+            task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
+            tasks_mode=rcpsp_do_domain.mode_details,
+            successors=rcpsp_do_domain.successors,
+            max_horizon=rcpsp_do_domain.horizon,
+            resource_availability=rcpsp_do_domain.resources,
+            resource_renewable={
+                r: r not in rcpsp_do_domain.non_renewable_resources
+                for r in rcpsp_do_domain.resources_list
+            },
+        )
+        return my_domain
+
+    elif (
+        isinstance(rcpsp_do_domain, RCPSPModel) and rcpsp_do_domain.is_rcpsp_multimode()
+    ):
+        my_domain = MRCPSP(
+            resource_names=rcpsp_do_domain.resources_list,
+            task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
+            tasks_mode=rcpsp_do_domain.mode_details,
+            successors=rcpsp_do_domain.successors,
+            max_horizon=rcpsp_do_domain.horizon,
+            resource_availability=rcpsp_do_domain.resources,
+            resource_renewable={
+                r: r not in rcpsp_do_domain.non_renewable_resources
+                for r in rcpsp_do_domain.resources_list
+            },
+        )
+        return my_domain
+
+    elif isinstance(rcpsp_do_domain, MS_RCPSPModel):
+        if not varying_ressource:
+            resource_type_names = list(rcpsp_do_domain.resources_list)
+            resource_skills = {r: {} for r in resource_type_names}
+            resource_availability = {
+                r: rcpsp_do_domain.resources_availability[r][0]
+                for r in rcpsp_do_domain.resources_availability
+            }
+            resource_renewable = {
+                r: r not in rcpsp_do_domain.non_renewable_resources
+                for r in rcpsp_do_domain.resources_list
+            }
+            resource_unit_names = []
+            for employee in rcpsp_do_domain.employees:
+                resource_unit_names += [str(employee)]
+                resource_skills[resource_unit_names[-1]] = {}
+                resource_availability[resource_unit_names[-1]] = 1
+                resource_renewable[resource_unit_names[-1]] = True
+                for s in rcpsp_do_domain.employees[employee].dict_skill:
+                    resource_skills[resource_unit_names[-1]][s] = (
+                        rcpsp_do_domain.employees[employee].dict_skill[s].skill_value
+                    )
+
+            return MSRCPSP(
+                skills_names=list(rcpsp_do_domain.skills_set),
+                resource_unit_names=resource_unit_names,
+                resource_type_names=resource_type_names,
+                resource_skills=resource_skills,
+                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
+                tasks_mode=rcpsp_do_domain.mode_details,
+                successors=rcpsp_do_domain.successors,
+                max_horizon=rcpsp_do_domain.horizon,
+                resource_availability=resource_availability,
+                resource_renewable=resource_renewable,
+            )
+        else:
+            resource_type_names = list(rcpsp_do_domain.resources_list)
+            resource_skills = {r: {} for r in resource_type_names}
+            resource_availability = {
+                r: rcpsp_do_domain.resources_availability[r]
+                for r in rcpsp_do_domain.resources_availability
+            }
+            resource_renewable = {
+                r: r not in rcpsp_do_domain.non_renewable_resources
+                for r in rcpsp_do_domain.resources_list
+            }
+            resource_unit_names = []
+            for employee in rcpsp_do_domain.employees:
+                resource_unit_names += [str(employee)]
+                resource_skills[resource_unit_names[-1]] = {}
+                resource_availability[resource_unit_names[-1]] = [
+                    1 if x else 0
+                    for x in rcpsp_do_domain.employees[employee].calendar_employee
+                ]
+                resource_renewable[resource_unit_names[-1]] = True
+                for s in rcpsp_do_domain.employees[employee].dict_skill:
+                    resource_skills[resource_unit_names[-1]][s] = (
+                        rcpsp_do_domain.employees[employee].dict_skill[s].skill_value
+                    )
+
+            return MSRCPSPCalendar(
+                skills_names=list(rcpsp_do_domain.skills_set),
+                resource_unit_names=resource_unit_names,
+                resource_type_names=resource_type_names,
+                resource_skills=resource_skills,
+                task_ids=sorted(rcpsp_do_domain.mode_details.keys()),
+                tasks_mode=rcpsp_do_domain.mode_details,
+                successors=rcpsp_do_domain.successors,
+                max_horizon=rcpsp_do_domain.horizon,
+                resource_availability=resource_availability,
+                resource_renewable=resource_renewable,
+            )
```

## skdecide/hub/solver/ilaostar/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .ilaostar import ILAOstar
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .ilaostar import ILAOstar
```

## skdecide/hub/solver/ilaostar/ilaostar.py

```diff
@@ -1,144 +1,271 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import os
-import sys
-from typing import Callable, Dict, Optional, Tuple
-
-from skdecide import Domain, Solver, hub
-from skdecide.builders.domain import (
-    Actions,
-    EnumerableTransitions,
-    FullyObservable,
-    Goals,
-    Markovian,
-    PositiveCosts,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
-from skdecide.core import Value
-
-record_sys_path = sys.path
-skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
-if skdecide_cpp_extension_lib_path not in sys.path:
-    sys.path.append(skdecide_cpp_extension_lib_path)
-
-try:
-
-    from __skdecide_hub_cpp import _ILAOStarSolver_ as ilaostar_solver
-
-    # TODO: remove Markovian req?
-    class D(
-        Domain,
-        SingleAgent,
-        Sequential,
-        EnumerableTransitions,
-        Actions,
-        Goals,
-        Markovian,
-        FullyObservable,
-        PositiveCosts,
-    ):
-        pass
-
-    class ILAOstar(ParallelSolver, Solver, DeterministicPolicies, Utilities):
-        T_domain = D
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            heuristic: Optional[
-                Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
-            ] = None,
-            discount: float = 1.0,
-            epsilon: float = 0.001,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-        ) -> None:
-            ParallelSolver.__init__(
-                self,
-                domain_factory=domain_factory,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-            )
-            self._solver = None
-            self._discount = discount
-            self._epsilon = epsilon
-            self._debug_logs = debug_logs
-            if heuristic is None:
-                self._heuristic = lambda d, s: Value(cost=0)
-            else:
-                self._heuristic = heuristic
-            self._lambdas = [self._heuristic]
-            self._ipc_notify = True
-
-        def close(self):
-            """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
-            """
-            if self._parallel:
-                self._solver.close()
-            ParallelSolver.close(self)
-
-        def _init_solve(self, domain_factory: Callable[[], Domain]) -> None:
-            self._domain_factory = domain_factory
-            self._solver = ilaostar_solver(
-                domain=self.get_domain(),
-                goal_checker=lambda d, s: d.is_goal(s),
-                heuristic=lambda d, s: self._heuristic(d, s)
-                if not self._parallel
-                else d.call(None, 0, s),
-                discount=self._discount,
-                epsilon=self._epsilon,
-                parallel=self._parallel,
-                debug_logs=self._debug_logs,
-            )
-            self._solver.clear()
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
-
-        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-            self._solver.solve(memory)
-
-        def _is_solution_defined_for(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> bool:
-            return self._solver.is_solution_defined_for(observation)
-
-        def _get_next_action(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if not self._is_solution_defined_for(observation):
-                self._solve_from(observation)
-            return self._solver.get_next_action(observation)
-
-        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-            return self._solver.get_utility(observation)
-
-        def get_nb_of_explored_states(self) -> int:
-            return self._solver.get_nb_of_explored_states()
-
-        def best_solution_graph_size(self) -> int:
-            return self._solver.best_solution_graph_size()
-
-        def get_policy(
-            self,
-        ) -> Dict[
-            D.T_agent[D.T_observation],
-            Tuple[D.T_agent[D.T_concurrency[D.T_event]], float],
-        ]:
-            return self._solver.get_policy()
-
-except ImportError:
-    sys.path = record_sys_path
-    print(
-        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
-    )
-    raise
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import os
+import sys
+from typing import Callable, Dict, Optional, Tuple
+
+from skdecide import Domain, Solver, hub
+from skdecide.builders.domain import (
+    Actions,
+    EnumerableTransitions,
+    FullyObservable,
+    Goals,
+    Markovian,
+    PositiveCosts,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
+from skdecide.core import Value
+
+record_sys_path = sys.path
+skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
+if skdecide_cpp_extension_lib_path not in sys.path:
+    sys.path.append(skdecide_cpp_extension_lib_path)
+
+try:
+
+    from __skdecide_hub_cpp import _ILAOStarSolver_ as ilaostar_solver
+
+    # TODO: remove Markovian req?
+    class D(
+        Domain,
+        SingleAgent,
+        Sequential,
+        EnumerableTransitions,
+        Actions,
+        Goals,
+        Markovian,
+        FullyObservable,
+        PositiveCosts,
+    ):
+        pass
+
+    class ILAOstar(
+        ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState
+    ):
+        """This is the skdecide implementation of Improved-LAO* as described in
+        "LAO*: A heuristic search algorithm that finds solutions with loops" by Eric
+        A. Hansen and Shlomo Zilberstein (2001)
+        """
+
+        T_domain = D
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], Domain],
+            heuristic: Optional[
+                Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
+            ] = lambda d, s: Value(cost=0),
+            discount: float = 1.0,
+            epsilon: float = 0.001,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[[ILAOstar], bool] = lambda slv: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a ILAO* solver instance
+
+            # Parameters
+            domain_factory (Callable[[], Domain]): The lambda function to create a domain instance.
+            heuristic (Optional[ Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]] ], optional):
+                Lambda function taking as arguments the domain and a state object,
+                and returning the heuristic estimate from the state to the goal.
+                Defaults to (lambda d, s: Value(cost=0)).
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that
+                the value function of the root state of the search has converged. Defaults to 0.001.
+            parallel (bool, optional): Parallelize the generation of state-action transitions and the update
+                of state attributes (e.g. Bellman residuals) on different processes using duplicated domains (True)
+                or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (_type_, optional): Lambda function called at the beginning of each policy update
+                depth-first search, taking as arguments the solver and the domain, and returning true if
+                the solver must be stopped. Defaults to (lambda slv: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be
+                logged (True) or not (False). Defaults to False.
+            """
+            ParallelSolver.__init__(
+                self,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+            )
+            Solver.__init__(self, domain_factory=domain_factory)
+            self._solver = None
+            self._discount = discount
+            self._epsilon = epsilon
+            self._heuristic = heuristic
+            self._lambdas = [self._heuristic]
+            self._callback = callback
+            self._verbose = verbose
+            self._ipc_notify = True
+
+        def close(self):
+            """Joins the parallel domains' processes.
+            Not calling this method (or not using the 'with' context statement)
+            results in the solver forever waiting for the domain processes to exit.
+            """
+            if self._parallel:
+                self._solver.close()
+            ParallelSolver.close(self)
+
+        def _init_solve(self) -> None:
+            self._solver = ilaostar_solver(
+                solver=self,
+                domain=self.get_domain(),
+                goal_checker=lambda d, s: d.is_goal(s),
+                heuristic=lambda d, s: (
+                    self._heuristic(d, s) if not self._parallel else d.call(None, 0, s)
+                ),
+                discount=self._discount,
+                epsilon=self._epsilon,
+                parallel=self._parallel,
+                callback=self._callback,
+                verbose=self._verbose,
+            )
+            self._solver.clear()
+
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
+
+        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the ILAO* algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): State from which ILAO* graph traversals
+                are performed (root of the search graph)
+            """
+            self._solver.solve(memory)
+
+        def _is_solution_defined_for(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> bool:
+            """Indicates whether the solution policy (potentially built from merging
+                several previously computed plans) is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if a plan that goes through the state has been previously computed,
+                False otherwise
+            """
+            return self._solver.is_solution_defined_for(observation)
+
+        def _get_next_action(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed action in terms of of best Q-value in a given state.
+                The solver is run from `observation` if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `ILAOstar.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed action
+            """
+            if not self._is_solution_defined_for(observation):
+                self._solve_from(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
+
+        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the best Q-value in a given state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `ILAOstar.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the best Q-value is requested
+
+            # Returns
+            D.T_value: Minimum Q-Value of the given state over the applicable actions in this state
+            """
+            return self._solver.get_utility(observation)
+
+        def get_nb_of_explored_states(self) -> int:
+            """Get the number of states present in the search graph
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_of_explored_states()
+
+        def get_explored_states(self) -> Set[D.T_agent[D.T_observation]]:
+            """Get the set of states present in the search graph (i.e. the graph's
+                state nodes minus the nodes' encapsulation and their children)
+
+            # Returns
+            Set[D.T_agent[D.T_observation]]: Set of states present in the search graph
+            """
+            return self._solver.get_explored_states()
+
+        def best_solution_graph_size(self) -> int:
+            """Get the number of states present in the current best policy graph
+
+            # Returns
+            int: Number of states present in the current best policy graph
+            """
+            return self._solver.best_solution_graph_size()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
+        def get_policy(
+            self,
+        ) -> Dict[
+            D.T_agent[D.T_observation],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], float],
+        ]:
+            """Get the (partial) solution policy defined for the states for which
+                the Q-value has been updated at least once (which is optimal for
+                the states reachable by the policy from the root solving state)
+
+            !!! warning
+                Only defined over the states reachable from the root solving state
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value], ]:
+                Mapping from states to pairs of action and best Q-value
+            """
+            return self._solver.get_policy()
+
+except ImportError:
+    sys.path = record_sys_path
+    print(
+        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
+    )
+    raise
```

## skdecide/hub/solver/iw/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .iw import IW
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .iw import IW
```

## skdecide/hub/solver/iw/iw.py

```diff
@@ -1,139 +1,293 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import os
-import sys
-from typing import Any, Callable, List, Tuple
-
-from skdecide import Domain, Solver, hub
-from skdecide.builders.domain import (
-    Actions,
-    DeterministicInitialized,
-    DeterministicTransitions,
-    FullyObservable,
-    Markovian,
-    Rewards,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
-from skdecide.hub.space.gym import ListSpace
-
-record_sys_path = sys.path
-skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
-if skdecide_cpp_extension_lib_path not in sys.path:
-    sys.path.append(skdecide_cpp_extension_lib_path)
-
-try:
-
-    from __skdecide_hub_cpp import _IWSolver_ as iw_solver
-
-    class D(
-        Domain,
-        SingleAgent,
-        Sequential,
-        DeterministicTransitions,
-        Actions,
-        DeterministicInitialized,
-        Markovian,
-        FullyObservable,
-        Rewards,
-    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
-        pass
-
-    class IW(ParallelSolver, Solver, DeterministicPolicies, Utilities):
-        T_domain = D
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            state_features: Callable[[Domain, D.T_state], Any],
-            use_state_feature_hash: bool = False,
-            node_ordering: Callable[[float, int, int, float, int, int], bool] = None,
-            time_budget: int = 0,  # time budget to continue searching for better plans after a goal has been reached
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-        ) -> None:
-            ParallelSolver.__init__(
-                self,
-                domain_factory=domain_factory,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-            )
-            self._solver = None
-            self._domain = None
-            self._state_features = state_features
-            self._use_state_feature_hash = use_state_feature_hash
-            self._node_ordering = node_ordering
-            self._time_budget = time_budget
-            self._debug_logs = debug_logs
-            self._lambdas = [self._state_features]
-            self._ipc_notify = True
-
-        def close(self):
-            """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
-            """
-            if self._parallel:
-                self._solver.close()
-            ParallelSolver.close(self)
-
-        def _init_solve(self, domain_factory: Callable[[], D]) -> None:
-            self._domain_factory = domain_factory
-            self._solver = iw_solver(
-                domain=self.get_domain(),
-                state_features=lambda d, s: self._state_features(d, s)
-                if not self._parallel
-                else d.call(None, 0, s),
-                use_state_feature_hash=self._use_state_feature_hash,
-                node_ordering=self._node_ordering,
-                time_budget=self._time_budget,
-                parallel=self._parallel,
-                debug_logs=self._debug_logs,
-            )
-            self._solver.clear()
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
-
-        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-            self._solver.solve(memory)
-
-        def _is_solution_defined_for(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> bool:
-            return self._solver.is_solution_defined_for(observation)
-
-        def _get_next_action(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if not self._is_solution_defined_for(observation):
-                self._solve_from(observation)
-            return self._solver.get_next_action(observation)
-
-        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-            return self._solver.get_utility(observation)
-
-        def _reset(self) -> None:
-            self._solver.clear()
-
-        def get_nb_of_explored_states(self) -> int:
-            return self._solver.get_nb_of_explored_states()
-
-        def get_nb_of_pruned_states(self) -> int:
-            return self._solver.get_nb_of_pruned_states()
-
-        def get_intermediate_scores(self) -> List[Tuple[int, float]]:
-            return self._solver.get_intermediate_scores()
-
-except ImportError:
-    sys.path = record_sys_path
-    print(
-        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
-    )
-    raise
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import os
+import sys
+from typing import Any, Callable, List, Set, Tuple
+
+from skdecide import Domain, Solver, hub
+from skdecide.builders.domain import (
+    Actions,
+    DeterministicInitialized,
+    DeterministicTransitions,
+    FullyObservable,
+    Markovian,
+    Rewards,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
+from skdecide.hub.space.gym import ListSpace
+
+record_sys_path = sys.path
+skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
+if skdecide_cpp_extension_lib_path not in sys.path:
+    sys.path.append(skdecide_cpp_extension_lib_path)
+
+try:
+
+    from __skdecide_hub_cpp import _IWSolver_ as iw_solver
+
+    class D(
+        Domain,
+        SingleAgent,
+        Sequential,
+        DeterministicTransitions,
+        Actions,
+        DeterministicInitialized,
+        Markovian,
+        FullyObservable,
+        Rewards,
+    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
+        pass
+
+    class IW(ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState):
+        """This is the skdecide implementation of the Iterated Width algorithm as described
+        in "Width and Serialization of Classical Planning Problems" by Nir Lipovetzky
+        and Hector Geffner (2012)
+        """
+
+        T_domain = D
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], Domain],
+            state_features: Callable[[Domain, D.T_state], Any],
+            use_state_feature_hash: bool = False,
+            node_ordering: Callable[[float, int, int, float, int, int], bool] = (
+                lambda a_gscore, a_novelty, a_depth, b_gscore, b_novelty, b_depth: a_gscore
+                > b_gscore
+            ),
+            time_budget: int = 0,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[[IW], bool] = lambda slv: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a IW solver instance
+
+            # Parameters
+            domain_factory (Callable[[], Domain]): The lambda function to create a domain instance.
+            state_features (Callable[[Domain, D.T_state], Any]): State feature vector
+                used to compute the novelty measure
+            use_state_feature_hash (bool, optional): Boolean indicating whether states
+                must be hashed by using their features (True) or by using their native
+                hash function (False). Defaults to False.
+            node_ordering (_type_, optional): Lambda function called to rank two search nodes
+                A and B, taking as inputs A's g-score, A's novelty, A's search depth,
+                B's g-score, B's novelty, B's search depth, and returning true when B should be
+                preferred to A (defaults to rank nodes based on their g-scores).
+                Defaults to ( lambda a_gscore, a_novelty, a_depth, b_gscore, b_novelty, b_depth: a_gscore > b_gscore ).
+            time_budget (int, optional): Maximum time allowed (in milliseconds) to continue searching
+                for better plans after a first plan reaching a goal has been found. Defaults to 0.
+            parallel (bool, optional): Parallelize the generation of state-action transitions
+                on different processes using duplicated domains (True) or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (_type_, optional): Lambda function called before popping
+                the next state from the (priority) open queue, taking as arguments the solver and the domain,
+                and returning true if the solver must be stopped. Defaults to (lambda slv:False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be
+                logged (True) or not (False). Defaults to False.
+            """
+            ParallelSolver.__init__(
+                self,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+            )
+            Solver.__init__(self, domain_factory=domain_factory)
+            self._solver = None
+            self._domain = None
+            self._state_features = state_features
+            self._use_state_feature_hash = use_state_feature_hash
+            self._node_ordering = node_ordering
+            self._time_budget = time_budget
+            self._lambdas = [self._state_features]
+            self._callback = callback
+            self._verbose = verbose
+            self._ipc_notify = True
+
+        def close(self):
+            """Joins the parallel domains' processes.
+            Not calling this method (or not using the 'with' context statement)
+            results in the solver forever waiting for the domain processes to exit.
+            """
+            if self._parallel:
+                self._solver.close()
+            ParallelSolver.close(self)
+
+        def _init_solve(self) -> None:
+            self._solver = iw_solver(
+                solver=self,
+                domain=self.get_domain(),
+                state_features=(
+                    (lambda d, s: self._state_features(d, s))
+                    if not self._parallel
+                    else (lambda d, s: d.call(None, 0, s))
+                ),
+                use_state_feature_hash=self._use_state_feature_hash,
+                node_ordering=self._node_ordering,
+                time_budget=self._time_budget,
+                parallel=self._parallel,
+                callback=self._callback,
+                verbose=self._verbose,
+            )
+            self._solver.clear()
+
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
+
+        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the IW algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): State from which IW graph traversals
+                are performed (root of the search graph)
+            """
+            self._solver.solve(memory)
+
+        def _is_solution_defined_for(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> bool:
+            """Indicates whether the solution policy (potentially built from merging
+                several previously computed plans) is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if a plan that goes through the state has been previously computed,
+                False otherwise
+            """
+            return self._solver.is_solution_defined_for(observation)
+
+        def _get_next_action(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed action in terms of minimum cost-to-go in a given state.
+                The solver is run from `observation` if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `IW.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed action
+            """
+            if not self._is_solution_defined_for(observation):
+                self._solve_from(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
+
+        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the minimum cost-to-go in a given state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `IW.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the minimum cost-to-go is requested
+
+            # Returns
+            D.T_value: Minimum cost-to-go of the given state over the applicable actions in this state
+            """
+            return self._solver.get_utility(observation)
+
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
+
+        def get_explored_states(self) -> Set[D.T_agent[D.T_observation]]:
+            """Get the set of states present in the search graph (i.e. the graph's
+                state nodes minus the nodes' encapsulation and their neighbors)
+
+            # Returns
+            Set[D.T_agent[D.T_observation]]: Set of states present in the search graph
+            """
+            return self._solver.get_explored_states()
+
+        def get_nb_of_pruned_states(self) -> int:
+            """Get the number of states pruned by the novelty measure among the
+                ones present in the search graph
+
+            # Returns
+            int: Number of states pruned by the novelty
+                measure among the ones present in the search graph graph
+            """
+            return self._solver.get_nb_of_pruned_states()
+
+        def get_nb_tip_states(self) -> int:
+            """Get the number of states present in the priority queue (i.e. those
+                explored states that have not been yet closed by IW) of the current width
+                search procedure (throws a runtime exception if no active width sub-solver
+                is active)
+
+            !!! warning
+                Throws a runtime exception if no active width sub-solver is active
+
+            # Returns
+            int: Number of states present in the (priority) open queue
+                of the current width search procedure
+            """
+            return self._solver.get_nb_tip_states()
+
+        def get_top_tip_state(self) -> D.T_agent[D.T_observation]:
+            """Get the top tip state, i.e. the tip state with the lowest
+                lexicographical score (according to the node ordering functor given in the
+                IWSolver instance's constructor) of the current width search procedure
+
+            !!! warning
+                Returns None if no active width sub-solver is active or if the priority queue
+                of the current width search procedure is empty
+
+            # Returns
+            D.T_agent[D.T_observation]: Next tip state to be closed by the current width
+                search procedure
+            """
+            return self._solver.get_top_tip_state()
+
+        def get_intermediate_scores(self) -> List[Tuple[int, int, float]]:
+            """Get the history of tuples of time point (in milliseconds), current
+                width, and root state's f-score, recorded each time a goal state is
+                encountered during the search
+
+            # Returns
+            List[Tuple[int, int, float]]: List of tuples of time point (in milliseconds),
+                current width, and root state's f-score
+            """
+            return self._solver.get_intermediate_scores()
+
+except ImportError:
+    sys.path = record_sys_path
+    print(
+        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
+    )
+    raise
```

## skdecide/hub/solver/lazy_astar/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .lazy_astar import LazyAstar
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .lazy_astar import LazyAstar
```

## skdecide/hub/solver/lazy_astar/lazy_astar.py

```diff
@@ -1,186 +1,227 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from heapq import heappop, heappush
-from itertools import count
-from typing import Callable, Optional
-
-from skdecide import Domain, Solver, Value
-from skdecide.builders.domain import (
-    Actions,
-    DeterministicTransitions,
-    FullyObservable,
-    Goals,
-    Markovian,
-    PositiveCosts,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, Utilities
-
-
-# TODO: remove Markovian req?
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    DeterministicTransitions,
-    Actions,
-    Goals,
-    Markovian,
-    FullyObservable,
-    PositiveCosts,
-):
-    pass
-
-
-class LazyAstar(Solver, DeterministicPolicies, Utilities):
-    T_domain = D
-
-    def __init__(
-        self,
-        from_state: Optional[D.T_state] = None,
-        heuristic: Optional[
-            Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
-        ] = None,
-        weight: float = 1.0,
-        verbose: bool = False,
-        render: bool = False,
-    ) -> None:
-
-        self._from_state = from_state
-        self._heuristic = (
-            (lambda _, __: Value(cost=0.0)) if heuristic is None else heuristic
-        )
-        self._weight = weight
-        self._verbose = verbose
-        self._render = render
-        self._values = {}
-        self._plan = []
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self._domain = domain_factory()
-
-        def extender(node, label, explored):
-            result = []
-            for a in self._domain.get_applicable_actions(node).get_elements():
-                n = self._domain.get_next_state(node, a)
-                if n not in explored:
-                    result.append(
-                        (
-                            n,
-                            self._domain.get_transition_value(node, a, n).cost,
-                            {"action": a},
-                        )
-                    )
-            return result
-
-        push = heappush
-        pop = heappop
-        if self._from_state is None:
-            # get initial observation from domain (assuming DeterministicInitialized)
-            sources = [self._domain.get_initial_state()]
-        else:
-            sources = [self._from_state]
-        # targets = list(self._domain.get_goals().get_elements())
-
-        # The queue is the OPEN list.
-        # It stores priority, node, cost to reach, parent and label (any data type) of transition from parent.
-        # Uses Python heapq to keep in priority order.
-        # Add a counter to the queue to prevent the underlying heap from
-        # attempting to compare the nodes themselves. The hash breaks ties in the
-        # priority and is guaranteed unique for all nodes in the graph.
-        c = count()
-
-        # TODO: check if necessary (a priori used to keep additional infos)
-        initial_label = {source: None for source in sources}
-        # Maps enqueued nodes to distance of discovered paths and the
-        # computed heuristics to target. We avoid computing the heuristics
-        # more than once and inserting the node into the queue too many times.
-        enqueued = {
-            source: (0, self._weight * self._heuristic(self._domain, source).cost)
-            for source in sources
-        }
-        # enqueued = {source: min([(0, self._weight * self._heuristic(source, target, initial_label[source]).cost)
-        # for target in targets], key=lambda x: x[1]) for source in sources}
-        queue = [
-            (enqueued[source][1], next(c), source, 0, None, initial_label[source])
-            for source in sources
-        ]
-        # The explored dict is the CLOSED list.
-        # It maps explored nodes to a pair of parent closest to the source and label of transition from parent.
-        explored = {}
-        path = []
-        estim_total = 0.0
-        while queue:
-            # Pop the smallest item from queue, i.e. with smallest f-value
-            estim_total, __, curnode, dist, parent, label = pop(queue)
-            if self._render:
-                self._domain.render(curnode)
-            if self._verbose:
-                print(
-                    curnode,
-                    f"- cumulated cost: {dist} - estimated total cost: {estim_total}",
-                )
-            if self._domain.is_goal(curnode):
-                path = [(parent, label), (curnode, None)]
-                node = parent
-                while node is not None:
-                    (parent, label) = explored[node]
-                    if parent is not None:
-                        path.insert(0, (parent, label))
-                    node = parent
-                break  # return path, dist, enqueued[curnode][0], len(enqueued)
-            if curnode in explored:
-                continue
-            explored[curnode] = (parent, label)
-            for neighbor, cost, lbl in extender(curnode, label, explored):
-                if neighbor in explored:
-                    continue
-                ncost = dist + cost
-                if neighbor in enqueued:
-                    qcost, h = enqueued[neighbor]
-                    # if qcost < ncost, a longer path to neighbor remains
-                    # enqueued. Removing it would need to filter the whole
-                    # queue, it's better just to leave it there and ignore
-                    # it when we visit the node a second time.
-                    if qcost <= ncost:
-                        continue
-                else:
-                    # h = min([self._heuristic(neighbor, target, lbl).cost for target in targets])
-                    h = self._heuristic(self._domain, neighbor).cost
-                enqueued[neighbor] = ncost, h
-                push(
-                    queue,
-                    (
-                        ncost + (self._weight * h),
-                        next(c),
-                        neighbor,
-                        ncost,
-                        curnode,
-                        lbl,
-                    ),
-                )
-        self._policy = {}
-        for node, label in path:
-            self._policy[node] = label["action"] if label is not None else None
-            self._values[node] = estim_total - enqueued[node][0]
-            if self._policy[node] is not None:
-                self._plan.append(self._policy[node])
-        # return estim_total, path  # TODO: find a way to expose these things through public API?
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        return self._policy[observation]
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return observation in self._policy
-
-    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-        if observation not in self._values:
-            return self._heuristic(self._domain, observation).cost
-        return self._values[observation]
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from heapq import heappop, heappush
+from itertools import count
+from typing import Callable, Dict, List, Optional
+
+from skdecide import Domain, Solver, Value
+from skdecide.builders.domain import (
+    Actions,
+    DeterministicTransitions,
+    FullyObservable,
+    Goals,
+    Markovian,
+    PositiveCosts,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import DeterministicPolicies, FromAnyState, Utilities
+
+
+# TODO: remove Markovian req?
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    DeterministicTransitions,
+    Actions,
+    Goals,
+    Markovian,
+    FullyObservable,
+    PositiveCosts,
+):
+    pass
+
+
+class LazyAstar(Solver, DeterministicPolicies, Utilities, FromAnyState):
+    """Lazy A* solver."""
+
+    T_domain = D
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        heuristic: Optional[
+            Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
+        ] = None,
+        weight: float = 1.0,
+        verbose: bool = False,
+        render: bool = False,
+        callback: Callable[[LazyAstar], bool] = lambda solver: False,
+    ) -> None:
+        """
+
+        # Parameters
+        domain_factory
+        heuristic
+        weight
+        verbose
+        render
+        callback: function called at each solver iteration. If returning true, the solve process stops.
+
+        """
+        self.callback = callback
+        Solver.__init__(self, domain_factory=domain_factory)
+        self._heuristic = (
+            (lambda _, __: Value(cost=0.0)) if heuristic is None else heuristic
+        )
+        self._weight = weight
+        self._verbose = verbose
+        self._render = render
+        self._values = {}
+        self._plan: List[D.T_event] = []
+
+    def get_plan(self) -> List[D.T_event]:
+        """Return the computed plan."""
+        return self._plan
+
+    def get_policy(self) -> Dict[D.T_observation, Optional[D.T_event]]:
+        """Return the computed policy."""
+        return self._policy
+
+    def _init_solve(self) -> None:
+        """Initialize solver before calling `solve_from()`
+
+        In particular, initialize the underlying domain.
+
+        """
+        self._domain = self._domain_factory()
+
+    def _solve_from(
+        self,
+        memory: D.T_state,
+    ) -> None:
+        """Run the solving process from a given state.
+
+        !!! tip
+            Create the domain first by calling the @FromAnyState._init_solve() method
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+
+        !!! tip
+            The nature of the solutions produced here depends on other solver's characteristics like
+            #policy and #assessibility.
+        """
+
+        def extender(node, label, explored):
+            result = []
+            for a in self._domain.get_applicable_actions(node).get_elements():
+                n = self._domain.get_next_state(node, a)
+                if n not in explored:
+                    result.append(
+                        (
+                            n,
+                            self._domain.get_transition_value(node, a, n).cost,
+                            {"action": a},
+                        )
+                    )
+            return result
+
+        push = heappush
+        pop = heappop
+        sources = [memory]
+        # targets = list(self._domain.get_goals().get_elements())
+
+        # The queue is the OPEN list.
+        # It stores priority, node, cost to reach, parent and label (any data type) of transition from parent.
+        # Uses Python heapq to keep in priority order.
+        # Add a counter to the queue to prevent the underlying heap from
+        # attempting to compare the nodes themselves. The hash breaks ties in the
+        # priority and is guaranteed unique for all nodes in the graph.
+        c = count()
+
+        # TODO: check if necessary (a priori used to keep additional infos)
+        initial_label = {source: None for source in sources}
+        # Maps enqueued nodes to distance of discovered paths and the
+        # computed heuristics to target. We avoid computing the heuristics
+        # more than once and inserting the node into the queue too many times.
+        enqueued = {
+            source: (0, self._weight * self._heuristic(self._domain, source).cost)
+            for source in sources
+        }
+        # enqueued = {source: min([(0, self._weight * self._heuristic(source, target, initial_label[source]).cost)
+        # for target in targets], key=lambda x: x[1]) for source in sources}
+        self.queue = [
+            (enqueued[source][1], next(c), source, 0, None, initial_label[source])
+            for source in sources
+        ]
+        # The explored dict is the CLOSED list.
+        # It maps explored nodes to a pair of parent closest to the source and label of transition from parent.
+        self.explored = {}
+        path = []
+        estim_total = 0.0
+        while self.queue and not self.callback(self):
+            # Pop the smallest item from queue, i.e. with smallest f-value
+            estim_total, __, curnode, dist, parent, label = pop(self.queue)
+
+            if self._render:
+                self._domain.render(curnode)
+            if self._verbose:
+                print(
+                    curnode,
+                    f"- cumulated cost: {dist} - estimated total cost: {estim_total}",
+                )
+            if self._domain.is_goal(curnode):
+                path = [(parent, label), (curnode, None)]
+                node = parent
+                while node is not None:
+                    (parent, label) = self.explored[node]
+                    if parent is not None:
+                        path.insert(0, (parent, label))
+                    node = parent
+                break  # return path, dist, enqueued[curnode][0], len(enqueued)
+            if curnode in self.explored:
+                continue
+            self.explored[curnode] = (parent, label)
+            for neighbor, cost, lbl in extender(curnode, label, self.explored):
+                if neighbor in self.explored:
+                    continue
+                ncost = dist + cost
+                if neighbor in enqueued:
+                    qcost, h = enqueued[neighbor]
+                    # if qcost < ncost, a longer path to neighbor remains
+                    # enqueued. Removing it would need to filter the whole
+                    # queue, it's better just to leave it there and ignore
+                    # it when we visit the node a second time.
+                    if qcost <= ncost:
+                        continue
+                else:
+                    # h = min([self._heuristic(neighbor, target, lbl).cost for target in targets])
+                    h = self._heuristic(self._domain, neighbor).cost
+                enqueued[neighbor] = ncost, h
+                push(
+                    self.queue,
+                    (
+                        ncost + (self._weight * h),
+                        next(c),
+                        neighbor,
+                        ncost,
+                        curnode,
+                        lbl,
+                    ),
+                )
+        self._policy: Dict[D.T_observation, Optional[D.T_event]] = {}
+        for node, label in path:
+            self._policy[node] = label["action"] if label is not None else None
+            self._values[node] = estim_total - enqueued[node][0]
+            if self._policy[node] is not None:
+                self._plan.append(self._policy[node])
+        # return estim_total, path  # TODO: find a way to expose these things through public API?
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        return self._policy[observation]
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return observation in self._policy
+
+    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+        if observation not in self._values:
+            return self._heuristic(self._domain, observation).cost
+        return self._values[observation]
```

## skdecide/hub/solver/lrtastar/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .lrtastar import LRTAstar
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .lrtastar import LRTAstar
```

## skdecide/hub/solver/lrtastar/lrtastar.py

```diff
@@ -1,167 +1,202 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-# TODO comment.
-
-from __future__ import annotations
-
-from typing import Callable, Optional
-
-from skdecide import Domain, Solver, Value
-from skdecide.builders.domain import (
-    Actions,
-    DeterministicTransitions,
-    FullyObservable,
-    Goals,
-    Markovian,
-    PositiveCosts,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, Utilities
-
-
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    DeterministicTransitions,
-    Actions,
-    Goals,
-    Markovian,
-    FullyObservable,
-    PositiveCosts,
-):
-    pass
-
-
-class LRTAstar(Solver, DeterministicPolicies, Utilities):
-    T_domain = D
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        return self._policy.get(observation, None)
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return observation is self._policy
-
-    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-        if observation not in self.values:
-            return self._heuristic(self._domain, observation).cost
-        return self.values[observation]
-
-    def __init__(
-        self,
-        from_state: Optional[D.T_state] = None,
-        heuristic: Optional[
-            Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
-        ] = None,
-        weight: float = 1.0,
-        verbose: bool = False,
-        max_iter=5000,
-        max_depth=200,
-    ) -> None:
-        self._from_state = from_state
-        self._heuristic = (
-            (lambda _, __: Value(cost=0.0)) if heuristic is None else heuristic
-        )
-        self._weight = weight
-        self.max_iter = max_iter
-        self.max_depth = max_depth
-        self._plan = []
-        self.values = {}
-
-        self._verbose = verbose
-
-        self.heuristic_changed = False
-        self._policy = {}
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self._domain = domain_factory()
-        self.values = {}
-        iteration = 0
-        best_cost = float("inf")
-        if self._from_state is None:
-            # get initial observation from domain (assuming DeterministicInitialized)
-            from_observation = self._domain.get_initial_state()
-        else:
-            from_observation = self._from_state
-        # best_path = None
-        while True:
-            print(from_observation)
-            dead_end, cumulated_cost, current_roll, list_action = self.doTrial(
-                from_observation
-            )
-            if self._verbose:
-                print(
-                    "iter ",
-                    iteration,
-                    "/",
-                    self.max_iter,
-                    " : dead end, ",
-                    dead_end,
-                    " cost : ",
-                    cumulated_cost,
-                )
-            if not dead_end and cumulated_cost < best_cost:
-                best_cost = cumulated_cost
-                # best_path = current_roll
-                for k in range(len(current_roll)):
-                    self._policy[current_roll[k][0]] = current_roll[k][1]["action"]
-            if not self.heuristic_changed:
-                print(self.heuristic_changed)
-                return
-            iteration += 1
-            if iteration > self.max_iter:
-                return
-
-    def doTrial(self, from_observation: D.T_agent[D.T_observation]):
-        list_action = []
-        current_state = from_observation
-        depth = 0
-        dead_end = False
-        cumulated_reward = 0.0
-        current_roll = [current_state]
-        current_roll_and_action = []
-        self.heuristic_changed = False
-        while (not self._domain.is_goal(current_state)) and (depth < self.max_depth):
-            next_action = None
-            next_state = None
-            best_estimated_cost = float("inf")
-            applicable_actions = self._domain.get_applicable_actions(current_state)
-            for action in applicable_actions.get_elements():
-                st = self._domain.get_next_state(current_state, action)
-                r = self._domain.get_transition_value(current_state, action, st).cost
-                if st in current_roll:
-                    continue
-                if st not in self.values:
-                    self.values[st] = self._heuristic(self._domain, st).cost
-                if r + self.values[st] < best_estimated_cost:
-                    next_state = st
-                    next_action = action
-                    best_estimated_cost = r + self.values[st]
-            if next_action is None:
-                self.values[current_state] = float("inf")
-                dead_end = True
-                self.heuristic_changed = True
-                break
-            else:
-                if (not current_state in self.values) or (
-                    self.values[current_state] != best_estimated_cost
-                ):
-                    self.heuristic_changed = True
-                    self.values[current_state] = best_estimated_cost
-            cumulated_reward += best_estimated_cost - (
-                self.values[next_state]
-                if next_state in self.values
-                else self._heuristic(self._domain, next_state).cost
-            )
-            list_action.append(next_action)
-            current_roll_and_action.append((current_state, {"action": next_action}))
-            current_state = next_state
-            depth += 1
-            current_roll.append(current_state)
-        current_roll_and_action.append((current_state, {"action": None}))
-        cumulated_reward += self.values[current_state]
-        return dead_end, cumulated_reward, current_roll_and_action, list_action
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+# TODO comment.
+
+from __future__ import annotations
+
+from typing import Callable, Dict, List, Optional
+
+from skdecide import Domain, Solver, Value
+from skdecide.builders.domain import (
+    Actions,
+    DeterministicTransitions,
+    FullyObservable,
+    Goals,
+    Markovian,
+    PositiveCosts,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import DeterministicPolicies, FromAnyState, Utilities
+
+
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    DeterministicTransitions,
+    Actions,
+    Goals,
+    Markovian,
+    FullyObservable,
+    PositiveCosts,
+):
+    pass
+
+
+class LRTAstar(Solver, DeterministicPolicies, Utilities, FromAnyState):
+    """Learning Real-Time A* solver."""
+
+    T_domain = D
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        return self._policy.get(observation, None)
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return observation in self._policy
+
+    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+        if observation not in self.values:
+            return self._heuristic(self._domain, observation).cost
+        return self.values[observation]
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        heuristic: Optional[
+            Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
+        ] = None,
+        weight: float = 1.0,
+        verbose: bool = False,
+        max_iter=5000,
+        max_depth=200,
+        callback: Callable[[LRTAstar], bool] = lambda solver: False,
+    ) -> None:
+        """
+
+        # Parameters
+        domain_factory
+        heuristic
+        weight
+        verbose
+        max_iter
+        max_depth
+        callback: function called at each solver iteration. If returning true, the solve process stops.
+
+        """
+        self.callback = callback
+        Solver.__init__(self, domain_factory=domain_factory)
+        self._heuristic = (
+            (lambda _, __: Value(cost=0.0)) if heuristic is None else heuristic
+        )
+        self._weight = weight
+        self.max_iter = max_iter
+        self.max_depth = max_depth
+        self._plan: List[D.T_event] = []
+        self.values = {}
+
+        self._verbose = verbose
+
+        self.heuristic_changed = False
+        self._policy: Dict[D.T_observation, Optional[D.T_event]] = {}
+
+    def get_policy(self) -> Dict[D.T_observation, Optional[D.T_event]]:
+        """Return the computed policy."""
+        return self._policy
+
+    def _init_solve(self) -> None:
+        """Initialize solver before calling `solve_from()`
+
+        In particular, initialize the underlying domain.
+
+        """
+        self._domain = self._domain_factory()
+
+    def _solve_from(
+        self,
+        memory: D.T_state,
+    ) -> None:
+        """Run the solving process from a given state.
+
+        !!! tip
+            Create the domain first by calling the @FromAnyState._init_solve() method
+
+        # Parameters
+        memory: The source memory (state or history) of the transition.
+
+        !!! tip
+            The nature of the solutions produced here depends on other solver's characteristics like
+            #policy and #assessibility.
+        """
+        self.values = {}
+        iteration = 0
+        best_cost = float("inf")
+        # best_path = None
+        while not self.callback(self):
+            print(memory)
+            dead_end, cumulated_cost, current_roll, list_action = self.doTrial(memory)
+            if self._verbose:
+                print(
+                    "iter ",
+                    iteration,
+                    "/",
+                    self.max_iter,
+                    " : dead end, ",
+                    dead_end,
+                    " cost : ",
+                    cumulated_cost,
+                )
+            if not dead_end and cumulated_cost < best_cost:
+                best_cost = cumulated_cost
+                # best_path = current_roll
+                for k in range(len(current_roll)):
+                    self._policy[current_roll[k][0]] = current_roll[k][1]["action"]
+            if not self.heuristic_changed:
+                print(self.heuristic_changed)
+                return
+            iteration += 1
+            if iteration > self.max_iter:
+                return
+
+    def doTrial(self, from_observation: D.T_agent[D.T_observation]):
+        list_action = []
+        current_state = from_observation
+        depth = 0
+        dead_end = False
+        cumulated_reward = 0.0
+        current_roll = [current_state]
+        current_roll_and_action = []
+        self.heuristic_changed = False
+        while (not self._domain.is_goal(current_state)) and (depth < self.max_depth):
+            next_action = None
+            next_state = None
+            best_estimated_cost = float("inf")
+            applicable_actions = self._domain.get_applicable_actions(current_state)
+            for action in applicable_actions.get_elements():
+                st = self._domain.get_next_state(current_state, action)
+                r = self._domain.get_transition_value(current_state, action, st).cost
+                if st in current_roll:
+                    continue
+                if st not in self.values:
+                    self.values[st] = self._heuristic(self._domain, st).cost
+                if r + self.values[st] < best_estimated_cost:
+                    next_state = st
+                    next_action = action
+                    best_estimated_cost = r + self.values[st]
+            if next_action is None:
+                self.values[current_state] = float("inf")
+                dead_end = True
+                self.heuristic_changed = True
+                break
+            else:
+                if (not current_state in self.values) or (
+                    self.values[current_state] != best_estimated_cost
+                ):
+                    self.heuristic_changed = True
+                    self.values[current_state] = best_estimated_cost
+            cumulated_reward += best_estimated_cost - (
+                self.values[next_state]
+                if next_state in self.values
+                else self._heuristic(self._domain, next_state).cost
+            )
+            list_action.append(next_action)
+            current_roll_and_action.append((current_state, {"action": next_action}))
+            current_state = next_state
+            depth += 1
+            current_roll.append(current_state)
+        current_roll_and_action.append((current_state, {"action": None}))
+        cumulated_reward += self.values[current_state]
+        return dead_end, cumulated_reward, current_roll_and_action, list_action
```

## skdecide/hub/solver/lrtdp/lrtdp.py

```diff
@@ -15,15 +15,20 @@
     Goals,
     Markovian,
     PositiveCosts,
     Sequential,
     SingleAgent,
     UncertainTransitions,
 )
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
 from skdecide.core import Value
 
 record_sys_path = sys.path
 skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
 if skdecide_cpp_extension_lib_path not in sys.path:
     sys.path.append(skdecide_cpp_extension_lib_path)
 
@@ -41,114 +46,197 @@
         Goals,
         Markovian,
         FullyObservable,
         PositiveCosts,
     ):
         pass
 
-    class LRTDP(ParallelSolver, Solver, DeterministicPolicies, Utilities):
+    class LRTDP(ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState):
+        """This is the skdecide implementation of "Labeled RTDP: Improving the
+        Convergence of Real-Time Dynamic Programming" by Blai Bonet and Hector
+        Geffner (ICAPS 2003)
+        """
+
         T_domain = D
 
         def __init__(
             self,
-            domain_factory: Callable[[], Domain] = None,
+            domain_factory: Callable[[], T_domain],
             heuristic: Optional[
-                Callable[[Domain, D.T_state], D.T_agent[Value[D.T_value]]]
-            ] = None,
+                Callable[[T_domain, D.T_state], D.T_agent[Value[D.T_value]]]
+            ] = lambda d, s: Value(cost=0),
             use_labels: bool = True,
             time_budget: int = 3600000,
             rollout_budget: int = 100000,
             max_depth: int = 1000,
-            epsilon_moving_average_window: int = 100,
+            residual_moving_average_window: int = 100,
             epsilon: float = 0.001,
             discount: float = 1.0,
             online_node_garbage: bool = False,
             continuous_planning: bool = True,
             parallel: bool = False,
             shared_memory_proxy=None,
-            debug_logs: bool = False,
-            watchdog: Callable[[int, int, float, float], bool] = None,
+            callback: Callable[
+                [LRTDP, Optional[int]], bool
+            ] = lambda slv, i=None: False,
+            verbose: bool = False,
         ) -> None:
+            """Construct a LRTDP solver instance
+
+            # Parameters
+            domain_factory (Callable[[], T_domain], optional): The lambda function to create a domain instance.
+            heuristic (Optional[ Callable[[T_domain, D.T_state], D.T_agent[Value[D.T_value]]] ], optional):
+                Lambda function taking as arguments the domain and a state, and returning the heuristic
+                estimate from the state to the goal.
+                Defaults to (lambda d, s: Value(cost=0)).
+            use_labels (bool, optional): Boolean indicating whether labels must be used (True) or not
+                (False), in which case the algorithm is equivalent to the standard RTDP). Defaults to True.
+            time_budget (int, optional): Maximum solving time in milliseconds. Defaults to 3600000.
+            rollout_budget (int, optional): Maximum number of rollouts (deactivated when
+                use_labels is True). Defaults to 100000.
+            max_depth (int, optional): Maximum depth of each LRTDP trial (rollout). Defaults to 1000.
+            residual_moving_average_window (int, optional): Number of latest computed residual values
+                to memorize in order to compute the average Bellman error (residual) at the root state
+                of the search (deactivated when use_labels is True). Defaults to 100.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that a state
+                is solved, or to decide when no labels are used that the value function of the root state
+                of the search has converged (in the latter case: the root state's Bellman error is averaged
+                over the residual_moving_average_window, deactivated when use_labels is True). Defaults to 0.001.
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            online_node_garbage (bool, optional): Boolean indicating whether the search graph which is
+                no more reachable from the root solving state should be deleted (True) or not (False). Defaults to False.
+            continuous_planning (bool, optional): Boolean whether the solver should optimize again the policy
+                from the current solving state (True) or not (False) even if the policy is already defined
+                in this state. Defaults to True.
+            parallel (bool, optional): Parallelize LRTDP trials on different processes using duplicated domains (True)
+                or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[LRTDP, Optional[int]], optional): Function called at the end of each LRTDP trial,
+                taking as arguments the solver and the thread/process ID (i.e. parallel domain ID, which is equal to None
+                in case of sequential execution, i.e. when 'parallel' is set to False in this constructor) from
+                which the callback is called, and returning True if the solver must be stopped. The callback lambda
+                function cannot take the (potentially parallelized) domain as argument because we could not otherwise
+                serialize (i.e. pickle) the solver to pass it to the corresponding parallel domain process in case of parallel
+                execution. Nevertheless, the `ParallelSolver.get_domain` method callable on the solver instance
+                can be used to retrieve either the user domain in sequential execution, or the parallel domains proxy
+                `ParallelDomain` in parallel execution from which domain methods can be called by using the
+                callback's process ID argument. Defaults to (lambda slv, i=None: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be logged (True)
+                or not (False). Defaults to False.
+            """
             ParallelSolver.__init__(
                 self,
-                domain_factory=domain_factory,
                 parallel=parallel,
                 shared_memory_proxy=shared_memory_proxy,
             )
+            Solver.__init__(self, domain_factory=domain_factory)
             self._solver = None
-            if heuristic is None:
-                self._heuristic = lambda d, s: Value(cost=0)
-            else:
-                self._heuristic = heuristic
+            self._heuristic = heuristic
             self._lambdas = [self._heuristic]
             self._use_labels = use_labels
             self._time_budget = time_budget
             self._rollout_budget = rollout_budget
             self._max_depth = max_depth
-            self._epsilon_moving_average_window = epsilon_moving_average_window
+            self._residual_moving_average_window = residual_moving_average_window
             self._epsilon = epsilon
             self._discount = discount
             self._online_node_garbage = online_node_garbage
             self._continuous_planning = continuous_planning
-            self._debug_logs = debug_logs
-            if watchdog is None:
-                self._watchdog = (
-                    lambda elapsed_time, number_rollouts, best_value, epsilon_moving_average: True
-                )
-            else:
-                self._watchdog = watchdog
+            self._callback = callback
+            self._verbose = verbose
             self._ipc_notify = True
 
         def close(self):
             """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
+
+            !!! warning
+                Not calling this method (or not using the 'with' context statement)
+                results in the solver forever waiting for the domain processes to exit.
+
             """
             if self._parallel:
                 self._solver.close()
             ParallelSolver.close(self)
 
-        def _init_solve(self, domain_factory: Callable[[], Domain]) -> None:
-            self._domain_factory = domain_factory
+        def _init_solve(self) -> None:
             self._solver = lrtdp_solver(
+                solver=self,
                 domain=self.get_domain(),
-                goal_checker=lambda d, s, i=None: d.is_goal(s)
-                if not self._parallel
-                else d.is_goal(s, i),
-                heuristic=lambda d, s, i=None: self._heuristic(d, s)
-                if not self._parallel
-                else d.call(i, 0, s),
+                goal_checker=(
+                    (lambda d, s, i=None: d.is_goal(s))
+                    if not self._parallel
+                    else (lambda d, s, i=None: d.is_goal(s, i))
+                ),
+                heuristic=(
+                    (lambda d, s, i=None: self._heuristic(d, s))
+                    if not self._parallel
+                    else (lambda d, s, i=None: d.call(i, 0, s))
+                ),
                 use_labels=self._use_labels,
                 time_budget=self._time_budget,
                 rollout_budget=self._rollout_budget,
                 max_depth=self._max_depth,
-                epsilon_moving_average_window=self._epsilon_moving_average_window,
+                residual_moving_average_window=self._residual_moving_average_window,
                 epsilon=self._epsilon,
                 discount=self._discount,
                 online_node_garbage=self._online_node_garbage,
                 parallel=self._parallel,
-                debug_logs=self._debug_logs,
-                watchdog=self._watchdog,
+                callback=self._callback,
+                verbose=self._verbose,
             )
             self._solver.clear()
 
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
 
         def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the LRTDP algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): State from which to run the LRTDP algorithm
+                (root of the search graph)
+            """
             self._solver.solve(memory)
 
         def _is_solution_defined_for(
             self, observation: D.T_agent[D.T_observation]
         ) -> bool:
+            """Indicates whether the solution policy is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if the state has been explored and an action is defined in this state,
+                False otherwise
+            """
             return self._solver.is_solution_defined_for(observation)
 
         def _get_next_action(
             self, observation: D.T_agent[D.T_observation]
         ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed action in terms of best Q-value in a given state. The search
+                subgraph which is no more reachable after executing the returned action is
+                also deleted if node garbage was set to True in the LRTDP instance's constructor.
+                The solver is run from `observation` if `continuous_planning` was set to True
+                in the LRTDP instance's constructor or if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `LRTDP.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed action
+            """
             if self._continuous_planning or not self._is_solution_defined_for(
                 observation
             ):
                 self._solve_from(observation)
             action = self._solver.get_next_action(observation)
             if action is None:
                 print(
@@ -159,28 +247,85 @@
                     + "\x1b[0m"
                 )
                 return self.call_domain_method("get_action_space").sample()
             else:
                 return action
 
         def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the best Q-value in a given state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `LRTDP.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the best Q-value is requested
+
+            # Returns
+            D.T_value: Minimum Q-value of the given state over the applicable actions in this state
+            """
             return self._solver.get_utility(observation)
 
-        def get_nb_of_explored_states(self) -> int:
-            return self._solver.get_nb_of_explored_states()
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph (which can be
+                lower than the number of actually explored states if node garbage was
+                set to True in the LRTDP instance's constructor)
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
 
         def get_nb_rollouts(self) -> int:
+            """Get the number of rollouts since the beginning of the search from
+                the root solving state
+
+            # Returns
+            int: Number of rollouts (LRTDP trials)
+            """
             return self._solver.get_nb_rollouts()
 
+        def get_residual_moving_average(self) -> float:
+            """Get the average Bellman error (residual) at the root state of the search,
+                or an infinite value if the number of computed residuals is lower than
+                the epsilon moving average window set in the LRTDP instance's constructor
+
+            # Returns
+            float: Bellman error at the root state of the search averaged over
+                the epsilon moving average window
+            """
+            return self._solver.get_residual_moving_average()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
         def get_policy(
             self,
         ) -> Dict[
             D.T_agent[D.T_observation],
-            Tuple[D.T_agent[D.T_concurrency[D.T_event]], float],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value],
         ]:
+            """Get the (partial) solution policy defined for the states for which
+                the Q-value has been updated at least once (which is optimal if the
+                algorithm has converged and labels are used)
+
+            !!! warning
+                Only defined over the states reachable from the last root solving state
+                when node garbage was set to True in the LRTDP instance's constructor
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value], ]:
+                Mapping from states to pairs of action and best Q-value
+            """
             return self._solver.get_policy()
 
 except ImportError:
     sys.path = record_sys_path
     print(
         'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
     )
```

## skdecide/hub/solver/mahd/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .mahd import MAHD
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .mahd import MAHD
```

## skdecide/hub/solver/mahd/mahd.py

```diff
@@ -1,187 +1,327 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Callable, Set, Tuple
-
-from skdecide import Domain, Solver
-from skdecide.builders.domain import MultiAgent, Sequential, SingleAgent
-from skdecide.builders.solver import DeterministicPolicies, Utilities
-from skdecide.core import Value
-
-
-# TODO: remove Markovian req?
-class D(Domain, MultiAgent, Sequential):
-    pass
-
-
-class MAHD(Solver, DeterministicPolicies, Utilities):
-    T_domain = D
-
-    def __init__(
-        self,
-        multiagent_solver_class,
-        singleagent_solver_class,
-        multiagent_domain_class,
-        singleagent_domain_class,
-        multiagent_domain_factory: Callable[[], Domain] = None,
-        singleagent_domain_factory: Callable[[Domain, Any], Domain] = None,
-        multiagent_solver_kwargs=None,
-        singleagent_solver_kwargs=None,
-    ) -> None:
-        if multiagent_solver_kwargs is None:
-            multiagent_solver_kwargs = {}
-        if "heuristic" in multiagent_solver_kwargs:
-            print(
-                "\x1b[3;33;40m"
-                + "Multi-agent solver heuristic will be overwritten by MAHD!"
-                + "\x1b[0m"
-            )
-        multiagent_solver_kwargs["heuristic"] = lambda d, o: self._multiagent_heuristic(
-            o
-        )
-        self._multiagent_solver = multiagent_solver_class(**multiagent_solver_kwargs)
-        self._multiagent_domain_class = multiagent_domain_class
-        self._multiagent_domain_factory = multiagent_domain_factory
-        self._multiagent_domain = self._multiagent_domain_factory()
-
-        self._singleagent_solver_class = singleagent_solver_class
-        self._singleagent_solver_kwargs = singleagent_solver_kwargs
-        self._singleagent_domain_class = singleagent_domain_class
-        self._singleagent_domain_factory = singleagent_domain_factory
-
-        self._singleagent_domains = {}
-        self._singleagent_solvers = {}
-        if self._singleagent_solver_kwargs is None:
-            self._singleagent_solver_kwargs = {}
-
-        for a in self._multiagent_domain.get_agents():
-            self._singleagent_solvers[a] = self._singleagent_solver_class(
-                **self._singleagent_solver_kwargs
-            )
-            self._singleagent_domain_class.solve_with(
-                solver=self._singleagent_solvers[a],
-                domain_factory=lambda: self._singleagent_domain_factory(
-                    self._multiagent_domain, a
-                )
-                if self._singleagent_domain_factory is not None
-                else None,
-            )
-
-        self._singleagent_solutions = {
-            a: {} for a in self._multiagent_domain.get_agents()
-        }
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self._multiagent_domain_class.solve_with(
-            solver=self._multiagent_solver, domain_factory=domain_factory
-        )
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        return self._multiagent_solver._get_next_action(observation)
-
-    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-        return self._multiagent_solver._get_utility(observation)
-
-    def _multiagent_heuristic(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> Tuple[D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]]]:
-        h = {}
-        for a, s in self._singleagent_solvers.items():
-            if observation[a] not in self._singleagent_solutions[a]:
-                undefined_solution = False
-                s.solve_from(observation[a])
-                if hasattr(self._singleagent_solvers[a], "get_policy"):
-                    p = self._singleagent_solvers[a].get_policy()
-                    for ps, pav in p.items():
-                        self._singleagent_solutions[a][ps] = pav[::-1]
-                    undefined_solution = (
-                        observation[a] not in self._singleagent_solutions[a]
-                    )
-                else:
-                    if not s.is_solution_defined_for(observation[a]):
-                        undefined_solution = True
-                    else:
-                        self._singleagent_solutions[a][observation[a]] = (
-                            s.get_utility(observation[a]),
-                            s.get_next_action(observation[a]),
-                        )
-                if undefined_solution:
-                    is_terminal = (
-                        hasattr(self._get_singleagent_domain(a), "is_goal")
-                        and self._get_singleagent_domain(a).is_goal(observation[a])
-                    ) or (
-                        hasattr(self._get_singleagent_domain(a), "is_terminal")
-                        and self._get_singleagent_domain(a).is_terminal(observation[a])
-                    )
-                    if not is_terminal:
-                        print(
-                            "\x1b[3;33;40m"
-                            + "/!\ Solution not defined for agent {} in non terminal state {}".format(
-                                a, observation[a]
-                            )
-                            + ": Assigning default action! (is it a terminal state without no-op action?)"
-                            "\x1b[0m"
-                        )
-                    try:
-                        self._singleagent_solutions[a][observation[a]] = (
-                            0,
-                            self._get_singleagent_domain(a)
-                            .get_applicable_actions(observation[a])
-                            .sample(),
-                        )
-                    except Exception as err:
-                        terminal_str = "terminal " if is_terminal else ""
-                        raise RuntimeError(
-                            "Cannot sample applicable action "
-                            "for agent {} in {}state {} "
-                            "(original exception is: {})".format(
-                                a, terminal_str, observation[a], err
-                            )
-                        )
-        if issubclass(self._multiagent_solver.T_domain, SingleAgent):
-            h = (
-                Value(
-                    cost=sum(
-                        p[observation[a]][0]
-                        for a, p in self._singleagent_solutions.items()
-                    )
-                ),
-                {
-                    a: p[observation[a]][1]
-                    for a, p in self._singleagent_solutions.items()
-                },
-            )
-        else:
-            h = (
-                {
-                    a: Value(cost=p[observation[a]][0])
-                    for a, p in self._singleagent_solutions.items()
-                },
-                {
-                    a: p[observation[a]][1]
-                    for a, p in self._singleagent_solutions.items()
-                },
-            )
-        return h
-
-    def _get_singleagent_domain(self, agent):
-        if agent not in self._singleagent_domains:
-            self._singleagent_domains[agent] = self._singleagent_domain_factory(
-                self._multiagent_domain, agent
-            )
-        return self._singleagent_domains[agent]
-
-    def _initialize(self):
-        self._multiagent_solver._initialize()
-        for a, s in self._singleagent_solvers.items():
-            s._initialize()
-
-    def _cleanup(self):
-        self._multiagent_solver._cleanup()
-        for a, s in self._singleagent_solvers.items():
-            s._cleanup()
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import inspect
+from typing import Any, Callable, List, Optional, Set, Tuple, Type
+
+from skdecide import Domain, Solver
+from skdecide.builders.domain import MultiAgent, Sequential, SingleAgent
+from skdecide.builders.solver import DeterministicPolicies, FromAnyState, Utilities
+from skdecide.core import Value
+
+
+# TODO: remove Markovian req?
+class D(Domain, MultiAgent, Sequential):
+    pass
+
+
+class MAHD(Solver, DeterministicPolicies, Utilities, FromAnyState):
+    """This is an experimental implementation of a centralized multi-agent heuristic solver
+    which makes use of a master heuristic-search solver (i.e. MARTDP, HMCTS, HUCT) to solve
+    the centralized multi-agent domain by calling a heuristic sub-solver (i.e. LRTDP, ILAO*,
+    A*) independently on each agent's domain to compute the heuristic
+    estimates of each agent as if it involved alone in the environment."""
+
+    T_domain = D
+
+    def __init__(
+        self,
+        multiagent_solver_class: Type[Solver],
+        singleagent_solver_class: Type[Solver],
+        multiagent_domain_factory: Callable[[], Domain],
+        singleagent_domain_class: Optional[Type[Domain]] = None,
+        singleagent_domain_factory: Optional[Callable[[Domain, Any], Domain]] = None,
+        multiagent_solver_kwargs=None,
+        singleagent_solver_kwargs=None,
+        callback: Callable[[MAHD], bool] = lambda solver: False,
+    ) -> None:
+        """Construct a MAHD solver instance
+
+        # Parameters
+        multiagent_solver_class (Type[Solver]): Class type of the higher-level multi-agent solver
+            called on the main multi-agent domain
+        singleagent_solver_class (Type[Solver]): Class type of the lower-level single-agent solver
+            called on the single-agent domain used to compute single agent heuristic estimates
+        multiagent_domain_factory (Callable[[], Domain]): Lambda function called to create a
+            multi-agent domain instance
+        singleagent_domain_class (Optional[Type[Domain]], optional): Class type of the single-agent
+            domain used to compute single agent heuristic estimates. Defaults to None.
+        singleagent_domain_factory (Optional[Callable[[Domain, Any], Domain]], optional): Lambda function
+            which takes as arguments the multi-agent domain and one agent, and that returns a domain
+            instance for this single agent; it is called to create the single-agent domain used
+            to compute single agent heuristic estimates. Defaults to None.
+        multiagent_solver_kwargs (_type_, optional): Optional arguments to be passed to the higher-level
+            multi-agent solver. Defaults to None.
+        singleagent_solver_kwargs (_type_, optional): Optional arguments to be passed to the lower-level
+            single-agent solver. Defaults to None.
+        callback: function called at each solver iteration. If returning true, the solve process stops.
+
+        !!! warning
+            One of `singleagent_domain_class` or `singleagent_domain_factory` must be not None, otherwise
+            a `ValueError` exception is raised.
+
+        """
+        Solver.__init__(self, domain_factory=multiagent_domain_factory)
+        self.callback = callback
+        if multiagent_solver_kwargs is None:
+            multiagent_solver_kwargs = {}
+        if "heuristic" in multiagent_solver_kwargs:
+            print(
+                "\x1b[3;33;40m"
+                + "Multi-agent solver heuristic will be overwritten by MAHD!"
+                + "\x1b[0m"
+            )
+        multiagent_solver_kwargs["heuristic"] = lambda d, o: self._multiagent_heuristic(
+            o
+        )
+        if ("domain_factory" not in multiagent_solver_kwargs) and (
+            "domain_factory"
+            in inspect.signature(multiagent_solver_class.__init__).parameters
+        ):
+            multiagent_solver_kwargs["domain_factory"] = multiagent_domain_factory
+        # add callback to multiagent solver
+        if "callback" in inspect.signature(multiagent_solver_class.__init__).parameters:
+            mahd_callback = MahdCallback(solver=self, callback=callback)
+            if "callback" in multiagent_solver_kwargs:
+                callbacks = [mahd_callback, multiagent_solver_kwargs["callback"]]
+                multiagent_solver_kwargs["callback"] = CallbackList(callbacks=callbacks)
+            else:
+                multiagent_solver_kwargs["callback"] = mahd_callback
+
+        self._multiagent_solver = multiagent_solver_class(**multiagent_solver_kwargs)
+        self._multiagent_domain_factory = multiagent_domain_factory
+        self._multiagent_domain = self._multiagent_domain_factory()
+
+        self._singleagent_solver_class = singleagent_solver_class
+        self._singleagent_solver_kwargs = singleagent_solver_kwargs
+        if singleagent_domain_factory is None:
+            if singleagent_domain_class is None:
+                raise ValueError(
+                    "singleagent_domain_factory and singleagent_domain_class cannot be None together."
+                )
+            else:
+                self._singleagent_domain_factory = (
+                    lambda multiagent_domain, agent: singleagent_domain_class()
+                )
+        else:
+            self._singleagent_domain_factory = singleagent_domain_factory
+
+        self._singleagent_domains = {}
+        self._singleagent_solvers = {}
+        if self._singleagent_solver_kwargs is None:
+            self._singleagent_solver_kwargs = {}
+
+        for a in self._multiagent_domain.get_agents():
+            singleagent_solver_kwargs = dict(self._singleagent_solver_kwargs)
+            singleagent_solver_kwargs[
+                "domain_factory"
+            ] = lambda: self._singleagent_domain_factory(self._multiagent_domain, a)
+            self._singleagent_solvers[a] = self._singleagent_solver_class(
+                **singleagent_solver_kwargs
+            )
+            self._singleagent_solvers[a]._init_solve(),
+
+        self._singleagent_solutions = {
+            a: {} for a in self._multiagent_domain.get_agents()
+        }
+
+    def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+        """Run the higher-level multi-agent heuristic solver from a given joint state
+
+        # Parameters
+        memory (D.T_memory[D.T_state]): Joint state from which to run the MAHD algorithm
+        """
+        self._multiagent_solver._solve_from(
+            memory=memory,
+        )
+
+    def _init_solve(self) -> None:
+        """Initializes the higher-level multi-agent solving process"""
+        self._multiagent_solver._init_solve()
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        """Gets the best computed joint action according to the higher-level heuristic
+            multi-agent solver in a given joint state.
+
+        # Parameters
+        observation (D.T_agent[D.T_observation]): Joint state for which the best action
+            is requested
+
+        # Returns
+        D.T_agent[D.T_concurrency[D.T_event]]: Best computed joint action
+        """
+        return self._multiagent_solver._get_next_action(observation)
+
+    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+        """Gets the best value in a given joint state according to the higher-level
+        heuristic multi-agent solver
+
+        # Parameters
+        observation (D.T_agent[D.T_observation]): Joint state from which the best value
+                is requested
+
+        # Returns
+        D.T_value: _description_
+        """
+        return self._multiagent_solver._get_utility(observation)
+
+    def _multiagent_heuristic(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> Tuple[D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]]]:
+        """Computes the multi-agent relaxed heuristics to be used by the higher-level
+            multi-agent solver as a pair of 2 dictionaries: one from single agents to
+            their individual heuristic estimates, and one from single agents to their
+            heuristic best actions in the given joint state
+
+        # Parameters
+        observation (D.T_agent[D.T_observation]): Joint state from which the relaxed
+            multi-agent heuristics are computed
+
+        !!! warning
+            Throws a `RuntimeError` exception if the single-agent solver cannot compute a
+            heuristic action for one of the agents and that no applicable action can be
+            then sampled for this agent
+
+        # Returns
+        Tuple[D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]]]:
+            Pair of 2 dictionaries: one from single agents to their individual
+            heuristic estimates, and one from single agents to their
+            heuristic best actions in the given joint state
+        """
+        h = {}
+        for a, s in self._singleagent_solvers.items():
+            if observation[a] not in self._singleagent_solutions[a]:
+                undefined_solution = False
+                s.solve_from(observation[a])
+                if hasattr(self._singleagent_solvers[a], "get_policy"):
+                    p = self._singleagent_solvers[a].get_policy()
+                    for ps, pav in p.items():
+                        self._singleagent_solutions[a][ps] = pav[::-1]
+                    undefined_solution = (
+                        observation[a] not in self._singleagent_solutions[a]
+                    )
+                else:
+                    if not s.is_solution_defined_for(observation[a]):
+                        undefined_solution = True
+                    else:
+                        self._singleagent_solutions[a][observation[a]] = (
+                            s.get_utility(observation[a]),
+                            s.get_next_action(observation[a]),
+                        )
+                if undefined_solution:
+                    is_terminal = (
+                        hasattr(self._get_singleagent_domain(a), "is_goal")
+                        and self._get_singleagent_domain(a).is_goal(observation[a])
+                    ) or (
+                        hasattr(self._get_singleagent_domain(a), "is_terminal")
+                        and self._get_singleagent_domain(a).is_terminal(observation[a])
+                    )
+                    if not is_terminal:
+                        print(
+                            "\x1b[3;33;40m"
+                            + "/!\ Solution not defined for agent {} in non terminal state {}".format(
+                                a, observation[a]
+                            )
+                            + ": Assigning default action! (is it a terminal state without no-op action?)"
+                            "\x1b[0m"
+                        )
+                    try:
+                        self._singleagent_solutions[a][observation[a]] = (
+                            Value(cost=0),
+                            self._get_singleagent_domain(a)
+                            .get_applicable_actions(observation[a])
+                            .sample(),
+                        )
+                    except Exception as err:
+                        terminal_str = "terminal " if is_terminal else ""
+                        raise RuntimeError(
+                            "Cannot sample applicable action "
+                            "for agent {} in {}state {} "
+                            "(original exception is: {})".format(
+                                a, terminal_str, observation[a], err
+                            )
+                        )
+        if issubclass(self._multiagent_solver.T_domain, SingleAgent):
+            h = (
+                Value(
+                    cost=sum(
+                        p[observation[a]][0].cost
+                        for a, p in self._singleagent_solutions.items()
+                    )
+                ),
+                {
+                    a: p[observation[a]][1]
+                    for a, p in self._singleagent_solutions.items()
+                },
+            )
+        else:
+            h = (
+                {
+                    a: Value(cost=p[observation[a]][0].cost)
+                    for a, p in self._singleagent_solutions.items()
+                },
+                {
+                    a: p[observation[a]][1]
+                    for a, p in self._singleagent_solutions.items()
+                },
+            )
+        return h
+
+    def _get_singleagent_domain(self, agent):
+        """Gets the single-agent domain of a given agent, potentially
+            building it from the single-agent domain factory given in the
+            MAHD instance's constructor if it has not been yet created for
+            this agent
+
+        # Parameters
+            agent (_type_): Agent for which the single-agent domain is requested
+
+        # Returns
+            _type_: Single-agent domain instance
+        """
+        if agent not in self._singleagent_domains:
+            self._singleagent_domains[agent] = self._singleagent_domain_factory(
+                self._multiagent_domain, agent
+            )
+        return self._singleagent_domains[agent]
+
+    def _initialize(self):
+        """Initializes the higher-level multi-agent solver and each lower-level
+        single-agent solver
+        """
+        self._multiagent_solver._initialize()
+        for a, s in self._singleagent_solvers.items():
+            s._initialize()
+
+    def _cleanup(self):
+        """Cleans up the higher-level multi-agent solver and each lower-level
+        single-agent solver
+        """
+        self._multiagent_solver._cleanup()
+        for a, s in self._singleagent_solvers.items():
+            s._cleanup()
+
+
+class MahdCallback:
+    def __init__(self, solver: MAHD, callback: Callable[[MAHD], bool]):
+        self.callback = callback
+        self.solver = solver
+
+    def __call__(self, solver: Solver, *args, **kwargs):
+        return self.callback(self.solver)
+
+
+class CallbackList:
+    def __init__(self, callbacks: List[Callable[[...], bool]]):
+        self.callbacks = callbacks
+
+    def __call__(self, *args, **kwargs):
+        stopping = False
+        for callback in self.callbacks:
+            stopping = stopping or callback(*args, **kwargs)
+        return stopping
```

## skdecide/hub/solver/martdp/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .martdp import MARTDP
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .martdp import MARTDP
```

## skdecide/hub/solver/martdp/martdp.py

```diff
@@ -1,203 +1,350 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import os
-import sys
-from typing import Callable, Dict, Optional, Tuple
-
-from skdecide import Domain, Solver, hub
-from skdecide.builders.domain import (
-    Actions,
-    FullyObservable,
-    Goals,
-    Markovian,
-    MultiAgent,
-    PositiveCosts,
-    Sequential,
-    Simulation,
-)
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
-from skdecide.core import Value
-
-record_sys_path = sys.path
-skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
-if skdecide_cpp_extension_lib_path not in sys.path:
-    sys.path.append(skdecide_cpp_extension_lib_path)
-
-try:
-
-    from __skdecide_hub_cpp import _MARTDPSolver_ as martdp_solver
-
-    # TODO: remove Markovian req?
-    class D(
-        Domain,
-        MultiAgent,
-        Sequential,
-        Simulation,
-        Actions,
-        Goals,
-        Markovian,
-        FullyObservable,
-        PositiveCosts,
-    ):
-        pass
-
-    class MARTDP(ParallelSolver, Solver, DeterministicPolicies, Utilities):
-        T_domain = D
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain] = None,
-            heuristic: Optional[
-                Callable[
-                    [Domain, D.T_state],
-                    Tuple[
-                        D.T_agent[Value[D.T_value]],
-                        D.T_agent[D.T_concurrency[D.T_event]],
-                    ],
-                ]
-            ] = None,
-            time_budget: int = 3600000,
-            rollout_budget: int = 100000,
-            max_depth: int = 1000,
-            max_feasibility_trials: int = 0,  # will then choose nb_agents if 0
-            graph_expansion_rate: float = 0.1,
-            epsilon_moving_average_window: int = 100,
-            epsilon: float = 0.0,  # not a stopping criterion by default
-            discount: float = 1.0,
-            action_choice_noise: float = 0.1,
-            dead_end_cost: float = 10000,
-            online_node_garbage: bool = False,
-            continuous_planning: bool = True,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-            watchdog: Callable[[int, int, float, float], bool] = None,
-        ) -> None:
-            ParallelSolver.__init__(
-                self,
-                domain_factory=domain_factory,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-            )
-            self._solver = None
-            if heuristic is None:
-                self._heuristic = lambda d, s: (
-                    {a: Value(cost=0) for a in s},
-                    {a: None for a in s},
-                )
-            else:
-                self._heuristic = heuristic
-            self._lambdas = [self._heuristic]
-            self._time_budget = time_budget
-            self._rollout_budget = rollout_budget
-            self._max_depth = max_depth
-            self._max_feasibility_trials = max_feasibility_trials
-            self._graph_expansion_rate = graph_expansion_rate
-            self._epsilon_moving_average_window = epsilon_moving_average_window
-            self._epsilon = epsilon
-            self._discount = discount
-            self._action_choice_noise = action_choice_noise
-            self._dead_end_cost = dead_end_cost
-            self._online_node_garbage = online_node_garbage
-            self._continuous_planning = continuous_planning
-            self._debug_logs = debug_logs
-            if watchdog is None:
-                self._watchdog = (
-                    lambda elapsed_time, number_rollouts, best_value, epsilon_moving_average: True
-                )
-            else:
-                self._watchdog = watchdog
-            self._ipc_notify = True
-
-        def close(self):
-            """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
-            """
-            if self._parallel:
-                self._solver.close()
-            ParallelSolver.close(self)
-
-        def _init_solve(self, domain_factory: Callable[[], Domain]) -> None:
-            self._domain_factory = domain_factory
-            self._solver = martdp_solver(
-                domain=self.get_domain(),
-                goal_checker=lambda d, s: d.is_goal(s),
-                heuristic=lambda d, s: self._heuristic(d, s)
-                if not self._parallel
-                else d.call(None, 0, s),
-                time_budget=self._time_budget,
-                rollout_budget=self._rollout_budget,
-                max_depth=self._max_depth,
-                max_feasibility_trials=self._max_feasibility_trials,
-                graph_expansion_rate=self._graph_expansion_rate,
-                epsilon_moving_average_window=self._epsilon_moving_average_window,
-                epsilon=self._epsilon,
-                discount=self._discount,
-                action_choice_noise=self._action_choice_noise,
-                dead_end_cost=self._dead_end_cost,
-                online_node_garbage=self._online_node_garbage,
-                parallel=self._parallel,
-                debug_logs=self._debug_logs,
-                watchdog=self._watchdog,
-            )
-            self._solver.clear()
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
-
-        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-            self._solver.solve(memory)
-
-        def _is_solution_defined_for(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> bool:
-            return self._solver.is_solution_defined_for(observation)
-
-        def _get_next_action(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if self._continuous_planning or not self._is_solution_defined_for(
-                observation
-            ):
-                self._solve_from(observation)
-            action = self._solver.get_next_action(observation)
-            if action is None:
-                print(
-                    "\x1b[3;33;40m"
-                    + "No best action found in observation "
-                    + str(observation)
-                    + ", applying random action"
-                    + "\x1b[0m"
-                )
-                return self.call_domain_method("get_action_space").sample()
-            else:
-                return action
-
-        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-            return self._solver.get_utility(observation)
-
-        def get_nb_of_explored_states(self) -> int:
-            return self._solver.get_nb_of_explored_states()
-
-        def get_nb_rollouts(self) -> int:
-            return self._solver.get_nb_rollouts()
-
-        def get_policy(
-            self,
-        ) -> Dict[
-            D.T_agent[D.T_observation],
-            Tuple[D.T_agent[D.T_concurrency[D.T_event]], float],
-        ]:
-            return self._solver.get_policy()
-
-except ImportError:
-    sys.path = record_sys_path
-    print(
-        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
-    )
-    raise
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import os
+import sys
+from typing import Callable, Dict, Optional, Tuple
+
+from skdecide import Domain, Solver, hub
+from skdecide.builders.domain import (
+    Actions,
+    FullyObservable,
+    Goals,
+    Markovian,
+    MultiAgent,
+    PositiveCosts,
+    Sequential,
+    Simulation,
+)
+from skdecide.builders.solver import DeterministicPolicies, FromAnyState, Utilities
+from skdecide.core import Value
+
+record_sys_path = sys.path
+skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
+if skdecide_cpp_extension_lib_path not in sys.path:
+    sys.path.append(skdecide_cpp_extension_lib_path)
+
+try:
+
+    from __skdecide_hub_cpp import _MARTDPSolver_ as martdp_solver
+
+    # TODO: remove Markovian req?
+    class D(
+        Domain,
+        MultiAgent,
+        Sequential,
+        Simulation,
+        Actions,
+        Goals,
+        Markovian,
+        FullyObservable,
+        PositiveCosts,
+    ):
+        pass
+
+    class MARTDP(Solver, DeterministicPolicies, Utilities, FromAnyState):
+        """This is an experimental implementation of a skdecide-specific
+        centralized multi-agent version of the RTDP algorithm ("Learning to act
+        using real-time dynamic programming" by Barto, Bradtke and Singh, AIJ 1995)
+        where the team's cost is the sum of individual costs and the joint applicable
+        actions in a given joint state are sampled to avoid a combinatorial explosion
+        of the joint action branching factor. This algorithm can (currently) only run
+        on a single CPU.
+        """
+
+        T_domain = D
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], T_domain],
+            heuristic: Optional[
+                Callable[
+                    [T_domain, D.T_state],
+                    Tuple[
+                        D.T_agent[Value[D.T_value]],
+                        D.T_agent[D.T_concurrency[D.T_event]],
+                    ],
+                ]
+            ] = lambda d, s: (
+                {a: Value(cost=0) for a in s},
+                {a: None for a in s},
+            ),
+            time_budget: int = 3600000,
+            rollout_budget: int = 100000,
+            max_depth: int = 1000,
+            max_feasibility_trials: int = 0,  # will then choose nb_agents if 0
+            graph_expansion_rate: float = 0.1,
+            residual_moving_average_window: int = 100,
+            epsilon: float = 0.0,  # not a stopping criterion by default
+            discount: float = 1.0,
+            action_choice_noise: float = 0.1,
+            dead_end_cost: float = 10000,
+            online_node_garbage: bool = False,
+            continuous_planning: bool = True,
+            callback: Callable[[MARTDP], bool] = lambda slv: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a MA-RTDP solver instance
+
+            # Parameters
+            domain_factory (Callable[[], T_domain], optional): The lambda function to create a domain instance.
+            heuristic (Optional[ Callable[ [T_domain, D.T_state], Tuple[ D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]], ], ] ], optional):
+                Lambda function taking as arguments the domain and a state, and returning a pair of
+                dictionary from agents to the individual heuristic estimates from the state to the goal,
+                and of dictionary from agents to best guess individual actions.
+                Defaults to lambda d, s: ({a: Value(cost=0) for a in s}, {a: None for a in s},).
+            time_budget (int, optional): Maximum solving time in milliseconds. Defaults to 3600000.
+            rollout_budget (int, optional): Maximum number of rollouts. Defaults to 100000.
+            max_depth (int, optional): Maximum depth of each MA-RTDP trial (rollout). Defaults to 1000.
+            max_feasibility_trials (int, optional): Number of trials for a given agent's applicable action
+                to insert it in the joint applicable action set by reshuffling the agents' actions
+                applicability ordering (set to the number of agents in the domain if it is equal to 0
+                in this constructor). Defaults to 0.
+            residual_moving_average_window (int, optional): Number of latest computed residual values
+                to memorize in order to compute the average Bellman error (residual) at the root state
+                of the search. Defaults to 100.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that a state
+                is solved, or to decide when no labels are used that the value function of the root state
+                of the search has converged (in the latter case: the root state's Bellman error is averaged
+                over the residual_moving_average_window). Defaults to 0.001.
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            action_choice_noise (float, optional): Bernoulli probability of choosing an agent's
+                random applicable action instead of the best current one when trying to
+                generate a feasible joint applicable action from another agent's viewpoint. Defaults to 0.1.
+            dead_end_cost (float, optional): Cost of a joint dead-end state (note that the
+                transition cost function which is independently decomposed over the agents
+                cannot easily model such joint dead-end state costs, which is why we allow
+                for setting this global dead-end cost in this constructor). Defaults to 10000.
+            online_node_garbage (bool, optional): Boolean indicating whether the search graph which is
+                no more reachable from the root solving state should be deleted (True) or not (False). Defaults to False.
+            continuous_planning (bool, optional): Boolean whether the solver should optimize again the policy
+                from the current solving state (True) or not (False) even if the policy is already defined
+                in this state. Defaults to True.
+            callback (Callable[[MARTDP], bool], optional): Function called at the end of each MA-RTDP trial,
+                taking as arguments the solver, and returning True if the solver must be stopped.
+                The `MARTDP.get_domain` method callable on the solver instance can be used to retrieve
+                the user domain. Defaults to (lambda slv: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be logged (True)
+                or not (False). Defaults to False.
+            """
+
+            Solver.__init__(self, domain_factory=domain_factory)
+            self._domain = self._domain_factory()
+            self._solver = None
+            self._heuristic = heuristic
+            self._time_budget = time_budget
+            self._rollout_budget = rollout_budget
+            self._max_depth = max_depth
+            self._max_feasibility_trials = max_feasibility_trials
+            self._graph_expansion_rate = graph_expansion_rate
+            self._residual_moving_average_window = residual_moving_average_window
+            self._epsilon = epsilon
+            self._discount = discount
+            self._action_choice_noise = action_choice_noise
+            self._dead_end_cost = dead_end_cost
+            self._online_node_garbage = online_node_garbage
+            self._continuous_planning = continuous_planning
+            self._callback = callback
+            self._verbose = verbose
+            self._ipc_notify = True
+
+        def _init_solve(self) -> None:
+            self._solver = martdp_solver(
+                solver=self,
+                domain=self.get_domain(),
+                goal_checker=lambda d, s: d.is_goal(s),
+                heuristic=lambda d, s: self._heuristic(d, s),
+                time_budget=self._time_budget,
+                rollout_budget=self._rollout_budget,
+                max_depth=self._max_depth,
+                max_feasibility_trials=self._max_feasibility_trials,
+                graph_expansion_rate=self._graph_expansion_rate,
+                residual_moving_average_window=self._residual_moving_average_window,
+                epsilon=self._epsilon,
+                discount=self._discount,
+                action_choice_noise=self._action_choice_noise,
+                dead_end_cost=self._dead_end_cost,
+                online_node_garbage=self._online_node_garbage,
+                callback=self._callback,
+                verbose=self._verbose,
+            )
+            self._solver.clear()
+
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
+
+        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the MA-RTDP algorithm from a given root solving joint state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): Joint state from which to run the MA-RTDP
+                algorithm (root of the search graph)
+            """
+            self._solver.solve(memory)
+
+        def _is_solution_defined_for(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> bool:
+            """Indicates whether the solution policy is defined for a given joint state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): Joint state for which an entry is
+                searched in the policy graph
+
+            # Returns
+            bool: True if the state has been explored and an action is defined in this state,
+                False otherwise
+            """
+            return self._solver.is_solution_defined_for(observation)
+
+        def _get_next_action(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed joint action in terms of best Q-value in a given joint state.
+                The search subgraph which is no more reachable after executing the returned action is
+                also deleted if node garbage was set to True in the MA-RTDP instance's constructor.
+                The solver is run from `observation` if `continuous_planning` was set to True
+                in the MA-RTDP instance's constructor or if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `MARTDP.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): Joint state for which the best action
+                is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed joint action
+            """
+            if self._continuous_planning or not self._is_solution_defined_for(
+                observation
+            ):
+                self._solve_from(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
+
+        def _get_utility(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[Value[D.T_value]]:
+            """Get the best Q-value in a given joint state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `MARTDP.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): Joint state from which the best Q-value
+                    is requested
+
+            # Returns
+            D.T_agent[Value[D.T_value]]: Maximum Q-value of the given joint state over the
+                applicable joint actions in this state
+            """
+            return self._solver.get_utility(observation)
+
+        def get_domain(self) -> T_domain:
+            """Get the domain used by the MARTDP solver
+
+            # Returns
+                T_domain: Domain instance created by the MARTDP solver
+            """
+            return self._domain
+
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph (which can be
+                lower than the number of actually explored states if node garbage was
+                set to True in the MA-RTDP instance's constructor)
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
+
+        def get_nb_rollouts(self) -> int:
+            """Get the number of rollouts since the beginning of the search from
+                the root solving state
+
+            # Returns
+            int: Number of rollouts (MA-RTDP trials)
+            """
+            return self._solver.get_nb_rollouts()
+
+        def get_state_nb_actions(self, observation: D.T_agent[D.T_observation]) -> int:
+            """Get the number of joint applicable actions generated so far in the
+                given joint state (throws a runtime error exception if the given state is
+                not present in the search graph, which can happen for instance when node
+                garbage is set to true in the MARTDP instance's constructor and the
+                non-reachable part of the search graph has been erased when calling the
+                MARTDPSolver::get_best_action method)
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): Joint state from which the
+                number of generated applicable actions is requested
+
+            # Returns
+            int: Number of generated applicable joint actions in the given state
+            """
+            return self._solver.get_state_nb_actions(observation)
+
+        def get_residual_moving_average(self) -> float:
+            """Get the average Bellman error (residual) at the root state of the search,
+                or an infinite value if the number of computed residuals is lower than
+                the epsilon moving average window set in the MARTDP instance's constructor
+
+            # Returns
+            float: Bellman error at the root state of the search averaged over
+                the epsilon moving average window
+            """
+            return self._solver.get_residual_moving_average()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
+        def get_policy(
+            self,
+        ) -> Dict[
+            D.T_agent[D.T_observation],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_agent[Value[D.T_value]]],
+        ]:
+            """Get the (partial) solution policy defined for the states for which
+                the Q-value has been updated at least once (which is optimal if the
+                algorithm has converged and labels are used)
+
+            !!! warning
+                Only defined over the states reachable from the last root solving state
+                when node garbage was set to True in the MA-RTDP instance's constructor
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_agent[Value[D.T_value]]], ]:
+                Mapping from joint states to pairs of joint action and best Q-value
+            """
+            return self._solver.get_policy()
+
+except ImportError:
+    sys.path = record_sys_path
+    print(
+        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
+    )
+    raise
```

## skdecide/hub/solver/maxent_irl/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .maxent_irl import MaxentIRL
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .maxent_irl import MaxentIRL
```

## skdecide/hub/solver/maxent_irl/maxent_irl.py

```diff
@@ -8,37 +8,58 @@
 from collections.abc import Iterable
 from typing import Callable
 
 import gymnasium as gym
 import numpy as np
 import pylab
 
-from skdecide import D, RLDomain, Solver
+from skdecide import D, Domain, RLDomain, Solver
 from skdecide.builders.solver import Policies, Restorable
 from skdecide.hub.solver.cgp import cgp
 
 
 class D(RLDomain):
     pass
 
 
-class MaxentIRL(Solver, Policies, Restorable):
+class MaxentIRL(Solver, Policies):
+    """Maximum Entropy Inverse Reinforcement Learning solver."""
+
     T_domain = D
 
     def __init__(
         self,
+        domain_factory: Callable[[], Domain],
         n_states=400,
         n_actions=3,
         one_feature=20,
         gamma=0.99,
         q_learning_rate=0.03,
         theta_learning_rate=0.05,
         n_epochs=20000,
         expert_trajectories="maxent_expert_demo.npy",
+        callback: Callable[[MaxentIRL], bool] = lambda solver: False,
     ) -> None:
+        """
+
+        # Parameters
+        domain_factory
+        n_states
+        n_actions
+        one_feature
+        gamma
+        q_learning_rate
+        theta_learning_rate
+        n_epochs
+        expert_trajectories
+        callback: function called at each solver epoch. If returning true, the solve process stops.
+
+        """
+        self.callback = callback
+        Solver.__init__(self, domain_factory=domain_factory)
         self.n_states = n_states
         self.feature_matrix = np.eye(self.n_states)
         self.n_actions = n_actions
         self.one_feature = one_feature
 
         self.q_table = np.zeros((n_states, n_actions))
         self.env = None
@@ -135,16 +156,16 @@
         index = 0
         for x in range(num_traj):
             for y in range(traj_length):
                 demonstrations[x][y][0] = index
                 demonstrations[x][y][1] = rawFile["actions"][index]
                 index += 1
 
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self.env = domain_factory()
+    def _solve(self) -> None:
+        self.env = self._domain_factory()
         if self.q_table is not None:
             return
         self.q_table = np.zeros((self.n_states, self.n_actions))
         # raw_demo2 = np.load(file=self.expert_trajectories)
         # if isinstance(raw_demo, np.lib.npyio.NpzFile):
 
         if not os.path.isfile(self.expert_trajectories):
@@ -223,14 +244,18 @@
                 pylab.plot(episodes, scores, "b")
                 pylab.savefig("./maxent.png")
                 np.save(
                     "./" + self.expert_trajectories[:-4] + "_maxent_q_table",
                     arr=self.q_table,
                 )
 
+            # Stopping because of user's callback?
+            if self.callback(self):
+                break
+
         self.q_table = np.load(
             file=self.expert_trajectories[:-4] + "_maxent_q_table.npy"
         )
 
     def _sample_action(
         self, observation: D.T_agent[D.T_observation]
     ) -> D.T_agent[D.T_concurrency[D.T_event]]:
@@ -245,13 +270,7 @@
 
     def _reset(self) -> None:
         self.state = self.env.reset()
         self.score = 0
 
     def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
         pass
-
-    def _save(self, path: str) -> None:
-        pass
-
-    def _load(self, path: str, domain_factory: Callable[[], D]) -> None:
-        pass
```

## skdecide/hub/solver/mcts/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .mcts import HMCTS, HUCT, MCTS, UCT
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .mcts import HMCTS, HUCT, MCTS, UCT
```

## skdecide/hub/solver/mcts/mcts.py

```diff
@@ -1,431 +1,879 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import os
-import random as rd
-import sys
-from math import sqrt
-from typing import Callable, Dict, List, Tuple
-
-from skdecide import Domain, Solver, hub
-from skdecide.builders.domain import (
-    Actions,
-    DeterministicInitialized,
-    Environment,
-    FullyObservable,
-    Markovian,
-    Rewards,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
-from skdecide.core import Value
-
-record_sys_path = sys.path
-skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
-if skdecide_cpp_extension_lib_path not in sys.path:
-    sys.path.append(skdecide_cpp_extension_lib_path)
-
-try:
-
-    from __skdecide_hub_cpp import _MCTSOptions_ as mcts_options
-    from __skdecide_hub_cpp import _MCTSSolver_ as mcts_solver
-
-    class D(
-        Domain,
-        SingleAgent,
-        Sequential,
-        Environment,
-        Actions,
-        DeterministicInitialized,
-        Markovian,
-        FullyObservable,
-        Rewards,
-    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
-        pass
-
-    class MCTS(ParallelSolver, Solver, DeterministicPolicies, Utilities):
-        T_domain = D
-
-        Options = mcts_options
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            time_budget: int = 3600000,
-            rollout_budget: int = 100000,
-            max_depth: int = 1000,
-            epsilon_moving_average_window: int = 100,
-            epsilon: float = 0.0,  # not a stopping criterion by default
-            discount: float = 1.0,
-            uct_mode: bool = True,
-            ucb_constant: float = 1.0 / sqrt(2.0),
-            online_node_garbage: bool = False,
-            custom_policy: Callable[
-                [Domain, D.T_agent[D.T_observation]],
-                D.T_agent[D.T_concurrency[D.T_event]],
-            ] = None,
-            heuristic: Callable[
-                [Domain, D.T_agent[D.T_observation]],
-                Tuple[D.T_agent[Value[D.T_value]], int],
-            ] = None,
-            state_expansion_rate: float = 0.1,
-            action_expansion_rate: float = 0.1,
-            transition_mode: Options.TransitionMode = Options.TransitionMode.Distribution,
-            tree_policy: Options.TreePolicy = Options.TreePolicy.Default,
-            expander: Options.Expander = Options.Expander.Full,
-            action_selector_optimization: Options.ActionSelector = Options.ActionSelector.UCB1,
-            action_selector_execution: Options.ActionSelector = Options.ActionSelector.BestQValue,
-            rollout_policy: Options.RolloutPolicy = Options.RolloutPolicy.Random,
-            back_propagator: Options.BackPropagator = Options.BackPropagator.Graph,
-            continuous_planning: bool = True,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-            watchdog: Callable[[int, int, float, float], bool] = None,
-        ) -> None:
-            ParallelSolver.__init__(
-                self,
-                domain_factory=domain_factory,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-            )
-            self._solver = None
-            self._domain = None
-            self._time_budget = time_budget
-            self._rollout_budget = rollout_budget
-            self._max_depth = max_depth
-            self._epsilon_moving_average_window = epsilon_moving_average_window
-            self._epsilon = epsilon
-            self._discount = discount
-            self._uct_mode = uct_mode
-            self._ucb_constant = ucb_constant
-            self._online_node_garbage = online_node_garbage
-            self._custom_policy = custom_policy
-            self._heuristic = heuristic
-            self._state_expansion_rate = state_expansion_rate
-            self._action_expansion_rate = action_expansion_rate
-            self._transition_mode = transition_mode
-            self._tree_policy = tree_policy
-            self._expander = expander
-            self._action_selector_optimization = action_selector_optimization
-            self._action_selector_execution = action_selector_execution
-            self._rollout_policy = rollout_policy
-            self._back_propagator = back_propagator
-            self._continuous_planning = continuous_planning
-            self._debug_logs = debug_logs
-            self._watchdog = watchdog
-            self._lambdas = [self._custom_policy, self._heuristic]
-            self._ipc_notify = True
-
-        def close(self):
-            """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
-            """
-            if self._parallel:
-                self._solver.close()
-            ParallelSolver.close(self)
-
-        def _init_solve(self, domain_factory: Callable[[], D]) -> None:
-            self._domain_factory = domain_factory
-            self._solver = mcts_solver(
-                domain=self.get_domain(),
-                time_budget=self._time_budget,
-                rollout_budget=self._rollout_budget,
-                max_depth=self._max_depth,
-                epsilon_moving_average_window=self._epsilon_moving_average_window,
-                epsilon=self._epsilon,
-                discount=self._discount,
-                uct_mode=self._uct_mode,
-                ucb_constant=self._ucb_constant,
-                online_node_garbage=self._online_node_garbage,
-                custom_policy=None
-                if self._custom_policy is None
-                else lambda d, s, i=None: self._custom_policy(d, s)
-                if not self._parallel
-                else d.call(i, 0, s),
-                heuristic=None
-                if self._heuristic is None
-                else lambda d, s, i=None: self._heuristic(d, s)
-                if not self._parallel
-                else d.call(i, 1, s),
-                state_expansion_rate=self._state_expansion_rate,
-                action_expansion_rate=self._action_expansion_rate,
-                transition_mode=self._transition_mode,
-                tree_policy=self._tree_policy,
-                expander=self._expander,
-                action_selector_optimization=self._action_selector_optimization,
-                action_selector_execution=self._action_selector_execution,
-                rollout_policy=self._rollout_policy,
-                back_propagator=self._back_propagator,
-                parallel=self._parallel,
-                debug_logs=self._debug_logs,
-                watchdog=self._watchdog
-                if self._watchdog is not None
-                else lambda elapsed_time, number_rollouts, best_value, epsilon_moving_average: True,
-            )
-            self._solver.clear()
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
-
-        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-            self._solver.solve(memory)
-
-        def _is_solution_defined_for(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> bool:
-            return self._solver.is_solution_defined_for(observation)
-
-        def _get_next_action(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if self._continuous_planning or not self._is_solution_defined_for(
-                observation
-            ):
-                self._solve_from(observation)
-            action = self._solver.get_next_action(observation)
-            if action is None:
-                print(
-                    "\x1b[3;33;40m"
-                    + "No best action found in observation "
-                    + str(observation)
-                    + ", applying random action"
-                    + "\x1b[0m"
-                )
-                return self.call_domain_method("get_action_space").sample()
-            else:
-                return action
-
-        def _reset(self) -> None:
-            self._solver.clear()
-
-        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-            return self._solver.get_utility(observation)
-
-        def get_nb_of_explored_states(self) -> int:
-            return self._solver.get_nb_of_explored_states()
-
-        def get_nb_rollouts(self) -> int:
-            return self._solver.get_nb_rollouts()
-
-        def get_policy(
-            self,
-        ) -> Dict[
-            D.T_agent[D.T_observation],
-            Tuple[D.T_agent[D.T_concurrency[D.T_event]], float],
-        ]:
-            return self._solver.get_policy()
-
-        def get_action_prefix(self) -> List[D.T_agent[D.T_observation]]:
-            return self._solver.get_action_prefix()
-
-    class HMCTS(MCTS):
-        Options = MCTS.Options
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            time_budget: int = 3600000,
-            rollout_budget: int = 100000,
-            max_depth: int = 1000,
-            epsilon_moving_average_window: int = 100,
-            epsilon: float = 0.0,  # not a stopping criterion by default
-            discount: float = 1.0,
-            ucb_constant: float = 1.0 / sqrt(2.0),
-            online_node_garbage: bool = False,
-            heuristic: Callable[
-                [Domain, D.T_state],
-                Tuple[
-                    D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]]
-                ],
-            ] = None,
-            heuristic_confidence: int = 1000,
-            action_choice_noise: float = 0.1,
-            state_expansion_rate: float = 0.1,
-            action_expansion_rate: float = 0.1,
-            transition_mode: Options.TransitionMode = Options.TransitionMode.Distribution,
-            tree_policy: Options.TreePolicy = Options.TreePolicy.Default,
-            expander: Options.Expander = Options.Expander.Full,
-            action_selector_optimization: Options.ActionSelector = Options.ActionSelector.UCB1,
-            action_selector_execution: Options.ActionSelector = Options.ActionSelector.BestQValue,
-            back_propagator: Options.BackPropagator = Options.BackPropagator.Graph,
-            continuous_planning: bool = True,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-            watchdog: Callable[[int, int, float, float], bool] = None,
-        ):
-            super().__init__(
-                domain_factory=domain_factory,
-                time_budget=time_budget,
-                rollout_budget=rollout_budget,
-                max_depth=max_depth,
-                epsilon_moving_average_window=epsilon_moving_average_window,
-                epsilon=epsilon,
-                discount=discount,
-                uct_mode=False,  # otherwise would select random policy rollouts!
-                ucb_constant=ucb_constant,
-                online_node_garbage=online_node_garbage,
-                heuristic=lambda d, o: self._value_heuristic(d, o),
-                custom_policy=lambda d, o: self._policy_heuristic(d, o),
-                state_expansion_rate=state_expansion_rate,
-                action_expansion_rate=action_expansion_rate,
-                transition_mode=transition_mode,
-                tree_policy=tree_policy,
-                expander=expander,
-                action_selector_optimization=action_selector_optimization,
-                action_selector_execution=action_selector_execution,
-                rollout_policy=MCTS.Options.RolloutPolicy.Custom,
-                back_propagator=back_propagator,
-                continuous_planning=continuous_planning,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-                debug_logs=debug_logs,
-                watchdog=watchdog,
-            )
-            self._compound_heuristic = heuristic
-            self._heuristic_confidence = heuristic_confidence
-            self._action_choice_noise = action_choice_noise
-            self._heuristic_records = {}
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            super()._solve_domain(domain_factory=domain_factory)
-            self._heuristic_records = {}
-
-        def _value_heuristic(
-            self, domain: Domain, observation: D.T_agent[D.T_observation]
-        ) -> Tuple[D.T_agent[Value[D.T_value]], int]:
-            if observation not in self._heuristic_records:
-                self._heuristic_records[observation] = self._compound_heuristic(
-                    domain, observation
-                )
-            return (self._heuristic_records[observation][0], self._heuristic_confidence)
-
-        def _policy_heuristic(
-            self, domain: Domain, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if observation not in self._heuristic_records:
-                self._heuristic_records[observation] = self._compound_heuristic(
-                    domain, observation
-                )
-            if rd.random() > self._action_choice_noise:
-                return self._heuristic_records[observation][1]
-            else:
-                return domain.get_applicable_actions(observation).sample()
-
-    class UCT(MCTS):
-        Options = MCTS.Options
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            time_budget: int = 3600000,
-            rollout_budget: int = 100000,
-            max_depth: int = 1000,
-            epsilon_moving_average_window: int = 100,
-            epsilon: float = 0.0,  # not a stopping criterion by default
-            discount: float = 1.0,
-            ucb_constant: float = 1.0 / sqrt(2.0),
-            online_node_garbage: float = False,
-            custom_policy: Callable[
-                [Domain, D.T_agent[D.T_observation]],
-                D.T_agent[D.T_concurrency[D.T_event]],
-            ] = None,
-            heuristic: Callable[
-                [Domain, D.T_agent[D.T_observation]],
-                Tuple[D.T_agent[Value[D.T_value]], int],
-            ] = None,
-            transition_mode: Options.TransitionMode = Options.TransitionMode.Distribution,
-            rollout_policy: Options.RolloutPolicy = Options.RolloutPolicy.Random,
-            continuous_planning: bool = True,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-            watchdog: Callable[[int, int, float, float], bool] = None,
-        ) -> None:
-            super().__init__(
-                domain_factory=domain_factory,
-                time_budget=time_budget,
-                rollout_budget=rollout_budget,
-                max_depth=max_depth,
-                epsilon_moving_average_window=epsilon_moving_average_window,
-                epsilon=epsilon,
-                discount=discount,
-                uct_mode=True,
-                ucb_constant=ucb_constant,
-                online_node_garbage=online_node_garbage,
-                custom_policy=custom_policy,
-                heuristic=heuristic,
-                transition_mode=transition_mode,
-                rollout_policy=rollout_policy,
-                continuous_planning=continuous_planning,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-                debug_logs=debug_logs,
-                watchdog=watchdog,
-            )
-
-    class HUCT(HMCTS):
-        Options = HMCTS.Options
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            time_budget: int = 3600000,
-            rollout_budget: int = 100000,
-            max_depth: int = 1000,
-            epsilon_moving_average_window: int = 100,
-            epsilon: float = 0.0,  # not a stopping criterion by default
-            discount: float = 1.0,
-            ucb_constant: float = 1.0 / sqrt(2.0),
-            online_node_garbage: float = False,
-            heuristic: Callable[
-                [Domain, D.T_state],
-                Tuple[
-                    D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]]
-                ],
-            ] = None,
-            heuristic_confidence: int = 1000,
-            action_choice_noise: float = 0.1,
-            transition_mode: Options.TransitionMode = Options.TransitionMode.Distribution,
-            rollout_policy: Options.RolloutPolicy = Options.RolloutPolicy.Random,
-            continuous_planning: bool = True,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-            watchdog: Callable[[int, int, float, float], bool] = None,
-        ) -> None:
-            super().__init__(
-                domain_factory=domain_factory,
-                time_budget=time_budget,
-                rollout_budget=rollout_budget,
-                max_depth=max_depth,
-                epsilon_moving_average_window=epsilon_moving_average_window,
-                epsilon=epsilon,
-                discount=discount,
-                uct_mode=False,  # otherwise would select random policy rollouts!
-                ucb_constant=ucb_constant,
-                online_node_garbage=online_node_garbage,
-                heuristic=heuristic,
-                heuristic_confidence=heuristic_confidence,
-                action_choice_noise=action_choice_noise,
-                transition_mode=transition_mode,
-                rollout_policy=rollout_policy,
-                continuous_planning=continuous_planning,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-                debug_logs=debug_logs,
-                watchdog=watchdog,
-            )
-
-except ImportError:
-    sys.path = record_sys_path
-    print(
-        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
-    )
-    raise
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import os
+import random as rd
+import sys
+from enum import Enum
+from math import sqrt
+from typing import Callable, Dict, List, Optional, Tuple
+
+from skdecide import Domain, Solver, hub
+from skdecide.builders.domain import (
+    Actions,
+    DeterministicInitialized,
+    Environment,
+    FullyObservable,
+    Markovian,
+    Rewards,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
+from skdecide.core import Value
+
+record_sys_path = sys.path
+skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
+if skdecide_cpp_extension_lib_path not in sys.path:
+    sys.path.append(skdecide_cpp_extension_lib_path)
+
+try:
+
+    from __skdecide_hub_cpp import _MCTSOptions_ as mcts_options
+    from __skdecide_hub_cpp import _MCTSSolver_ as mcts_solver
+
+    class D(
+        Domain,
+        SingleAgent,
+        Sequential,
+        Environment,
+        Actions,
+        DeterministicInitialized,
+        Markovian,
+        FullyObservable,
+        Rewards,
+    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
+        pass
+
+    class MCTS(ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState):
+        """This is the skdecide implementation of MCTS and UCT from
+        "A Survey of Monte Carlo Tree Search Methods" by Browne et al
+        (IEEE Transactions on Computational Intelligence  and AI in games,
+        2012). We additionally implement a heuristic value estimate as in
+        "Monte-Carlo tree search and rapid action value estimation in
+        computer Go" by Gelly and Silver (Artificial Intelligence, 2011)
+        except that the heuristic estimate is called on states but not
+        on state-action pairs to be more in line with heuristic search
+        algorithms in the literature and other implementations of
+        heuristic search algorithms in skdecide.
+        """
+
+        T_domain = D
+
+        class TransitionMode(Enum):
+            STEP = mcts_options.TransitionMode.Step
+            SAMPLE = mcts_options.TransitionMode.Sample
+            DISTRIBUTION = mcts_options.TransitionMode.Distribution
+
+        class TreePolicy(Enum):
+            DEFAULT = mcts_options.TreePolicy.Default
+
+        class Expander(Enum):
+            FULL = mcts_options.Expander.Full
+            PARTIAL = mcts_options.Expander.Partial
+
+        class ActionSelector(Enum):
+            UCB1 = mcts_options.ActionSelector.UCB1
+            BEST_Q_VALUE = mcts_options.ActionSelector.BestQValue
+
+        class RolloutPolicy(Enum):
+            RANDOM = mcts_options.RolloutPolicy.Random
+            CUSTOM = mcts_options.RolloutPolicy.Custom
+            VOID = mcts_options.RolloutPolicy.Void
+
+        class BackPropagator(Enum):
+            GRAPH = mcts_options.BackPropagator.Graph
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], T_domain],
+            time_budget: int = 3600000,
+            rollout_budget: int = 100000,
+            max_depth: int = 1000,
+            residual_moving_average_window: int = 100,
+            epsilon: float = 0.0,  # not a stopping criterion by default
+            discount: float = 1.0,
+            ucb_constant: float = 1.0 / sqrt(2.0),
+            online_node_garbage: bool = False,
+            custom_policy: Callable[
+                [T_domain, D.T_agent[D.T_observation]],
+                D.T_agent[D.T_concurrency[D.T_event]],
+            ] = None,
+            heuristic: Callable[
+                [T_domain, D.T_agent[D.T_observation]],
+                Tuple[D.T_agent[Value[D.T_value]], int],
+            ] = None,
+            state_expansion_rate: float = 0.1,
+            action_expansion_rate: float = 0.1,
+            transition_mode: TransitionMode = TransitionMode.DISTRIBUTION,
+            tree_policy: TreePolicy = TreePolicy.DEFAULT,
+            expander: Expander = Expander.FULL,
+            action_selector_optimization: ActionSelector = ActionSelector.UCB1,
+            action_selector_execution: ActionSelector = ActionSelector.BEST_Q_VALUE,
+            rollout_policy: RolloutPolicy = RolloutPolicy.RANDOM,
+            back_propagator: BackPropagator = BackPropagator.GRAPH,
+            continuous_planning: bool = True,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[[MCTS, Optional[int]], bool] = lambda slv, i=None: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a MCTS solver instance
+
+            # Parameters
+            domain_factory (Callable[[], T_domain]): The lambda function to create a domain instance.
+            time_budget (int, optional): Maximum solving time in milliseconds. Defaults to 3600000.
+            rollout_budget (int, optional): Maximum number of rollouts. Defaults to 100000.
+            max_depth (int, optional): Maximum depth of each MCTS rollout. Defaults to 1000.
+            residual_moving_average_window (int, optional): Number of latest computed residual values
+                to memorize in order to compute the average Bellman error (residual) at the root state
+                of the search. Defaults to 100.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that a state
+                is solved, or to decide when no labels are used that the value function of the root state
+                of the search has converged (in the latter case: the root state's Bellman error is averaged
+                over the residual_moving_average_window). Defaults to 0.0.
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            ucb_constant (float, optional): UCB constant as used in the UCT algorithm when the action selector
+                (for optimization or execution) is `MCTS.ActionSelector.UCB1`. Defaults to 1.0/sqrt(2.0).
+            online_node_garbage (bool, optional): Boolean indicating whether the search graph which is
+                no more reachable from the root solving state should be deleted (True) or not (False). Defaults to False.
+            custom_policy (Callable[ [T_domain, D.T_agent[D.T_observation]], D.T_agent[D.T_concurrency[D.T_event]], ], optional):
+                Custom policy function to use in the rollout policy from non-expanded state nodes when the rollout policy is
+                `MCTS.RolloutPolicy.CUSTOM`. Defaults to None (no custom policy in use).
+            heuristic (Callable[ [T_domain, D.T_agent[D.T_observation]], Tuple[D.T_agent[Value[D.T_value]], int], ], optional):
+                Optional Heuristic function to initialize non-expanded state nodes (returns a pair of value estimate and
+                fake number of visit counts). Defaults to None (no heuristic in use).
+            state_expansion_rate (float, optional): Value $rs$ used when the expander is `MCTS.Expander.PARTIAL`
+                such that the probability of discovering new applicable actions in a given state node with already $na$ discovered
+                applicable actions is equal to $e^{-rs \cdot na}$. Defaults to 0.1.
+            action_expansion_rate (float, optional):  Value $ra$ used when the expander is `MCTS.Expander.PARTIAL`
+                such that the probability of discovering new state outcomes in a given action node with already $ns$ discovered
+                state outcomes is equal to $e^{-ra \cdot ns}$. Defaults to 0.1.
+            transition_mode (MCTS.TransitionMode, optional): Transition mode enum (one of `MCTS.TransitionMode.STEP`,
+                `MCTS.TransitionMode.SAMPLE` or `MCTS.TransitionMode.DISTRIBUTION` to progress the
+                trajectories with, respectively, the 'step' or 'sample' or 'get_next_state_distribution' method of the domain
+                depending on the domain's dynamics capabilities). Defaults to `MCTS.TransitionMode.DISTRIBUTION`.
+            tree_policy (MCTS.TreePolicy, optional): Tree policy enum (currently only
+                `MCTS.TreePolicy.DEFAULT` which rollouts a random trajectory from the current root
+                solving state until reaching a non-expanded state node of the tree). Defaults to `MCTS.TreePolicy.DEFAULT`.
+            expander (MCTS.Expander, optional): Expander enum used when a state needs to be
+                expanded (one of `MCTS.Expander.FULL` if applicable actions and next states should be
+                all enumerated for each transition function, or `MCTS.Expander.PARTIAL` if they should
+                be sampled with a probability which exponentially decreases as the number of already discovered
+                applicable actions and next states increases). Defaults to `MCTS.Expander.FULL`.
+            action_selector_optimization (MCTS.ActionSelector, optional): Action selector class used to
+                select actions in the tree policy's trajectory simulations (one of
+                `MCTS.ActionSelector.UCB1` to select the action based on the UCB criterion, or
+                `MCTS.ActionSelector.BEST_Q_VALUE` to select the action with maximum Q-Value in the
+                current state node). Defaults to `MCTS.ActionSelector.UCB1`.
+            action_selector_execution (MCTS.ActionSelector, optional): Action selector class used to
+                select actions at execution time when the 'get_best_action' method of the
+                solver is invoked in a given execution state (one of
+                `MCTS.ActionSelector.UCB1` to select the action based on the UCB criterion, or
+                `MCTS.ActionSelector.BEST_Q_VALUE` to select the action with maximum Q-Value in the
+                current state node). Defaults to `MCTS.ActionSelector.BEST_Q_VALUE`.
+            rollout_policy (MCTS.RolloutPolicy, optional): Rollout policy enum (one of
+                `MCTS.RolloutPolicy.RANDOM` to simulate trajectories starting in a non-expanded state
+                node of the tree by sampling random applicable actions in each visited state, or
+                `MCTS.RolloutPolicy.CUSTOM` to simulate them by applying actions from the given policy
+                'custom_policy' given to this constructor, or `MCTS.RolloutPolicy.VOID` to deactivate
+                the simulation of trajectories from non-expanded state nodes, in which latter case it is advised to
+                provide the 'heuristic' function in this constructor to initialize non-expanded state nodes' values).
+                Defaults to `MCTS.RolloutPolicy.RANDOM`.
+            back_propagator (MCTS.BackPropagator, optional): Back propagator enum (currently only
+                `MCTS.BackPropagator.GRAPH` which back-propagates empirical Q-values from non-expanded
+                state nodes up to the root node of the tree along the tree policy's sampled
+                trajectories). Defaults to `MCTS.BackPropagator.GRAPH`.
+            continuous_planning (bool, optional): Boolean whether the solver should optimize again the policy
+                from the current solving state (True) or not (False) even if the policy is already defined
+                in this state. Defaults to True.
+            parallel (bool, optional): Parallelize MCTS rollouts on different processes using duplicated domains (True)
+                or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[MCTS, Optional[int]], optional): Function called at the end of each RIW rollout,
+                taking as arguments the solver and the thread/process ID (i.e. parallel domain ID, which is equal to None
+                in case of sequential execution, i.e. when 'parallel' is set to False in this constructor) from
+                which the callback is called, and returning True if the solver must be stopped. The callback lambda
+                function cannot take the (potentially parallelized) domain as argument because we could not otherwise
+                serialize (i.e. pickle) the solver to pass it to the corresponding parallel domain process in case of parallel
+                execution. Nevertheless, the `ParallelSolver.get_domain` method callable on the solver instance
+                can be used to retrieve either the user domain in sequential execution, or the parallel domains proxy
+                `ParallelDomain` in parallel execution from which domain methods can be called by using the
+                callback's process ID argument. Defaults to (lambda slv, i=None: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be logged (True)
+                or not (False). Defaults to False.
+            """
+            ParallelSolver.__init__(
+                self,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+            )
+            Solver.__init__(self, domain_factory=domain_factory)
+            self._solver = None
+            self._domain = None
+            self._time_budget = time_budget
+            self._rollout_budget = rollout_budget
+            self._max_depth = max_depth
+            self._residual_moving_average_window = residual_moving_average_window
+            self._epsilon = epsilon
+            self._discount = discount
+            self._ucb_constant = ucb_constant
+            self._online_node_garbage = online_node_garbage
+            self._custom_policy = custom_policy
+            self._heuristic = heuristic
+            self._state_expansion_rate = state_expansion_rate
+            self._action_expansion_rate = action_expansion_rate
+            self._transition_mode = transition_mode
+            self._tree_policy = tree_policy
+            self._expander = expander
+            self._action_selector_optimization = action_selector_optimization
+            self._action_selector_execution = action_selector_execution
+            self._rollout_policy = rollout_policy
+            self._back_propagator = back_propagator
+            self._continuous_planning = continuous_planning
+            self._callback = callback
+            self._verbose = verbose
+            self._lambdas = [self._custom_policy, self._heuristic]
+            self._ipc_notify = True
+
+        def close(self):
+            """Joins the parallel domains' processes.
+            Not calling this method (or not using the 'with' context statement)
+            results in the solver forever waiting for the domain processes to exit.
+            """
+            if self._parallel:
+                self._solver.close()
+            ParallelSolver.close(self)
+
+        def _init_solve(self) -> None:
+            self._solver = mcts_solver(
+                solver=self,
+                domain=self.get_domain(),
+                time_budget=self._time_budget,
+                rollout_budget=self._rollout_budget,
+                max_depth=self._max_depth,
+                residual_moving_average_window=self._residual_moving_average_window,
+                epsilon=self._epsilon,
+                discount=self._discount,
+                ucb_constant=self._ucb_constant,
+                online_node_garbage=self._online_node_garbage,
+                custom_policy=(
+                    None
+                    if self._custom_policy is None
+                    else (
+                        (lambda d, s, i=None: self._custom_policy(d, s))
+                        if not self._parallel
+                        else (lambda d, s, i=None: d.call(i, 0, s))
+                    )
+                ),
+                heuristic=(
+                    None
+                    if self._heuristic is None
+                    else (
+                        (lambda d, s, i=None: self._heuristic(d, s))
+                        if not self._parallel
+                        else (lambda d, s, i=None: d.call(i, 1, s))
+                    )
+                ),
+                state_expansion_rate=self._state_expansion_rate,
+                action_expansion_rate=self._action_expansion_rate,
+                transition_mode=self._transition_mode.value,
+                tree_policy=self._tree_policy.value,
+                expander=self._expander.value,
+                action_selector_optimization=self._action_selector_optimization.value,
+                action_selector_execution=self._action_selector_execution.value,
+                rollout_policy=self._rollout_policy.value,
+                back_propagator=self._back_propagator.value,
+                parallel=self._parallel,
+                callback=self._callback,
+                verbose=self._verbose,
+            )
+            self._solver.clear()
+
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
+
+        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the MCTS algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): Root state of the search grph from which
+                MCTS rollouts are launched
+            """
+            self._solver.solve(memory)
+
+        def _is_solution_defined_for(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> bool:
+            """Indicates whether the solution policy is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if the state has been explored and an action can be obtained
+                from the execution action selector, False otherwise
+            """
+            return self._solver.is_solution_defined_for(observation)
+
+        def _get_next_action(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best action to execute in a given state according to the execution action selector.
+                The search subgraph which is no more reachable after executing the returned action is
+                also deleted if node garbage was set to True in the MCTS instance's constructor.
+                The solver is run from `observation` if `continuous_planning` was set to True
+                in the MCTS instance's constructor or if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `MCTS.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best action to execute according to the
+                execution action selector
+            """
+            if self._continuous_planning or not self._is_solution_defined_for(
+                observation
+            ):
+                self._solve_from(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
+
+        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the best value in a given state according to the execution action selector
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `MCTS.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the best value is requested
+
+            # Returns
+            D.T_value: Value of the action returned by the execution action selector
+            """
+            return self._solver.get_utility(observation)
+
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph (which can be
+                lower than the number of actually explored states if node garbage was
+                set to True in the MCTS instance's constructor)
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
+
+        def get_nb_rollouts(self) -> int:
+            """Get the number of rollouts since the beginning of the search from
+                the root solving state
+
+            # Returns
+                int: Number of MCTS rollouts
+            """
+            return self._solver.get_nb_rollouts()
+
+        def get_residual_moving_average(self) -> float:
+            """Get the average Bellman error (residual) at the root state of the search,
+                or an infinite value if the number of computed residuals is lower than
+                the epsilon moving average window set in the MCTS instance's constructor
+
+            # Returns
+            float: Bellman error at the root state of the search averaged over
+                the epsilon moving average window
+            """
+            return self._solver.get_residual_moving_average()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
+        def get_policy(
+            self,
+        ) -> Dict[
+            D.T_agent[D.T_observation],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], float],
+        ]:
+            """Get the (partial) solution policy defined for the states for which
+                the best value according to the execution action selector has been updated
+                at least once (which is optimal if the algorithm has converged and labels are used)
+
+            !!! warning
+                Only defined over the states reachable from the last root solving state
+                when node garbage was set to True in the MCTS instance's constructor
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], float], ]:
+                Mapping from states to pairs of action and best value according to the
+                execution action selector
+            """
+            return self._solver.get_policy()
+
+        def get_action_prefix(self) -> List[D.T_agent[D.T_observation]]:
+            """Get the list of actions returned by the solver so far after each
+                call to the `MCTS.get_next_action` method (mostly internal use in order
+                to rebuild the sequence of visited states until reaching the current
+                solving state, when using `MCTS.TransitionMode.STEP` for which we can
+                only progress the transition function with steps that hide the current
+                state of the domain)
+
+            # Returns
+            List[D.T_agent[D.T_observation]]: List of actions executed by the solver
+                so far after each call to the `MCTS.get_next_action` method
+            """
+            return self._solver.get_action_prefix()
+
+    class HMCTS(MCTS):
+        """MCTS solver to use with the multi-agent hierarchical `MAHD` solver
+        as the multi-agent compound solver"""
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], MCTS.T_domain],
+            time_budget: int = 3600000,
+            rollout_budget: int = 100000,
+            max_depth: int = 1000,
+            residual_moving_average_window: int = 100,
+            epsilon: float = 0.0,  # not a stopping criterion by default
+            discount: float = 1.0,
+            ucb_constant: float = 1.0 / sqrt(2.0),
+            online_node_garbage: bool = False,
+            heuristic: Callable[
+                [MCTS.T_domain, D.T_state],
+                Tuple[
+                    D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]]
+                ],
+            ] = None,
+            heuristic_confidence: int = 1000,
+            action_choice_noise: float = 0.1,
+            state_expansion_rate: float = 0.1,
+            action_expansion_rate: float = 0.1,
+            transition_mode: MCTS.TransitionMode = MCTS.TransitionMode.DISTRIBUTION,
+            tree_policy: MCTS.TreePolicy = MCTS.TreePolicy.DEFAULT,
+            expander: MCTS.Expander = MCTS.Expander.FULL,
+            action_selector_optimization: MCTS.ActionSelector = MCTS.ActionSelector.UCB1,
+            action_selector_execution: MCTS.ActionSelector = MCTS.ActionSelector.BEST_Q_VALUE,
+            back_propagator: MCTS.BackPropagator = MCTS.BackPropagator.GRAPH,
+            continuous_planning: bool = True,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[
+                [HMCTS, Optional[int]], bool
+            ] = lambda slv, i=None: False,
+            verbose: bool = False,
+        ):
+            """Construct a HMCTS solver instance
+
+            # Parameters
+            domain_factory (Callable[[], MCTS.T_domain]): The lambda function to create a domain instance.
+            time_budget (int, optional): Maximum solving time in milliseconds. Defaults to 3600000.
+            rollout_budget (int, optional): Maximum number of rollouts. Defaults to 100000.
+            max_depth (int, optional): Maximum depth of each MCTS rollout. Defaults to 1000.
+            residual_moving_average_window (int, optional): Number of latest computed residual values
+                to memorize in order to compute the average Bellman error (residual) at the root state
+                of the search. Defaults to 100.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that a state
+                is solved, or to decide when no labels are used that the value function of the root state
+                of the search has converged (in the latter case: the root state's Bellman error is averaged
+                over the residual_moving_average_window). Defaults to 0.0.
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            ucb_constant (float, optional): UCB constant as used in the UCT algorithm when the action selector
+                (for optimization or execution) is `MCTS.ActionSelector.UCB1`. Defaults to 1.0/sqrt(2.0).
+            online_node_garbage (bool, optional): Boolean indicating whether the search graph which is
+                no more reachable from the root solving state should be deleted (True) or not (False). Defaults to False.
+            heuristic (Callable[ [MCTS.T_domain, D.T_state], Tuple[ D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]] ], ], optional):
+                Multi-agent compound heuristic as returned by the `MAHD` algorithm from independent
+                agent heuristic contributions. Defaults to None (no heuristic in use).
+            heuristic_confidence (int, optional): Fake state node visits set on non-expanded state nodes for which the
+                multi-agent compound heuristic is computed by `MAHD`. Defaults to 1000.
+            action_choice_noise (float, optional): Probability used to sample random actions instead of executing the
+                compound heuristic actions returned by the `MAHD` algorithm. Defaults to 0.1.
+            state_expansion_rate (float, optional): Value $rs$ used when the expander is `MCTS.Expander.PARTIAL`
+                such that the probability of discovering new applicable actions in a given state node with already $na$ discovered
+                applicable actions is equal to $e^{-rs \cdot na}$. Defaults to 0.1.
+            action_expansion_rate (float, optional):  Value $ra$ used when the expander is `MCTS.Expander.PARTIAL`
+                such that the probability of discovering new state outcomes in a given action node with already $ns$ discovered
+                state outcomes is equal to $e^{-ra \cdot ns}$. Defaults to 0.1.
+            transition_mode (MCTS.TransitionMode, optional): Transition mode enum (one of `MCTS.TransitionMode.STEP`,
+                `MCTS.TransitionMode.SAMPLE` or `MCTS.TransitionMode.DISTRIBUTION` to progress the
+                trajectories with, respectively, the 'step' or 'sample' or 'get_next_state_distribution' method of the domain
+                depending on the domain's dynamics capabilities). Defaults to `MCTS.TransitionMode.DISTRIBUTION`.
+            tree_policy (MCTS.TreePolicy, optional): Tree policy enum (currently only
+                `MCTS.TreePolicy.DEFAULT` which rollouts a random trajectory from the current root
+                solving state until reaching a non-expanded state node of the tree). Defaults to `MCTS.TreePolicy.DEFAULT`.
+            expander (MCTS.Expander, optional): Expander enum used when a state needs to be
+                expanded (one of `MCTS.Expander.FULL` if applicable actions and next states should be
+                all enumerated for each transition function, or `MCTS.Expander.PARTIAL` if they should
+                be sampled with a probability which exponentially decreases as the number of already discovered
+                applicable actions and next states increases). Defaults to `MCTS.Expander.FULL`.
+            action_selector_optimization (MCTS.ActionSelector, optional): Action selector class used to
+                select actions in the tree policy's trajectory simulations (one of
+                `MCTS.ActionSelector.UCB1` to select the action based on the UCB criterion, or
+                `MCTS.ActionSelector.BEST_Q_VALUE` to select the action with maximum Q-Value in the
+                current state node). Defaults to `MCTS.ActionSelector.UCB1`.
+            action_selector_execution (MCTS.ActionSelector, optional): Action selector class used to
+                select actions at execution time when the 'get_best_action' method of the
+                solver is invoked in a given execution state (one of
+                `MCTS.ActionSelector.UCB1` to select the action based on the UCB criterion, or
+                `MCTS.ActionSelector.BEST_Q_VALUE` to select the action with maximum Q-Value in the
+                current state node). Defaults to `MCTS.ActionSelector.BEST_Q_VALUE`.
+            back_propagator (MCTS.BackPropagator, optional): Back propagator enum (currently only
+                `MCTS.BackPropagator.GRAPH` which back-propagates empirical Q-values from non-expanded
+                state nodes up to the root node of the tree along the tree policy's sampled
+                trajectories). Defaults to `MCTS.BackPropagator.GRAPH`.
+            continuous_planning (bool, optional): Boolean whether the solver should optimize again the policy
+                from the current solving state (True) or not (False) even if the policy is already defined
+                in this state. Defaults to True.
+            parallel (bool, optional): Parallelize MCTS rollouts on different processes using duplicated domains (True)
+                or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[HMCTS, Optional[int]], optional): Function called at the end of each MCTS rollout,
+                taking as arguments the solver and the thread/process ID (i.e. parallel domain ID, which is equal to None
+                in case of sequential execution, i.e. when 'parallel' is set to False in this constructor) from
+                which the callback is called, and returning True if the solver must be stopped. The callback lambda
+                function cannot take the (potentially parallelized) domain as argument because we could not otherwise
+                serialize (i.e. pickle) the solver to pass it to the corresponding parallel domain process in case of parallel
+                execution. Nevertheless, the `ParallelSolver.get_domain` method callable on the solver instance
+                can be used to retrieve either the user domain in sequential execution, or the parallel domains proxy
+                `ParallelDomain` in parallel execution from which domain methods can be called by using the
+                callback's process ID argument. Defaults to (lambda slv, i=None: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be logged (True)
+                or not (False). Defaults to False.
+            """
+            super().__init__(
+                domain_factory=domain_factory,
+                time_budget=time_budget,
+                rollout_budget=rollout_budget,
+                max_depth=max_depth,
+                residual_moving_average_window=residual_moving_average_window,
+                epsilon=epsilon,
+                discount=discount,
+                ucb_constant=ucb_constant,
+                online_node_garbage=online_node_garbage,
+                heuristic=lambda d, o: self._value_heuristic(d, o),
+                custom_policy=lambda d, o: self._policy_heuristic(d, o),
+                state_expansion_rate=state_expansion_rate,
+                action_expansion_rate=action_expansion_rate,
+                transition_mode=transition_mode,
+                tree_policy=tree_policy,
+                expander=expander,
+                action_selector_optimization=action_selector_optimization,
+                action_selector_execution=action_selector_execution,
+                rollout_policy=MCTS.RolloutPolicy.CUSTOM,
+                back_propagator=back_propagator,
+                continuous_planning=continuous_planning,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+                callback=callback,
+                verbose=verbose,
+            )
+            self._compound_heuristic = heuristic
+            self._heuristic_confidence = heuristic_confidence
+            self._action_choice_noise = action_choice_noise
+            self._heuristic_records = {}
+
+        def _init_solve(self) -> None:
+            super()._init_solve()
+            self._heuristic_records = {}
+
+        def _value_heuristic(
+            self, domain: MCTS.T_domain, observation: D.T_agent[D.T_observation]
+        ) -> Tuple[D.T_agent[Value[D.T_value]], int]:
+            """Reconstitutes the MCTS heuristic used to initialize the value of non-expanded
+                state nodes from the multi-agent compound heuristic computed by the
+                `MAHD` algorithm
+
+            # Parameters
+            domain (MCTS.T_domain): The domain instance
+            observation (D.T_agent[D.T_observation]): The non-expanded state node from which
+                the heuristic must be computed
+
+            # Returns
+            Tuple[D.T_agent[Value[D.T_value]], int]: MCTS heuristic value at the given state
+            """
+            if observation not in self._heuristic_records:
+                self._heuristic_records[observation] = self._compound_heuristic(
+                    domain, observation
+                )
+            return (self._heuristic_records[observation][0], self._heuristic_confidence)
+
+        def _policy_heuristic(
+            self, domain: MCTS.T_domain, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Reconstitutes the MCTS custom rollout executed starting in non-expanded
+                state nodes from the multi-agent compound heuristic computed by the
+                `MAHD` algorithm
+
+            # Parameters
+            domain (MCTS.T_domain): The domain instance
+            observation (D.T_agent[D.T_observation]): The non-expanded state node from which
+                the custom rollout policy must be run
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Rollout action to execute in the given state
+            """
+            if observation not in self._heuristic_records:
+                self._heuristic_records[observation] = self._compound_heuristic(
+                    domain, observation
+                )
+            if rd.random() > self._action_choice_noise:
+                return self._heuristic_records[observation][1]
+            else:
+                return domain.get_applicable_actions(observation).sample()
+
+    class UCT(MCTS):
+        """UCT as described in the paper " Bandit Based Monte-Carlo Planning" by
+        Levente Kocsis and Csaba Szepesvari (ECML 2006) is a famous variant of MCTS
+        with some specific options including the famous UCB1 action selector to perform tree exploration
+        """
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], MCTS.T_domain],
+            time_budget: int = 3600000,
+            rollout_budget: int = 100000,
+            max_depth: int = 1000,
+            residual_moving_average_window: int = 100,
+            epsilon: float = 0.0,  # not a stopping criterion by default
+            discount: float = 1.0,
+            ucb_constant: float = 1.0 / sqrt(2.0),
+            online_node_garbage: float = False,
+            custom_policy: Callable[
+                [MCTS.T_domain, D.T_agent[D.T_observation]],
+                D.T_agent[D.T_concurrency[D.T_event]],
+            ] = None,
+            heuristic: Callable[
+                [MCTS.T_domain, D.T_agent[D.T_observation]],
+                Tuple[D.T_agent[Value[D.T_value]], int],
+            ] = None,
+            transition_mode: MCTS.TransitionMode = MCTS.TransitionMode.DISTRIBUTION,
+            rollout_policy: MCTS.RolloutPolicy = MCTS.RolloutPolicy.RANDOM,
+            continuous_planning: bool = True,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[[UCT, Optional[int]], bool] = lambda slv, i=None: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a UCT solver instance
+
+            # Parameters
+            domain_factory (Callable[[], MCTS.T_domain]): The lambda function to create a domain instance.
+            time_budget (int, optional): Maximum solving time in milliseconds. Defaults to 3600000.
+            rollout_budget (int, optional): Maximum number of rollouts. Defaults to 100000.
+            max_depth (int, optional): Maximum depth of each UCT rollout. Defaults to 1000.
+            residual_moving_average_window (int, optional): Number of latest computed residual values
+                to memorize in order to compute the average Bellman error (residual) at the root state
+                of the search. Defaults to 100.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that a state
+                is solved, or to decide when no labels are used that the value function of the root state
+                of the search has converged (in the latter case: the root state's Bellman error is averaged
+                over the residual_moving_average_window). Defaults to 0.0.
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            ucb_constant (float, optional): UCB constant as used in the UCT algorithm when the action selector
+                (for optimization or execution) is `MCTS.ActionSelector.UCB1`. Defaults to 1.0/sqrt(2.0).
+            online_node_garbage (bool, optional): Boolean indicating whether the search graph which is
+                no more reachable from the root solving state should be deleted (True) or not (False). Defaults to False.
+            custom_policy (Callable[ [MCTS.T_domain, D.T_agent[D.T_observation]], D.T_agent[D.T_concurrency[D.T_event]], ], optional):
+                Custom policy function to use in the rollout policy from non-expanded state nodes when the rollout policy is
+                `MCTS.RolloutPolicy.CUSTOM`. Defaults to None (no custom policy in use).
+            heuristic (Callable[ [MCTS.T_domain, D.T_agent[D.T_observation]], Tuple[D.T_agent[Value[D.T_value]], int], ], optional):
+                Optional Heuristic function to initialize non-expanded state nodes (returns a pair of value estimate and
+                fake number of visit counts). Defaults to None (no heuristic in use).
+            transition_mode (MCTS.TransitionMode, optional): Transition mode enum (one of `MCTS.TransitionMode.STEP`,
+                `MCTS.TransitionMode.SAMPLE` or `MCTS.TransitionMode.DISTRIBUTION` to progress the
+                trajectories with, respectively, the 'step' or 'sample' or 'get_next_state_distribution' method of the domain
+                depending on the domain's dynamics capabilities). Defaults to `MCTS.TransitionMode.DISTRIBUTION`.
+            rollout_policy (MCTS.RolloutPolicy, optional): Rollout policy enum (one of
+                :`MCTS.RolloutPolicy.RANDOM` to simulate trajectories starting in a non-expanded state
+                node of the tree by sampling random applicable actions in each visited state, or
+                `MCTS.RolloutPolicy.CUSTOM` to simulate them by applying actions from the given policy
+                'custom_policy' given to this constructor, or `MCTS.RolloutPolicy.VOID` to deactivate
+                the simulation of trajectories from non-expanded state nodes, in which latter case it is advised to
+                provide the 'heuristic' function in this constructor to initialize non-expanded state nodes' values).
+                Defaults to :`MCTS.RolloutPolicy.RANDOM`.
+            continuous_planning (bool, optional): Boolean whether the solver should optimize again the policy
+                from the current solving state (True) or not (False) even if the policy is already defined
+                in this state. Defaults to True.
+            parallel (bool, optional): Parallelize MCTS rollouts on different processes using duplicated domains (True)
+                or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[UCT, Optional[int]], optional): Function called at the end of each RIW rollout,
+                taking as arguments the solver and the thread/process ID (i.e. parallel domain ID, which is equal to None
+                in case of sequential execution, i.e. when 'parallel' is set to False in this constructor) from
+                which the callback is called, and returning True if the solver must be stopped. The callback lambda
+                function cannot take the (potentially parallelized) domain as argument because we could not otherwise
+                serialize (i.e. pickle) the solver to pass it to the corresponding parallel domain process in case of parallel
+                execution. Nevertheless, the `ParallelSolver.get_domain` method callable on the solver instance
+                can be used to retrieve either the user domain in sequential execution, or the parallel domains proxy
+                `ParallelDomain` in parallel execution from which domain methods can be called by using the
+                callback's process ID argument. Defaults to (lambda slv, i=None: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be logged (True)
+                or not (False). Defaults to False.
+            """
+            super().__init__(
+                domain_factory=domain_factory,
+                time_budget=time_budget,
+                rollout_budget=rollout_budget,
+                max_depth=max_depth,
+                residual_moving_average_window=residual_moving_average_window,
+                epsilon=epsilon,
+                discount=discount,
+                ucb_constant=ucb_constant,
+                online_node_garbage=online_node_garbage,
+                custom_policy=custom_policy,
+                heuristic=heuristic,
+                transition_mode=transition_mode,
+                tree_policy=MCTS.TreePolicy.DEFAULT,
+                expander=MCTS.Expander.FULL,
+                action_selector_optimization=MCTS.ActionSelector.UCB1,
+                action_selector_execution=MCTS.ActionSelector.BEST_Q_VALUE,
+                rollout_policy=rollout_policy,
+                back_propagator=MCTS.BackPropagator.GRAPH,
+                continuous_planning=continuous_planning,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+                callback=callback,
+                verbose=verbose,
+            )
+
+    class HUCT(HMCTS):
+        """UCT solver to use with the multi-agent hierarchical `MAHD` solver
+        as the multi-agent compound solver"""
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], MCTS.T_domain],
+            time_budget: int = 3600000,
+            rollout_budget: int = 100000,
+            max_depth: int = 1000,
+            residual_moving_average_window: int = 100,
+            epsilon: float = 0.0,  # not a stopping criterion by default
+            discount: float = 1.0,
+            ucb_constant: float = 1.0 / sqrt(2.0),
+            online_node_garbage: float = False,
+            heuristic: Callable[
+                [MCTS.T_domain, D.T_state],
+                Tuple[
+                    D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]]
+                ],
+            ] = None,
+            heuristic_confidence: int = 1000,
+            action_choice_noise: float = 0.1,
+            transition_mode: MCTS.TransitionMode = MCTS.TransitionMode.DISTRIBUTION,
+            continuous_planning: bool = True,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[[HUCT, Optional[int]], bool] = lambda slv, i=None: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a HUCT solver instance
+
+            # Parameters
+            domain_factory (Callable[[], MCTS.T_domain]): The lambda function to create a domain instance.
+            time_budget (int, optional): Maximum solving time in milliseconds. Defaults to 3600000.
+            rollout_budget (int, optional): Maximum number of rollouts. Defaults to 100000.
+            max_depth (int, optional): Maximum depth of each UCT rollout. Defaults to 1000.
+            residual_moving_average_window (int, optional): Number of latest computed residual values
+                to memorize in order to compute the average Bellman error (residual) at the root state
+                of the search. Defaults to 100.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that a state
+                is solved, or to decide when no labels are used that the value function of the root state
+                of the search has converged (in the latter case: the root state's Bellman error is averaged
+                over the residual_moving_average_window). Defaults to 0.0.
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            ucb_constant (float, optional): UCB constant as used in the UCT algorithm when the action selector
+                (for optimization or execution) is `MCTS.ActionSelector.UCB1`. Defaults to 1.0/sqrt(2.0).
+            online_node_garbage (bool, optional): Boolean indicating whether the search graph which is
+                no more reachable from the root solving state should be deleted (True) or not (False). Defaults to False.
+            heuristic (Callable[ [MCTS.T_domain, D.T_state], Tuple[ D.T_agent[Value[D.T_value]], D.T_agent[D.T_concurrency[D.T_event]] ], ], optional):
+                Multi-agent compound heuristic as returned by the `MAHD` algorithm from independent
+                agent heuristic contributions. Defaults to None (no heuristic in use).
+            heuristic_confidence (int, optional): Fake state node visits set on non-expanded state nodes for which the
+                multi-agent compound heuristic is computed by `MAHD`. Defaults to 1000.
+            action_choice_noise (float, optional): Probability used to sample random actions instead of executing the
+                compound heuristic actions returned by the `MAHD` algorithm. Defaults to 0.1.
+            transition_mode (MCTS.TransitionMode, optional): Transition mode enum (one of `MCTS.TransitionMode.STEP`,
+                `MCTS.TransitionMode.SAMPLE` or `MCTS.TransitionMode.DISTRIBUTION` to progress the
+                trajectories with, respectively, the 'step' or 'sample' or 'get_next_state_distribution' method of the domain
+                depending on the domain's dynamics capabilities). Defaults to `MCTS.TransitionMode.DISTRIBUTION`.
+            continuous_planning (bool, optional): Boolean whether the solver should optimize again the policy
+                from the current solving state (True) or not (False) even if the policy is already defined
+                in this state. Defaults to True.
+            parallel (bool, optional): Parallelize MCTS rollouts on different processes using duplicated domains (True)
+                or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[HUCT, Optional[int]], optional): Function called at the end of each RIW rollout,
+                taking as arguments the solver and the thread/process ID (i.e. parallel domain ID, which is equal to None
+                in case of sequential execution, i.e. when 'parallel' is set to False in this constructor) from
+                which the callback is called, and returning True if the solver must be stopped. The callback lambda
+                function cannot take the (potentially parallelized) domain as argument because we could not otherwise
+                serialize (i.e. pickle) the solver to pass it to the corresponding parallel domain process in case of parallel
+                execution. Nevertheless, the `ParallelSolver.get_domain` method callable on the solver instance
+                can be used to retrieve either the user domain in sequential execution, or the parallel domains proxy
+                `ParallelDomain` in parallel execution from which domain methods can be called by using the
+                callback's process ID argument. Defaults to (lambda slv, i=None: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be logged (True)
+                or not (False). Defaults to False.
+            """
+            super().__init__(
+                domain_factory=domain_factory,
+                time_budget=time_budget,
+                rollout_budget=rollout_budget,
+                max_depth=max_depth,
+                residual_moving_average_window=residual_moving_average_window,
+                epsilon=epsilon,
+                discount=discount,
+                ucb_constant=ucb_constant,
+                online_node_garbage=online_node_garbage,
+                heuristic=heuristic,
+                heuristic_confidence=heuristic_confidence,
+                action_choice_noise=action_choice_noise,
+                transition_mode=transition_mode,
+                tree_policy=MCTS.TreePolicy.DEFAULT,
+                expander=MCTS.Expander.FULL,
+                action_selector_optimization=MCTS.ActionSelector.UCB1,
+                action_selector_execution=MCTS.ActionSelector.BEST_Q_VALUE,
+                back_propagator=MCTS.BackPropagator.GRAPH,
+                continuous_planning=continuous_planning,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+                callback=callback,
+                verbose=verbose,
+            )
+
+except ImportError:
+    sys.path = record_sys_path
+    print(
+        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
+    )
+    raise
```

## skdecide/hub/solver/pomcp/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .pomcp import POMCP
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .pomcp import POMCP
```

## skdecide/hub/solver/pomcp/pomcp.py

```diff
@@ -1,253 +1,277 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-# Original code by Patrik Haslum, based on POMCP from:
-# Silver, D., & Veness, J. (2010). Monte-Carlo Planning in Large POMDPs.
-# In Advances in neural information processing systems (pp. 21642172).
-from __future__ import annotations
-
-import math
-import random
-from typing import Callable
-
-from skdecide import DiscreteDistribution, Domain, Memory, Solver
-from skdecide.builders.domain import (
-    Actions,
-    EnumerableTransitions,
-    Goals,
-    Sequential,
-    SingleAgent,
-    UncertainInitialized,
-)
-from skdecide.builders.solver import DeterministicPolicies
-
-
-class D(
-    Domain,
-    SingleAgent,
-    Sequential,
-    EnumerableTransitions,
-    Actions,
-    Goals,
-    UncertainInitialized,
-):
-    pass
-
-
-class POMCP(Solver, DeterministicPolicies):
-    T_domain = D
-
-    def __init__(self, max_iterations=5000, max_depth=50, n_samples=5000) -> None:
-        self._max_iterations = max_iterations
-        self._max_depth = max_depth
-        self._n_samples = n_samples
-
-    def _reset(self) -> None:
-        # Reset whatever is needed on this solver before running a new episode
-        self._obs_history = tuple()
-        self._act_history = (None,)
-        self._belief = self._initial_belief
-        self._tree = dict()
-        # VLV is the Very Large Value; this is supposed to be a value that
-        # represents "infinite" cost (i.e., goal not reached within depth
-        # bound). The approximation 2 * max_depth is ok if all actions have
-        # cost 1. In general, there seems to be no way to query the domain
-        # for the range of possible cost values.
-        self._VLV = 100 * self._max_depth
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self._domain = domain_factory()
-        self._initial_belief = []
-        d = self._domain.get_initial_state_distribution()
-        for _ in range(self._n_samples):
-            self._initial_belief.append(d.sample())
-        # No further solving code required here since everything is computed online
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        # Get the next action from the solver's current policy:
-        # this corresponds to the top-level Search procedure in the POMCP paper
-
-        # Since we have now received a new observation, update our
-        # belief state with this information; note that obs may
-        # depend on the last action taken:
-        self._belief = self._filter_belief_state(
-            self._belief, self._act_history[-1], observation
-        )
-
-        # Record the added observation:
-        self._obs_history = self._obs_history + (observation,)
-
-        # Then, update each state in the filtered belief with the
-        # effects of the last action taken:
-        self._belief = self._update_belief_state(self._belief, self._act_history[-1])
-
-        # Now, we can make a decision from the new belief state:
-        iterations = 0
-        while iterations < self._max_iterations:  # or some other cut-off
-            # sample a state from the current belief
-            state = random.choice(self._belief)
-            self._tree_search(state, self._act_history, self._obs_history, 0)
-            iterations += 1
-
-        # Select the best action from the successors of the current node:
-        action = self._get_best_action(self._act_history, self._obs_history)
-
-        # Record the last action, and then return it:
-        self._act_history = self._act_history + (action,)
-
-        return action
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
-
-    def _filter_belief_state(self, belief, action, obs):
-        prob = [0] * len(belief)
-        for i, state in enumerate(belief):
-            d = self._domain.get_observation_distribution(state, action)
-            prob[i] = get_probability(d, obs)
-        new_belief = random.choices(belief, weights=prob, k=len(belief))
-        return new_belief
-
-    def _update_belief_state(self, belief, action):
-        new_belief = []
-        for state in belief:
-            d = (
-                self._domain.get_next_state_distribution(Memory([state]), action)
-                if action is not None
-                else self._domain.get_initial_state_distribution()
-            )
-            new_state = d.sample()
-            new_belief.append(new_state)
-        return new_belief
-
-    def _get_best_action(self, h_act, h_obs, w=0):
-        """Retrieve best action at (h_act, h_obs) from stored tree.
-
-        If w > 0, best is determined using the UCT formula with weight w;
-        else it's just the action with min expected cost.
-        """
-        best_action = None
-        best_action_score = self._VLV
-        if w > 0:
-            parent = self._tree[(h_act, h_obs)]
-        for action in self._domain.get_action_space().get_elements():
-            key = (h_act + (action,), h_obs)
-            if key in self._tree:
-                node = self._tree[key]
-                # node[0] is visit count (N); node[1] is average cost (V)
-                if w > 0:
-                    if node[0] == 0:
-                        score = -self._VLV
-                    else:
-                        score = node[1] - (w * math.sqrt(math.log(parent[0]) / node[0]))
-                else:
-                    score = node[1]
-                if score <= best_action_score:
-                    best_action = action
-                    best_action_score = score
-        return best_action
-
-    def _tree_search(self, state, h_act, h_obs, depth):
-        """UCT search from a given state with act/obs history.
-
-        This corresponds to the Simulate function in the POMCP paper.
-        """
-        # This must be a history that ends on an observation
-        assert len(h_act) == len(h_obs)
-        if depth > self._max_depth:
-            return self._VLV
-        if (h_act, h_obs) not in self._tree:
-            # generate new child nodes
-            for action in self._domain.get_applicable_actions(
-                Memory([state])
-            ).get_elements():
-                assert action is not None
-                self._tree[(h_act + (action,), h_obs)] = [0, 0, []]
-            # but we must also store this node, or we'll never get out of this case!
-            cost = self._rollout(state, h_act, h_obs, depth)
-            self._tree[(h_act, h_obs)] = [1, cost, [state]]
-            return cost
-        else:
-            # pick a successor node according to the UCT formula
-            action = self._get_best_action(h_act, h_obs, w=self._max_depth)
-            assert action is not None
-            # simulate outcome of this action:
-            new_state = self._domain.get_next_state_distribution(
-                Memory([state]), action
-            ).sample()
-            TV = self._domain.get_transition_value(Memory([state]), action, new_state)
-            new_obs = self._domain.get_observation_distribution(state, action).sample()
-            if self._domain.is_goal(new_obs):
-                s_cost = TV.cost
-            else:
-                s_cost = TV.cost + self._tree_search(
-                    new_state, h_act + (action,), h_obs + (new_obs,), depth + 1
-                )
-                s_cost = min(s_cost, self._VLV)
-            this_node = self._tree[(h_act, h_obs)]
-            succ_node = self._tree[(h_act + (action,), h_obs)]
-            # update average cost for succ node:
-            succ_node[1] = ((succ_node[1] * succ_node[0]) + s_cost) / (succ_node[0] + 1)
-            # increment visit counters for both this node and succ node:
-            this_node[0] = this_node[0] + 1
-            succ_node[0] = succ_node[0] + 1
-            return s_cost
-
-    def _rollout(self, state, h_act, h_obs, depth):
-        if depth > self._max_depth:
-            return self._VLV
-        action = self._get_random_action(state, h_act, h_obs, depth)
-        assert action is not None
-        new_state = self._domain.get_next_state_distribution(
-            Memory([state]), action
-        ).sample()
-        TV = self._domain.get_transition_value(Memory([state]), action, new_state)
-        new_obs = self._domain.get_observation_distribution(state, action).sample()
-        if self._domain.is_goal(new_obs):
-            s_cost = TV.cost
-        else:
-            s_cost = TV.cost + self._rollout(
-                new_state, h_act + (action,), h_obs + (new_obs,), depth + 1
-            )
-            s_cost = min(s_cost, self._VLV)
-        return s_cost
-
-    def _get_random_action(self, state, h_act, h_obs, depth):
-        sel = self._domain.get_applicable_actions(Memory([state])).sample()
-        return sel
-
-
-def get_probability(distribution, element, n=100):
-    """Utility function to get the probability of a specific element from a scikit-decide distribution
-    (based on sampling if this distribution is not a DiscreteDistribution)."""
-
-    # Avoid "dumb" sampling if the distribution is a DiscreteDistribution:
-    if isinstance(distribution, DiscreteDistribution):
-        return next((p for e, p in distribution.get_values() if e == element), 0.0)
-    else:
-        p = 0
-        for i in range(n):
-            x = distribution.sample()
-            if x == element:
-                p += 1
-        return p / n
-
-
-if __name__ == "__main__":
-    from skdecide.hub.domain.mastermind import MasterMind
-    from skdecide.utils import rollout
-
-    domain_factory = lambda: MasterMind(3, 3)
-    domain = domain_factory()
-    if POMCP.check_domain(domain):
-        solver = MasterMind.solve_with(POMCP, domain_factory)
-        rollout(
-            domain,
-            solver,
-            num_episodes=5,
-            max_steps=1000,
-            outcome_formatter=lambda o: f"{o.observation} - cost: {o.value.cost:.2f}",
-        )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+# Original code by Patrik Haslum, based on POMCP from:
+# Silver, D., & Veness, J. (2010). Monte-Carlo Planning in Large POMDPs.
+# In Advances in neural information processing systems (pp. 21642172).
+from __future__ import annotations
+
+import math
+import random
+from typing import Callable
+
+from skdecide import DiscreteDistribution, Domain, Memory, Solver
+from skdecide.builders.domain import (
+    Actions,
+    EnumerableTransitions,
+    Goals,
+    Sequential,
+    SingleAgent,
+    UncertainInitialized,
+)
+from skdecide.builders.solver import DeterministicPolicies
+
+
+class D(
+    Domain,
+    SingleAgent,
+    Sequential,
+    EnumerableTransitions,
+    Actions,
+    Goals,
+    UncertainInitialized,
+):
+    pass
+
+
+class POMCP(Solver, DeterministicPolicies):
+    """Partially-Observable Monte Carlo Planning solver."""
+
+    T_domain = D
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        max_iterations=5000,
+        max_depth=50,
+        n_samples=5000,
+        callback: Callable[[POMCP], bool] = lambda solver: False,
+    ) -> None:
+        """
+
+        # Parameters
+        domain_factory
+        max_iterations
+        max_depth
+        n_samples
+        callback: function called at each solver iteration. If returning true, the solve process stops.
+
+        """
+        self.callback = callback
+        Solver.__init__(self, domain_factory=domain_factory)
+        self._max_iterations = max_iterations
+        self._max_depth = max_depth
+        self._n_samples = n_samples
+
+    def _reset(self) -> None:
+        # Reset whatever is needed on this solver before running a new episode
+        self._obs_history = tuple()
+        self._act_history = (None,)
+        self._belief = self._initial_belief
+        self._tree = dict()
+        # VLV is the Very Large Value; this is supposed to be a value that
+        # represents "infinite" cost (i.e., goal not reached within depth
+        # bound). The approximation 2 * max_depth is ok if all actions have
+        # cost 1. In general, there seems to be no way to query the domain
+        # for the range of possible cost values.
+        self._VLV = 100 * self._max_depth
+
+    def _solve(self) -> None:
+        self._domain = self._domain_factory()
+        self._initial_belief = []
+        d = self._domain.get_initial_state_distribution()
+        for _ in range(self._n_samples):
+            self._initial_belief.append(d.sample())
+        # No further solving code required here since everything is computed online
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        # Get the next action from the solver's current policy:
+        # this corresponds to the top-level Search procedure in the POMCP paper
+
+        # Since we have now received a new observation, update our
+        # belief state with this information; note that obs may
+        # depend on the last action taken:
+        self._belief = self._filter_belief_state(
+            self._belief, self._act_history[-1], observation
+        )
+
+        # Record the added observation:
+        self._obs_history = self._obs_history + (observation,)
+
+        # Then, update each state in the filtered belief with the
+        # effects of the last action taken:
+        self._belief = self._update_belief_state(self._belief, self._act_history[-1])
+
+        # Now, we can make a decision from the new belief state:
+        iterations = 0
+        while iterations < self._max_iterations and not self.callback(
+            self
+        ):  # or some other cut-off
+            # sample a state from the current belief
+            state = random.choice(self._belief)
+            self._tree_search(state, self._act_history, self._obs_history, 0)
+            iterations += 1
+
+        # Select the best action from the successors of the current node:
+        action = self._get_best_action(self._act_history, self._obs_history)
+
+        # Record the last action, and then return it:
+        self._act_history = self._act_history + (action,)
+
+        return action
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
+
+    def _filter_belief_state(self, belief, action, obs):
+        prob = [0] * len(belief)
+        for i, state in enumerate(belief):
+            d = self._domain.get_observation_distribution(state, action)
+            prob[i] = get_probability(d, obs)
+        new_belief = random.choices(belief, weights=prob, k=len(belief))
+        return new_belief
+
+    def _update_belief_state(self, belief, action):
+        new_belief = []
+        for state in belief:
+            d = (
+                self._domain.get_next_state_distribution(Memory([state]), action)
+                if action is not None
+                else self._domain.get_initial_state_distribution()
+            )
+            new_state = d.sample()
+            new_belief.append(new_state)
+        return new_belief
+
+    def _get_best_action(self, h_act, h_obs, w=0):
+        """Retrieve best action at (h_act, h_obs) from stored tree.
+
+        If w > 0, best is determined using the UCT formula with weight w;
+        else it's just the action with min expected cost.
+        """
+        best_action = None
+        best_action_score = self._VLV
+        if w > 0:
+            parent = self._tree[(h_act, h_obs)]
+        for action in self._domain.get_action_space().get_elements():
+            key = (h_act + (action,), h_obs)
+            if key in self._tree:
+                node = self._tree[key]
+                # node[0] is visit count (N); node[1] is average cost (V)
+                if w > 0:
+                    if node[0] == 0:
+                        score = -self._VLV
+                    else:
+                        score = node[1] - (w * math.sqrt(math.log(parent[0]) / node[0]))
+                else:
+                    score = node[1]
+                if score <= best_action_score:
+                    best_action = action
+                    best_action_score = score
+        return best_action
+
+    def _tree_search(self, state, h_act, h_obs, depth):
+        """UCT search from a given state with act/obs history.
+
+        This corresponds to the Simulate function in the POMCP paper.
+        """
+        # This must be a history that ends on an observation
+        assert len(h_act) == len(h_obs)
+        if depth > self._max_depth:
+            return self._VLV
+        if (h_act, h_obs) not in self._tree:
+            # generate new child nodes
+            for action in self._domain.get_applicable_actions(
+                Memory([state])
+            ).get_elements():
+                assert action is not None
+                self._tree[(h_act + (action,), h_obs)] = [0, 0, []]
+            # but we must also store this node, or we'll never get out of this case!
+            cost = self._rollout(state, h_act, h_obs, depth)
+            self._tree[(h_act, h_obs)] = [1, cost, [state]]
+            return cost
+        else:
+            # pick a successor node according to the UCT formula
+            action = self._get_best_action(h_act, h_obs, w=self._max_depth)
+            assert action is not None
+            # simulate outcome of this action:
+            new_state = self._domain.get_next_state_distribution(
+                Memory([state]), action
+            ).sample()
+            TV = self._domain.get_transition_value(Memory([state]), action, new_state)
+            new_obs = self._domain.get_observation_distribution(state, action).sample()
+            if self._domain.is_goal(new_obs):
+                s_cost = TV.cost
+            else:
+                s_cost = TV.cost + self._tree_search(
+                    new_state, h_act + (action,), h_obs + (new_obs,), depth + 1
+                )
+                s_cost = min(s_cost, self._VLV)
+            this_node = self._tree[(h_act, h_obs)]
+            succ_node = self._tree[(h_act + (action,), h_obs)]
+            # update average cost for succ node:
+            succ_node[1] = ((succ_node[1] * succ_node[0]) + s_cost) / (succ_node[0] + 1)
+            # increment visit counters for both this node and succ node:
+            this_node[0] = this_node[0] + 1
+            succ_node[0] = succ_node[0] + 1
+            return s_cost
+
+    def _rollout(self, state, h_act, h_obs, depth):
+        if depth > self._max_depth:
+            return self._VLV
+        action = self._get_random_action(state, h_act, h_obs, depth)
+        assert action is not None
+        new_state = self._domain.get_next_state_distribution(
+            Memory([state]), action
+        ).sample()
+        TV = self._domain.get_transition_value(Memory([state]), action, new_state)
+        new_obs = self._domain.get_observation_distribution(state, action).sample()
+        if self._domain.is_goal(new_obs):
+            s_cost = TV.cost
+        else:
+            s_cost = TV.cost + self._rollout(
+                new_state, h_act + (action,), h_obs + (new_obs,), depth + 1
+            )
+            s_cost = min(s_cost, self._VLV)
+        return s_cost
+
+    def _get_random_action(self, state, h_act, h_obs, depth):
+        sel = self._domain.get_applicable_actions(Memory([state])).sample()
+        return sel
+
+
+def get_probability(distribution, element, n=100):
+    """Utility function to get the probability of a specific element from a scikit-decide distribution
+    (based on sampling if this distribution is not a DiscreteDistribution)."""
+
+    # Avoid "dumb" sampling if the distribution is a DiscreteDistribution:
+    if isinstance(distribution, DiscreteDistribution):
+        return next((p for e, p in distribution.get_values() if e == element), 0.0)
+    else:
+        p = 0
+        for i in range(n):
+            x = distribution.sample()
+            if x == element:
+                p += 1
+        return p / n
+
+
+if __name__ == "__main__":
+    from skdecide.hub.domain.mastermind import MasterMind
+    from skdecide.utils import rollout
+
+    domain_factory = lambda: MasterMind(3, 3)
+    domain = domain_factory()
+    if POMCP.check_domain(domain):
+        with POMCP(domain_factory=domain_factory) as solver:
+            solver.solve()
+            rollout(
+                domain,
+                solver,
+                num_episodes=5,
+                max_steps=1000,
+                outcome_formatter=lambda o: f"{o.observation} - cost: {o.value.cost:.2f}",
+            )
```

## skdecide/hub/solver/ray_rllib/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .ray_rllib import RayRLlib
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .ray_rllib import RayRLlib
```

## skdecide/hub/solver/ray_rllib/custom_models.py

```diff
@@ -1,151 +1,151 @@
-from gymnasium.spaces import flatten_space
-from ray.rllib.models.tf.fcnet import FullyConnectedNetwork as TFFullyConnectedNetwork
-from ray.rllib.models.tf.tf_modelv2 import TFModelV2
-from ray.rllib.models.torch.fcnet import (
-    FullyConnectedNetwork as TorchFullyConnectedNetwork,
-)
-from ray.rllib.models.torch.torch_modelv2 import TorchModelV2
-from ray.rllib.utils.framework import try_import_tf, try_import_torch
-from ray.rllib.utils.spaces.space_utils import flatten_to_single_ndarray, unbatch
-from ray.rllib.utils.torch_utils import FLOAT_MAX, FLOAT_MIN
-
-tf1, tf, tfv = try_import_tf()
-torch, nn = try_import_torch()
-
-
-class TFParametricActionsModel(TFModelV2):
-    """Parametric action model that handles the dot product and masking and
-    that also learns action embeddings. TensorFlow version.
-
-    This assumes the outputs are logits for a single Categorical action dist.
-    """
-
-    def __init__(self, obs_space, action_space, num_outputs, model_config, name, **kw):
-        super(TFParametricActionsModel, self).__init__(
-            obs_space, action_space, num_outputs, model_config, name, **kw
-        )
-
-        self.action_ids_shifted = tf.constant(
-            list(range(1, num_outputs + 1)), dtype=tf.float32
-        )
-        self.true_obs_space = model_config["custom_model_config"]["true_obs_space"]
-
-        self.pred_action_embed_model = TFFullyConnectedNetwork(
-            flatten_space(self.true_obs_space),
-            action_space,
-            model_config["custom_model_config"]["action_embed_size"],
-            model_config,
-            name + "_pred_action_embed",
-        )
-
-        self.action_embedding = tf.keras.layers.Embedding(
-            input_dim=num_outputs + 1,
-            output_dim=model_config["custom_model_config"]["action_embed_size"],
-            name="action_embed_matrix",
-        )
-
-    def forward(self, input_dict, state, seq_lens):
-        # Extract the available actions mask tensor from the observation.
-        valid_avail_actions_mask = input_dict["obs"]["valid_avail_actions_mask"]
-
-        # Unbatch true observations before flattening them
-        unbatched_true_obs = unbatch(input_dict["obs"]["true_obs"])
-
-        # Compute the predicted action embedding
-        pred_action_embed, _ = self.pred_action_embed_model(
-            {
-                "obs": tf.stack(
-                    [flatten_to_single_ndarray(o) for o in unbatched_true_obs]
-                )
-            }
-        )
-
-        # Expand the model output to [BATCH, 1, EMBED_SIZE]. Note that the
-        # avail actions tensor is of shape [BATCH, MAX_ACTIONS, EMBED_SIZE].
-        intent_vector = tf.expand_dims(pred_action_embed, 1)
-
-        valid_avail_actions = self.action_ids_shifted * valid_avail_actions_mask
-
-        # Embedding for valid available actions which will be learned.
-        # Embedding vector for 0 is an invalid embedding (a "dummy embedding").
-        valid_avail_actions_embed = self.action_embedding(valid_avail_actions)
-
-        # Batch dot product => shape of logits is [BATCH, MAX_ACTIONS].
-        action_logits = tf.reduce_sum(valid_avail_actions_embed * intent_vector, axis=2)
-
-        # Mask out invalid actions (use tf.float32.min for stability)
-        inf_mask = tf.maximum(tf.math.log(valid_avail_actions_mask), tf.float32.min)
-
-        return action_logits + inf_mask, state
-
-    def value_function(self):
-        return self.pred_action_embed_model.value_function()
-
-
-class TorchParametricActionsModel(TorchModelV2, nn.Module):
-    """Parametric action model that handles the dot product and masking and
-    that also learns action embeddings. PyTorch version.
-
-    This assumes the outputs are logits for a single Categorical action dist.
-    """
-
-    def __init__(self, obs_space, action_space, num_outputs, model_config, name, **kw):
-        nn.Module.__init__(self)
-        super(TorchParametricActionsModel, self).__init__(
-            obs_space, action_space, num_outputs, model_config, name, **kw
-        )
-
-        self.action_ids_shifted = torch.arange(1, num_outputs + 1, dtype=torch.int64)
-        self.true_obs_space = model_config["custom_model_config"]["true_obs_space"]
-
-        self.pred_action_embed_model = TorchFullyConnectedNetwork(
-            flatten_space(self.true_obs_space),
-            action_space,
-            model_config["custom_model_config"]["action_embed_size"],
-            model_config,
-            name + "_pred_action_embed",
-        )
-
-        self.action_embedding = nn.Embedding(
-            num_embeddings=num_outputs + 1,
-            embedding_dim=model_config["custom_model_config"]["action_embed_size"],
-        )
-
-    def forward(self, input_dict, state, seq_lens):
-        # Extract the available actions mask tensor from the observation.
-        valid_avail_actions_mask = input_dict["obs"]["valid_avail_actions_mask"]
-
-        # Unbatch true observations before flattening them
-        unbatched_true_obs = unbatch(input_dict["obs"]["true_obs"])
-
-        # Compute the predicted action embedding
-        pred_action_embed, _ = self.pred_action_embed_model(
-            {
-                "obs": torch.stack(
-                    [flatten_to_single_ndarray(o) for o in unbatched_true_obs]
-                )
-            }
-        )
-
-        # Expand the model output to [BATCH, 1, EMBED_SIZE]. Note that the
-        # avail actions tensor is of shape [BATCH, MAX_ACTIONS, EMBED_SIZE].
-        intent_vector = torch.unsqueeze(pred_action_embed, 1)
-
-        valid_avail_actions = self.action_ids_shifted * valid_avail_actions_mask
-
-        # Embedding for valid available actions which will be learned.
-        # Embedding vector for 0 is an invalid embedding (a "dummy embedding").
-        valid_avail_actions_embed = self.action_embedding(valid_avail_actions.int())
-
-        # Batch dot product => shape of logits is [BATCH, MAX_ACTIONS].
-        action_logits = torch.sum(valid_avail_actions_embed * intent_vector, dim=2)
-
-        # Mask out invalid actions (use tf.float32.min for stability)
-        inf_mask = torch.clamp(
-            torch.log(valid_avail_actions_mask), FLOAT_MIN, FLOAT_MAX
-        )
-
-        return action_logits + inf_mask, state
-
-    def value_function(self):
-        return self.action_embed_model.value_function()
+from gymnasium.spaces import flatten_space
+from ray.rllib.models.tf.fcnet import FullyConnectedNetwork as TFFullyConnectedNetwork
+from ray.rllib.models.tf.tf_modelv2 import TFModelV2
+from ray.rllib.models.torch.fcnet import (
+    FullyConnectedNetwork as TorchFullyConnectedNetwork,
+)
+from ray.rllib.models.torch.torch_modelv2 import TorchModelV2
+from ray.rllib.utils.framework import try_import_tf, try_import_torch
+from ray.rllib.utils.spaces.space_utils import flatten_to_single_ndarray, unbatch
+from ray.rllib.utils.torch_utils import FLOAT_MAX, FLOAT_MIN
+
+tf1, tf, tfv = try_import_tf()
+torch, nn = try_import_torch()
+
+
+class TFParametricActionsModel(TFModelV2):
+    """Parametric action model that handles the dot product and masking and
+    that also learns action embeddings. TensorFlow version.
+
+    This assumes the outputs are logits for a single Categorical action dist.
+    """
+
+    def __init__(self, obs_space, action_space, num_outputs, model_config, name, **kw):
+        super(TFParametricActionsModel, self).__init__(
+            obs_space, action_space, num_outputs, model_config, name, **kw
+        )
+
+        self.action_ids_shifted = tf.constant(
+            list(range(1, num_outputs + 1)), dtype=tf.float32
+        )
+        self.true_obs_space = model_config["custom_model_config"]["true_obs_space"]
+
+        self.pred_action_embed_model = TFFullyConnectedNetwork(
+            flatten_space(self.true_obs_space),
+            action_space,
+            model_config["custom_model_config"]["action_embed_size"],
+            model_config,
+            name + "_pred_action_embed",
+        )
+
+        self.action_embedding = tf.keras.layers.Embedding(
+            input_dim=num_outputs + 1,
+            output_dim=model_config["custom_model_config"]["action_embed_size"],
+            name="action_embed_matrix",
+        )
+
+    def forward(self, input_dict, state, seq_lens):
+        # Extract the available actions mask tensor from the observation.
+        valid_avail_actions_mask = input_dict["obs"]["valid_avail_actions_mask"]
+
+        # Unbatch true observations before flattening them
+        unbatched_true_obs = unbatch(input_dict["obs"]["true_obs"])
+
+        # Compute the predicted action embedding
+        pred_action_embed, _ = self.pred_action_embed_model(
+            {
+                "obs": tf.stack(
+                    [flatten_to_single_ndarray(o) for o in unbatched_true_obs]
+                )
+            }
+        )
+
+        # Expand the model output to [BATCH, 1, EMBED_SIZE]. Note that the
+        # avail actions tensor is of shape [BATCH, MAX_ACTIONS, EMBED_SIZE].
+        intent_vector = tf.expand_dims(pred_action_embed, 1)
+
+        valid_avail_actions = self.action_ids_shifted * valid_avail_actions_mask
+
+        # Embedding for valid available actions which will be learned.
+        # Embedding vector for 0 is an invalid embedding (a "dummy embedding").
+        valid_avail_actions_embed = self.action_embedding(valid_avail_actions)
+
+        # Batch dot product => shape of logits is [BATCH, MAX_ACTIONS].
+        action_logits = tf.reduce_sum(valid_avail_actions_embed * intent_vector, axis=2)
+
+        # Mask out invalid actions (use tf.float32.min for stability)
+        inf_mask = tf.maximum(tf.math.log(valid_avail_actions_mask), tf.float32.min)
+
+        return action_logits + inf_mask, state
+
+    def value_function(self):
+        return self.pred_action_embed_model.value_function()
+
+
+class TorchParametricActionsModel(TorchModelV2, nn.Module):
+    """Parametric action model that handles the dot product and masking and
+    that also learns action embeddings. PyTorch version.
+
+    This assumes the outputs are logits for a single Categorical action dist.
+    """
+
+    def __init__(self, obs_space, action_space, num_outputs, model_config, name, **kw):
+        nn.Module.__init__(self)
+        super(TorchParametricActionsModel, self).__init__(
+            obs_space, action_space, num_outputs, model_config, name, **kw
+        )
+
+        self.action_ids_shifted = torch.arange(1, num_outputs + 1, dtype=torch.int64)
+        self.true_obs_space = model_config["custom_model_config"]["true_obs_space"]
+
+        self.pred_action_embed_model = TorchFullyConnectedNetwork(
+            flatten_space(self.true_obs_space),
+            action_space,
+            model_config["custom_model_config"]["action_embed_size"],
+            model_config,
+            name + "_pred_action_embed",
+        )
+
+        self.action_embedding = nn.Embedding(
+            num_embeddings=num_outputs + 1,
+            embedding_dim=model_config["custom_model_config"]["action_embed_size"],
+        )
+
+    def forward(self, input_dict, state, seq_lens):
+        # Extract the available actions mask tensor from the observation.
+        valid_avail_actions_mask = input_dict["obs"]["valid_avail_actions_mask"]
+
+        # Unbatch true observations before flattening them
+        unbatched_true_obs = unbatch(input_dict["obs"]["true_obs"])
+
+        # Compute the predicted action embedding
+        pred_action_embed, _ = self.pred_action_embed_model(
+            {
+                "obs": torch.stack(
+                    [flatten_to_single_ndarray(o) for o in unbatched_true_obs]
+                )
+            }
+        )
+
+        # Expand the model output to [BATCH, 1, EMBED_SIZE]. Note that the
+        # avail actions tensor is of shape [BATCH, MAX_ACTIONS, EMBED_SIZE].
+        intent_vector = torch.unsqueeze(pred_action_embed, 1)
+
+        valid_avail_actions = self.action_ids_shifted * valid_avail_actions_mask
+
+        # Embedding for valid available actions which will be learned.
+        # Embedding vector for 0 is an invalid embedding (a "dummy embedding").
+        valid_avail_actions_embed = self.action_embedding(valid_avail_actions.int())
+
+        # Batch dot product => shape of logits is [BATCH, MAX_ACTIONS].
+        action_logits = torch.sum(valid_avail_actions_embed * intent_vector, dim=2)
+
+        # Mask out invalid actions (use tf.float32.min for stability)
+        inf_mask = torch.clamp(
+            torch.log(valid_avail_actions_mask), FLOAT_MIN, FLOAT_MAX
+        )
+
+        return action_logits + inf_mask, state
+
+    def value_function(self):
+        return self.pred_action_embed_model.value_function()
```

## skdecide/hub/solver/ray_rllib/ray_rllib.py

```diff
@@ -1,480 +1,643 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Callable, Dict, Optional, Set, Type
-
-import gymnasium as gym
-import numpy as np
-import ray
-from ray.rllib.algorithms.algorithm import Algorithm, AlgorithmConfig
-from ray.rllib.env.wrappers.multi_agent_env_compatibility import (
-    MultiAgentEnvCompatibility,
-)
-from ray.rllib.models import ModelCatalog
-from ray.rllib.utils.from_config import NotProvided
-from ray.tune.registry import register_env
-
-from skdecide import Domain, Solver
-from skdecide.builders.domain import SingleAgent, UnrestrictedActions
-from skdecide.builders.domain.observability import FullyObservable
-from skdecide.builders.solver import Policies, Restorable
-from skdecide.core import EnumerableSpace
-from skdecide.domains import MultiAgentRLDomain
-from skdecide.hub.domain.gym import AsLegacyGymV21Env
-from skdecide.hub.space.gym import GymSpace
-
-from .custom_models import TFParametricActionsModel, TorchParametricActionsModel
-
-
-class D(MultiAgentRLDomain):
-    pass
-
-
-class RayRLlib(Solver, Policies, Restorable):
-    """This class wraps a Ray RLlib solver (ray[rllib]) as a scikit-decide solver.
-
-    !!! warning
-        Using this class requires Ray RLlib to be installed.
-    """
-
-    T_domain = D
-
-    def __init__(
-        self,
-        algo_class: Type[Algorithm],
-        train_iterations: int,
-        config: Optional[AlgorithmConfig] = None,
-        policy_configs: Optional[Dict[str, Dict]] = None,
-        policy_mapping_fn: Optional[
-            Callable[[str, Optional["EpisodeV2"], Optional["RolloutWorker"]], str]
-        ] = None,
-        action_embed_sizes: Optional[Dict[str, int]] = None,
-    ) -> None:
-        """Initialize Ray RLlib.
-
-        # Parameters
-        algo_class: The class of Ray RLlib trainer/agent to wrap.
-        train_iterations: The number of iterations to call the trainer's train() method.
-        config: The configuration dictionary for the trainer.
-        policy_configs: The mapping from policy id (str) to additional config (dict) (leave default for single policy).
-        policy_mapping_fn: The function mapping agent ids to policy ids (leave default for single policy).
-        action_embed_sizes: The mapping from policy id (str) to action embedding size (only used with domains filtering allowed actions per state, default to 2)
-        """
-        self._algo_class = algo_class
-        self._train_iterations = train_iterations
-        self._config = config or algo_class.get_default_config()
-        if policy_configs is None:
-            self._policy_configs = {"policy": {}}
-        else:
-            self._policy_configs = policy_configs
-        if policy_mapping_fn is None:
-            self._policy_mapping_fn = lambda agent_id, episode, worker: "policy"
-        else:
-            self._policy_mapping_fn = policy_mapping_fn
-        self._action_embed_sizes = (
-            action_embed_sizes
-            if action_embed_sizes is not None
-            else {k: 2 for k in self._policy_configs.keys()}
-        )
-        if self._action_embed_sizes.keys() != self._policy_configs.keys():
-            raise RuntimeError(
-                "Action embed size keys must be the same as policy config keys"
-            )
-
-        ray.init(ignore_reinit_error=True)
-
-    @classmethod
-    def _check_domain_additional(cls, domain: Domain) -> bool:
-        if isinstance(domain, SingleAgent):
-            return isinstance(domain.get_action_space(), GymSpace) and isinstance(
-                domain.get_observation_space(), GymSpace
-            )
-        else:
-            return all(
-                isinstance(a, GymSpace) for a in domain.get_action_space().values()
-            ) and all(
-                isinstance(o, GymSpace) for o in domain.get_observation_space().values()
-            )
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        # Reuse algo if possible (enables further learning)
-        if not hasattr(self, "_algo"):
-            self._init_algo(domain_factory)
-
-        # Training loop
-        for _ in range(self._train_iterations):
-            self._algo.train()
-
-    def _sample_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        action = {
-            k: self._algo.compute_single_action(
-                self._unwrap_obs(observation, k),
-                policy_id=self._policy_mapping_fn(k, None, None),
-            )
-            for k in observation.keys()
-        }
-        return self._wrap_action(action)
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
-
-    def _save(self, path: str) -> None:
-        self._algo.save(path)
-
-    def _load(self, path: str, domain_factory: Callable[[], D]):
-        self._init_algo(domain_factory)
-        self._algo.restore(path)
-
-    def _init_algo(self, domain_factory: Callable[[], D]):
-        domain = domain_factory()
-        wrapped_action_space = domain.get_action_space()
-        wrapped_observation_space = domain.get_observation_space()
-        # Test if the domain is using restricted actions or not
-        self._action_masking = (
-            (not isinstance(domain, UnrestrictedActions))
-            and isinstance(domain, FullyObservable)
-            and all(
-                isinstance(agent_action_space, EnumerableSpace)
-                for agent_action_space in wrapped_action_space.values()
-            )
-            and self._algo_class.__name__
-            # Only the following algos handle action masking in ray[rllib]==2.9.0
-            in ["APPO", "BC", "DQN", "Rainbow", "IMPALA", "MARWIL", "PPO"]
-        )
-        if self._action_masking:
-            if self._config.get("framework") not in ["tf", "tf2", "torch"]:
-                raise RuntimeError(
-                    "Action masking (invalid action filtering) for RLlib requires TensorFlow or PyTorch to be installed"
-                )
-            ModelCatalog.register_custom_model(
-                "skdecide_rllib_custom_model",
-                TFParametricActionsModel
-                if self._config.get("framework") in ["tf", "tf2"]
-                else TorchParametricActionsModel
-                if self._config.get("framework") == "torch"
-                else NotProvided,
-            )
-            if self._algo_class.__name__ == "DQN":
-                self._config.training(
-                    hiddens=[],
-                    dueling=False,
-                )
-            elif self._algo_class.__name__ == "PPO":
-                self._config.training(
-                    model={"vf_share_layers": True},
-                )
-            # States are not automatically autocasted when the domain is actually single agent
-            # because the type hints of states in functions taking them as argument are not in
-            # the form of D.T_agent[...] (since they are global to all the agents in multi-agent settings)
-            self._state_access = (
-                (lambda s: next(iter(s.values())))
-                if isinstance(domain, SingleAgent)
-                else (lambda s: s)
-            )
-        else:
-            self._state_access = None
-        self._wrap_action = lambda a, wrapped_action_space=wrapped_action_space: {
-            # Trick to assign v's wrapped value to self._wrap_action
-            # (no wrapping method for single unwrapped values in enumerable spaces)
-            k: next(iter(wrapped_action_space[k].from_unwrapped([v])))
-            for k, v in a.items()
-        }
-        # Trick to assign o's unwrapped value to self._unwrap_obs
-        # (no unwrapping method for single elements in enumerable spaces)
-        self._unwrap_obs = (
-            lambda obs, agent, domain=domain, wrapped_action_space=wrapped_action_space, wrapped_observation_space=wrapped_observation_space: next(
-                iter(wrapped_observation_space[agent].to_unwrapped([obs[agent]]))
-            )
-            if not self._action_masking
-            else {
-                "valid_avail_actions_mask": np.array(
-                    [
-                        1
-                        if domain.get_applicable_actions(self._state_access(obs))[
-                            agent
-                        ].contains(a)
-                        else 0
-                        for a in wrapped_action_space[agent].get_elements()
-                    ],
-                    dtype=np.int64,
-                ),
-                "true_obs": next(
-                    iter(wrapped_observation_space[agent].to_unwrapped([obs[agent]]))
-                ),
-            }
-        )
-        # Overwrite multi-agent config
-        pol_obs_spaces = (
-            {
-                self._policy_mapping_fn(k, None, None): v.unwrapped()
-                for k, v in wrapped_observation_space.items()
-            }
-            if not self._action_masking
-            else {
-                self._policy_mapping_fn(k, None, None): gym.spaces.Dict(
-                    {
-                        "valid_avail_actions_mask": gym.spaces.Box(
-                            0,
-                            1,
-                            shape=(len(wrapped_action_space[k].get_elements()),),
-                            dtype=np.int64,
-                        ),
-                        "true_obs": v.unwrapped(),
-                    }
-                )
-                for k, v in wrapped_observation_space.items()
-            }
-        )
-        pol_act_spaces = {
-            self._policy_mapping_fn(k, None, None): v.unwrapped()
-            for k, v in wrapped_action_space.items()
-        }
-
-        policies = (
-            {
-                k: (None, pol_obs_spaces[k], pol_act_spaces[k], v or {})
-                for k, v in self._policy_configs.items()
-            }
-            if not self._action_masking
-            else {
-                self._policy_mapping_fn(k, None, None): (
-                    None,
-                    pol_obs_spaces[k],
-                    pol_act_spaces[k],
-                    {
-                        **(self._policy_configs[k] or {}),
-                        **{
-                            "model": {
-                                "custom_model": "skdecide_rllib_custom_model",
-                                "custom_model_config": {
-                                    "true_obs_space": pol_obs_spaces[k].spaces[
-                                        "true_obs"
-                                    ],
-                                    "action_embed_size": action_embed_size,
-                                },
-                            },
-                        },
-                    },
-                )
-                for k, action_embed_size in self._action_embed_sizes.items()
-            }
-        )
-        self._config.multi_agent(
-            policies=policies,
-            policy_mapping_fn=self._policy_mapping_fn,
-        )
-
-        # Instantiate algo
-        register_env(
-            "skdecide_env",
-            lambda _, domain_factory=domain_factory, rayrllib=self: AsRLlibMultiAgentEnv(
-                domain=domain_factory(),
-                action_masking=rayrllib._action_masking,
-                state_access=rayrllib._state_access,
-            ),
-        )
-        # Disable env checking in case of action masking otherwise RLlib will try to simulate
-        # next state transition with invalid actions, which might make some domains crash if
-        # they require action masking
-        self._config.environment(
-            env="skdecide_env", disable_env_checking=self._action_masking
-        )
-        self._algo = self._algo_class(config=self._config)
-
-
-class AsRLlibMultiAgentEnv(MultiAgentEnvCompatibility):
-    def __init__(
-        self,
-        domain: D,
-        action_masking: bool = False,
-        state_access: Callable[D.T_agent[D.T_observation], D.T_state] = None,
-        render_mode: Optional[str] = None,
-    ) -> None:
-        old_env = AsLegacyRLlibMultiAgentEnv(
-            domain=domain, action_masking=action_masking, state_access=state_access
-        )
-        self._domain = domain
-        super().__init__(old_env=old_env, render_mode=render_mode)
-
-    def get_agent_ids(self) -> Set[str]:
-        return self._domain.get_agents()
-
-
-class AsLegacyRLlibMultiAgentEnv(AsLegacyGymV21Env):
-    def __init__(
-        self,
-        domain: D,
-        action_masking: bool,
-        state_access: Callable[D.T_agent[D.T_observation], D.T_state],
-        unwrap_spaces: bool = True,
-    ) -> None:
-        """Initialize AsLegacyRLlibMultiAgentEnv.
-
-        # Parameters
-        domain: The scikit-decide domain to wrap as a RLlib multi-agent environment.
-        action_masking: Boolean specifying whether action masking is used
-        state_access: Lambda function auto-casting fully observable observations in single or multi agent states accordingly
-        unwrap_spaces: Boolean specifying whether the action & observation spaces should be unwrapped.
-        """
-        self._domain = domain
-        self._action_masking = action_masking
-        self._state_access = state_access
-        self._unwrap_spaces = unwrap_spaces
-        self._wrapped_observation_space = domain.get_observation_space()
-        self._wrapped_action_space = domain.get_action_space()
-        if unwrap_spaces:
-            if not self._action_masking:
-                self.observation_space = gym.spaces.Dict(
-                    {
-                        k: agent_observation_space.unwrapped()
-                        for k, agent_observation_space in self._wrapped_observation_space.items()
-                    }
-                )
-            else:
-                self.observation_space = gym.spaces.Dict(
-                    {
-                        k: gym.spaces.Dict(
-                            {
-                                "valid_avail_actions_mask": gym.spaces.Box(
-                                    0,
-                                    1,
-                                    shape=(
-                                        len(
-                                            self._wrapped_action_space[k].get_elements()
-                                        ),
-                                    ),
-                                    dtype=np.int64,
-                                ),
-                                "true_obs": agent_observation_space.unwrapped(),
-                            }
-                        )
-                        for k, agent_observation_space in self._wrapped_observation_space.items()
-                    }
-                )
-            self.action_space = gym.spaces.Dict(
-                {
-                    k: agent_action_space.unwrapped()
-                    for k, agent_action_space in self._wrapped_action_space.items()
-                }
-            )
-        else:
-            if not self._action_masking:
-                self.observation_space = self._wrapped_observation_space
-            else:
-                self.observation_space = gym.spaces.Dict(
-                    {
-                        k: gym.spaces.Dict(
-                            {
-                                "valid_avail_actions_mask": gym.spaces.Box(
-                                    0,
-                                    1,
-                                    shape=(
-                                        len(
-                                            self._wrapped_action_space[k].get_elements()
-                                        ),
-                                    ),
-                                    dtype=np.int64,
-                                ),
-                                "true_obs": agent_observation_space,
-                            }
-                        )
-                        for k, agent_observation_space in self._wrapped_observation_space.items()
-                    }
-                )
-            self.action_space = self._wrapped_action_space
-
-    def reset(self):
-        """Resets the env and returns observations from ready agents.
-
-        # Returns
-        obs (dict): New observations for each ready agent.
-        """
-        raw_observation = self._domain.reset()
-        if not self._action_masking:
-            observation = {
-                # Trick to assign v's unwrapped value to k
-                # (no unwrapping method for single elements in enumerable spaces)
-                k: next(iter(self._wrapped_observation_space[k].to_unwrapped([v])))
-                for k, v in raw_observation.items()
-            }
-        else:
-            applicable_actions = self._domain.get_applicable_actions(
-                self._state_access(raw_observation)
-            )
-            observation = {
-                # Trick to assign v's unwrapped value to k
-                # (no unwrapping method for single elements in enumerable spaces)
-                k: {
-                    "valid_avail_actions_mask": np.array(
-                        [
-                            1 if applicable_actions[k].contains(a) else 0
-                            for a in self._wrapped_action_space[k].get_elements()
-                        ],
-                        dtype=np.int64,
-                    ),
-                    "true_obs": next(
-                        iter(self._wrapped_observation_space[k].to_unwrapped([v]))
-                    ),
-                }
-                for k, v in raw_observation.items()
-            }
-        return observation
-
-    def step(self, action_dict):
-        """Returns observations from ready agents.
-
-        The returns are dicts mapping from agent_id strings to values. The
-        number of agents in the env can vary over time.
-
-        # Returns
-        obs (dict): New observations for each ready agent.
-        rewards (dict): Reward values for each ready agent. If the episode is just started, the value will be None.
-        dones (dict): Done values for each ready agent. The special key "__all__" (required) is used to indicate env
-            termination.
-        infos (dict): Optional info values for each agent id.
-        """
-        action = {
-            # Trick to assign v's wrapped value to k
-            # (no wrapping method from single unwrapped values in enumerable spaces)
-            k: next(iter(self._wrapped_action_space[k].from_unwrapped([v])))
-            for k, v in action_dict.items()
-        }
-        outcome = self._domain.step(action)
-        if not self._action_masking:
-            observations = {
-                # Trick to assign v's unwrapped value to k
-                # (no unwrapping method for single elements in enumerable spaces)
-                k: next(iter(self._wrapped_observation_space[k].to_unwrapped([v])))
-                for k, v in outcome.observation.items()
-            }
-        else:
-            applicable_actions = self._domain.get_applicable_actions(
-                self._state_access(outcome.observation)
-            )
-            observations = {
-                # Trick to assign v's unwrapped value to k
-                # (no unwrapping method for single elements in enumerable spaces)
-                k: {
-                    "valid_avail_actions_mask": np.array(
-                        [
-                            1 if applicable_actions[k].contains(a) else 0
-                            for a in self._wrapped_action_space[k].get_elements()
-                        ],
-                        dtype=np.int64,
-                    ),
-                    "true_obs": next(
-                        iter(self._wrapped_observation_space[k].to_unwrapped([v]))
-                    ),
-                }
-                for k, v in outcome.observation.items()
-            }
-        rewards = {k: v.reward for k, v in outcome.value.items()}
-        done = outcome.termination
-        done.update({"__all__": all(outcome.termination.values())})
-        infos = {k: (v or {}) for k, v in outcome.info.items()}
-        return observations, rewards, done, infos
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Callable, Dict, Optional, Set, Type, Union
+
+import gymnasium as gym
+import numpy as np
+import ray
+from packaging.version import Version
+from ray.rllib.algorithms.algorithm import Algorithm, AlgorithmConfig
+from ray.rllib.algorithms.callbacks import DefaultCallbacks
+from ray.rllib.env.wrappers.multi_agent_env_compatibility import (
+    MultiAgentEnvCompatibility,
+)
+from ray.rllib.models import ModelCatalog
+from ray.rllib.policy.policy import Policy
+from ray.rllib.utils.from_config import NotProvided
+from ray.tune.registry import register_env
+
+from skdecide import Domain, Solver
+from skdecide.builders.domain import SingleAgent, UnrestrictedActions
+from skdecide.builders.domain.observability import FullyObservable
+from skdecide.builders.solver import Policies, Restorable
+from skdecide.core import EnumerableSpace
+from skdecide.domains import MultiAgentRLDomain
+from skdecide.hub.domain.gym import AsLegacyGymV21Env
+from skdecide.hub.space.gym import GymSpace
+
+from .custom_models import TFParametricActionsModel, TorchParametricActionsModel
+
+if TYPE_CHECKING:
+    # imports useful only in annotations, may change according to releases
+    from ray.rllib import RolloutWorker
+
+
+class D(MultiAgentRLDomain):
+    pass
+
+
+class RayRLlib(Solver, Policies, Restorable):
+    """This class wraps a Ray RLlib solver (ray[rllib]) as a scikit-decide solver.
+
+    !!! warning
+        Using this class requires Ray RLlib to be installed.
+    """
+
+    T_domain = D
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        algo_class: Type[Algorithm],
+        train_iterations: int,
+        config: Optional[AlgorithmConfig] = None,
+        policy_configs: Optional[Dict[str, Dict]] = None,
+        policy_mapping_fn: Optional[
+            Callable[[str, Optional["EpisodeV2"], Optional["RolloutWorker"]], str]
+        ] = None,
+        action_embed_sizes: Optional[Dict[str, int]] = None,
+        callback: Callable[[RayRLlib], bool] = lambda solver: False,
+    ) -> None:
+        """Initialize Ray RLlib.
+
+        # Parameters
+        domain_factory: A callable with no argument returning the domain to solve (can be a mere domain class).
+            The resulting domain will be auto-cast to the level expected by the solver.
+        algo_class: The class of Ray RLlib trainer/agent to wrap.
+        train_iterations: The number of iterations to call the trainer's train() method.
+        config: The configuration dictionary for the trainer.
+        policy_configs: The mapping from policy id (str) to additional config (dict) (leave default for single policy).
+        policy_mapping_fn: The function mapping agent ids to policy ids (leave default for single policy).
+        action_embed_sizes: The mapping from policy id (str) to action embedding size (only used with domains filtering allowed actions per state, default to 2)
+        callback: function called at each solver iteration.
+            If returning true, the solve process stops and exit the current train iteration.
+            However, if train_iterations > 1, another train loop will be entered after that.
+            (One can code its callback in such a way that further training loop are stopped directly after that.)
+
+        """
+        Solver.__init__(self, domain_factory=domain_factory)
+        self.callback = callback
+        self._algo_class = algo_class
+        self._train_iterations = train_iterations
+        self._config = config or algo_class.get_default_config()
+        if policy_configs is None:
+            self._policy_configs = {"policy": {}}
+        else:
+            self._policy_configs = policy_configs
+        if policy_mapping_fn is None:
+            self._policy_mapping_fn = lambda agent_id, episode, worker: "policy"
+        else:
+            self._policy_mapping_fn = policy_mapping_fn
+        self._action_embed_sizes = (
+            action_embed_sizes
+            if action_embed_sizes is not None
+            else {k: 2 for k in self._policy_configs.keys()}
+        )
+        if self._action_embed_sizes.keys() != self._policy_configs.keys():
+            raise RuntimeError(
+                "Action embed size keys must be the same as policy config keys"
+            )
+
+        ray.init(ignore_reinit_error=True)
+        self._algo_callbacks: Optional[DefaultCallbacks] = None
+        self._algo_worker_callbacks: Optional[DefaultCallbacks] = None
+        self._algo_evaluation_worker_callbacks: Optional[DefaultCallbacks] = None
+
+    def get_policy(self) -> Dict[str, Policy]:
+        """Return the computed policy."""
+        return {
+            policy_id: self._algo.get_policy(policy_id=policy_id)
+            for policy_id in self._policy_configs
+        }
+
+    @classmethod
+    def _check_domain_additional(cls, domain: Domain) -> bool:
+        if isinstance(domain, SingleAgent):
+            return isinstance(domain.get_action_space(), GymSpace) and isinstance(
+                domain.get_observation_space(), GymSpace
+            )
+        else:
+            return all(
+                isinstance(a, GymSpace) for a in domain.get_action_space().values()
+            ) and all(
+                isinstance(o, GymSpace) for o in domain.get_observation_space().values()
+            )
+
+    def _solve(self) -> None:
+        # Reuse algo if possible (enables further learning)
+        if not hasattr(self, "_algo"):
+            self._init_algo()
+
+        # Training loop
+        for _ in range(self._train_iterations):
+            try:
+                self._algo.train()
+            except SolveEarlyStop as e:
+                # if stopping exception raise, we choose to stop this train iteration
+                pass
+
+    def _sample_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        action = {
+            k: self._algo.compute_single_action(
+                self._unwrap_obs(observation, k),
+                policy_id=self._policy_mapping_fn(k, None, None),
+            )
+            for k in observation.keys()
+        }
+        return self._wrap_action(action)
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
+
+    def _save(self, path: str) -> None:
+        self.forget_callback()  # avoid serializing issues
+        self._algo.save(path)
+        self.set_callback()  # put it back in case of further solve
+
+    def _load(self, path: str):
+        self._init_algo()
+        self._algo.restore(path)
+        self.set_callback()  # ensure putting back actual callback
+
+    def _init_algo(self) -> None:
+        domain = self._domain_factory()
+        wrapped_action_space = domain.get_action_space()
+        wrapped_observation_space = domain.get_observation_space()
+        # Test if the domain is using restricted actions or not
+        self._action_masking = (
+            (not isinstance(domain, UnrestrictedActions))
+            and isinstance(domain, FullyObservable)
+            and all(
+                isinstance(agent_action_space, EnumerableSpace)
+                for agent_action_space in wrapped_action_space.values()
+            )
+            and self._algo_class.__name__
+            # Only the following algos handle action masking in ray[rllib]==2.9.0
+            in ["APPO", "BC", "DQN", "Rainbow", "IMPALA", "MARWIL", "PPO"]
+        )
+        if self._action_masking:
+            if self._config.get("framework") not in ["tf", "tf2", "torch"]:
+                raise RuntimeError(
+                    "Action masking (invalid action filtering) for RLlib requires TensorFlow or PyTorch to be installed"
+                )
+            ModelCatalog.register_custom_model(
+                "skdecide_rllib_custom_model",
+                TFParametricActionsModel
+                if self._config.get("framework") in ["tf", "tf2"]
+                else TorchParametricActionsModel
+                if self._config.get("framework") == "torch"
+                else NotProvided,
+            )
+            if self._algo_class.__name__ == "DQN":
+                self._config.training(
+                    hiddens=[],
+                    dueling=False,
+                )
+            elif self._algo_class.__name__ == "PPO":
+                self._config.training(
+                    model={"vf_share_layers": True},
+                )
+            # States are not automatically autocasted when the domain is actually single agent
+            # because the type hints of states in functions taking them as argument are not in
+            # the form of D.T_agent[...] (since they are global to all the agents in multi-agent settings)
+            self._state_access = (
+                (lambda s: next(iter(s.values())))
+                if isinstance(domain, SingleAgent)
+                else (lambda s: s)
+            )
+        else:
+            self._state_access = None
+        self._wrap_action = lambda a, wrapped_action_space=wrapped_action_space: {
+            # Trick to assign v's wrapped value to self._wrap_action
+            # (no wrapping method for single unwrapped values in enumerable spaces)
+            k: next(iter(wrapped_action_space[k].from_unwrapped([v])))
+            for k, v in a.items()
+        }
+        # Trick to assign o's unwrapped value to self._unwrap_obs
+        # (no unwrapping method for single elements in enumerable spaces)
+        self._unwrap_obs = (
+            lambda obs, agent, domain=domain, wrapped_action_space=wrapped_action_space, wrapped_observation_space=wrapped_observation_space: next(
+                iter(wrapped_observation_space[agent].to_unwrapped([obs[agent]]))
+            )
+            if not self._action_masking
+            else {
+                "valid_avail_actions_mask": np.array(
+                    [
+                        1
+                        if domain.get_applicable_actions(self._state_access(obs))[
+                            agent
+                        ].contains(a)
+                        else 0
+                        for a in wrapped_action_space[agent].get_elements()
+                    ],
+                    dtype=np.int64,
+                ),
+                "true_obs": next(
+                    iter(wrapped_observation_space[agent].to_unwrapped([obs[agent]]))
+                ),
+            }
+        )
+        # Overwrite multi-agent config
+        pol_obs_spaces = (
+            {
+                self._policy_mapping_fn(k, None, None): v.unwrapped()
+                for k, v in wrapped_observation_space.items()
+            }
+            if not self._action_masking
+            else {
+                self._policy_mapping_fn(k, None, None): gym.spaces.Dict(
+                    {
+                        "valid_avail_actions_mask": gym.spaces.Box(
+                            0,
+                            1,
+                            shape=(len(wrapped_action_space[k].get_elements()),),
+                            dtype=np.int64,
+                        ),
+                        "true_obs": v.unwrapped(),
+                    }
+                )
+                for k, v in wrapped_observation_space.items()
+            }
+        )
+        pol_act_spaces = {
+            self._policy_mapping_fn(k, None, None): v.unwrapped()
+            for k, v in wrapped_action_space.items()
+        }
+
+        policies = (
+            {
+                k: (None, pol_obs_spaces[k], pol_act_spaces[k], v or {})
+                for k, v in self._policy_configs.items()
+            }
+            if not self._action_masking
+            else {
+                self._policy_mapping_fn(k, None, None): (
+                    None,
+                    pol_obs_spaces[k],
+                    pol_act_spaces[k],
+                    {
+                        **(self._policy_configs[k] or {}),
+                        **{
+                            "model": {
+                                "custom_model": "skdecide_rllib_custom_model",
+                                "custom_model_config": {
+                                    "true_obs_space": pol_obs_spaces[k].spaces[
+                                        "true_obs"
+                                    ],
+                                    "action_embed_size": action_embed_size,
+                                },
+                            },
+                        },
+                    },
+                )
+                for k, action_embed_size in self._action_embed_sizes.items()
+            }
+        )
+        self._config.multi_agent(
+            policies=policies,
+            policy_mapping_fn=self._policy_mapping_fn,
+        )
+
+        register_env(
+            "skdecide_env",
+            lambda _, domain_factory=self._domain_factory, rayrllib=self: AsRLlibMultiAgentEnv(
+                domain=domain_factory(),
+                action_masking=rayrllib._action_masking,
+                state_access=rayrllib._state_access,
+            ),
+        )
+        if Version(ray.__version__) >= Version("2.20.0"):
+            # starting from ray 2.20, no more checks on environment are made,
+            # and `disable_env_checking` use raises an error
+            self._config.environment(env="skdecide_env")
+        else:
+            # Disable env checking in case of action masking otherwise RLlib will try to simulate
+            # next state transition with invalid actions, which might make some domains crash if
+            # they require action masking
+            self._config.environment(
+                env="skdecide_env", disable_env_checking=self._action_masking
+            )
+
+        # set callback class for algo config
+        self.set_callback()
+
+        # Instantiate algo
+        self._algo = self._algo_class(config=self._config)
+
+    def set_callback(self):
+        """Set back callback.
+
+        Useful to do it after serializing/deserializing because of potential issues with
+        - lambda functions
+        - dynamic classes
+
+        """
+        # generate specific callback class
+        callbacks_class = generate_rllibcallback_class(
+            callback=self.callback, solver=self
+        )
+        # use it in all algo config, and callbacks attributes
+        self._set_callbackclass(callbacks_class=callbacks_class)
+
+    def forget_callback(self):
+        """Forget about actual callback to avoid serializing issues."""
+        # use default callback class
+        callbacks_class = DefaultCallbacks
+        # use it in algo config & evaluation_config, worker config, and for algo.callbacks, worker.callbacks
+        self._set_callbackclass(callbacks_class=callbacks_class)
+
+    def _set_callbackclass(self, callbacks_class: Type[DefaultCallbacks]):
+        _set_callbackclass_in_config(
+            callbacks_class=callbacks_class, config=self._config
+        )
+        if hasattr(self, "_algo"):
+            tmp = self._algo.callbacks
+            if (
+                self._algo_callbacks
+                and self._algo_callbacks.__class__ is callbacks_class
+            ):
+                self._algo.callbacks = self._algo_callbacks
+            else:
+                self._algo.callbacks = callbacks_class()
+            self._algo_callbacks = tmp
+            if self._algo.evaluation_config:
+                _set_callbackclass_in_config(
+                    callbacks_class=callbacks_class, config=self._algo.evaluation_config
+                )
+            if self._algo.workers:
+                local_worker: RolloutWorker = self._algo.workers.local_worker()
+                if local_worker:
+                    _set_callbackclass_in_config(
+                        callbacks_class=callbacks_class, config=local_worker.config
+                    )
+                    self._algo_worker_callbacks = _swap_callbacks(
+                        algo_or_worker=local_worker,
+                        previous_callbacks=self._algo_worker_callbacks,
+                        callbacks_class=callbacks_class,
+                    )
+                    for pid, policy in local_worker.policy_map.items():
+                        policy.config["callbacks"] = callbacks_class
+
+
+def _set_callbackclass_in_config(
+    callbacks_class: Type[DefaultCallbacks], config: AlgorithmConfig
+) -> None:
+    is_frozen = config._is_frozen
+    if is_frozen:
+        # allow callbacks update
+        config._is_frozen = False
+    config.callbacks(callbacks_class=callbacks_class)
+    config._is_frozen = is_frozen
+
+
+def _swap_callbacks(
+    algo_or_worker: Union[Algorithm, RolloutWorker, Policy],
+    previous_callbacks,
+    callbacks_class,
+):
+    tmp = algo_or_worker.callbacks
+    if previous_callbacks and previous_callbacks.__class__ is callbacks_class:
+        algo_or_worker.callbacks = previous_callbacks
+    else:
+        algo_or_worker.callbacks = callbacks_class()
+    previous_callbacks = tmp
+    return previous_callbacks
+
+
+class AsRLlibMultiAgentEnv(MultiAgentEnvCompatibility):
+    def __init__(
+        self,
+        domain: D,
+        action_masking: bool = False,
+        state_access: Callable[D.T_agent[D.T_observation], D.T_state] = None,
+        render_mode: Optional[str] = None,
+    ) -> None:
+        old_env = AsLegacyRLlibMultiAgentEnv(
+            domain=domain, action_masking=action_masking, state_access=state_access
+        )
+        self._domain = domain
+        super().__init__(old_env=old_env, render_mode=render_mode)
+
+    def get_agent_ids(self) -> Set[str]:
+        return self._domain.get_agents()
+
+
+class AsLegacyRLlibMultiAgentEnv(AsLegacyGymV21Env):
+    def __init__(
+        self,
+        domain: D,
+        action_masking: bool,
+        state_access: Callable[D.T_agent[D.T_observation], D.T_state],
+        unwrap_spaces: bool = True,
+    ) -> None:
+        """Initialize AsLegacyRLlibMultiAgentEnv.
+
+        # Parameters
+        domain: The scikit-decide domain to wrap as a RLlib multi-agent environment.
+        action_masking: Boolean specifying whether action masking is used
+        state_access: Lambda function auto-casting fully observable observations in single or multi agent states accordingly
+        unwrap_spaces: Boolean specifying whether the action & observation spaces should be unwrapped.
+        """
+        self._domain = domain
+        self._action_masking = action_masking
+        self._state_access = state_access
+        self._unwrap_spaces = unwrap_spaces
+        self._wrapped_observation_space = domain.get_observation_space()
+        self._wrapped_action_space = domain.get_action_space()
+        if unwrap_spaces:
+            if not self._action_masking:
+                self.observation_space = gym.spaces.Dict(
+                    {
+                        k: agent_observation_space.unwrapped()
+                        for k, agent_observation_space in self._wrapped_observation_space.items()
+                    }
+                )
+            else:
+                self.observation_space = gym.spaces.Dict(
+                    {
+                        k: gym.spaces.Dict(
+                            {
+                                "valid_avail_actions_mask": gym.spaces.Box(
+                                    0,
+                                    1,
+                                    shape=(
+                                        len(
+                                            self._wrapped_action_space[k].get_elements()
+                                        ),
+                                    ),
+                                    dtype=np.int64,
+                                ),
+                                "true_obs": agent_observation_space.unwrapped(),
+                            }
+                        )
+                        for k, agent_observation_space in self._wrapped_observation_space.items()
+                    }
+                )
+            self.action_space = gym.spaces.Dict(
+                {
+                    k: agent_action_space.unwrapped()
+                    for k, agent_action_space in self._wrapped_action_space.items()
+                }
+            )
+        else:
+            if not self._action_masking:
+                self.observation_space = self._wrapped_observation_space
+            else:
+                self.observation_space = gym.spaces.Dict(
+                    {
+                        k: gym.spaces.Dict(
+                            {
+                                "valid_avail_actions_mask": gym.spaces.Box(
+                                    0,
+                                    1,
+                                    shape=(
+                                        len(
+                                            self._wrapped_action_space[k].get_elements()
+                                        ),
+                                    ),
+                                    dtype=np.int64,
+                                ),
+                                "true_obs": agent_observation_space,
+                            }
+                        )
+                        for k, agent_observation_space in self._wrapped_observation_space.items()
+                    }
+                )
+            self.action_space = self._wrapped_action_space
+
+    def reset(self):
+        """Resets the env and returns observations from ready agents.
+
+        # Returns
+        obs (dict): New observations for each ready agent.
+        """
+        raw_observation = self._domain.reset()
+        if not self._action_masking:
+            observation = {
+                # Trick to assign v's unwrapped value to k
+                # (no unwrapping method for single elements in enumerable spaces)
+                k: next(iter(self._wrapped_observation_space[k].to_unwrapped([v])))
+                for k, v in raw_observation.items()
+            }
+        else:
+            applicable_actions = self._domain.get_applicable_actions(
+                self._state_access(raw_observation)
+            )
+            observation = {
+                # Trick to assign v's unwrapped value to k
+                # (no unwrapping method for single elements in enumerable spaces)
+                k: {
+                    "valid_avail_actions_mask": np.array(
+                        [
+                            1 if applicable_actions[k].contains(a) else 0
+                            for a in self._wrapped_action_space[k].get_elements()
+                        ],
+                        dtype=np.int64,
+                    ),
+                    "true_obs": next(
+                        iter(self._wrapped_observation_space[k].to_unwrapped([v]))
+                    ),
+                }
+                for k, v in raw_observation.items()
+            }
+        return observation
+
+    def step(self, action_dict):
+        """Returns observations from ready agents.
+
+        The returns are dicts mapping from agent_id strings to values. The
+        number of agents in the env can vary over time.
+
+        # Returns
+        obs (dict): New observations for each ready agent.
+        rewards (dict): Reward values for each ready agent. If the episode is just started, the value will be None.
+        dones (dict): Done values for each ready agent. The special key "__all__" (required) is used to indicate env
+            termination.
+        infos (dict): Optional info values for each agent id.
+        """
+        action = {
+            # Trick to assign v's wrapped value to k
+            # (no wrapping method from single unwrapped values in enumerable spaces)
+            k: next(iter(self._wrapped_action_space[k].from_unwrapped([v])))
+            for k, v in action_dict.items()
+        }
+        outcome = self._domain.step(action)
+        if not self._action_masking:
+            observations = {
+                # Trick to assign v's unwrapped value to k
+                # (no unwrapping method for single elements in enumerable spaces)
+                k: next(iter(self._wrapped_observation_space[k].to_unwrapped([v])))
+                for k, v in outcome.observation.items()
+            }
+        else:
+            applicable_actions = self._domain.get_applicable_actions(
+                self._state_access(outcome.observation)
+            )
+            observations = {
+                # Trick to assign v's unwrapped value to k
+                # (no unwrapping method for single elements in enumerable spaces)
+                k: {
+                    "valid_avail_actions_mask": np.array(
+                        [
+                            1 if applicable_actions[k].contains(a) else 0
+                            for a in self._wrapped_action_space[k].get_elements()
+                        ],
+                        dtype=np.int64,
+                    ),
+                    "true_obs": next(
+                        iter(self._wrapped_observation_space[k].to_unwrapped([v]))
+                    ),
+                }
+                for k, v in outcome.observation.items()
+            }
+        rewards = {k: v.reward for k, v in outcome.value.items()}
+        done = outcome.termination
+        done.update({"__all__": all(outcome.termination.values())})
+        infos = {k: (v or {}) for k, v in outcome.info.items()}
+        return observations, rewards, done, infos
+
+
+class BaseRLlibCallback(DefaultCallbacks):
+    callback: _CallbackWrapper
+    solver: RayRLlib
+
+    def on_episode_step(
+        self,
+        *args,
+        **kwargs,
+    ) -> None:
+        stopping = self.callback(self.solver)
+        if stopping:
+            raise SolveEarlyStop("Solve process stopped by user callback")
+
+
+class _CallbackWrapper:
+    """Wrapper to avoid surprises with lambda functions"""
+
+    def __init__(self, callback: Callable[[RayRLlib], bool]):
+        self.callback = callback
+
+    def __call__(self, solver) -> bool:
+        return self.callback(solver)
+
+
+class SolveEarlyStop(Exception):
+    """Exception raised if a callback tells to stop the solve process."""
+
+
+def generate_rllibcallback_class(
+    callback: _CallbackWrapper, solver: RayRLlib, classname=None
+) -> Type[BaseRLlibCallback]:
+    if classname is None:
+        classname = f"MyCallbackClass{id(solver)}"
+    return type(
+        classname,
+        (BaseRLlibCallback,),
+        dict(solver=solver, callback=_CallbackWrapper(callback=callback)),
+    )
```

## skdecide/hub/solver/riw/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .riw import RIW
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .riw import RIW
```

## skdecide/hub/solver/riw/riw.py

```diff
@@ -1,193 +1,374 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import os
-import sys
-from typing import Any, Callable, Dict, List, Tuple
-
-from skdecide import Domain, Solver, hub
-from skdecide.builders.domain import (
-    Actions,
-    DeterministicInitialized,
-    Environment,
-    FullyObservable,
-    Markovian,
-    Rewards,
-    Sequential,
-    SingleAgent,
-)
-from skdecide.builders.solver import DeterministicPolicies, ParallelSolver, Utilities
-
-record_sys_path = sys.path
-skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
-if skdecide_cpp_extension_lib_path not in sys.path:
-    sys.path.append(skdecide_cpp_extension_lib_path)
-
-try:
-
-    from __skdecide_hub_cpp import _RIWSolver_ as riw_solver
-
-    class D(
-        Domain,
-        SingleAgent,
-        Sequential,
-        Environment,
-        Actions,
-        DeterministicInitialized,
-        Markovian,
-        FullyObservable,
-        Rewards,
-    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
-        pass
-
-    class RIW(ParallelSolver, Solver, DeterministicPolicies, Utilities):
-        T_domain = D
-
-        def __init__(
-            self,
-            domain_factory: Callable[[], Domain],
-            state_features: Callable[[Domain, D.T_state], Any],
-            use_state_feature_hash: bool = False,
-            use_simulation_domain: bool = False,
-            time_budget: int = 3600000,
-            rollout_budget: int = 100000,
-            max_depth: int = 1000,
-            exploration: float = 0.25,
-            epsilon_moving_average_window: int = 100,
-            epsilon: float = 0.001,
-            discount: float = 1.0,
-            online_node_garbage: bool = False,
-            continuous_planning: bool = True,
-            parallel: bool = False,
-            shared_memory_proxy=None,
-            debug_logs: bool = False,
-            watchdog: Callable[[int, int, float, float], bool] = None,
-        ) -> None:
-            ParallelSolver.__init__(
-                self,
-                domain_factory=domain_factory,
-                parallel=parallel,
-                shared_memory_proxy=shared_memory_proxy,
-            )
-            self._solver = None
-            self._domain = None
-            self._state_features = state_features
-            self._use_state_feature_hash = use_state_feature_hash
-            self._use_simulation_domain = use_simulation_domain
-            self._time_budget = time_budget
-            self._rollout_budget = rollout_budget
-            self._max_depth = max_depth
-            self._exploration = exploration
-            self._epsilon_moving_average_window = epsilon_moving_average_window
-            self._epsilon = epsilon
-            self._discount = discount
-            self._online_node_garbage = online_node_garbage
-            self._continuous_planning = continuous_planning
-            self._debug_logs = debug_logs
-            if watchdog is None:
-                self._watchdog = (
-                    lambda elapsed_time, number_rollouts, best_value, epsilon_moving_average: True
-                )
-            else:
-                self._watchdog = watchdog
-            self._lambdas = [self._state_features]
-            self._ipc_notify = True
-
-        def close(self):
-            """Joins the parallel domains' processes.
-            Not calling this method (or not using the 'with' context statement)
-            results in the solver forever waiting for the domain processes to exit.
-            """
-            if self._parallel:
-                self._solver.close()
-            ParallelSolver.close(self)
-
-        def _init_solve(self, domain_factory: Callable[[], D]) -> None:
-            self._domain_factory = domain_factory
-            self._solver = riw_solver(
-                domain=self.get_domain(),
-                state_features=lambda d, s, i=None: self._state_features(d, s)
-                if not self._parallel
-                else d.call(i, 0, s),
-                use_state_feature_hash=self._use_state_feature_hash,
-                use_simulation_domain=self._use_simulation_domain,
-                time_budget=self._time_budget,
-                rollout_budget=self._rollout_budget,
-                max_depth=self._max_depth,
-                exploration=self._exploration,
-                epsilon_moving_average_window=self._epsilon_moving_average_window,
-                epsilon=self._epsilon,
-                discount=self._discount,
-                online_node_garbage=self._online_node_garbage,
-                parallel=self._parallel,
-                debug_logs=self._debug_logs,
-                watchdog=self._watchdog,
-            )
-            self._solver.clear()
-
-        def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-            self._init_solve(domain_factory)
-
-        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-            self._solver.solve(memory)
-
-        def _is_solution_defined_for(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> bool:
-            return self._solver.is_solution_defined_for(observation)
-
-        def _get_next_action(
-            self, observation: D.T_agent[D.T_observation]
-        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-            if self._continuous_planning or not self._is_solution_defined_for(
-                observation
-            ):
-                self._solve_from(observation)
-            action = self._solver.get_next_action(observation)
-            if action is None:
-                print(
-                    "\x1b[3;33;40m"
-                    + "No best action found in observation "
-                    + str(observation)
-                    + ", applying random action"
-                    + "\x1b[0m"
-                )
-                return self.call_domain_method("get_action_space").sample()
-            else:
-                return action
-
-        def _reset(self) -> None:
-            self._solver.clear()
-
-        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-            return self._solver.get_utility(observation)
-
-        def get_nb_of_explored_states(self) -> int:
-            return self._solver.get_nb_of_explored_states()
-
-        def get_nb_of_pruned_states(self) -> int:
-            return self._solver.get_nb_of_pruned_states()
-
-        def get_nb_rollouts(self) -> int:
-            return self._solver.get_nb_rollouts()
-
-        def get_policy(
-            self,
-        ) -> Dict[
-            D.T_agent[D.T_observation],
-            Tuple[D.T_agent[D.T_concurrency[D.T_event]], float],
-        ]:
-            return self._solver.get_policy()
-
-        def get_action_prefix(self) -> List[D.T_agent[D.T_observation]]:
-            return self._solver.get_action_prefix()
-
-except ImportError:
-    sys.path = record_sys_path
-    print(
-        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
-    )
-    raise
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import os
+import sys
+from typing import Any, Callable, Dict, List, Optional, Tuple
+
+from skdecide import Domain, Solver, hub
+from skdecide.builders.domain import (
+    Actions,
+    DeterministicInitialized,
+    Environment,
+    FullyObservable,
+    Markovian,
+    Rewards,
+    Sequential,
+    SingleAgent,
+)
+from skdecide.builders.solver import (
+    DeterministicPolicies,
+    FromAnyState,
+    ParallelSolver,
+    Utilities,
+)
+
+record_sys_path = sys.path
+skdecide_cpp_extension_lib_path = os.path.abspath(hub.__path__[0])
+if skdecide_cpp_extension_lib_path not in sys.path:
+    sys.path.append(skdecide_cpp_extension_lib_path)
+
+try:
+
+    from __skdecide_hub_cpp import _RIWSolver_ as riw_solver
+
+    class D(
+        Domain,
+        SingleAgent,
+        Sequential,
+        Environment,
+        Actions,
+        DeterministicInitialized,
+        Markovian,
+        FullyObservable,
+        Rewards,
+    ):  # TODO: check why DeterministicInitialized & PositiveCosts/Rewards?
+        pass
+
+    class RIW(ParallelSolver, Solver, DeterministicPolicies, Utilities, FromAnyState):
+        """This is the skdecide implementation of "Planning with Pixels in
+        (Almost) Real Time" by Wilmer Bandres, Blai Bonet, Hector Geffner (AAAI 2018)
+        """
+
+        T_domain = D
+
+        def __init__(
+            self,
+            domain_factory: Callable[[], T_domain],
+            state_features: Callable[[T_domain, D.T_state], Any],
+            use_state_feature_hash: bool = False,
+            use_simulation_domain: bool = False,
+            time_budget: int = 3600000,
+            rollout_budget: int = 100000,
+            max_depth: int = 1000,
+            exploration: float = 0.25,
+            residual_moving_average_window: int = 100,
+            epsilon: float = 0.001,
+            discount: float = 1.0,
+            online_node_garbage: bool = False,
+            continuous_planning: bool = True,
+            parallel: bool = False,
+            shared_memory_proxy=None,
+            callback: Callable[[RIW, Optional[int]], bool] = lambda slv, i=None: False,
+            verbose: bool = False,
+        ) -> None:
+            """Construct a RIW solver instance
+
+            # Parameters
+            domain_factory (Callable[[], T_domain]): The lambda function to create a domain instance.
+            state_features (Callable[[T_domain, D.T_state], Any]): State feature vector
+                used to compute the novelty measure
+            use_state_feature_hash (bool, optional): Boolean indicating whether states
+                must be hashed by using their features (True) or by using their native
+                hash function (False). Defaults to False.
+            use_simulation_domain (bool, optional): Boolean indicating whether the state
+                transitions should be generated by using the `Simulation.sample`
+                method of the domain (True) or the `Environment.step` method of
+                the domain (False) depending on the domain's dynamics capabilities.
+                Defaults to False.
+            time_budget (int, optional): Maximum solving time in milliseconds. Defaults to 3600000.
+            rollout_budget (int, optional): Maximum number of rollouts. Defaults to 100000.
+            max_depth (int, optional): Maximum depth of each RIW trial (rollout). Defaults to 1000.
+            exploration (float, optional): Probability of choosing a non-solved child of
+                a given node (more precisely, a first-time explored child is chosen with a
+                probability 'exploration', and a already-explored but non-solved child is
+                chosen with a probability of '1 - exploration' divided by its novelty
+                measure; probabilities among children are then normalized). Defaults to 0.25.
+            residual_moving_average_window (int, optional): Number of latest computed residual values
+                to memorize in order to compute the average Bellman error (residual) at the root state
+                of the search (deactivated when use_labels is True). Defaults to 100.
+            epsilon (float, optional): Maximum Bellman error (residual) allowed to decide that a state
+                is solved, or to decide when no labels are used that the value function of the root state
+                of the search has converged (in the latter case: the root state's Bellman error is averaged
+                over the residual_moving_average_window, deactivated when use_labels is True). Defaults to 0.001.
+            discount (float, optional): Value function's discount factor. Defaults to 1.0.
+            online_node_garbage (bool, optional): Boolean indicating whether the search graph which is
+                no more reachable from the root solving state should be deleted (True) or not (False). Defaults to False.
+            continuous_planning (bool, optional): Boolean whether the solver should optimize again the policy
+                from the current solving state (True) or not (False) even if the policy is already defined
+                in this state. Defaults to True.
+            parallel (bool, optional): Parallelize RIW rollouts on different processes using duplicated domains (True)
+                or not (False). Defaults to False.
+            shared_memory_proxy (_type_, optional): The optional shared memory proxy. Defaults to None.
+            callback (Callable[[RIW, Optional[int]], optional): Function called at the end of each RIW rollout,
+                taking as arguments the solver and the thread/process ID (i.e. parallel domain ID, which is equal to None
+                in case of sequential execution, i.e. when 'parallel' is set to False in this constructor) from
+                which the callback is called, and returning True if the solver must be stopped. The callback lambda
+                function cannot take the (potentially parallelized) domain as argument because we could not otherwise
+                serialize (i.e. pickle) the solver to pass it to the corresponding parallel domain process in case of parallel
+                execution. Nevertheless, the `ParallelSolver.get_domain` method callable on the solver instance
+                can be used to retrieve either the user domain in sequential execution, or the parallel domains proxy
+                `ParallelDomain` in parallel execution from which domain methods can be called by using the
+                callback's process ID argument. Defaults to (lambda slv, i=None: False).
+            verbose (bool, optional): Boolean indicating whether verbose messages should be logged (True)
+                or not (False). Defaults to False.
+            """
+            ParallelSolver.__init__(
+                self,
+                parallel=parallel,
+                shared_memory_proxy=shared_memory_proxy,
+            )
+            Solver.__init__(self, domain_factory=domain_factory)
+            self._solver = None
+            self._domain = None
+            self._state_features = state_features
+            self._use_state_feature_hash = use_state_feature_hash
+            self._use_simulation_domain = use_simulation_domain
+            self._time_budget = time_budget
+            self._rollout_budget = rollout_budget
+            self._max_depth = max_depth
+            self._exploration = exploration
+            self._residual_moving_average_window = residual_moving_average_window
+            self._epsilon = epsilon
+            self._discount = discount
+            self._online_node_garbage = online_node_garbage
+            self._continuous_planning = continuous_planning
+            self._callback = callback
+            self._verbose = verbose
+            self._lambdas = [self._state_features]
+            self._ipc_notify = True
+
+        def close(self):
+            """Joins the parallel domains' processes.
+
+            !!! warning
+                Not calling this method (or not using the 'with' context statement)
+                results in the solver forever waiting for the domain processes to exit.
+
+            """
+            if self._parallel:
+                self._solver.close()
+            ParallelSolver.close(self)
+
+        def _init_solve(self) -> None:
+            self._solver = riw_solver(
+                solver=self,
+                domain=self.get_domain(),
+                state_features=(
+                    (lambda d, s, i=None: self._state_features(d, s))
+                    if not self._parallel
+                    else (lambda d, s, i=None: d.call(i, 0, s))
+                ),
+                use_state_feature_hash=self._use_state_feature_hash,
+                use_simulation_domain=self._use_simulation_domain,
+                time_budget=self._time_budget,
+                rollout_budget=self._rollout_budget,
+                max_depth=self._max_depth,
+                exploration=self._exploration,
+                residual_moving_average_window=self._residual_moving_average_window,
+                epsilon=self._epsilon,
+                discount=self._discount,
+                online_node_garbage=self._online_node_garbage,
+                parallel=self._parallel,
+                callback=self._callback,
+                verbose=self._verbose,
+            )
+            self._solver.clear()
+
+        def _reset(self) -> None:
+            """Clears the search graph."""
+            self._solver.clear()
+
+        def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
+            """Run the RIW algorithm from a given root solving state
+
+            # Parameters
+            memory (D.T_memory[D.T_state]): State from which to run the RIW algorithm
+                (root of the search graph)
+            """
+            self._solver.solve(memory)
+
+        def _is_solution_defined_for(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> bool:
+            """Indicates whether the solution policy is defined for a given state
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which an entry is searched
+                in the policy graph
+
+            # Returns
+            bool: True if the state has been explored and an action is defined in this state,
+                False otherwise
+            """
+            return self._solver.is_solution_defined_for(observation)
+
+        def _get_next_action(
+            self, observation: D.T_agent[D.T_observation]
+        ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+            """Get the best computed action in terms of best Q-value in a given state. The search
+                subgraph which is no more reachable after executing the returned action is
+                also deleted if node garbage was set to true in the RIW instance's constructor.
+                The solver is run from `observation` if `continuous_planning` was set to True
+                in the RIW instance's constructor or if no solution is defined (i.e. has been
+                previously computed) in `observation`.
+
+            !!! warning
+                Returns a random action if no action is defined in the given state,
+                which is why it is advised to call `RIW.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State for which the best action is requested
+
+            # Returns
+            D.T_agent[D.T_concurrency[D.T_event]]: Best computed action
+            """
+            if self._continuous_planning or not self._is_solution_defined_for(
+                observation
+            ):
+                self._solve_from(observation)
+            action = self._solver.get_next_action(observation)
+            if action is None:
+                print(
+                    "\x1b[3;33;40m"
+                    + "No best action found in observation "
+                    + str(observation)
+                    + ", applying random action"
+                    + "\x1b[0m"
+                )
+                return self.call_domain_method("get_action_space").sample()
+            else:
+                return action
+
+        def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+            """Get the best Q-value in a given state
+
+            !!! warning
+                Returns None if no action is defined in the given state, which is why
+                it is advised to call `RIW.is_solution_defined_for` before
+
+            # Parameters
+            observation (D.T_agent[D.T_observation]): State from which the best Q-value is requested
+
+            # Returns
+            D.T_value: Maximum Q-value of the given state over the applicable actions in this state
+            """
+            return self._solver.get_utility(observation)
+
+        def get_nb_explored_states(self) -> int:
+            """Get the number of states present in the search graph (which can be
+                lower than the number of actually explored states if node garbage was
+                set to True in the RIW instance's constructor)
+
+            # Returns
+            int: Number of states present in the search graph
+            """
+            return self._solver.get_nb_explored_states()
+
+        def get_nb_pruned_states(self) -> int:
+            """Get the number of states present in the search graph that have been
+                pruned by the novelty test (which can be lower than the number of actually
+                explored states if node garbage was set to True in the RIWSolver
+                instance's constructor)
+
+            # Returns
+            int: Number of states present in the search graph that have been pruned by
+                the novelty test
+            """
+            return self._solver.get_nb_pruned_states()
+
+        def get_exploration_statistics(self) -> int:
+            """Get the exploration statistics as number of states present in the
+                search graph and number of such states that have been pruned by the novelty
+                test (both statistics can be lower than the number of actually
+                explored states if node garbage was set to True in the RIWSolver
+                instance's constructor)
+
+            # Returns
+            int: Pair of number of states present in the search graph and of number of
+                such states that have been pruned by the novelty test
+            """
+            return self._solver.get_nb_pruned_states()
+
+        def get_nb_rollouts(self) -> int:
+            """Get the number of rollouts since the beginning of the search from
+                the root solving state
+
+            # Returns
+            int: Number of RIW rollouts
+            """
+            return self._solver.get_nb_rollouts()
+
+        def get_residual_moving_average(self) -> float:
+            """Get the average Bellman error (residual) at the root state of the search,
+                or an infinite value if the number of computed residuals is lower than
+                the epsilon moving average window set in the RIW instance's constructor
+
+            # Returns
+            float: Bellman error at the root state of the search averaged over
+                the epsilon moving average window
+            """
+            return self._solver.get_residual_moving_average()
+
+        def get_solving_time(self) -> int:
+            """Get the solving time in milliseconds since the beginning of the
+                search from the root solving state
+
+            # Returns
+            int: Solving time in milliseconds
+            """
+            return self._solver.get_solving_time()
+
+        def get_policy(
+            self,
+        ) -> Dict[
+            D.T_agent[D.T_observation],
+            Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value],
+        ]:
+            """Get the (partial) solution policy defined for the states for which
+                the Q-value has been updated at least once (which is optimal if the
+                algorithm has converged and labels are used)
+
+            !!! warning
+                Only defined over the states reachable from the last root solving state
+                when node garbage was set to True in the RIW instance's constructor
+
+            # Returns
+            Dict[ D.T_agent[D.T_observation], Tuple[D.T_agent[D.T_concurrency[D.T_event]], D.T_value], ]:
+                Mapping from states to pairs of action and best Q-value
+            """
+            return self._solver.get_policy()
+
+        def get_action_prefix(self) -> List[D.T_agent[D.T_observation]]:
+            """Get the list of actions returned by the solver so far after each
+                call to the RIW.get_next_action method (mostly internal use in order
+                to rebuild the sequence of visited states until reaching the current
+                solving state, when 'use_simulation_domain' was set to False in the
+                RIW instance's constructor for which we can only progress the
+                transition function with steps that hide the current state of the environment)
+
+            # Returns
+            List[D.T_agent[D.T_observation]]: List of actions executed by the solver
+                so far after each call to the `RIW.get_next_action` method
+            """
+            return self._solver.get_action_prefix()
+
+except ImportError:
+    sys.path = record_sys_path
+    print(
+        'Scikit-decide C++ hub library not found. Please check it is installed in "skdecide/hub".'
+    )
+    raise
```

## skdecide/hub/solver/simple_greedy/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .simple_greedy import SimpleGreedy
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .simple_greedy import SimpleGreedy
```

## skdecide/hub/solver/simple_greedy/simple_greedy.py

```diff
@@ -1,60 +1,60 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Callable
-
-from skdecide import DeterministicPolicySolver, Domain, EnumerableSpace, Memory
-from skdecide.builders.domain import EnumerableTransitions, FullyObservable, SingleAgent
-
-
-class D(Domain, SingleAgent, EnumerableTransitions, FullyObservable):
-    pass
-
-
-class SimpleGreedy(DeterministicPolicySolver):
-    T_domain = D
-
-    @classmethod
-    def _check_domain_additional(cls, domain: D) -> bool:
-        return isinstance(domain.get_action_space(), EnumerableSpace)
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self._domain = (
-            domain_factory()
-        )  # no further solving code required here since everything is computed online
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        # This solver selects the first action with the highest expected immediate reward (greedy)
-        domain = self._domain
-        memory = Memory(
-            [observation]
-        )  # note: observation == state (because FullyObservable)
-        applicable_actions = domain.get_applicable_actions(memory)
-        if domain.is_transition_value_dependent_on_next_state():
-            values = []
-            for a in applicable_actions.get_elements():
-                next_state_prob = domain.get_next_state_distribution(
-                    memory, [a]
-                ).get_values()
-                expected_value = sum(
-                    p * domain.get_transition_value(memory, [a], s).reward
-                    for s, p in next_state_prob
-                )
-                values.append(expected_value)
-        else:
-            values = [
-                domain.get_transition_value(memory, a).reward
-                for a in applicable_actions
-            ]
-        argmax = max(range(len(values)), key=lambda i: values[i])
-        return [
-            applicable_actions.get_elements()[argmax]
-        ]  # list of action here because we handle Parallel domains
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Callable
+
+from skdecide import DeterministicPolicySolver, Domain, EnumerableSpace, Memory
+from skdecide.builders.domain import EnumerableTransitions, FullyObservable, SingleAgent
+
+
+class D(Domain, SingleAgent, EnumerableTransitions, FullyObservable):
+    pass
+
+
+class SimpleGreedy(DeterministicPolicySolver):
+    T_domain = D
+
+    @classmethod
+    def _check_domain_additional(cls, domain: D) -> bool:
+        return isinstance(domain.get_action_space(), EnumerableSpace)
+
+    def _solve(self) -> None:
+        self._domain = (
+            self._domain_factory()
+        )  # no further solving code required here since everything is computed online
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        # This solver selects the first action with the highest expected immediate reward (greedy)
+        domain = self._domain
+        memory = Memory(
+            [observation]
+        )  # note: observation == state (because FullyObservable)
+        applicable_actions = domain.get_applicable_actions(memory)
+        if domain.is_transition_value_dependent_on_next_state():
+            values = []
+            for a in applicable_actions.get_elements():
+                next_state_prob = domain.get_next_state_distribution(
+                    memory, [a]
+                ).get_values()
+                expected_value = sum(
+                    p * domain.get_transition_value(memory, [a], s).reward
+                    for s, p in next_state_prob
+                )
+                values.append(expected_value)
+        else:
+            values = [
+                domain.get_transition_value(memory, a).reward
+                for a in applicable_actions
+            ]
+        argmax = max(range(len(values)), key=lambda i: values[i])
+        return [
+            applicable_actions.get_elements()[argmax]
+        ]  # list of action here because we handle Parallel domains
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
```

## skdecide/hub/solver/stable_baselines/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .stable_baselines import StableBaseline
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .stable_baselines import StableBaseline
```

## skdecide/hub/solver/stable_baselines/stable_baselines.py

```diff
@@ -1,99 +1,143 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Callable, Dict
-
-from stable_baselines3.common.vec_env import DummyVecEnv
-
-from skdecide import Domain, Solver
-from skdecide.builders.domain import (
-    Initializable,
-    Sequential,
-    SingleAgent,
-    UnrestrictedActions,
-)
-from skdecide.builders.solver import Policies, Restorable
-from skdecide.hub.domain.gym import AsGymnasiumEnv
-from skdecide.hub.space.gym import GymSpace
-
-
-class D(Domain, SingleAgent, Sequential, UnrestrictedActions, Initializable):
-    pass
-
-
-class StableBaseline(Solver, Policies, Restorable):
-    """This class wraps a stable OpenAI Baselines solver (stable_baselines3) as a scikit-decide solver.
-
-    !!! warning
-        Using this class requires Stable Baselines 3 to be installed.
-    """
-
-    T_domain = D
-
-    def __init__(
-        self,
-        algo_class: type,
-        baselines_policy: Any,
-        learn_config: Dict = None,
-        **kwargs: Any,
-    ) -> None:
-        """Initialize StableBaselines.
-
-        # Parameters
-        algo_class: The class of Baselines solver (stable_baselines3) to wrap.
-        baselines_policy: The class of Baselines policy network (stable_baselines3.common.policies or str) to use.
-        """
-        self._algo_class = algo_class
-        self._baselines_policy = baselines_policy
-        self._learn_config = learn_config if learn_config is not None else {}
-        self._algo_kwargs = kwargs
-
-    @classmethod
-    def _check_domain_additional(cls, domain: Domain) -> bool:
-        return isinstance(domain.get_action_space(), GymSpace) and isinstance(
-            domain.get_observation_space(), GymSpace
-        )
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        # TODO: improve code for parallelism
-        #  (https://stable-baselines3.readthedocs.io/en/master/guide/examples.html
-        #  #multiprocessing-unleashing-the-power-of-vectorized-environments)?
-        if not hasattr(
-            self, "_algo"
-        ):  # reuse algo if possible (enables further learning)
-            domain = domain_factory()
-            env = DummyVecEnv(
-                [lambda: AsGymnasiumEnv(domain)]
-            )  # the algorithms require a vectorized environment to run
-            self._algo = self._algo_class(
-                self._baselines_policy, env, **self._algo_kwargs
-            )
-            self._init_algo(domain)
-        self._algo.learn(**self._learn_config)
-
-    def _sample_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        action, _ = self._algo.predict(self._unwrap_obs(observation))
-        return self._wrap_action(action)
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
-
-    def _save(self, path: str) -> None:
-        self._algo.save(path)
-
-    def _load(self, path: str, domain_factory: Callable[[], D]):
-        self._algo = self._algo_class.load(path)
-        self._init_algo(domain_factory())
-
-    def _init_algo(self, domain: D):
-        self._wrap_action = lambda a: next(
-            iter(domain.get_action_space().from_unwrapped([a]))
-        )
-        self._unwrap_obs = lambda o: next(
-            iter(domain.get_observation_space().to_unwrapped([o]))
-        )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Callable, Dict, Optional, Type, Union
+
+from stable_baselines3.common.base_class import BaseAlgorithm
+from stable_baselines3.common.callbacks import BaseCallback, ConvertCallback
+from stable_baselines3.common.policies import BasePolicy
+from stable_baselines3.common.type_aliases import MaybeCallback
+from stable_baselines3.common.vec_env import DummyVecEnv
+
+from skdecide import Domain, Solver
+from skdecide.builders.domain import (
+    Initializable,
+    Sequential,
+    SingleAgent,
+    UnrestrictedActions,
+)
+from skdecide.builders.solver import Policies, Restorable
+from skdecide.hub.domain.gym import AsGymnasiumEnv
+from skdecide.hub.space.gym import GymSpace
+
+
+class D(Domain, SingleAgent, Sequential, UnrestrictedActions, Initializable):
+    pass
+
+
+class StableBaseline(Solver, Policies, Restorable):
+    """This class wraps a stable OpenAI Baselines solver (stable_baselines3) as a scikit-decide solver.
+
+    !!! warning
+        Using this class requires Stable Baselines 3 to be installed.
+    """
+
+    T_domain = D
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        algo_class: Type[BaseAlgorithm],
+        baselines_policy: Union[str, Type[BasePolicy]],
+        learn_config: Optional[Dict[str, Any]] = None,
+        callback: Callable[[StableBaseline], bool] = lambda solver: False,
+        **kwargs: Any,
+    ) -> None:
+        """Initialize StableBaselines.
+
+        # Parameters
+        domain_factory: A callable with no argument returning the domain to solve (can be a mere domain class).
+            The resulting domain will be auto-cast to the level expected by the solver.
+        algo_class: The class of Baselines solver (stable_baselines3) to wrap.
+        baselines_policy: The class of Baselines policy network (stable_baselines3.common.policies or str) to use.
+        learn_config: the kwargs passed to sb3 algo's `learn()` method
+        callback: function called at each solver iteration. If returning true, the solve process stops.
+
+        """
+        Solver.__init__(self, domain_factory=domain_factory)
+        self._algo_class = algo_class
+        self._baselines_policy = baselines_policy
+        self._learn_config = learn_config if learn_config is not None else {}
+        self._algo_kwargs = kwargs
+        self.callback = callback
+
+    @classmethod
+    def _check_domain_additional(cls, domain: Domain) -> bool:
+        return isinstance(domain.get_action_space(), GymSpace) and isinstance(
+            domain.get_observation_space(), GymSpace
+        )
+
+    def _solve(self) -> None:
+        # TODO: improve code for parallelism
+        #  (https://stable-baselines3.readthedocs.io/en/master/guide/examples.html
+        #  #multiprocessing-unleashing-the-power-of-vectorized-environments)?
+        if not hasattr(
+            self, "_algo"
+        ):  # reuse algo if possible (enables further learning)
+            domain = self._domain_factory()
+            env = DummyVecEnv(
+                [lambda: AsGymnasiumEnv(domain)]
+            )  # the algorithms require a vectorized environment to run
+            self._algo = self._algo_class(
+                self._baselines_policy, env, **self._algo_kwargs
+            )
+            self._init_algo(domain)
+
+        # Add user callback to list of callbacks in learn_config
+        learn_config = dict(self._learn_config)
+        callbacks_list: MaybeCallback = learn_config.get("callback", [])
+        if callbacks_list is None:
+            callbacks_list = []
+        if isinstance(callbacks_list, BaseCallback):
+            callbacks_list = [callbacks_list]
+        elif not isinstance(callbacks_list, list):
+            callbacks_list = [ConvertCallback(callbacks_list)]
+        callbacks_list.append(Sb3Callback(callback=self.callback, solver=self))
+        learn_config["callback"] = callbacks_list
+
+        self._algo.learn(**learn_config)
+
+    def _sample_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        action, _ = self._algo.predict(self._unwrap_obs(observation))
+        return self._wrap_action(action)
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
+
+    def _save(self, path: str) -> None:
+        self._algo.save(path)
+
+    def _load(self, path: str):
+        domain = self._domain_factory()
+        env = DummyVecEnv([lambda: AsGymnasiumEnv(domain)])
+        self._algo = self._algo_class.load(path, env=env)
+        self._init_algo(domain)
+
+    def _init_algo(self, domain: D):
+        self._wrap_action = lambda a: next(
+            iter(domain.get_action_space().from_unwrapped([a]))
+        )
+        self._unwrap_obs = lambda o: next(
+            iter(domain.get_observation_space().to_unwrapped([o]))
+        )
+
+    def get_policy(self) -> BasePolicy:
+        """Return the computed policy."""
+        return self._algo.policy
+
+
+class Sb3Callback(BaseCallback):
+    def __init__(
+        self, callback: Callable[[StableBaseline], bool], solver: StableBaseline
+    ):
+        super().__init__()
+        self.solver = solver
+        self.callback = callback
+
+    def _on_step(self) -> bool:
+        return not self.callback(self.solver)
```

## skdecide/hub/solver/up/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .up import UPSolver
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .up import UPSolver
```

## skdecide/hub/solver/up/up.py

```diff
@@ -1,96 +1,105 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Callable, Dict, List
-
-from unified_planning.engines import Engine
-from unified_planning.exceptions import UPValueError
-from unified_planning.shortcuts import FluentExp, SequentialSimulator
-
-from skdecide import Solver, Value
-from skdecide.builders.solver import DeterministicPolicies, Utilities
-from skdecide.hub.domain.up import SkUPAction, SkUPState, UPDomain
-
-
-# TODO: remove Markovian req?
-class D(UPDomain):
-    pass
-
-
-class UPSolver(Solver, DeterministicPolicies, Utilities):
-    """This class wraps a Unified Planning engine as a scikit-decide solver.
-
-    !!! warning
-        Using this class requires unified-planning[engine] to be installed.
-    """
-
-    T_domain = D
-
-    def __init__(
-        self,
-        operation_mode: Engine,
-        engine_params: Dict[str, Any] = {},
-        **operation_mode_params,
-    ) -> None:
-        """Initialize UPSolver.
-
-        # Parameters
-        operation_mode: UP operation mode class.
-        engine_params: The optional dict parameters to pass to the UP engine's solve method.
-        operation_mode_params: The optional dict parameters to pass to the constructor of the UP operation mode object.
-        """
-        super().__init__()
-        self._operation_mode = operation_mode
-        self._operation_mode_params = operation_mode_params
-        self._engine_params = engine_params
-        self._plan = []
-        self._policy = {}
-        self._values = {}
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self._domain = domain_factory()
-        problem = self._domain._problem
-        om_params = (
-            self._operation_mode_params
-            if len(self._operation_mode_params) > 0
-            else {"problem_kind": problem.kind}
-        )
-        with self._operation_mode(**om_params) as planner:
-            result = planner.solve(problem, **self._engine_params)
-            self._plan = [SkUPAction(a) for a in result.plan.actions]
-            plan_extractor_domain = domain_factory()
-            state = plan_extractor_domain.get_initial_state()
-            self._values[state] = Value(cost=0)
-            plan_cost = Value(cost=0)
-            state_sequence = [state]
-            for ai in self._plan:
-                self._policy[state] = ai
-                next_state = plan_extractor_domain.get_next_state(state, ai)
-                transition_cost = plan_extractor_domain.get_transition_value(
-                    state, ai, next_state
-                )
-                plan_cost = Value(cost=plan_cost.cost + transition_cost.cost)
-                self._values[next_state] = plan_cost
-                state_sequence.append(next_state)
-                state = next_state
-            for state in state_sequence:
-                self._values[state] = Value(
-                    cost=plan_cost.cost - self._values[state].cost
-                )
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        return self._policy[observation]
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return observation in self._policy
-
-    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
-        return self._values[observation]
-
-    def get_plan(self) -> List[SkUPAction]:
-        return self._plan
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Callable, Dict, List, Optional
+
+from unified_planning.engines import Engine
+from unified_planning.exceptions import UPValueError
+from unified_planning.shortcuts import FluentExp, SequentialSimulator
+
+from skdecide import Domain, Solver, Value
+from skdecide.builders.solver import DeterministicPolicies, Utilities
+from skdecide.hub.domain.up import SkUPAction, SkUPState, UPDomain
+
+
+# TODO: remove Markovian req?
+class D(UPDomain):
+    pass
+
+
+class UPSolver(Solver, DeterministicPolicies, Utilities):
+    """This class wraps a Unified Planning engine as a scikit-decide solver.
+
+    !!! warning
+        Using this class requires unified-planning[engine] to be installed.
+    """
+
+    T_domain = D
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+        operation_mode: Engine,
+        engine_params: Optional[Dict[str, Any]] = None,
+        **operation_mode_params,
+    ) -> None:
+        """Initialize UPSolver.
+
+        # Parameters
+        operation_mode: UP operation mode class.
+        engine_params: The optional dict parameters to pass to the UP engine's solve method.
+        operation_mode_params: The optional dict parameters to pass to the constructor of the UP operation mode object.
+        """
+        Solver.__init__(self, domain_factory=domain_factory)
+        self._operation_mode = operation_mode
+        self._operation_mode_params = operation_mode_params
+        if engine_params is None:
+            self._engine_params = {}
+        else:
+            self._engine_params = engine_params
+        self._plan = []
+        self._policy = {}
+        self._values = {}
+
+    def _solve(self) -> None:
+        self._domain = self._domain_factory()
+        problem = self._domain._problem
+        om_params = (
+            self._operation_mode_params
+            if len(self._operation_mode_params) > 0
+            else {"problem_kind": problem.kind}
+        )
+        with self._operation_mode(**om_params) as planner:
+            result = planner.solve(problem, **self._engine_params)
+            self._plan = [SkUPAction(a) for a in result.plan.actions]
+            plan_extractor_domain = self._domain_factory()
+            state = plan_extractor_domain.get_initial_state()
+            self._values[state] = Value(cost=0)
+            plan_cost = Value(cost=0)
+            state_sequence = [state]
+            for ai in self._plan:
+                self._policy[state] = ai
+                next_state = plan_extractor_domain.get_next_state(state, ai)
+                transition_cost = plan_extractor_domain.get_transition_value(
+                    state, ai, next_state
+                )
+                plan_cost = Value(cost=plan_cost.cost + transition_cost.cost)
+                self._values[next_state] = plan_cost
+                state_sequence.append(next_state)
+                state = next_state
+            for state in state_sequence:
+                self._values[state] = Value(
+                    cost=plan_cost.cost - self._values[state].cost
+                )
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        return self._policy[observation]
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return observation in self._policy
+
+    def _get_utility(self, observation: D.T_agent[D.T_observation]) -> D.T_value:
+        return self._values[observation]
+
+    def get_policy(self) -> Dict[D.T_agent[D.T_observation], SkUPAction]:
+        """Return the computed policy."""
+        return self._policy
+
+    def get_plan(self) -> List[SkUPAction]:
+        """Return the computed plan."""
+        return self._plan
```

## skdecide/hub/space/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
```

## skdecide/hub/space/gym/__init__.py

 * *Ordering differences only*

```diff
@@ -1,17 +1,17 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from .gym import (
-    BoxSpace,
-    DataSpace,
-    DictSpace,
-    DiscreteSpace,
-    EnumSpace,
-    GymSpace,
-    ListSpace,
-    MultiBinarySpace,
-    MultiDiscreteSpace,
-    SetSpace,
-    TupleSpace,
-)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from .gym import (
+    BoxSpace,
+    DataSpace,
+    DictSpace,
+    DiscreteSpace,
+    EnumSpace,
+    GymSpace,
+    ListSpace,
+    MultiBinarySpace,
+    MultiDiscreteSpace,
+    SetSpace,
+    TupleSpace,
+)
```

## skdecide/hub/space/gym/gym.py

 * *Ordering differences only*

```diff
@@ -1,511 +1,511 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import itertools
-from dataclasses import asdict
-from enum import EnumMeta
-from typing import Any, Dict, Generic, Iterable, List, Sequence, Tuple, Union
-
-import gymnasium as gym
-import gymnasium.spaces as gym_spaces
-import numpy as np
-
-from skdecide import EnumerableSpace, SamplableSpace, SerializableSpace, T
-
-
-class GymSpace(Generic[T], SamplableSpace[T], SerializableSpace[T]):
-    """This class wraps a gymnasium space (gym.spaces) as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, gym_space: gym.Space) -> None:
-        """Initialize GymSpace.
-
-        # Parameters
-        gym_space: The Gym space (gym.spaces) to wrap.
-        """
-        super().__init__()
-        self._gym_space = gym_space
-        self.shape = gym_space.shape  # TODO: remove if unnecessary?
-        self.dtype = gym_space.dtype  # TODO: remove if unnecessary?
-
-    def contains(self, x: T) -> bool:
-        return self._gym_space.contains(x)
-
-    def sample(self) -> T:
-        return self._gym_space.sample()
-
-    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
-        return self._gym_space.to_jsonable(sample_n)
-
-    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
-        return self._gym_space.from_jsonable(sample_n)
-
-    def unwrapped(self) -> gym.Space:
-        """Unwrap the Gym space (gym.spaces) and return it.
-
-        # Returns
-        The original Gym space.
-        """
-        return self._gym_space
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
-        return sample_n
-
-    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
-        return sample_n
-
-
-class BoxSpace(GymSpace[T]):
-    """This class wraps a gymnasium Box space (gym.spaces.Box) as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, low, high, shape=None, dtype=np.float32):
-        super().__init__(gym_space=gym_spaces.Box(low, high, shape, dtype))
-
-
-class DiscreteSpace(GymSpace[T], EnumerableSpace[T]):
-    """This class wraps a gymnasium Discrete space (gym.spaces.Discrete) as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, n, element_class=int):
-        super().__init__(gym_space=gym_spaces.Discrete(n))
-        self._element_class = element_class
-
-    def get_elements(self) -> Iterable[T]:
-        """Get the elements of this space.
-
-        # Returns
-        The elements of this space.
-        """
-        return np.array(list(range(self._gym_space.n)), dtype=np.int64)
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
-        return (
-            sample_n
-            if self._element_class is int
-            else [int(sample) for sample in sample_n]
-        )
-
-    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
-        return (
-            sample_n
-            if self._element_class is int
-            else [self._element_class(sample) for sample in sample_n]
-        )
-
-
-class MultiDiscreteSpace(GymSpace[T], EnumerableSpace[T]):
-    """This class wraps a gymnasium MultiDiscrete space (gym.spaces.MultiDiscrete) as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, nvec, element_class=np.ndarray):
-        super().__init__(gym_space=gym_spaces.MultiDiscrete(nvec))
-        self._element_class = element_class
-
-    def get_elements(self) -> Iterable[T]:
-        """Get the elements of this space.
-
-        # Returns
-        The elements of this space.
-        """
-        return np.array(
-            list(itertools.product(*[list(range(n)) for n in self._gym_space.nvec])),
-            dtype=np.int64,
-        )
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
-        return (
-            sample_n
-            if self._element_class is np.ndarray
-            else [np.asarray(sample, dtype=np.int64) for sample in sample_n]
-        )
-
-    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
-        return (
-            sample_n
-            if self._element_class is np.ndarray
-            else [self._element_class(sample) for sample in sample_n]
-        )
-
-
-class MultiBinarySpace(GymSpace[T], EnumerableSpace[T]):
-    """This class wraps a gymnasium MultiBinary space (gym.spaces.MultiBinary) as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, n, element_class=np.ndarray):
-        super().__init__(gym_space=gym_spaces.MultiBinary(n))
-        self._element_class = element_class
-
-    def get_elements(self) -> Iterable[T]:
-        """Get the elements of this space.
-
-        # Returns
-        The elements of this space.
-        """
-        return np.array(
-            list(itertools.product(*[(1, 0) for _ in range(self._gym_space.n)])),
-            dtype=np.int8,
-        )
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
-        return (
-            sample_n
-            if self._element_class is np.ndarray
-            else [np.asarray(sample, dtype=np.bool_).astype(int) for sample in sample_n]
-        )
-
-    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
-        return (
-            sample_n
-            if self._element_class is np.ndarray
-            else [self._element_class(sample) for sample in sample_n]
-        )
-
-
-class TupleSpace(GymSpace[T]):
-    """This class wraps a gymnasium Tuple space (gym.spaces.Tuple) as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(
-        self, spaces: Tuple[Union[GymSpace[T], gym.Space]], element_class=tuple
-    ):
-        super().__init__(
-            gym_space=gym_spaces.Tuple(
-                [sp if isinstance(sp, gym.Space) else sp.unwrapped() for sp in spaces]
-            )
-        )
-        self._spaces = spaces
-        self._element_class = element_class
-        assert element_class is tuple or all(
-            m in dir(element_class) for m in ["to_tuple", "from_tuple"]
-        ), "Tuple space's element class must be of type tuple or it must provide the to_tuple and from_tuple methods"
-        self._to_tuple = (
-            (lambda e: e) if element_class is tuple else (lambda e: e.to_tuple())
-        )
-        self._from_tuple = (
-            (lambda e: e)
-            if element_class is tuple
-            else (lambda e: self._element_class.from_tuple(e))
-        )
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
-        return [
-            tuple(
-                next(iter(self._spaces[i].to_unwrapped([e])))
-                if isinstance(self._spaces[i], GymSpace)
-                else e
-                for i, e in enumerate(self._to_tuple(sample))
-            )
-            for sample in sample_n
-        ]
-
-    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
-        return [
-            self._from_tuple(
-                tuple(
-                    next(iter(self._spaces[i].from_unwrapped([e])))
-                    if isinstance(self._spaces[i], GymSpace)
-                    else e
-                    for i, e in enumerate(sample)
-                )
-            )
-            for sample in sample_n
-        ]
-
-
-class DictSpace(GymSpace[T]):
-    """This class wraps a gymnasium Dict space (gym.spaces.Dict) as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(
-        self,
-        spaces: Dict[Any, Union[GymSpace[T], gym.Space]] = None,
-        element_class=dict,
-        **spaces_kwargs,
-    ):
-        super().__init__(
-            gym_space=gym_spaces.Dict(
-                {
-                    k: sp if isinstance(sp, gym.Space) else sp.unwrapped()
-                    for k, sp in spaces.items()
-                },
-                **spaces_kwargs,
-            )
-        )
-        self._spaces = spaces
-        self._element_class = element_class
-        assert element_class is dict or all(
-            m in dir(element_class) for m in ["to_dict", "from_dict"]
-        ), "Dict space's element class must be of type dict or it must provide the to_dict and from_dict methods"
-        self._to_dict = (
-            (lambda e: e) if element_class is dict else (lambda e: e.to_dict())
-        )
-        self._from_dict = (
-            (lambda e: e)
-            if element_class is dict
-            else (lambda e: self._element_class.from_dict(e))
-        )
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
-        return [
-            {
-                k: next(iter(self._spaces[k].to_unwrapped([e])))
-                if isinstance(self._spaces[k], GymSpace)
-                else e
-                for k, e in self._to_dict(sample).items()
-            }
-            for sample in sample_n
-        ]
-
-    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
-        return [
-            self._from_dict(
-                {
-                    k: next(iter(self._spaces[k].from_unwrapped([e])))
-                    if isinstance(self._spaces[k], GymSpace)
-                    else e
-                    for k, e in sample.items()
-                }
-            )
-            for sample in sample_n
-        ]
-
-
-class EnumSpace(Generic[T], GymSpace[T], EnumerableSpace[T]):
-    """This class creates a gymnasium Discrete space (gym.spaces.Discrete) from an enumeration and wraps it as a
-    scikit-decide enumerable space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, enum_class: EnumMeta) -> None:
-        """Initialize EnumSpace.
-
-        # Parameters
-        enum_class: The enumeration class for creating the Gym Discrete space (gym.spaces.Discrete) to wrap.
-        """
-        self._enum_class = enum_class
-        self._list_enum = list(enum_class)
-        gym_space = gym_spaces.Discrete(len(enum_class))
-        super().__init__(gym_space)
-
-    def contains(self, x: T) -> bool:
-        return isinstance(x, self._enum_class)
-
-    def get_elements(self) -> Iterable[T]:
-        return self._list_enum
-
-    def sample(self) -> T:
-        return self._list_enum[super().sample()]
-
-    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
-        return [sample.name for sample in sample_n]
-
-    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
-        return [self._enum_class[sample] for sample in sample_n]
-
-    def unwrapped(self) -> gym_spaces.Discrete:
-        """Unwrap the Gym Discrete space (gym.spaces.Discrete) and return it.
-
-        # Returns
-        The original Gym Discrete space created from the enumeration.
-        """
-        return super().unwrapped()
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[int]:
-        return [self._list_enum.index(sample) for sample in sample_n]
-
-    def from_unwrapped(self, sample_n: Iterable[int]) -> Iterable[T]:
-        return [self._list_enum[sample] for sample in sample_n]
-
-
-class ListSpace(Generic[T], GymSpace[T], EnumerableSpace[T]):
-    """This class creates a gymnasium Discrete space (gym.spaces.Discrete) from a list of elements and wraps it as a
-    scikit-decide enumerable space. If ordering is not important contrary to the 'contains' test, it is advised to
-    use the 'SetSpace' class instead.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, elements: Iterable[T]) -> None:
-        """Initialize ListSpace.
-
-        # Parameters
-        elements: The list of elements for creating the Gym Discrete space (gym.spaces.Discrete) to wrap.
-        """
-        self._elements = list(elements)
-        gym_space = gym_spaces.Discrete(len(self._elements))
-        super().__init__(gym_space)
-
-    def contains(self, x: T) -> bool:
-        return x in self._elements
-
-    def get_elements(self) -> Iterable[T]:
-        return self._elements
-
-    def sample(self) -> T:
-        return self._elements[super().sample()]
-
-    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
-        return sample_n
-
-    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
-        return sample_n
-
-    def unwrapped(self) -> gym_spaces.Discrete:
-        """Unwrap the Gym Discrete space (gym.spaces.Discrete) and return it.
-
-        # Returns
-        The original Gym Discrete space created from the list.
-        """
-        return super().unwrapped()
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[int]:
-        return [self._elements.index(sample) for sample in sample_n]
-
-    def from_unwrapped(self, sample_n: Iterable[int]) -> Iterable[T]:
-        return [self._elements[sample] for sample in sample_n]
-
-
-class SetSpace(Generic[T], GymSpace[T], EnumerableSpace[T]):
-    """This class creates a gymnasium Discrete space (gym.spaces.Discrete) from a set of elements and wraps it as a
-    scikit-decide enumerable space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(self, elements: Iterable[T]) -> None:
-        """Initialize SetSpace.
-
-        # Parameters
-        elements: The set of elements for creating the Gym Discrete space (gym.spaces.Discrete) to wrap.
-        """
-        self._elements = set(elements)
-        self._to_indexes = {e: i for i, e in enumerate(self._elements)}
-        self._to_elements = [e for e in self._elements]
-        gym_space = gym_spaces.Discrete(len(self._elements))
-        super().__init__(gym_space)
-
-    def contains(self, x: T) -> bool:
-        return x in self._elements
-
-    def get_elements(self) -> Iterable[T]:
-        return self._elements
-
-    def sample(self) -> T:
-        return self._to_elements[super().sample()]
-
-    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
-        return sample_n
-
-    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
-        return sample_n
-
-    def unwrapped(self) -> gym_spaces.Discrete:
-        """Unwrap the Gym Discrete space (gym.spaces.Discrete) and return it.
-
-        # Returns
-        The original Gym Discrete space created from the list.
-        """
-        return super().unwrapped()
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[int]:
-        return [self._to_indexes[sample] for sample in sample_n]
-
-    def from_unwrapped(self, sample_n: Iterable[int]) -> Iterable[T]:
-        return [self._to_elements[sample] for sample in sample_n]
-
-
-class DataSpace(GymSpace[T]):
-    """This class creates a gymnasium Dict space (gym.spaces.Dict) from a dataclass and wraps it as a scikit-decide space.
-
-    !!! warning
-        Using this class requires gymnasium to be installed.
-    """
-
-    def __init__(
-        self,
-        data_class: type,
-        spaces: Union[Dict[str, gym.Space], List[Tuple[str, gym.Space]]],
-    ) -> None:
-        """Initialize DataSpace.
-
-        # Parameters
-        data_class: The dataclass for creating the Gym Dict space (gym.spaces.Dict) to wrap.
-        spaces: The spaces description passed to the created Dict space (see gym.spaces.Dict constructor documentation).
-
-        # Example
-        ```python
-        from skdecide.wrappers.space import DataSpace
-
-        @dataclass(frozen=True)
-        class Action:
-            position: int
-            velocity: int
-
-        my_action_space = DataSpace(Action, {"position": gym.spaces.Discrete(2), "velocity": gym.spaces.Discrete(3)})
-        ```
-        """
-        self._data_class = data_class
-        gym_space = gym_spaces.Dict(spaces)
-        super().__init__(gym_space)
-
-    def contains(self, x: T) -> bool:
-        # works even when fields of the dataclass have been recast (e.g. numpy 0-dimensional array to scalar)
-        return super().contains(super().from_jsonable(self.to_jsonable([x]))[0])
-        # # bug: does not work when fields of the dataclass have been recast (e.g. numpy 0-dimensional array to scalar)
-        # return super().contains(asdict(x))
-
-    def sample(self) -> T:
-        # TODO: convert to simple types (get rid of ndarray created by gym dict space...)?
-        return self._data_class(**super().sample())
-
-    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
-        dict_sample_n = self.to_unwrapped(sample_n)
-        return super().to_jsonable(dict_sample_n)
-
-    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
-        dict_sample_n = super().from_jsonable(sample_n)
-        return self.from_unwrapped(dict_sample_n)
-
-    def unwrapped(self) -> gym_spaces.Dict:
-        """Unwrap the Gym Dict space (gym.spaces.Dict) and return it.
-
-        # Returns
-        The original Gym Dict space created from the dataclass.
-        """
-        return super().unwrapped()
-
-    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[Dict]:
-        return [asdict(sample) for sample in sample_n]
-
-    def from_unwrapped(self, sample_n: Iterable[Dict]) -> Iterable[T]:
-        # TODO: convert to simple types (get rid of ndarray created by gym dict space...)?
-        return [self._data_class(**sample) for sample in sample_n]
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import itertools
+from dataclasses import asdict
+from enum import EnumMeta
+from typing import Any, Dict, Generic, Iterable, List, Sequence, Tuple, Union
+
+import gymnasium as gym
+import gymnasium.spaces as gym_spaces
+import numpy as np
+
+from skdecide import EnumerableSpace, SamplableSpace, SerializableSpace, T
+
+
+class GymSpace(Generic[T], SamplableSpace[T], SerializableSpace[T]):
+    """This class wraps a gymnasium space (gym.spaces) as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, gym_space: gym.Space) -> None:
+        """Initialize GymSpace.
+
+        # Parameters
+        gym_space: The Gym space (gym.spaces) to wrap.
+        """
+        super().__init__()
+        self._gym_space = gym_space
+        self.shape = gym_space.shape  # TODO: remove if unnecessary?
+        self.dtype = gym_space.dtype  # TODO: remove if unnecessary?
+
+    def contains(self, x: T) -> bool:
+        return self._gym_space.contains(x)
+
+    def sample(self) -> T:
+        return self._gym_space.sample()
+
+    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
+        return self._gym_space.to_jsonable(sample_n)
+
+    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
+        return self._gym_space.from_jsonable(sample_n)
+
+    def unwrapped(self) -> gym.Space:
+        """Unwrap the Gym space (gym.spaces) and return it.
+
+        # Returns
+        The original Gym space.
+        """
+        return self._gym_space
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
+        return sample_n
+
+    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
+        return sample_n
+
+
+class BoxSpace(GymSpace[T]):
+    """This class wraps a gymnasium Box space (gym.spaces.Box) as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, low, high, shape=None, dtype=np.float32):
+        super().__init__(gym_space=gym_spaces.Box(low, high, shape, dtype))
+
+
+class DiscreteSpace(GymSpace[T], EnumerableSpace[T]):
+    """This class wraps a gymnasium Discrete space (gym.spaces.Discrete) as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, n, element_class=int):
+        super().__init__(gym_space=gym_spaces.Discrete(n))
+        self._element_class = element_class
+
+    def get_elements(self) -> Iterable[T]:
+        """Get the elements of this space.
+
+        # Returns
+        The elements of this space.
+        """
+        return np.array(list(range(self._gym_space.n)), dtype=np.int64)
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
+        return (
+            sample_n
+            if self._element_class is int
+            else [int(sample) for sample in sample_n]
+        )
+
+    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
+        return (
+            sample_n
+            if self._element_class is int
+            else [self._element_class(sample) for sample in sample_n]
+        )
+
+
+class MultiDiscreteSpace(GymSpace[T], EnumerableSpace[T]):
+    """This class wraps a gymnasium MultiDiscrete space (gym.spaces.MultiDiscrete) as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, nvec, element_class=np.ndarray):
+        super().__init__(gym_space=gym_spaces.MultiDiscrete(nvec))
+        self._element_class = element_class
+
+    def get_elements(self) -> Iterable[T]:
+        """Get the elements of this space.
+
+        # Returns
+        The elements of this space.
+        """
+        return np.array(
+            list(itertools.product(*[list(range(n)) for n in self._gym_space.nvec])),
+            dtype=np.int64,
+        )
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
+        return (
+            sample_n
+            if self._element_class is np.ndarray
+            else [np.asarray(sample, dtype=np.int64) for sample in sample_n]
+        )
+
+    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
+        return (
+            sample_n
+            if self._element_class is np.ndarray
+            else [self._element_class(sample) for sample in sample_n]
+        )
+
+
+class MultiBinarySpace(GymSpace[T], EnumerableSpace[T]):
+    """This class wraps a gymnasium MultiBinary space (gym.spaces.MultiBinary) as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, n, element_class=np.ndarray):
+        super().__init__(gym_space=gym_spaces.MultiBinary(n))
+        self._element_class = element_class
+
+    def get_elements(self) -> Iterable[T]:
+        """Get the elements of this space.
+
+        # Returns
+        The elements of this space.
+        """
+        return np.array(
+            list(itertools.product(*[(1, 0) for _ in range(self._gym_space.n)])),
+            dtype=np.int8,
+        )
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
+        return (
+            sample_n
+            if self._element_class is np.ndarray
+            else [np.asarray(sample, dtype=np.bool_).astype(int) for sample in sample_n]
+        )
+
+    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
+        return (
+            sample_n
+            if self._element_class is np.ndarray
+            else [self._element_class(sample) for sample in sample_n]
+        )
+
+
+class TupleSpace(GymSpace[T]):
+    """This class wraps a gymnasium Tuple space (gym.spaces.Tuple) as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(
+        self, spaces: Tuple[Union[GymSpace[T], gym.Space]], element_class=tuple
+    ):
+        super().__init__(
+            gym_space=gym_spaces.Tuple(
+                [sp if isinstance(sp, gym.Space) else sp.unwrapped() for sp in spaces]
+            )
+        )
+        self._spaces = spaces
+        self._element_class = element_class
+        assert element_class is tuple or all(
+            m in dir(element_class) for m in ["to_tuple", "from_tuple"]
+        ), "Tuple space's element class must be of type tuple or it must provide the to_tuple and from_tuple methods"
+        self._to_tuple = (
+            (lambda e: e) if element_class is tuple else (lambda e: e.to_tuple())
+        )
+        self._from_tuple = (
+            (lambda e: e)
+            if element_class is tuple
+            else (lambda e: self._element_class.from_tuple(e))
+        )
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
+        return [
+            tuple(
+                next(iter(self._spaces[i].to_unwrapped([e])))
+                if isinstance(self._spaces[i], GymSpace)
+                else e
+                for i, e in enumerate(self._to_tuple(sample))
+            )
+            for sample in sample_n
+        ]
+
+    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
+        return [
+            self._from_tuple(
+                tuple(
+                    next(iter(self._spaces[i].from_unwrapped([e])))
+                    if isinstance(self._spaces[i], GymSpace)
+                    else e
+                    for i, e in enumerate(sample)
+                )
+            )
+            for sample in sample_n
+        ]
+
+
+class DictSpace(GymSpace[T]):
+    """This class wraps a gymnasium Dict space (gym.spaces.Dict) as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(
+        self,
+        spaces: Dict[Any, Union[GymSpace[T], gym.Space]] = None,
+        element_class=dict,
+        **spaces_kwargs,
+    ):
+        super().__init__(
+            gym_space=gym_spaces.Dict(
+                {
+                    k: sp if isinstance(sp, gym.Space) else sp.unwrapped()
+                    for k, sp in spaces.items()
+                },
+                **spaces_kwargs,
+            )
+        )
+        self._spaces = spaces
+        self._element_class = element_class
+        assert element_class is dict or all(
+            m in dir(element_class) for m in ["to_dict", "from_dict"]
+        ), "Dict space's element class must be of type dict or it must provide the to_dict and from_dict methods"
+        self._to_dict = (
+            (lambda e: e) if element_class is dict else (lambda e: e.to_dict())
+        )
+        self._from_dict = (
+            (lambda e: e)
+            if element_class is dict
+            else (lambda e: self._element_class.from_dict(e))
+        )
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable:
+        return [
+            {
+                k: next(iter(self._spaces[k].to_unwrapped([e])))
+                if isinstance(self._spaces[k], GymSpace)
+                else e
+                for k, e in self._to_dict(sample).items()
+            }
+            for sample in sample_n
+        ]
+
+    def from_unwrapped(self, sample_n: Iterable) -> Iterable[T]:
+        return [
+            self._from_dict(
+                {
+                    k: next(iter(self._spaces[k].from_unwrapped([e])))
+                    if isinstance(self._spaces[k], GymSpace)
+                    else e
+                    for k, e in sample.items()
+                }
+            )
+            for sample in sample_n
+        ]
+
+
+class EnumSpace(Generic[T], GymSpace[T], EnumerableSpace[T]):
+    """This class creates a gymnasium Discrete space (gym.spaces.Discrete) from an enumeration and wraps it as a
+    scikit-decide enumerable space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, enum_class: EnumMeta) -> None:
+        """Initialize EnumSpace.
+
+        # Parameters
+        enum_class: The enumeration class for creating the Gym Discrete space (gym.spaces.Discrete) to wrap.
+        """
+        self._enum_class = enum_class
+        self._list_enum = list(enum_class)
+        gym_space = gym_spaces.Discrete(len(enum_class))
+        super().__init__(gym_space)
+
+    def contains(self, x: T) -> bool:
+        return isinstance(x, self._enum_class)
+
+    def get_elements(self) -> Iterable[T]:
+        return self._list_enum
+
+    def sample(self) -> T:
+        return self._list_enum[super().sample()]
+
+    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
+        return [sample.name for sample in sample_n]
+
+    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
+        return [self._enum_class[sample] for sample in sample_n]
+
+    def unwrapped(self) -> gym_spaces.Discrete:
+        """Unwrap the Gym Discrete space (gym.spaces.Discrete) and return it.
+
+        # Returns
+        The original Gym Discrete space created from the enumeration.
+        """
+        return super().unwrapped()
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[int]:
+        return [self._list_enum.index(sample) for sample in sample_n]
+
+    def from_unwrapped(self, sample_n: Iterable[int]) -> Iterable[T]:
+        return [self._list_enum[sample] for sample in sample_n]
+
+
+class ListSpace(Generic[T], GymSpace[T], EnumerableSpace[T]):
+    """This class creates a gymnasium Discrete space (gym.spaces.Discrete) from a list of elements and wraps it as a
+    scikit-decide enumerable space. If ordering is not important contrary to the 'contains' test, it is advised to
+    use the 'SetSpace' class instead.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, elements: Iterable[T]) -> None:
+        """Initialize ListSpace.
+
+        # Parameters
+        elements: The list of elements for creating the Gym Discrete space (gym.spaces.Discrete) to wrap.
+        """
+        self._elements = list(elements)
+        gym_space = gym_spaces.Discrete(len(self._elements))
+        super().__init__(gym_space)
+
+    def contains(self, x: T) -> bool:
+        return x in self._elements
+
+    def get_elements(self) -> Iterable[T]:
+        return self._elements
+
+    def sample(self) -> T:
+        return self._elements[super().sample()]
+
+    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
+        return sample_n
+
+    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
+        return sample_n
+
+    def unwrapped(self) -> gym_spaces.Discrete:
+        """Unwrap the Gym Discrete space (gym.spaces.Discrete) and return it.
+
+        # Returns
+        The original Gym Discrete space created from the list.
+        """
+        return super().unwrapped()
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[int]:
+        return [self._elements.index(sample) for sample in sample_n]
+
+    def from_unwrapped(self, sample_n: Iterable[int]) -> Iterable[T]:
+        return [self._elements[sample] for sample in sample_n]
+
+
+class SetSpace(Generic[T], GymSpace[T], EnumerableSpace[T]):
+    """This class creates a gymnasium Discrete space (gym.spaces.Discrete) from a set of elements and wraps it as a
+    scikit-decide enumerable space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(self, elements: Iterable[T]) -> None:
+        """Initialize SetSpace.
+
+        # Parameters
+        elements: The set of elements for creating the Gym Discrete space (gym.spaces.Discrete) to wrap.
+        """
+        self._elements = set(elements)
+        self._to_indexes = {e: i for i, e in enumerate(self._elements)}
+        self._to_elements = [e for e in self._elements]
+        gym_space = gym_spaces.Discrete(len(self._elements))
+        super().__init__(gym_space)
+
+    def contains(self, x: T) -> bool:
+        return x in self._elements
+
+    def get_elements(self) -> Iterable[T]:
+        return self._elements
+
+    def sample(self) -> T:
+        return self._to_elements[super().sample()]
+
+    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
+        return sample_n
+
+    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
+        return sample_n
+
+    def unwrapped(self) -> gym_spaces.Discrete:
+        """Unwrap the Gym Discrete space (gym.spaces.Discrete) and return it.
+
+        # Returns
+        The original Gym Discrete space created from the list.
+        """
+        return super().unwrapped()
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[int]:
+        return [self._to_indexes[sample] for sample in sample_n]
+
+    def from_unwrapped(self, sample_n: Iterable[int]) -> Iterable[T]:
+        return [self._to_elements[sample] for sample in sample_n]
+
+
+class DataSpace(GymSpace[T]):
+    """This class creates a gymnasium Dict space (gym.spaces.Dict) from a dataclass and wraps it as a scikit-decide space.
+
+    !!! warning
+        Using this class requires gymnasium to be installed.
+    """
+
+    def __init__(
+        self,
+        data_class: type,
+        spaces: Union[Dict[str, gym.Space], List[Tuple[str, gym.Space]]],
+    ) -> None:
+        """Initialize DataSpace.
+
+        # Parameters
+        data_class: The dataclass for creating the Gym Dict space (gym.spaces.Dict) to wrap.
+        spaces: The spaces description passed to the created Dict space (see gym.spaces.Dict constructor documentation).
+
+        # Example
+        ```python
+        from skdecide.wrappers.space import DataSpace
+
+        @dataclass(frozen=True)
+        class Action:
+            position: int
+            velocity: int
+
+        my_action_space = DataSpace(Action, {"position": gym.spaces.Discrete(2), "velocity": gym.spaces.Discrete(3)})
+        ```
+        """
+        self._data_class = data_class
+        gym_space = gym_spaces.Dict(spaces)
+        super().__init__(gym_space)
+
+    def contains(self, x: T) -> bool:
+        # works even when fields of the dataclass have been recast (e.g. numpy 0-dimensional array to scalar)
+        return super().contains(super().from_jsonable(self.to_jsonable([x]))[0])
+        # # bug: does not work when fields of the dataclass have been recast (e.g. numpy 0-dimensional array to scalar)
+        # return super().contains(asdict(x))
+
+    def sample(self) -> T:
+        # TODO: convert to simple types (get rid of ndarray created by gym dict space...)?
+        return self._data_class(**super().sample())
+
+    def to_jsonable(self, sample_n: Iterable[T]) -> Sequence:
+        dict_sample_n = self.to_unwrapped(sample_n)
+        return super().to_jsonable(dict_sample_n)
+
+    def from_jsonable(self, sample_n: Sequence) -> Iterable[T]:
+        dict_sample_n = super().from_jsonable(sample_n)
+        return self.from_unwrapped(dict_sample_n)
+
+    def unwrapped(self) -> gym_spaces.Dict:
+        """Unwrap the Gym Dict space (gym.spaces.Dict) and return it.
+
+        # Returns
+        The original Gym Dict space created from the dataclass.
+        """
+        return super().unwrapped()
+
+    def to_unwrapped(self, sample_n: Iterable[T]) -> Iterable[Dict]:
+        return [asdict(sample) for sample in sample_n]
+
+    def from_unwrapped(self, sample_n: Iterable[Dict]) -> Iterable[T]:
+        # TODO: convert to simple types (get rid of ndarray created by gym dict space...)?
+        return [self._data_class(**sample) for sample in sample_n]
```

## skdecide/parallel_domains.py

```diff
@@ -1,629 +1,634 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-"""This module contains helper classes to manage domains for parallel compurations."""
-
-from __future__ import annotations
-
-import os
-import tempfile
-
-# Following import is required to make Enum objects serializable
-# (useful when multiprocessing and pickling domains that use Enum classes)
-import dill
-from pathos.helpers import mp
-from pynng import Push0
-
-from skdecide.domains import logger
-
-dill.settings["byref"] = True
-
-
-class ParallelDomain:
-    """Base class for creating and launching n domains in separate processes.
-    Each domain listens for incoming domain requests.
-    Each request can indicate which domain should serve it, otherwise the first available
-    domain i is chosen and its id is returned to the incoming request.
-    """
-
-    def __init__(
-        self, domain_factory, lambdas=None, nb_domains=os.cpu_count(), ipc_notify=False
-    ):
-        self._domain_factory = domain_factory
-        self._lambdas = lambdas
-        self._active_domains = mp.Array(
-            "b", [False for i in range(nb_domains)], lock=True
-        )
-        self._initializations = [
-            mp.Value("b", False, lock=True) for i in range(nb_domains)
-        ]
-        self._conditions = [mp.Condition() for i in range(nb_domains)]
-        self._temp_connections = [None] * nb_domains
-        self._ipc_connections = [None] * nb_domains
-        self._processes = [None] * nb_domains
-        self._ipc_notify = ipc_notify
-
-    def open_ipc_connection(self, i):
-        self._temp_connections[i] = tempfile.NamedTemporaryFile(delete=True)
-        self._ipc_connections[i] = "ipc://" + self._temp_connections[i].name + ".ipc"
-
-    def close_ipc_connection(self, i):
-        self._temp_connections[i].close()
-        self._ipc_connections[i] = None
-
-    def _launch_processes(self):
-        raise NotImplementedError
-
-    def close(self):
-        raise NotImplementedError
-
-    def __enter__(self):
-        self._launch_processes()
-        return self
-
-    def __exit__(self, type, value, tb):
-        self.close()
-
-    def launch(self, i, name, *args):
-        raise NotImplementedError
-
-    def get_proc_connections(self):  # process connections for use in python
-        raise NotImplementedError
-
-    def get_ipc_connections(self):  # inter-process connections for use with C++
-        return self._ipc_connections
-
-    def get_parallel_capacity(self):
-        return self.nb_domains()
-
-    def nb_domains(self):
-        return len(self._processes)
-
-    def wake_up_domain(self, i=None):
-        if i is None:
-            while True:
-                for j, v in enumerate(self._active_domains):
-                    if not v:
-                        self._active_domains[j] = True
-                        return j
-        else:
-            self._active_domains[i] = True
-            return i
-
-    def reset(self, i=None):
-        return self.launch(i, "reset")
-
-    def get_initial_state_distribution(self, i=None):
-        return self.launch(i, "get_initial_state_distribution")
-
-    def get_initial_state(self, i=None):
-        return self.launch(i, "get_initial_state")
-
-    def get_observation_space(self, i=None):
-        return self.launch(i, "get_observation_space")
-
-    def is_observation(self, observation, i=None):
-        return self.launch(i, "is_observation", observation)
-
-    def get_observation_distribution(self, state, action, i=None):
-        return self.launch(i, "get_observation_distribution", state, action)
-
-    def get_observation(self, state, action, i=None):
-        return self.launch(i, "get_observation", state, action)
-
-    def get_enabled_events(self, memory, i=None):
-        return self.launch(i, "get_enabled_events", memory)
-
-    def is_enabled_event(self, event, memory, i=None):
-        return self.launch(i, "is_enabled_event", event, memory)
-
-    def get_action_space(self, i=None):
-        return self.launch(i, "get_action_space")
-
-    def is_action(self, event, i=None):
-        return self.launch(i, "is_action", event)
-
-    def get_applicable_actions(self, memory, i=None):
-        return self.launch(i, "get_applicable_actions", memory)
-
-    def is_applicable_action(self, action, memory, i=None):
-        return self.launch(i, "is_applicable_action", action, memory)
-
-    def step(self, action, i=None):
-        return self.launch(i, "step", action)
-
-    def sample(self, memory, action, i=None):
-        return self.launch(i, "sample", memory, action)
-
-    def get_next_state_distribution(self, memory, action, i=None):
-        return self.launch(i, "get_next_state_distribution", memory, action)
-
-    def get_next_state(self, memory, action, i=None):
-        return self.launch(i, "get_next_state", memory, action)
-
-    def get_transition_value(self, memory, action, next_state, i=None):
-        return self.launch(i, "get_transition_value", memory, action, next_state)
-
-    def is_transition_value_dependent_on_next_state(self, i=None):
-        return self.launch(i, "is_transition_value_dependent_on_next_state")
-
-    def get_goals(self, i=None):
-        return self.launch(i, "get_goals")
-
-    def is_goal(self, observation, i=None):
-        return self.launch(i, "is_goal", observation)
-
-    def is_terminal(self, state, i=None):
-        return self.launch(i, "is_terminal", state)
-
-    def check_value(self, value, i=None):
-        return self.launch(i, "check_value", value)
-
-    def render(self, memory, i=None):
-        return self.launch(i, "render", memory)
-
-    # Call a lambda function (usually involves the original domain)
-    def call(self, i, lambda_id, *args):
-        return self.launch(i, lambda_id, *args)
-
-    # The original sequential domain may have methods we don't know
-    def __getattr__(self, name):
-        def method(*args, i=None):
-            return self.launch(i, name, *args)
-
-        return method
-
-    # Bypass __getattr_.method() when serializing the class.
-    # Required on Windows when spawning the main process.
-    def __getstate__(self):
-        d = self.__dict__.copy()
-        del d["_temp_connections"]  # we cannot serialize a file
-        return d
-
-    # Bypass __getattr_.method() when serializing the class.
-    # Required on Windows when spawning the main process.
-    def __setstate__(self, state):
-        self.__dict__ = state
-        # TODO: reopen the temp connection from _ipc_connections
-
-
-def _launch_domain_server_(
-    domain_factory, lambdas, i, job_results, conn, init, cond, ipc_conn, logger
-):
-    domain = domain_factory()
-
-    if ipc_conn is not None:
-        pusher = Push0()
-        pusher.dial(ipc_conn)
-
-    with cond:
-        init.value = True
-        cond.notify_all()  # inform the parent process that we are ready to process requests
-
-    while True:
-        job = conn.recv()
-        job_results[i] = None
-        if job is None:
-            if ipc_conn is not None:
-                pusher.close()
-            conn.close()
-            break
-        else:
-            try:
-                if isinstance(job[0], str):  # job[0] is a domain class' method
-                    r = getattr(domain, job[0])(*job[1])
-                else:  # job[0] is a lambda function
-                    r = lambdas[job[0]](domain, *job[1])
-                job_results[i] = r
-                if ipc_conn is not None:
-                    pusher.send(b"0")  # send success
-                conn.send("0")  # send success
-            except Exception as e:
-                logger.error(rf"/!\ Unable to perform job {job[0]}: {e}")
-                if ipc_conn is not None:
-                    pusher.send(str(e).encode(encoding="UTF-8"))  # send error message
-                else:
-                    conn.send(str(e))  # send failure (!= 0)
-
-
-class PipeParallelDomain(ParallelDomain):
-    """This class can be used to create and launch n domains in separate processes.
-    Each domain listens for incoming domain requests.
-    Each request can indicate which domain should serve it, otherwise the first available
-    domain i is chosen and its id is returned to the incoming request.
-    """
-
-    def __init__(
-        self, domain_factory, lambdas=None, nb_domains=os.cpu_count(), ipc_notify=False
-    ):
-        super().__init__(domain_factory, lambdas, nb_domains, ipc_notify)
-        self._manager = mp.Manager()
-        self._waiting_jobs = [None] * nb_domains
-        self._job_results = self._manager.list([None for i in range(nb_domains)])
-        logger.info(rf"Using {nb_domains} parallel piped domains")
-
-    def get_proc_connections(self):
-        return self._waiting_jobs
-
-    def launch(self, i, function, *args):
-        if not any(self._processes):
-            self._launch_processes()
-        try:
-            mi = self.wake_up_domain(i)
-            self._waiting_jobs[mi].send((function, args))
-            return mi
-        except Exception as e:
-            if isinstance(function, str):
-                logger.error(rf"/!\ Unable to launch job {function}: {e}")
-            else:
-                logger.error(rf"/!\ Unable to launch job lambdas[{function}]: {e}")
-
-    def get_result(self, i):
-        self._waiting_jobs[i].recv()
-        r = self._job_results[i]
-        self._job_results[i] = None
-        self._active_domains[i] = False
-        return r
-
-    def _launch_processes(self):
-        for i in range(len(self._job_results)):
-            self.open_ipc_connection(i)
-            pparent, pchild = mp.Pipe()
-            self._waiting_jobs[i] = pparent
-            self._processes[i] = mp.Process(
-                target=_launch_domain_server_,
-                args=[
-                    self._domain_factory,
-                    self._lambdas,
-                    i,
-                    self._job_results,
-                    pchild,
-                    self._initializations[i],
-                    self._conditions[i],
-                    self._ipc_connections[i] if self._ipc_notify else None,
-                    logger,
-                ],
-            )
-            self._processes[i].start()
-        # Waits for all jobs to be launched and waiting each for requests
-        for i in range(len(self._job_results)):
-            with self._conditions[i]:
-                self._conditions[i].wait_for(
-                    lambda: bool(self._initializations[i].value) == True
-                )
-
-    def close(self):
-        for i in range(len(self._job_results)):
-            self._initializations[i].value = False
-            self._waiting_jobs[i].send(None)
-            self._processes[i].join()
-            self._processes[i].close()
-            self._waiting_jobs[i].close()
-            self._processes[i] = None
-            self.close_ipc_connection(i)
-
-
-def _shm_launch_domain_server_(
-    domain_factory,
-    lambdas,
-    i,
-    shm_proxy,
-    shm_registers,
-    shm_types,
-    shm_sizes,
-    rsize,
-    shm_arrays,
-    shm_lambdas,
-    shm_names,
-    shm_params,
-    init,
-    activation,
-    done,
-    cond,
-    ipc_conn,
-    logger,
-):
-    domain = domain_factory()
-
-    if ipc_conn is not None:
-        pusher = Push0()
-        pusher.dial(ipc_conn)
-
-    with cond:
-        init.value = True
-        cond.notify_all()  # inform the parent process that we are ready to process requests
-
-    def get_string(s):
-        for i, c in enumerate(s):
-            if c == b"\x00":
-                return s[:i].decode()
-        return s.decode()
-
-    while True:
-        with cond:
-            cond.wait_for(lambda: bool(activation.value) == True)
-            activation.value = False
-        if int(shm_lambdas[i].value) == -1 and shm_names[i][0] == b"\x00":
-            if ipc_conn is not None:
-                pusher.close()
-            break
-        else:
-            try:
-                job_args = []
-                for p in shm_params[i]:
-                    if p >= 0:
-                        sz = shm_sizes[shm_types[p].__name__]
-                        if sz > 1:
-                            si = (i * rsize) + p
-                            job_args.append(
-                                shm_proxy.decode(
-                                    shm_types[p], shm_arrays[si : (si + sz)]
-                                )
-                            )
-                        else:
-                            job_args.append(
-                                shm_proxy.decode(
-                                    shm_types[p], shm_arrays[(i * rsize) + p]
-                                )
-                            )
-                    else:
-                        break  # no more args
-                if (
-                    int(shm_lambdas[i].value) == -1
-                ):  # we are working with a domain class' method
-                    result = getattr(domain, get_string(shm_names[i]))(*job_args)
-                else:  # we are working with a lambda function
-                    result = lambdas[int(shm_lambdas[i].value)](domain, *job_args)
-                shm_params[i][:] = [-1] * len(shm_params[i])
-                if type(result) is not tuple:
-                    result = (result,)
-                if result[0] is not None:
-                    type_counters = {}
-                    for j, r in enumerate(result):
-                        res_name = type(r).__name__
-                        (start, end) = shm_registers[res_name]
-                        if res_name in type_counters:
-                            type_counters[res_name] += 1
-                            k = type_counters[res_name]
-                            if k >= end:
-                                raise IndexError(
-                                    """No more available register for type {}.
-                                                    Please increase the number of registers
-                                                    for that type.""".format(
-                                        res_name
-                                    )
-                                )
-                        else:
-                            type_counters[res_name] = start
-                            k = start
-                        shm_params[i][j] = k
-                        sz = shm_sizes[res_name]
-                        if sz > 1:
-                            si = (i * rsize) + k
-                            shm_proxy.encode(r, shm_arrays[si : (si + sz)])
-                        else:
-                            shm_proxy.encode(r, shm_arrays[(i * rsize) + k])
-                if ipc_conn is not None:
-                    pusher.send(b"0")  # send success
-            except Exception as e:
-                if int(shm_lambdas[i].value) == -1:
-                    logger.error(
-                        rf"/!\ Unable to perform job {get_string(shm_names[i])}: {e}"
-                    )
-                else:
-                    logger.error(
-                        rf"/!\ Unable to perform job {int(shm_lambdas[i].value)}: {e}"
-                    )
-                if ipc_conn is not None:
-                    pusher.send(str(e).encode(encoding="UTF-8"))  # send error message
-            with cond:
-                done.value = True
-                cond.notify_all()  # send finished status (no success nor failure information)
-
-
-class ShmParallelDomain(ParallelDomain):
-    """This class can be used to create and launch n domains in separate processes
-    with shared memory between the Python processes.
-    Each domain listens for incoming domain requests.
-    Each request can indicate which domain should serve it, otherwise the first available
-    domain is chosen and its id is returned to the incoming request.
-    """
-
-    def __init__(
-        self,
-        domain_factory,
-        shm_proxy,
-        lambdas=None,
-        nb_domains=os.cpu_count(),
-        ipc_notify=False,
-    ):
-        super().__init__(domain_factory, lambdas, nb_domains, ipc_notify)
-        self._activations = [mp.Value("b", False, lock=True) for i in range(nb_domains)]
-        self._dones = [mp.Value("b", False, lock=True) for i in range(nb_domains)]
-        self._shm_proxy = shm_proxy
-        self._shm_registers = (
-            {}
-        )  # Maps from registered method parameter types to vectorized array ranges
-        self._shm_types = {}  # Maps from register index to type
-        self._shm_sizes = (
-            {}
-        )  # Maps from register method parameter types to number of arrays encoding each type
-        self._shm_arrays = []  # Methods' vectorized parameters
-        self._rsize = 0  # Total size of the register (updated below)
-        self._shm_lambdas = [None] * nb_domains  # Vectorized lambdas' ids
-        self._shm_names = [None] * nb_domains  # Vectorized methods' names
-        self._shm_params = [
-            None
-        ] * nb_domains  # Indices of methods' vectorized parameters
-        for i in range(nb_domains):
-            j = 0
-            for r in shm_proxy.register():
-                for k in range(r[1]):
-                    m = shm_proxy.initialize(r[0])
-                    if type(m) == list or type(m) == tuple:
-                        if (
-                            i == 0 and k == 0
-                        ):  # do it once for all the domains and redundant initializers
-                            self._shm_sizes[r[0].__name__] = len(m)
-                            self._shm_registers[r[0].__name__] = (
-                                j,
-                                j + (r[1] * len(m)),
-                            )
-                            self._shm_types.update(
-                                {
-                                    kk: r[0]
-                                    for kk in range(j, j + (r[1] * len(m)), len(m))
-                                }
-                            )
-                            self._rsize += r[1] * len(m)
-                        self._shm_arrays.extend(m)
-                        j += len(m)
-                    else:
-                        if (
-                            i == 0 and k == 0
-                        ):  # do it once for all the domains and redundant initializers
-                            self._shm_sizes[r[0].__name__] = 1
-                            self._shm_registers[r[0].__name__] = (j, j + r[1])
-                            self._shm_types.update(
-                                {kk: r[0] for kk in range(j, j + r[1])}
-                            )
-                            self._rsize += r[1]
-                        self._shm_arrays.append(m)
-                        j += 1
-            self._shm_lambdas[i] = mp.Value("i", -1, lock=True)
-            self._shm_names[i] = mp.Array("c", bytearray(100))
-            self._shm_params[i] = mp.Array(
-                "i", [-1] * sum(r[1] for r in shm_proxy.register())
-            )
-        logger.info(rf"Using {nb_domains} parallel shared memory domains")
-
-    def get_proc_connections(self):
-        return (self._activations, self._conditions)
-
-    def launch(self, i, function, *args):
-        if not any(self._processes):
-            self._launch_processes()
-        try:
-            mi = self.wake_up_domain(i)
-            if isinstance(function, str):  # function is a domain class' method
-                self._shm_lambdas[mi].value = -1
-                self._shm_names[mi][:] = bytearray(
-                    function, encoding="utf-8"
-                ) + bytearray(len(self._shm_names[mi]) - len(function))
-            else:  # function is a lambda id
-                self._shm_lambdas[mi].value = int(function)
-                self._shm_names[mi][:] = bytearray(
-                    len(self._shm_names[mi])
-                )  # reset with null bytes
-            self._shm_params[mi][:] = [-1] * len(self._shm_params[mi])
-            type_counters = {}
-            for j, a in enumerate(args):
-                arg_name = type(a).__name__
-                (start, end) = self._shm_registers[arg_name]
-                if arg_name in type_counters:
-                    type_counters[arg_name] += self._shm_sizes[arg_name]
-                    k = type_counters[arg_name]
-                    if k >= end:
-                        raise IndexError(
-                            """No more available register for type {}.
-                                            Please increase the number of registers
-                                            for that type.""".format(
-                                arg_name
-                            )
-                        )
-                else:
-                    type_counters[arg_name] = start
-                    k = start
-                self._shm_params[mi][j] = k
-                sz = self._shm_sizes[arg_name]
-                if sz > 1:
-                    si = (mi * self._rsize) + k
-                    self._shm_proxy.encode(a, self._shm_arrays[si : (si + sz)])
-                else:
-                    self._shm_proxy.encode(a, self._shm_arrays[(mi * self._rsize) + k])
-            with self._conditions[mi]:
-                self._activations[mi].value = True
-                self._conditions[mi].notify_all()
-            return mi
-        except Exception as e:
-            if isinstance(function, str):
-                logger.error(rf"/!\ Unable to launch job {function}: {e}")
-            else:
-                logger.error(rf"/!\ Unable to launch job lambdas[{function}]: {e}")
-
-    def get_result(self, i):
-        with self._conditions[i]:
-            self._conditions[i].wait_for(lambda: bool(self._dones[i].value) == True)
-            self._dones[i].value = False
-        results = []
-        for r in self._shm_params[i]:
-            if r >= 0:
-                sz = self._shm_sizes[self._shm_types[r].__name__]
-                if sz > 1:
-                    si = (i * self._rsize) + r
-                    results.append(
-                        self._shm_proxy.decode(
-                            self._shm_types[r], self._shm_arrays[si : (si + sz)]
-                        )
-                    )
-                else:
-                    results.append(
-                        self._shm_proxy.decode(
-                            self._shm_types[r], self._shm_arrays[(i * self._rsize) + r]
-                        )
-                    )
-            else:
-                break  # no more params
-        self._active_domains[i] = False
-        return results if len(results) > 1 else results[0] if len(results) > 0 else None
-
-    def _launch_processes(self):
-        for i in range(len(self._processes)):
-            self.open_ipc_connection(i)
-            self._processes[i] = mp.Process(
-                target=_shm_launch_domain_server_,
-                args=[
-                    self._domain_factory,
-                    self._lambdas,
-                    i,
-                    self._shm_proxy.copy(),
-                    dict(self._shm_registers),
-                    dict(self._shm_types),
-                    dict(self._shm_sizes),
-                    self._rsize,
-                    list(self._shm_arrays),
-                    list(self._shm_lambdas),
-                    list(self._shm_names),
-                    list(self._shm_params),
-                    self._initializations[i],
-                    self._activations[i],
-                    self._dones[i],
-                    self._conditions[i],
-                    self._ipc_connections[i] if self._ipc_notify else None,
-                    logger,
-                ],
-            )
-            self._processes[i].start()
-        # Waits for all jobs to be launched and waiting each for requests
-        for i in range(len(self._processes)):
-            with self._conditions[i]:
-                self._conditions[i].wait_for(
-                    lambda: bool(self._initializations[i].value) == True
-                )
-
-    def close(self):
-        for i in range(len(self._processes)):
-            self._initializations[i].value = False
-            self._shm_lambdas[i].value = -1
-            self._shm_names[i][:] = bytearray(
-                len(self._shm_names[i])
-            )  # reset with null bytes
-            self._shm_params[i][:] = [-1] * len(self._shm_params[i])
-            with self._conditions[i]:
-                self._activations[i].value = True
-                self._conditions[i].notify_all()
-            self._processes[i].join()
-            self._processes[i].close()
-            self._processes[i] = None
-            self.close_ipc_connection(i)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+"""This module contains helper classes to manage domains for parallel compurations."""
+
+from __future__ import annotations
+
+import logging
+import os
+import tempfile
+
+# Following import is required to make Enum objects serializable
+# (useful when multiprocessing and pickling domains that use Enum classes)
+import dill
+from pathos.helpers import mp
+from pynng import Push0
+
+logger = logging.getLogger(__name__)
+
+dill.settings["byref"] = True
+
+
+class ParallelDomain:
+    """Base class for creating and launching n domains in separate processes.
+    Each domain listens for incoming domain requests.
+    Each request can indicate which domain should serve it, otherwise the first available
+    domain i is chosen and its id is returned to the incoming request.
+    """
+
+    def __init__(
+        self, domain_factory, lambdas=None, nb_domains=os.cpu_count(), ipc_notify=False
+    ):
+        self._domain_factory = domain_factory
+        self._lambdas = lambdas
+        self._active_domains = mp.Array(
+            "b", [False for i in range(nb_domains)], lock=True
+        )
+        self._initializations = [
+            mp.Value("b", False, lock=True) for i in range(nb_domains)
+        ]
+        self._conditions = [mp.Condition() for i in range(nb_domains)]
+        self._temp_connections = [None] * nb_domains
+        self._ipc_connections = [None] * nb_domains
+        self._processes = [None] * nb_domains
+        self._ipc_notify = ipc_notify
+
+    def open_ipc_connection(self, i):
+        self._temp_connections[i] = tempfile.NamedTemporaryFile(delete=True)
+        self._ipc_connections[i] = "ipc://" + self._temp_connections[i].name + ".ipc"
+
+    def close_ipc_connection(self, i):
+        self._temp_connections[i].close()
+        self._ipc_connections[i] = None
+
+    def _launch_processes(self):
+        raise NotImplementedError
+
+    def close(self):
+        raise NotImplementedError
+
+    def __enter__(self):
+        self._launch_processes()
+        return self
+
+    def __exit__(self, type, value, tb):
+        self.close()
+
+    def launch(self, i, name, *args):
+        raise NotImplementedError
+
+    def get_proc_connections(self):  # process connections for use in python
+        raise NotImplementedError
+
+    def get_ipc_connections(self):  # inter-process connections for use with C++
+        return self._ipc_connections
+
+    def get_parallel_capacity(self):
+        return self.nb_domains()
+
+    def nb_domains(self):
+        return len(self._processes)
+
+    def wake_up_domain(self, i=None):
+        if i is None:
+            while True:
+                for j, v in enumerate(self._active_domains):
+                    if not v:
+                        self._active_domains[j] = True
+                        return j
+        else:
+            self._active_domains[i] = True
+            return i
+
+    def reset(self, i=None):
+        return self.launch(i, "reset")
+
+    def get_initial_state_distribution(self, i=None):
+        return self.launch(i, "get_initial_state_distribution")
+
+    def get_initial_state(self, i=None):
+        return self.launch(i, "get_initial_state")
+
+    def get_observation_space(self, i=None):
+        return self.launch(i, "get_observation_space")
+
+    def is_observation(self, observation, i=None):
+        return self.launch(i, "is_observation", observation)
+
+    def get_observation_distribution(self, state, action, i=None):
+        return self.launch(i, "get_observation_distribution", state, action)
+
+    def get_observation(self, state, action, i=None):
+        return self.launch(i, "get_observation", state, action)
+
+    def get_enabled_events(self, memory, i=None):
+        return self.launch(i, "get_enabled_events", memory)
+
+    def is_enabled_event(self, event, memory, i=None):
+        return self.launch(i, "is_enabled_event", event, memory)
+
+    def get_action_space(self, i=None):
+        return self.launch(i, "get_action_space")
+
+    def is_action(self, event, i=None):
+        return self.launch(i, "is_action", event)
+
+    def get_applicable_actions(self, memory, i=None):
+        return self.launch(i, "get_applicable_actions", memory)
+
+    def is_applicable_action(self, action, memory, i=None):
+        return self.launch(i, "is_applicable_action", action, memory)
+
+    def step(self, action, i=None):
+        return self.launch(i, "step", action)
+
+    def sample(self, memory, action, i=None):
+        return self.launch(i, "sample", memory, action)
+
+    def get_next_state_distribution(self, memory, action, i=None):
+        return self.launch(i, "get_next_state_distribution", memory, action)
+
+    def get_next_state(self, memory, action, i=None):
+        return self.launch(i, "get_next_state", memory, action)
+
+    def get_transition_value(self, memory, action, next_state, i=None):
+        return self.launch(i, "get_transition_value", memory, action, next_state)
+
+    def is_transition_value_dependent_on_next_state(self, i=None):
+        return self.launch(i, "is_transition_value_dependent_on_next_state")
+
+    def get_goals(self, i=None):
+        return self.launch(i, "get_goals")
+
+    def is_goal(self, observation, i=None):
+        return self.launch(i, "is_goal", observation)
+
+    def is_terminal(self, state, i=None):
+        return self.launch(i, "is_terminal", state)
+
+    def check_value(self, value, i=None):
+        return self.launch(i, "check_value", value)
+
+    def render(self, memory, i=None):
+        return self.launch(i, "render", memory)
+
+    # Call a lambda function (usually involves the original domain)
+    def call(self, i, lambda_id, *args):
+        return self.launch(i, lambda_id, *args)
+
+    # The original sequential domain may have methods we don't know
+    def __getattr__(self, name):
+        def method(*args, i=None):
+            return self.launch(i, name, *args)
+
+        return method
+
+    # Bypass __getattr_.method() when serializing the class.
+    # Required on Windows when spawning the main process.
+    def __getstate__(self):
+        d = self.__dict__.copy()
+        del d["_temp_connections"]  # we cannot serialize a file
+        return d
+
+    # Bypass __getattr_.method() when serializing the class.
+    # Required on Windows when spawning the main process.
+    def __setstate__(self, state):
+        self.__dict__ = state
+        # TODO: reopen the temp connection from _ipc_connections
+
+
+def _launch_domain_server_(
+    domain_factory, lambdas, i, job_results, conn, init, cond, ipc_conn, logger
+):
+    domain = domain_factory()
+
+    if ipc_conn is not None:
+        pusher = Push0()
+        pusher.dial(
+            ipc_conn, block=False
+        )  # WARNING: recent pynng updates only work with non-blocking dials!
+
+    with cond:
+        init.value = True
+        cond.notify_all()  # inform the parent process that we are ready to process requests
+
+    while True:
+        job = conn.recv()
+        job_results[i] = None
+        if job is None:
+            if ipc_conn is not None:
+                pusher.close()
+            conn.close()
+            break
+        else:
+            try:
+                if isinstance(job[0], str):  # job[0] is a domain class' method
+                    r = getattr(domain, job[0])(*job[1])
+                else:  # job[0] is a lambda function
+                    r = lambdas[job[0]](domain, *job[1])
+                job_results[i] = r
+                if ipc_conn is not None:
+                    pusher.send(b"0")  # send success
+                conn.send("0")  # send success
+            except Exception as e:
+                logger.error(rf"/!\ Unable to perform job {job[0]}: {e}")
+                if ipc_conn is not None:
+                    pusher.send(str(e).encode(encoding="UTF-8"))  # send error message
+                else:
+                    conn.send(str(e))  # send failure (!= 0)
+
+
+class PipeParallelDomain(ParallelDomain):
+    """This class can be used to create and launch n domains in separate processes.
+    Each domain listens for incoming domain requests.
+    Each request can indicate which domain should serve it, otherwise the first available
+    domain i is chosen and its id is returned to the incoming request.
+    """
+
+    def __init__(
+        self, domain_factory, lambdas=None, nb_domains=os.cpu_count(), ipc_notify=False
+    ):
+        super().__init__(domain_factory, lambdas, nb_domains, ipc_notify)
+        self._manager = mp.Manager()
+        self._waiting_jobs = [None] * nb_domains
+        self._job_results = self._manager.list([None for i in range(nb_domains)])
+        logger.info(rf"Using {nb_domains} parallel piped domains")
+
+    def get_proc_connections(self):
+        return self._waiting_jobs
+
+    def launch(self, i, function, *args):
+        if not any(self._processes):
+            self._launch_processes()
+        try:
+            mi = self.wake_up_domain(i)
+            self._waiting_jobs[mi].send((function, args))
+            return mi
+        except Exception as e:
+            if isinstance(function, str):
+                logger.error(rf"/!\ Unable to launch job {function}: {e}")
+            else:
+                logger.error(rf"/!\ Unable to launch job lambdas[{function}]: {e}")
+
+    def get_result(self, i):
+        self._waiting_jobs[i].recv()
+        r = self._job_results[i]
+        self._job_results[i] = None
+        self._active_domains[i] = False
+        return r
+
+    def _launch_processes(self):
+        for i in range(len(self._job_results)):
+            self.open_ipc_connection(i)
+            pparent, pchild = mp.Pipe()
+            self._waiting_jobs[i] = pparent
+            self._processes[i] = mp.Process(
+                target=_launch_domain_server_,
+                args=[
+                    self._domain_factory,
+                    self._lambdas,
+                    i,
+                    self._job_results,
+                    pchild,
+                    self._initializations[i],
+                    self._conditions[i],
+                    self._ipc_connections[i] if self._ipc_notify else None,
+                    logger,
+                ],
+            )
+            self._processes[i].start()
+        # Waits for all jobs to be launched and waiting each for requests
+        for i in range(len(self._job_results)):
+            with self._conditions[i]:
+                self._conditions[i].wait_for(
+                    lambda: bool(self._initializations[i].value) == True
+                )
+
+    def close(self):
+        for i in range(len(self._job_results)):
+            self._initializations[i].value = False
+            self._waiting_jobs[i].send(None)
+            self._processes[i].join()
+            self._processes[i].close()
+            self._waiting_jobs[i].close()
+            self._processes[i] = None
+            self.close_ipc_connection(i)
+
+
+def _shm_launch_domain_server_(
+    domain_factory,
+    lambdas,
+    i,
+    shm_proxy,
+    shm_registers,
+    shm_types,
+    shm_sizes,
+    rsize,
+    shm_arrays,
+    shm_lambdas,
+    shm_names,
+    shm_params,
+    init,
+    activation,
+    done,
+    cond,
+    ipc_conn,
+    logger,
+):
+    domain = domain_factory()
+
+    if ipc_conn is not None:
+        pusher = Push0()
+        pusher.dial(
+            ipc_conn, block=False
+        )  # WARNING: recent pynng updates only work with non-blocking dials!
+
+    with cond:
+        init.value = True
+        cond.notify_all()  # inform the parent process that we are ready to process requests
+
+    def get_string(s):
+        for i, c in enumerate(s):
+            if c == b"\x00":
+                return s[:i].decode()
+        return s.decode()
+
+    while True:
+        with cond:
+            cond.wait_for(lambda: bool(activation.value) == True)
+            activation.value = False
+        if int(shm_lambdas[i].value) == -1 and shm_names[i][0] == b"\x00":
+            if ipc_conn is not None:
+                pusher.close()
+            break
+        else:
+            try:
+                job_args = []
+                for p in shm_params[i]:
+                    if p >= 0:
+                        sz = shm_sizes[shm_types[p].__name__]
+                        if sz > 1:
+                            si = (i * rsize) + p
+                            job_args.append(
+                                shm_proxy.decode(
+                                    shm_types[p], shm_arrays[si : (si + sz)]
+                                )
+                            )
+                        else:
+                            job_args.append(
+                                shm_proxy.decode(
+                                    shm_types[p], shm_arrays[(i * rsize) + p]
+                                )
+                            )
+                    else:
+                        break  # no more args
+                if (
+                    int(shm_lambdas[i].value) == -1
+                ):  # we are working with a domain class' method
+                    result = getattr(domain, get_string(shm_names[i]))(*job_args)
+                else:  # we are working with a lambda function
+                    result = lambdas[int(shm_lambdas[i].value)](domain, *job_args)
+                shm_params[i][:] = [-1] * len(shm_params[i])
+                if type(result) is not tuple:
+                    result = (result,)
+                if result[0] is not None:
+                    type_counters = {}
+                    for j, r in enumerate(result):
+                        res_name = type(r).__name__
+                        (start, end) = shm_registers[res_name]
+                        if res_name in type_counters:
+                            type_counters[res_name] += 1
+                            k = type_counters[res_name]
+                            if k >= end:
+                                raise IndexError(
+                                    """No more available register for type {}.
+                                                    Please increase the number of registers
+                                                    for that type.""".format(
+                                        res_name
+                                    )
+                                )
+                        else:
+                            type_counters[res_name] = start
+                            k = start
+                        shm_params[i][j] = k
+                        sz = shm_sizes[res_name]
+                        if sz > 1:
+                            si = (i * rsize) + k
+                            shm_proxy.encode(r, shm_arrays[si : (si + sz)])
+                        else:
+                            shm_proxy.encode(r, shm_arrays[(i * rsize) + k])
+                if ipc_conn is not None:
+                    pusher.send(b"0")  # send success
+            except Exception as e:
+                if int(shm_lambdas[i].value) == -1:
+                    logger.error(
+                        rf"/!\ Unable to perform job {get_string(shm_names[i])}: {e}"
+                    )
+                else:
+                    logger.error(
+                        rf"/!\ Unable to perform job {int(shm_lambdas[i].value)}: {e}"
+                    )
+                if ipc_conn is not None:
+                    pusher.send(str(e).encode(encoding="UTF-8"))  # send error message
+            with cond:
+                done.value = True
+                cond.notify_all()  # send finished status (no success nor failure information)
+
+
+class ShmParallelDomain(ParallelDomain):
+    """This class can be used to create and launch n domains in separate processes
+    with shared memory between the Python processes.
+    Each domain listens for incoming domain requests.
+    Each request can indicate which domain should serve it, otherwise the first available
+    domain is chosen and its id is returned to the incoming request.
+    """
+
+    def __init__(
+        self,
+        domain_factory,
+        shm_proxy,
+        lambdas=None,
+        nb_domains=os.cpu_count(),
+        ipc_notify=False,
+    ):
+        super().__init__(domain_factory, lambdas, nb_domains, ipc_notify)
+        self._activations = [mp.Value("b", False, lock=True) for i in range(nb_domains)]
+        self._dones = [mp.Value("b", False, lock=True) for i in range(nb_domains)]
+        self._shm_proxy = shm_proxy
+        self._shm_registers = (
+            {}
+        )  # Maps from registered method parameter types to vectorized array ranges
+        self._shm_types = {}  # Maps from register index to type
+        self._shm_sizes = (
+            {}
+        )  # Maps from register method parameter types to number of arrays encoding each type
+        self._shm_arrays = []  # Methods' vectorized parameters
+        self._rsize = 0  # Total size of the register (updated below)
+        self._shm_lambdas = [None] * nb_domains  # Vectorized lambdas' ids
+        self._shm_names = [None] * nb_domains  # Vectorized methods' names
+        self._shm_params = [
+            None
+        ] * nb_domains  # Indices of methods' vectorized parameters
+        for i in range(nb_domains):
+            j = 0
+            for r in shm_proxy.register():
+                for k in range(r[1]):
+                    m = shm_proxy.initialize(r[0])
+                    if type(m) == list or type(m) == tuple:
+                        if (
+                            i == 0 and k == 0
+                        ):  # do it once for all the domains and redundant initializers
+                            self._shm_sizes[r[0].__name__] = len(m)
+                            self._shm_registers[r[0].__name__] = (
+                                j,
+                                j + (r[1] * len(m)),
+                            )
+                            self._shm_types.update(
+                                {
+                                    kk: r[0]
+                                    for kk in range(j, j + (r[1] * len(m)), len(m))
+                                }
+                            )
+                            self._rsize += r[1] * len(m)
+                        self._shm_arrays.extend(m)
+                        j += len(m)
+                    else:
+                        if (
+                            i == 0 and k == 0
+                        ):  # do it once for all the domains and redundant initializers
+                            self._shm_sizes[r[0].__name__] = 1
+                            self._shm_registers[r[0].__name__] = (j, j + r[1])
+                            self._shm_types.update(
+                                {kk: r[0] for kk in range(j, j + r[1])}
+                            )
+                            self._rsize += r[1]
+                        self._shm_arrays.append(m)
+                        j += 1
+            self._shm_lambdas[i] = mp.Value("i", -1, lock=True)
+            self._shm_names[i] = mp.Array("c", bytearray(100))
+            self._shm_params[i] = mp.Array(
+                "i", [-1] * sum(r[1] for r in shm_proxy.register())
+            )
+        logger.info(rf"Using {nb_domains} parallel shared memory domains")
+
+    def get_proc_connections(self):
+        return (self._activations, self._conditions)
+
+    def launch(self, i, function, *args):
+        if not any(self._processes):
+            self._launch_processes()
+        try:
+            mi = self.wake_up_domain(i)
+            if isinstance(function, str):  # function is a domain class' method
+                self._shm_lambdas[mi].value = -1
+                self._shm_names[mi][:] = bytearray(
+                    function, encoding="utf-8"
+                ) + bytearray(len(self._shm_names[mi]) - len(function))
+            else:  # function is a lambda id
+                self._shm_lambdas[mi].value = int(function)
+                self._shm_names[mi][:] = bytearray(
+                    len(self._shm_names[mi])
+                )  # reset with null bytes
+            self._shm_params[mi][:] = [-1] * len(self._shm_params[mi])
+            type_counters = {}
+            for j, a in enumerate(args):
+                arg_name = type(a).__name__
+                (start, end) = self._shm_registers[arg_name]
+                if arg_name in type_counters:
+                    type_counters[arg_name] += self._shm_sizes[arg_name]
+                    k = type_counters[arg_name]
+                    if k >= end:
+                        raise IndexError(
+                            """No more available register for type {}.
+                                            Please increase the number of registers
+                                            for that type.""".format(
+                                arg_name
+                            )
+                        )
+                else:
+                    type_counters[arg_name] = start
+                    k = start
+                self._shm_params[mi][j] = k
+                sz = self._shm_sizes[arg_name]
+                if sz > 1:
+                    si = (mi * self._rsize) + k
+                    self._shm_proxy.encode(a, self._shm_arrays[si : (si + sz)])
+                else:
+                    self._shm_proxy.encode(a, self._shm_arrays[(mi * self._rsize) + k])
+            with self._conditions[mi]:
+                self._activations[mi].value = True
+                self._conditions[mi].notify_all()
+            return mi
+        except Exception as e:
+            if isinstance(function, str):
+                logger.error(rf"/!\ Unable to launch job {function}: {e}")
+            else:
+                logger.error(rf"/!\ Unable to launch job lambdas[{function}]: {e}")
+
+    def get_result(self, i):
+        with self._conditions[i]:
+            self._conditions[i].wait_for(lambda: bool(self._dones[i].value) == True)
+            self._dones[i].value = False
+        results = []
+        for r in self._shm_params[i]:
+            if r >= 0:
+                sz = self._shm_sizes[self._shm_types[r].__name__]
+                if sz > 1:
+                    si = (i * self._rsize) + r
+                    results.append(
+                        self._shm_proxy.decode(
+                            self._shm_types[r], self._shm_arrays[si : (si + sz)]
+                        )
+                    )
+                else:
+                    results.append(
+                        self._shm_proxy.decode(
+                            self._shm_types[r], self._shm_arrays[(i * self._rsize) + r]
+                        )
+                    )
+            else:
+                break  # no more params
+        self._active_domains[i] = False
+        return results if len(results) > 1 else results[0] if len(results) > 0 else None
+
+    def _launch_processes(self):
+        for i in range(len(self._processes)):
+            self.open_ipc_connection(i)
+            self._processes[i] = mp.Process(
+                target=_shm_launch_domain_server_,
+                args=[
+                    self._domain_factory,
+                    self._lambdas,
+                    i,
+                    self._shm_proxy.copy(),
+                    dict(self._shm_registers),
+                    dict(self._shm_types),
+                    dict(self._shm_sizes),
+                    self._rsize,
+                    list(self._shm_arrays),
+                    list(self._shm_lambdas),
+                    list(self._shm_names),
+                    list(self._shm_params),
+                    self._initializations[i],
+                    self._activations[i],
+                    self._dones[i],
+                    self._conditions[i],
+                    self._ipc_connections[i] if self._ipc_notify else None,
+                    logger,
+                ],
+            )
+            self._processes[i].start()
+        # Waits for all jobs to be launched and waiting each for requests
+        for i in range(len(self._processes)):
+            with self._conditions[i]:
+                self._conditions[i].wait_for(
+                    lambda: bool(self._initializations[i].value) == True
+                )
+
+    def close(self):
+        for i in range(len(self._processes)):
+            self._initializations[i].value = False
+            self._shm_lambdas[i].value = -1
+            self._shm_names[i][:] = bytearray(
+                len(self._shm_names[i])
+            )  # reset with null bytes
+            self._shm_params[i][:] = [-1] * len(self._shm_params[i])
+            with self._conditions[i]:
+                self._activations[i].value = True
+                self._conditions[i].notify_all()
+            self._processes[i].join()
+            self._processes[i].close()
+            self._processes[i] = None
+            self.close_ipc_connection(i)
```

## skdecide/solvers.py

```diff
@@ -1,293 +1,221 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-"""This module contains base classes for quickly building solvers."""
-from __future__ import annotations
-
-from typing import Callable, List
-
-from skdecide.builders.solver.policy import DeterministicPolicies
-from skdecide.core import D, autocast_all, autocastable
-from skdecide.domains import Domain
-
-__all__ = ["Solver", "DeterministicPolicySolver"]
-
-
-# MAIN BASE CLASS
-
-
-class Solver:
-    """This is the highest level solver class (inheriting top-level class for each mandatory solver characteristic).
-
-    This helper class can be used as the main base class for solvers.
-
-    Typical use:
-    ```python
-    class MySolver(Solver, ...)
-    ```
-
-    with "..." replaced when needed by a number of classes from following domain characteristics (the ones in
-    parentheses are optional):
-
-    - **(assessability)**: Utilities -> QValues
-    - **(policy)**: Policies -> UncertainPolicies -> DeterministicPolicies
-    - **(restorability)**: Restorable
-    """
-
-    T_domain = Domain
-
-    @classmethod
-    def get_domain_requirements(cls) -> List[type]:
-        """Get domain requirements for this solver class to be applicable.
-
-        Domain requirements are classes from the #skdecide.builders.domain package that the domain needs to inherit from.
-
-        # Returns
-        A list of classes to inherit from.
-        """
-        return cls._get_domain_requirements()
-
-    @classmethod
-    def _get_domain_requirements(cls) -> List[type]:
-        """Get domain requirements for this solver class to be applicable.
-
-        Domain requirements are classes from the #skdecide.builders.domain package that the domain needs to inherit from.
-
-        # Returns
-        A list of classes to inherit from.
-        """
-
-        def is_domain_builder(
-            cls,
-        ):  # detected by having only single-'base class' ancestors until root
-            remove_ancestors = []
-            while True:
-                bases = cls.__bases__
-                if len(bases) == 0:
-                    return True, remove_ancestors
-                elif len(bases) == 1:
-                    cls = bases[0]
-                    remove_ancestors.append(cls)
-                else:
-                    return False, []
-
-        i = 0
-        sorted_ancestors = list(cls.T_domain.__mro__[:-1])
-        while i < len(sorted_ancestors):
-            ancestor = sorted_ancestors[i]
-            is_builder, remove_ancestors = is_domain_builder(ancestor)
-            if is_builder:
-                sorted_ancestors = [
-                    a for a in sorted_ancestors if a not in remove_ancestors
-                ]
-                i += 1
-            else:
-                sorted_ancestors.remove(ancestor)
-        return sorted_ancestors
-
-    @classmethod
-    def check_domain(cls, domain: Domain) -> bool:
-        """Check whether a domain is compliant with this solver type.
-
-        By default, #Solver.check_domain() provides some boilerplate code and internally
-        calls #Solver._check_domain_additional() (which returns True by default but can be overridden  to define
-        specific checks in addition to the "domain requirements"). The boilerplate code automatically checks whether all
-        domain requirements are met.
-
-        # Parameters
-        domain: The domain to check.
-
-        # Returns
-        True if the domain is compliant with the solver type (False otherwise).
-        """
-        return cls._check_domain(domain)
-
-    @classmethod
-    def _check_domain(cls, domain: Domain) -> bool:
-        """Check whether a domain is compliant with this solver type.
-
-        By default, #Solver._check_domain() provides some boilerplate code and internally
-        calls #Solver._check_domain_additional() (which returns True by default but can be overridden to define specific
-        checks in addition to the "domain requirements"). The boilerplate code automatically checks whether all domain
-        requirements are met.
-
-        # Parameters
-        domain: The domain to check.
-
-        # Returns
-        True if the domain is compliant with the solver type (False otherwise).
-        """
-        check_requirements = all(
-            isinstance(domain, req) for req in cls._get_domain_requirements()
-        )
-        return check_requirements and cls._check_domain_additional(domain)
-
-    @classmethod
-    def _check_domain_additional(cls, domain: D) -> bool:
-        """Check whether the given domain is compliant with the specific requirements of this solver type (i.e. the
-        ones in addition to "domain requirements").
-
-        This is a helper function called by default from #Solver._check_domain(). It focuses on specific checks, as
-        opposed to taking also into account the domain requirements for the latter.
-
-        # Parameters
-        domain: The domain to check.
-
-        # Returns
-        True if the domain is compliant with the specific requirements of this solver type (False otherwise).
-        """
-        return True
-
-    def reset(self) -> None:
-        """Reset whatever is needed on this solver before running a new episode.
-
-        This function does nothing by default but can be overridden if needed (e.g. to reset the hidden state of a LSTM
-        policy network, which carries information about past observations seen in the previous episode).
-        """
-        return self._reset()
-
-    def _reset(self) -> None:
-        """Reset whatever is needed on this solver before running a new episode.
-
-        This function does nothing by default but can be overridden if needed (e.g. to reset the hidden state of a LSTM
-        policy network, which carries information about past observations seen in the previous episode).
-        """
-        pass
-
-    def solve(self, domain_factory: Callable[[], Domain]) -> None:
-        """Run the solving process.
-
-        By default, #Solver.solve() provides some boilerplate code and internally calls #Solver._solve(). The
-        boilerplate code transforms the domain factory to auto-cast the new domains to the level expected by the solver.
-
-        # Parameters
-        domain_factory: A callable with no argument returning the domain to solve (can be just a domain class).
-
-        !!! tip
-            The nature of the solutions produced here depends on other solver's characteristics like
-            #policy and #assessibility.
-        """
-        return self._solve(domain_factory)
-
-    def _solve(self, domain_factory: Callable[[], Domain]) -> None:
-        """Run the solving process.
-
-        By default, #Solver._solve() provides some boilerplate code and internally calls #Solver._solve_domain(). The
-        boilerplate code transforms the domain factory to auto-cast the new domains to the level expected by the solver.
-
-        # Parameters
-        domain_factory: A callable with no argument returning the domain to solve (can be just a domain class).
-
-        !!! tip
-            The nature of the solutions produced here depends on other solver's characteristics like
-            #policy and #assessibility.
-        """
-
-        def cast_domain_factory():
-            domain = domain_factory()
-            autocast_all(domain, domain, self.T_domain)
-            return domain
-
-        return self._solve_domain(cast_domain_factory)
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        """Run the solving process.
-
-        This is a helper function called by default from #Solver._solve(), the difference being that the domain factory
-        here returns domains auto-cast to the level expected by the solver.
-
-        # Parameters
-        domain_factory: A callable with no argument returning the domain to solve (auto-cast to expected level).
-
-        !!! tip
-            The nature of the solutions produced here depends on other solver's characteristics like
-            #policy and #assessibility.
-        """
-        raise NotImplementedError
-
-    @autocastable
-    def solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-        """Run the solving process from a given state.
-
-        !!! tip
-            Create the domain first by calling the @Solver.reset() method
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-
-        !!! tip
-            The nature of the solutions produced here depends on other solver's characteristics like
-            #policy and #assessibility.
-        """
-        return self._solve_from(memory)
-
-    def _solve_from(self, memory: D.T_memory[D.T_state]) -> None:
-        """Run the solving process from a given state.
-
-        !!! tip
-            Create the domain first by calling the @Solver.reset() method
-
-        # Parameters
-        memory: The source memory (state or history) of the transition.
-
-        !!! tip
-            The nature of the solutions produced here depends on other solver's characteristics like
-            #policy and #assessibility.
-        """
-        pass
-
-    def _initialize(self):
-        """Runs long-lasting initialization code here, or code to be executed at the
-        entering of a 'with' context statement.
-        """
-        pass
-
-    def _cleanup(self):
-        """Runs cleanup code here, or code to be executed at the exit of a
-        'with' context statement.
-        """
-        pass
-
-    def __enter__(self):
-        """Allow for calling the solver within a 'with' context statement.
-        Note that some solvers require such context statements to properly
-        clean their status before exiting the Python interpreter, thus it
-        is a good habit to always call solvers within a 'with' statement.
-        """
-        self._initialize()
-        return self
-
-    def __exit__(self, type, value, tb):
-        """Allow for calling the solver within a 'with' context statement.
-        Note that some solvers require such context statements to properly
-        clean their status before exiting the Python interpreter, thus it
-        is a good habit to always call solvers within a 'with' statement.
-        """
-        self._cleanup()
-
-
-# ALTERNATE BASE CLASSES (for typical combinations)
-
-
-class DeterministicPolicySolver(Solver, DeterministicPolicies):
-    """This is a typical deterministic policy solver class.
-
-    This helper class can be used as an alternate base class for domains, inheriting the following:
-
-    - Solver
-    - DeterministicPolicies
-
-    Typical use:
-    ```python
-    class MySolver(DeterministicPolicySolver)
-    ```
-
-    !!! tip
-        It is also possible to refine any alternate base class, like for instance:
-        ```python
-        class MySolver(DeterministicPolicySolver, QValues)
-        ```
-    """
-
-    pass
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+"""This module contains base classes for quickly building solvers."""
+from __future__ import annotations
+
+from typing import Callable, List, Optional, Type
+
+from skdecide import autocast_all
+from skdecide.builders.solver.fromanystatesolvability import FromInitialState
+from skdecide.builders.solver.policy import DeterministicPolicies
+from skdecide.domains import Domain
+
+__all__ = ["Solver", "DeterministicPolicySolver"]
+
+
+# MAIN BASE CLASS
+
+
+class Solver(FromInitialState):
+    """This is the highest level solver class (inheriting top-level class for each mandatory solver characteristic).
+
+    This helper class can be used as the main base class for solvers.
+
+    Typical use:
+    ```python
+    class MySolver(Solver, ...)
+    ```
+
+    with "..." replaced when needed by a number of classes from following domain characteristics (the ones in
+    parentheses are optional):
+
+    - **(assessability)**: Utilities -> QValues
+    - **(policy)**: Policies -> UncertainPolicies -> DeterministicPolicies
+    - **(restorability)**: Restorable
+
+    """
+
+    T_domain = Domain
+
+    _already_autocast = False
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], Domain],
+    ):
+        """
+
+        # Parameters
+        domain_factory: A callable with no argument returning the domain to solve (can be a mere domain class).
+            The resulting domain will be auto-cast to the level expected by the solver.
+
+        """
+
+        def cast_domain_factory():
+            domain = domain_factory()
+            autocast_all(domain, domain, self.T_domain)
+            return domain
+
+        self._domain_factory = cast_domain_factory
+        self._original_domain_factory = domain_factory
+
+    @classmethod
+    def get_domain_requirements(cls) -> List[type]:
+        """Get domain requirements for this solver class to be applicable.
+
+        Domain requirements are classes from the #skdecide.builders.domain package that the domain needs to inherit from.
+
+        # Returns
+        A list of classes to inherit from.
+        """
+
+        def is_domain_builder(
+            cls,
+        ):  # detected by having only single-'base class' ancestors until root
+            remove_ancestors = []
+            while True:
+                bases = cls.__bases__
+                if len(bases) == 0:
+                    return True, remove_ancestors
+                elif len(bases) == 1:
+                    cls = bases[0]
+                    remove_ancestors.append(cls)
+                else:
+                    return False, []
+
+        i = 0
+        sorted_ancestors = list(cls.T_domain.__mro__[:-1])
+        while i < len(sorted_ancestors):
+            ancestor = sorted_ancestors[i]
+            is_builder, remove_ancestors = is_domain_builder(ancestor)
+            if is_builder:
+                sorted_ancestors = [
+                    a for a in sorted_ancestors if a not in remove_ancestors
+                ]
+                i += 1
+            else:
+                sorted_ancestors.remove(ancestor)
+        return sorted_ancestors
+
+    @classmethod
+    def check_domain(cls, domain: Domain) -> bool:
+        """Check whether a domain is compliant with this solver type.
+
+        By default, #Solver.check_domain() provides some boilerplate code and internally
+        calls #Solver._check_domain_additional() (which returns True by default but can be overridden  to define
+        specific checks in addition to the "domain requirements"). The boilerplate code automatically checks whether all
+        domain requirements are met.
+
+        # Parameters
+        domain: The domain to check.
+
+        # Returns
+        True if the domain is compliant with the solver type (False otherwise).
+        """
+        check_requirements = all(
+            isinstance(domain, req) for req in cls.get_domain_requirements()
+        )
+        return check_requirements and cls._check_domain_additional(domain)
+
+    @classmethod
+    def _check_domain_additional(cls, domain: Domain) -> bool:
+        """Check whether the given domain is compliant with the specific requirements of this solver type (i.e. the
+        ones in addition to "domain requirements").
+
+        This is a helper function called by default from #Solver.check_domain(). It focuses on specific checks, as
+        opposed to taking also into account the domain requirements for the latter.
+
+        # Parameters
+        domain: The domain to check.
+
+        # Returns
+        True if the domain is compliant with the specific requirements of this solver type (False otherwise).
+        """
+        return True
+
+    def reset(self) -> None:
+        """Reset whatever is needed on this solver before running a new episode.
+
+        This function does nothing by default but can be overridden if needed (e.g. to reset the hidden state of a LSTM
+        policy network, which carries information about past observations seen in the previous episode).
+        """
+        return self._reset()
+
+    def _reset(self) -> None:
+        """Reset whatever is needed on this solver before running a new episode.
+
+        This function does nothing by default but can be overridden if needed (e.g. to reset the hidden state of a LSTM
+        policy network, which carries information about past observations seen in the previous episode).
+        """
+        pass
+
+    def _initialize(self):
+        """Runs long-lasting initialization code here, or code to be executed at the
+        entering of a 'with' context statement.
+        """
+        pass
+
+    def _cleanup(self):
+        """Runs cleanup code here, or code to be executed at the exit of a
+        'with' context statement.
+        """
+        pass
+
+    def __enter__(self):
+        """Allow for calling the solver within a 'with' context statement.
+        Note that some solvers require such context statements to properly
+        clean their status before exiting the Python interpreter, thus it
+        is a good habit to always call solvers within a 'with' statement.
+        """
+        self._initialize()
+        return self
+
+    def __exit__(self, type, value, tb):
+        """Allow for calling the solver within a 'with' context statement.
+        Note that some solvers require such context statements to properly
+        clean their status before exiting the Python interpreter, thus it
+        is a good habit to always call solvers within a 'with' statement.
+        """
+        self._cleanup()
+
+    def autocast(self, domain_cls: Optional[Type[Domain]] = None) -> None:
+        """Autocast itself to the level corresponding to the given domain class.
+
+        # Parameters
+        domain_cls: the domain class to which level the solver needs to autocast itself.
+            By default, use the original domain factory passed to its constructor.
+
+        """
+        if not self._already_autocast:
+            if domain_cls is None:
+                domain_cls = type(self._original_domain_factory())
+            autocast_all(self, self.T_domain, domain_cls)
+            self._already_autocast = True
+
+
+# ALTERNATE BASE CLASSES (for typical combinations)
+
+
+class DeterministicPolicySolver(Solver, DeterministicPolicies):
+    """This is a typical deterministic policy solver class.
+
+    This helper class can be used as an alternate base class for domains, inheriting the following:
+
+    - Solver
+    - DeterministicPolicies
+
+    Typical use:
+    ```python
+    class MySolver(DeterministicPolicySolver)
+    ```
+
+    !!! tip
+        It is also possible to refine any alternate base class, like for instance:
+        ```python
+        class MySolver(DeterministicPolicySolver, QValues)
+        ```
+    """
+
+    pass
```

## skdecide/utils.py

```diff
@@ -1,415 +1,313 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-"""This module contains utility functions."""
-from __future__ import annotations
-
-import copy
-import datetime
-import importlib.metadata
-import logging
-import os
-import sys
-import time
-from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Type, Union
-
-from skdecide import (
-    D,
-    Domain,
-    EnvironmentOutcome,
-    Solver,
-    Space,
-    autocast_all,
-    autocastable,
-)
-from skdecide.builders.domain import FullyObservable, Goals, Markovian, Renderable
-from skdecide.builders.solver import Policies
-
-__all__ = [
-    "get_registered_domains",
-    "get_registered_solvers",
-    "load_registered_domain",
-    "load_registered_solver",
-    "match_solvers",
-    "rollout",
-    "rollout_episode",
-]
-
-SKDECIDE_DEFAULT_DATAHOME = "~/skdecide_data"
-SKDECIDE_DEFAULT_DATAHOME_ENVVARNAME = "SKDECIDE_DATA"
-
-logger = logging.getLogger("skdecide.utils")
-
-logger.setLevel(logging.INFO)
-
-if not len(logger.handlers):
-    ch = logging.StreamHandler()
-    # create formatter and add it to the handlers
-    formatter = logging.Formatter(
-        "%(asctime)s | %(name)s | %(levelname)s | %(message)s"
-    )
-    ch.setFormatter(formatter)
-    # add the handlers to the logger
-    logger.addHandler(ch)
-    logger.propagate = False
-
-
-def get_data_home(data_home: Optional[str] = None) -> str:
-    """Return the path of the scikit-decide data directory.
-
-    This folder is used by some large dataset loaders to avoid downloading the
-    data several times, as for instance the weather data used by the flight planning domain.
-    By default the data dir is set to a folder named 'skdecide_data' in the
-    user home folder.
-    Alternatively, it can be set by the 'SKDECIDE_DATA' environment
-    variable or programmatically by giving an explicit folder path. The '~'
-    symbol is expanded to the user home folder.
-    If the folder does not already exist, it is automatically created.
-
-    Params:
-        data_home : The path to scikit-decide data directory. If `None`, the default path
-        is `~/skdecide_data`.
-
-    """
-    if data_home is None:
-        data_home = os.environ.get(
-            SKDECIDE_DEFAULT_DATAHOME_ENVVARNAME, SKDECIDE_DEFAULT_DATAHOME
-        )
-    data_home = os.path.expanduser(data_home)
-    os.makedirs(data_home, exist_ok=True)
-    return data_home
-
-
-def _get_registered_entries(entry_type: str) -> List[str]:
-    if (
-        sys.version_info.minor < 10 and sys.version_info.major == 3
-    ):  # different behaviour for 3.8 and 3.9
-        return [e.name for e in importlib.metadata.entry_points()[entry_type]]
-    else:
-        return [e.name for e in importlib.metadata.entry_points(group=entry_type)]
-
-
-def _load_registered_entry(entry_type: str, entry_name: str) -> Optional[Any]:
-    if (
-        sys.version_info.minor < 10 and sys.version_info.major == 3
-    ):  # different behaviour for 3.8 and 3.9
-        potential_entry_points = tuple(
-            e
-            for e in importlib.metadata.entry_points()[entry_type]
-            if e.name == entry_name
-        )
-    else:
-        potential_entry_points = tuple(
-            importlib.metadata.entry_points(group=entry_type, name=entry_name)
-        )
-    if len(potential_entry_points) == 0:
-        logger.warning(
-            rf'/!\ {entry_name} could not be loaded because it is not registered in group "{entry_type}".'
-        )
-    else:
-        try:
-            return potential_entry_points[0].load()
-        except Exception as e:
-            logger.warning(rf"/!\ {entry_name} could not be loaded ({e}).")
-
-
-def get_registered_domains() -> List[str]:
-    return _get_registered_entries("skdecide.domains")
-
-
-def get_registered_solvers() -> List[str]:
-    return _get_registered_entries("skdecide.solvers")
-
-
-def load_registered_domain(name: str) -> Type[Domain]:
-    return _load_registered_entry("skdecide.domains", name)
-
-
-def load_registered_solver(name: str) -> Type[Solver]:
-    return _load_registered_entry("skdecide.solvers", name)
-
-
-# TODO: implement ranking heuristic
-def match_solvers(
-    domain: Domain,
-    candidates: Optional[Iterable[Type[Solver]]] = None,
-    ranked: bool = False,
-) -> Union[List[Type[Solver]], List[Tuple[Type[Solver], int]]]:
-    if candidates is None:
-        candidates = [load_registered_solver(s) for s in get_registered_solvers()]
-        candidates = [
-            c for c in candidates if c is not None
-        ]  # filter out None entries (failed loadings)
-    matches = []
-    for solver_type in candidates:
-        if solver_type.check_domain(domain):
-            matches.append(solver_type)
-    return matches
-
-
-def rollout(
-    domain: Domain,
-    solver: Optional[Solver] = None,
-    from_memory: Optional[D.T_memory[D.T_state]] = None,
-    from_action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    num_episodes: int = 1,
-    max_steps: Optional[int] = None,
-    render: bool = True,
-    max_framerate: Optional[float] = None,
-    verbose: bool = True,
-    action_formatter: Optional[Callable[[D.T_event], str]] = lambda a: str(a),
-    outcome_formatter: Optional[Callable[[EnvironmentOutcome], str]] = lambda o: str(o),
-) -> None:
-    """This method will run one or more episodes in a domain according to the policy of a solver.
-
-    # Parameters
-    domain: The domain in which the episode(s) will be run.
-    solver: The solver whose policy will select actions to take (if None, a random policy is used).
-    from_memory: The memory or state to consider as rollout starting point (if None, the domain is reset first).
-    from_action: The last applied action when from_memory is used (if necessary for initial observation computation).
-    num_episodes: The number of episodes to run.
-    max_steps: The maximum number of steps for each episode (if None, no limit is set).
-    render: Whether to render the episode(s) during rollout if the domain is renderable.
-    max_framerate: The maximum number of steps/renders per second (if None, steps/renders are never slowed down).
-    verbose: Whether to print information to the console during rollout.
-    action_formatter: The function transforming actions in the string to print (if None, no print).
-    outcome_formatter: The function transforming EnvironmentOutcome objects in the string to print (if None, no print).
-    """
-    if verbose:
-        logger.setLevel(logging.DEBUG)
-        logger.debug(
-            "Logger is in verbose mode: all debug messages will be there for you to enjoy ^^ )"
-        )
-
-    if solver is None:
-        # Create solver-like random walker that works for any domain
-        class RandomWalk(Policies):
-            T_domain = Domain
-            T_agent = Domain.T_agent
-            T_event = Domain.T_event
-
-            def __init__(self):
-                class CastDomain:  # trick to autocast domain's get_applicable_actions() without mutating domain
-                    T_agent = domain.T_agent
-                    T_event = domain.T_event
-
-                    @autocastable
-                    def get_applicable_actions(self) -> D.T_agent[Space[D.T_event]]:
-                        return domain.get_applicable_actions()
-
-                self._domain = CastDomain()
-                autocast_all(self._domain, self._domain, self)
-
-            @autocastable
-            def reset(self) -> None:
-                pass
-
-            @autocastable
-            def sample_action(
-                self, observation: D.T_agent[D.T_observation]
-            ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-                return {
-                    agent: [space.sample()]
-                    for agent, space in self._domain.get_applicable_actions().items()
-                }
-
-            @autocastable
-            def is_policy_defined_for(
-                self, observation: D.T_agent[D.T_observation]
-            ) -> bool:
-                return True
-
-        solver = RandomWalk()
-        autocast_all(solver, solver.T_domain, domain)
-
-    has_render = isinstance(domain, Renderable)
-    has_goal = isinstance(domain, Goals)
-    has_memory = not isinstance(domain, Markovian)
-    for i_episode in range(num_episodes):
-        # Initialize episode
-        solver.reset()
-        if from_memory is None:
-            observation = domain.reset()
-        else:
-            domain.set_memory(from_memory)
-            last_state = from_memory[-1] if has_memory else from_memory
-            observation = domain.get_observation_distribution(
-                last_state, from_action
-            ).sample()
-        logger.debug(f"Episode {i_episode + 1} started with following observation:")
-        logger.debug(observation)
-        # Run episode
-        step = 1
-
-        while max_steps is None or step <= max_steps:
-            old_time = time.perf_counter()
-            if render and has_render:
-                domain.render()
-            # assert solver.is_policy_defined_for(observation)
-            action = solver.sample_action(observation)
-            if action_formatter is not None:
-                logger.debug("Action: {}".format(action_formatter(action)))
-            outcome = domain.step(action)
-            observation = outcome.observation
-            if outcome_formatter is not None:
-                logger.debug("Result: {}".format(outcome_formatter(outcome)))
-            termination = (
-                outcome.termination
-                if domain.T_agent == Union
-                else all(t for a, t in outcome.termination.items())
-            )
-            if termination:
-                logger.debug(
-                    f"Episode {i_episode + 1} terminated after {step + 1} steps."
-                )
-                break
-            if max_framerate is not None:
-                wait = 1 / max_framerate - (time.perf_counter() - old_time)
-                if wait > 0:
-                    time.sleep(wait)
-            step += 1
-        if render and has_render:
-            domain.render()
-        if has_goal:
-            logger.info(
-                f'The goal was{"" if domain.is_goal(observation) else " not"} reached '
-                f"in episode {i_episode + 1}."
-            )
-
-
-def rollout_episode(
-    domain: Domain,
-    solver: Optional[Union[Solver, Policies]] = None,
-    from_memory: Optional[D.T_memory[D.T_state]] = None,
-    from_action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
-    num_episodes: int = 1,
-    max_steps: Optional[int] = None,
-    render: bool = True,
-    max_framerate: Optional[float] = None,
-    verbose: bool = True,
-    action_formatter: Optional[Callable[[D.T_event], str]] = None,
-    outcome_formatter: Optional[Callable[[EnvironmentOutcome], str]] = None,
-) -> Tuple[List[D.T_observation], List[D.T_event], List[D.T_value]]:
-    """This method will run one or more episodes in a domain according to the policy of a solver.
-
-    # Parameters
-    domain: The domain in which the episode(s) will be run.
-    solver: The solver whose policy will select actions to take (if None, a random policy is used).
-    from_memory: The memory or state to consider as rollout starting point (if None, the domain is reset first).
-    from_action: The last applied action when from_memory is used (if necessary for initial observation computation).
-    num_episodes: The number of episodes to run.
-    max_steps: The maximum number of steps for each episode (if None, no limit is set).
-    render: Whether to render the episode(s) during rollout if the domain is renderable.
-    max_framerate: The maximum number of steps/renders per second (if None, steps/renders are never slowed down).
-    verbose: Whether to print information to the console during rollout.
-    action_formatter: The function transforming actions in the string to print (if None, no print).
-    outcome_formatter: The function transforming EnvironmentOutcome objects in the string to print (if None, no print).
-    """
-    if verbose:
-        logger.setLevel(logging.DEBUG)
-        logger.debug(
-            "Logger is in verbose mode: all debug messages will be there for you to enjoy ^^ )"
-        )
-
-    if solver is None:
-        # Create solver-like random walker that works for any domain
-        class RandomWalk(Policies):
-            T_domain = Domain
-            T_agent = Domain.T_agent
-            T_event = Domain.T_event
-
-            def __init__(self):
-                class CastDomain:  # trick to autocast domain's get_applicable_actions() without mutating domain
-                    T_agent = domain.T_agent
-                    T_event = domain.T_event
-
-                    @autocastable
-                    def get_applicable_actions(self) -> D.T_agent[Space[D.T_event]]:
-                        return domain.get_applicable_actions()
-
-                self._domain = CastDomain()
-                autocast_all(self._domain, self._domain, self)
-
-            @autocastable
-            def reset(self) -> None:
-                pass
-
-            @autocastable
-            def sample_action(
-                self, observation: D.T_agent[D.T_observation]
-            ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-                return {
-                    agent: [space.sample()]
-                    for agent, space in self._domain.get_applicable_actions().items()
-                }
-
-            @autocastable
-            def is_policy_defined_for(
-                self, observation: D.T_agent[D.T_observation]
-            ) -> bool:
-                return True
-
-        solver = RandomWalk()
-        autocast_all(solver, solver.T_domain, domain)
-
-    has_render = isinstance(domain, Renderable)
-    has_goal = isinstance(domain, Goals)
-    has_memory = not isinstance(domain, Markovian)
-    for i_episode in range(num_episodes):
-        # Initialize episode
-        solver.reset()
-        if from_memory is None:
-            # observation = domain.reset()
-            pass
-        else:
-            domain.set_memory(from_memory)
-            last_state = from_memory[-1] if has_memory else from_memory
-            observation = domain.get_observation_distribution(
-                last_state, from_action
-            ).sample()
-        if verbose:
-            logger.debug(f"Episode {i_episode + 1} started with following observation:")
-            logger.debug(observation)
-        # Run episode
-        step = 1
-
-        observations = []
-        actions = []
-        values = []
-        # save the initial observation
-        observations.append(observation)
-
-        while max_steps is None or step <= max_steps:
-            old_time = time.perf_counter()
-            if render and has_render:
-                domain.render()
-            action = solver.sample_action(observation)
-            if action_formatter is not None:
-                logger.debug("Action: {}".format(action_formatter(action)))
-            domain.set_memory(observations[-1])
-            outcome = domain.step(action)
-            observation = outcome.observation
-            observations.append(observation)
-            actions.append(action)
-            values.append(outcome.value)
-            if outcome_formatter is not None:
-                logger.debug("Result: {}".format(outcome_formatter(outcome)))
-            if outcome.termination:
-                logger.debug(
-                    f"Episode {i_episode + 1} terminated after {step + 1} steps."
-                )
-                break
-            if max_framerate is not None:
-                wait = 1 / max_framerate - (time.perf_counter() - old_time)
-                if wait > 0:
-                    time.sleep(wait)
-            step += 1
-        if render and has_render:
-            domain.render()
-        if has_goal and verbose:
-            logger.info(
-                f'The goal was{"" if domain.is_goal(observation) else " not"} reached '
-                f"in episode {i_episode + 1}."
-            )
-        return observations, actions, values
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+"""This module contains utility functions."""
+from __future__ import annotations
+
+import copy
+import datetime
+import importlib.metadata
+import logging
+import os
+import sys
+import time
+from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Type, Union
+
+from skdecide import (
+    D,
+    Domain,
+    EnvironmentOutcome,
+    Solver,
+    Space,
+    autocast_all,
+    autocastable,
+)
+from skdecide.builders.domain import FullyObservable, Goals, Markovian, Renderable
+from skdecide.builders.solver import Policies
+
+__all__ = [
+    "get_registered_domains",
+    "get_registered_solvers",
+    "load_registered_domain",
+    "load_registered_solver",
+    "match_solvers",
+    "rollout",
+]
+
+SKDECIDE_DEFAULT_DATAHOME = "~/skdecide_data"
+SKDECIDE_DEFAULT_DATAHOME_ENVVARNAME = "SKDECIDE_DATA"
+
+logger = logging.getLogger("skdecide.utils")
+
+logger.setLevel(logging.INFO)
+
+if not len(logger.handlers):
+    ch = logging.StreamHandler()
+    # create formatter and add it to the handlers
+    formatter = logging.Formatter(
+        "%(asctime)s | %(name)s | %(levelname)s | %(message)s"
+    )
+    ch.setFormatter(formatter)
+    # add the handlers to the logger
+    logger.addHandler(ch)
+    logger.propagate = False
+
+
+def get_data_home(data_home: Optional[str] = None) -> str:
+    """Return the path of the scikit-decide data directory.
+
+    This folder is used by some large dataset loaders to avoid downloading the
+    data several times, as for instance the weather data used by the flight planning domain.
+    By default the data dir is set to a folder named 'skdecide_data' in the
+    user home folder.
+    Alternatively, it can be set by the 'SKDECIDE_DATA' environment
+    variable or programmatically by giving an explicit folder path. The '~'
+    symbol is expanded to the user home folder.
+    If the folder does not already exist, it is automatically created.
+
+    Params:
+        data_home : The path to scikit-decide data directory. If `None`, the default path
+        is `~/skdecide_data`.
+
+    """
+    if data_home is None:
+        data_home = os.environ.get(
+            SKDECIDE_DEFAULT_DATAHOME_ENVVARNAME, SKDECIDE_DEFAULT_DATAHOME
+        )
+    data_home = os.path.expanduser(data_home)
+    os.makedirs(data_home, exist_ok=True)
+    return data_home
+
+
+def _get_registered_entries(entry_type: str) -> List[str]:
+    if (
+        sys.version_info.minor < 10 and sys.version_info.major == 3
+    ):  # different behaviour for 3.8 and 3.9
+        return [e.name for e in importlib.metadata.entry_points()[entry_type]]
+    else:
+        return [e.name for e in importlib.metadata.entry_points(group=entry_type)]
+
+
+def _load_registered_entry(entry_type: str, entry_name: str) -> Optional[Any]:
+    if (
+        sys.version_info.minor < 10 and sys.version_info.major == 3
+    ):  # different behaviour for 3.8 and 3.9
+        potential_entry_points = tuple(
+            e
+            for e in importlib.metadata.entry_points()[entry_type]
+            if e.name == entry_name
+        )
+    else:
+        potential_entry_points = tuple(
+            importlib.metadata.entry_points(group=entry_type, name=entry_name)
+        )
+    if len(potential_entry_points) == 0:
+        logger.warning(
+            rf'/!\ {entry_name} could not be loaded because it is not registered in group "{entry_type}".'
+        )
+    else:
+        try:
+            return potential_entry_points[0].load()
+        except Exception as e:
+            logger.warning(rf"/!\ {entry_name} could not be loaded ({e}).")
+
+
+def get_registered_domains() -> List[str]:
+    return _get_registered_entries("skdecide.domains")
+
+
+def get_registered_solvers() -> List[str]:
+    return _get_registered_entries("skdecide.solvers")
+
+
+def load_registered_domain(name: str) -> Type[Domain]:
+    return _load_registered_entry("skdecide.domains", name)
+
+
+def load_registered_solver(name: str) -> Type[Solver]:
+    return _load_registered_entry("skdecide.solvers", name)
+
+
+# TODO: implement ranking heuristic
+def match_solvers(
+    domain: Domain,
+    candidates: Optional[Iterable[Type[Solver]]] = None,
+    ranked: bool = False,
+) -> Union[List[Type[Solver]], List[Tuple[Type[Solver], int]]]:
+    if candidates is None:
+        candidates = [load_registered_solver(s) for s in get_registered_solvers()]
+        candidates = [
+            c for c in candidates if c is not None
+        ]  # filter out None entries (failed loadings)
+    matches = []
+    for solver_type in candidates:
+        if solver_type.check_domain(domain):
+            matches.append(solver_type)
+    return matches
+
+
+def rollout(
+    domain: Domain,
+    solver: Optional[Union[Solver, Policies]] = None,
+    from_memory: Optional[D.T_memory[D.T_state]] = None,
+    from_action: Optional[D.T_agent[D.T_concurrency[D.T_event]]] = None,
+    num_episodes: int = 1,
+    max_steps: Optional[int] = None,
+    render: bool = True,
+    max_framerate: Optional[float] = None,
+    verbose: bool = True,
+    action_formatter: Optional[Callable[[D.T_event], str]] = lambda a: str(a),
+    outcome_formatter: Optional[Callable[[EnvironmentOutcome], str]] = lambda o: str(o),
+    return_episodes: bool = False,
+    goal_logging_level: int = logging.INFO,
+) -> Optional[List[Tuple[List[D.T_observation], List[D.T_event], List[D.T_value]]]]:
+    """This method will run one or more episodes in a domain according to the policy of a solver.
+
+    # Parameters
+    domain: The domain in which the episode(s) will be run.
+    solver: The solver whose policy will select actions to take (if None, a random policy is used).
+    from_memory: The memory or state to consider as rollout starting point (if None, the domain is reset first).
+    from_action: The last applied action when from_memory is used (if necessary for initial observation computation).
+    num_episodes: The number of episodes to run.
+    max_steps: The maximum number of steps for each episode (if None, no limit is set).
+    render: Whether to render the episode(s) during rollout if the domain is renderable.
+    max_framerate: The maximum number of steps/renders per second (if None, steps/renders are never slowed down).
+    verbose: Whether to print information to the console during rollout.
+    action_formatter: The function transforming actions in the string to print (if None, no print).
+    outcome_formatter: The function transforming EnvironmentOutcome objects in the string to print (if None, no print).
+    return_episodes: if True, return the list of episodes, each episode as a tuple of observations, actions, and values.
+        else return nothing.
+    goal_logging_level: logging level at which we want to display if goal has been reached or not
+    """
+    previous_log_level = logger.level
+    if verbose:
+        logger.setLevel(logging.DEBUG)
+        logger.debug(
+            "Logger is in verbose mode: all debug messages will be there for you to enjoy ^^ )"
+        )
+
+    if solver is None:
+        # Create solver-like random walker that works for any domain
+        class RandomWalk(Policies):
+            T_domain = Domain
+            T_agent = Domain.T_agent
+            T_event = Domain.T_event
+
+            def __init__(self):
+                class CastDomain:  # trick to autocast domain's get_applicable_actions() without mutating domain
+                    T_agent = domain.T_agent
+                    T_event = domain.T_event
+
+                    @autocastable
+                    def get_applicable_actions(self) -> D.T_agent[Space[D.T_event]]:
+                        return domain.get_applicable_actions()
+
+                self._domain = CastDomain()
+                autocast_all(self._domain, self._domain, self)
+
+            @autocastable
+            def reset(self) -> None:
+                pass
+
+            @autocastable
+            def sample_action(
+                self, observation: D.T_agent[D.T_observation]
+            ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+                return {
+                    agent: [space.sample()]
+                    for agent, space in self._domain.get_applicable_actions().items()
+                }
+
+            @autocastable
+            def is_policy_defined_for(
+                self, observation: D.T_agent[D.T_observation]
+            ) -> bool:
+                return True
+
+        solver = RandomWalk()
+        autocast_all(solver, solver.T_domain, domain)
+
+    episodes: List[Tuple[List[D.T_observation], List[D.T_event], List[D.T_value]]] = []
+
+    if num_episodes > 1 and from_memory is None and not hasattr(domain, "reset"):
+        raise ValueError(
+            "If from_memory is not specified and domain has no reset() method, "
+            "num_episodes should be equal to 1."
+        )
+
+    has_render = isinstance(domain, Renderable)
+    has_goal = isinstance(domain, Goals)
+    has_memory = not isinstance(domain, Markovian)
+    for i_episode in range(num_episodes):
+        # Initialize episode
+        solver.reset()
+        if from_memory is None:
+            if hasattr(domain, "reset"):
+                observation = domain.reset()
+        else:
+            if hasattr(domain, "set_memory"):
+                domain.set_memory(from_memory)
+                last_state = from_memory[-1] if has_memory else from_memory
+                observation = domain.get_observation_distribution(
+                    last_state, from_action
+                ).sample()
+            else:
+                raise ValueError(
+                    "from_memory must be None if domain has no set_memory() method."
+                )
+        logger.debug(f"Episode {i_episode + 1} started with following observation:")
+        logger.debug(observation)
+        # Run episode
+        step = 1
+
+        observations = []
+        actions = []
+        values = []
+        # save the initial observation
+        observations.append(observation)
+
+        while max_steps is None or step <= max_steps:
+            old_time = time.perf_counter()
+            if render and has_render:
+                domain.render()
+            action = solver.sample_action(observation)
+            if action_formatter is not None:
+                logger.debug("Action: {}".format(action_formatter(action)))
+            outcome = domain.step(action)
+            observation = outcome.observation
+            if return_episodes:
+                observations.append(observation)
+                actions.append(action)
+                values.append(outcome.value)
+            if outcome_formatter is not None:
+                logger.debug("Result: {}".format(outcome_formatter(outcome)))
+            termination = (
+                outcome.termination
+                if domain.T_agent == Union
+                else all(t for a, t in outcome.termination.items())
+            )
+            if termination:
+                logger.debug(
+                    f"Episode {i_episode + 1} terminated after {step + 1} steps."
+                )
+                break
+            if max_framerate is not None:
+                wait = 1 / max_framerate - (time.perf_counter() - old_time)
+                if wait > 0:
+                    time.sleep(wait)
+            step += 1
+        if render and has_render:
+            domain.render()
+        if has_goal:
+            logger.log(
+                goal_logging_level,
+                f'The goal was{"" if domain.is_goal(observation) else " not"} reached '
+                f"in episode {i_episode + 1}.",
+            )
+        if return_episodes:
+            episodes.append((observations, actions, values))
+    if verbose:
+        logger.setLevel(previous_log_level)
+    if return_episodes:
+        return episodes
```

## skdecide/hub/include/nng/compat/nanomsg/bus.h

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_BUS_H
-#define NNG_COMPAT_BUS_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// BUS sockopt level.
-#define NN_PROTO_BUS 7
-#define NN_BUS (NN_PROTO_BUS * 16 + 0)
-
-// BUS has no options.
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_BUS_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_BUS_H
+#define NNG_COMPAT_BUS_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// BUS sockopt level.
+#define NN_PROTO_BUS 7
+#define NN_BUS (NN_PROTO_BUS * 16 + 0)
+
+// BUS has no options.
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_BUS_H
```

## skdecide/hub/include/nng/compat/nanomsg/inproc.h

 * *Ordering differences only*

```diff
@@ -1,31 +1,31 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_INPROC_H
-#define NNG_COMPAT_INPROC_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// inproc sockopt level.
-// There are no inproc tunables.
-#define NN_INPROC (-1)
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_INPROC_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_INPROC_H
+#define NNG_COMPAT_INPROC_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// inproc sockopt level.
+// There are no inproc tunables.
+#define NN_INPROC (-1)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_INPROC_H
```

## skdecide/hub/include/nng/compat/nanomsg/ipc.h

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_IPC_H
-#define NNG_COMPAT_IPC_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// IPC sockopt level.
-#define NN_IPC (-2)
-
-// IPC options.  Note that these are not currently supported.
-// IPC_SEC_ATTR works quite differently in NNG, and must be
-// configured using the new API.  The buffer sizing options are
-// not supported at all.  None of these were ever documented, and
-// are offered here only for source compatibility.
-#define NN_IPC_SEC_ATTR 1
-#define NN_IPC_OUTBUFSZ 2
-#define NN_IPC_INBUFSZ 3
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_IPC_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_IPC_H
+#define NNG_COMPAT_IPC_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// IPC sockopt level.
+#define NN_IPC (-2)
+
+// IPC options.  Note that these are not currently supported.
+// IPC_SEC_ATTR works quite differently in NNG, and must be
+// configured using the new API.  The buffer sizing options are
+// not supported at all.  None of these were ever documented, and
+// are offered here only for source compatibility.
+#define NN_IPC_SEC_ATTR 1
+#define NN_IPC_OUTBUFSZ 2
+#define NN_IPC_INBUFSZ 3
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_IPC_H
```

## skdecide/hub/include/nng/compat/nanomsg/nn.h

 * *Ordering differences only*

```diff
@@ -1,284 +1,284 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_NN_H
-#define NNG_COMPAT_NN_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-// Note that compatibility promises are limited to public portions of the
-// nanomsg API, and specifically do NOT extend to the ABI.  Furthermore,
-// there may be other limitations around less commonly used portions of the
-// API; for example only SP headers may be transported in control data for
-// messages, there is almost no compatibility offered for statistics.
-// Error values may differ from those returned by nanomsg as well; the nng
-// error reporting facility expresses only a subset of the possibilities of
-// nanomsg.
-
-// Note that unlike nanomsg, nng does not aggressively recycle socket or
-// endpoint IDs, which means applications which made assumptions that these
-// would be relatively small integers (e.g. to use them as array indices)
-// may break.  (No promise about values was ever made.)
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <errno.h>
-#include <stddef.h>
-#include <stdint.h>
-
-// clang-format gets in the way of most of this file.
-// We turn it off, at least until it gets smarter about aligning
-// macro definitions or we adopt enums or somesuch.
-// clang-format off
-
-// NNG_DECL is used on declarations to deal with scope.
-// For building Windows DLLs, it should be the appropriate __declspec().
-// For shared libraries with platforms that support hidden visibility,
-// it should evaluate to __attribute__((visibility("default"))).
-#ifndef NN_DECL
-#if defined(_WIN32) && !defined(NNG_STATIC_LIB)
-#if defined(NNG_SHARED_LIB)
-#define NN_DECL		__declspec(dllexport)
-#else
-#define NN_DECL		__declspec(dllimport)
-#endif // NNG_SHARED_LIB
-#else
-#if defined(NNG_SHARED_LIB) && defined(NNG_HIDDEN_VISIBILITY)
-#define NN_DECL __attribute__((visibility("default")))
-#else
-#define NN_DECL extern
-#endif
-#endif // _WIN32 && !NNG_STATIC_LIB
-#endif  // NN_DECL
-
-#define AF_SP			1
-#define AF_SP_RAW		2
-
-#define NN_SOCKADDR_MAX		128
-#define NN_SOL_SOCKET		0
-
-// Flag for send/recv (nonblocking)
-#define NN_DONTWAIT		1
-
-// CMSG data type
-#define PROTO_SP		1
-#define SP_HDR			1
-
-// Errnos.  Legacy nanomsg uses posix errnos where possible.
-// If a define is not set, use add NN_ERRBASE.  nng does not
-// return all of these values, so there may be some loss of
-// of information for edge cases, but we don't expect that to be
-// a problem really.
-#define NN_ERRBASE		(0x10000000)
-#ifndef ENOTSUP
-#define ENOTSUP			(NN_ERRBASE+1)
-#endif
-#ifndef EPROTONOSUPPORT
-#define EPROTONOSUPPORT		(NN_ERRBASE+2)
-#endif
-#ifndef ENOBUFS
-#define ENOBUFS			(NN_ERRBASE+3)
-#endif
-#ifndef ENETDOWN
-#define ENETDOWN		(NN_ERRBASE+4)
-#endif
-#ifndef EADDRINUSE
-#define EADDRINUSE		(NN_ERRBASE+5)
-#endif
-#ifndef EADDRNOTAVAIL
-#define EADDRNOTAVAIL		(NN_ERRBASE+6)
-#endif
-#ifndef ENOTSOCK
-#define ENOTSOCK		(NN_ERRBASE+7)
-#endif
-#ifndef EAGAIN
-#define EAGAIN			(NN_ERRBASE+8)
-#endif
-#ifndef EBADF
-#define EBADF			(NN_ERRBASE+9)
-#endif
-#ifndef EINVAL
-#define EINVAL			(NN_ERRBASE+10)
-#endif
-#ifndef EMFILE
-#define EMFILE			(NN_ERRBASE+11)
-#endif
-#ifndef EFAULT
-#define EFAULT			(NN_ERRBASE+12)
-#endif
-#ifndef EACCES
-#define EACCES			(NN_ERRBASE+13)
-#endif
-#ifndef ENETRESET
-#define ENETRESET		(NN_ERRBASE+14)
-#endif
-#ifndef ENETUNREACH
-#define ENETUNREACH		(NN_ERRBASE+15)
-#endif
-#ifndef EHOSTUNREACH
-#define EHOSTUNREACH		(NN_ERRBASE+16)
-#endif
-#ifndef EAFNOSUPPORT
-#define EAFNOSUPPORT		(NN_ERRBASE+17)
-#endif
-#ifndef EINPROGRESS
-#define EINPROGRESS		(NN_ERRBASE+18)
-#endif
-#ifndef EPROTO
-#define EPROTO			(NN_ERRBASE+19)
-#endif
-#ifndef ECONNREFUSED
-#define ECONNREFUSED		(NN_ERRBASE+20)
-#endif
-#ifndef ENOTCONN
-#define ENOTCONN		(NN_ERRBASE+21)
-#endif
-#ifndef EMSGSIZE
-#define EMSGSIZE		(NN_ERRBASE+22)
-#endif
-#ifndef ETIMEDOUT
-#define ETIMEDOUT		(NN_ERRBASE+23)
-#endif
-#ifndef ECONNABORTED
-#define ECONNABORTED		(NN_ERRBASE+24)
-#endif
-#ifndef ECONNRESET
-#define ECONNRESET		(NN_ERRBASE+25)
-#endif
-#ifndef ENOPROTOOPT
-#define ENOPROTOOPT		(NN_ERRBASE+26)
-#endif
-#ifndef EISCONN
-#define EISCONN			(NN_ERRBASE+27)
-#endif
-#ifndef ESOCKNOSUPPORT
-#define ESOCKNOSPPORT		(NN_ERRBASE+28)
-#endif
-#ifndef ETERM
-#define ETERM			(NN_ERRBASE+29)
-#endif
-#ifndef EFSM
-#define EFSM			(NN_ERRBASE+30)
-#endif
-#ifndef ENOENT
-#define ENOENT			(NN_ERRBASE+31)
-#endif
-#ifndef EIO
-#define EIO			(NN_ERRBASE+32)
-#endif
-#ifndef EEXIST
-#define EEXIST			(NN_ERRBASE+33)
-#endif
-#ifndef ENOSPC
-#define ENOSPC			(NN_ERRBASE+34)
-#endif
-
-
-// Socket options
-#define NN_LINGER		1
-#define NN_SNDBUF		2
-#define NN_RCVBUF		3
-#define NN_SNDTIMEO		4
-#define NN_RCVTIMEO		5
-#define NN_RECONNECT_IVL	6
-#define NN_RECONNECT_IVL_MAX	7
-#define NN_SNDPRIO		8
-#define NN_RCVPRIO		9
-#define NN_SNDFD		10
-#define NN_RCVFD		11
-#define NN_DOMAIN		12
-#define NN_PROTOCOL		13
-#define NN_IPV4ONLY		14
-#define NN_SOCKET_NAME		15
-#define NN_RCVMAXSIZE		16
-#define NN_MAXTTL		17
-
-// from this point on formatting is fine
-// clang-format on
-
-// Poll stuff
-#define NN_POLLIN 1
-#define NN_POLLOUT 2
-struct nn_pollfd {
-	int      fd;
-	uint16_t events;
-	uint16_t revents;
-};
-
-// Magical size for allocation
-#define NN_MSG ((size_t) -1)
-
-struct nn_iovec {
-	void * iov_base;
-	size_t iov_len;
-};
-
-struct nn_msghdr {
-	struct nn_iovec *msg_iov;
-	int              msg_iovlen;
-	void *           msg_control;
-	size_t           msg_controllen;
-};
-
-struct nn_cmsghdr {
-	size_t cmsg_len;
-	int    cmsg_level;
-	int    cmsg_type;
-};
-
-#define NN_CMSG_ALIGN(len) \
-	(((len) + sizeof(size_t) - 1) & (size_t) ~(sizeof(size_t) - 1))
-
-// Unlike old nanomsg, we explicitly only support the SP header as attached
-// cmsg data.  It turns out that old nanomsg didn't really store anything
-// useful otherwise anyway.  (One specific exception was that it stored the
-// message type of text or binary for the websocket transport.  We don't think
-// anyone used that in practice though.)
-#define NN_CMSG_FIRSTHDR(mh) nn_cmsg_next((struct nn_msghdr *) (mh), NULL)
-#define NN_CMSG_NXTHDR(mh, ch) \
-	nn_cmsg_next((struct nn_msghdr *) (mh), (struct nn_cmsghdr *) ch)
-#define NN_CMSG_DATA(ch) ((unsigned char *) (((struct nn_cmsghdr *) (ch)) + 1))
-#define NN_CMSG_SPACE(len) \
-	(NN_CMSG_ALIGN(len) + NN_CMSG_ALIGN(sizeof(struct nn_cmsghdr)))
-#define NN_CMSG_LEN(len) (NN_CMSG_ALIGN(sizeof(struct nn_cmsghdr)) + (len))
-
-NN_DECL struct nn_cmsghdr *nn_cmsg_next(
-    struct nn_msghdr *, struct nn_cmsghdr *);
-NN_DECL int nn_socket(int, int);
-NN_DECL int nn_setsockopt(int, int, int, const void *, size_t);
-NN_DECL int nn_getsockopt(int, int, int, void *, size_t *);
-NN_DECL int nn_bind(int, const char *);
-NN_DECL int nn_connect(int, const char *);
-NN_DECL int nn_shutdown(int, int);
-NN_DECL int nn_send(int, const void *, size_t, int);
-NN_DECL int nn_recv(int, void *, size_t, int);
-NN_DECL int nn_sendmsg(int, const struct nn_msghdr *, int);
-NN_DECL int nn_recvmsg(int, struct nn_msghdr *, int);
-NN_DECL int nn_close(int);
-NN_DECL int nn_poll(struct nn_pollfd *, int, int);
-NN_DECL int nn_device(int, int);
-NN_DECL uint64_t    nn_get_statistic(int, int);
-NN_DECL void *      nn_allocmsg(size_t, int);
-NN_DECL void *      nn_reallocmsg(void *, size_t);
-NN_DECL int         nn_freemsg(void *);
-NN_DECL int         nn_errno(void);
-NN_DECL const char *nn_strerror(int);
-NN_DECL void        nn_term(void);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_NN_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_NN_H
+#define NNG_COMPAT_NN_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+// Note that compatibility promises are limited to public portions of the
+// nanomsg API, and specifically do NOT extend to the ABI.  Furthermore,
+// there may be other limitations around less commonly used portions of the
+// API; for example only SP headers may be transported in control data for
+// messages, there is almost no compatibility offered for statistics.
+// Error values may differ from those returned by nanomsg as well; the nng
+// error reporting facility expresses only a subset of the possibilities of
+// nanomsg.
+
+// Note that unlike nanomsg, nng does not aggressively recycle socket or
+// endpoint IDs, which means applications which made assumptions that these
+// would be relatively small integers (e.g. to use them as array indices)
+// may break.  (No promise about values was ever made.)
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <errno.h>
+#include <stddef.h>
+#include <stdint.h>
+
+// clang-format gets in the way of most of this file.
+// We turn it off, at least until it gets smarter about aligning
+// macro definitions or we adopt enums or somesuch.
+// clang-format off
+
+// NNG_DECL is used on declarations to deal with scope.
+// For building Windows DLLs, it should be the appropriate __declspec().
+// For shared libraries with platforms that support hidden visibility,
+// it should evaluate to __attribute__((visibility("default"))).
+#ifndef NN_DECL
+#if defined(_WIN32) && !defined(NNG_STATIC_LIB)
+#if defined(NNG_SHARED_LIB)
+#define NN_DECL		__declspec(dllexport)
+#else
+#define NN_DECL		__declspec(dllimport)
+#endif // NNG_SHARED_LIB
+#else
+#if defined(NNG_SHARED_LIB) && defined(NNG_HIDDEN_VISIBILITY)
+#define NN_DECL __attribute__((visibility("default")))
+#else
+#define NN_DECL extern
+#endif
+#endif // _WIN32 && !NNG_STATIC_LIB
+#endif  // NN_DECL
+
+#define AF_SP			1
+#define AF_SP_RAW		2
+
+#define NN_SOCKADDR_MAX		128
+#define NN_SOL_SOCKET		0
+
+// Flag for send/recv (nonblocking)
+#define NN_DONTWAIT		1
+
+// CMSG data type
+#define PROTO_SP		1
+#define SP_HDR			1
+
+// Errnos.  Legacy nanomsg uses posix errnos where possible.
+// If a define is not set, use add NN_ERRBASE.  nng does not
+// return all of these values, so there may be some loss of
+// of information for edge cases, but we don't expect that to be
+// a problem really.
+#define NN_ERRBASE		(0x10000000)
+#ifndef ENOTSUP
+#define ENOTSUP			(NN_ERRBASE+1)
+#endif
+#ifndef EPROTONOSUPPORT
+#define EPROTONOSUPPORT		(NN_ERRBASE+2)
+#endif
+#ifndef ENOBUFS
+#define ENOBUFS			(NN_ERRBASE+3)
+#endif
+#ifndef ENETDOWN
+#define ENETDOWN		(NN_ERRBASE+4)
+#endif
+#ifndef EADDRINUSE
+#define EADDRINUSE		(NN_ERRBASE+5)
+#endif
+#ifndef EADDRNOTAVAIL
+#define EADDRNOTAVAIL		(NN_ERRBASE+6)
+#endif
+#ifndef ENOTSOCK
+#define ENOTSOCK		(NN_ERRBASE+7)
+#endif
+#ifndef EAGAIN
+#define EAGAIN			(NN_ERRBASE+8)
+#endif
+#ifndef EBADF
+#define EBADF			(NN_ERRBASE+9)
+#endif
+#ifndef EINVAL
+#define EINVAL			(NN_ERRBASE+10)
+#endif
+#ifndef EMFILE
+#define EMFILE			(NN_ERRBASE+11)
+#endif
+#ifndef EFAULT
+#define EFAULT			(NN_ERRBASE+12)
+#endif
+#ifndef EACCES
+#define EACCES			(NN_ERRBASE+13)
+#endif
+#ifndef ENETRESET
+#define ENETRESET		(NN_ERRBASE+14)
+#endif
+#ifndef ENETUNREACH
+#define ENETUNREACH		(NN_ERRBASE+15)
+#endif
+#ifndef EHOSTUNREACH
+#define EHOSTUNREACH		(NN_ERRBASE+16)
+#endif
+#ifndef EAFNOSUPPORT
+#define EAFNOSUPPORT		(NN_ERRBASE+17)
+#endif
+#ifndef EINPROGRESS
+#define EINPROGRESS		(NN_ERRBASE+18)
+#endif
+#ifndef EPROTO
+#define EPROTO			(NN_ERRBASE+19)
+#endif
+#ifndef ECONNREFUSED
+#define ECONNREFUSED		(NN_ERRBASE+20)
+#endif
+#ifndef ENOTCONN
+#define ENOTCONN		(NN_ERRBASE+21)
+#endif
+#ifndef EMSGSIZE
+#define EMSGSIZE		(NN_ERRBASE+22)
+#endif
+#ifndef ETIMEDOUT
+#define ETIMEDOUT		(NN_ERRBASE+23)
+#endif
+#ifndef ECONNABORTED
+#define ECONNABORTED		(NN_ERRBASE+24)
+#endif
+#ifndef ECONNRESET
+#define ECONNRESET		(NN_ERRBASE+25)
+#endif
+#ifndef ENOPROTOOPT
+#define ENOPROTOOPT		(NN_ERRBASE+26)
+#endif
+#ifndef EISCONN
+#define EISCONN			(NN_ERRBASE+27)
+#endif
+#ifndef ESOCKNOSUPPORT
+#define ESOCKNOSPPORT		(NN_ERRBASE+28)
+#endif
+#ifndef ETERM
+#define ETERM			(NN_ERRBASE+29)
+#endif
+#ifndef EFSM
+#define EFSM			(NN_ERRBASE+30)
+#endif
+#ifndef ENOENT
+#define ENOENT			(NN_ERRBASE+31)
+#endif
+#ifndef EIO
+#define EIO			(NN_ERRBASE+32)
+#endif
+#ifndef EEXIST
+#define EEXIST			(NN_ERRBASE+33)
+#endif
+#ifndef ENOSPC
+#define ENOSPC			(NN_ERRBASE+34)
+#endif
+
+
+// Socket options
+#define NN_LINGER		1
+#define NN_SNDBUF		2
+#define NN_RCVBUF		3
+#define NN_SNDTIMEO		4
+#define NN_RCVTIMEO		5
+#define NN_RECONNECT_IVL	6
+#define NN_RECONNECT_IVL_MAX	7
+#define NN_SNDPRIO		8
+#define NN_RCVPRIO		9
+#define NN_SNDFD		10
+#define NN_RCVFD		11
+#define NN_DOMAIN		12
+#define NN_PROTOCOL		13
+#define NN_IPV4ONLY		14
+#define NN_SOCKET_NAME		15
+#define NN_RCVMAXSIZE		16
+#define NN_MAXTTL		17
+
+// from this point on formatting is fine
+// clang-format on
+
+// Poll stuff
+#define NN_POLLIN 1
+#define NN_POLLOUT 2
+struct nn_pollfd {
+	int      fd;
+	uint16_t events;
+	uint16_t revents;
+};
+
+// Magical size for allocation
+#define NN_MSG ((size_t) -1)
+
+struct nn_iovec {
+	void * iov_base;
+	size_t iov_len;
+};
+
+struct nn_msghdr {
+	struct nn_iovec *msg_iov;
+	int              msg_iovlen;
+	void *           msg_control;
+	size_t           msg_controllen;
+};
+
+struct nn_cmsghdr {
+	size_t cmsg_len;
+	int    cmsg_level;
+	int    cmsg_type;
+};
+
+#define NN_CMSG_ALIGN(len) \
+	(((len) + sizeof(size_t) - 1) & (size_t) ~(sizeof(size_t) - 1))
+
+// Unlike old nanomsg, we explicitly only support the SP header as attached
+// cmsg data.  It turns out that old nanomsg didn't really store anything
+// useful otherwise anyway.  (One specific exception was that it stored the
+// message type of text or binary for the websocket transport.  We don't think
+// anyone used that in practice though.)
+#define NN_CMSG_FIRSTHDR(mh) nn_cmsg_next((struct nn_msghdr *) (mh), NULL)
+#define NN_CMSG_NXTHDR(mh, ch) \
+	nn_cmsg_next((struct nn_msghdr *) (mh), (struct nn_cmsghdr *) ch)
+#define NN_CMSG_DATA(ch) ((unsigned char *) (((struct nn_cmsghdr *) (ch)) + 1))
+#define NN_CMSG_SPACE(len) \
+	(NN_CMSG_ALIGN(len) + NN_CMSG_ALIGN(sizeof(struct nn_cmsghdr)))
+#define NN_CMSG_LEN(len) (NN_CMSG_ALIGN(sizeof(struct nn_cmsghdr)) + (len))
+
+NN_DECL struct nn_cmsghdr *nn_cmsg_next(
+    struct nn_msghdr *, struct nn_cmsghdr *);
+NN_DECL int nn_socket(int, int);
+NN_DECL int nn_setsockopt(int, int, int, const void *, size_t);
+NN_DECL int nn_getsockopt(int, int, int, void *, size_t *);
+NN_DECL int nn_bind(int, const char *);
+NN_DECL int nn_connect(int, const char *);
+NN_DECL int nn_shutdown(int, int);
+NN_DECL int nn_send(int, const void *, size_t, int);
+NN_DECL int nn_recv(int, void *, size_t, int);
+NN_DECL int nn_sendmsg(int, const struct nn_msghdr *, int);
+NN_DECL int nn_recvmsg(int, struct nn_msghdr *, int);
+NN_DECL int nn_close(int);
+NN_DECL int nn_poll(struct nn_pollfd *, int, int);
+NN_DECL int nn_device(int, int);
+NN_DECL uint64_t    nn_get_statistic(int, int);
+NN_DECL void *      nn_allocmsg(size_t, int);
+NN_DECL void *      nn_reallocmsg(void *, size_t);
+NN_DECL int         nn_freemsg(void *);
+NN_DECL int         nn_errno(void);
+NN_DECL const char *nn_strerror(int);
+NN_DECL void        nn_term(void);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_NN_H
```

## skdecide/hub/include/nng/compat/nanomsg/pair.h

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_PAIR_H
-#define NNG_COMPAT_PAIR_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// PAIR sockopt level.
-#define NN_PROTO_PAIR 1
-#define NN_PAIR (NN_PROTO_PAIR * 16 + 0)
-
-// These are technically "new", and not available in nanomsg, but
-// offered here as a transition aid.  If you want to use the advanced
-// PAIRv1 options (POLYAMOROUS mode) you still need to use the new API.
-#define NN_PAIR_v0 (NN_PROTO_PAIR * 16 + 0)
-#define NN_PAIR_V1 (NN_PROTO_PAIR * 16 + 1)
-
-// PAIR has no options.
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_PAIR_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_PAIR_H
+#define NNG_COMPAT_PAIR_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// PAIR sockopt level.
+#define NN_PROTO_PAIR 1
+#define NN_PAIR (NN_PROTO_PAIR * 16 + 0)
+
+// These are technically "new", and not available in nanomsg, but
+// offered here as a transition aid.  If you want to use the advanced
+// PAIRv1 options (POLYAMOROUS mode) you still need to use the new API.
+#define NN_PAIR_v0 (NN_PROTO_PAIR * 16 + 0)
+#define NN_PAIR_V1 (NN_PROTO_PAIR * 16 + 1)
+
+// PAIR has no options.
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_PAIR_H
```

## skdecide/hub/include/nng/compat/nanomsg/pipeline.h

 * *Ordering differences only*

```diff
@@ -1,34 +1,34 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_PIPELINE_H
-#define NNG_COMPAT_PIPELINE_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// PUSH and PULL sockopt level.
-#define NN_PROTO_PIPELINE 5
-#define NN_PUSH (NN_PROTO_PIPELINE * 16 + 0)
-#define NN_PULL (NN_PROTO_PIPELINE * 16 + 1)
-
-// PUSH and PULL have no options.
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_PIPELINE_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_PIPELINE_H
+#define NNG_COMPAT_PIPELINE_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// PUSH and PULL sockopt level.
+#define NN_PROTO_PIPELINE 5
+#define NN_PUSH (NN_PROTO_PIPELINE * 16 + 0)
+#define NN_PULL (NN_PROTO_PIPELINE * 16 + 1)
+
+// PUSH and PULL have no options.
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_PIPELINE_H
```

## skdecide/hub/include/nng/compat/nanomsg/pubsub.h

 * *Ordering differences only*

```diff
@@ -1,36 +1,36 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_PUBSUB_H
-#define NNG_COMPAT_PUBSUB_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// PUB and SUB sockopt level.
-#define NN_PROTO_PUBSUB 2
-#define NN_PUB (NN_PROTO_PUBSUB * 16 + 0)
-#define NN_SUB (NN_PROTO_PUBSUB * 16 + 1)
-
-// SUB options.  (PUB has none.)
-#define NN_SUB_SUBSCRIBE (NN_SUB * 16 + 1)
-#define NN_SUB_UNSUBSCRIBE (NN_SUB * 16 + 2)
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_PUBSUB_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_PUBSUB_H
+#define NNG_COMPAT_PUBSUB_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// PUB and SUB sockopt level.
+#define NN_PROTO_PUBSUB 2
+#define NN_PUB (NN_PROTO_PUBSUB * 16 + 0)
+#define NN_SUB (NN_PROTO_PUBSUB * 16 + 1)
+
+// SUB options.  (PUB has none.)
+#define NN_SUB_SUBSCRIBE (NN_SUB * 16 + 1)
+#define NN_SUB_UNSUBSCRIBE (NN_SUB * 16 + 2)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_PUBSUB_H
```

## skdecide/hub/include/nng/compat/nanomsg/reqrep.h

 * *Ordering differences only*

```diff
@@ -1,35 +1,35 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_REQREP_H
-#define NNG_COMPAT_REQREP_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// REQ and REP sockopt level.
-#define NN_PROTO_REQREP 3
-#define NN_REQ (NN_PROTO_REQREP * 16 + 0)
-#define NN_REP (NN_PROTO_REQREP * 16 + 1)
-
-// REQ options.  (REP has none.)
-#define NN_REQ_RESEND_IVL (NN_REQ * 16 + 1)
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_REQREP_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_REQREP_H
+#define NNG_COMPAT_REQREP_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// REQ and REP sockopt level.
+#define NN_PROTO_REQREP 3
+#define NN_REQ (NN_PROTO_REQREP * 16 + 0)
+#define NN_REP (NN_PROTO_REQREP * 16 + 1)
+
+// REQ options.  (REP has none.)
+#define NN_REQ_RESEND_IVL (NN_REQ * 16 + 1)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_REQREP_H
```

## skdecide/hub/include/nng/compat/nanomsg/survey.h

 * *Ordering differences only*

```diff
@@ -1,36 +1,36 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_SURVEY_H
-#define NNG_COMPAT_SURVEY_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// SURVEYOR and RESPONDENT sockopt level.
-#define NN_PROTO_SURVEY 6
-#define NN_SURVEYOR (NN_PROTO_SURVEY * 16 + 2)
-#define NN_RESPONDENT (NN_PROTO_SURVEY * 16 + 3)
-
-// SURVEYOR options.  (RESPONDENT has none.)
-
-#define NN_SURVEYOR_DEADLINE (NN_SURVEYOR * 16 + 1)
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_SURVEY_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_SURVEY_H
+#define NNG_COMPAT_SURVEY_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// SURVEYOR and RESPONDENT sockopt level.
+#define NN_PROTO_SURVEY 6
+#define NN_SURVEYOR (NN_PROTO_SURVEY * 16 + 2)
+#define NN_RESPONDENT (NN_PROTO_SURVEY * 16 + 3)
+
+// SURVEYOR options.  (RESPONDENT has none.)
+
+#define NN_SURVEYOR_DEADLINE (NN_SURVEYOR * 16 + 1)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_SURVEY_H
```

## skdecide/hub/include/nng/compat/nanomsg/tcp.h

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_TCP_H
-#define NNG_COMPAT_TCP_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// TCP sockopt level.
-#define NN_TCP (-3)
-
-// TCP options.
-#define NN_TCP_NODELAY 1
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_TCP_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_TCP_H
+#define NNG_COMPAT_TCP_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// TCP sockopt level.
+#define NN_TCP (-3)
+
+// TCP options.
+#define NN_TCP_NODELAY 1
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_TCP_H
```

## skdecide/hub/include/nng/compat/nanomsg/ws.h

 * *Ordering differences only*

```diff
@@ -1,41 +1,41 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_COMPAT_WS_H
-#define NNG_COMPAT_WS_H
-
-// This header contains interfaces that are intended to offer compatibility
-// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
-// and consumers should only use these if they are porting software that
-// previously used nanomsg.  New programs should use the nng native APIs.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// WS sockopt level.
-#define NN_WS (-4)
-
-// WS options.
-
-// Note that while legacy libnanomsg had *some* support for text messages,
-// NNG only supports binary.  Binary types are required to pass protocol
-// headers with NNG and nanomsg in any event.  This means that the NNG
-// WebSocket support will not be compatible with some very old browsers.
-#define NN_WS_MSG_TYPE 1
-
-#define NN_WS_MSG_TYPE_TEXT 0x1
-#define NN_WS_MSG_TYPE_BINARY 0x2
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_COMPAT_WS_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_COMPAT_WS_H
+#define NNG_COMPAT_WS_H
+
+// This header contains interfaces that are intended to offer compatibility
+// with nanomsg v1.0.  These are not the "preferred" interfaces for nng,
+// and consumers should only use these if they are porting software that
+// previously used nanomsg.  New programs should use the nng native APIs.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// WS sockopt level.
+#define NN_WS (-4)
+
+// WS options.
+
+// Note that while legacy libnanomsg had *some* support for text messages,
+// NNG only supports binary.  Binary types are required to pass protocol
+// headers with NNG and nanomsg in any event.  This means that the NNG
+// WebSocket support will not be compatible with some very old browsers.
+#define NN_WS_MSG_TYPE 1
+
+#define NN_WS_MSG_TYPE_TEXT 0x1
+#define NN_WS_MSG_TYPE_BINARY 0x2
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_COMPAT_WS_H
```

## skdecide/hub/include/nng/nng.h

 * *Ordering differences only*

```diff
@@ -1,1333 +1,1333 @@
-//
-// Copyright 2023 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_NNG_H
-#define NNG_NNG_H
-
-// NNG (nanomsg-next-gen) is an improved implementation of the SP protocols.
-// The APIs have changed, and there is no attempt to provide API compatibility
-// with legacy libnanomsg. This file defines the library consumer-facing
-// Public API. Use of definitions or declarations not found in this header
-// file is specifically unsupported and strongly discouraged.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stdbool.h>
-#include <stddef.h>
-#include <stdint.h>
-
-// NNG_DECL is used on declarations to deal with scope.
-// For building Windows DLLs, it should be the appropriate __declspec().
-// For shared libraries with platforms that support hidden visibility,
-// it should evaluate to __attribute__((visibility("default"))).
-#ifndef NNG_DECL
-#if defined(_WIN32) && !defined(NNG_STATIC_LIB)
-#if defined(NNG_SHARED_LIB)
-#define NNG_DECL __declspec(dllexport)
-#else
-#define NNG_DECL __declspec(dllimport)
-#endif // NNG_SHARED_LIB
-#else
-#if defined(NNG_SHARED_LIB) && defined(NNG_HIDDEN_VISIBILITY)
-#define NNG_DECL __attribute__((visibility("default")))
-#else
-#define NNG_DECL extern
-#endif
-#endif // _WIN32 && !NNG_STATIC_LIB
-#endif // NNG_DECL
-
-#ifndef NNG_DEPRECATED
-#if defined(__GNUC__) || defined(__clang__)
-#define NNG_DEPRECATED __attribute__ ((deprecated))
-#else
-#define NNG_DEPRECATED
-#endif
-#endif
-
-// NNG Library & API version.
-// We use SemVer, and these versions are about the API, and
-// may not necessarily match the ABI versions.
-#define NNG_MAJOR_VERSION 1
-#define NNG_MINOR_VERSION 6
-#define NNG_PATCH_VERSION 0
-#define NNG_RELEASE_SUFFIX "" // if non-empty (i.e. "pre"), this is a pre-release
-
-// Maximum length of a socket address. This includes the terminating NUL.
-// This limit is built into other implementations, so do not change it.
-// Note that some transports are quite happy to let you use addresses
-// in excess of this, but if you do you may not be able to communicate
-// with other implementations.
-#define NNG_MAXADDRLEN (128)
-
-// NNG_PROTOCOL_NUMBER is used by protocol headers to calculate their
-// protocol number from a major and minor number.  Applications should
-// probably not need to use this.
-#define NNG_PROTOCOL_NUMBER(maj, min) (((x) *16) + (y))
-
-// Types common to nng.
-
-// Identifiers are wrapped in a structure to improve compiler validation
-// of incorrect passing.  This gives us strong type checking.  Modern
-// compilers compile passing these by value to identical code as passing
-// the integer type (at least with optimization applied).  Please do not
-// access the ID member directly.
-
-typedef struct nng_ctx_s {
-	uint32_t id;
-} nng_ctx;
-
-typedef struct nng_dialer_s {
-	uint32_t id;
-} nng_dialer;
-
-typedef struct nng_listener_s {
-	uint32_t id;
-} nng_listener;
-
-typedef struct nng_pipe_s {
-	uint32_t id;
-} nng_pipe;
-
-typedef struct nng_socket_s {
-	uint32_t id;
-} nng_socket;
-
-typedef int32_t         nng_duration; // in milliseconds
-typedef struct nng_msg  nng_msg;
-typedef struct nng_stat nng_stat;
-typedef struct nng_aio  nng_aio;
-
-// Initializers.
-// clang-format off
-#define NNG_PIPE_INITIALIZER { 0 }
-#define NNG_SOCKET_INITIALIZER { 0 }
-#define NNG_DIALER_INITIALIZER { 0 }
-#define NNG_LISTENER_INITIALIZER { 0 }
-#define NNG_CTX_INITIALIZER { 0 }
-// clang-format on
-
-// Some address details. This is in some ways like a traditional sockets
-// sockaddr, but we have our own to cope with our unique families, etc.
-// The details of this structure are directly exposed to applications.
-// These structures can be obtained via property lookups, etc.
-struct nng_sockaddr_inproc {
-	uint16_t sa_family;
-	char     sa_name[NNG_MAXADDRLEN];
-};
-
-struct nng_sockaddr_path {
-	uint16_t sa_family;
-	char     sa_path[NNG_MAXADDRLEN];
-};
-
-struct nng_sockaddr_in6 {
-	uint16_t sa_family;
-	uint16_t sa_port;
-	uint8_t  sa_addr[16];
-	uint32_t sa_scope;
-};
-struct nng_sockaddr_in {
-	uint16_t sa_family;
-	uint16_t sa_port;
-	uint32_t sa_addr;
-};
-
-struct nng_sockaddr_zt {
-	uint16_t sa_family;
-	uint64_t sa_nwid;
-	uint64_t sa_nodeid;
-	uint32_t sa_port;
-};
-
-struct nng_sockaddr_abstract {
-	uint16_t sa_family;
-	uint16_t sa_len;       // will be 0 - 107 max.
-	uint8_t  sa_name[107]; // 108 linux/windows, without leading NUL
-};
-
-// nng_sockaddr_storage is the the size required to store any nng_sockaddr.
-// This size must not change, and no individual nng_sockaddr type may grow
-// larger than this without breaking binary compatibility.
-struct nng_sockaddr_storage {
-	uint16_t sa_family;
-	uint64_t sa_pad[16];
-};
-
-typedef struct nng_sockaddr_inproc   nng_sockaddr_inproc;
-typedef struct nng_sockaddr_path     nng_sockaddr_path;
-typedef struct nng_sockaddr_path     nng_sockaddr_ipc;
-typedef struct nng_sockaddr_in       nng_sockaddr_in;
-typedef struct nng_sockaddr_in6      nng_sockaddr_in6;
-typedef struct nng_sockaddr_zt       nng_sockaddr_zt;
-typedef struct nng_sockaddr_abstract nng_sockaddr_abstract;
-typedef struct nng_sockaddr_storage  nng_sockaddr_storage;
-
-typedef union nng_sockaddr {
-	uint16_t              s_family;
-	nng_sockaddr_ipc      s_ipc;
-	nng_sockaddr_inproc   s_inproc;
-	nng_sockaddr_in6      s_in6;
-	nng_sockaddr_in       s_in;
-	nng_sockaddr_zt       s_zt;
-	nng_sockaddr_abstract s_abstract;
-	nng_sockaddr_storage  s_storage;
-} nng_sockaddr;
-
-enum nng_sockaddr_family {
-	NNG_AF_UNSPEC   = 0,
-	NNG_AF_INPROC   = 1,
-	NNG_AF_IPC      = 2,
-	NNG_AF_INET     = 3,
-	NNG_AF_INET6    = 4,
-	NNG_AF_ZT       = 5, // ZeroTier
-	NNG_AF_ABSTRACT = 6
-};
-
-// Scatter/gather I/O.
-typedef struct nng_iov {
-	void * iov_buf;
-	size_t iov_len;
-} nng_iov;
-
-// Some definitions for durations used with timeouts.
-#define NNG_DURATION_INFINITE (-1)
-#define NNG_DURATION_DEFAULT (-2)
-#define NNG_DURATION_ZERO (0)
-
-// nng_fini is used to terminate the library, freeing certain global resources.
-// This should only be called during atexit() or just before dlclose().
-// THIS FUNCTION MUST NOT BE CALLED CONCURRENTLY WITH ANY OTHER FUNCTION
-// IN THIS LIBRARY; IT IS NOT REENTRANT OR THREADSAFE.
-//
-// For most cases, this call is unnecessary, but it is provided to assist
-// when debugging with memory checkers (e.g. valgrind).  Calling this
-// function prevents global library resources from being reported incorrectly
-// as memory leaks.  In those cases, we recommend doing this with atexit().
-NNG_DECL void nng_fini(void);
-
-// nng_close closes the socket, terminating all activity and
-// closing any underlying connections and releasing any associated
-// resources.
-NNG_DECL int nng_close(nng_socket);
-
-// nng_socket_id returns the positive socket id for the socket, or -1
-// if the socket is not valid.
-NNG_DECL int nng_socket_id(nng_socket);
-
-NNG_DECL int nng_socket_set(nng_socket, const char *, const void *, size_t);
-NNG_DECL int nng_socket_set_bool(nng_socket, const char *, bool);
-NNG_DECL int nng_socket_set_int(nng_socket, const char *, int);
-NNG_DECL int nng_socket_set_size(nng_socket, const char *, size_t);
-NNG_DECL int nng_socket_set_uint64(nng_socket, const char *, uint64_t);
-NNG_DECL int nng_socket_set_string(nng_socket, const char *, const char *);
-NNG_DECL int nng_socket_set_ptr(nng_socket, const char *, void *);
-NNG_DECL int nng_socket_set_ms(nng_socket, const char *, nng_duration);
-NNG_DECL int nng_socket_set_addr(
-    nng_socket, const char *, const nng_sockaddr *);
-
-NNG_DECL int nng_socket_get(nng_socket, const char *, void *, size_t *);
-NNG_DECL int nng_socket_get_bool(nng_socket, const char *, bool *);
-NNG_DECL int nng_socket_get_int(nng_socket, const char *, int *);
-NNG_DECL int nng_socket_get_size(nng_socket, const char *, size_t *);
-NNG_DECL int nng_socket_get_uint64(nng_socket, const char *, uint64_t *);
-NNG_DECL int nng_socket_get_string(nng_socket, const char *, char **);
-NNG_DECL int nng_socket_get_ptr(nng_socket, const char *, void **);
-NNG_DECL int nng_socket_get_ms(nng_socket, const char *, nng_duration *);
-NNG_DECL int nng_socket_get_addr(nng_socket, const char *, nng_sockaddr *);
-
-// Arguably the pipe callback functions could be handled as an option,
-// but with the need to specify an argument, we find it best to unify
-// this as a separate function to pass in the argument and the callback.
-// Only one callback can be set on a given socket, and there is no way
-// to retrieve the old value.
-typedef enum {
-	NNG_PIPE_EV_ADD_PRE,  // Called just before pipe added to socket
-	NNG_PIPE_EV_ADD_POST, // Called just after pipe added to socket
-	NNG_PIPE_EV_REM_POST, // Called just after pipe removed from socket
-	NNG_PIPE_EV_NUM,      // Used internally, must be last.
-} nng_pipe_ev;
-
-typedef void (*nng_pipe_cb)(nng_pipe, nng_pipe_ev, void *);
-
-// nng_pipe_notify registers a callback to be executed when the
-// given event is triggered.  To watch for different events, register
-// multiple times.  Each event can have at most one callback registered.
-NNG_DECL int nng_pipe_notify(nng_socket, nng_pipe_ev, nng_pipe_cb, void *);
-
-// nng_listen creates a listening endpoint with no special options,
-// and starts it listening.  It is functionally equivalent to the legacy
-// nn_bind(). The underlying endpoint is returned back to the caller in the
-// endpoint pointer, if it is not NULL.  The flags are ignored at present.
-NNG_DECL int nng_listen(nng_socket, const char *, nng_listener *, int);
-
-// nng_dial creates a dialing endpoint, with no special options, and
-// starts it dialing.  Dialers have at most one active connection at a time
-// This is similar to the legacy nn_connect().  The underlying endpoint
-// is returned back to the caller in the endpoint pointer, if it is not NULL.
-// The flags may be NNG_FLAG_NONBLOCK to indicate that the first attempt to
-// dial will be made in the background, returning control to the caller
-// immediately.  In this case, if the connection fails, the function will
-// keep retrying in the background.  (If the connection is dropped in either
-// case, it will still be reconnected in the background -- only the initial
-// connection attempt is normally synchronous.)
-NNG_DECL int nng_dial(nng_socket, const char *, nng_dialer *, int);
-
-// nng_dialer_create creates a new dialer, that is not yet started.
-NNG_DECL int nng_dialer_create(nng_dialer *, nng_socket, const char *);
-
-// nng_listener_create creates a new listener, that is not yet started.
-NNG_DECL int nng_listener_create(nng_listener *, nng_socket, const char *);
-
-// nng_dialer_start starts the endpoint dialing.  This is only possible if
-// the dialer is not already dialing.
-NNG_DECL int nng_dialer_start(nng_dialer, int);
-
-// nng_listener_start starts the endpoint listening.  This is only possible if
-// the listener is not already listening.
-NNG_DECL int nng_listener_start(nng_listener, int);
-
-// nng_dialer_close closes the dialer, shutting down all underlying
-// connections and releasing all associated resources.
-NNG_DECL int nng_dialer_close(nng_dialer);
-
-// nng_listener_close closes the listener, shutting down all underlying
-// connections and releasing all associated resources.
-NNG_DECL int nng_listener_close(nng_listener);
-
-// nng_dialer_id returns the positive dialer ID, or -1 if the dialer is
-// invalid.
-NNG_DECL int nng_dialer_id(nng_dialer);
-
-// nng_listener_id returns the positive listener ID, or -1 if the listener is
-// invalid.
-NNG_DECL int nng_listener_id(nng_listener);
-
-NNG_DECL int nng_dialer_set(nng_dialer, const char *, const void *, size_t);
-NNG_DECL int nng_dialer_set_bool(nng_dialer, const char *, bool);
-NNG_DECL int nng_dialer_set_int(nng_dialer, const char *, int);
-NNG_DECL int nng_dialer_set_size(nng_dialer, const char *, size_t);
-NNG_DECL int nng_dialer_set_uint64(nng_dialer, const char *, uint64_t);
-NNG_DECL int nng_dialer_set_string(nng_dialer, const char *, const char *);
-NNG_DECL int nng_dialer_set_ptr(nng_dialer, const char *, void *);
-NNG_DECL int nng_dialer_set_ms(nng_dialer, const char *, nng_duration);
-NNG_DECL int nng_dialer_set_addr(
-    nng_dialer, const char *, const nng_sockaddr *);
-
-NNG_DECL int nng_dialer_get(nng_dialer, const char *, void *, size_t *);
-NNG_DECL int nng_dialer_get_bool(nng_dialer, const char *, bool *);
-NNG_DECL int nng_dialer_get_int(nng_dialer, const char *, int *);
-NNG_DECL int nng_dialer_get_size(nng_dialer, const char *, size_t *);
-NNG_DECL int nng_dialer_get_uint64(nng_dialer, const char *, uint64_t *);
-NNG_DECL int nng_dialer_get_string(nng_dialer, const char *, char **);
-NNG_DECL int nng_dialer_get_ptr(nng_dialer, const char *, void **);
-NNG_DECL int nng_dialer_get_ms(nng_dialer, const char *, nng_duration *);
-NNG_DECL int nng_dialer_get_addr(nng_dialer, const char *, nng_sockaddr *);
-
-NNG_DECL int nng_listener_set(
-    nng_listener, const char *, const void *, size_t);
-NNG_DECL int nng_listener_set_bool(nng_listener, const char *, bool);
-NNG_DECL int nng_listener_set_int(nng_listener, const char *, int);
-NNG_DECL int nng_listener_set_size(nng_listener, const char *, size_t);
-NNG_DECL int nng_listener_set_uint64(nng_listener, const char *, uint64_t);
-NNG_DECL int nng_listener_set_string(nng_listener, const char *, const char *);
-NNG_DECL int nng_listener_set_ptr(nng_listener, const char *, void *);
-NNG_DECL int nng_listener_set_ms(nng_listener, const char *, nng_duration);
-NNG_DECL int nng_listener_set_addr(
-    nng_listener, const char *, const nng_sockaddr *);
-
-NNG_DECL int nng_listener_get(nng_listener, const char *, void *, size_t *);
-NNG_DECL int nng_listener_get_bool(nng_listener, const char *, bool *);
-NNG_DECL int nng_listener_get_int(nng_listener, const char *, int *);
-NNG_DECL int nng_listener_get_size(nng_listener, const char *, size_t *);
-NNG_DECL int nng_listener_get_uint64(nng_listener, const char *, uint64_t *);
-NNG_DECL int nng_listener_get_string(nng_listener, const char *, char **);
-NNG_DECL int nng_listener_get_ptr(nng_listener, const char *, void **);
-NNG_DECL int nng_listener_get_ms(nng_listener, const char *, nng_duration *);
-NNG_DECL int nng_listener_get_addr(nng_listener, const char *, nng_sockaddr *);
-
-// nng_strerror returns a human readable string associated with the error
-// code supplied.
-NNG_DECL const char *nng_strerror(int);
-
-// nng_send sends (or arranges to send) the data on the socket.  Note that
-// this function may (will!) return before any receiver has actually
-// received the data.  The return value will be zero to indicate that the
-// socket has accepted the entire data for send, or an errno to indicate
-// failure.  The flags may include NNG_FLAG_NONBLOCK or NNG_FLAG_ALLOC.
-// If the flag includes NNG_FLAG_ALLOC, then the function will call
-// nng_free() on the supplied pointer & size on success. (If the call
-// fails then the memory is not freed.)
-NNG_DECL int nng_send(nng_socket, void *, size_t, int);
-
-// nng_recv receives message data into the socket, up to the supplied size.
-// The actual size of the message data will be written to the value pointed
-// to by size.  The flags may include NNG_FLAG_NONBLOCK and NNG_FLAG_ALLOC.
-// If NNG_FLAG_ALLOC is supplied then the library will allocate memory for
-// the caller.  In that case the pointer to the allocated will be stored
-// instead of the data itself.  The caller is responsible for freeing the
-// associated memory with nng_free().
-NNG_DECL int nng_recv(nng_socket, void *, size_t *, int);
-
-// nng_sendmsg is like nng_send, but offers up a message structure, which
-// gives the ability to provide more control over the message, including
-// providing backtrace information.  It also can take a message that was
-// obtain via nn_recvmsg, allowing for zero copy forwarding.
-NNG_DECL int nng_sendmsg(nng_socket, nng_msg *, int);
-
-// nng_recvmsg is like nng_recv, but is used to obtain a message structure
-// as well as the data buffer.  This can be used to obtain more information
-// about where the message came from, access raw headers, etc.  It also
-// can be passed off directly to nng_sendmsg.
-NNG_DECL int nng_recvmsg(nng_socket, nng_msg **, int);
-
-// nng_send_aio sends data on the socket asynchronously.  As with nng_send,
-// the completion may be executed before the data has actually been delivered,
-// but only when it is accepted for delivery.  The supplied AIO must have
-// been initialized, and have an associated message.  The message will be
-// "owned" by the socket if the operation completes successfully.  Otherwise
-// the caller is responsible for freeing it.
-NNG_DECL void nng_send_aio(nng_socket, nng_aio *);
-
-// nng_recv_aio receives data on the socket asynchronously.  On a successful
-// result, the AIO will have an associated message, that can be obtained
-// with nng_aio_get_msg().  The caller takes ownership of the message at
-// this point.
-NNG_DECL void nng_recv_aio(nng_socket, nng_aio *);
-
-// Context support.  User contexts are not supported by all protocols,
-// but for those that do, they give a way to create multiple contexts
-// on a single socket, each of which runs the protocol's state machinery
-// independently, offering a way to achieve concurrent protocol support
-// without resorting to raw mode sockets.  See the protocol specific
-// documentation for further details.  (Note that at this time, only
-// asynchronous send/recv are supported for contexts, but its easy enough
-// to make synchronous versions with nng_aio_wait().)  Note that nng_close
-// of the parent socket will *block* as long as any contexts are open.
-
-// nng_ctx_open creates a context.  This returns NNG_ENOTSUP if the
-// protocol implementation does not support separate contexts.
-NNG_DECL int nng_ctx_open(nng_ctx *, nng_socket);
-
-// nng_ctx_close closes the context.
-NNG_DECL int nng_ctx_close(nng_ctx);
-
-// nng_ctx_id returns the numeric id for the context; this will be
-// a positive value for a valid context, or < 0 for an invalid context.
-// A valid context is not necessarily an *open* context.
-NNG_DECL int nng_ctx_id(nng_ctx);
-
-// nng_ctx_recv receives asynchronously.  It works like nng_recv_aio, but
-// uses a local context instead of the socket global context.
-NNG_DECL void nng_ctx_recv(nng_ctx, nng_aio *);
-
-// nng_ctx_recvmsg is allows for receiving a message synchronously using
-// a context.  It has the same semantics as nng_recvmsg, but operates
-// on a context instead of a socket.
-NNG_DECL int nng_ctx_recvmsg(nng_ctx, nng_msg **, int);
-
-// nng_ctx_send sends asynchronously. It works like nng_send_aio, but
-// uses a local context instead of the socket global context.
-NNG_DECL void nng_ctx_send(nng_ctx, nng_aio *);
-
-// nng_ctx_sendmsg is allows for sending a message synchronously using
-// a context.  It has the same semantics as nng_sendmsg, but operates
-// on a context instead of a socket.
-NNG_DECL int nng_ctx_sendmsg(nng_ctx, nng_msg *, int);
-
-NNG_DECL int nng_ctx_get(nng_ctx, const char *, void *, size_t *);
-NNG_DECL int nng_ctx_get_bool(nng_ctx, const char *, bool *);
-NNG_DECL int nng_ctx_get_int(nng_ctx, const char *, int *);
-NNG_DECL int nng_ctx_get_size(nng_ctx, const char *, size_t *);
-NNG_DECL int nng_ctx_get_uint64(nng_ctx, const char *, uint64_t *);
-NNG_DECL int nng_ctx_get_string(nng_ctx, const char *, char **);
-NNG_DECL int nng_ctx_get_ptr(nng_ctx, const char *, void **);
-NNG_DECL int nng_ctx_get_ms(nng_ctx, const char *, nng_duration *);
-NNG_DECL int nng_ctx_get_addr(nng_ctx, const char *, nng_sockaddr *);
-
-NNG_DECL int nng_ctx_set(nng_ctx, const char *, const void *, size_t);
-NNG_DECL int nng_ctx_set_bool(nng_ctx, const char *, bool);
-NNG_DECL int nng_ctx_set_int(nng_ctx, const char *, int);
-NNG_DECL int nng_ctx_set_size(nng_ctx, const char *, size_t);
-NNG_DECL int nng_ctx_set_uint64(nng_ctx, const char *, uint64_t);
-NNG_DECL int nng_ctx_set_string(nng_ctx, const char *, const char *);
-NNG_DECL int nng_ctx_set_ptr(nng_ctx, const char *, void *);
-NNG_DECL int nng_ctx_set_ms(nng_ctx, const char *, nng_duration);
-NNG_DECL int nng_ctx_set_addr(nng_ctx, const char *, const nng_sockaddr *);
-
-// nng_alloc is used to allocate memory.  It's intended purpose is for
-// allocating memory suitable for message buffers with nng_send().
-// Applications that need memory for other purposes should use their platform
-// specific API.
-NNG_DECL void *nng_alloc(size_t);
-
-// nng_free is used to free memory allocated with nng_alloc, which includes
-// memory allocated by nng_recv() when the NNG_FLAG_ALLOC message is supplied.
-// As the application is required to keep track of the size of memory, this
-// is probably less convenient for general uses than the C library malloc and
-// calloc.
-NNG_DECL void nng_free(void *, size_t);
-
-// nng_strdup duplicates the source string, using nng_alloc. The result
-// should be freed with nng_strfree (or nng_free(strlen(s)+1)).
-NNG_DECL char *nng_strdup(const char *);
-
-// nng_strfree is equivalent to nng_free(strlen(s)+1).
-NNG_DECL void nng_strfree(char *);
-
-// Async IO API.  AIO structures can be thought of as "handles" to
-// support asynchronous operations.  They contain the completion callback, and
-// a pointer to consumer data.  This is similar to how overlapped I/O
-// works in Windows, when used with a completion callback.
-//
-// AIO structures can carry up to 4 distinct input values, and up to
-// 4 distinct output values, and up to 4 distinct "private state" values.
-// The meaning of the inputs and the outputs are determined by the
-// I/O functions being called.
-
-// nng_aio_alloc allocates a new AIO, and associated the completion
-// callback and its opaque argument.  If NULL is supplied for the
-// callback, then the caller must use nng_aio_wait() to wait for the
-// operation to complete.  If the completion callback is not NULL, then
-// when a submitted operation completes (or is canceled or fails) the
-// callback will be executed, generally in a different thread, with no
-// locks held.
-NNG_DECL int nng_aio_alloc(nng_aio **, void (*)(void *), void *);
-
-// nng_aio_free frees the AIO and any associated resources.
-// It *must not* be in use at the time it is freed.
-NNG_DECL void nng_aio_free(nng_aio *);
-
-// nng_aio_reap is like nng_aio_free, but calls it from a background
-// reaper thread.  This can be useful to free aio objects from aio
-// callbacks (e.g. when the result of the callback is to discard
-// the object in question.)  The aio object must be in further use
-// when this is called.
-NNG_DECL void nng_aio_reap(nng_aio *);
-
-// nng_aio_stop stops any outstanding operation, and waits for the
-// AIO to be free, including for the callback to have completed
-// execution.  Therefore the caller must NOT hold any locks that
-// are acquired in the callback, or deadlock will occur.
-NNG_DECL void nng_aio_stop(nng_aio *);
-
-// nng_aio_result returns the status/result of the operation. This
-// will be zero on successful completion, or an nng error code on
-// failure.
-NNG_DECL int nng_aio_result(nng_aio *);
-
-// nng_aio_count returns the number of bytes transferred for certain
-// I/O operations.  This is meaningless for other operations (e.g.
-// DNS lookups or TCP connection setup).
-NNG_DECL size_t nng_aio_count(nng_aio *);
-
-// nng_aio_cancel attempts to cancel any in-progress I/O operation.
-// The AIO callback will still be executed, but if the cancellation is
-// successful then the status will be NNG_ECANCELED.
-NNG_DECL void nng_aio_cancel(nng_aio *);
-
-// nng_aio_abort is like nng_aio_cancel, but allows for a different
-// error result to be returned.
-NNG_DECL void nng_aio_abort(nng_aio *, int);
-
-// nng_aio_wait waits synchronously for any pending operation to complete.
-// It also waits for the callback to have completed execution.  Therefore,
-// the caller of this function must not hold any locks acquired by the
-// callback or deadlock may occur.
-NNG_DECL void nng_aio_wait(nng_aio *);
-
-// nng_aio_busy returns true if the aio is still busy processing the
-// operation, or executing associated completion functions.  Note that
-// if the completion function schedules a new operation using the aio,
-// then this function will continue to return true.
-NNG_DECL bool nng_aio_busy(nng_aio *);
-
-// nng_aio_set_msg sets the message structure to use for asynchronous
-// message send operations.
-NNG_DECL void nng_aio_set_msg(nng_aio *, nng_msg *);
-
-// nng_aio_get_msg returns the message structure associated with a completed
-// receive operation.
-NNG_DECL nng_msg *nng_aio_get_msg(nng_aio *);
-
-// nng_aio_set_input sets an input parameter at the given index.
-NNG_DECL int nng_aio_set_input(nng_aio *, unsigned, void *);
-
-// nng_aio_get_input retrieves the input parameter at the given index.
-NNG_DECL void *nng_aio_get_input(nng_aio *, unsigned);
-
-// nng_aio_set_output sets an output result at the given index.
-NNG_DECL int nng_aio_set_output(nng_aio *, unsigned, void *);
-
-// nng_aio_get_output retrieves the output result at the given index.
-NNG_DECL void *nng_aio_get_output(nng_aio *, unsigned);
-
-// nng_aio_set_timeout sets a timeout on the AIO.  This should be called for
-// operations that should time out after a period.  The timeout should be
-// either a positive number of milliseconds, or NNG_DURATION_INFINITE to
-// indicate that the operation has no timeout.  A poll may be done by
-// specifying NNG_DURATION_ZERO.  The value NNG_DURATION_DEFAULT indicates
-// that any socket specific timeout should be used.
-NNG_DECL void nng_aio_set_timeout(nng_aio *, nng_duration);
-
-// nng_aio_set_iov sets a scatter/gather vector on the aio.  The iov array
-// itself is copied. Data members (the memory regions referenced) *may* be
-// copied as well, depending on the operation.  This operation is guaranteed
-// to succeed if n <= 4, otherwise it may fail due to NNG_ENOMEM.
-NNG_DECL int nng_aio_set_iov(nng_aio *, unsigned, const nng_iov *);
-
-// nng_aio_begin is called by the provider to mark the operation as
-// beginning.  If it returns false, then the provider must take no
-// further action on the aio.
-NNG_DECL bool nng_aio_begin(nng_aio *);
-
-// nng_aio_finish is used to "finish" an asynchronous operation.
-// It should only be called by "providers" (such as HTTP server API users).
-// The argument is the value that nng_aio_result() should return.
-// IMPORTANT: Callers must ensure that this is called EXACTLY ONCE on any
-// given aio.
-NNG_DECL void nng_aio_finish(nng_aio *, int);
-
-// nng_aio_defer is used to register a cancellation routine, and indicate
-// that the operation will be completed asynchronously.  It must only be
-// called once per operation on an aio, and must only be called by providers.
-// If the operation is canceled by the consumer, the cancellation callback
-// will be called.  The provider *must* still ensure that the nng_aio_finish()
-// function is called EXACTLY ONCE.  If the operation cannot be canceled
-// for any reason, the cancellation callback should do nothing.  The
-// final argument is passed to the cancelfn.  The final argument of the
-// cancellation function is the error number (will not be zero) corresponding
-// to the reason for cancellation, e.g. NNG_ETIMEDOUT or NNG_ECANCELED.
-typedef void (*nng_aio_cancelfn)(nng_aio *, void *, int);
-NNG_DECL void nng_aio_defer(nng_aio *, nng_aio_cancelfn, void *);
-
-// nng_aio_sleep does a "sleeping" operation, basically does nothing
-// but wait for the specified number of milliseconds to expire, then
-// calls the callback.  This returns 0, rather than NNG_ETIMEDOUT.
-NNG_DECL void nng_sleep_aio(nng_duration, nng_aio *);
-
-// Message API.
-NNG_DECL int      nng_msg_alloc(nng_msg **, size_t);
-NNG_DECL void     nng_msg_free(nng_msg *);
-NNG_DECL int      nng_msg_realloc(nng_msg *, size_t);
-NNG_DECL int      nng_msg_reserve(nng_msg *, size_t);
-NNG_DECL size_t   nng_msg_capacity(nng_msg *);
-NNG_DECL void *   nng_msg_header(nng_msg *);
-NNG_DECL size_t   nng_msg_header_len(const nng_msg *);
-NNG_DECL void *   nng_msg_body(nng_msg *);
-NNG_DECL size_t   nng_msg_len(const nng_msg *);
-NNG_DECL int      nng_msg_append(nng_msg *, const void *, size_t);
-NNG_DECL int      nng_msg_insert(nng_msg *, const void *, size_t);
-NNG_DECL int      nng_msg_trim(nng_msg *, size_t);
-NNG_DECL int      nng_msg_chop(nng_msg *, size_t);
-NNG_DECL int      nng_msg_header_append(nng_msg *, const void *, size_t);
-NNG_DECL int      nng_msg_header_insert(nng_msg *, const void *, size_t);
-NNG_DECL int      nng_msg_header_trim(nng_msg *, size_t);
-NNG_DECL int      nng_msg_header_chop(nng_msg *, size_t);
-NNG_DECL int      nng_msg_header_append_u16(nng_msg *, uint16_t);
-NNG_DECL int      nng_msg_header_append_u32(nng_msg *, uint32_t);
-NNG_DECL int      nng_msg_header_append_u64(nng_msg *, uint64_t);
-NNG_DECL int      nng_msg_header_insert_u16(nng_msg *, uint16_t);
-NNG_DECL int      nng_msg_header_insert_u32(nng_msg *, uint32_t);
-NNG_DECL int      nng_msg_header_insert_u64(nng_msg *, uint64_t);
-NNG_DECL int      nng_msg_header_chop_u16(nng_msg *, uint16_t *);
-NNG_DECL int      nng_msg_header_chop_u32(nng_msg *, uint32_t *);
-NNG_DECL int      nng_msg_header_chop_u64(nng_msg *, uint64_t *);
-NNG_DECL int      nng_msg_header_trim_u16(nng_msg *, uint16_t *);
-NNG_DECL int      nng_msg_header_trim_u32(nng_msg *, uint32_t *);
-NNG_DECL int      nng_msg_header_trim_u64(nng_msg *, uint64_t *);
-NNG_DECL int      nng_msg_append_u16(nng_msg *, uint16_t);
-NNG_DECL int      nng_msg_append_u32(nng_msg *, uint32_t);
-NNG_DECL int      nng_msg_append_u64(nng_msg *, uint64_t);
-NNG_DECL int      nng_msg_insert_u16(nng_msg *, uint16_t);
-NNG_DECL int      nng_msg_insert_u32(nng_msg *, uint32_t);
-NNG_DECL int      nng_msg_insert_u64(nng_msg *, uint64_t);
-NNG_DECL int      nng_msg_chop_u16(nng_msg *, uint16_t *);
-NNG_DECL int      nng_msg_chop_u32(nng_msg *, uint32_t *);
-NNG_DECL int      nng_msg_chop_u64(nng_msg *, uint64_t *);
-NNG_DECL int      nng_msg_trim_u16(nng_msg *, uint16_t *);
-NNG_DECL int      nng_msg_trim_u32(nng_msg *, uint32_t *);
-NNG_DECL int      nng_msg_trim_u64(nng_msg *, uint64_t *);
-NNG_DECL int      nng_msg_dup(nng_msg **, const nng_msg *);
-NNG_DECL void     nng_msg_clear(nng_msg *);
-NNG_DECL void     nng_msg_header_clear(nng_msg *);
-NNG_DECL void     nng_msg_set_pipe(nng_msg *, nng_pipe);
-NNG_DECL nng_pipe nng_msg_get_pipe(const nng_msg *);
-
-// Pipe API. Generally pipes are only "observable" to applications, but
-// we do permit an application to close a pipe. This can be useful, for
-// example during a connection notification, to disconnect a pipe that
-// is associated with an invalid or untrusted remote peer.
-NNG_DECL int nng_pipe_get(nng_pipe, const char *, void *, size_t *);
-NNG_DECL int nng_pipe_get_bool(nng_pipe, const char *, bool *);
-NNG_DECL int nng_pipe_get_int(nng_pipe, const char *, int *);
-NNG_DECL int nng_pipe_get_ms(nng_pipe, const char *, nng_duration *);
-NNG_DECL int nng_pipe_get_size(nng_pipe, const char *, size_t *);
-NNG_DECL int nng_pipe_get_uint64(nng_pipe, const char *, uint64_t *);
-NNG_DECL int nng_pipe_get_string(nng_pipe, const char *, char **);
-NNG_DECL int nng_pipe_get_ptr(nng_pipe, const char *, void **);
-NNG_DECL int nng_pipe_get_addr(nng_pipe, const char *, nng_sockaddr *);
-
-NNG_DECL int          nng_pipe_close(nng_pipe);
-NNG_DECL int          nng_pipe_id(nng_pipe);
-NNG_DECL nng_socket   nng_pipe_socket(nng_pipe);
-NNG_DECL nng_dialer   nng_pipe_dialer(nng_pipe);
-NNG_DECL nng_listener nng_pipe_listener(nng_pipe);
-
-// Flags.
-#define NNG_FLAG_ALLOC 1u // Recv to allocate receive buffer
-#define NNG_FLAG_NONBLOCK 2u // Non-blocking operations
-
-// Options.
-#define NNG_OPT_SOCKNAME "socket-name"
-#define NNG_OPT_RAW "raw"
-#define NNG_OPT_PROTO "protocol"
-#define NNG_OPT_PROTONAME "protocol-name"
-#define NNG_OPT_PEER "peer"
-#define NNG_OPT_PEERNAME "peer-name"
-#define NNG_OPT_RECVBUF "recv-buffer"
-#define NNG_OPT_SENDBUF "send-buffer"
-#define NNG_OPT_RECVFD "recv-fd"
-#define NNG_OPT_SENDFD "send-fd"
-#define NNG_OPT_RECVTIMEO "recv-timeout"
-#define NNG_OPT_SENDTIMEO "send-timeout"
-#define NNG_OPT_LOCADDR "local-address"
-#define NNG_OPT_REMADDR "remote-address"
-#define NNG_OPT_URL "url"
-#define NNG_OPT_MAXTTL "ttl-max"
-#define NNG_OPT_RECVMAXSZ "recv-size-max"
-#define NNG_OPT_RECONNMINT "reconnect-time-min"
-#define NNG_OPT_RECONNMAXT "reconnect-time-max"
-
-// TLS options are only used when the underlying transport supports TLS.
-
-// NNG_OPT_TLS_CONFIG is a pointer to an nng_tls_config object.  Generally
-// this can used with endpoints, although once an endpoint is started, or
-// once a configuration is used, the value becomes read-only. Note that
-// when configuring the object, a hold is placed on the TLS configuration,
-// using a reference count.  When retrieving the object, no such hold is
-// placed, and so the caller must take care not to use the associated object
-// after the endpoint it is associated with is closed.
-#define NNG_OPT_TLS_CONFIG "tls-config"
-
-// NNG_OPT_TLS_AUTH_MODE is a write-only integer (int) option that specifies
-// whether peer authentication is needed.  The option can take one of the
-// values of NNG_TLS_AUTH_MODE_NONE, NNG_TLS_AUTH_MODE_OPTIONAL, or
-// NNG_TLS_AUTH_MODE_REQUIRED.  The default is typically NNG_TLS_AUTH_MODE_NONE
-// for listeners, and NNG_TLS_AUTH_MODE_REQUIRED for dialers. If set to
-// REQUIRED, then connections will be rejected if the peer cannot be verified.
-// If set to OPTIONAL, then a verification step takes place, but the connection
-// is still permitted.  (The result can be checked with NNG_OPT_TLS_VERIFIED).
-#define NNG_OPT_TLS_AUTH_MODE "tls-authmode"
-
-// NNG_OPT_TLS_CERT_KEY_FILE names a single file that contains a certificate
-// and key identifying the endpoint.  This is a write-only value.  This can be
-// set multiple times for times for different keys/certs corresponding to
-// different algorithms on listeners, whereas dialers only support one.  The
-// file must contain both cert and key as PEM blocks, and the key must
-// not be encrypted.  (If more flexibility is needed, use the TLS configuration
-// directly, via NNG_OPT_TLS_CONFIG.)
-#define NNG_OPT_TLS_CERT_KEY_FILE "tls-cert-key-file"
-
-// NNG_OPT_TLS_CA_FILE names a single file that contains certificate(s) for a
-// CA, and optionally CRLs, which are used to validate the peer's certificate.
-// This is a write-only value, but multiple CAs can be loaded by setting this
-// multiple times.
-#define NNG_OPT_TLS_CA_FILE "tls-ca-file"
-
-// NNG_OPT_TLS_SERVER_NAME is a write-only string that can typically be
-// set on dialers to check the CN of the server for a match.  This
-// can also affect SNI (server name indication).  It usually has no effect
-// on listeners.
-#define NNG_OPT_TLS_SERVER_NAME "tls-server-name"
-
-// NNG_OPT_TLS_VERIFIED returns a boolean indicating whether the peer has
-// been verified (true) or not (false). Typically this is read-only, and
-// only available for pipes. This option may return incorrect results if
-// peer authentication is disabled with `NNG_TLS_AUTH_MODE_NONE`.
-#define NNG_OPT_TLS_VERIFIED "tls-verified"
-
-// NNG_OPT_TLS_PEER_CN returns the string with the common name
-// of the peer certificate. Typically this is read-only and
-// only available for pipes. This option may return incorrect results if
-// peer authentication is disabled with `NNG_TLS_AUTH_MODE_NONE`.
-#define NNG_OPT_TLS_PEER_CN "tls-peer-cn"
-
-// NNG_OPT_TLS_PEER_ALT_NAMES returns string list with the
-// subject alternative names of the peer certificate. Typically this is
-// read-only and only available for pipes. This option may return
-// incorrect results if peer authentication is disabled with
-// `NNG_TLS_AUTH_MODE_NONE`.
-#define NNG_OPT_TLS_PEER_ALT_NAMES "tls-peer-alt-names"
-
-// TCP options.  These may be supported on various transports that use
-// TCP underneath such as TLS, or not.
-
-// TCP nodelay disables the use of Nagle, so that messages are sent
-// as soon as data is available. This tends to reduce latency, but
-// can come at the cost of extra messages being sent, and may have
-// a detrimental effect on performance. For most uses, we recommend
-// enabling this. (Disable it if you are on a very slow network.)
-// This is a boolean.
-#define NNG_OPT_TCP_NODELAY "tcp-nodelay"
-
-// TCP keepalive causes the underlying transport to send keep-alive
-// messages, and keep the session active. Keepalives are zero length
-// messages with the ACK flag turned on. If we don't get an ACK back,
-// then we know the other side is gone. This is useful for detecting
-// dead peers, and is also used to prevent disconnections caused by
-// middle boxes thinking the session has gone idle (e.g. keeping NAT
-// state current). This is a boolean.
-#define NNG_OPT_TCP_KEEPALIVE "tcp-keepalive"
-
-// Local TCP port number.  This is used on a listener, and is intended
-// to be used after starting the listener in combination with a wildcard
-// (0) local port.  This determines the actual ephemeral port that was
-// selected and bound.  The value is provided as an int, but only the
-// low order 16 bits will be set.  This is provided in native byte order,
-// which makes it more convenient than using the NNG_OPT_LOCADDR option.
-#define NNG_OPT_TCP_BOUND_PORT "tcp-bound-port"
-
-// IPC options.  These will largely vary depending on the platform,
-// as POSIX systems have very different options than Windows.
-
-// Security Descriptor.  This option may only be set on listeners
-// on the Windows platform, where the object is a pointer to a
-// a Windows SECURITY_DESCRIPTOR.
-#define NNG_OPT_IPC_SECURITY_DESCRIPTOR "ipc:security-descriptor"
-
-// Permissions bits.  This option is only valid for listeners on
-// POSIX platforms and others that honor UNIX style permission bits.
-// Note that some platforms may not honor the permissions here, although
-// at least Linux and macOS seem to do so.  Check before you rely on
-// this for security.
-#define NNG_OPT_IPC_PERMISSIONS "ipc:permissions"
-
-// Peer UID.  This is only available on POSIX style systems.
-#define NNG_OPT_IPC_PEER_UID "ipc:peer-uid"
-
-// Peer GID (primary group).  This is only available on POSIX style systems.
-#define NNG_OPT_IPC_PEER_GID "ipc:peer-gid"
-
-// Peer process ID.  Available on Windows, Linux, and SunOS.
-// In theory we could obtain this with the first message sent,
-// but we have elected not to do this for now. (Nice RFE for a FreeBSD
-// guru though.)
-#define NNG_OPT_IPC_PEER_PID "ipc:peer-pid"
-
-// Peer Zone ID.  Only on SunOS systems.  (Linux containers have no
-// definable kernel identity; they are a user-land fabrication made up
-// from various pieces of different namespaces. FreeBSD does have
-// something called JailIDs, but it isn't obvious how to determine this,
-// or even if processes can use IPC across jail boundaries.)
-#define NNG_OPT_IPC_PEER_ZONEID "ipc:peer-zoneid"
-
-// WebSocket Options.
-
-// NNG_OPT_WS_REQUEST_HEADERS is a string containing the
-// request headers, formatted as CRLF terminated lines.
-#define NNG_OPT_WS_REQUEST_HEADERS "ws:request-headers"
-
-// NNG_OPT_WS_RESPONSE_HEADERS is a string containing the
-// response headers, formatted as CRLF terminated lines.
-#define NNG_OPT_WS_RESPONSE_HEADERS "ws:response-headers"
-
-// NNG_OPT_WS_REQUEST_HEADER is a prefix, for a dynamic
-// property name.  This allows direct access to any named header.
-// Concatenate this with the name of the property (case is not sensitive).
-// Only the first such header is returned.
-#define NNG_OPT_WS_RESPONSE_HEADER "ws:response-header:"
-
-// NNG_OPT_WS_RESPONSE_HEADER is like NNG_OPT_REQUEST_HEADER, but used for
-// accessing the request headers.
-#define NNG_OPT_WS_REQUEST_HEADER "ws:request-header:"
-
-// NNG_OPT_WS_REQUEST_URI is used to obtain the URI sent by the client.
-// This can be useful when a handler supports an entire directory tree.
-#define NNG_OPT_WS_REQUEST_URI "ws:request-uri"
-
-// NNG_OPT_WS_SENDMAXFRAME is used to configure the fragmentation size
-// used for frames.  This has a default value of 64k.  Large values
-// are good for throughput, but penalize latency.  They also require
-// additional buffering on the peer.  This value must not be larger
-// than what the peer will accept, and unfortunately there is no way
-// to negotiate this.
-#define NNG_OPT_WS_SENDMAXFRAME "ws:txframe-max"
-
-// NNG_OPT_WS_RECVMAXFRAME is the largest frame we will accept.  This should
-// probably not be larger than NNG_OPT_RECVMAXSZ. If the sender attempts
-// to send more data than this in a single message, it will be dropped.
-#define NNG_OPT_WS_RECVMAXFRAME "ws:rxframe-max"
-
-// NNG_OPT_WS_PROTOCOL is the "websocket sub-protocol" -- it's a string.
-// This is also known as the Sec-WebSocket-Protocol header. It is treated
-// specially.  This is part of the websocket handshake.
-#define NNG_OPT_WS_PROTOCOL "ws:protocol"
-
-// NNG_OPT_WS_SEND_TEXT is a boolean used to tell the WS stream
-// transport to send text messages.  This is not supported for the
-// core WebSocket transport, but when using streams it might be useful
-// to speak with 3rd party WebSocket applications.  This mode should
-// not be used unless absolutely required. No validation of the message
-// contents is performed by NNG; applications are expected to honor
-// the requirement to send only valid UTF-8.  (Compliant applications
-// will close the socket if they see this message type with invalid UTF-8.)
-#define NNG_OPT_WS_SEND_TEXT "ws:send-text"
-
-// NNG_OPT_WS_RECV_TEXT is a boolean that enables NNG to receive
-// TEXT frames.  This is only useful for stream mode applications --
-// SP protocol requires the use of binary frames.  Note also that
-// NNG does not validate the message contents for valid UTF-8; this
-// means it will not be conformant with RFC-6455 on it's own. Applications
-// that need this should check the message contents themselves, and
-// close the connection if invalid UTF-8 is received.  This option
-// should not be used unless required to communication with 3rd party
-// peers that cannot be coerced into sending binary frames.
-#define NNG_OPT_WS_RECV_TEXT "ws:recv-text"
-
-// XXX: TBD: priorities, ipv4only
-
-// Statistics. These are for informational purposes only, and subject
-// to change without notice. The API for accessing these is stable,
-// but the individual statistic names, values, and meanings are all
-// subject to change.
-
-// nng_stats_get takes a snapshot of the entire set of statistics.
-// While the operation can be somewhat expensive (allocations), it
-// is done in a way that minimizes impact to running operations.
-// Note that the statistics are provided as a tree, with parents
-// used for grouping, and with child statistics underneath.  The
-// top stat returned will be of type NNG_STAT_SCOPE with name "".
-// Applications may choose to consider this root scope as "root", if
-// the empty string is not suitable.
-NNG_DECL int nng_stats_get(nng_stat **);
-
-// nng_stats_free frees a previous list of snapshots.  This should only
-// be called on the parent statistic that obtained via nng_stats_get.
-NNG_DECL void nng_stats_free(nng_stat *);
-
-// nng_stats_dump is a debugging function that dumps the entire set of
-// statistics to stdout.
-NNG_DECL void nng_stats_dump(nng_stat *);
-
-// nng_stat_next finds the next sibling for the current stat.  If there
-// are no more siblings, it returns NULL.
-NNG_DECL nng_stat *nng_stat_next(nng_stat *);
-
-// nng_stat_child finds the first child of the current stat.  If no children
-// exist, then NULL is returned.
-NNG_DECL nng_stat *nng_stat_child(nng_stat *);
-
-// nng_stat_name is used to determine the name of the statistic.
-// This is a human readable name.  Statistic names, as well as the presence
-// or absence or semantic of any particular statistic are not part of any
-// stable API, and may be changed without notice in future updates.
-NNG_DECL const char *nng_stat_name(nng_stat *);
-
-// nng_stat_type is used to determine the type of the statistic.
-// Counters generally increment, and therefore changes in the value over
-// time are likely more interesting than the actual level.  Level
-// values reflect some absolute state however, and should be presented to the
-// user as is.
-NNG_DECL int nng_stat_type(nng_stat *);
-
-// nng_stat_find is used to find a specific named statistic within
-// a statistic tree.  NULL is returned if no such statistic exists.
-NNG_DECL nng_stat *nng_stat_find(nng_stat *, const char *);
-
-// nng_stat_find_socket is used to find the stats for the given socket.
-NNG_DECL nng_stat *nng_stat_find_socket(nng_stat *, nng_socket);
-
-// nng_stat_find_dialer is used to find the stats for the given dialer.
-NNG_DECL nng_stat *nng_stat_find_dialer(nng_stat *, nng_dialer);
-
-// nng_stat_find_listener is used to find the stats for the given listener.
-NNG_DECL nng_stat *nng_stat_find_listener(nng_stat *, nng_listener);
-
-enum nng_stat_type_enum {
-	NNG_STAT_SCOPE   = 0, // Stat is for scoping, and carries no value
-	NNG_STAT_LEVEL   = 1, // Numeric "absolute" value, diffs meaningless
-	NNG_STAT_COUNTER = 2, // Incrementing value (diffs are meaningful)
-	NNG_STAT_STRING  = 3, // Value is a string
-	NNG_STAT_BOOLEAN = 4, // Value is a boolean
-	NNG_STAT_ID      = 5, // Value is a numeric ID
-};
-
-// nng_stat_unit provides information about the unit for the statistic,
-// such as NNG_UNIT_BYTES or NNG_UNIT_BYTES.  If no specific unit is
-// applicable, such as a relative priority, then NN_UNIT_NONE is returned.
-NNG_DECL int nng_stat_unit(nng_stat *);
-
-enum nng_unit_enum {
-	NNG_UNIT_NONE     = 0, // No special units
-	NNG_UNIT_BYTES    = 1, // Bytes, e.g. bytes sent, etc.
-	NNG_UNIT_MESSAGES = 2, // Messages, one per message
-	NNG_UNIT_MILLIS   = 3, // Milliseconds
-	NNG_UNIT_EVENTS   = 4  // Some other type of event
-};
-
-// nng_stat_value returns returns the actual value of the statistic.
-// Statistic values reflect their value at the time that the corresponding
-// snapshot was updated, and are undefined until an update is performed.
-NNG_DECL uint64_t nng_stat_value(nng_stat *);
-
-// nng_stat_value returns returns the actual value of the statistic.
-// Statistic values reflect their value at the time that the corresponding
-// snapshot was updated, and are undefined until an update is performed.
-NNG_DECL bool nng_stat_bool(nng_stat *);
-
-// nng_stat_string returns the string associated with a string statistic,
-// or NULL if the statistic is not part of the string.  The value returned
-// is valid until the associated statistic is freed.
-NNG_DECL const char *nng_stat_string(nng_stat *);
-
-// nng_stat_desc returns a human readable description of the statistic.
-// This may be useful for display in diagnostic interfaces, etc.
-NNG_DECL const char *nng_stat_desc(nng_stat *);
-
-// nng_stat_timestamp returns a timestamp (milliseconds) when the statistic
-// was captured.  The base offset is the same as used by nng_clock().
-// We don't use nng_time though, because that's in the supplemental header.
-NNG_DECL uint64_t nng_stat_timestamp(nng_stat *);
-
-// Device functionality.  This connects two sockets together in a device,
-// which means that messages from one side are forwarded to the other.
-// This version is synchronous, which means the caller will block until
-// one of the sockets is closed. Note that caller is responsible for
-// finally closing both sockets when this function returns.
-NNG_DECL int nng_device(nng_socket, nng_socket);
-
-// Asynchronous form of nng_device.  When this succeeds, the device is
-// left intact and functioning in the background, until one of the sockets
-// is closed or the application exits.  The sockets may be shut down if
-// the device fails, but the caller is responsible for ultimately closing
-// the sockets properly after the device is torn down.
-NNG_DECL void nng_device_aio(nng_aio *, nng_socket, nng_socket);
-
-// Symbol name and visibility.  TBD.  The only symbols that really should
-// be directly exported to runtimes IMO are the option symbols.  And frankly
-// they have enough special logic around them that it might be best not to
-// automate the promotion of them to other APIs.  This is an area open
-// for discussion.
-
-// Error codes.  These generally have different values from UNIX errnos,
-// so take care about converting them.  The one exception is that 0 is
-// unambiguously "success".
-//
-// NNG_SYSERR is a special code, which allows us to wrap errors from the
-// underlying operating system.  We generally prefer to map errors to one
-// of the above, but if we cannot, then we just encode an error this way.
-// The bit is large enough to accommodate all known UNIX and Win32 error
-// codes.  We try hard to match things semantically to one of our standard
-// errors.  For example, a connection reset or aborted we treat as a
-// closed connection, because that's basically what it means.  (The remote
-// peer closed the connection.)  For certain kinds of resource exhaustion
-// we treat it the same as memory.  But for files, etc. that's OS-specific,
-// and we use the generic below.  Some of the above error codes we use
-// internally, and the application should never see (e.g. NNG_EINTR).
-//
-// NNG_ETRANERR is like ESYSERR, but is used to wrap transport specific
-// errors, from different transports.  It should only be used when none
-// of the other options are available.
-
-enum nng_errno_enum {
-	NNG_EINTR        = 1,
-	NNG_ENOMEM       = 2,
-	NNG_EINVAL       = 3,
-	NNG_EBUSY        = 4,
-	NNG_ETIMEDOUT    = 5,
-	NNG_ECONNREFUSED = 6,
-	NNG_ECLOSED      = 7,
-	NNG_EAGAIN       = 8,
-	NNG_ENOTSUP      = 9,
-	NNG_EADDRINUSE   = 10,
-	NNG_ESTATE       = 11,
-	NNG_ENOENT       = 12,
-	NNG_EPROTO       = 13,
-	NNG_EUNREACHABLE = 14,
-	NNG_EADDRINVAL   = 15,
-	NNG_EPERM        = 16,
-	NNG_EMSGSIZE     = 17,
-	NNG_ECONNABORTED = 18,
-	NNG_ECONNRESET   = 19,
-	NNG_ECANCELED    = 20,
-	NNG_ENOFILES     = 21,
-	NNG_ENOSPC       = 22,
-	NNG_EEXIST       = 23,
-	NNG_EREADONLY    = 24,
-	NNG_EWRITEONLY   = 25,
-	NNG_ECRYPTO      = 26,
-	NNG_EPEERAUTH    = 27,
-	NNG_ENOARG       = 28,
-	NNG_EAMBIGUOUS   = 29,
-	NNG_EBADTYPE     = 30,
-	NNG_ECONNSHUT    = 31,
-	NNG_EINTERNAL    = 1000,
-	NNG_ESYSERR      = 0x10000000,
-	NNG_ETRANERR     = 0x20000000
-};
-
-// URL support.  We frequently want to process a URL, and these methods
-// give us a convenient way of doing so.
-
-typedef struct nng_url {
-	char *u_rawurl;   // never NULL
-	char *u_scheme;   // never NULL
-	char *u_userinfo; // will be NULL if not specified
-	char *u_host;     // including colon and port
-	char *u_hostname; // name only, will be "" if not specified
-	char *u_port;     // port, will be "" if not specified
-	char *u_path;     // path, will be "" if not specified
-	char *u_query;    // without '?', will be NULL if not specified
-	char *u_fragment; // without '#', will be NULL if not specified
-	char *u_requri;   // includes query and fragment, "" if not specified
-} nng_url;
-
-// nng_url_parse parses a URL string into a structured form.
-// Note that the u_port member will be filled out with a numeric
-// port if one isn't specified and a default port is appropriate for
-// the scheme.  The URL structure is allocated, along with individual
-// members.  It can be freed with nng_url_free.
-NNG_DECL int nng_url_parse(nng_url **, const char *);
-
-// nng_url_free frees a URL structure that was created by nng_url_parse().
-NNG_DECL void nng_url_free(nng_url *);
-
-// nng_url_clone clones a URL structure.
-NNG_DECL int nng_url_clone(nng_url **, const nng_url *);
-
-// nng_version returns the library version as a human readable string.
-NNG_DECL const char *nng_version(void);
-
-// nng_stream operations permit direct access to low level streams,
-// which can have a variety of uses.  Internally most of the transports
-// are built on top of these.  Streams are created by other dialers or
-// listeners.  The API for creating dialers and listeners varies.
-
-typedef struct nng_stream          nng_stream;
-typedef struct nng_stream_dialer   nng_stream_dialer;
-typedef struct nng_stream_listener nng_stream_listener;
-
-NNG_DECL void nng_stream_free(nng_stream *);
-NNG_DECL void nng_stream_close(nng_stream *);
-NNG_DECL void nng_stream_send(nng_stream *, nng_aio *);
-NNG_DECL void nng_stream_recv(nng_stream *, nng_aio *);
-NNG_DECL int  nng_stream_get(nng_stream *, const char *, void *, size_t *);
-NNG_DECL int  nng_stream_get_bool(nng_stream *, const char *, bool *);
-NNG_DECL int  nng_stream_get_int(nng_stream *, const char *, int *);
-NNG_DECL int  nng_stream_get_ms(nng_stream *, const char *, nng_duration *);
-NNG_DECL int  nng_stream_get_size(nng_stream *, const char *, size_t *);
-NNG_DECL int  nng_stream_get_uint64(nng_stream *, const char *, uint64_t *);
-NNG_DECL int  nng_stream_get_string(nng_stream *, const char *, char **);
-NNG_DECL int  nng_stream_get_ptr(nng_stream *, const char *, void **);
-NNG_DECL int  nng_stream_get_addr(nng_stream *, const char *, nng_sockaddr *);
-NNG_DECL int  nng_stream_set(nng_stream *, const char *, const void *, size_t);
-NNG_DECL int  nng_stream_set_bool(nng_stream *, const char *, bool);
-NNG_DECL int  nng_stream_set_int(nng_stream *, const char *, int);
-NNG_DECL int  nng_stream_set_ms(nng_stream *, const char *, nng_duration);
-NNG_DECL int  nng_stream_set_size(nng_stream *, const char *, size_t);
-NNG_DECL int  nng_stream_set_uint64(nng_stream *, const char *, uint64_t);
-NNG_DECL int  nng_stream_set_string(nng_stream *, const char *, const char *);
-NNG_DECL int  nng_stream_set_ptr(nng_stream *, const char *, void *);
-NNG_DECL int  nng_stream_set_addr(
-     nng_stream *, const char *, const nng_sockaddr *);
-
-NNG_DECL int nng_stream_dialer_alloc(nng_stream_dialer **, const char *);
-NNG_DECL int nng_stream_dialer_alloc_url(
-    nng_stream_dialer **, const nng_url *);
-NNG_DECL void nng_stream_dialer_free(nng_stream_dialer *);
-NNG_DECL void nng_stream_dialer_close(nng_stream_dialer *);
-NNG_DECL void nng_stream_dialer_dial(nng_stream_dialer *, nng_aio *);
-NNG_DECL int  nng_stream_dialer_set(
-     nng_stream_dialer *, const char *, const void *, size_t);
-NNG_DECL int nng_stream_dialer_get(
-    nng_stream_dialer *, const char *, void *, size_t *);
-NNG_DECL int nng_stream_dialer_get_bool(
-    nng_stream_dialer *, const char *, bool *);
-NNG_DECL int nng_stream_dialer_get_int(
-    nng_stream_dialer *, const char *, int *);
-NNG_DECL int nng_stream_dialer_get_ms(
-    nng_stream_dialer *, const char *, nng_duration *);
-NNG_DECL int nng_stream_dialer_get_size(
-    nng_stream_dialer *, const char *, size_t *);
-NNG_DECL int nng_stream_dialer_get_uint64(
-    nng_stream_dialer *, const char *, uint64_t *);
-NNG_DECL int nng_stream_dialer_get_string(
-    nng_stream_dialer *, const char *, char **);
-NNG_DECL int nng_stream_dialer_get_ptr(
-    nng_stream_dialer *, const char *, void **);
-NNG_DECL int nng_stream_dialer_get_addr(
-    nng_stream_dialer *, const char *, nng_sockaddr *);
-NNG_DECL int nng_stream_dialer_set_bool(
-    nng_stream_dialer *, const char *, bool);
-NNG_DECL int nng_stream_dialer_set_int(nng_stream_dialer *, const char *, int);
-NNG_DECL int nng_stream_dialer_set_ms(
-    nng_stream_dialer *, const char *, nng_duration);
-NNG_DECL int nng_stream_dialer_set_size(
-    nng_stream_dialer *, const char *, size_t);
-NNG_DECL int nng_stream_dialer_set_uint64(
-    nng_stream_dialer *, const char *, uint64_t);
-NNG_DECL int nng_stream_dialer_set_string(
-    nng_stream_dialer *, const char *, const char *);
-NNG_DECL int nng_stream_dialer_set_ptr(
-    nng_stream_dialer *, const char *, void *);
-NNG_DECL int nng_stream_dialer_set_addr(
-    nng_stream_dialer *, const char *, const nng_sockaddr *);
-
-NNG_DECL int nng_stream_listener_alloc(nng_stream_listener **, const char *);
-NNG_DECL int nng_stream_listener_alloc_url(
-    nng_stream_listener **, const nng_url *);
-NNG_DECL void nng_stream_listener_free(nng_stream_listener *);
-NNG_DECL void nng_stream_listener_close(nng_stream_listener *);
-NNG_DECL int  nng_stream_listener_listen(nng_stream_listener *);
-NNG_DECL void nng_stream_listener_accept(nng_stream_listener *, nng_aio *);
-NNG_DECL int  nng_stream_listener_set(
-     nng_stream_listener *, const char *, const void *, size_t);
-NNG_DECL int nng_stream_listener_get(
-    nng_stream_listener *, const char *, void *, size_t *);
-NNG_DECL int nng_stream_listener_get_bool(
-    nng_stream_listener *, const char *, bool *);
-NNG_DECL int nng_stream_listener_get_int(
-    nng_stream_listener *, const char *, int *);
-NNG_DECL int nng_stream_listener_get_ms(
-    nng_stream_listener *, const char *, nng_duration *);
-NNG_DECL int nng_stream_listener_get_size(
-    nng_stream_listener *, const char *, size_t *);
-NNG_DECL int nng_stream_listener_get_uint64(
-    nng_stream_listener *, const char *, uint64_t *);
-NNG_DECL int nng_stream_listener_get_string(
-    nng_stream_listener *, const char *, char **);
-NNG_DECL int nng_stream_listener_get_ptr(
-    nng_stream_listener *, const char *, void **);
-NNG_DECL int nng_stream_listener_get_addr(
-    nng_stream_listener *, const char *, nng_sockaddr *);
-NNG_DECL int nng_stream_listener_set_bool(
-    nng_stream_listener *, const char *, bool);
-NNG_DECL int nng_stream_listener_set_int(
-    nng_stream_listener *, const char *, int);
-NNG_DECL int nng_stream_listener_set_ms(
-    nng_stream_listener *, const char *, nng_duration);
-NNG_DECL int nng_stream_listener_set_size(
-    nng_stream_listener *, const char *, size_t);
-NNG_DECL int nng_stream_listener_set_uint64(
-    nng_stream_listener *, const char *, uint64_t);
-NNG_DECL int nng_stream_listener_set_string(
-    nng_stream_listener *, const char *, const char *);
-NNG_DECL int nng_stream_listener_set_ptr(
-    nng_stream_listener *, const char *, void *);
-NNG_DECL int nng_stream_listener_set_addr(
-    nng_stream_listener *, const char *, const nng_sockaddr *);
-
-
-#ifndef NNG_ELIDE_DEPRECATED
-// These are legacy APIs that have been deprecated.
-// Their use is strongly discouraged.
-
-// nng_msg_getopt is defunct, and should not be used by programs. It
-// always returns NNG_ENOTSUP.
-NNG_DECL int nng_msg_getopt(nng_msg *, int, void *, size_t *) NNG_DEPRECATED;
-
-// Socket options.  Use nng_socket_get and nng_socket_set instead.
-NNG_DECL int nng_getopt(nng_socket, const char *, void *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_getopt_bool(nng_socket, const char *, bool *) NNG_DEPRECATED;
-NNG_DECL int nng_getopt_int(nng_socket, const char *, int *) NNG_DEPRECATED;
-NNG_DECL int nng_getopt_ms(nng_socket, const char *, nng_duration *) NNG_DEPRECATED;
-NNG_DECL int nng_getopt_size(nng_socket, const char *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_getopt_uint64(nng_socket, const char *, uint64_t *) NNG_DEPRECATED;
-NNG_DECL int nng_getopt_ptr(nng_socket, const char *, void **) NNG_DEPRECATED;
-NNG_DECL int nng_getopt_string(nng_socket, const char *, char **) NNG_DEPRECATED;
-NNG_DECL int nng_setopt(nng_socket, const char *, const void *, size_t) NNG_DEPRECATED;
-NNG_DECL int nng_setopt_bool(nng_socket, const char *, bool) NNG_DEPRECATED;
-NNG_DECL int nng_setopt_int(nng_socket, const char *, int) NNG_DEPRECATED;
-NNG_DECL int nng_setopt_ms(nng_socket, const char *, nng_duration) NNG_DEPRECATED;
-NNG_DECL int nng_setopt_size(nng_socket, const char *, size_t) NNG_DEPRECATED;
-NNG_DECL int nng_setopt_uint64(nng_socket, const char *, uint64_t) NNG_DEPRECATED;
-NNG_DECL int nng_setopt_string(nng_socket, const char *, const char *) NNG_DEPRECATED;
-NNG_DECL int nng_setopt_ptr(nng_socket, const char *, void *) NNG_DEPRECATED;
-
-// Context options.  Use nng_ctx_get and nng_ctx_set instead.
-NNG_DECL int nng_ctx_getopt(nng_ctx, const char *, void *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_getopt_bool(nng_ctx, const char *, bool *) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_getopt_int(nng_ctx, const char *, int *) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_getopt_ms(nng_ctx, const char *, nng_duration *) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_getopt_size(nng_ctx, const char *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_setopt(nng_ctx, const char *, const void *, size_t) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_setopt_bool(nng_ctx, const char *, bool) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_setopt_int(nng_ctx, const char *, int) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_setopt_ms(nng_ctx, const char *, nng_duration) NNG_DEPRECATED;
-NNG_DECL int nng_ctx_setopt_size(nng_ctx, const char *, size_t) NNG_DEPRECATED;
-
-// Dialer options.  Use nng_dialer_get and nng_dialer_set instead.
-NNG_DECL int nng_dialer_getopt(nng_dialer, const char *, void *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_bool(nng_dialer, const char *, bool *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_int(nng_dialer, const char *, int *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_ms(nng_dialer, const char *, nng_duration *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_size(nng_dialer, const char *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_sockaddr(
-    nng_dialer, const char *, nng_sockaddr *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_uint64(nng_dialer, const char *, uint64_t *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_ptr(nng_dialer, const char *, void **) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_getopt_string(nng_dialer, const char *, char **) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt(nng_dialer, const char *, const void *, size_t) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt_bool(nng_dialer, const char *, bool) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt_int(nng_dialer, const char *, int) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt_ms(nng_dialer, const char *, nng_duration) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt_size(nng_dialer, const char *, size_t) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt_uint64(nng_dialer, const char *, uint64_t) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt_ptr(nng_dialer, const char *, void *) NNG_DEPRECATED;
-NNG_DECL int nng_dialer_setopt_string(nng_dialer, const char *, const char *) NNG_DEPRECATED;
-
-// Listener options.  Use nng_listener_get and nng_listener_set instead.
-NNG_DECL int nng_listener_getopt(nng_listener, const char *, void *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_bool(nng_listener, const char *, bool *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_int(nng_listener, const char *, int *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_ms(
-    nng_listener, const char *, nng_duration *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_size(nng_listener, const char *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_sockaddr(
-    nng_listener, const char *, nng_sockaddr *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_uint64(
-    nng_listener, const char *, uint64_t *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_ptr(nng_listener, const char *, void **) NNG_DEPRECATED;
-NNG_DECL int nng_listener_getopt_string(nng_listener, const char *, char **) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt(
-    nng_listener, const char *, const void *, size_t) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt_bool(nng_listener, const char *, bool) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt_int(nng_listener, const char *, int) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt_ms(nng_listener, const char *, nng_duration) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt_size(nng_listener, const char *, size_t) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt_uint64(nng_listener, const char *, uint64_t) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt_ptr(nng_listener, const char *, void *) NNG_DEPRECATED;
-NNG_DECL int nng_listener_setopt_string(
-    nng_listener, const char *, const char *) NNG_DEPRECATED;
-
-// Pipe options.  Use nng_pipe_get instead.
-NNG_DECL int nng_pipe_getopt(nng_pipe, const char *, void *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_bool(nng_pipe, const char *, bool *) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_int(nng_pipe, const char *, int *) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_ms(nng_pipe, const char *, nng_duration *) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_size(nng_pipe, const char *, size_t *) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_sockaddr(nng_pipe, const char *, nng_sockaddr *) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_uint64(nng_pipe, const char *, uint64_t *) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_ptr(nng_pipe, const char *, void **) NNG_DEPRECATED;
-NNG_DECL int nng_pipe_getopt_string(nng_pipe, const char *, char **) NNG_DEPRECATED;
-
-// nng_closeall closes all open sockets. Do not call this from
-// a library; it will affect all sockets.
-NNG_DECL void nng_closeall(void) NNG_DEPRECATED;
-
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_NNG_H
+//
+// Copyright 2023 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_NNG_H
+#define NNG_NNG_H
+
+// NNG (nanomsg-next-gen) is an improved implementation of the SP protocols.
+// The APIs have changed, and there is no attempt to provide API compatibility
+// with legacy libnanomsg. This file defines the library consumer-facing
+// Public API. Use of definitions or declarations not found in this header
+// file is specifically unsupported and strongly discouraged.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <stdbool.h>
+#include <stddef.h>
+#include <stdint.h>
+
+// NNG_DECL is used on declarations to deal with scope.
+// For building Windows DLLs, it should be the appropriate __declspec().
+// For shared libraries with platforms that support hidden visibility,
+// it should evaluate to __attribute__((visibility("default"))).
+#ifndef NNG_DECL
+#if defined(_WIN32) && !defined(NNG_STATIC_LIB)
+#if defined(NNG_SHARED_LIB)
+#define NNG_DECL __declspec(dllexport)
+#else
+#define NNG_DECL __declspec(dllimport)
+#endif // NNG_SHARED_LIB
+#else
+#if defined(NNG_SHARED_LIB) && defined(NNG_HIDDEN_VISIBILITY)
+#define NNG_DECL __attribute__((visibility("default")))
+#else
+#define NNG_DECL extern
+#endif
+#endif // _WIN32 && !NNG_STATIC_LIB
+#endif // NNG_DECL
+
+#ifndef NNG_DEPRECATED
+#if defined(__GNUC__) || defined(__clang__)
+#define NNG_DEPRECATED __attribute__ ((deprecated))
+#else
+#define NNG_DEPRECATED
+#endif
+#endif
+
+// NNG Library & API version.
+// We use SemVer, and these versions are about the API, and
+// may not necessarily match the ABI versions.
+#define NNG_MAJOR_VERSION 1
+#define NNG_MINOR_VERSION 6
+#define NNG_PATCH_VERSION 0
+#define NNG_RELEASE_SUFFIX "" // if non-empty (i.e. "pre"), this is a pre-release
+
+// Maximum length of a socket address. This includes the terminating NUL.
+// This limit is built into other implementations, so do not change it.
+// Note that some transports are quite happy to let you use addresses
+// in excess of this, but if you do you may not be able to communicate
+// with other implementations.
+#define NNG_MAXADDRLEN (128)
+
+// NNG_PROTOCOL_NUMBER is used by protocol headers to calculate their
+// protocol number from a major and minor number.  Applications should
+// probably not need to use this.
+#define NNG_PROTOCOL_NUMBER(maj, min) (((x) *16) + (y))
+
+// Types common to nng.
+
+// Identifiers are wrapped in a structure to improve compiler validation
+// of incorrect passing.  This gives us strong type checking.  Modern
+// compilers compile passing these by value to identical code as passing
+// the integer type (at least with optimization applied).  Please do not
+// access the ID member directly.
+
+typedef struct nng_ctx_s {
+	uint32_t id;
+} nng_ctx;
+
+typedef struct nng_dialer_s {
+	uint32_t id;
+} nng_dialer;
+
+typedef struct nng_listener_s {
+	uint32_t id;
+} nng_listener;
+
+typedef struct nng_pipe_s {
+	uint32_t id;
+} nng_pipe;
+
+typedef struct nng_socket_s {
+	uint32_t id;
+} nng_socket;
+
+typedef int32_t         nng_duration; // in milliseconds
+typedef struct nng_msg  nng_msg;
+typedef struct nng_stat nng_stat;
+typedef struct nng_aio  nng_aio;
+
+// Initializers.
+// clang-format off
+#define NNG_PIPE_INITIALIZER { 0 }
+#define NNG_SOCKET_INITIALIZER { 0 }
+#define NNG_DIALER_INITIALIZER { 0 }
+#define NNG_LISTENER_INITIALIZER { 0 }
+#define NNG_CTX_INITIALIZER { 0 }
+// clang-format on
+
+// Some address details. This is in some ways like a traditional sockets
+// sockaddr, but we have our own to cope with our unique families, etc.
+// The details of this structure are directly exposed to applications.
+// These structures can be obtained via property lookups, etc.
+struct nng_sockaddr_inproc {
+	uint16_t sa_family;
+	char     sa_name[NNG_MAXADDRLEN];
+};
+
+struct nng_sockaddr_path {
+	uint16_t sa_family;
+	char     sa_path[NNG_MAXADDRLEN];
+};
+
+struct nng_sockaddr_in6 {
+	uint16_t sa_family;
+	uint16_t sa_port;
+	uint8_t  sa_addr[16];
+	uint32_t sa_scope;
+};
+struct nng_sockaddr_in {
+	uint16_t sa_family;
+	uint16_t sa_port;
+	uint32_t sa_addr;
+};
+
+struct nng_sockaddr_zt {
+	uint16_t sa_family;
+	uint64_t sa_nwid;
+	uint64_t sa_nodeid;
+	uint32_t sa_port;
+};
+
+struct nng_sockaddr_abstract {
+	uint16_t sa_family;
+	uint16_t sa_len;       // will be 0 - 107 max.
+	uint8_t  sa_name[107]; // 108 linux/windows, without leading NUL
+};
+
+// nng_sockaddr_storage is the the size required to store any nng_sockaddr.
+// This size must not change, and no individual nng_sockaddr type may grow
+// larger than this without breaking binary compatibility.
+struct nng_sockaddr_storage {
+	uint16_t sa_family;
+	uint64_t sa_pad[16];
+};
+
+typedef struct nng_sockaddr_inproc   nng_sockaddr_inproc;
+typedef struct nng_sockaddr_path     nng_sockaddr_path;
+typedef struct nng_sockaddr_path     nng_sockaddr_ipc;
+typedef struct nng_sockaddr_in       nng_sockaddr_in;
+typedef struct nng_sockaddr_in6      nng_sockaddr_in6;
+typedef struct nng_sockaddr_zt       nng_sockaddr_zt;
+typedef struct nng_sockaddr_abstract nng_sockaddr_abstract;
+typedef struct nng_sockaddr_storage  nng_sockaddr_storage;
+
+typedef union nng_sockaddr {
+	uint16_t              s_family;
+	nng_sockaddr_ipc      s_ipc;
+	nng_sockaddr_inproc   s_inproc;
+	nng_sockaddr_in6      s_in6;
+	nng_sockaddr_in       s_in;
+	nng_sockaddr_zt       s_zt;
+	nng_sockaddr_abstract s_abstract;
+	nng_sockaddr_storage  s_storage;
+} nng_sockaddr;
+
+enum nng_sockaddr_family {
+	NNG_AF_UNSPEC   = 0,
+	NNG_AF_INPROC   = 1,
+	NNG_AF_IPC      = 2,
+	NNG_AF_INET     = 3,
+	NNG_AF_INET6    = 4,
+	NNG_AF_ZT       = 5, // ZeroTier
+	NNG_AF_ABSTRACT = 6
+};
+
+// Scatter/gather I/O.
+typedef struct nng_iov {
+	void * iov_buf;
+	size_t iov_len;
+} nng_iov;
+
+// Some definitions for durations used with timeouts.
+#define NNG_DURATION_INFINITE (-1)
+#define NNG_DURATION_DEFAULT (-2)
+#define NNG_DURATION_ZERO (0)
+
+// nng_fini is used to terminate the library, freeing certain global resources.
+// This should only be called during atexit() or just before dlclose().
+// THIS FUNCTION MUST NOT BE CALLED CONCURRENTLY WITH ANY OTHER FUNCTION
+// IN THIS LIBRARY; IT IS NOT REENTRANT OR THREADSAFE.
+//
+// For most cases, this call is unnecessary, but it is provided to assist
+// when debugging with memory checkers (e.g. valgrind).  Calling this
+// function prevents global library resources from being reported incorrectly
+// as memory leaks.  In those cases, we recommend doing this with atexit().
+NNG_DECL void nng_fini(void);
+
+// nng_close closes the socket, terminating all activity and
+// closing any underlying connections and releasing any associated
+// resources.
+NNG_DECL int nng_close(nng_socket);
+
+// nng_socket_id returns the positive socket id for the socket, or -1
+// if the socket is not valid.
+NNG_DECL int nng_socket_id(nng_socket);
+
+NNG_DECL int nng_socket_set(nng_socket, const char *, const void *, size_t);
+NNG_DECL int nng_socket_set_bool(nng_socket, const char *, bool);
+NNG_DECL int nng_socket_set_int(nng_socket, const char *, int);
+NNG_DECL int nng_socket_set_size(nng_socket, const char *, size_t);
+NNG_DECL int nng_socket_set_uint64(nng_socket, const char *, uint64_t);
+NNG_DECL int nng_socket_set_string(nng_socket, const char *, const char *);
+NNG_DECL int nng_socket_set_ptr(nng_socket, const char *, void *);
+NNG_DECL int nng_socket_set_ms(nng_socket, const char *, nng_duration);
+NNG_DECL int nng_socket_set_addr(
+    nng_socket, const char *, const nng_sockaddr *);
+
+NNG_DECL int nng_socket_get(nng_socket, const char *, void *, size_t *);
+NNG_DECL int nng_socket_get_bool(nng_socket, const char *, bool *);
+NNG_DECL int nng_socket_get_int(nng_socket, const char *, int *);
+NNG_DECL int nng_socket_get_size(nng_socket, const char *, size_t *);
+NNG_DECL int nng_socket_get_uint64(nng_socket, const char *, uint64_t *);
+NNG_DECL int nng_socket_get_string(nng_socket, const char *, char **);
+NNG_DECL int nng_socket_get_ptr(nng_socket, const char *, void **);
+NNG_DECL int nng_socket_get_ms(nng_socket, const char *, nng_duration *);
+NNG_DECL int nng_socket_get_addr(nng_socket, const char *, nng_sockaddr *);
+
+// Arguably the pipe callback functions could be handled as an option,
+// but with the need to specify an argument, we find it best to unify
+// this as a separate function to pass in the argument and the callback.
+// Only one callback can be set on a given socket, and there is no way
+// to retrieve the old value.
+typedef enum {
+	NNG_PIPE_EV_ADD_PRE,  // Called just before pipe added to socket
+	NNG_PIPE_EV_ADD_POST, // Called just after pipe added to socket
+	NNG_PIPE_EV_REM_POST, // Called just after pipe removed from socket
+	NNG_PIPE_EV_NUM,      // Used internally, must be last.
+} nng_pipe_ev;
+
+typedef void (*nng_pipe_cb)(nng_pipe, nng_pipe_ev, void *);
+
+// nng_pipe_notify registers a callback to be executed when the
+// given event is triggered.  To watch for different events, register
+// multiple times.  Each event can have at most one callback registered.
+NNG_DECL int nng_pipe_notify(nng_socket, nng_pipe_ev, nng_pipe_cb, void *);
+
+// nng_listen creates a listening endpoint with no special options,
+// and starts it listening.  It is functionally equivalent to the legacy
+// nn_bind(). The underlying endpoint is returned back to the caller in the
+// endpoint pointer, if it is not NULL.  The flags are ignored at present.
+NNG_DECL int nng_listen(nng_socket, const char *, nng_listener *, int);
+
+// nng_dial creates a dialing endpoint, with no special options, and
+// starts it dialing.  Dialers have at most one active connection at a time
+// This is similar to the legacy nn_connect().  The underlying endpoint
+// is returned back to the caller in the endpoint pointer, if it is not NULL.
+// The flags may be NNG_FLAG_NONBLOCK to indicate that the first attempt to
+// dial will be made in the background, returning control to the caller
+// immediately.  In this case, if the connection fails, the function will
+// keep retrying in the background.  (If the connection is dropped in either
+// case, it will still be reconnected in the background -- only the initial
+// connection attempt is normally synchronous.)
+NNG_DECL int nng_dial(nng_socket, const char *, nng_dialer *, int);
+
+// nng_dialer_create creates a new dialer, that is not yet started.
+NNG_DECL int nng_dialer_create(nng_dialer *, nng_socket, const char *);
+
+// nng_listener_create creates a new listener, that is not yet started.
+NNG_DECL int nng_listener_create(nng_listener *, nng_socket, const char *);
+
+// nng_dialer_start starts the endpoint dialing.  This is only possible if
+// the dialer is not already dialing.
+NNG_DECL int nng_dialer_start(nng_dialer, int);
+
+// nng_listener_start starts the endpoint listening.  This is only possible if
+// the listener is not already listening.
+NNG_DECL int nng_listener_start(nng_listener, int);
+
+// nng_dialer_close closes the dialer, shutting down all underlying
+// connections and releasing all associated resources.
+NNG_DECL int nng_dialer_close(nng_dialer);
+
+// nng_listener_close closes the listener, shutting down all underlying
+// connections and releasing all associated resources.
+NNG_DECL int nng_listener_close(nng_listener);
+
+// nng_dialer_id returns the positive dialer ID, or -1 if the dialer is
+// invalid.
+NNG_DECL int nng_dialer_id(nng_dialer);
+
+// nng_listener_id returns the positive listener ID, or -1 if the listener is
+// invalid.
+NNG_DECL int nng_listener_id(nng_listener);
+
+NNG_DECL int nng_dialer_set(nng_dialer, const char *, const void *, size_t);
+NNG_DECL int nng_dialer_set_bool(nng_dialer, const char *, bool);
+NNG_DECL int nng_dialer_set_int(nng_dialer, const char *, int);
+NNG_DECL int nng_dialer_set_size(nng_dialer, const char *, size_t);
+NNG_DECL int nng_dialer_set_uint64(nng_dialer, const char *, uint64_t);
+NNG_DECL int nng_dialer_set_string(nng_dialer, const char *, const char *);
+NNG_DECL int nng_dialer_set_ptr(nng_dialer, const char *, void *);
+NNG_DECL int nng_dialer_set_ms(nng_dialer, const char *, nng_duration);
+NNG_DECL int nng_dialer_set_addr(
+    nng_dialer, const char *, const nng_sockaddr *);
+
+NNG_DECL int nng_dialer_get(nng_dialer, const char *, void *, size_t *);
+NNG_DECL int nng_dialer_get_bool(nng_dialer, const char *, bool *);
+NNG_DECL int nng_dialer_get_int(nng_dialer, const char *, int *);
+NNG_DECL int nng_dialer_get_size(nng_dialer, const char *, size_t *);
+NNG_DECL int nng_dialer_get_uint64(nng_dialer, const char *, uint64_t *);
+NNG_DECL int nng_dialer_get_string(nng_dialer, const char *, char **);
+NNG_DECL int nng_dialer_get_ptr(nng_dialer, const char *, void **);
+NNG_DECL int nng_dialer_get_ms(nng_dialer, const char *, nng_duration *);
+NNG_DECL int nng_dialer_get_addr(nng_dialer, const char *, nng_sockaddr *);
+
+NNG_DECL int nng_listener_set(
+    nng_listener, const char *, const void *, size_t);
+NNG_DECL int nng_listener_set_bool(nng_listener, const char *, bool);
+NNG_DECL int nng_listener_set_int(nng_listener, const char *, int);
+NNG_DECL int nng_listener_set_size(nng_listener, const char *, size_t);
+NNG_DECL int nng_listener_set_uint64(nng_listener, const char *, uint64_t);
+NNG_DECL int nng_listener_set_string(nng_listener, const char *, const char *);
+NNG_DECL int nng_listener_set_ptr(nng_listener, const char *, void *);
+NNG_DECL int nng_listener_set_ms(nng_listener, const char *, nng_duration);
+NNG_DECL int nng_listener_set_addr(
+    nng_listener, const char *, const nng_sockaddr *);
+
+NNG_DECL int nng_listener_get(nng_listener, const char *, void *, size_t *);
+NNG_DECL int nng_listener_get_bool(nng_listener, const char *, bool *);
+NNG_DECL int nng_listener_get_int(nng_listener, const char *, int *);
+NNG_DECL int nng_listener_get_size(nng_listener, const char *, size_t *);
+NNG_DECL int nng_listener_get_uint64(nng_listener, const char *, uint64_t *);
+NNG_DECL int nng_listener_get_string(nng_listener, const char *, char **);
+NNG_DECL int nng_listener_get_ptr(nng_listener, const char *, void **);
+NNG_DECL int nng_listener_get_ms(nng_listener, const char *, nng_duration *);
+NNG_DECL int nng_listener_get_addr(nng_listener, const char *, nng_sockaddr *);
+
+// nng_strerror returns a human readable string associated with the error
+// code supplied.
+NNG_DECL const char *nng_strerror(int);
+
+// nng_send sends (or arranges to send) the data on the socket.  Note that
+// this function may (will!) return before any receiver has actually
+// received the data.  The return value will be zero to indicate that the
+// socket has accepted the entire data for send, or an errno to indicate
+// failure.  The flags may include NNG_FLAG_NONBLOCK or NNG_FLAG_ALLOC.
+// If the flag includes NNG_FLAG_ALLOC, then the function will call
+// nng_free() on the supplied pointer & size on success. (If the call
+// fails then the memory is not freed.)
+NNG_DECL int nng_send(nng_socket, void *, size_t, int);
+
+// nng_recv receives message data into the socket, up to the supplied size.
+// The actual size of the message data will be written to the value pointed
+// to by size.  The flags may include NNG_FLAG_NONBLOCK and NNG_FLAG_ALLOC.
+// If NNG_FLAG_ALLOC is supplied then the library will allocate memory for
+// the caller.  In that case the pointer to the allocated will be stored
+// instead of the data itself.  The caller is responsible for freeing the
+// associated memory with nng_free().
+NNG_DECL int nng_recv(nng_socket, void *, size_t *, int);
+
+// nng_sendmsg is like nng_send, but offers up a message structure, which
+// gives the ability to provide more control over the message, including
+// providing backtrace information.  It also can take a message that was
+// obtain via nn_recvmsg, allowing for zero copy forwarding.
+NNG_DECL int nng_sendmsg(nng_socket, nng_msg *, int);
+
+// nng_recvmsg is like nng_recv, but is used to obtain a message structure
+// as well as the data buffer.  This can be used to obtain more information
+// about where the message came from, access raw headers, etc.  It also
+// can be passed off directly to nng_sendmsg.
+NNG_DECL int nng_recvmsg(nng_socket, nng_msg **, int);
+
+// nng_send_aio sends data on the socket asynchronously.  As with nng_send,
+// the completion may be executed before the data has actually been delivered,
+// but only when it is accepted for delivery.  The supplied AIO must have
+// been initialized, and have an associated message.  The message will be
+// "owned" by the socket if the operation completes successfully.  Otherwise
+// the caller is responsible for freeing it.
+NNG_DECL void nng_send_aio(nng_socket, nng_aio *);
+
+// nng_recv_aio receives data on the socket asynchronously.  On a successful
+// result, the AIO will have an associated message, that can be obtained
+// with nng_aio_get_msg().  The caller takes ownership of the message at
+// this point.
+NNG_DECL void nng_recv_aio(nng_socket, nng_aio *);
+
+// Context support.  User contexts are not supported by all protocols,
+// but for those that do, they give a way to create multiple contexts
+// on a single socket, each of which runs the protocol's state machinery
+// independently, offering a way to achieve concurrent protocol support
+// without resorting to raw mode sockets.  See the protocol specific
+// documentation for further details.  (Note that at this time, only
+// asynchronous send/recv are supported for contexts, but its easy enough
+// to make synchronous versions with nng_aio_wait().)  Note that nng_close
+// of the parent socket will *block* as long as any contexts are open.
+
+// nng_ctx_open creates a context.  This returns NNG_ENOTSUP if the
+// protocol implementation does not support separate contexts.
+NNG_DECL int nng_ctx_open(nng_ctx *, nng_socket);
+
+// nng_ctx_close closes the context.
+NNG_DECL int nng_ctx_close(nng_ctx);
+
+// nng_ctx_id returns the numeric id for the context; this will be
+// a positive value for a valid context, or < 0 for an invalid context.
+// A valid context is not necessarily an *open* context.
+NNG_DECL int nng_ctx_id(nng_ctx);
+
+// nng_ctx_recv receives asynchronously.  It works like nng_recv_aio, but
+// uses a local context instead of the socket global context.
+NNG_DECL void nng_ctx_recv(nng_ctx, nng_aio *);
+
+// nng_ctx_recvmsg is allows for receiving a message synchronously using
+// a context.  It has the same semantics as nng_recvmsg, but operates
+// on a context instead of a socket.
+NNG_DECL int nng_ctx_recvmsg(nng_ctx, nng_msg **, int);
+
+// nng_ctx_send sends asynchronously. It works like nng_send_aio, but
+// uses a local context instead of the socket global context.
+NNG_DECL void nng_ctx_send(nng_ctx, nng_aio *);
+
+// nng_ctx_sendmsg is allows for sending a message synchronously using
+// a context.  It has the same semantics as nng_sendmsg, but operates
+// on a context instead of a socket.
+NNG_DECL int nng_ctx_sendmsg(nng_ctx, nng_msg *, int);
+
+NNG_DECL int nng_ctx_get(nng_ctx, const char *, void *, size_t *);
+NNG_DECL int nng_ctx_get_bool(nng_ctx, const char *, bool *);
+NNG_DECL int nng_ctx_get_int(nng_ctx, const char *, int *);
+NNG_DECL int nng_ctx_get_size(nng_ctx, const char *, size_t *);
+NNG_DECL int nng_ctx_get_uint64(nng_ctx, const char *, uint64_t *);
+NNG_DECL int nng_ctx_get_string(nng_ctx, const char *, char **);
+NNG_DECL int nng_ctx_get_ptr(nng_ctx, const char *, void **);
+NNG_DECL int nng_ctx_get_ms(nng_ctx, const char *, nng_duration *);
+NNG_DECL int nng_ctx_get_addr(nng_ctx, const char *, nng_sockaddr *);
+
+NNG_DECL int nng_ctx_set(nng_ctx, const char *, const void *, size_t);
+NNG_DECL int nng_ctx_set_bool(nng_ctx, const char *, bool);
+NNG_DECL int nng_ctx_set_int(nng_ctx, const char *, int);
+NNG_DECL int nng_ctx_set_size(nng_ctx, const char *, size_t);
+NNG_DECL int nng_ctx_set_uint64(nng_ctx, const char *, uint64_t);
+NNG_DECL int nng_ctx_set_string(nng_ctx, const char *, const char *);
+NNG_DECL int nng_ctx_set_ptr(nng_ctx, const char *, void *);
+NNG_DECL int nng_ctx_set_ms(nng_ctx, const char *, nng_duration);
+NNG_DECL int nng_ctx_set_addr(nng_ctx, const char *, const nng_sockaddr *);
+
+// nng_alloc is used to allocate memory.  It's intended purpose is for
+// allocating memory suitable for message buffers with nng_send().
+// Applications that need memory for other purposes should use their platform
+// specific API.
+NNG_DECL void *nng_alloc(size_t);
+
+// nng_free is used to free memory allocated with nng_alloc, which includes
+// memory allocated by nng_recv() when the NNG_FLAG_ALLOC message is supplied.
+// As the application is required to keep track of the size of memory, this
+// is probably less convenient for general uses than the C library malloc and
+// calloc.
+NNG_DECL void nng_free(void *, size_t);
+
+// nng_strdup duplicates the source string, using nng_alloc. The result
+// should be freed with nng_strfree (or nng_free(strlen(s)+1)).
+NNG_DECL char *nng_strdup(const char *);
+
+// nng_strfree is equivalent to nng_free(strlen(s)+1).
+NNG_DECL void nng_strfree(char *);
+
+// Async IO API.  AIO structures can be thought of as "handles" to
+// support asynchronous operations.  They contain the completion callback, and
+// a pointer to consumer data.  This is similar to how overlapped I/O
+// works in Windows, when used with a completion callback.
+//
+// AIO structures can carry up to 4 distinct input values, and up to
+// 4 distinct output values, and up to 4 distinct "private state" values.
+// The meaning of the inputs and the outputs are determined by the
+// I/O functions being called.
+
+// nng_aio_alloc allocates a new AIO, and associated the completion
+// callback and its opaque argument.  If NULL is supplied for the
+// callback, then the caller must use nng_aio_wait() to wait for the
+// operation to complete.  If the completion callback is not NULL, then
+// when a submitted operation completes (or is canceled or fails) the
+// callback will be executed, generally in a different thread, with no
+// locks held.
+NNG_DECL int nng_aio_alloc(nng_aio **, void (*)(void *), void *);
+
+// nng_aio_free frees the AIO and any associated resources.
+// It *must not* be in use at the time it is freed.
+NNG_DECL void nng_aio_free(nng_aio *);
+
+// nng_aio_reap is like nng_aio_free, but calls it from a background
+// reaper thread.  This can be useful to free aio objects from aio
+// callbacks (e.g. when the result of the callback is to discard
+// the object in question.)  The aio object must be in further use
+// when this is called.
+NNG_DECL void nng_aio_reap(nng_aio *);
+
+// nng_aio_stop stops any outstanding operation, and waits for the
+// AIO to be free, including for the callback to have completed
+// execution.  Therefore the caller must NOT hold any locks that
+// are acquired in the callback, or deadlock will occur.
+NNG_DECL void nng_aio_stop(nng_aio *);
+
+// nng_aio_result returns the status/result of the operation. This
+// will be zero on successful completion, or an nng error code on
+// failure.
+NNG_DECL int nng_aio_result(nng_aio *);
+
+// nng_aio_count returns the number of bytes transferred for certain
+// I/O operations.  This is meaningless for other operations (e.g.
+// DNS lookups or TCP connection setup).
+NNG_DECL size_t nng_aio_count(nng_aio *);
+
+// nng_aio_cancel attempts to cancel any in-progress I/O operation.
+// The AIO callback will still be executed, but if the cancellation is
+// successful then the status will be NNG_ECANCELED.
+NNG_DECL void nng_aio_cancel(nng_aio *);
+
+// nng_aio_abort is like nng_aio_cancel, but allows for a different
+// error result to be returned.
+NNG_DECL void nng_aio_abort(nng_aio *, int);
+
+// nng_aio_wait waits synchronously for any pending operation to complete.
+// It also waits for the callback to have completed execution.  Therefore,
+// the caller of this function must not hold any locks acquired by the
+// callback or deadlock may occur.
+NNG_DECL void nng_aio_wait(nng_aio *);
+
+// nng_aio_busy returns true if the aio is still busy processing the
+// operation, or executing associated completion functions.  Note that
+// if the completion function schedules a new operation using the aio,
+// then this function will continue to return true.
+NNG_DECL bool nng_aio_busy(nng_aio *);
+
+// nng_aio_set_msg sets the message structure to use for asynchronous
+// message send operations.
+NNG_DECL void nng_aio_set_msg(nng_aio *, nng_msg *);
+
+// nng_aio_get_msg returns the message structure associated with a completed
+// receive operation.
+NNG_DECL nng_msg *nng_aio_get_msg(nng_aio *);
+
+// nng_aio_set_input sets an input parameter at the given index.
+NNG_DECL int nng_aio_set_input(nng_aio *, unsigned, void *);
+
+// nng_aio_get_input retrieves the input parameter at the given index.
+NNG_DECL void *nng_aio_get_input(nng_aio *, unsigned);
+
+// nng_aio_set_output sets an output result at the given index.
+NNG_DECL int nng_aio_set_output(nng_aio *, unsigned, void *);
+
+// nng_aio_get_output retrieves the output result at the given index.
+NNG_DECL void *nng_aio_get_output(nng_aio *, unsigned);
+
+// nng_aio_set_timeout sets a timeout on the AIO.  This should be called for
+// operations that should time out after a period.  The timeout should be
+// either a positive number of milliseconds, or NNG_DURATION_INFINITE to
+// indicate that the operation has no timeout.  A poll may be done by
+// specifying NNG_DURATION_ZERO.  The value NNG_DURATION_DEFAULT indicates
+// that any socket specific timeout should be used.
+NNG_DECL void nng_aio_set_timeout(nng_aio *, nng_duration);
+
+// nng_aio_set_iov sets a scatter/gather vector on the aio.  The iov array
+// itself is copied. Data members (the memory regions referenced) *may* be
+// copied as well, depending on the operation.  This operation is guaranteed
+// to succeed if n <= 4, otherwise it may fail due to NNG_ENOMEM.
+NNG_DECL int nng_aio_set_iov(nng_aio *, unsigned, const nng_iov *);
+
+// nng_aio_begin is called by the provider to mark the operation as
+// beginning.  If it returns false, then the provider must take no
+// further action on the aio.
+NNG_DECL bool nng_aio_begin(nng_aio *);
+
+// nng_aio_finish is used to "finish" an asynchronous operation.
+// It should only be called by "providers" (such as HTTP server API users).
+// The argument is the value that nng_aio_result() should return.
+// IMPORTANT: Callers must ensure that this is called EXACTLY ONCE on any
+// given aio.
+NNG_DECL void nng_aio_finish(nng_aio *, int);
+
+// nng_aio_defer is used to register a cancellation routine, and indicate
+// that the operation will be completed asynchronously.  It must only be
+// called once per operation on an aio, and must only be called by providers.
+// If the operation is canceled by the consumer, the cancellation callback
+// will be called.  The provider *must* still ensure that the nng_aio_finish()
+// function is called EXACTLY ONCE.  If the operation cannot be canceled
+// for any reason, the cancellation callback should do nothing.  The
+// final argument is passed to the cancelfn.  The final argument of the
+// cancellation function is the error number (will not be zero) corresponding
+// to the reason for cancellation, e.g. NNG_ETIMEDOUT or NNG_ECANCELED.
+typedef void (*nng_aio_cancelfn)(nng_aio *, void *, int);
+NNG_DECL void nng_aio_defer(nng_aio *, nng_aio_cancelfn, void *);
+
+// nng_aio_sleep does a "sleeping" operation, basically does nothing
+// but wait for the specified number of milliseconds to expire, then
+// calls the callback.  This returns 0, rather than NNG_ETIMEDOUT.
+NNG_DECL void nng_sleep_aio(nng_duration, nng_aio *);
+
+// Message API.
+NNG_DECL int      nng_msg_alloc(nng_msg **, size_t);
+NNG_DECL void     nng_msg_free(nng_msg *);
+NNG_DECL int      nng_msg_realloc(nng_msg *, size_t);
+NNG_DECL int      nng_msg_reserve(nng_msg *, size_t);
+NNG_DECL size_t   nng_msg_capacity(nng_msg *);
+NNG_DECL void *   nng_msg_header(nng_msg *);
+NNG_DECL size_t   nng_msg_header_len(const nng_msg *);
+NNG_DECL void *   nng_msg_body(nng_msg *);
+NNG_DECL size_t   nng_msg_len(const nng_msg *);
+NNG_DECL int      nng_msg_append(nng_msg *, const void *, size_t);
+NNG_DECL int      nng_msg_insert(nng_msg *, const void *, size_t);
+NNG_DECL int      nng_msg_trim(nng_msg *, size_t);
+NNG_DECL int      nng_msg_chop(nng_msg *, size_t);
+NNG_DECL int      nng_msg_header_append(nng_msg *, const void *, size_t);
+NNG_DECL int      nng_msg_header_insert(nng_msg *, const void *, size_t);
+NNG_DECL int      nng_msg_header_trim(nng_msg *, size_t);
+NNG_DECL int      nng_msg_header_chop(nng_msg *, size_t);
+NNG_DECL int      nng_msg_header_append_u16(nng_msg *, uint16_t);
+NNG_DECL int      nng_msg_header_append_u32(nng_msg *, uint32_t);
+NNG_DECL int      nng_msg_header_append_u64(nng_msg *, uint64_t);
+NNG_DECL int      nng_msg_header_insert_u16(nng_msg *, uint16_t);
+NNG_DECL int      nng_msg_header_insert_u32(nng_msg *, uint32_t);
+NNG_DECL int      nng_msg_header_insert_u64(nng_msg *, uint64_t);
+NNG_DECL int      nng_msg_header_chop_u16(nng_msg *, uint16_t *);
+NNG_DECL int      nng_msg_header_chop_u32(nng_msg *, uint32_t *);
+NNG_DECL int      nng_msg_header_chop_u64(nng_msg *, uint64_t *);
+NNG_DECL int      nng_msg_header_trim_u16(nng_msg *, uint16_t *);
+NNG_DECL int      nng_msg_header_trim_u32(nng_msg *, uint32_t *);
+NNG_DECL int      nng_msg_header_trim_u64(nng_msg *, uint64_t *);
+NNG_DECL int      nng_msg_append_u16(nng_msg *, uint16_t);
+NNG_DECL int      nng_msg_append_u32(nng_msg *, uint32_t);
+NNG_DECL int      nng_msg_append_u64(nng_msg *, uint64_t);
+NNG_DECL int      nng_msg_insert_u16(nng_msg *, uint16_t);
+NNG_DECL int      nng_msg_insert_u32(nng_msg *, uint32_t);
+NNG_DECL int      nng_msg_insert_u64(nng_msg *, uint64_t);
+NNG_DECL int      nng_msg_chop_u16(nng_msg *, uint16_t *);
+NNG_DECL int      nng_msg_chop_u32(nng_msg *, uint32_t *);
+NNG_DECL int      nng_msg_chop_u64(nng_msg *, uint64_t *);
+NNG_DECL int      nng_msg_trim_u16(nng_msg *, uint16_t *);
+NNG_DECL int      nng_msg_trim_u32(nng_msg *, uint32_t *);
+NNG_DECL int      nng_msg_trim_u64(nng_msg *, uint64_t *);
+NNG_DECL int      nng_msg_dup(nng_msg **, const nng_msg *);
+NNG_DECL void     nng_msg_clear(nng_msg *);
+NNG_DECL void     nng_msg_header_clear(nng_msg *);
+NNG_DECL void     nng_msg_set_pipe(nng_msg *, nng_pipe);
+NNG_DECL nng_pipe nng_msg_get_pipe(const nng_msg *);
+
+// Pipe API. Generally pipes are only "observable" to applications, but
+// we do permit an application to close a pipe. This can be useful, for
+// example during a connection notification, to disconnect a pipe that
+// is associated with an invalid or untrusted remote peer.
+NNG_DECL int nng_pipe_get(nng_pipe, const char *, void *, size_t *);
+NNG_DECL int nng_pipe_get_bool(nng_pipe, const char *, bool *);
+NNG_DECL int nng_pipe_get_int(nng_pipe, const char *, int *);
+NNG_DECL int nng_pipe_get_ms(nng_pipe, const char *, nng_duration *);
+NNG_DECL int nng_pipe_get_size(nng_pipe, const char *, size_t *);
+NNG_DECL int nng_pipe_get_uint64(nng_pipe, const char *, uint64_t *);
+NNG_DECL int nng_pipe_get_string(nng_pipe, const char *, char **);
+NNG_DECL int nng_pipe_get_ptr(nng_pipe, const char *, void **);
+NNG_DECL int nng_pipe_get_addr(nng_pipe, const char *, nng_sockaddr *);
+
+NNG_DECL int          nng_pipe_close(nng_pipe);
+NNG_DECL int          nng_pipe_id(nng_pipe);
+NNG_DECL nng_socket   nng_pipe_socket(nng_pipe);
+NNG_DECL nng_dialer   nng_pipe_dialer(nng_pipe);
+NNG_DECL nng_listener nng_pipe_listener(nng_pipe);
+
+// Flags.
+#define NNG_FLAG_ALLOC 1u // Recv to allocate receive buffer
+#define NNG_FLAG_NONBLOCK 2u // Non-blocking operations
+
+// Options.
+#define NNG_OPT_SOCKNAME "socket-name"
+#define NNG_OPT_RAW "raw"
+#define NNG_OPT_PROTO "protocol"
+#define NNG_OPT_PROTONAME "protocol-name"
+#define NNG_OPT_PEER "peer"
+#define NNG_OPT_PEERNAME "peer-name"
+#define NNG_OPT_RECVBUF "recv-buffer"
+#define NNG_OPT_SENDBUF "send-buffer"
+#define NNG_OPT_RECVFD "recv-fd"
+#define NNG_OPT_SENDFD "send-fd"
+#define NNG_OPT_RECVTIMEO "recv-timeout"
+#define NNG_OPT_SENDTIMEO "send-timeout"
+#define NNG_OPT_LOCADDR "local-address"
+#define NNG_OPT_REMADDR "remote-address"
+#define NNG_OPT_URL "url"
+#define NNG_OPT_MAXTTL "ttl-max"
+#define NNG_OPT_RECVMAXSZ "recv-size-max"
+#define NNG_OPT_RECONNMINT "reconnect-time-min"
+#define NNG_OPT_RECONNMAXT "reconnect-time-max"
+
+// TLS options are only used when the underlying transport supports TLS.
+
+// NNG_OPT_TLS_CONFIG is a pointer to an nng_tls_config object.  Generally
+// this can used with endpoints, although once an endpoint is started, or
+// once a configuration is used, the value becomes read-only. Note that
+// when configuring the object, a hold is placed on the TLS configuration,
+// using a reference count.  When retrieving the object, no such hold is
+// placed, and so the caller must take care not to use the associated object
+// after the endpoint it is associated with is closed.
+#define NNG_OPT_TLS_CONFIG "tls-config"
+
+// NNG_OPT_TLS_AUTH_MODE is a write-only integer (int) option that specifies
+// whether peer authentication is needed.  The option can take one of the
+// values of NNG_TLS_AUTH_MODE_NONE, NNG_TLS_AUTH_MODE_OPTIONAL, or
+// NNG_TLS_AUTH_MODE_REQUIRED.  The default is typically NNG_TLS_AUTH_MODE_NONE
+// for listeners, and NNG_TLS_AUTH_MODE_REQUIRED for dialers. If set to
+// REQUIRED, then connections will be rejected if the peer cannot be verified.
+// If set to OPTIONAL, then a verification step takes place, but the connection
+// is still permitted.  (The result can be checked with NNG_OPT_TLS_VERIFIED).
+#define NNG_OPT_TLS_AUTH_MODE "tls-authmode"
+
+// NNG_OPT_TLS_CERT_KEY_FILE names a single file that contains a certificate
+// and key identifying the endpoint.  This is a write-only value.  This can be
+// set multiple times for times for different keys/certs corresponding to
+// different algorithms on listeners, whereas dialers only support one.  The
+// file must contain both cert and key as PEM blocks, and the key must
+// not be encrypted.  (If more flexibility is needed, use the TLS configuration
+// directly, via NNG_OPT_TLS_CONFIG.)
+#define NNG_OPT_TLS_CERT_KEY_FILE "tls-cert-key-file"
+
+// NNG_OPT_TLS_CA_FILE names a single file that contains certificate(s) for a
+// CA, and optionally CRLs, which are used to validate the peer's certificate.
+// This is a write-only value, but multiple CAs can be loaded by setting this
+// multiple times.
+#define NNG_OPT_TLS_CA_FILE "tls-ca-file"
+
+// NNG_OPT_TLS_SERVER_NAME is a write-only string that can typically be
+// set on dialers to check the CN of the server for a match.  This
+// can also affect SNI (server name indication).  It usually has no effect
+// on listeners.
+#define NNG_OPT_TLS_SERVER_NAME "tls-server-name"
+
+// NNG_OPT_TLS_VERIFIED returns a boolean indicating whether the peer has
+// been verified (true) or not (false). Typically this is read-only, and
+// only available for pipes. This option may return incorrect results if
+// peer authentication is disabled with `NNG_TLS_AUTH_MODE_NONE`.
+#define NNG_OPT_TLS_VERIFIED "tls-verified"
+
+// NNG_OPT_TLS_PEER_CN returns the string with the common name
+// of the peer certificate. Typically this is read-only and
+// only available for pipes. This option may return incorrect results if
+// peer authentication is disabled with `NNG_TLS_AUTH_MODE_NONE`.
+#define NNG_OPT_TLS_PEER_CN "tls-peer-cn"
+
+// NNG_OPT_TLS_PEER_ALT_NAMES returns string list with the
+// subject alternative names of the peer certificate. Typically this is
+// read-only and only available for pipes. This option may return
+// incorrect results if peer authentication is disabled with
+// `NNG_TLS_AUTH_MODE_NONE`.
+#define NNG_OPT_TLS_PEER_ALT_NAMES "tls-peer-alt-names"
+
+// TCP options.  These may be supported on various transports that use
+// TCP underneath such as TLS, or not.
+
+// TCP nodelay disables the use of Nagle, so that messages are sent
+// as soon as data is available. This tends to reduce latency, but
+// can come at the cost of extra messages being sent, and may have
+// a detrimental effect on performance. For most uses, we recommend
+// enabling this. (Disable it if you are on a very slow network.)
+// This is a boolean.
+#define NNG_OPT_TCP_NODELAY "tcp-nodelay"
+
+// TCP keepalive causes the underlying transport to send keep-alive
+// messages, and keep the session active. Keepalives are zero length
+// messages with the ACK flag turned on. If we don't get an ACK back,
+// then we know the other side is gone. This is useful for detecting
+// dead peers, and is also used to prevent disconnections caused by
+// middle boxes thinking the session has gone idle (e.g. keeping NAT
+// state current). This is a boolean.
+#define NNG_OPT_TCP_KEEPALIVE "tcp-keepalive"
+
+// Local TCP port number.  This is used on a listener, and is intended
+// to be used after starting the listener in combination with a wildcard
+// (0) local port.  This determines the actual ephemeral port that was
+// selected and bound.  The value is provided as an int, but only the
+// low order 16 bits will be set.  This is provided in native byte order,
+// which makes it more convenient than using the NNG_OPT_LOCADDR option.
+#define NNG_OPT_TCP_BOUND_PORT "tcp-bound-port"
+
+// IPC options.  These will largely vary depending on the platform,
+// as POSIX systems have very different options than Windows.
+
+// Security Descriptor.  This option may only be set on listeners
+// on the Windows platform, where the object is a pointer to a
+// a Windows SECURITY_DESCRIPTOR.
+#define NNG_OPT_IPC_SECURITY_DESCRIPTOR "ipc:security-descriptor"
+
+// Permissions bits.  This option is only valid for listeners on
+// POSIX platforms and others that honor UNIX style permission bits.
+// Note that some platforms may not honor the permissions here, although
+// at least Linux and macOS seem to do so.  Check before you rely on
+// this for security.
+#define NNG_OPT_IPC_PERMISSIONS "ipc:permissions"
+
+// Peer UID.  This is only available on POSIX style systems.
+#define NNG_OPT_IPC_PEER_UID "ipc:peer-uid"
+
+// Peer GID (primary group).  This is only available on POSIX style systems.
+#define NNG_OPT_IPC_PEER_GID "ipc:peer-gid"
+
+// Peer process ID.  Available on Windows, Linux, and SunOS.
+// In theory we could obtain this with the first message sent,
+// but we have elected not to do this for now. (Nice RFE for a FreeBSD
+// guru though.)
+#define NNG_OPT_IPC_PEER_PID "ipc:peer-pid"
+
+// Peer Zone ID.  Only on SunOS systems.  (Linux containers have no
+// definable kernel identity; they are a user-land fabrication made up
+// from various pieces of different namespaces. FreeBSD does have
+// something called JailIDs, but it isn't obvious how to determine this,
+// or even if processes can use IPC across jail boundaries.)
+#define NNG_OPT_IPC_PEER_ZONEID "ipc:peer-zoneid"
+
+// WebSocket Options.
+
+// NNG_OPT_WS_REQUEST_HEADERS is a string containing the
+// request headers, formatted as CRLF terminated lines.
+#define NNG_OPT_WS_REQUEST_HEADERS "ws:request-headers"
+
+// NNG_OPT_WS_RESPONSE_HEADERS is a string containing the
+// response headers, formatted as CRLF terminated lines.
+#define NNG_OPT_WS_RESPONSE_HEADERS "ws:response-headers"
+
+// NNG_OPT_WS_REQUEST_HEADER is a prefix, for a dynamic
+// property name.  This allows direct access to any named header.
+// Concatenate this with the name of the property (case is not sensitive).
+// Only the first such header is returned.
+#define NNG_OPT_WS_RESPONSE_HEADER "ws:response-header:"
+
+// NNG_OPT_WS_RESPONSE_HEADER is like NNG_OPT_REQUEST_HEADER, but used for
+// accessing the request headers.
+#define NNG_OPT_WS_REQUEST_HEADER "ws:request-header:"
+
+// NNG_OPT_WS_REQUEST_URI is used to obtain the URI sent by the client.
+// This can be useful when a handler supports an entire directory tree.
+#define NNG_OPT_WS_REQUEST_URI "ws:request-uri"
+
+// NNG_OPT_WS_SENDMAXFRAME is used to configure the fragmentation size
+// used for frames.  This has a default value of 64k.  Large values
+// are good for throughput, but penalize latency.  They also require
+// additional buffering on the peer.  This value must not be larger
+// than what the peer will accept, and unfortunately there is no way
+// to negotiate this.
+#define NNG_OPT_WS_SENDMAXFRAME "ws:txframe-max"
+
+// NNG_OPT_WS_RECVMAXFRAME is the largest frame we will accept.  This should
+// probably not be larger than NNG_OPT_RECVMAXSZ. If the sender attempts
+// to send more data than this in a single message, it will be dropped.
+#define NNG_OPT_WS_RECVMAXFRAME "ws:rxframe-max"
+
+// NNG_OPT_WS_PROTOCOL is the "websocket sub-protocol" -- it's a string.
+// This is also known as the Sec-WebSocket-Protocol header. It is treated
+// specially.  This is part of the websocket handshake.
+#define NNG_OPT_WS_PROTOCOL "ws:protocol"
+
+// NNG_OPT_WS_SEND_TEXT is a boolean used to tell the WS stream
+// transport to send text messages.  This is not supported for the
+// core WebSocket transport, but when using streams it might be useful
+// to speak with 3rd party WebSocket applications.  This mode should
+// not be used unless absolutely required. No validation of the message
+// contents is performed by NNG; applications are expected to honor
+// the requirement to send only valid UTF-8.  (Compliant applications
+// will close the socket if they see this message type with invalid UTF-8.)
+#define NNG_OPT_WS_SEND_TEXT "ws:send-text"
+
+// NNG_OPT_WS_RECV_TEXT is a boolean that enables NNG to receive
+// TEXT frames.  This is only useful for stream mode applications --
+// SP protocol requires the use of binary frames.  Note also that
+// NNG does not validate the message contents for valid UTF-8; this
+// means it will not be conformant with RFC-6455 on it's own. Applications
+// that need this should check the message contents themselves, and
+// close the connection if invalid UTF-8 is received.  This option
+// should not be used unless required to communication with 3rd party
+// peers that cannot be coerced into sending binary frames.
+#define NNG_OPT_WS_RECV_TEXT "ws:recv-text"
+
+// XXX: TBD: priorities, ipv4only
+
+// Statistics. These are for informational purposes only, and subject
+// to change without notice. The API for accessing these is stable,
+// but the individual statistic names, values, and meanings are all
+// subject to change.
+
+// nng_stats_get takes a snapshot of the entire set of statistics.
+// While the operation can be somewhat expensive (allocations), it
+// is done in a way that minimizes impact to running operations.
+// Note that the statistics are provided as a tree, with parents
+// used for grouping, and with child statistics underneath.  The
+// top stat returned will be of type NNG_STAT_SCOPE with name "".
+// Applications may choose to consider this root scope as "root", if
+// the empty string is not suitable.
+NNG_DECL int nng_stats_get(nng_stat **);
+
+// nng_stats_free frees a previous list of snapshots.  This should only
+// be called on the parent statistic that obtained via nng_stats_get.
+NNG_DECL void nng_stats_free(nng_stat *);
+
+// nng_stats_dump is a debugging function that dumps the entire set of
+// statistics to stdout.
+NNG_DECL void nng_stats_dump(nng_stat *);
+
+// nng_stat_next finds the next sibling for the current stat.  If there
+// are no more siblings, it returns NULL.
+NNG_DECL nng_stat *nng_stat_next(nng_stat *);
+
+// nng_stat_child finds the first child of the current stat.  If no children
+// exist, then NULL is returned.
+NNG_DECL nng_stat *nng_stat_child(nng_stat *);
+
+// nng_stat_name is used to determine the name of the statistic.
+// This is a human readable name.  Statistic names, as well as the presence
+// or absence or semantic of any particular statistic are not part of any
+// stable API, and may be changed without notice in future updates.
+NNG_DECL const char *nng_stat_name(nng_stat *);
+
+// nng_stat_type is used to determine the type of the statistic.
+// Counters generally increment, and therefore changes in the value over
+// time are likely more interesting than the actual level.  Level
+// values reflect some absolute state however, and should be presented to the
+// user as is.
+NNG_DECL int nng_stat_type(nng_stat *);
+
+// nng_stat_find is used to find a specific named statistic within
+// a statistic tree.  NULL is returned if no such statistic exists.
+NNG_DECL nng_stat *nng_stat_find(nng_stat *, const char *);
+
+// nng_stat_find_socket is used to find the stats for the given socket.
+NNG_DECL nng_stat *nng_stat_find_socket(nng_stat *, nng_socket);
+
+// nng_stat_find_dialer is used to find the stats for the given dialer.
+NNG_DECL nng_stat *nng_stat_find_dialer(nng_stat *, nng_dialer);
+
+// nng_stat_find_listener is used to find the stats for the given listener.
+NNG_DECL nng_stat *nng_stat_find_listener(nng_stat *, nng_listener);
+
+enum nng_stat_type_enum {
+	NNG_STAT_SCOPE   = 0, // Stat is for scoping, and carries no value
+	NNG_STAT_LEVEL   = 1, // Numeric "absolute" value, diffs meaningless
+	NNG_STAT_COUNTER = 2, // Incrementing value (diffs are meaningful)
+	NNG_STAT_STRING  = 3, // Value is a string
+	NNG_STAT_BOOLEAN = 4, // Value is a boolean
+	NNG_STAT_ID      = 5, // Value is a numeric ID
+};
+
+// nng_stat_unit provides information about the unit for the statistic,
+// such as NNG_UNIT_BYTES or NNG_UNIT_BYTES.  If no specific unit is
+// applicable, such as a relative priority, then NN_UNIT_NONE is returned.
+NNG_DECL int nng_stat_unit(nng_stat *);
+
+enum nng_unit_enum {
+	NNG_UNIT_NONE     = 0, // No special units
+	NNG_UNIT_BYTES    = 1, // Bytes, e.g. bytes sent, etc.
+	NNG_UNIT_MESSAGES = 2, // Messages, one per message
+	NNG_UNIT_MILLIS   = 3, // Milliseconds
+	NNG_UNIT_EVENTS   = 4  // Some other type of event
+};
+
+// nng_stat_value returns returns the actual value of the statistic.
+// Statistic values reflect their value at the time that the corresponding
+// snapshot was updated, and are undefined until an update is performed.
+NNG_DECL uint64_t nng_stat_value(nng_stat *);
+
+// nng_stat_value returns returns the actual value of the statistic.
+// Statistic values reflect their value at the time that the corresponding
+// snapshot was updated, and are undefined until an update is performed.
+NNG_DECL bool nng_stat_bool(nng_stat *);
+
+// nng_stat_string returns the string associated with a string statistic,
+// or NULL if the statistic is not part of the string.  The value returned
+// is valid until the associated statistic is freed.
+NNG_DECL const char *nng_stat_string(nng_stat *);
+
+// nng_stat_desc returns a human readable description of the statistic.
+// This may be useful for display in diagnostic interfaces, etc.
+NNG_DECL const char *nng_stat_desc(nng_stat *);
+
+// nng_stat_timestamp returns a timestamp (milliseconds) when the statistic
+// was captured.  The base offset is the same as used by nng_clock().
+// We don't use nng_time though, because that's in the supplemental header.
+NNG_DECL uint64_t nng_stat_timestamp(nng_stat *);
+
+// Device functionality.  This connects two sockets together in a device,
+// which means that messages from one side are forwarded to the other.
+// This version is synchronous, which means the caller will block until
+// one of the sockets is closed. Note that caller is responsible for
+// finally closing both sockets when this function returns.
+NNG_DECL int nng_device(nng_socket, nng_socket);
+
+// Asynchronous form of nng_device.  When this succeeds, the device is
+// left intact and functioning in the background, until one of the sockets
+// is closed or the application exits.  The sockets may be shut down if
+// the device fails, but the caller is responsible for ultimately closing
+// the sockets properly after the device is torn down.
+NNG_DECL void nng_device_aio(nng_aio *, nng_socket, nng_socket);
+
+// Symbol name and visibility.  TBD.  The only symbols that really should
+// be directly exported to runtimes IMO are the option symbols.  And frankly
+// they have enough special logic around them that it might be best not to
+// automate the promotion of them to other APIs.  This is an area open
+// for discussion.
+
+// Error codes.  These generally have different values from UNIX errnos,
+// so take care about converting them.  The one exception is that 0 is
+// unambiguously "success".
+//
+// NNG_SYSERR is a special code, which allows us to wrap errors from the
+// underlying operating system.  We generally prefer to map errors to one
+// of the above, but if we cannot, then we just encode an error this way.
+// The bit is large enough to accommodate all known UNIX and Win32 error
+// codes.  We try hard to match things semantically to one of our standard
+// errors.  For example, a connection reset or aborted we treat as a
+// closed connection, because that's basically what it means.  (The remote
+// peer closed the connection.)  For certain kinds of resource exhaustion
+// we treat it the same as memory.  But for files, etc. that's OS-specific,
+// and we use the generic below.  Some of the above error codes we use
+// internally, and the application should never see (e.g. NNG_EINTR).
+//
+// NNG_ETRANERR is like ESYSERR, but is used to wrap transport specific
+// errors, from different transports.  It should only be used when none
+// of the other options are available.
+
+enum nng_errno_enum {
+	NNG_EINTR        = 1,
+	NNG_ENOMEM       = 2,
+	NNG_EINVAL       = 3,
+	NNG_EBUSY        = 4,
+	NNG_ETIMEDOUT    = 5,
+	NNG_ECONNREFUSED = 6,
+	NNG_ECLOSED      = 7,
+	NNG_EAGAIN       = 8,
+	NNG_ENOTSUP      = 9,
+	NNG_EADDRINUSE   = 10,
+	NNG_ESTATE       = 11,
+	NNG_ENOENT       = 12,
+	NNG_EPROTO       = 13,
+	NNG_EUNREACHABLE = 14,
+	NNG_EADDRINVAL   = 15,
+	NNG_EPERM        = 16,
+	NNG_EMSGSIZE     = 17,
+	NNG_ECONNABORTED = 18,
+	NNG_ECONNRESET   = 19,
+	NNG_ECANCELED    = 20,
+	NNG_ENOFILES     = 21,
+	NNG_ENOSPC       = 22,
+	NNG_EEXIST       = 23,
+	NNG_EREADONLY    = 24,
+	NNG_EWRITEONLY   = 25,
+	NNG_ECRYPTO      = 26,
+	NNG_EPEERAUTH    = 27,
+	NNG_ENOARG       = 28,
+	NNG_EAMBIGUOUS   = 29,
+	NNG_EBADTYPE     = 30,
+	NNG_ECONNSHUT    = 31,
+	NNG_EINTERNAL    = 1000,
+	NNG_ESYSERR      = 0x10000000,
+	NNG_ETRANERR     = 0x20000000
+};
+
+// URL support.  We frequently want to process a URL, and these methods
+// give us a convenient way of doing so.
+
+typedef struct nng_url {
+	char *u_rawurl;   // never NULL
+	char *u_scheme;   // never NULL
+	char *u_userinfo; // will be NULL if not specified
+	char *u_host;     // including colon and port
+	char *u_hostname; // name only, will be "" if not specified
+	char *u_port;     // port, will be "" if not specified
+	char *u_path;     // path, will be "" if not specified
+	char *u_query;    // without '?', will be NULL if not specified
+	char *u_fragment; // without '#', will be NULL if not specified
+	char *u_requri;   // includes query and fragment, "" if not specified
+} nng_url;
+
+// nng_url_parse parses a URL string into a structured form.
+// Note that the u_port member will be filled out with a numeric
+// port if one isn't specified and a default port is appropriate for
+// the scheme.  The URL structure is allocated, along with individual
+// members.  It can be freed with nng_url_free.
+NNG_DECL int nng_url_parse(nng_url **, const char *);
+
+// nng_url_free frees a URL structure that was created by nng_url_parse().
+NNG_DECL void nng_url_free(nng_url *);
+
+// nng_url_clone clones a URL structure.
+NNG_DECL int nng_url_clone(nng_url **, const nng_url *);
+
+// nng_version returns the library version as a human readable string.
+NNG_DECL const char *nng_version(void);
+
+// nng_stream operations permit direct access to low level streams,
+// which can have a variety of uses.  Internally most of the transports
+// are built on top of these.  Streams are created by other dialers or
+// listeners.  The API for creating dialers and listeners varies.
+
+typedef struct nng_stream          nng_stream;
+typedef struct nng_stream_dialer   nng_stream_dialer;
+typedef struct nng_stream_listener nng_stream_listener;
+
+NNG_DECL void nng_stream_free(nng_stream *);
+NNG_DECL void nng_stream_close(nng_stream *);
+NNG_DECL void nng_stream_send(nng_stream *, nng_aio *);
+NNG_DECL void nng_stream_recv(nng_stream *, nng_aio *);
+NNG_DECL int  nng_stream_get(nng_stream *, const char *, void *, size_t *);
+NNG_DECL int  nng_stream_get_bool(nng_stream *, const char *, bool *);
+NNG_DECL int  nng_stream_get_int(nng_stream *, const char *, int *);
+NNG_DECL int  nng_stream_get_ms(nng_stream *, const char *, nng_duration *);
+NNG_DECL int  nng_stream_get_size(nng_stream *, const char *, size_t *);
+NNG_DECL int  nng_stream_get_uint64(nng_stream *, const char *, uint64_t *);
+NNG_DECL int  nng_stream_get_string(nng_stream *, const char *, char **);
+NNG_DECL int  nng_stream_get_ptr(nng_stream *, const char *, void **);
+NNG_DECL int  nng_stream_get_addr(nng_stream *, const char *, nng_sockaddr *);
+NNG_DECL int  nng_stream_set(nng_stream *, const char *, const void *, size_t);
+NNG_DECL int  nng_stream_set_bool(nng_stream *, const char *, bool);
+NNG_DECL int  nng_stream_set_int(nng_stream *, const char *, int);
+NNG_DECL int  nng_stream_set_ms(nng_stream *, const char *, nng_duration);
+NNG_DECL int  nng_stream_set_size(nng_stream *, const char *, size_t);
+NNG_DECL int  nng_stream_set_uint64(nng_stream *, const char *, uint64_t);
+NNG_DECL int  nng_stream_set_string(nng_stream *, const char *, const char *);
+NNG_DECL int  nng_stream_set_ptr(nng_stream *, const char *, void *);
+NNG_DECL int  nng_stream_set_addr(
+     nng_stream *, const char *, const nng_sockaddr *);
+
+NNG_DECL int nng_stream_dialer_alloc(nng_stream_dialer **, const char *);
+NNG_DECL int nng_stream_dialer_alloc_url(
+    nng_stream_dialer **, const nng_url *);
+NNG_DECL void nng_stream_dialer_free(nng_stream_dialer *);
+NNG_DECL void nng_stream_dialer_close(nng_stream_dialer *);
+NNG_DECL void nng_stream_dialer_dial(nng_stream_dialer *, nng_aio *);
+NNG_DECL int  nng_stream_dialer_set(
+     nng_stream_dialer *, const char *, const void *, size_t);
+NNG_DECL int nng_stream_dialer_get(
+    nng_stream_dialer *, const char *, void *, size_t *);
+NNG_DECL int nng_stream_dialer_get_bool(
+    nng_stream_dialer *, const char *, bool *);
+NNG_DECL int nng_stream_dialer_get_int(
+    nng_stream_dialer *, const char *, int *);
+NNG_DECL int nng_stream_dialer_get_ms(
+    nng_stream_dialer *, const char *, nng_duration *);
+NNG_DECL int nng_stream_dialer_get_size(
+    nng_stream_dialer *, const char *, size_t *);
+NNG_DECL int nng_stream_dialer_get_uint64(
+    nng_stream_dialer *, const char *, uint64_t *);
+NNG_DECL int nng_stream_dialer_get_string(
+    nng_stream_dialer *, const char *, char **);
+NNG_DECL int nng_stream_dialer_get_ptr(
+    nng_stream_dialer *, const char *, void **);
+NNG_DECL int nng_stream_dialer_get_addr(
+    nng_stream_dialer *, const char *, nng_sockaddr *);
+NNG_DECL int nng_stream_dialer_set_bool(
+    nng_stream_dialer *, const char *, bool);
+NNG_DECL int nng_stream_dialer_set_int(nng_stream_dialer *, const char *, int);
+NNG_DECL int nng_stream_dialer_set_ms(
+    nng_stream_dialer *, const char *, nng_duration);
+NNG_DECL int nng_stream_dialer_set_size(
+    nng_stream_dialer *, const char *, size_t);
+NNG_DECL int nng_stream_dialer_set_uint64(
+    nng_stream_dialer *, const char *, uint64_t);
+NNG_DECL int nng_stream_dialer_set_string(
+    nng_stream_dialer *, const char *, const char *);
+NNG_DECL int nng_stream_dialer_set_ptr(
+    nng_stream_dialer *, const char *, void *);
+NNG_DECL int nng_stream_dialer_set_addr(
+    nng_stream_dialer *, const char *, const nng_sockaddr *);
+
+NNG_DECL int nng_stream_listener_alloc(nng_stream_listener **, const char *);
+NNG_DECL int nng_stream_listener_alloc_url(
+    nng_stream_listener **, const nng_url *);
+NNG_DECL void nng_stream_listener_free(nng_stream_listener *);
+NNG_DECL void nng_stream_listener_close(nng_stream_listener *);
+NNG_DECL int  nng_stream_listener_listen(nng_stream_listener *);
+NNG_DECL void nng_stream_listener_accept(nng_stream_listener *, nng_aio *);
+NNG_DECL int  nng_stream_listener_set(
+     nng_stream_listener *, const char *, const void *, size_t);
+NNG_DECL int nng_stream_listener_get(
+    nng_stream_listener *, const char *, void *, size_t *);
+NNG_DECL int nng_stream_listener_get_bool(
+    nng_stream_listener *, const char *, bool *);
+NNG_DECL int nng_stream_listener_get_int(
+    nng_stream_listener *, const char *, int *);
+NNG_DECL int nng_stream_listener_get_ms(
+    nng_stream_listener *, const char *, nng_duration *);
+NNG_DECL int nng_stream_listener_get_size(
+    nng_stream_listener *, const char *, size_t *);
+NNG_DECL int nng_stream_listener_get_uint64(
+    nng_stream_listener *, const char *, uint64_t *);
+NNG_DECL int nng_stream_listener_get_string(
+    nng_stream_listener *, const char *, char **);
+NNG_DECL int nng_stream_listener_get_ptr(
+    nng_stream_listener *, const char *, void **);
+NNG_DECL int nng_stream_listener_get_addr(
+    nng_stream_listener *, const char *, nng_sockaddr *);
+NNG_DECL int nng_stream_listener_set_bool(
+    nng_stream_listener *, const char *, bool);
+NNG_DECL int nng_stream_listener_set_int(
+    nng_stream_listener *, const char *, int);
+NNG_DECL int nng_stream_listener_set_ms(
+    nng_stream_listener *, const char *, nng_duration);
+NNG_DECL int nng_stream_listener_set_size(
+    nng_stream_listener *, const char *, size_t);
+NNG_DECL int nng_stream_listener_set_uint64(
+    nng_stream_listener *, const char *, uint64_t);
+NNG_DECL int nng_stream_listener_set_string(
+    nng_stream_listener *, const char *, const char *);
+NNG_DECL int nng_stream_listener_set_ptr(
+    nng_stream_listener *, const char *, void *);
+NNG_DECL int nng_stream_listener_set_addr(
+    nng_stream_listener *, const char *, const nng_sockaddr *);
+
+
+#ifndef NNG_ELIDE_DEPRECATED
+// These are legacy APIs that have been deprecated.
+// Their use is strongly discouraged.
+
+// nng_msg_getopt is defunct, and should not be used by programs. It
+// always returns NNG_ENOTSUP.
+NNG_DECL int nng_msg_getopt(nng_msg *, int, void *, size_t *) NNG_DEPRECATED;
+
+// Socket options.  Use nng_socket_get and nng_socket_set instead.
+NNG_DECL int nng_getopt(nng_socket, const char *, void *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_getopt_bool(nng_socket, const char *, bool *) NNG_DEPRECATED;
+NNG_DECL int nng_getopt_int(nng_socket, const char *, int *) NNG_DEPRECATED;
+NNG_DECL int nng_getopt_ms(nng_socket, const char *, nng_duration *) NNG_DEPRECATED;
+NNG_DECL int nng_getopt_size(nng_socket, const char *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_getopt_uint64(nng_socket, const char *, uint64_t *) NNG_DEPRECATED;
+NNG_DECL int nng_getopt_ptr(nng_socket, const char *, void **) NNG_DEPRECATED;
+NNG_DECL int nng_getopt_string(nng_socket, const char *, char **) NNG_DEPRECATED;
+NNG_DECL int nng_setopt(nng_socket, const char *, const void *, size_t) NNG_DEPRECATED;
+NNG_DECL int nng_setopt_bool(nng_socket, const char *, bool) NNG_DEPRECATED;
+NNG_DECL int nng_setopt_int(nng_socket, const char *, int) NNG_DEPRECATED;
+NNG_DECL int nng_setopt_ms(nng_socket, const char *, nng_duration) NNG_DEPRECATED;
+NNG_DECL int nng_setopt_size(nng_socket, const char *, size_t) NNG_DEPRECATED;
+NNG_DECL int nng_setopt_uint64(nng_socket, const char *, uint64_t) NNG_DEPRECATED;
+NNG_DECL int nng_setopt_string(nng_socket, const char *, const char *) NNG_DEPRECATED;
+NNG_DECL int nng_setopt_ptr(nng_socket, const char *, void *) NNG_DEPRECATED;
+
+// Context options.  Use nng_ctx_get and nng_ctx_set instead.
+NNG_DECL int nng_ctx_getopt(nng_ctx, const char *, void *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_getopt_bool(nng_ctx, const char *, bool *) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_getopt_int(nng_ctx, const char *, int *) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_getopt_ms(nng_ctx, const char *, nng_duration *) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_getopt_size(nng_ctx, const char *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_setopt(nng_ctx, const char *, const void *, size_t) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_setopt_bool(nng_ctx, const char *, bool) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_setopt_int(nng_ctx, const char *, int) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_setopt_ms(nng_ctx, const char *, nng_duration) NNG_DEPRECATED;
+NNG_DECL int nng_ctx_setopt_size(nng_ctx, const char *, size_t) NNG_DEPRECATED;
+
+// Dialer options.  Use nng_dialer_get and nng_dialer_set instead.
+NNG_DECL int nng_dialer_getopt(nng_dialer, const char *, void *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_bool(nng_dialer, const char *, bool *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_int(nng_dialer, const char *, int *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_ms(nng_dialer, const char *, nng_duration *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_size(nng_dialer, const char *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_sockaddr(
+    nng_dialer, const char *, nng_sockaddr *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_uint64(nng_dialer, const char *, uint64_t *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_ptr(nng_dialer, const char *, void **) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_getopt_string(nng_dialer, const char *, char **) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt(nng_dialer, const char *, const void *, size_t) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt_bool(nng_dialer, const char *, bool) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt_int(nng_dialer, const char *, int) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt_ms(nng_dialer, const char *, nng_duration) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt_size(nng_dialer, const char *, size_t) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt_uint64(nng_dialer, const char *, uint64_t) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt_ptr(nng_dialer, const char *, void *) NNG_DEPRECATED;
+NNG_DECL int nng_dialer_setopt_string(nng_dialer, const char *, const char *) NNG_DEPRECATED;
+
+// Listener options.  Use nng_listener_get and nng_listener_set instead.
+NNG_DECL int nng_listener_getopt(nng_listener, const char *, void *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_bool(nng_listener, const char *, bool *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_int(nng_listener, const char *, int *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_ms(
+    nng_listener, const char *, nng_duration *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_size(nng_listener, const char *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_sockaddr(
+    nng_listener, const char *, nng_sockaddr *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_uint64(
+    nng_listener, const char *, uint64_t *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_ptr(nng_listener, const char *, void **) NNG_DEPRECATED;
+NNG_DECL int nng_listener_getopt_string(nng_listener, const char *, char **) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt(
+    nng_listener, const char *, const void *, size_t) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt_bool(nng_listener, const char *, bool) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt_int(nng_listener, const char *, int) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt_ms(nng_listener, const char *, nng_duration) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt_size(nng_listener, const char *, size_t) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt_uint64(nng_listener, const char *, uint64_t) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt_ptr(nng_listener, const char *, void *) NNG_DEPRECATED;
+NNG_DECL int nng_listener_setopt_string(
+    nng_listener, const char *, const char *) NNG_DEPRECATED;
+
+// Pipe options.  Use nng_pipe_get instead.
+NNG_DECL int nng_pipe_getopt(nng_pipe, const char *, void *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_bool(nng_pipe, const char *, bool *) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_int(nng_pipe, const char *, int *) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_ms(nng_pipe, const char *, nng_duration *) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_size(nng_pipe, const char *, size_t *) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_sockaddr(nng_pipe, const char *, nng_sockaddr *) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_uint64(nng_pipe, const char *, uint64_t *) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_ptr(nng_pipe, const char *, void **) NNG_DEPRECATED;
+NNG_DECL int nng_pipe_getopt_string(nng_pipe, const char *, char **) NNG_DEPRECATED;
+
+// nng_closeall closes all open sockets. Do not call this from
+// a library; it will affect all sockets.
+NNG_DECL void nng_closeall(void) NNG_DEPRECATED;
+
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_NNG_H
```

## skdecide/hub/include/nng/protocol/bus0/bus.h

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-//
-// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_BUS0_BUS_H
-#define NNG_PROTOCOL_BUS0_BUS_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_bus0_open(nng_socket *);
-
-NNG_DECL int nng_bus0_open_raw(nng_socket *);
-
-#ifndef nng_bus_open
-#define nng_bus_open nng_bus0_open
-#endif
-
-#ifndef nng_bus_open_raw
-#define nng_bus_open_raw nng_bus0_open_raw
-#endif
-
-#define NNG_BUS0_SELF 0x70
-#define NNG_BUS0_PEER 0x70
-#define NNG_BUS0_SELF_NAME "bus"
-#define NNG_BUS0_PEER_NAME "bus"
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_BUS0_BUS_H
+//
+// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_BUS0_BUS_H
+#define NNG_PROTOCOL_BUS0_BUS_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_bus0_open(nng_socket *);
+
+NNG_DECL int nng_bus0_open_raw(nng_socket *);
+
+#ifndef nng_bus_open
+#define nng_bus_open nng_bus0_open
+#endif
+
+#ifndef nng_bus_open_raw
+#define nng_bus_open_raw nng_bus0_open_raw
+#endif
+
+#define NNG_BUS0_SELF 0x70
+#define NNG_BUS0_PEER 0x70
+#define NNG_BUS0_SELF_NAME "bus"
+#define NNG_BUS0_PEER_NAME "bus"
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_BUS0_BUS_H
```

## skdecide/hub/include/nng/protocol/pair0/pair.h

 * *Ordering differences only*

```diff
@@ -1,34 +1,34 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_PAIR0_PAIR_H
-#define NNG_PROTOCOL_PAIR0_PAIR_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_pair0_open(nng_socket *);
-
-NNG_DECL int nng_pair0_open_raw(nng_socket *);
-
-#ifndef nng_pair_open
-#define nng_pair_open nng_pair0_open
-#endif
-
-#ifndef nng_pair_open_raw
-#define nng_pair_open_raw nng_pair0_open_raw
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_PAIR0_PAIR_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_PAIR0_PAIR_H
+#define NNG_PROTOCOL_PAIR0_PAIR_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_pair0_open(nng_socket *);
+
+NNG_DECL int nng_pair0_open_raw(nng_socket *);
+
+#ifndef nng_pair_open
+#define nng_pair_open nng_pair0_open
+#endif
+
+#ifndef nng_pair_open_raw
+#define nng_pair_open_raw nng_pair0_open_raw
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_PAIR0_PAIR_H
```

## skdecide/hub/include/nng/protocol/pair1/pair.h

 * *Ordering differences only*

```diff
@@ -1,40 +1,40 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_PAIR1_PAIR_H
-#define NNG_PROTOCOL_PAIR1_PAIR_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_pair1_open(nng_socket *);
-NNG_DECL int nng_pair1_open_raw(nng_socket *);
-NNG_DECL int nng_pair1_open_poly(nng_socket *);
-
-#ifndef nng_pair_open
-#define nng_pair_open nng_pair1_open
-#endif
-
-#ifndef nng_pair_open_raw
-#define nng_pair_open_raw nng_pair1_open_raw
-#endif
-
-#define NNG_OPT_PAIR1_POLY "pair1:polyamorous"
-#define NNG_PAIR1_SELF 0x11
-#define NNG_PAIR1_PEER 0x11
-#define NNG_PAIR1_SELF_NAME "pair1"
-#define NNG_PAIR1_PEER_NAME "pair1"
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_PAIR1_PAIR_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_PAIR1_PAIR_H
+#define NNG_PROTOCOL_PAIR1_PAIR_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_pair1_open(nng_socket *);
+NNG_DECL int nng_pair1_open_raw(nng_socket *);
+NNG_DECL int nng_pair1_open_poly(nng_socket *);
+
+#ifndef nng_pair_open
+#define nng_pair_open nng_pair1_open
+#endif
+
+#ifndef nng_pair_open_raw
+#define nng_pair_open_raw nng_pair1_open_raw
+#endif
+
+#define NNG_OPT_PAIR1_POLY "pair1:polyamorous"
+#define NNG_PAIR1_SELF 0x11
+#define NNG_PAIR1_PEER 0x11
+#define NNG_PAIR1_SELF_NAME "pair1"
+#define NNG_PAIR1_PEER_NAME "pair1"
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_PAIR1_PAIR_H
```

## skdecide/hub/include/nng/protocol/pipeline0/pull.h

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_PIPELINE0_PULL_H
-#define NNG_PROTOCOL_PIPELINE0_PULL_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_pull0_open(nng_socket *);
-NNG_DECL int nng_pull0_open_raw(nng_socket *);
-
-#ifndef nng_pull_open
-#define nng_pull_open nng_pull0_open
-#endif
-
-#ifndef nng_pull_open_raw
-#define nng_pull_open_raw nng_pull0_open_raw
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_PIPELINE0_PULL_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_PIPELINE0_PULL_H
+#define NNG_PROTOCOL_PIPELINE0_PULL_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_pull0_open(nng_socket *);
+NNG_DECL int nng_pull0_open_raw(nng_socket *);
+
+#ifndef nng_pull_open
+#define nng_pull_open nng_pull0_open
+#endif
+
+#ifndef nng_pull_open_raw
+#define nng_pull_open_raw nng_pull0_open_raw
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_PIPELINE0_PULL_H
```

## skdecide/hub/include/nng/protocol/pipeline0/push.h

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_PIPELINE0_PUSH_H
-#define NNG_PROTOCOL_PIPELINE0_PUSH_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_push0_open(nng_socket *);
-NNG_DECL int nng_push0_open_raw(nng_socket *);
-
-#ifndef nng_push_open
-#define nng_push_open nng_push0_open
-#endif
-
-#ifndef nng_push_open_raw
-#define nng_push_open_raw nng_push0_open_raw
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_PIPELINE0_PUSH_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_PIPELINE0_PUSH_H
+#define NNG_PROTOCOL_PIPELINE0_PUSH_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_push0_open(nng_socket *);
+NNG_DECL int nng_push0_open_raw(nng_socket *);
+
+#ifndef nng_push_open
+#define nng_push_open nng_push0_open
+#endif
+
+#ifndef nng_push_open_raw
+#define nng_push_open_raw nng_push0_open_raw
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_PIPELINE0_PUSH_H
```

## skdecide/hub/include/nng/protocol/pubsub0/pub.h

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_PUBSUB0_PUB_H
-#define NNG_PROTOCOL_PUBSUB0_PUB_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_pub0_open(nng_socket *);
-NNG_DECL int nng_pub0_open_raw(nng_socket *);
-
-#ifndef nng_pub_open
-#define nng_pub_open nng_pub0_open
-#endif
-
-#ifndef nng_pub_open_raw
-#define nng_pub_open_raw nng_pub0_open_raw
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_PUBSUB0_PUB_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_PUBSUB0_PUB_H
+#define NNG_PROTOCOL_PUBSUB0_PUB_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_pub0_open(nng_socket *);
+NNG_DECL int nng_pub0_open_raw(nng_socket *);
+
+#ifndef nng_pub_open
+#define nng_pub_open nng_pub0_open
+#endif
+
+#ifndef nng_pub_open_raw
+#define nng_pub_open_raw nng_pub0_open_raw
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_PUBSUB0_PUB_H
```

## skdecide/hub/include/nng/protocol/pubsub0/sub.h

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_PUBSUB0_SUB_H
-#define NNG_PROTOCOL_PUBSUB0_SUB_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_sub0_open(nng_socket *);
-
-NNG_DECL int nng_sub0_open_raw(nng_socket *);
-
-#ifndef nng_sub_open
-#define nng_sub_open nng_sub0_open
-#endif
-
-#ifndef nng_sub_open_raw
-#define nng_sub_open_raw nng_sub0_open_raw
-#endif
-
-#define NNG_OPT_SUB_SUBSCRIBE "sub:subscribe"
-#define NNG_OPT_SUB_UNSUBSCRIBE "sub:unsubscribe"
-
-#define NNG_OPT_SUB_PREFNEW "sub:prefnew"
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_PUBSUB0_SUB_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_PUBSUB0_SUB_H
+#define NNG_PROTOCOL_PUBSUB0_SUB_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_sub0_open(nng_socket *);
+
+NNG_DECL int nng_sub0_open_raw(nng_socket *);
+
+#ifndef nng_sub_open
+#define nng_sub_open nng_sub0_open
+#endif
+
+#ifndef nng_sub_open_raw
+#define nng_sub_open_raw nng_sub0_open_raw
+#endif
+
+#define NNG_OPT_SUB_SUBSCRIBE "sub:subscribe"
+#define NNG_OPT_SUB_UNSUBSCRIBE "sub:unsubscribe"
+
+#define NNG_OPT_SUB_PREFNEW "sub:prefnew"
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_PUBSUB0_SUB_H
```

## skdecide/hub/include/nng/protocol/reqrep0/rep.h

 * *Ordering differences only*

```diff
@@ -1,38 +1,38 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_REQREP0_REP_H
-#define NNG_PROTOCOL_REQREP0_REP_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_rep0_open(nng_socket *);
-NNG_DECL int nng_rep0_open_raw(nng_socket *);
-
-#ifndef nng_rep_open
-#define nng_rep_open nng_rep0_open
-#endif
-
-#ifndef nng_rep_open_raw
-#define nng_rep_open_raw nng_rep0_open_raw
-#endif
-
-#define NNG_REP0_SELF 0x31
-#define NNG_REP0_PEER 0x30
-#define NNG_REP0_SELF_NAME "rep"
-#define NNG_REP0_PEER_NAME "req"
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_REQREP0_REP_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_REQREP0_REP_H
+#define NNG_PROTOCOL_REQREP0_REP_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_rep0_open(nng_socket *);
+NNG_DECL int nng_rep0_open_raw(nng_socket *);
+
+#ifndef nng_rep_open
+#define nng_rep_open nng_rep0_open
+#endif
+
+#ifndef nng_rep_open_raw
+#define nng_rep_open_raw nng_rep0_open_raw
+#endif
+
+#define NNG_REP0_SELF 0x31
+#define NNG_REP0_PEER 0x30
+#define NNG_REP0_SELF_NAME "rep"
+#define NNG_REP0_PEER_NAME "req"
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_REQREP0_REP_H
```

## skdecide/hub/include/nng/protocol/reqrep0/req.h

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_REQREP0_REQ_H
-#define NNG_PROTOCOL_REQREP0_REQ_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_req0_open(nng_socket *);
-NNG_DECL int nng_req0_open_raw(nng_socket *);
-
-#ifndef nng_req_open
-#define nng_req_open nng_req0_open
-#endif
-#ifndef nng_req_open_raw
-#define nng_req_open_raw nng_req0_open_raw
-#endif
-
-#define NNG_REQ0_SELF 0x30
-#define NNG_REQ0_PEER 0x31
-#define NNG_REQ0_SELF_NAME "req"
-#define NNG_REQ0_PEER_NAME "rep"
-
-#define NNG_OPT_REQ_RESENDTIME "req:resend-time"
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_REQREP0_REQ_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_REQREP0_REQ_H
+#define NNG_PROTOCOL_REQREP0_REQ_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_req0_open(nng_socket *);
+NNG_DECL int nng_req0_open_raw(nng_socket *);
+
+#ifndef nng_req_open
+#define nng_req_open nng_req0_open
+#endif
+#ifndef nng_req_open_raw
+#define nng_req_open_raw nng_req0_open_raw
+#endif
+
+#define NNG_REQ0_SELF 0x30
+#define NNG_REQ0_PEER 0x31
+#define NNG_REQ0_SELF_NAME "req"
+#define NNG_REQ0_PEER_NAME "rep"
+
+#define NNG_OPT_REQ_RESENDTIME "req:resend-time"
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_REQREP0_REQ_H
```

## skdecide/hub/include/nng/protocol/survey0/respond.h

 * *Ordering differences only*

```diff
@@ -1,38 +1,38 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_SURVEY0_RESPOND_H
-#define NNG_PROTOCOL_SURVEY0_RESPOND_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_respondent0_open(nng_socket *);
-NNG_DECL int nng_respondent0_open_raw(nng_socket *);
-
-#ifndef nng_respondent_open
-#define nng_respondent_open nng_respondent0_open
-#endif
-
-#ifndef nng_respondent_open_raw
-#define nng_respondent_open_raw nng_respondent0_open_raw
-#endif
-
-#define NNG_RESPONDENT0_SELF 0x63
-#define NNG_RESPONDENT0_PEER 0x62
-#define NNG_RESPONDENT0_SELF_NAME "respondent"
-#define NNG_RESPONDENT0_PEER_NAME "surveyor"
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_SURVEY0_RESPOND_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_SURVEY0_RESPOND_H
+#define NNG_PROTOCOL_SURVEY0_RESPOND_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_respondent0_open(nng_socket *);
+NNG_DECL int nng_respondent0_open_raw(nng_socket *);
+
+#ifndef nng_respondent_open
+#define nng_respondent_open nng_respondent0_open
+#endif
+
+#ifndef nng_respondent_open_raw
+#define nng_respondent_open_raw nng_respondent0_open_raw
+#endif
+
+#define NNG_RESPONDENT0_SELF 0x63
+#define NNG_RESPONDENT0_PEER 0x62
+#define NNG_RESPONDENT0_SELF_NAME "respondent"
+#define NNG_RESPONDENT0_PEER_NAME "surveyor"
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_SURVEY0_RESPOND_H
```

## skdecide/hub/include/nng/protocol/survey0/survey.h

 * *Ordering differences only*

```diff
@@ -1,40 +1,40 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_PROTOCOL_SURVEY0_SURVEY_H
-#define NNG_PROTOCOL_SURVEY0_SURVEY_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-NNG_DECL int nng_surveyor0_open(nng_socket *);
-NNG_DECL int nng_surveyor0_open_raw(nng_socket *);
-
-#ifndef nng_surveyor_open
-#define nng_surveyor_open nng_surveyor0_open
-#endif
-
-#ifndef nng_surveyor_open_raw
-#define nng_surveyor_open_raw nng_surveyor0_open_raw
-#endif
-
-#define NNG_SURVEYOR0_SELF 0x62
-#define NNG_SURVEYOR0_PEER 0x63
-#define NNG_SURVEYOR0_SELF_NAME "surveyor"
-#define NNG_SURVEYOR0_PEER_NAME "respondent"
-
-#define NNG_OPT_SURVEYOR_SURVEYTIME "surveyor:survey-time"
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_PROTOCOL_SURVEY0_SURVEY_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_PROTOCOL_SURVEY0_SURVEY_H
+#define NNG_PROTOCOL_SURVEY0_SURVEY_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+NNG_DECL int nng_surveyor0_open(nng_socket *);
+NNG_DECL int nng_surveyor0_open_raw(nng_socket *);
+
+#ifndef nng_surveyor_open
+#define nng_surveyor_open nng_surveyor0_open
+#endif
+
+#ifndef nng_surveyor_open_raw
+#define nng_surveyor_open_raw nng_surveyor0_open_raw
+#endif
+
+#define NNG_SURVEYOR0_SELF 0x62
+#define NNG_SURVEYOR0_PEER 0x63
+#define NNG_SURVEYOR0_SELF_NAME "surveyor"
+#define NNG_SURVEYOR0_PEER_NAME "respondent"
+
+#define NNG_OPT_SURVEYOR_SURVEYTIME "surveyor:survey-time"
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_PROTOCOL_SURVEY0_SURVEY_H
```

## skdecide/hub/include/nng/supplemental/http/http.h

 * *Ordering differences only*

```diff
@@ -1,539 +1,539 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-// Copyright 2020 Dirac Research <robert.bielik@dirac.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_SUPPLEMENTAL_HTTP_HTTP_H
-#define NNG_SUPPLEMENTAL_HTTP_HTTP_H
-
-// HTTP API.  Only present if HTTP support compiled into the library.
-// Functions will return NNG_ENOTSUP (or NULL or 0 as appropriate)
-// if the library lacks support for HTTP.
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stdint.h>
-
-struct nng_tls_config;
-
-// HTTP status codes.  This list is not exhaustive.
-enum nng_http_status {
-	NNG_HTTP_STATUS_CONTINUE                 = 100,
-	NNG_HTTP_STATUS_SWITCHING                = 101,
-	NNG_HTTP_STATUS_PROCESSING               = 102,
-	NNG_HTTP_STATUS_OK                       = 200,
-	NNG_HTTP_STATUS_CREATED                  = 201,
-	NNG_HTTP_STATUS_ACCEPTED                 = 202,
-	NNG_HTTP_STATUS_NOT_AUTHORITATIVE        = 203,
-	NNG_HTTP_STATUS_NO_CONTENT               = 204,
-	NNG_HTTP_STATUS_RESET_CONTENT            = 205,
-	NNG_HTTP_STATUS_PARTIAL_CONTENT          = 206,
-	NNG_HTTP_STATUS_MULTI_STATUS             = 207,
-	NNG_HTTP_STATUS_ALREADY_REPORTED         = 208,
-	NNG_HTTP_STATUS_IM_USED                  = 226,
-	NNG_HTTP_STATUS_MULTIPLE_CHOICES         = 300,
-	NNG_HTTP_STATUS_STATUS_MOVED_PERMANENTLY = 301,
-	NNG_HTTP_STATUS_FOUND                    = 302,
-	NNG_HTTP_STATUS_SEE_OTHER                = 303,
-	NNG_HTTP_STATUS_NOT_MODIFIED             = 304,
-	NNG_HTTP_STATUS_USE_PROXY                = 305,
-	NNG_HTTP_STATUS_TEMPORARY_REDIRECT       = 307,
-	NNG_HTTP_STATUS_PERMANENT_REDIRECT       = 308,
-	NNG_HTTP_STATUS_BAD_REQUEST              = 400,
-	NNG_HTTP_STATUS_UNAUTHORIZED             = 401,
-	NNG_HTTP_STATUS_PAYMENT_REQUIRED         = 402,
-	NNG_HTTP_STATUS_FORBIDDEN                = 403,
-	NNG_HTTP_STATUS_NOT_FOUND                = 404,
-	NNG_HTTP_STATUS_METHOD_NOT_ALLOWED       = 405,
-	NNG_HTTP_STATUS_NOT_ACCEPTABLE           = 406,
-	NNG_HTTP_STATUS_PROXY_AUTH_REQUIRED      = 407,
-	NNG_HTTP_STATUS_REQUEST_TIMEOUT          = 408,
-	NNG_HTTP_STATUS_CONFLICT                 = 409,
-	NNG_HTTP_STATUS_GONE                     = 410,
-	NNG_HTTP_STATUS_LENGTH_REQUIRED          = 411,
-	NNG_HTTP_STATUS_PRECONDITION_FAILED      = 412,
-	NNG_HTTP_STATUS_PAYLOAD_TOO_LARGE        = 413,
-	NNG_HTTP_STATUS_ENTITY_TOO_LONG          = 414,
-	NNG_HTTP_STATUS_UNSUPPORTED_MEDIA_TYPE   = 415,
-	NNG_HTTP_STATUS_RANGE_NOT_SATISFIABLE    = 416,
-	NNG_HTTP_STATUS_EXPECTATION_FAILED       = 417,
-	NNG_HTTP_STATUS_TEAPOT                   = 418,
-	NNG_HTTP_STATUS_UNPROCESSABLE_ENTITY     = 422,
-	NNG_HTTP_STATUS_LOCKED                   = 423,
-	NNG_HTTP_STATUS_FAILED_DEPENDENCY        = 424,
-	NNG_HTTP_STATUS_UPGRADE_REQUIRED         = 426,
-	NNG_HTTP_STATUS_PRECONDITION_REQUIRED    = 428,
-	NNG_HTTP_STATUS_TOO_MANY_REQUESTS        = 429,
-	NNG_HTTP_STATUS_HEADERS_TOO_LARGE        = 431,
-	NNG_HTTP_STATUS_UNAVAIL_LEGAL_REASONS    = 451,
-	NNG_HTTP_STATUS_INTERNAL_SERVER_ERROR    = 500,
-	NNG_HTTP_STATUS_NOT_IMPLEMENTED          = 501,
-	NNG_HTTP_STATUS_BAD_GATEWAY              = 502,
-	NNG_HTTP_STATUS_SERVICE_UNAVAILABLE      = 503,
-	NNG_HTTP_STATUS_GATEWAY_TIMEOUT          = 504,
-	NNG_HTTP_STATUS_HTTP_VERSION_NOT_SUPP    = 505,
-	NNG_HTTP_STATUS_VARIANT_ALSO_NEGOTIATES  = 506,
-	NNG_HTTP_STATUS_INSUFFICIENT_STORAGE     = 507,
-	NNG_HTTP_STATUS_LOOP_DETECTED            = 508,
-	NNG_HTTP_STATUS_NOT_EXTENDED             = 510,
-	NNG_HTTP_STATUS_NETWORK_AUTH_REQUIRED    = 511,
-};
-
-// nng_http_req represents an HTTP request.
-typedef struct nng_http_req nng_http_req;
-
-// nng_http_req_alloc creates a vanilla HTTP request object.  The object is
-// initialized with the given URL object for an HTTP/1.1 GET request by
-// default. It also adds the Host: header required for HTTP/1.1.  If the
-// url is NULL, then the uri and Host: header are uninitialized, and will
-// need to be set explicitly.
-NNG_DECL int nng_http_req_alloc(nng_http_req **, const nng_url *);
-
-// nng_http_req_free frees an HTTP request object.
-NNG_DECL void nng_http_req_free(nng_http_req *);
-
-// nng_http_req_get_method returns the method.
-NNG_DECL const char *nng_http_req_get_method(nng_http_req *);
-
-// nng_http_req_get_version returns the version, usually HTTP/1.1.
-NNG_DECL const char *nng_http_req_get_version(nng_http_req *);
-
-// nng_http_req_get_uri returns the "abs-uri", which is URL without
-// the scheme, host, or port.
-NNG_DECL const char *nng_http_req_get_uri(nng_http_req *);
-
-// nng_http_req_set_header sets an HTTP header, replacing any previous value
-// that might have been present.
-NNG_DECL int nng_http_req_set_header(
-    nng_http_req *, const char *, const char *);
-
-// nng_http_req_add_header adds an HTTP header, without disrupting any other
-// with the same name that might have been present.
-NNG_DECL int nng_http_req_add_header(
-    nng_http_req *, const char *, const char *);
-
-// nng_http_req_del_header deletes all occurrences of a named header.
-NNG_DECL int nng_http_req_del_header(nng_http_req *, const char *);
-
-// nng_http_req_get_header looks up a header with the named, returns NULL
-// if not found.
-NNG_DECL const char *nng_http_req_get_header(nng_http_req *, const char *);
-
-// nng_http_req_set_method is used to change the method of a request.
-// The method should be an upper case HTTP method, like POST, or DELETE.
-// Null sets the default ("GET").
-NNG_DECL int nng_http_req_set_method(nng_http_req *, const char *);
-
-// nng_http_req_set_version is used to change the version of a request.
-// Normally the version is "HTTP/1.1".  Note that the framework does
-// not support HTTP/2 at all.  Null sets the default ("HTTP/1.1").
-NNG_DECL int nng_http_req_set_version(nng_http_req *, const char *);
-
-// nng_http_req_set_uri is used to change the URI of a request.  This
-// should be an "abs-uri", that is a path, plus query and fragment if
-// needed.  The scheme, host, and port don't belong here.  The URI should
-// start with a leading '/' per HTTP.
-NNG_DECL int nng_http_req_set_uri(nng_http_req *, const char *);
-
-// nng_http_req_set_data adds entity data to the request.  The
-// data object must persist (so only really useful for static data).
-// The content-length header is updated as well, but the caller should
-// probably set the content-type header.
-NNG_DECL int nng_http_req_set_data(nng_http_req *, const void *, size_t);
-
-// nng_http_req_copy_data adds entity data to the response. A private
-// copy of the data is made (will be freed with the request).
-// The content-length header is updated as well, but the caller should
-// probably set the content-type header.
-NNG_DECL int nng_http_req_copy_data(nng_http_req *, const void *, size_t);
-
-// nng_http_req_get_data gets the data for the response.
-NNG_DECL void nng_http_req_get_data(nng_http_req *, void **, size_t *);
-
-// nng_http_res represents an HTTP response.
-typedef struct nng_http_res nng_http_res;
-
-// nng_http_res_alloc creates a vanilla HTTP response object.  The object is
-// initialized for an HTTP/1.1 200 OK response by default.
-NNG_DECL int nng_http_res_alloc(nng_http_res **);
-
-// nng_http_res_alloc_error creates an error HTTP response object.  The object
-// is initialized for an HTTP/1.1 response, and contains an associated
-// generic HTML error page.
-NNG_DECL int nng_http_res_alloc_error(nng_http_res **, uint16_t);
-
-// nng_http_res_free frees an HTTP response object.
-NNG_DECL void nng_http_res_free(nng_http_res *);
-
-// nng_http_res_get_status returns the HTTP status code from the server.
-NNG_DECL uint16_t nng_http_res_get_status(nng_http_res *);
-
-// nng_http_res_set_status sets the HTTP status code.
-NNG_DECL int nng_http_res_set_status(nng_http_res *, uint16_t);
-
-// nng_http_res_get_reason returns the human readable status message
-// that the server responds (or responded) with.
-NNG_DECL const char *nng_http_res_get_reason(nng_http_res *);
-
-// nng_http_res_set_reason sets the human readable status message.
-// NULL means that a default reason is used based on the status code.
-NNG_DECL int nng_http_res_set_reason(nng_http_res *, const char *);
-
-// nng_http_res_set_header sets an HTTP header, replacing any previous value
-// that might have been present.
-NNG_DECL int nng_http_res_set_header(
-    nng_http_res *, const char *, const char *);
-
-// nng_http_res_add_header adds an HTTP header, without disrupting any other
-// with the same name that might have been present.
-NNG_DECL int nng_http_res_add_header(
-    nng_http_res *, const char *, const char *);
-
-// nng_http_res_del_header deletes all occurrences of a named header.
-NNG_DECL int nng_http_res_del_header(nng_http_res *, const char *);
-
-// nng_http_res_get_header looks up a header with the named, returns NULL
-// if not found.
-NNG_DECL const char *nng_http_res_get_header(nng_http_res *, const char *);
-
-// nng_http_res_set_version is used to change the version of a response.
-// Normally the version is "HTTP/1.1".  Note that the framework does
-// not support HTTP/2 at all.  NULL sets the default ("HTTP/1.1").
-NNG_DECL int nng_http_res_set_version(nng_http_res *, const char *);
-
-// nng_http_res_get_version returns the version, usually HTTP/1.1.
-NNG_DECL const char *nng_http_res_get_version(nng_http_res *);
-
-// nng_http_res_get_data gets the data for the response.
-NNG_DECL void nng_http_res_get_data(nng_http_res *, void **, size_t *);
-
-// nng_http_res_set_data adds entity data to the response.  The
-// data object must persist (so only really useful for static data).
-// The content-length header is updated as well, but the caller should
-// probably set the content-type header.
-NNG_DECL int nng_http_res_set_data(nng_http_res *, const void *, size_t);
-
-// nng_http_res_copy_data adds entity data to the response. A private
-// copy of the data is made (will be freed with the request).
-// The content-length header is updated as well, but the caller should
-// probably set the content-type header.
-NNG_DECL int nng_http_res_copy_data(nng_http_res *, const void *, size_t);
-
-// An nng_http_conn represents an underlying "connection".  It may be
-// a TCP channel, or a TLS channel, but the main thing is that this is
-// normally only used for exchanging HTTP requests and responses.
-typedef struct nng_http_conn nng_http_conn;
-
-// nng_http_conn_close closes the underlying channel.  Applications should
-// not use this channel after this operation is performed.
-NNG_DECL void nng_http_conn_close(nng_http_conn *);
-
-// nng_http_conn_read attempts to read data from the connection.  This
-// completes as soon as at least one byte is read; it does not wait
-// for the entire aio to be filled.
-NNG_DECL void nng_http_conn_read(nng_http_conn *, nng_aio *);
-
-// nng_http_conn_read_all is like nng_http_conn_read, but it does not
-// finish until either all the requested data is read, or an error occurs.
-NNG_DECL void nng_http_conn_read_all(nng_http_conn *, nng_aio *);
-
-// nng_http_conn_write attempts to write data, but it can write less
-// than the amount requested. (It completes as soon as at least one
-// byte is written.)
-NNG_DECL void nng_http_conn_write(nng_http_conn *, nng_aio *);
-
-// nng_http_conn_write_all is like nng_http_conn_write, but it does not
-// finish until either all the requested data is written, or an error occurs.
-NNG_DECL void nng_http_conn_write_all(nng_http_conn *, nng_aio *);
-
-// nng_http_conn_write_req writes the entire request.  It will also write any
-// data that has been attached.
-NNG_DECL void nng_http_conn_write_req(
-    nng_http_conn *, nng_http_req *, nng_aio *);
-
-// nng_http_conn_write_res writes the entire response.  It will also write any
-// data that has been attached.
-NNG_DECL void nng_http_conn_write_res(
-    nng_http_conn *, nng_http_res *, nng_aio *);
-
-// nng_http_conn_read_req reads an entire request, EXCEPT for any entity
-// data.  The caller is responsible for processing the headers in the request
-// and reading any submitted entity data itself.
-NNG_DECL void nng_http_conn_read_req(
-    nng_http_conn *, nng_http_req *, nng_aio *);
-
-// nng_http_conn_read_res reads an entire response, EXCEPT for any entity
-// data.  The caller is responsible for processing the headers in the response
-// and reading any submitted entity data itself.
-NNG_DECL void nng_http_conn_read_res(
-    nng_http_conn *, nng_http_res *, nng_aio *);
-
-// nng_http_req_reset resets the request to an initially allocated state.
-NNG_DECL void nng_http_req_reset(nng_http_req *);
-
-// nng_http_res_reset resets the response to an initially allocated state.
-NNG_DECL void nng_http_res_reset(nng_http_res *);
-
-// nng_http_handler is a handler used on the server side to handle HTTP
-// requests coming into a specific URL.
-typedef struct nng_http_handler nng_http_handler;
-
-// nng_http_handler_alloc creates a server handler object, for the supplied
-// absolute URI (path only) with the callback.  By default the handler
-// is assumed to handle only GET requests (and implictly HEAD requests
-// as well.)
-//
-// Note that methods which modify a handler cannot be called while the handler
-// is registered with the server, and that a handler can only be registered
-// once per server.
-//
-// The callback function will receive the following arguments (via
-// nng_aio_get_input(): nng_http_request *, nng_http_handler *, and
-// nng_http_conn *.  The first is a request object, for convenience.
-// The second is the handler, from which the callback can obtain any other
-// data it has set.  The final is the http connection, which can be used
-// to hijack the session.
-//
-// Upon completion, the handler should store an nng_http_res * as the
-// first output using nng_aio_set_output.  If it does not do so, or supplies
-// NULL, then it must send a response itself.
-//
-// The callback should complete with a result of 0 in most circumstances.
-// If it completes with an error, then the connection is terminated, after
-// possibly sending a 500 error response to the client.
-NNG_DECL int nng_http_handler_alloc(
-    nng_http_handler **, const char *, void (*)(nng_aio *));
-
-// nng_http_handler_free frees the handler. This actually just drops a
-// reference count on the handler, as it may be in use by an existing
-// server.  The server will also call this when it is destroyed.
-NNG_DECL void nng_http_handler_free(nng_http_handler *);
-
-// nng_http_handler_alloc_file creates a "file" based handler, that
-// serves up static content from the given file path.  The content-type
-// supplied is determined from the file name using a simple built-in map.
-NNG_DECL int nng_http_handler_alloc_file(
-    nng_http_handler **, const char *, const char *);
-
-// nng_http_handler_alloc_static creates a static-content handler.
-// The last argument is the content-type, which may be NULL (in which case
-// "application/octet-stream" is assumed.)
-NNG_DECL int nng_http_handler_alloc_static(
-    nng_http_handler **, const char *, const void *, size_t, const char *);
-
-// nng_http_handler_alloc_redirect creates an HTTP redirect handler.
-// The status is given, along with the new URL.  If the status is 0,
-// then 301 will be used instead.
-NNG_DECL int nng_http_handler_alloc_redirect(
-    nng_http_handler **, const char *, uint16_t, const char *);
-
-// nng_http_handler_alloc_file creates a "directory" based handler, that
-// serves up static content from the given directory tree.  Directories
-// that contain an index.html or index.htm file use that file for the
-// directory content, otherwise a suitable error page is returned (the server
-// does not generate index pages automatically.)  The content-type for
-// files is determined from the file name using a simple built-in map.
-NNG_DECL int nng_http_handler_alloc_directory(
-    nng_http_handler **, const char *, const char *);
-
-// nng_http_handler_set_method sets the method that the handler will be
-// called for.  By default this is GET.  If NULL is supplied for the
-// method, then the handler is executed regardless of method, and must
-// inspect the method itself.
-NNG_DECL int nng_http_handler_set_method(nng_http_handler *, const char *);
-
-// nng_http_handler_set_host sets the Host: that the handler will be
-// called for (to allow for virtual hosts).  If the value is NULL (the
-// default, then the Host: header is not considered when matching the
-// handler.)  Note that the Host: header must match *exactly* (except
-// that case is not considered.)
-NNG_DECL int nng_http_handler_set_host(nng_http_handler *, const char *);
-
-// nng_http_handler_collect_body is used to indicate the server should
-// check for, and process, data sent by the client, which will be attached
-// to the request.  If this is false, then the handler will need to check
-// for and process any content data.  By default the server will accept
-// up to 1MB.  If the client attempts to send more data than requested,
-// then a 400 Bad Request will be sent back to the client.  To set an
-// unlimited value, use (size_t)-1.  To preclude the client from sending
-// *any* data, use 0.  (The static and file handlers use 0 by default.)
-NNG_DECL int nng_http_handler_collect_body(nng_http_handler *, bool, size_t);
-
-// nng_http_handler_set_tree indicates that the handler is being registered
-// for a hierarchical tree, rather than just a single path, so it will be
-// called for all child paths supplied.  By default the handler is only
-// called for an exact path match.
-NNG_DECL int nng_http_handler_set_tree(nng_http_handler *);
-
-// nng_http_handler_set_tree_exclusive indicates that the handler is being
-// registered for a heirarchical tree *exclusively*, rather than just a single
-// path, so it will be called for all child paths supplied. By default the
-// handler is only called for an exact path match. Exclusive means that any
-// other handler on a conflicting path will induce an address conflict error
-// when added to a server.
-NNG_DECL int nng_http_handler_set_tree_exclusive(nng_http_handler *);
-
-// nng_http_handler_set_data is used to store additional data, along with
-// a possible clean up routine.  (The clean up is a custom de-allocator and
-// will be called with the supplied data as an argument, when the handler
-// is being de-allocated.)
-NNG_DECL int nng_http_handler_set_data(
-    nng_http_handler *, void *, void (*)(void *));
-
-// nng_http_handler_get_data returns the data that was previously stored.
-NNG_DECL void *nng_http_handler_get_data(nng_http_handler *);
-
-// nng_http_server is a handle to an HTTP server instance.  Servers
-// only serve a single port / address at this time.
-
-typedef struct nng_http_server nng_http_server;
-
-// nng_http_server_hold gets a server structure, using the address determined
-// from the URL.  If a server already exists, then a hold is placed on it, and
-// that instance is returned.  If no such server exists, then a new instance
-// is created.
-NNG_DECL int nng_http_server_hold(nng_http_server **, const nng_url *);
-
-// nng_http_server_release releases the hold on the server.  If this is the
-// last instance of the server, then it is shutdown and resources are freed.
-NNG_DECL void nng_http_server_release(nng_http_server *);
-
-// nng_http_server_start starts the server handling HTTP.  Once this is
-// called, it will not be possible to change certain parameters (such as
-// any TLS configuration).
-NNG_DECL int nng_http_server_start(nng_http_server *);
-
-// nng_http_server_stop stops the server.  No new client connections are
-// accepted after this returns.  Once a server is stopped fully, the
-// instance will no longer be returned by nng_http_server_hold, as the
-// server may not be reused.
-NNG_DECL void nng_http_server_stop(nng_http_server *);
-
-// nng_http_server_add_handler registers a handler on the server.
-// This function will return NNG_EADDRINUSE if a conflicting handler
-// is already registered (i.e. a handler with the same value for Host,
-// Method, and URL.)
-NNG_DECL int nng_http_server_add_handler(
-    nng_http_server *, nng_http_handler *);
-
-// nni_http_del_handler removes the given handler.  The caller is
-// responsible for finalizing it afterwards.  If the handler was not found
-// (not registered), NNG_ENOENT is returned.  In this case it is unsafe
-// to make assumptions about the validity of the handler.
-NNG_DECL int nng_http_server_del_handler(
-    nng_http_server *, nng_http_handler *);
-
-// nng_http_server_set_tls adds a TLS configuration to the server,
-// and enables the use of it.  This returns NNG_EBUSY if the server is
-// already started.   This wipes out the entire TLS configuration on the
-// server client, so the caller must have configured it reasonably.
-// This API is not recommended unless the caller needs complete control
-// over the TLS configuration.
-NNG_DECL int nng_http_server_set_tls(
-    nng_http_server *, struct nng_tls_config *);
-
-// nng_http_server_get_tls obtains the TLS configuration if one is present,
-// or returns NNG_EINVAL.  The TLS configuration is invalidated if the
-// nng_http_server_set_tls function is called, so be careful.
-NNG_DECL int nng_http_server_get_tls(
-    nng_http_server *, struct nng_tls_config **);
-
-// nng_http_server_get_addr obtains the address with which the server was
-// initialized or returns NNG_EINVAL. Useful for instance when the port has
-// been automatically assigned.
-NNG_DECL int nng_http_server_get_addr(nng_http_server *, nng_sockaddr *);
-
-// nng_http_server_set_error_page sets a custom error page (HTML) content
-// to be sent for the given error code.  This is used when the error is
-// generated internally by the framework, or when the application returns
-// the response back to the server via the handler's aio, and the response
-// was allocated with nng_http_res_alloc_error.  If the response was not
-// allocated this way, or the application writes the response itself instead
-// of letting the server do so, then this setting will be ignored.
-NNG_DECL int nng_http_server_set_error_page(
-    nng_http_server *, uint16_t, const char *);
-
-// nng_http_server_set_error_file works like nng_http_server_error_page,
-// except that the content is loaded from the named file path.  The contents
-// are loaded at the time this function is called, so this function should be
-// called anytime the contents of the named file have changed.
-NNG_DECL int nng_http_server_set_error_file(
-    nng_http_server *, uint16_t, const char *);
-
-// nng_http_server_res_error takes replaces the body of the response with
-// a custom error page previously set for the server, using the status
-// of the response.  The response must have the status set first using
-// nng_http_res_set_status or implicitly via nng_http_res_alloc_error.
-NNG_DECL int nng_http_server_res_error(nng_http_server *, nng_http_res *);
-
-// nng_http_hijack is intended to be called by a handler that wishes to
-// take over the processing of the HTTP session -- usually to change protocols
-// (such as in the case of websocket).  The caller is responsible for the
-// final disposal of the associated nng_http_conn.  Also, this completely
-// disassociates the http session from the server, so the server may be
-// stopped or destroyed without affecting the hijacked session.  Note also
-// that the hijacker will need to issue any HTTP reply itself.  Finally,
-// when a session is hijacked, the caller is also responsible for disposing
-// of the request structure.  (Some hijackers may keep the request for
-// further processing.)
-
-NNG_DECL int nng_http_hijack(nng_http_conn *);
-
-// nng_http_client represents a "client" object.  Clients can be used
-// to create HTTP connections.  At present, connections are not cached
-// or reused, but that could change in the future.
-typedef struct nng_http_client nng_http_client;
-
-// nng_http_client_alloc allocates a client object, associated with
-// the given URL.
-NNG_DECL int nng_http_client_alloc(nng_http_client **, const nng_url *);
-
-// nng_http_client_free frees the client.  Connections created by the
-// the client are not necessarily closed.
-NNG_DECL void nng_http_client_free(nng_http_client *);
-
-// nng_http_client_set_tls sets the TLS configuration.  This wipes out
-// the entire TLS configuration on the client, so the caller must have
-// configured it reasonably.  This API is not recommended unless the
-// caller needs complete control over the TLS configuration.
-NNG_DECL int nng_http_client_set_tls(
-    nng_http_client *, struct nng_tls_config *);
-
-// nng_http_client_get_tls obtains the TLS configuration if one is present,
-// or returns NNG_EINVAL.  The supplied TLS configuration object may
-// be invalidated by any future calls to nni_http_client_set_tls.
-NNG_DECL int nng_http_client_get_tls(
-    nng_http_client *, struct nng_tls_config **);
-
-// nng_http_client_connect establishes a new connection with the server
-// named in the URL used when the client was created.  Once the connection
-// is established, the associated nng_http_conn object pointer is returned
-// in the first (index 0) output for the aio.
-NNG_DECL void nng_http_client_connect(nng_http_client *, nng_aio *);
-
-// nng_http_conn_transact is used to perform a round-trip exchange (i.e. a
-// single HTTP transaction).  It will not automatically close the connection,
-// unless some kind of significant error occurs.  The caller should close
-// the connection if the aio does not complete successfully.
-NNG_DECL void nng_http_conn_transact(
-    nng_http_conn *, nng_http_req *, nng_http_res *, nng_aio *);
-
-// nng_http_client_transact is used to execute a single transaction to a
-// server. The connection is opened, and will be closed when the transaction is
-// complete.
-NNG_DECL void nng_http_client_transact(
-    nng_http_client *, nng_http_req *, nng_http_res *, nng_aio *);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+// Copyright 2020 Dirac Research <robert.bielik@dirac.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_SUPPLEMENTAL_HTTP_HTTP_H
+#define NNG_SUPPLEMENTAL_HTTP_HTTP_H
+
+// HTTP API.  Only present if HTTP support compiled into the library.
+// Functions will return NNG_ENOTSUP (or NULL or 0 as appropriate)
+// if the library lacks support for HTTP.
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <stdint.h>
+
+struct nng_tls_config;
+
+// HTTP status codes.  This list is not exhaustive.
+enum nng_http_status {
+	NNG_HTTP_STATUS_CONTINUE                 = 100,
+	NNG_HTTP_STATUS_SWITCHING                = 101,
+	NNG_HTTP_STATUS_PROCESSING               = 102,
+	NNG_HTTP_STATUS_OK                       = 200,
+	NNG_HTTP_STATUS_CREATED                  = 201,
+	NNG_HTTP_STATUS_ACCEPTED                 = 202,
+	NNG_HTTP_STATUS_NOT_AUTHORITATIVE        = 203,
+	NNG_HTTP_STATUS_NO_CONTENT               = 204,
+	NNG_HTTP_STATUS_RESET_CONTENT            = 205,
+	NNG_HTTP_STATUS_PARTIAL_CONTENT          = 206,
+	NNG_HTTP_STATUS_MULTI_STATUS             = 207,
+	NNG_HTTP_STATUS_ALREADY_REPORTED         = 208,
+	NNG_HTTP_STATUS_IM_USED                  = 226,
+	NNG_HTTP_STATUS_MULTIPLE_CHOICES         = 300,
+	NNG_HTTP_STATUS_STATUS_MOVED_PERMANENTLY = 301,
+	NNG_HTTP_STATUS_FOUND                    = 302,
+	NNG_HTTP_STATUS_SEE_OTHER                = 303,
+	NNG_HTTP_STATUS_NOT_MODIFIED             = 304,
+	NNG_HTTP_STATUS_USE_PROXY                = 305,
+	NNG_HTTP_STATUS_TEMPORARY_REDIRECT       = 307,
+	NNG_HTTP_STATUS_PERMANENT_REDIRECT       = 308,
+	NNG_HTTP_STATUS_BAD_REQUEST              = 400,
+	NNG_HTTP_STATUS_UNAUTHORIZED             = 401,
+	NNG_HTTP_STATUS_PAYMENT_REQUIRED         = 402,
+	NNG_HTTP_STATUS_FORBIDDEN                = 403,
+	NNG_HTTP_STATUS_NOT_FOUND                = 404,
+	NNG_HTTP_STATUS_METHOD_NOT_ALLOWED       = 405,
+	NNG_HTTP_STATUS_NOT_ACCEPTABLE           = 406,
+	NNG_HTTP_STATUS_PROXY_AUTH_REQUIRED      = 407,
+	NNG_HTTP_STATUS_REQUEST_TIMEOUT          = 408,
+	NNG_HTTP_STATUS_CONFLICT                 = 409,
+	NNG_HTTP_STATUS_GONE                     = 410,
+	NNG_HTTP_STATUS_LENGTH_REQUIRED          = 411,
+	NNG_HTTP_STATUS_PRECONDITION_FAILED      = 412,
+	NNG_HTTP_STATUS_PAYLOAD_TOO_LARGE        = 413,
+	NNG_HTTP_STATUS_ENTITY_TOO_LONG          = 414,
+	NNG_HTTP_STATUS_UNSUPPORTED_MEDIA_TYPE   = 415,
+	NNG_HTTP_STATUS_RANGE_NOT_SATISFIABLE    = 416,
+	NNG_HTTP_STATUS_EXPECTATION_FAILED       = 417,
+	NNG_HTTP_STATUS_TEAPOT                   = 418,
+	NNG_HTTP_STATUS_UNPROCESSABLE_ENTITY     = 422,
+	NNG_HTTP_STATUS_LOCKED                   = 423,
+	NNG_HTTP_STATUS_FAILED_DEPENDENCY        = 424,
+	NNG_HTTP_STATUS_UPGRADE_REQUIRED         = 426,
+	NNG_HTTP_STATUS_PRECONDITION_REQUIRED    = 428,
+	NNG_HTTP_STATUS_TOO_MANY_REQUESTS        = 429,
+	NNG_HTTP_STATUS_HEADERS_TOO_LARGE        = 431,
+	NNG_HTTP_STATUS_UNAVAIL_LEGAL_REASONS    = 451,
+	NNG_HTTP_STATUS_INTERNAL_SERVER_ERROR    = 500,
+	NNG_HTTP_STATUS_NOT_IMPLEMENTED          = 501,
+	NNG_HTTP_STATUS_BAD_GATEWAY              = 502,
+	NNG_HTTP_STATUS_SERVICE_UNAVAILABLE      = 503,
+	NNG_HTTP_STATUS_GATEWAY_TIMEOUT          = 504,
+	NNG_HTTP_STATUS_HTTP_VERSION_NOT_SUPP    = 505,
+	NNG_HTTP_STATUS_VARIANT_ALSO_NEGOTIATES  = 506,
+	NNG_HTTP_STATUS_INSUFFICIENT_STORAGE     = 507,
+	NNG_HTTP_STATUS_LOOP_DETECTED            = 508,
+	NNG_HTTP_STATUS_NOT_EXTENDED             = 510,
+	NNG_HTTP_STATUS_NETWORK_AUTH_REQUIRED    = 511,
+};
+
+// nng_http_req represents an HTTP request.
+typedef struct nng_http_req nng_http_req;
+
+// nng_http_req_alloc creates a vanilla HTTP request object.  The object is
+// initialized with the given URL object for an HTTP/1.1 GET request by
+// default. It also adds the Host: header required for HTTP/1.1.  If the
+// url is NULL, then the uri and Host: header are uninitialized, and will
+// need to be set explicitly.
+NNG_DECL int nng_http_req_alloc(nng_http_req **, const nng_url *);
+
+// nng_http_req_free frees an HTTP request object.
+NNG_DECL void nng_http_req_free(nng_http_req *);
+
+// nng_http_req_get_method returns the method.
+NNG_DECL const char *nng_http_req_get_method(nng_http_req *);
+
+// nng_http_req_get_version returns the version, usually HTTP/1.1.
+NNG_DECL const char *nng_http_req_get_version(nng_http_req *);
+
+// nng_http_req_get_uri returns the "abs-uri", which is URL without
+// the scheme, host, or port.
+NNG_DECL const char *nng_http_req_get_uri(nng_http_req *);
+
+// nng_http_req_set_header sets an HTTP header, replacing any previous value
+// that might have been present.
+NNG_DECL int nng_http_req_set_header(
+    nng_http_req *, const char *, const char *);
+
+// nng_http_req_add_header adds an HTTP header, without disrupting any other
+// with the same name that might have been present.
+NNG_DECL int nng_http_req_add_header(
+    nng_http_req *, const char *, const char *);
+
+// nng_http_req_del_header deletes all occurrences of a named header.
+NNG_DECL int nng_http_req_del_header(nng_http_req *, const char *);
+
+// nng_http_req_get_header looks up a header with the named, returns NULL
+// if not found.
+NNG_DECL const char *nng_http_req_get_header(nng_http_req *, const char *);
+
+// nng_http_req_set_method is used to change the method of a request.
+// The method should be an upper case HTTP method, like POST, or DELETE.
+// Null sets the default ("GET").
+NNG_DECL int nng_http_req_set_method(nng_http_req *, const char *);
+
+// nng_http_req_set_version is used to change the version of a request.
+// Normally the version is "HTTP/1.1".  Note that the framework does
+// not support HTTP/2 at all.  Null sets the default ("HTTP/1.1").
+NNG_DECL int nng_http_req_set_version(nng_http_req *, const char *);
+
+// nng_http_req_set_uri is used to change the URI of a request.  This
+// should be an "abs-uri", that is a path, plus query and fragment if
+// needed.  The scheme, host, and port don't belong here.  The URI should
+// start with a leading '/' per HTTP.
+NNG_DECL int nng_http_req_set_uri(nng_http_req *, const char *);
+
+// nng_http_req_set_data adds entity data to the request.  The
+// data object must persist (so only really useful for static data).
+// The content-length header is updated as well, but the caller should
+// probably set the content-type header.
+NNG_DECL int nng_http_req_set_data(nng_http_req *, const void *, size_t);
+
+// nng_http_req_copy_data adds entity data to the response. A private
+// copy of the data is made (will be freed with the request).
+// The content-length header is updated as well, but the caller should
+// probably set the content-type header.
+NNG_DECL int nng_http_req_copy_data(nng_http_req *, const void *, size_t);
+
+// nng_http_req_get_data gets the data for the response.
+NNG_DECL void nng_http_req_get_data(nng_http_req *, void **, size_t *);
+
+// nng_http_res represents an HTTP response.
+typedef struct nng_http_res nng_http_res;
+
+// nng_http_res_alloc creates a vanilla HTTP response object.  The object is
+// initialized for an HTTP/1.1 200 OK response by default.
+NNG_DECL int nng_http_res_alloc(nng_http_res **);
+
+// nng_http_res_alloc_error creates an error HTTP response object.  The object
+// is initialized for an HTTP/1.1 response, and contains an associated
+// generic HTML error page.
+NNG_DECL int nng_http_res_alloc_error(nng_http_res **, uint16_t);
+
+// nng_http_res_free frees an HTTP response object.
+NNG_DECL void nng_http_res_free(nng_http_res *);
+
+// nng_http_res_get_status returns the HTTP status code from the server.
+NNG_DECL uint16_t nng_http_res_get_status(nng_http_res *);
+
+// nng_http_res_set_status sets the HTTP status code.
+NNG_DECL int nng_http_res_set_status(nng_http_res *, uint16_t);
+
+// nng_http_res_get_reason returns the human readable status message
+// that the server responds (or responded) with.
+NNG_DECL const char *nng_http_res_get_reason(nng_http_res *);
+
+// nng_http_res_set_reason sets the human readable status message.
+// NULL means that a default reason is used based on the status code.
+NNG_DECL int nng_http_res_set_reason(nng_http_res *, const char *);
+
+// nng_http_res_set_header sets an HTTP header, replacing any previous value
+// that might have been present.
+NNG_DECL int nng_http_res_set_header(
+    nng_http_res *, const char *, const char *);
+
+// nng_http_res_add_header adds an HTTP header, without disrupting any other
+// with the same name that might have been present.
+NNG_DECL int nng_http_res_add_header(
+    nng_http_res *, const char *, const char *);
+
+// nng_http_res_del_header deletes all occurrences of a named header.
+NNG_DECL int nng_http_res_del_header(nng_http_res *, const char *);
+
+// nng_http_res_get_header looks up a header with the named, returns NULL
+// if not found.
+NNG_DECL const char *nng_http_res_get_header(nng_http_res *, const char *);
+
+// nng_http_res_set_version is used to change the version of a response.
+// Normally the version is "HTTP/1.1".  Note that the framework does
+// not support HTTP/2 at all.  NULL sets the default ("HTTP/1.1").
+NNG_DECL int nng_http_res_set_version(nng_http_res *, const char *);
+
+// nng_http_res_get_version returns the version, usually HTTP/1.1.
+NNG_DECL const char *nng_http_res_get_version(nng_http_res *);
+
+// nng_http_res_get_data gets the data for the response.
+NNG_DECL void nng_http_res_get_data(nng_http_res *, void **, size_t *);
+
+// nng_http_res_set_data adds entity data to the response.  The
+// data object must persist (so only really useful for static data).
+// The content-length header is updated as well, but the caller should
+// probably set the content-type header.
+NNG_DECL int nng_http_res_set_data(nng_http_res *, const void *, size_t);
+
+// nng_http_res_copy_data adds entity data to the response. A private
+// copy of the data is made (will be freed with the request).
+// The content-length header is updated as well, but the caller should
+// probably set the content-type header.
+NNG_DECL int nng_http_res_copy_data(nng_http_res *, const void *, size_t);
+
+// An nng_http_conn represents an underlying "connection".  It may be
+// a TCP channel, or a TLS channel, but the main thing is that this is
+// normally only used for exchanging HTTP requests and responses.
+typedef struct nng_http_conn nng_http_conn;
+
+// nng_http_conn_close closes the underlying channel.  Applications should
+// not use this channel after this operation is performed.
+NNG_DECL void nng_http_conn_close(nng_http_conn *);
+
+// nng_http_conn_read attempts to read data from the connection.  This
+// completes as soon as at least one byte is read; it does not wait
+// for the entire aio to be filled.
+NNG_DECL void nng_http_conn_read(nng_http_conn *, nng_aio *);
+
+// nng_http_conn_read_all is like nng_http_conn_read, but it does not
+// finish until either all the requested data is read, or an error occurs.
+NNG_DECL void nng_http_conn_read_all(nng_http_conn *, nng_aio *);
+
+// nng_http_conn_write attempts to write data, but it can write less
+// than the amount requested. (It completes as soon as at least one
+// byte is written.)
+NNG_DECL void nng_http_conn_write(nng_http_conn *, nng_aio *);
+
+// nng_http_conn_write_all is like nng_http_conn_write, but it does not
+// finish until either all the requested data is written, or an error occurs.
+NNG_DECL void nng_http_conn_write_all(nng_http_conn *, nng_aio *);
+
+// nng_http_conn_write_req writes the entire request.  It will also write any
+// data that has been attached.
+NNG_DECL void nng_http_conn_write_req(
+    nng_http_conn *, nng_http_req *, nng_aio *);
+
+// nng_http_conn_write_res writes the entire response.  It will also write any
+// data that has been attached.
+NNG_DECL void nng_http_conn_write_res(
+    nng_http_conn *, nng_http_res *, nng_aio *);
+
+// nng_http_conn_read_req reads an entire request, EXCEPT for any entity
+// data.  The caller is responsible for processing the headers in the request
+// and reading any submitted entity data itself.
+NNG_DECL void nng_http_conn_read_req(
+    nng_http_conn *, nng_http_req *, nng_aio *);
+
+// nng_http_conn_read_res reads an entire response, EXCEPT for any entity
+// data.  The caller is responsible for processing the headers in the response
+// and reading any submitted entity data itself.
+NNG_DECL void nng_http_conn_read_res(
+    nng_http_conn *, nng_http_res *, nng_aio *);
+
+// nng_http_req_reset resets the request to an initially allocated state.
+NNG_DECL void nng_http_req_reset(nng_http_req *);
+
+// nng_http_res_reset resets the response to an initially allocated state.
+NNG_DECL void nng_http_res_reset(nng_http_res *);
+
+// nng_http_handler is a handler used on the server side to handle HTTP
+// requests coming into a specific URL.
+typedef struct nng_http_handler nng_http_handler;
+
+// nng_http_handler_alloc creates a server handler object, for the supplied
+// absolute URI (path only) with the callback.  By default the handler
+// is assumed to handle only GET requests (and implictly HEAD requests
+// as well.)
+//
+// Note that methods which modify a handler cannot be called while the handler
+// is registered with the server, and that a handler can only be registered
+// once per server.
+//
+// The callback function will receive the following arguments (via
+// nng_aio_get_input(): nng_http_request *, nng_http_handler *, and
+// nng_http_conn *.  The first is a request object, for convenience.
+// The second is the handler, from which the callback can obtain any other
+// data it has set.  The final is the http connection, which can be used
+// to hijack the session.
+//
+// Upon completion, the handler should store an nng_http_res * as the
+// first output using nng_aio_set_output.  If it does not do so, or supplies
+// NULL, then it must send a response itself.
+//
+// The callback should complete with a result of 0 in most circumstances.
+// If it completes with an error, then the connection is terminated, after
+// possibly sending a 500 error response to the client.
+NNG_DECL int nng_http_handler_alloc(
+    nng_http_handler **, const char *, void (*)(nng_aio *));
+
+// nng_http_handler_free frees the handler. This actually just drops a
+// reference count on the handler, as it may be in use by an existing
+// server.  The server will also call this when it is destroyed.
+NNG_DECL void nng_http_handler_free(nng_http_handler *);
+
+// nng_http_handler_alloc_file creates a "file" based handler, that
+// serves up static content from the given file path.  The content-type
+// supplied is determined from the file name using a simple built-in map.
+NNG_DECL int nng_http_handler_alloc_file(
+    nng_http_handler **, const char *, const char *);
+
+// nng_http_handler_alloc_static creates a static-content handler.
+// The last argument is the content-type, which may be NULL (in which case
+// "application/octet-stream" is assumed.)
+NNG_DECL int nng_http_handler_alloc_static(
+    nng_http_handler **, const char *, const void *, size_t, const char *);
+
+// nng_http_handler_alloc_redirect creates an HTTP redirect handler.
+// The status is given, along with the new URL.  If the status is 0,
+// then 301 will be used instead.
+NNG_DECL int nng_http_handler_alloc_redirect(
+    nng_http_handler **, const char *, uint16_t, const char *);
+
+// nng_http_handler_alloc_file creates a "directory" based handler, that
+// serves up static content from the given directory tree.  Directories
+// that contain an index.html or index.htm file use that file for the
+// directory content, otherwise a suitable error page is returned (the server
+// does not generate index pages automatically.)  The content-type for
+// files is determined from the file name using a simple built-in map.
+NNG_DECL int nng_http_handler_alloc_directory(
+    nng_http_handler **, const char *, const char *);
+
+// nng_http_handler_set_method sets the method that the handler will be
+// called for.  By default this is GET.  If NULL is supplied for the
+// method, then the handler is executed regardless of method, and must
+// inspect the method itself.
+NNG_DECL int nng_http_handler_set_method(nng_http_handler *, const char *);
+
+// nng_http_handler_set_host sets the Host: that the handler will be
+// called for (to allow for virtual hosts).  If the value is NULL (the
+// default, then the Host: header is not considered when matching the
+// handler.)  Note that the Host: header must match *exactly* (except
+// that case is not considered.)
+NNG_DECL int nng_http_handler_set_host(nng_http_handler *, const char *);
+
+// nng_http_handler_collect_body is used to indicate the server should
+// check for, and process, data sent by the client, which will be attached
+// to the request.  If this is false, then the handler will need to check
+// for and process any content data.  By default the server will accept
+// up to 1MB.  If the client attempts to send more data than requested,
+// then a 400 Bad Request will be sent back to the client.  To set an
+// unlimited value, use (size_t)-1.  To preclude the client from sending
+// *any* data, use 0.  (The static and file handlers use 0 by default.)
+NNG_DECL int nng_http_handler_collect_body(nng_http_handler *, bool, size_t);
+
+// nng_http_handler_set_tree indicates that the handler is being registered
+// for a hierarchical tree, rather than just a single path, so it will be
+// called for all child paths supplied.  By default the handler is only
+// called for an exact path match.
+NNG_DECL int nng_http_handler_set_tree(nng_http_handler *);
+
+// nng_http_handler_set_tree_exclusive indicates that the handler is being
+// registered for a heirarchical tree *exclusively*, rather than just a single
+// path, so it will be called for all child paths supplied. By default the
+// handler is only called for an exact path match. Exclusive means that any
+// other handler on a conflicting path will induce an address conflict error
+// when added to a server.
+NNG_DECL int nng_http_handler_set_tree_exclusive(nng_http_handler *);
+
+// nng_http_handler_set_data is used to store additional data, along with
+// a possible clean up routine.  (The clean up is a custom de-allocator and
+// will be called with the supplied data as an argument, when the handler
+// is being de-allocated.)
+NNG_DECL int nng_http_handler_set_data(
+    nng_http_handler *, void *, void (*)(void *));
+
+// nng_http_handler_get_data returns the data that was previously stored.
+NNG_DECL void *nng_http_handler_get_data(nng_http_handler *);
+
+// nng_http_server is a handle to an HTTP server instance.  Servers
+// only serve a single port / address at this time.
+
+typedef struct nng_http_server nng_http_server;
+
+// nng_http_server_hold gets a server structure, using the address determined
+// from the URL.  If a server already exists, then a hold is placed on it, and
+// that instance is returned.  If no such server exists, then a new instance
+// is created.
+NNG_DECL int nng_http_server_hold(nng_http_server **, const nng_url *);
+
+// nng_http_server_release releases the hold on the server.  If this is the
+// last instance of the server, then it is shutdown and resources are freed.
+NNG_DECL void nng_http_server_release(nng_http_server *);
+
+// nng_http_server_start starts the server handling HTTP.  Once this is
+// called, it will not be possible to change certain parameters (such as
+// any TLS configuration).
+NNG_DECL int nng_http_server_start(nng_http_server *);
+
+// nng_http_server_stop stops the server.  No new client connections are
+// accepted after this returns.  Once a server is stopped fully, the
+// instance will no longer be returned by nng_http_server_hold, as the
+// server may not be reused.
+NNG_DECL void nng_http_server_stop(nng_http_server *);
+
+// nng_http_server_add_handler registers a handler on the server.
+// This function will return NNG_EADDRINUSE if a conflicting handler
+// is already registered (i.e. a handler with the same value for Host,
+// Method, and URL.)
+NNG_DECL int nng_http_server_add_handler(
+    nng_http_server *, nng_http_handler *);
+
+// nni_http_del_handler removes the given handler.  The caller is
+// responsible for finalizing it afterwards.  If the handler was not found
+// (not registered), NNG_ENOENT is returned.  In this case it is unsafe
+// to make assumptions about the validity of the handler.
+NNG_DECL int nng_http_server_del_handler(
+    nng_http_server *, nng_http_handler *);
+
+// nng_http_server_set_tls adds a TLS configuration to the server,
+// and enables the use of it.  This returns NNG_EBUSY if the server is
+// already started.   This wipes out the entire TLS configuration on the
+// server client, so the caller must have configured it reasonably.
+// This API is not recommended unless the caller needs complete control
+// over the TLS configuration.
+NNG_DECL int nng_http_server_set_tls(
+    nng_http_server *, struct nng_tls_config *);
+
+// nng_http_server_get_tls obtains the TLS configuration if one is present,
+// or returns NNG_EINVAL.  The TLS configuration is invalidated if the
+// nng_http_server_set_tls function is called, so be careful.
+NNG_DECL int nng_http_server_get_tls(
+    nng_http_server *, struct nng_tls_config **);
+
+// nng_http_server_get_addr obtains the address with which the server was
+// initialized or returns NNG_EINVAL. Useful for instance when the port has
+// been automatically assigned.
+NNG_DECL int nng_http_server_get_addr(nng_http_server *, nng_sockaddr *);
+
+// nng_http_server_set_error_page sets a custom error page (HTML) content
+// to be sent for the given error code.  This is used when the error is
+// generated internally by the framework, or when the application returns
+// the response back to the server via the handler's aio, and the response
+// was allocated with nng_http_res_alloc_error.  If the response was not
+// allocated this way, or the application writes the response itself instead
+// of letting the server do so, then this setting will be ignored.
+NNG_DECL int nng_http_server_set_error_page(
+    nng_http_server *, uint16_t, const char *);
+
+// nng_http_server_set_error_file works like nng_http_server_error_page,
+// except that the content is loaded from the named file path.  The contents
+// are loaded at the time this function is called, so this function should be
+// called anytime the contents of the named file have changed.
+NNG_DECL int nng_http_server_set_error_file(
+    nng_http_server *, uint16_t, const char *);
+
+// nng_http_server_res_error takes replaces the body of the response with
+// a custom error page previously set for the server, using the status
+// of the response.  The response must have the status set first using
+// nng_http_res_set_status or implicitly via nng_http_res_alloc_error.
+NNG_DECL int nng_http_server_res_error(nng_http_server *, nng_http_res *);
+
+// nng_http_hijack is intended to be called by a handler that wishes to
+// take over the processing of the HTTP session -- usually to change protocols
+// (such as in the case of websocket).  The caller is responsible for the
+// final disposal of the associated nng_http_conn.  Also, this completely
+// disassociates the http session from the server, so the server may be
+// stopped or destroyed without affecting the hijacked session.  Note also
+// that the hijacker will need to issue any HTTP reply itself.  Finally,
+// when a session is hijacked, the caller is also responsible for disposing
+// of the request structure.  (Some hijackers may keep the request for
+// further processing.)
+
+NNG_DECL int nng_http_hijack(nng_http_conn *);
+
+// nng_http_client represents a "client" object.  Clients can be used
+// to create HTTP connections.  At present, connections are not cached
+// or reused, but that could change in the future.
+typedef struct nng_http_client nng_http_client;
+
+// nng_http_client_alloc allocates a client object, associated with
+// the given URL.
+NNG_DECL int nng_http_client_alloc(nng_http_client **, const nng_url *);
+
+// nng_http_client_free frees the client.  Connections created by the
+// the client are not necessarily closed.
+NNG_DECL void nng_http_client_free(nng_http_client *);
+
+// nng_http_client_set_tls sets the TLS configuration.  This wipes out
+// the entire TLS configuration on the client, so the caller must have
+// configured it reasonably.  This API is not recommended unless the
+// caller needs complete control over the TLS configuration.
+NNG_DECL int nng_http_client_set_tls(
+    nng_http_client *, struct nng_tls_config *);
+
+// nng_http_client_get_tls obtains the TLS configuration if one is present,
+// or returns NNG_EINVAL.  The supplied TLS configuration object may
+// be invalidated by any future calls to nni_http_client_set_tls.
+NNG_DECL int nng_http_client_get_tls(
+    nng_http_client *, struct nng_tls_config **);
+
+// nng_http_client_connect establishes a new connection with the server
+// named in the URL used when the client was created.  Once the connection
+// is established, the associated nng_http_conn object pointer is returned
+// in the first (index 0) output for the aio.
+NNG_DECL void nng_http_client_connect(nng_http_client *, nng_aio *);
+
+// nng_http_conn_transact is used to perform a round-trip exchange (i.e. a
+// single HTTP transaction).  It will not automatically close the connection,
+// unless some kind of significant error occurs.  The caller should close
+// the connection if the aio does not complete successfully.
+NNG_DECL void nng_http_conn_transact(
+    nng_http_conn *, nng_http_req *, nng_http_res *, nng_aio *);
+
+// nng_http_client_transact is used to execute a single transaction to a
+// server. The connection is opened, and will be closed when the transaction is
+// complete.
+NNG_DECL void nng_http_client_transact(
+    nng_http_client *, nng_http_req *, nng_http_res *, nng_aio *);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_H
```

## skdecide/hub/include/nng/supplemental/tls/engine.h

 * *Ordering differences only*

```diff
@@ -1,215 +1,215 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-// This file is used to enable external TLS "engines", so
-// that third party TLS libraries can be plugged in
-
-#ifndef NNG_SUPPLEMENTAL_TLS_ENGINE_H
-#define NNG_SUPPLEMENTAL_TLS_ENGINE_H
-
-#include <nng/supplemental/tls/tls.h>
-
-// Locking theory statement for TLS engines.  The engine is assumed
-// operate only from the context of threads called by the common
-// framework.  That is to say, the callbacks made by the engine
-// should always be on a thread that has context from the framework
-// calling into the engine.  This means that the lower level send
-// and receive functions can assume that they have lock ownership
-// inherited on the stack.
-
-// nng_tls_engine_conn represents the engine-specific private
-// state for a TLS connection.  It is provided here for type
-// safety.  Engine implementations should provide the structure
-// definition locally.
-typedef struct nng_tls_engine_conn nng_tls_engine_conn;
-
-// nng_tls_engine_config represents the engine-specific private
-// state for the TLS configuration.  It is provided here for type
-// safety.  Engine implementations should provide the structure
-// definition locally.
-typedef struct nng_tls_engine_config nng_tls_engine_config;
-
-typedef struct nng_tls_engine_conn_ops_s {
-	// size is the size of the engine's per-connection state.
-	// The framework will allocate this on behalf of the engine.
-	// Typically this will be sizeof (struct nng_tls_engine_conn).
-	size_t size;
-
-	// init is used to initialize a connection object.
-	// The passed in connection state will be aligned naturally,
-	// and zeroed.  On success this returns 0, else an NNG error code.
-	int (*init)(nng_tls_engine_conn *, void *, nng_tls_engine_config *);
-
-	// fini destroys a connection object.  This will
-	// be called only when no other external use of the connection
-	// object exists, and only on fully initialed connection objects.
-	void (*fini)(nng_tls_engine_conn *);
-
-	// close closes the connection object, but should not
-	// deallocate any memory.  It may also issue a TLS close-notify.
-	void (*close)(nng_tls_engine_conn *);
-
-	// handshake attempts to complete the SSL handshake phase.
-	// It returns zero on success, or an error if one occurred.
-	// The value NNG_EAGAIN should be returned if underlying I/O
-	// is required to be completed first.  The framework will
-	// ensure that the handshake completes before sending any data
-	// down.
-	int (*handshake)(nng_tls_engine_conn *);
-
-	// recv attempts to read data (decrypted) from the connection.
-	// It returns 0 on success, otherwise an error.  The implementation
-	// should return NNG_EAGAIN if I/O to the underlying stream is
-	// required to complete the operation.  On success, the count
-	// is updated to reflect the number of bytes actually received.
-	int (*recv)(nng_tls_engine_conn *, uint8_t *, size_t *);
-
-	// send attempts to write data to the underlying connection.
-	// It returns zero on success, otherwise an error. The implementation
-	// should return NNG_EAGAIN if I/O to the underlying stream is
-	// required to complete the operation.  On success, the count
-	// is updated to reflect the number of bytes actually sent.
-	int (*send)(nng_tls_engine_conn *, const uint8_t *, size_t *);
-
-	// verified returns true if the connection is fully
-	// TLS verified, false otherwise.
-	bool (*verified)(nng_tls_engine_conn *);
-
-	// peer_cn returns the common name of the peer
-	// The return string needs to be freed.
-	char *(*peer_cn)(nng_tls_engine_conn *);
-
-	// peer_alt_names returns the subject alternative names.
-	// The return string list and its strings need to be freed.
-	char **(*peer_alt_names)(nng_tls_engine_conn *);
-} nng_tls_engine_conn_ops;
-
-typedef struct nng_tls_engine_config_ops_s {
-	// size is the size of the engine's configuration object.
-	// The framework will allocate this on behalf of the engine.
-	// Typically this will be sizeof (struct nng_tls_engine_config).
-	size_t size;
-
-	// init prepares the configuration object object.
-	// The mode indicates whether the object should be
-	// initialized for use as a TLS server or client.
-	// The config passed in will be aligned on a 64-bit boundary,
-	// and will be initialized to zero.  On success this returns
-	// 0, else an NNG error code.
-	int (*init)(nng_tls_engine_config *, nng_tls_mode);
-
-	// fini is used to tear down the configuration object.
-	// This will only be called on objects that have been properly
-	// initialized with nte_config_init.
-	void (*fini)(nng_tls_engine_config *);
-
-	// server is used to set the server name.  This can be used in SNI,
-	// and will also be used on the client to validate the identity.
-	// If this is not set, then no verification will be performed.
-	int (*server)(nng_tls_engine_config *, const char *);
-
-	// auth is used to configure the authentication mode.  Values:
-	// NNG_AUTH_MODE_NONE
-	//   No validation of the peer is performed.  Public facing
-	//   servers often use this.
-	// NNG_AUTH_MODE_OPTIONAL
-	//   The peer's identity is validated if a certificate is presented.
-	//   This is typically useful on servers.
-	// NNG_AUTH_MODE_REQUIRED
-	//   The peer's certificate must be present and is verified.
-	//   This is standard for the client, and on servers it is used
-	//   when client (mutual) authentication is needed.
-	int (*auth)(nng_tls_engine_config *, nng_tls_auth_mode);
-
-	// ca_chain sets the configuration authorities that will be
-	// used to validate peers.  An optional CRL is supplied as well.
-	// Both values are C strings (NUL terminated) containing
-	// PEM data.  There may be multiple PEM blocks.  The
-	// CRL may be NULL if not needed.
-	int (*ca_chain)(nng_tls_engine_config *, const char *, const char *);
-
-	// own_cert configures our identity -- the certificate containing
-	// our public key, our private key (which might be encrypted), and
-	// potentially a password used to decrypt the private key.
-	// All of these are C strings.  The cert may actually be a chain
-	// which will be presented to our peer.   This function may be
-	// called multiple times to register different keys with different
-	// parameters on a server.  (For example, once for RSA parameters,
-	// and again later with EC parameters.)  The certificate and the
-	// private key may be presented in the same file.  The implementation
-	// is responsible for parsing out the relevant data.  If the password
-	// is NULL, then the key file should be unencrypted.  The supplied
-	// password may be ignored if the key is not encrypted.  Not all
-	// engine implementations need support encryption of the key.
-	int (*own_cert)(
-	    nng_tls_engine_config *, const char *, const char *, const char *);
-
-	// version configures the minimum and maximum TLS versions.  The
-	// engine should default to supporting TLS1.0 through 1.2, and
-	// optionally 1.3 if it can.  The engine should restrict the
-	// the requested range to what it can support -- if no version
-	// within the range is supported (such as if NNG_TLS_1_3 is
-	// specified for both min and max, and the engine lacks support
-	// for v1.3, then NNG_ENOTSUP should be returned.
-	int (*version)(
-	    nng_tls_engine_config *, nng_tls_version, nng_tls_version);
-} nng_tls_engine_config_ops;
-
-typedef enum nng_tls_engine_version_e {
-	NNG_TLS_ENGINE_V0      = 0,
-	NNG_TLS_ENGINE_V1      = 1,
-	NNG_TLS_ENGINE_VERSION = NNG_TLS_ENGINE_V1,
-} nng_tls_engine_version;
-
-typedef struct nng_tls_engine_s {
-	// _version is the engine version.  This for now must
-	// be NNG_TLS_ENGINE_VERSION.  If the version does not match
-	// then registration of the engine will fail.
-	nng_tls_engine_version version;
-
-	// config_ops is the operations for TLS configuration objects.
-	nng_tls_engine_config_ops *config_ops;
-
-	// conn_ops is the operations for TLS connections (stream-oriented).
-	nng_tls_engine_conn_ops *conn_ops;
-
-	// name contains the name of the engine, for example "wolfSSL".
-	// It is acceptable to append a version number as well.
-	const char *name;
-
-	// description contains a human readable description.  This can
-	// supply information about the backing library, for example
-	// "mbed TLS v2.7"
-	const char *description;
-
-	// fips_mode is true if the engine is in FIPS mode.
-	// It is expected that this will be enabled either at compile
-	// time, or via environment variables at engine initialization.
-	// FIPS mode cannot be changed once the engine is registered.
-	bool fips_mode;
-} nng_tls_engine;
-
-NNG_DECL int nng_tls_engine_register(const nng_tls_engine *);
-
-// nng_tls_engine_send is called by the engine to send data over the
-// underlying connection.  It returns zero on success, NNG_EAGAIN if
-// the operation can't be completed yet (the transport is busy and cannot
-// accept more data yet), or some other error.  On success the count is
-// updated with the number of bytes actually sent.  The first argument
-// is the context structure passed in when starting the engine.
-NNG_DECL int nng_tls_engine_send(void *, const uint8_t *, size_t *);
-
-// nng_tls_engine_recv is called byu the engine to receive data over
-// the underlying connection.  It returns zero on success, NNG_EAGAIN
-// if the operation can't be completed yet (there is no data available
-// for reading), or some other error.  On success the count is updated
-// with the number of bytes actually received.
-NNG_DECL int nng_tls_engine_recv(void *, uint8_t *, size_t *);
-
-#endif // NNG_SUPPLEMENTAL_TLS_ENGINE_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+// This file is used to enable external TLS "engines", so
+// that third party TLS libraries can be plugged in
+
+#ifndef NNG_SUPPLEMENTAL_TLS_ENGINE_H
+#define NNG_SUPPLEMENTAL_TLS_ENGINE_H
+
+#include <nng/supplemental/tls/tls.h>
+
+// Locking theory statement for TLS engines.  The engine is assumed
+// operate only from the context of threads called by the common
+// framework.  That is to say, the callbacks made by the engine
+// should always be on a thread that has context from the framework
+// calling into the engine.  This means that the lower level send
+// and receive functions can assume that they have lock ownership
+// inherited on the stack.
+
+// nng_tls_engine_conn represents the engine-specific private
+// state for a TLS connection.  It is provided here for type
+// safety.  Engine implementations should provide the structure
+// definition locally.
+typedef struct nng_tls_engine_conn nng_tls_engine_conn;
+
+// nng_tls_engine_config represents the engine-specific private
+// state for the TLS configuration.  It is provided here for type
+// safety.  Engine implementations should provide the structure
+// definition locally.
+typedef struct nng_tls_engine_config nng_tls_engine_config;
+
+typedef struct nng_tls_engine_conn_ops_s {
+	// size is the size of the engine's per-connection state.
+	// The framework will allocate this on behalf of the engine.
+	// Typically this will be sizeof (struct nng_tls_engine_conn).
+	size_t size;
+
+	// init is used to initialize a connection object.
+	// The passed in connection state will be aligned naturally,
+	// and zeroed.  On success this returns 0, else an NNG error code.
+	int (*init)(nng_tls_engine_conn *, void *, nng_tls_engine_config *);
+
+	// fini destroys a connection object.  This will
+	// be called only when no other external use of the connection
+	// object exists, and only on fully initialed connection objects.
+	void (*fini)(nng_tls_engine_conn *);
+
+	// close closes the connection object, but should not
+	// deallocate any memory.  It may also issue a TLS close-notify.
+	void (*close)(nng_tls_engine_conn *);
+
+	// handshake attempts to complete the SSL handshake phase.
+	// It returns zero on success, or an error if one occurred.
+	// The value NNG_EAGAIN should be returned if underlying I/O
+	// is required to be completed first.  The framework will
+	// ensure that the handshake completes before sending any data
+	// down.
+	int (*handshake)(nng_tls_engine_conn *);
+
+	// recv attempts to read data (decrypted) from the connection.
+	// It returns 0 on success, otherwise an error.  The implementation
+	// should return NNG_EAGAIN if I/O to the underlying stream is
+	// required to complete the operation.  On success, the count
+	// is updated to reflect the number of bytes actually received.
+	int (*recv)(nng_tls_engine_conn *, uint8_t *, size_t *);
+
+	// send attempts to write data to the underlying connection.
+	// It returns zero on success, otherwise an error. The implementation
+	// should return NNG_EAGAIN if I/O to the underlying stream is
+	// required to complete the operation.  On success, the count
+	// is updated to reflect the number of bytes actually sent.
+	int (*send)(nng_tls_engine_conn *, const uint8_t *, size_t *);
+
+	// verified returns true if the connection is fully
+	// TLS verified, false otherwise.
+	bool (*verified)(nng_tls_engine_conn *);
+
+	// peer_cn returns the common name of the peer
+	// The return string needs to be freed.
+	char *(*peer_cn)(nng_tls_engine_conn *);
+
+	// peer_alt_names returns the subject alternative names.
+	// The return string list and its strings need to be freed.
+	char **(*peer_alt_names)(nng_tls_engine_conn *);
+} nng_tls_engine_conn_ops;
+
+typedef struct nng_tls_engine_config_ops_s {
+	// size is the size of the engine's configuration object.
+	// The framework will allocate this on behalf of the engine.
+	// Typically this will be sizeof (struct nng_tls_engine_config).
+	size_t size;
+
+	// init prepares the configuration object object.
+	// The mode indicates whether the object should be
+	// initialized for use as a TLS server or client.
+	// The config passed in will be aligned on a 64-bit boundary,
+	// and will be initialized to zero.  On success this returns
+	// 0, else an NNG error code.
+	int (*init)(nng_tls_engine_config *, nng_tls_mode);
+
+	// fini is used to tear down the configuration object.
+	// This will only be called on objects that have been properly
+	// initialized with nte_config_init.
+	void (*fini)(nng_tls_engine_config *);
+
+	// server is used to set the server name.  This can be used in SNI,
+	// and will also be used on the client to validate the identity.
+	// If this is not set, then no verification will be performed.
+	int (*server)(nng_tls_engine_config *, const char *);
+
+	// auth is used to configure the authentication mode.  Values:
+	// NNG_AUTH_MODE_NONE
+	//   No validation of the peer is performed.  Public facing
+	//   servers often use this.
+	// NNG_AUTH_MODE_OPTIONAL
+	//   The peer's identity is validated if a certificate is presented.
+	//   This is typically useful on servers.
+	// NNG_AUTH_MODE_REQUIRED
+	//   The peer's certificate must be present and is verified.
+	//   This is standard for the client, and on servers it is used
+	//   when client (mutual) authentication is needed.
+	int (*auth)(nng_tls_engine_config *, nng_tls_auth_mode);
+
+	// ca_chain sets the configuration authorities that will be
+	// used to validate peers.  An optional CRL is supplied as well.
+	// Both values are C strings (NUL terminated) containing
+	// PEM data.  There may be multiple PEM blocks.  The
+	// CRL may be NULL if not needed.
+	int (*ca_chain)(nng_tls_engine_config *, const char *, const char *);
+
+	// own_cert configures our identity -- the certificate containing
+	// our public key, our private key (which might be encrypted), and
+	// potentially a password used to decrypt the private key.
+	// All of these are C strings.  The cert may actually be a chain
+	// which will be presented to our peer.   This function may be
+	// called multiple times to register different keys with different
+	// parameters on a server.  (For example, once for RSA parameters,
+	// and again later with EC parameters.)  The certificate and the
+	// private key may be presented in the same file.  The implementation
+	// is responsible for parsing out the relevant data.  If the password
+	// is NULL, then the key file should be unencrypted.  The supplied
+	// password may be ignored if the key is not encrypted.  Not all
+	// engine implementations need support encryption of the key.
+	int (*own_cert)(
+	    nng_tls_engine_config *, const char *, const char *, const char *);
+
+	// version configures the minimum and maximum TLS versions.  The
+	// engine should default to supporting TLS1.0 through 1.2, and
+	// optionally 1.3 if it can.  The engine should restrict the
+	// the requested range to what it can support -- if no version
+	// within the range is supported (such as if NNG_TLS_1_3 is
+	// specified for both min and max, and the engine lacks support
+	// for v1.3, then NNG_ENOTSUP should be returned.
+	int (*version)(
+	    nng_tls_engine_config *, nng_tls_version, nng_tls_version);
+} nng_tls_engine_config_ops;
+
+typedef enum nng_tls_engine_version_e {
+	NNG_TLS_ENGINE_V0      = 0,
+	NNG_TLS_ENGINE_V1      = 1,
+	NNG_TLS_ENGINE_VERSION = NNG_TLS_ENGINE_V1,
+} nng_tls_engine_version;
+
+typedef struct nng_tls_engine_s {
+	// _version is the engine version.  This for now must
+	// be NNG_TLS_ENGINE_VERSION.  If the version does not match
+	// then registration of the engine will fail.
+	nng_tls_engine_version version;
+
+	// config_ops is the operations for TLS configuration objects.
+	nng_tls_engine_config_ops *config_ops;
+
+	// conn_ops is the operations for TLS connections (stream-oriented).
+	nng_tls_engine_conn_ops *conn_ops;
+
+	// name contains the name of the engine, for example "wolfSSL".
+	// It is acceptable to append a version number as well.
+	const char *name;
+
+	// description contains a human readable description.  This can
+	// supply information about the backing library, for example
+	// "mbed TLS v2.7"
+	const char *description;
+
+	// fips_mode is true if the engine is in FIPS mode.
+	// It is expected that this will be enabled either at compile
+	// time, or via environment variables at engine initialization.
+	// FIPS mode cannot be changed once the engine is registered.
+	bool fips_mode;
+} nng_tls_engine;
+
+NNG_DECL int nng_tls_engine_register(const nng_tls_engine *);
+
+// nng_tls_engine_send is called by the engine to send data over the
+// underlying connection.  It returns zero on success, NNG_EAGAIN if
+// the operation can't be completed yet (the transport is busy and cannot
+// accept more data yet), or some other error.  On success the count is
+// updated with the number of bytes actually sent.  The first argument
+// is the context structure passed in when starting the engine.
+NNG_DECL int nng_tls_engine_send(void *, const uint8_t *, size_t *);
+
+// nng_tls_engine_recv is called byu the engine to receive data over
+// the underlying connection.  It returns zero on success, NNG_EAGAIN
+// if the operation can't be completed yet (there is no data available
+// for reading), or some other error.  On success the count is updated
+// with the number of bytes actually received.
+NNG_DECL int nng_tls_engine_recv(void *, uint8_t *, size_t *);
+
+#endif // NNG_SUPPLEMENTAL_TLS_ENGINE_H
```

## skdecide/hub/include/nng/supplemental/tls/tls.h

 * *Ordering differences only*

```diff
@@ -1,142 +1,142 @@
-//
-// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_SUPPLEMENTAL_TLS_TLS_H
-#define NNG_SUPPLEMENTAL_TLS_TLS_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stddef.h>
-#include <stdint.h>
-
-// Note that TLS functions may be stubbed out if TLS is not enabled in
-// the build.
-
-// For some transports, we need TLS configuration, including certificates
-// and so forth.  A TLS configuration cannot be changed once it is in use.
-typedef struct nng_tls_config nng_tls_config;
-
-typedef enum nng_tls_mode {
-	NNG_TLS_MODE_CLIENT = 0,
-	NNG_TLS_MODE_SERVER = 1,
-} nng_tls_mode;
-
-typedef enum nng_tls_auth_mode {
-	NNG_TLS_AUTH_MODE_NONE     = 0, // No verification is performed
-	NNG_TLS_AUTH_MODE_OPTIONAL = 1, // Verify cert if presented
-	NNG_TLS_AUTH_MODE_REQUIRED = 2, // Verify cert, close if invalid
-} nng_tls_auth_mode;
-
-// TLS version numbers.  We encode the major number and minor number
-// as separate byte fields.  No support for SSL 3.0 or earlier -- older
-// versions are known to be insecure and should not be used.
-// When possible applications should restrict themselves to TLS 1.2 or better.
-typedef enum nng_tls_version {
-	NNG_TLS_1_0 = 0x301,
-	NNG_TLS_1_1 = 0x302,
-	NNG_TLS_1_2 = 0x303,
-	NNG_TLS_1_3 = 0x304
-} nng_tls_version;
-
-// nng_tls_config_alloc creates a TLS configuration using
-// reasonable defaults.  This configuration can be shared
-// with multiple pipes or services/servers.
-NNG_DECL int nng_tls_config_alloc(nng_tls_config **, nng_tls_mode);
-
-// nng_tls_config_hold increments the reference count on the TLS
-// configuration object.  The hold can be dropped by calling
-// nng_tls_config_free later.
-NNG_DECL void nng_tls_config_hold(nng_tls_config *);
-
-// nng_tls_config_free drops the reference count on the TLS
-// configuration object, and if zero, deallocates it.
-NNG_DECL void nng_tls_config_free(nng_tls_config *);
-
-// nng_tls_config_server_name sets the server name.  This is
-// called by clients to set the name that the server supplied
-// certificate should be matched against.  This can also cause
-// the SNI to be sent to the server to tell it which cert to
-// use if it supports more than one.
-NNG_DECL int nng_tls_config_server_name(nng_tls_config *, const char *);
-
-// nng_tls_config_ca_cert configures one or more CAs used for validation
-// of peer certificates.  Multiple CAs (and their chains) may be configured
-// by either calling this multiple times, or by specifying a list of
-// certificates as concatenated data.  The final argument is an optional CRL
-// (revocation list) for the CA, also in PEM.  Both PEM strings are ASCIIZ
-// format (except that the CRL may be NULL).
-NNG_DECL int nng_tls_config_ca_chain(
-    nng_tls_config *, const char *, const char *);
-
-// nng_tls_config_own_cert is used to load our own certificate and public
-// key.  For servers, this may be called more than once to configure multiple
-// different keys, for example with different algorithms depending on what
-// the peer supports. On the client, only a single option is available.
-// The first two arguments are the cert (or validation chain) and the
-// key as PEM format ASCIIZ strings.  The final argument is an optional
-// password and may be NULL.
-NNG_DECL int nng_tls_config_own_cert(
-    nng_tls_config *, const char *, const char *, const char *);
-
-// nng_tls_config_key is used to pass our own private key.
-NNG_DECL int nng_tls_config_key(nng_tls_config *, const uint8_t *, size_t);
-
-// nng_tls_config_pass is used to pass a password used to decrypt
-// private keys that are encrypted.
-NNG_DECL int nng_tls_config_pass(nng_tls_config *, const char *);
-
-// nng_tls_config_auth_mode is used to configure the authentication mode use.
-// The default is that servers have this off (i.e. no client authentication)
-// and clients have it on (they verify the server), which matches typical
-// practice.
-NNG_DECL int nng_tls_config_auth_mode(nng_tls_config *, nng_tls_auth_mode);
-
-// nng_tls_config_ca_file is used to pass a CA chain and optional CRL
-// via the filesystem.  If CRL data is present, it must be contained
-// in the file, along with the CA certificate data.  The format is PEM.
-// The path name must be a legal file name.
-NNG_DECL int nng_tls_config_ca_file(nng_tls_config *, const char *);
-
-// nng_tls_config_cert_key_file is used to pass our own certificate and
-// private key data via the filesystem.  Both the key and certificate
-// must be present as PEM blocks in the same file.  A password is used to
-// decrypt the private key if it is encrypted and the password supplied is not
-// NULL. This may be called multiple times on servers, but only once on a
-// client. (Servers can support multiple different certificates and keys for
-// different cryptographic algorithms.  Clients only get one.)
-NNG_DECL int nng_tls_config_cert_key_file(
-    nng_tls_config *, const char *, const char *);
-
-// Configure supported TLS version.  By default we usually restrict
-// ourselves to TLS 1.2 and newer.  We do not support older versions.
-// If the implementation cannot support any version (for example if
-// the minimum requested is 1.3 but the TLS implementation lacks support
-// for TLS 1.3) then NNG_ENOTSUP will be returned.
-NNG_DECL int nng_tls_config_version(
-    nng_tls_config *, nng_tls_version, nng_tls_version);
-
-// nng_tls_engine_name returns the "name" of the TLS engine.  If no
-// TLS engine support is enabled, then "none" is returned.
-NNG_DECL const char *nng_tls_engine_name(void);
-
-// nng_tls_engine_description returns the "description" of the TLS engine.
-// If no TLS engine support is enabled, then an empty string is returned.
-NNG_DECL const char *nng_tls_engine_description(void);
-
-// nng_tls_engine_fips_mode returns true if the engine is in FIPS 140-2 mode.
-NNG_DECL bool nng_tls_engine_fips_mode(void);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_SUPPLEMENTAL_TLS_TLS_H
+//
+// Copyright 2020 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_SUPPLEMENTAL_TLS_TLS_H
+#define NNG_SUPPLEMENTAL_TLS_TLS_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <stddef.h>
+#include <stdint.h>
+
+// Note that TLS functions may be stubbed out if TLS is not enabled in
+// the build.
+
+// For some transports, we need TLS configuration, including certificates
+// and so forth.  A TLS configuration cannot be changed once it is in use.
+typedef struct nng_tls_config nng_tls_config;
+
+typedef enum nng_tls_mode {
+	NNG_TLS_MODE_CLIENT = 0,
+	NNG_TLS_MODE_SERVER = 1,
+} nng_tls_mode;
+
+typedef enum nng_tls_auth_mode {
+	NNG_TLS_AUTH_MODE_NONE     = 0, // No verification is performed
+	NNG_TLS_AUTH_MODE_OPTIONAL = 1, // Verify cert if presented
+	NNG_TLS_AUTH_MODE_REQUIRED = 2, // Verify cert, close if invalid
+} nng_tls_auth_mode;
+
+// TLS version numbers.  We encode the major number and minor number
+// as separate byte fields.  No support for SSL 3.0 or earlier -- older
+// versions are known to be insecure and should not be used.
+// When possible applications should restrict themselves to TLS 1.2 or better.
+typedef enum nng_tls_version {
+	NNG_TLS_1_0 = 0x301,
+	NNG_TLS_1_1 = 0x302,
+	NNG_TLS_1_2 = 0x303,
+	NNG_TLS_1_3 = 0x304
+} nng_tls_version;
+
+// nng_tls_config_alloc creates a TLS configuration using
+// reasonable defaults.  This configuration can be shared
+// with multiple pipes or services/servers.
+NNG_DECL int nng_tls_config_alloc(nng_tls_config **, nng_tls_mode);
+
+// nng_tls_config_hold increments the reference count on the TLS
+// configuration object.  The hold can be dropped by calling
+// nng_tls_config_free later.
+NNG_DECL void nng_tls_config_hold(nng_tls_config *);
+
+// nng_tls_config_free drops the reference count on the TLS
+// configuration object, and if zero, deallocates it.
+NNG_DECL void nng_tls_config_free(nng_tls_config *);
+
+// nng_tls_config_server_name sets the server name.  This is
+// called by clients to set the name that the server supplied
+// certificate should be matched against.  This can also cause
+// the SNI to be sent to the server to tell it which cert to
+// use if it supports more than one.
+NNG_DECL int nng_tls_config_server_name(nng_tls_config *, const char *);
+
+// nng_tls_config_ca_cert configures one or more CAs used for validation
+// of peer certificates.  Multiple CAs (and their chains) may be configured
+// by either calling this multiple times, or by specifying a list of
+// certificates as concatenated data.  The final argument is an optional CRL
+// (revocation list) for the CA, also in PEM.  Both PEM strings are ASCIIZ
+// format (except that the CRL may be NULL).
+NNG_DECL int nng_tls_config_ca_chain(
+    nng_tls_config *, const char *, const char *);
+
+// nng_tls_config_own_cert is used to load our own certificate and public
+// key.  For servers, this may be called more than once to configure multiple
+// different keys, for example with different algorithms depending on what
+// the peer supports. On the client, only a single option is available.
+// The first two arguments are the cert (or validation chain) and the
+// key as PEM format ASCIIZ strings.  The final argument is an optional
+// password and may be NULL.
+NNG_DECL int nng_tls_config_own_cert(
+    nng_tls_config *, const char *, const char *, const char *);
+
+// nng_tls_config_key is used to pass our own private key.
+NNG_DECL int nng_tls_config_key(nng_tls_config *, const uint8_t *, size_t);
+
+// nng_tls_config_pass is used to pass a password used to decrypt
+// private keys that are encrypted.
+NNG_DECL int nng_tls_config_pass(nng_tls_config *, const char *);
+
+// nng_tls_config_auth_mode is used to configure the authentication mode use.
+// The default is that servers have this off (i.e. no client authentication)
+// and clients have it on (they verify the server), which matches typical
+// practice.
+NNG_DECL int nng_tls_config_auth_mode(nng_tls_config *, nng_tls_auth_mode);
+
+// nng_tls_config_ca_file is used to pass a CA chain and optional CRL
+// via the filesystem.  If CRL data is present, it must be contained
+// in the file, along with the CA certificate data.  The format is PEM.
+// The path name must be a legal file name.
+NNG_DECL int nng_tls_config_ca_file(nng_tls_config *, const char *);
+
+// nng_tls_config_cert_key_file is used to pass our own certificate and
+// private key data via the filesystem.  Both the key and certificate
+// must be present as PEM blocks in the same file.  A password is used to
+// decrypt the private key if it is encrypted and the password supplied is not
+// NULL. This may be called multiple times on servers, but only once on a
+// client. (Servers can support multiple different certificates and keys for
+// different cryptographic algorithms.  Clients only get one.)
+NNG_DECL int nng_tls_config_cert_key_file(
+    nng_tls_config *, const char *, const char *);
+
+// Configure supported TLS version.  By default we usually restrict
+// ourselves to TLS 1.2 and newer.  We do not support older versions.
+// If the implementation cannot support any version (for example if
+// the minimum requested is 1.3 but the TLS implementation lacks support
+// for TLS 1.3) then NNG_ENOTSUP will be returned.
+NNG_DECL int nng_tls_config_version(
+    nng_tls_config *, nng_tls_version, nng_tls_version);
+
+// nng_tls_engine_name returns the "name" of the TLS engine.  If no
+// TLS engine support is enabled, then "none" is returned.
+NNG_DECL const char *nng_tls_engine_name(void);
+
+// nng_tls_engine_description returns the "description" of the TLS engine.
+// If no TLS engine support is enabled, then an empty string is returned.
+NNG_DECL const char *nng_tls_engine_description(void);
+
+// nng_tls_engine_fips_mode returns true if the engine is in FIPS 140-2 mode.
+NNG_DECL bool nng_tls_engine_fips_mode(void);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_SUPPLEMENTAL_TLS_TLS_H
```

## skdecide/hub/include/nng/supplemental/util/options.h

 * *Ordering differences only*

```diff
@@ -1,48 +1,48 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_SUPPLEMENTAL_UTIL_OPTIONS_H
-#define NNG_SUPPLEMENTAL_UTIL_OPTIONS_H
-
-#include <stdbool.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// This is a relatively simple "options parsing" library, used to
-// parse command line options.  We would use getopt(3), but there are
-// two problems with getopt(3).  First, it isn't available on all
-// platforms (especially Win32), and second, it doesn't support long
-// options.  We *exclusively* support long options.  POSIX style
-// short option clustering is *NOT* supported.
-
-struct nng_optspec {
-	const char *o_name;  // Long style name (may be NULL for short only)
-	int         o_short; // Short option (no clustering!)
-	int         o_val;   // Value stored on a good parse (>0)
-	bool        o_arg;   // Option takes an argument if true
-};
-
-typedef struct nng_optspec nng_optspec;
-
-// Call with *optidx set to 1 to start parsing for a standard program.
-// The val will store the value of the matched "o_val", optarg will be
-// set to match the option string, and optidx will be increment appropriately.
-// Returns -1 when the end of options is reached, 0 on success, or
-// NNG_EINVAL if the option parse is invalid for any reason.
-NNG_DECL int nng_opts_parse(int argc, char *const *argv,
-    const nng_optspec *opts, int *val, char **optarg, int *optidx);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_SUPPLEMENTAL_UTIL_OPTIONS_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_SUPPLEMENTAL_UTIL_OPTIONS_H
+#define NNG_SUPPLEMENTAL_UTIL_OPTIONS_H
+
+#include <stdbool.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// This is a relatively simple "options parsing" library, used to
+// parse command line options.  We would use getopt(3), but there are
+// two problems with getopt(3).  First, it isn't available on all
+// platforms (especially Win32), and second, it doesn't support long
+// options.  We *exclusively* support long options.  POSIX style
+// short option clustering is *NOT* supported.
+
+struct nng_optspec {
+	const char *o_name;  // Long style name (may be NULL for short only)
+	int         o_short; // Short option (no clustering!)
+	int         o_val;   // Value stored on a good parse (>0)
+	bool        o_arg;   // Option takes an argument if true
+};
+
+typedef struct nng_optspec nng_optspec;
+
+// Call with *optidx set to 1 to start parsing for a standard program.
+// The val will store the value of the matched "o_val", optarg will be
+// set to match the option string, and optidx will be increment appropriately.
+// Returns -1 when the end of options is reached, 0 on success, or
+// NNG_EINVAL if the option parse is invalid for any reason.
+NNG_DECL int nng_opts_parse(int argc, char *const *argv,
+    const nng_optspec *opts, int *val, char **optarg, int *optidx);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_SUPPLEMENTAL_UTIL_OPTIONS_H
```

## skdecide/hub/include/nng/supplemental/util/platform.h

 * *Ordering differences only*

```diff
@@ -1,111 +1,111 @@
-//
-// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_SUPPLEMENTAL_UTIL_PLATFORM_H
-#define NNG_SUPPLEMENTAL_UTIL_PLATFORM_H
-
-// The declarations in this file are provided to assist with application
-// portability.  Conceptually these APIs are based on work we have already
-// done for NNG internals, and we find that they are useful in building
-// portable applications.
-
-// If it is more natural to use native system APIs like pthreads or C11
-// APIs or Windows APIs, then by all means please feel free to simply
-// ignore this.
-
-#include <stddef.h>
-#include <stdint.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// nng_time represents an absolute time since some arbitrary point in the
-// past, measured in milliseconds.  The values are always positive.
-typedef uint64_t nng_time;
-
-// Return an absolute time from some arbitrary point.  The value is
-// provided in milliseconds, and is of limited resolution based on the
-// system clock.  (Do not use it for fine grained performance measurements.)
-NNG_DECL nng_time nng_clock(void);
-
-// Sleep for specified msecs.
-NNG_DECL void nng_msleep(nng_duration);
-
-// nng_thread is a handle to a "thread", which may be a real system
-// thread, or a coroutine on some platforms.
-typedef struct nng_thread nng_thread;
-
-// Create and start a thread.  Note that on some platforms, this might
-// actually be a coroutine, with limitations about what system APIs
-// you can call.  Therefore, these threads should only be used with the
-// I/O APIs provided by nng.  The thread runs until completion.
-NNG_DECL int nng_thread_create(nng_thread **, void (*)(void *), void *);
-
-// Set the thread name.  Support for this is platform specific and varies.
-// It is intended to provide information for use when debugging applications,
-// and not for programmatic use beyond that.
-NNG_DECL void nng_thread_set_name(nng_thread *, const char *);
-
-// Destroy a thread (waiting for it to complete.)  When this function
-// returns all resources for the thread are cleaned up.
-NNG_DECL void nng_thread_destroy(nng_thread *);
-
-// nng_mtx represents a mutex, which is a simple, non-reentrant, boolean lock.
-typedef struct nng_mtx nng_mtx;
-
-// nng_mtx_alloc allocates a mutex structure.
-NNG_DECL int nng_mtx_alloc(nng_mtx **);
-
-// nng_mtx_free frees the mutex.  It must not be locked.
-NNG_DECL void nng_mtx_free(nng_mtx *);
-
-// nng_mtx_lock locks the mutex; if it is already locked it will block
-// until it can be locked.  If the caller already holds the lock, the
-// results are undefined (a panic may occur).
-NNG_DECL void nng_mtx_lock(nng_mtx *);
-
-// nng_mtx_unlock unlocks a previously locked mutex.  It is an error to
-// call this on a mutex which is not owned by caller.
-NNG_DECL void nng_mtx_unlock(nng_mtx *);
-
-// nng_cv is a condition variable.  It is always allocated with an
-// associated mutex, which must be held when waiting for it, or
-// when signaling it.
-typedef struct nng_cv nng_cv;
-
-NNG_DECL int nng_cv_alloc(nng_cv **, nng_mtx *);
-
-// nng_cv_free frees the condition variable.
-NNG_DECL void nng_cv_free(nng_cv *);
-
-// nng_cv_wait waits until the condition variable is "signaled".
-NNG_DECL void nng_cv_wait(nng_cv *);
-
-// nng_cv_until waits until either the condition is signaled, or
-// the timeout expires.  It returns NNG_ETIMEDOUT in that case.
-NNG_DECL int nng_cv_until(nng_cv *, nng_time);
-
-// nng_cv_wake wakes all threads waiting on the condition.
-NNG_DECL void nng_cv_wake(nng_cv *);
-
-// nng_cv_wake1 wakes only one thread waiting on the condition.  This may
-// reduce the thundering herd problem, but care must be taken to ensure
-// that no waiter starves forever.
-NNG_DECL void nng_cv_wake1(nng_cv *);
-
-// nng_random returns a "strong" (cryptographic sense) random number.
-NNG_DECL uint32_t nng_random(void);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_SUPPLEMENTAL_UTIL_PLATFORM_H
+//
+// Copyright 2018 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_SUPPLEMENTAL_UTIL_PLATFORM_H
+#define NNG_SUPPLEMENTAL_UTIL_PLATFORM_H
+
+// The declarations in this file are provided to assist with application
+// portability.  Conceptually these APIs are based on work we have already
+// done for NNG internals, and we find that they are useful in building
+// portable applications.
+
+// If it is more natural to use native system APIs like pthreads or C11
+// APIs or Windows APIs, then by all means please feel free to simply
+// ignore this.
+
+#include <stddef.h>
+#include <stdint.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// nng_time represents an absolute time since some arbitrary point in the
+// past, measured in milliseconds.  The values are always positive.
+typedef uint64_t nng_time;
+
+// Return an absolute time from some arbitrary point.  The value is
+// provided in milliseconds, and is of limited resolution based on the
+// system clock.  (Do not use it for fine grained performance measurements.)
+NNG_DECL nng_time nng_clock(void);
+
+// Sleep for specified msecs.
+NNG_DECL void nng_msleep(nng_duration);
+
+// nng_thread is a handle to a "thread", which may be a real system
+// thread, or a coroutine on some platforms.
+typedef struct nng_thread nng_thread;
+
+// Create and start a thread.  Note that on some platforms, this might
+// actually be a coroutine, with limitations about what system APIs
+// you can call.  Therefore, these threads should only be used with the
+// I/O APIs provided by nng.  The thread runs until completion.
+NNG_DECL int nng_thread_create(nng_thread **, void (*)(void *), void *);
+
+// Set the thread name.  Support for this is platform specific and varies.
+// It is intended to provide information for use when debugging applications,
+// and not for programmatic use beyond that.
+NNG_DECL void nng_thread_set_name(nng_thread *, const char *);
+
+// Destroy a thread (waiting for it to complete.)  When this function
+// returns all resources for the thread are cleaned up.
+NNG_DECL void nng_thread_destroy(nng_thread *);
+
+// nng_mtx represents a mutex, which is a simple, non-reentrant, boolean lock.
+typedef struct nng_mtx nng_mtx;
+
+// nng_mtx_alloc allocates a mutex structure.
+NNG_DECL int nng_mtx_alloc(nng_mtx **);
+
+// nng_mtx_free frees the mutex.  It must not be locked.
+NNG_DECL void nng_mtx_free(nng_mtx *);
+
+// nng_mtx_lock locks the mutex; if it is already locked it will block
+// until it can be locked.  If the caller already holds the lock, the
+// results are undefined (a panic may occur).
+NNG_DECL void nng_mtx_lock(nng_mtx *);
+
+// nng_mtx_unlock unlocks a previously locked mutex.  It is an error to
+// call this on a mutex which is not owned by caller.
+NNG_DECL void nng_mtx_unlock(nng_mtx *);
+
+// nng_cv is a condition variable.  It is always allocated with an
+// associated mutex, which must be held when waiting for it, or
+// when signaling it.
+typedef struct nng_cv nng_cv;
+
+NNG_DECL int nng_cv_alloc(nng_cv **, nng_mtx *);
+
+// nng_cv_free frees the condition variable.
+NNG_DECL void nng_cv_free(nng_cv *);
+
+// nng_cv_wait waits until the condition variable is "signaled".
+NNG_DECL void nng_cv_wait(nng_cv *);
+
+// nng_cv_until waits until either the condition is signaled, or
+// the timeout expires.  It returns NNG_ETIMEDOUT in that case.
+NNG_DECL int nng_cv_until(nng_cv *, nng_time);
+
+// nng_cv_wake wakes all threads waiting on the condition.
+NNG_DECL void nng_cv_wake(nng_cv *);
+
+// nng_cv_wake1 wakes only one thread waiting on the condition.  This may
+// reduce the thundering herd problem, but care must be taken to ensure
+// that no waiter starves forever.
+NNG_DECL void nng_cv_wake1(nng_cv *);
+
+// nng_random returns a "strong" (cryptographic sense) random number.
+NNG_DECL uint32_t nng_random(void);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_SUPPLEMENTAL_UTIL_PLATFORM_H
```

## skdecide/hub/include/nng/transport/inproc/inproc.h

 * *Ordering differences only*

```diff
@@ -1,29 +1,29 @@
-//
-// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2017 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_TRANSPORT_INPROC_INPROC_H
-#define NNG_TRANSPORT_INPROC_INPROC_H
-
-#include <nng/nng.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// inproc transport.  This is used for intra-process communication.
-#ifndef NNG_ELIDE_DEPRECATED
-NNG_DECL int nng_inproc_register(void);
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_TRANSPORT_INPROC_INPROC_H
+//
+// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2017 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_TRANSPORT_INPROC_INPROC_H
+#define NNG_TRANSPORT_INPROC_INPROC_H
+
+#include <nng/nng.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// inproc transport.  This is used for intra-process communication.
+#ifndef NNG_ELIDE_DEPRECATED
+NNG_DECL int nng_inproc_register(void);
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_TRANSPORT_INPROC_INPROC_H
```

## skdecide/hub/include/nng/transport/ipc/ipc.h

 * *Ordering differences only*

```diff
@@ -1,31 +1,31 @@
-//
-// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_TRANSPORT_IPC_IPC_H
-#define NNG_TRANSPORT_IPC_IPC_H
-
-#include <nng/nng.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// ipc transport.  This is used for inter-process communication on
-// the same host computer.
-
-#ifndef NNG_ELIDE_DEPRECATED
-NNG_DECL int nng_ipc_register(void);
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_TRANSPORT_IPC_IPC_H
+//
+// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_TRANSPORT_IPC_IPC_H
+#define NNG_TRANSPORT_IPC_IPC_H
+
+#include <nng/nng.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// ipc transport.  This is used for inter-process communication on
+// the same host computer.
+
+#ifndef NNG_ELIDE_DEPRECATED
+NNG_DECL int nng_ipc_register(void);
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_TRANSPORT_IPC_IPC_H
```

## skdecide/hub/include/nng/transport/tcp/tcp.h

 * *Ordering differences only*

```diff
@@ -1,30 +1,30 @@
-//
-// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2017 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_TRANSPORT_TCP_TCP_H
-#define NNG_TRANSPORT_TCP_TCP_H
-
-#include <nng/nng.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// TCP transport.  This is used for communication over TCP/IP.
-
-#ifndef NNG_ELIDE_DEPRECATED
-NNG_DECL int nng_tcp_register(void);
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_TRANSPORT_TCP_TCP_H
+//
+// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2017 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_TRANSPORT_TCP_TCP_H
+#define NNG_TRANSPORT_TCP_TCP_H
+
+#include <nng/nng.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// TCP transport.  This is used for communication over TCP/IP.
+
+#ifndef NNG_ELIDE_DEPRECATED
+NNG_DECL int nng_tcp_register(void);
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_TRANSPORT_TCP_TCP_H
```

## skdecide/hub/include/nng/transport/tls/tls.h

 * *Ordering differences only*

```diff
@@ -1,30 +1,30 @@
-//
-// Copyright 2019 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_TRANSPORT_TLS_TLS_H
-#define NNG_TRANSPORT_TLS_TLS_H
-
-#include <nng/nng.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// TLS transport.  This is used for communication via TLS v1.2 over TCP/IP.
-
-#ifndef NNG_ELIDE_DEPRECATED
-NNG_DECL int nng_tls_register(void);
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_TRANSPORT_TLS_TLS_H
+//
+// Copyright 2019 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_TRANSPORT_TLS_TLS_H
+#define NNG_TRANSPORT_TLS_TLS_H
+
+#include <nng/nng.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// TLS transport.  This is used for communication via TLS v1.2 over TCP/IP.
+
+#ifndef NNG_ELIDE_DEPRECATED
+NNG_DECL int nng_tls_register(void);
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_TRANSPORT_TLS_TLS_H
```

## skdecide/hub/include/nng/transport/ws/websocket.h

 * *Ordering differences only*

```diff
@@ -1,35 +1,35 @@
-//
-// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_TRANSPORT_WS_WEBSOCKET_H
-#define NNG_TRANSPORT_WS_WEBSOCKET_H
-
-#include <nng/nng.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// WebSocket transport.  This is used for communication via WebSocket.
-
-// These aliases are for WSS naming consistency.
-#define NNG_OPT_WSS_REQUEST_HEADERS NNG_OPT_WS_REQUEST_HEADERS
-#define NNG_OPT_WSS_RESPONSE_HEADERS NNG_OPT_WS_RESPONSE_HEADERS
-
-#ifndef NNG_ELIDE_DEPRECATED
-NNG_DECL int nng_ws_register(void);
-NNG_DECL int nng_wss_register(void);
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_TRANSPORT_WS_WEBSOCKET_H
+//
+// Copyright 2021 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_TRANSPORT_WS_WEBSOCKET_H
+#define NNG_TRANSPORT_WS_WEBSOCKET_H
+
+#include <nng/nng.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// WebSocket transport.  This is used for communication via WebSocket.
+
+// These aliases are for WSS naming consistency.
+#define NNG_OPT_WSS_REQUEST_HEADERS NNG_OPT_WS_REQUEST_HEADERS
+#define NNG_OPT_WSS_RESPONSE_HEADERS NNG_OPT_WS_RESPONSE_HEADERS
+
+#ifndef NNG_ELIDE_DEPRECATED
+NNG_DECL int nng_ws_register(void);
+NNG_DECL int nng_wss_register(void);
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_TRANSPORT_WS_WEBSOCKET_H
```

## skdecide/hub/include/nng/transport/zerotier/zerotier.h

 * *Ordering differences only*

```diff
@@ -1,161 +1,161 @@
-//
-// Copyright 2019 Staysail Systems, Inc. <info@staysail.tech>
-// Copyright 2018 Capitar IT Group BV <info@capitar.com>
-//
-// This software is supplied under the terms of the MIT License, a
-// copy of which should be located in the distribution where this
-// file was obtained (LICENSE.txt).  A copy of the license may also be
-// found online at https://opensource.org/licenses/MIT.
-//
-
-#ifndef NNG_TRANSPORT_ZEROTIER_ZEROTIER_H
-#define NNG_TRANSPORT_ZEROTIER_ZEROTIER_H
-
-#include <nng/nng.h>
-
-// ZeroTier Transport.  This sits on the ZeroTier L2 network, which itself
-// is implemented on top of UDP.  This requires the 3rd party
-// libzerotiercore library (which is GPLv3!) and platform specific UDP
-// functionality to be built in.  Note that care must be taken to link
-// dynamically if one wishes to avoid making your entire application GPL3.
-// (Alternatively ZeroTier offers commercial licenses which may prevent
-// this particular problem.)  This implementation does not make use of
-// certain advanced capabilities in ZeroTier such as more sophisticated
-// route management and TCP fallback.  You need to have connectivity
-// to the Internet to use this.  (Or at least to your Planetary root.)
-//
-// The ZeroTier URL format we support is zt://<ztid>.<nwid>:<port> where
-// the <nwid> component represents the 64-bit hexadecimal ZeroTier
-// network ID,the <ztid> represents the 40-bit hexadecimal ZeroTier
-// node (device) ID, and the <port> is a 24-bit (decimal) port number.
-//
-// A listener may replace the <ztid> with a wildcard, to just bind to itself,
-// in which case the format will be zt://*.<nwid>:<port>
-//
-// A listener may also use either 0 or * for the <port> to indicate that
-// a random local ephemeral port should be used.
-//
-// Because ZeroTier takes a while to establish connectivity, it is even
-// more important that applications using the ZeroTier transport not
-// assume that a connection will be immediately available.  It can take
-// quite a few seconds for peer-to-peer connectivity to be established.
-//
-// The ZeroTier transport was funded by Capitar IT Group, BV.
-//
-// The protocol itself is documented online at:
-// http://nanomsg.org/rfcs/sp-zerotier-v0.html
-//
-// This transport is highly experimental.
-
-// ZeroTier transport-specific options.
-
-// NNG_OPT_ZT_HOME is a string containing a directory, where persistent
-// state (key files, etc.) will be stored.  It should be protected from
-// unauthorized viewing and modification.  This option must be set on an
-// endpoint or socket before the endpoint(s) are started.  If the unset,
-// or an empty string, then no persistence is used and an ephemeral node
-// will be created instead.  Note that different endpoints may use different
-// values for this option, and that will lead to each endpoint having a
-// different ZeroTier identity -- however only one ephemeral node will
-// be created for the application.
-#define NNG_OPT_ZT_HOME "zt:home"
-
-// NNG_OPT_ZT_NWID is the 64-bit network ID, represented using a uint64_t in
-// native byte order.  This is a read-only option; it is derived automatically
-// from the URL.
-#define NNG_OPT_ZT_NWID "zt:nwid"
-
-// NNG_OPT_ZT_NODE is the 40-bit node ID, stored in native order in the low
-// 40-bits of a uint64_t, of the node.  This is a read-only option.
-#define NNG_OPT_ZT_NODE "zt:node"
-
-// NNG_OPT_ZT_NETWORK_STATUS represents the status of the ZeroTier virtual
-// network.  The option is a read-only value, stored as an integer, which
-// takes of the nng_zt_network_status_xxx values listed below.
-#define NNG_OPT_ZT_NETWORK_STATUS "zt:network-status"
-
-// NNG_OPT_ZT_NETWORK_NAME is a human-readable name for the ZeroTier virtual
-// network.  This will only be set once the ZeroTier network has come up
-// as the name comes from the network controller.  This is read-only, and
-// is presented as an ASCIIZ string.
-#define NNG_OPT_ZT_NETWORK_NAME "zt:network-name"
-
-// NNG_OPT_ZT_PING_TIME and NNG_OPT_ZT_PING_TRIES are used to send ping
-// requests when a connection appears to be idled.  If a logical session
-// has not received traffic from it's peer for ping-time, then a ping packet
-// is sent.  This will be done up to ping-count times.  If no traffic from
-// the remote peer is seen after all ping requests are sent, then the peer
-// is assumed to be dead or offline, and the session is closed.  The
-// NNG_OPT_ZT_PING_TIME is a duration (msec, stored as an nng_duration, and
-// NNG_OPT_ZT_PING_COUNT is an integer.)  This ping process can be disabled
-// by setting either ping-time or ping-count to zero.
-#define NNG_OPT_ZT_PING_TIME "zt:ping-time"
-#define NNG_OPT_ZT_PING_TRIES "zt:ping-tries"
-
-// NNG_OPT_ZT_CONN_TIME and NNG_OPT_ZT_CONN_TRIES are used to control
-// the interval between connection attempts, and the maximum number of
-// connection attempts to make before assuming that the peer is absent
-// (and returning NNG_ETIMEDOUT).  The NNG_OPT_ZT_CONN_TIME is a duration,
-// the NNG_OPT_ZT_CONN_TRIES is an integer.
-#define NNG_OPT_ZT_CONN_TIME "zt:conn-time"
-#define NNG_OPT_ZT_CONN_TRIES "zt:conn-tries"
-
-// NNG_OPT_ZT_MTU is a read-only size_t and contains the ZeroTier virtual
-// network MTU (i.e. the L2 payload MTU). Messages that are larger than this
-// (including our 20-byte header data) will be fragmented into multiple
-// virtual L2 frames.
-#define NNG_OPT_ZT_MTU "zt:mtu"
-
-// NNG_OPT_ZT_ORBIT is a write-only API to add a "moon" -- this affects the
-// endpoint, and all other endpoints using the same node. The value is
-// a pair of 64-bit integers -- the first is the moon ID, and the second, if
-// non-zero, is the node ID of a server.  Conventionally this is the same
-// as the moon ID.
-#define NNG_OPT_ZT_ORBIT "zt:orbit"
-
-// NNG_OPT_ZT_DEORBIT removes the moon ID from the node, so that it will
-// no longer use that moon.  The argument is a moon ID to remove.  If the
-// node is not already orbiting, then this operation does nothing.
-#define NNG_OPT_ZT_DEORBIT "zt:deorbit"
-
-// NNG_OPT_ZT_ADD_LOCAL_ADDR adds the local address (IP address) as
-// local interface address.  This facilitates the local startup and
-// discovery.  Note that this can be called multiple times to add
-// additional address.  This is optional, and usually not needed.
-// The value is an nng_sockaddr corresponding to an IP (or IPv6) address.
-#define NNG_OPT_ZT_ADD_LOCAL_ADDR "zt:add-local-addr"
-
-// NNG_OPT_ZT_CLEAR_LOCAL_ADDRS clears ZeroTier's notion of all
-// local addresses.  This may be useful when used on a mobile node,
-// to reset the notion of what the local addresses are.  This
-// option takes no argument really.
-#define NNG_OPT_ZT_CLEAR_LOCAL_ADDRS "zt:clear-local-addrs"
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-// Network status values.
-// These values are supplied to help folks checking status.  They are the
-// return values from zt_opt_status.  We avoid hard coding them as defines,
-// to keep applications from baking in values that may change if the
-// underlying ZeroTier transport changes.
-enum nng_zt_status {
-	NNG_ZT_STATUS_UP,
-	NNG_ZT_STATUS_CONFIG,
-	NNG_ZT_STATUS_DENIED,
-	NNG_ZT_STATUS_NOTFOUND,
-	NNG_ZT_STATUS_ERROR,
-	NNG_ZT_STATUS_OBSOLETE,
-	NNG_ZT_STATUS_UNKNOWN,
-};
-
-#ifndef NNG_ELIDE_DEPRECATED
-NNG_DECL int nng_zt_register(void);
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif // NNG_TRANSPORT_ZEROTIER_ZEROTIER_H
+//
+// Copyright 2019 Staysail Systems, Inc. <info@staysail.tech>
+// Copyright 2018 Capitar IT Group BV <info@capitar.com>
+//
+// This software is supplied under the terms of the MIT License, a
+// copy of which should be located in the distribution where this
+// file was obtained (LICENSE.txt).  A copy of the license may also be
+// found online at https://opensource.org/licenses/MIT.
+//
+
+#ifndef NNG_TRANSPORT_ZEROTIER_ZEROTIER_H
+#define NNG_TRANSPORT_ZEROTIER_ZEROTIER_H
+
+#include <nng/nng.h>
+
+// ZeroTier Transport.  This sits on the ZeroTier L2 network, which itself
+// is implemented on top of UDP.  This requires the 3rd party
+// libzerotiercore library (which is GPLv3!) and platform specific UDP
+// functionality to be built in.  Note that care must be taken to link
+// dynamically if one wishes to avoid making your entire application GPL3.
+// (Alternatively ZeroTier offers commercial licenses which may prevent
+// this particular problem.)  This implementation does not make use of
+// certain advanced capabilities in ZeroTier such as more sophisticated
+// route management and TCP fallback.  You need to have connectivity
+// to the Internet to use this.  (Or at least to your Planetary root.)
+//
+// The ZeroTier URL format we support is zt://<ztid>.<nwid>:<port> where
+// the <nwid> component represents the 64-bit hexadecimal ZeroTier
+// network ID,the <ztid> represents the 40-bit hexadecimal ZeroTier
+// node (device) ID, and the <port> is a 24-bit (decimal) port number.
+//
+// A listener may replace the <ztid> with a wildcard, to just bind to itself,
+// in which case the format will be zt://*.<nwid>:<port>
+//
+// A listener may also use either 0 or * for the <port> to indicate that
+// a random local ephemeral port should be used.
+//
+// Because ZeroTier takes a while to establish connectivity, it is even
+// more important that applications using the ZeroTier transport not
+// assume that a connection will be immediately available.  It can take
+// quite a few seconds for peer-to-peer connectivity to be established.
+//
+// The ZeroTier transport was funded by Capitar IT Group, BV.
+//
+// The protocol itself is documented online at:
+// http://nanomsg.org/rfcs/sp-zerotier-v0.html
+//
+// This transport is highly experimental.
+
+// ZeroTier transport-specific options.
+
+// NNG_OPT_ZT_HOME is a string containing a directory, where persistent
+// state (key files, etc.) will be stored.  It should be protected from
+// unauthorized viewing and modification.  This option must be set on an
+// endpoint or socket before the endpoint(s) are started.  If the unset,
+// or an empty string, then no persistence is used and an ephemeral node
+// will be created instead.  Note that different endpoints may use different
+// values for this option, and that will lead to each endpoint having a
+// different ZeroTier identity -- however only one ephemeral node will
+// be created for the application.
+#define NNG_OPT_ZT_HOME "zt:home"
+
+// NNG_OPT_ZT_NWID is the 64-bit network ID, represented using a uint64_t in
+// native byte order.  This is a read-only option; it is derived automatically
+// from the URL.
+#define NNG_OPT_ZT_NWID "zt:nwid"
+
+// NNG_OPT_ZT_NODE is the 40-bit node ID, stored in native order in the low
+// 40-bits of a uint64_t, of the node.  This is a read-only option.
+#define NNG_OPT_ZT_NODE "zt:node"
+
+// NNG_OPT_ZT_NETWORK_STATUS represents the status of the ZeroTier virtual
+// network.  The option is a read-only value, stored as an integer, which
+// takes of the nng_zt_network_status_xxx values listed below.
+#define NNG_OPT_ZT_NETWORK_STATUS "zt:network-status"
+
+// NNG_OPT_ZT_NETWORK_NAME is a human-readable name for the ZeroTier virtual
+// network.  This will only be set once the ZeroTier network has come up
+// as the name comes from the network controller.  This is read-only, and
+// is presented as an ASCIIZ string.
+#define NNG_OPT_ZT_NETWORK_NAME "zt:network-name"
+
+// NNG_OPT_ZT_PING_TIME and NNG_OPT_ZT_PING_TRIES are used to send ping
+// requests when a connection appears to be idled.  If a logical session
+// has not received traffic from it's peer for ping-time, then a ping packet
+// is sent.  This will be done up to ping-count times.  If no traffic from
+// the remote peer is seen after all ping requests are sent, then the peer
+// is assumed to be dead or offline, and the session is closed.  The
+// NNG_OPT_ZT_PING_TIME is a duration (msec, stored as an nng_duration, and
+// NNG_OPT_ZT_PING_COUNT is an integer.)  This ping process can be disabled
+// by setting either ping-time or ping-count to zero.
+#define NNG_OPT_ZT_PING_TIME "zt:ping-time"
+#define NNG_OPT_ZT_PING_TRIES "zt:ping-tries"
+
+// NNG_OPT_ZT_CONN_TIME and NNG_OPT_ZT_CONN_TRIES are used to control
+// the interval between connection attempts, and the maximum number of
+// connection attempts to make before assuming that the peer is absent
+// (and returning NNG_ETIMEDOUT).  The NNG_OPT_ZT_CONN_TIME is a duration,
+// the NNG_OPT_ZT_CONN_TRIES is an integer.
+#define NNG_OPT_ZT_CONN_TIME "zt:conn-time"
+#define NNG_OPT_ZT_CONN_TRIES "zt:conn-tries"
+
+// NNG_OPT_ZT_MTU is a read-only size_t and contains the ZeroTier virtual
+// network MTU (i.e. the L2 payload MTU). Messages that are larger than this
+// (including our 20-byte header data) will be fragmented into multiple
+// virtual L2 frames.
+#define NNG_OPT_ZT_MTU "zt:mtu"
+
+// NNG_OPT_ZT_ORBIT is a write-only API to add a "moon" -- this affects the
+// endpoint, and all other endpoints using the same node. The value is
+// a pair of 64-bit integers -- the first is the moon ID, and the second, if
+// non-zero, is the node ID of a server.  Conventionally this is the same
+// as the moon ID.
+#define NNG_OPT_ZT_ORBIT "zt:orbit"
+
+// NNG_OPT_ZT_DEORBIT removes the moon ID from the node, so that it will
+// no longer use that moon.  The argument is a moon ID to remove.  If the
+// node is not already orbiting, then this operation does nothing.
+#define NNG_OPT_ZT_DEORBIT "zt:deorbit"
+
+// NNG_OPT_ZT_ADD_LOCAL_ADDR adds the local address (IP address) as
+// local interface address.  This facilitates the local startup and
+// discovery.  Note that this can be called multiple times to add
+// additional address.  This is optional, and usually not needed.
+// The value is an nng_sockaddr corresponding to an IP (or IPv6) address.
+#define NNG_OPT_ZT_ADD_LOCAL_ADDR "zt:add-local-addr"
+
+// NNG_OPT_ZT_CLEAR_LOCAL_ADDRS clears ZeroTier's notion of all
+// local addresses.  This may be useful when used on a mobile node,
+// to reset the notion of what the local addresses are.  This
+// option takes no argument really.
+#define NNG_OPT_ZT_CLEAR_LOCAL_ADDRS "zt:clear-local-addrs"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// Network status values.
+// These values are supplied to help folks checking status.  They are the
+// return values from zt_opt_status.  We avoid hard coding them as defines,
+// to keep applications from baking in values that may change if the
+// underlying ZeroTier transport changes.
+enum nng_zt_status {
+	NNG_ZT_STATUS_UP,
+	NNG_ZT_STATUS_CONFIG,
+	NNG_ZT_STATUS_DENIED,
+	NNG_ZT_STATUS_NOTFOUND,
+	NNG_ZT_STATUS_ERROR,
+	NNG_ZT_STATUS_OBSOLETE,
+	NNG_ZT_STATUS_UNKNOWN,
+};
+
+#ifndef NNG_ELIDE_DEPRECATED
+NNG_DECL int nng_zt_register(void);
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // NNG_TRANSPORT_ZEROTIER_ZEROTIER_H
```

## Comparing `skdecide/hub/solver/gphh/gphh.py` & `skdecide/hub/solver/do_solver/gphh.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,1261 +1,1200 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-import operator
-import random
-from enum import Enum
-from typing import Callable, Dict, List, Set
-
-import numpy as np
-from deap import algorithms, creator, gp, tools
-from deap.base import Fitness, Toolbox
-from deap.gp import PrimitiveSet, PrimitiveTree, genHalfAndHalf
-from discrete_optimization.rcpsp.rcpsp_model import RCPSPSolution
-from discrete_optimization.rcpsp.solver.cpm import CPM
-from scipy import stats
-from scipy.spatial import distance
-
-from skdecide import Solver
-from skdecide.builders.domain.scheduling.modes import SingleMode
-from skdecide.builders.domain.scheduling.scheduling_domains import D, SchedulingDomain
-from skdecide.builders.domain.scheduling.scheduling_domains_modelling import (
-    SchedulingAction,
-    State,
-    rebuild_all_tasks_dict,
-    rebuild_tasks_complete_details_dict,
-)
-from skdecide.builders.solver.policy import DeterministicPolicies
-from skdecide.hub.solver.do_solver.do_solver_scheduling import (
-    DOSolver,
-    PolicyMethodParams,
-    PolicyRCPSP,
-    SolvingMethod,
-)
-from skdecide.hub.solver.do_solver.sk_to_do_binding import build_do_domain
-from skdecide.hub.solver.sgs_policies.sgs_policies import BasePolicyMethod
-
-
-def if_then_else(input, output1, output2):
-    if input:
-        return output1
-    else:
-        return output2
-
-
-def protected_div(left, right):
-    if right != 0.0:
-        return left / right
-    else:
-        return 1.0
-
-
-def max_operator(left, right):
-    return max(left, right)
-
-
-def min_operator(left, right):
-    return min(left, right)
-
-
-def feature_task_duration(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    return domain.sample_task_duration(task_id)
-
-
-def feature_total_n_res(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
-    val = 0
-    mode_consumption = domain.get_task_modes(task_id)[1]
-    for res in mode_consumption.get_ressource_names():
-        val += mode_consumption.get_resource_need(res)
-    return val
-
-
-def feature_n_successors(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    return len(domain.get_successors_task(task_id)) / len(domain.get_tasks_ids())
-
-
-def feature_n_predecessors(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    return len(domain.get_predecessors_task(task_id)) / len(domain.get_tasks_ids())
-
-
-def get_resource_requirements_across_duration(
-    domain: SchedulingDomain, task_id: int, **kwargs
-):
-    values = []
-    mode_consumption = domain.get_task_modes(task_id)[1]
-    duration = domain.get_latest_sampled_duration(task_id, 1, 0.0)
-    if duration > 0:
-        for res in mode_consumption.get_ressource_names():
-            tmp = 0
-            for t in range(duration):
-                need = mode_consumption.get_resource_need_at_time(res, t)
-                total = domain.sample_quantity_resource(res, t)
-                tmp += need / total
-            values.append(tmp / duration)
-    else:
-        values = [0.0]
-    # print(task_id,':', values)
-    return values
-
-
-def feature_average_resource_requirements(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
-    val = np.mean(values)
-    return val
-
-
-def feature_minimum_resource_requirements(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
-    val = np.min(values)
-    return val
-
-
-def feature_non_zero_minimum_resource_requirements(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
-    if np.sum(values) > 0.0:
-        val = np.min([x for x in values if x > 0.0])
-    else:
-        val = np.min(values)
-    return val
-
-
-def feature_maximum_resource_requirements(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
-    val = np.max(values)
-    return val
-
-
-def feature_resource_requirements(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
-    val = len([x for x in values if x > 0.0]) / len(values)
-    return val
-
-
-def feature_all_descendants(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
-):
-    return len(domain.full_successors[task_id]) / len(domain.get_tasks_ids())
-
-
-def feature_precedence_done(
-    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, state: State, **kwargs
-):
-    return task_id in domain.task_possible_to_launch_precedence(state=state)
-
-
-def compute_cpm(do_domain):
-    cpm_solver = CPM(do_domain)
-    path = cpm_solver.run_classic_cpm()
-    cpm = cpm_solver.map_node
-    cpm_esd = cpm[path[-1]]._ESD  # to normalize...
-    return cpm, cpm_esd
-
-
-def feature_esd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
-    """Will only work if you store cpm results into the object. dirty trick"""
-    return cpm[task_id]._ESD / cpm_esd
-
-
-def feature_lsd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
-    """Will only work if you store cpm results into the object. dirty trick"""
-    return cpm[task_id]._LSD / cpm_esd
-
-
-def feature_efd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
-    """Will only work if you store cpm results into the object. dirty trick"""
-    return cpm[task_id]._EFD / cpm_esd
-
-
-def feature_lfd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
-    """Will only work if you store cpm results into the object. dirty trick"""
-    return cpm[task_id]._LFD / cpm_esd
-
-
-class D(SchedulingDomain, SingleMode):
-    pass
-
-
-class FeatureEnum(Enum):
-    TASK_DURATION = "task_duration"
-    RESSOURCE_TOTAL = "total_nres"
-    N_SUCCESSORS = "n_successors"
-    N_PREDECESSORS = "n_predecessors"
-    RESSOURCE_REQUIRED = "res_requ"
-    RESSOURCE_AVG = "avg_res_requ"
-    RESSOURCE_MIN = "min_res_requ"
-    RESSOURCE_NZ_MIN = "nz_min_res_requ"
-    RESSOURCE_MAX = "max_res_requ"
-    ALL_DESCENDANTS = "all_descendants"
-    PRECEDENCE_DONE = "precedence_done"
-    EARLIEST_START_DATE = "ESD"
-    LATEST_START_DATE = "LSD"
-    EARLIEST_FINISH_DATE = "EFD"
-    LATEST_FINISH_DATE = "LFD"
-
-
-feature_function_map = {
-    FeatureEnum.TASK_DURATION: feature_task_duration,
-    FeatureEnum.RESSOURCE_TOTAL: feature_total_n_res,
-    FeatureEnum.N_SUCCESSORS: feature_n_successors,
-    FeatureEnum.N_PREDECESSORS: feature_n_predecessors,  #
-    FeatureEnum.RESSOURCE_REQUIRED: feature_resource_requirements,  #
-    FeatureEnum.RESSOURCE_AVG: feature_average_resource_requirements,  #
-    FeatureEnum.RESSOURCE_MIN: feature_minimum_resource_requirements,  #
-    FeatureEnum.RESSOURCE_NZ_MIN: feature_non_zero_minimum_resource_requirements,  #
-    FeatureEnum.RESSOURCE_MAX: feature_maximum_resource_requirements,  #
-    FeatureEnum.ALL_DESCENDANTS: feature_all_descendants,  #
-    FeatureEnum.PRECEDENCE_DONE: feature_precedence_done,
-    FeatureEnum.EARLIEST_START_DATE: feature_esd,  #
-    FeatureEnum.EARLIEST_FINISH_DATE: feature_efd,  #
-    FeatureEnum.LATEST_START_DATE: feature_lsd,  #
-    FeatureEnum.LATEST_FINISH_DATE: feature_lfd,
-}  #
-
-feature_static_map = {
-    FeatureEnum.TASK_DURATION: True,
-    FeatureEnum.RESSOURCE_TOTAL: True,
-    FeatureEnum.N_SUCCESSORS: True,
-    FeatureEnum.N_PREDECESSORS: True,  #
-    FeatureEnum.RESSOURCE_REQUIRED: True,  #
-    FeatureEnum.RESSOURCE_AVG: True,  #
-    FeatureEnum.RESSOURCE_MIN: True,  #
-    FeatureEnum.RESSOURCE_NZ_MIN: True,  #
-    FeatureEnum.RESSOURCE_MAX: True,  #
-    FeatureEnum.ALL_DESCENDANTS: True,  #
-    FeatureEnum.PRECEDENCE_DONE: False,
-    FeatureEnum.EARLIEST_START_DATE: True,  #
-    FeatureEnum.EARLIEST_FINISH_DATE: True,  #
-    FeatureEnum.LATEST_START_DATE: True,  #
-    FeatureEnum.LATEST_FINISH_DATE: True,
-}  #
-
-
-class EvaluationGPHH(Enum):
-    SGS = 0
-    PERMUTATION_DISTANCE = 1
-    # SGS_DEVIATION = 2
-
-
-class PermutationDistance(Enum):
-    KTD = 0
-    HAMMING = 1
-    KTD_HAMMING = 2
-
-
-class ParametersGPHH:
-    set_feature: Set[FeatureEnum] = None
-    set_primitves: PrimitiveSet = None
-    tournament_ratio: float = None
-    pop_size: int = None
-    n_gen: int = None
-    min_tree_depth: int = None
-    max_tree_depth: int = None
-    crossover_rate: float = None
-    mutation_rate: float = None
-    base_policy_method = None
-    delta_index_freedom: int = None
-    delta_time_freedom: int = None
-    deap_verbose: bool = None
-    evaluation: EvaluationGPHH = None
-    permutation_distance = PermutationDistance.KTD
-
-    def __init__(
-        self,
-        set_feature,
-        set_primitves,
-        tournament_ratio,
-        pop_size,
-        n_gen,
-        min_tree_depth,
-        max_tree_depth,
-        crossover_rate,
-        mutation_rate,
-        base_policy_method,
-        delta_index_freedom,
-        delta_time_freedom,
-        deap_verbose,
-        evaluation,
-        permutation_distance,
-    ):
-        self.set_feature = set_feature
-        self.set_primitves = set_primitves
-        self.tournament_ratio = tournament_ratio
-        self.pop_size = pop_size
-        self.n_gen = n_gen
-        self.min_tree_depth = min_tree_depth
-        self.max_tree_depth = max_tree_depth
-        self.crossover_rate = crossover_rate
-        self.mutation_rate = mutation_rate
-        self.base_policy_method = base_policy_method
-        self.delta_index_freedom = delta_index_freedom
-        self.delta_time_freedom = delta_time_freedom
-        self.deap_verbose = deap_verbose
-        self.evaluation = evaluation
-        self.permutation_distance = permutation_distance
-
-    @staticmethod
-    def default():
-        set_feature = {
-            FeatureEnum.EARLIEST_FINISH_DATE,
-            FeatureEnum.EARLIEST_START_DATE,
-            FeatureEnum.LATEST_FINISH_DATE,
-            FeatureEnum.LATEST_START_DATE,
-            FeatureEnum.N_PREDECESSORS,
-            FeatureEnum.N_SUCCESSORS,
-            FeatureEnum.ALL_DESCENDANTS,
-            FeatureEnum.RESSOURCE_REQUIRED,
-            FeatureEnum.RESSOURCE_AVG,
-            FeatureEnum.RESSOURCE_MAX,
-            # FeatureEnum.RESSOURCE_MIN
-            FeatureEnum.RESSOURCE_NZ_MIN,
-        }
-
-        pset = PrimitiveSet("main", len(set_feature))
-        pset.addPrimitive(operator.add, 2)
-        pset.addPrimitive(operator.sub, 2)
-        pset.addPrimitive(operator.mul, 2)
-        pset.addPrimitive(protected_div, 2)
-        pset.addPrimitive(max_operator, 2)
-        pset.addPrimitive(min_operator, 2)
-        pset.addPrimitive(operator.neg, 1)
-
-        return ParametersGPHH(
-            set_feature=set_feature,
-            set_primitves=pset,
-            tournament_ratio=0.1,
-            pop_size=40,
-            n_gen=100,
-            min_tree_depth=1,
-            max_tree_depth=4,
-            crossover_rate=0.7,
-            mutation_rate=0.3,
-            base_policy_method=BasePolicyMethod.FOLLOW_GANTT,
-            delta_index_freedom=0,
-            delta_time_freedom=0,
-            deap_verbose=True,
-            # evaluation=EvaluationGPHH.PERMUTATION_DISTANCE,
-            evaluation=EvaluationGPHH.SGS,
-            permutation_distance=PermutationDistance.KTD,
-        )
-
-    @staticmethod
-    def fast_test():
-        set_feature = {
-            FeatureEnum.EARLIEST_FINISH_DATE,
-            FeatureEnum.EARLIEST_START_DATE,
-            FeatureEnum.LATEST_FINISH_DATE,
-            FeatureEnum.LATEST_START_DATE,
-            FeatureEnum.N_PREDECESSORS,
-            FeatureEnum.N_SUCCESSORS,
-            FeatureEnum.ALL_DESCENDANTS,
-            FeatureEnum.RESSOURCE_REQUIRED,
-            FeatureEnum.RESSOURCE_AVG,
-            FeatureEnum.RESSOURCE_MAX,
-            # FeatureEnum.RESSOURCE_MIN
-            FeatureEnum.RESSOURCE_NZ_MIN,
-        }
-
-        pset = PrimitiveSet("main", len(set_feature))
-        pset.addPrimitive(operator.add, 2)
-        pset.addPrimitive(operator.sub, 2)
-        pset.addPrimitive(operator.mul, 2)
-        pset.addPrimitive(protected_div, 2)
-        pset.addPrimitive(max_operator, 2)
-        pset.addPrimitive(min_operator, 2)
-        pset.addPrimitive(operator.neg, 1)
-
-        return ParametersGPHH(
-            set_feature=set_feature,
-            set_primitves=pset,
-            tournament_ratio=0.1,
-            pop_size=10,
-            n_gen=2,
-            min_tree_depth=1,
-            max_tree_depth=4,
-            crossover_rate=0.7,
-            mutation_rate=0.3,
-            base_policy_method=BasePolicyMethod.FOLLOW_GANTT,
-            delta_index_freedom=0,
-            delta_time_freedom=0,
-            deap_verbose=True,
-            evaluation=EvaluationGPHH.SGS,
-            # evaluation=EvaluationGPHH.PERMUTATION_DISTANCE,
-            permutation_distance=PermutationDistance.KTD,
-        )
-
-    @staticmethod
-    def default_for_set_features(set_feature: Set[FeatureEnum]):
-        pset = PrimitiveSet("main", len(set_feature))
-        pset.addPrimitive(operator.add, 2)
-        pset.addPrimitive(operator.sub, 2)
-        pset.addPrimitive(operator.mul, 2)
-        # pset.addPrimitive(protected_div, 2)
-        pset.addPrimitive(max_operator, 2)
-        pset.addPrimitive(min_operator, 2)
-        pset.addPrimitive(operator.neg, 1)
-
-        return ParametersGPHH(
-            set_feature=set_feature,
-            set_primitves=pset,
-            tournament_ratio=0.25,
-            pop_size=20,
-            n_gen=20,
-            min_tree_depth=1,
-            max_tree_depth=4,
-            crossover_rate=0.7,
-            mutation_rate=0.1,
-            base_policy_method=BasePolicyMethod.SGS_READY,
-            delta_index_freedom=0,
-            delta_time_freedom=0,
-            deap_verbose=True,
-            evaluation=EvaluationGPHH.PERMUTATION_DISTANCE,
-            permutation_distance=PermutationDistance.KTD,
-        )
-
-
-class GPHH(Solver, DeterministicPolicies):
-    T_domain = D
-
-    training_domains: List[T_domain]
-    verbose: bool
-    weight: int
-    pset: PrimitiveSet
-    toolbox: Toolbox
-    policy: DeterministicPolicies
-    params_gphh: ParametersGPHH
-    # policy: GPHHPolicy
-    evaluation_method: EvaluationGPHH
-    reference_permutations: Dict
-    permutation_distance: PermutationDistance
-
-    def __init__(
-        self,
-        training_domains: List[T_domain],
-        domain_model: SchedulingDomain,
-        weight: int,
-        # set_feature: Set[FeatureEnum]=None,
-        params_gphh: ParametersGPHH = ParametersGPHH.default(),
-        reference_permutations=None,
-        # reference_makespans=None,
-        training_domains_names=None,
-        verbose: bool = False,
-    ):
-        self.training_domains = training_domains
-        self.domain_model = domain_model
-        self.params_gphh = params_gphh
-        # self.set_feature = set_feature
-        self.set_feature = self.params_gphh.set_feature
-        print("self.set_feature: ", self.set_feature)
-        print("Evaluation: ", self.params_gphh.evaluation)
-        # if set_feature is None:
-        #     self.set_feature = {FeatureEnum.RESSOURCE_TOTAL,
-        #                         FeatureEnum.TASK_DURATION,
-        #                         FeatureEnum.N_SUCCESSORS,
-        #                         FeatureEnum.N_SUCCESSORS,
-        #                         FeatureEnum.RESSOURCE_AVG}
-        self.list_feature = list(self.set_feature)
-        self.verbose = verbose
-        self.pset = self.init_primitives(self.params_gphh.set_primitves)
-        self.weight = weight
-        self.evaluation_method = self.params_gphh.evaluation
-        self.initialize_cpm_data_for_training()
-        if self.evaluation_method == EvaluationGPHH.PERMUTATION_DISTANCE:
-            self.init_reference_permutations(
-                reference_permutations, training_domains_names
-            )
-            self.permutation_distance = self.params_gphh.permutation_distance
-        # if self.evaluation_method == EvaluationGPHH.SGS_DEVIATION:
-        #     self.init_reference_makespans(reference_makespans, training_domains_names)
-
-    def init_reference_permutations(
-        self, reference_permutations={}, training_domains_names=[]
-    ) -> None:
-        self.reference_permutations = {}
-        for i in range(len(self.training_domains)):
-            td = self.training_domains[i]
-            td_name = training_domains_names[i]
-            if td_name not in reference_permutations.keys():
-                # Run CP
-                td.set_inplace_environment(False)
-                solver = DOSolver(
-                    policy_method_params=PolicyMethodParams(
-                        base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
-                        delta_index_freedom=0,
-                        delta_time_freedom=0,
-                    ),
-                    method=SolvingMethod.CP,
-                )
-                solver.solve(domain_factory=lambda: td)
-                raw_permutation = solver.best_solution.rcpsp_permutation
-                full_permutation = [x + 2 for x in raw_permutation]
-                full_permutation.insert(0, 1)
-                full_permutation.append(np.max(full_permutation) + 1)
-                print("full_perm: ", full_permutation)
-                self.reference_permutations[td] = full_permutation
-            else:
-                self.reference_permutations[td] = reference_permutations[td_name]
-
-    # def init_reference_makespans(self, reference_makespans={}, training_domains_names=[]) -> None:
-    #     self.reference_makespans = {}
-    #     for i in range(len(self.training_domains)):
-    #         td = self.training_domains[i]
-    #         td_name = training_domains_names[i]
-    #     # for td in self.training_domains:
-    #         print('td:',td)
-    #         if td_name not in reference_makespans.keys():
-    #             # Run CP
-    #             td.set_inplace_environment(False)
-    #             solver = DOSolver(policy_method_params=PolicyMethodParams(base_policy_method=BasePolicyMethod.FOLLOW_GANTT,
-    #                                                           delta_index_freedom=0,
-    #                                                           delta_time_freedom=0),
-    #                               method=SolvingMethod.CP)
-    #             solver.solve(domain_factory=lambda: td)
-    #
-    #             state = td.get_initial_state()
-    #             states, actions, values = rollout_episode(domain=td,
-    #                                                       max_steps=1000,
-    #                                                       solver=solver,
-    #                                                       from_memory=state,
-    #                                                       verbose=False,
-    #                                                       outcome_formatter=lambda
-    #                                                           o: f'{o.observation} - cost: {o.value.cost:.2f}')
-    #
-    #             makespan = sum([v.cost for v in values])
-    #             self.reference_makespans[td] = makespan
-    #         else:
-    #             self.reference_makespans[td] = reference_makespans[td_name]
-
-    def _solve_domain(self, domain_factory: Callable[[], D]) -> None:
-        self.domain = domain_factory()
-
-        tournament_ratio = self.params_gphh.tournament_ratio
-        pop_size = self.params_gphh.pop_size
-        n_gen = self.params_gphh.n_gen
-        min_tree_depth = self.params_gphh.min_tree_depth
-        max_tree_depth = self.params_gphh.max_tree_depth
-        crossover_rate = self.params_gphh.crossover_rate
-        mutation_rate = self.params_gphh.mutation_rate
-
-        creator.create("FitnessMin", Fitness, weights=(self.weight,))
-        creator.create("Individual", PrimitiveTree, fitness=creator.FitnessMin)
-
-        self.toolbox = Toolbox()
-        self.toolbox.register(
-            "expr",
-            genHalfAndHalf,
-            pset=self.pset,
-            min_=min_tree_depth,
-            max_=max_tree_depth,
-        )
-        self.toolbox.register(
-            "individual", tools.initIterate, creator.Individual, self.toolbox.expr
-        )
-        self.toolbox.register(
-            "population", tools.initRepeat, list, self.toolbox.individual
-        )
-        self.toolbox.register("compile", gp.compile, pset=self.pset)
-
-        if self.evaluation_method == EvaluationGPHH.SGS:
-            self.toolbox.register(
-                "evaluate", self.evaluate_heuristic, domains=self.training_domains
-            )
-        # if self.evaluation_method == EvaluationGPHH.SGS_DEVIATION:
-        #     self.toolbox.register("evaluate", self.evaluate_heuristic_sgs_deviation, domains=self.training_domains)
-        elif self.evaluation_method == EvaluationGPHH.PERMUTATION_DISTANCE:
-            self.toolbox.register(
-                "evaluate",
-                self.evaluate_heuristic_permutation,
-                domains=self.training_domains,
-            )
-        # self.toolbox.register("evaluate", self.evaluate_heuristic, domains=[self.training_domains[1]])
-
-        self.toolbox.register(
-            "select", tools.selTournament, tournsize=int(tournament_ratio * pop_size)
-        )
-        self.toolbox.register("mate", gp.cxOnePoint)
-        self.toolbox.register("expr_mut", gp.genFull, min_=0, max_=max_tree_depth)
-        self.toolbox.register(
-            "mutate", gp.mutUniform, expr=self.toolbox.expr_mut, pset=self.pset
-        )
-
-        self.toolbox.decorate(
-            "mate", gp.staticLimit(key=operator.attrgetter("height"), max_value=17)
-        )
-        self.toolbox.decorate(
-            "mutate", gp.staticLimit(key=operator.attrgetter("height"), max_value=17)
-        )
-
-        stats_fit = tools.Statistics(lambda ind: ind.fitness.values)
-        stats_size = tools.Statistics(len)
-        mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)
-        mstats.register("avg", np.mean)
-        mstats.register("std", np.std)
-        mstats.register("min", np.min)
-        mstats.register("max", np.max)
-
-        pop = self.toolbox.population(n=pop_size)
-        hof = tools.HallOfFame(1)
-        self.hof = hof
-        pop, log = algorithms.eaSimple(
-            pop,
-            self.toolbox,
-            crossover_rate,
-            mutation_rate,
-            n_gen,
-            stats=mstats,
-            halloffame=hof,
-            verbose=True,
-        )
-
-        self.best_heuristic = hof[0]
-        print("best_heuristic: ", self.best_heuristic)
-
-        self.func_heuristic = self.toolbox.compile(expr=self.best_heuristic)
-        self.policy = GPHHPolicy(
-            self.domain,
-            self.domain_model,
-            self.func_heuristic,
-            features=self.list_feature,
-            params_gphh=self.params_gphh,
-            recompute_cpm=True,
-        )
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        action = self.policy.sample_action(observation)
-        # print('action_1: ', action.action)
-        return action
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
-
-    def init_primitives(self, pset) -> PrimitiveSet:
-        for i in range(len(self.list_feature)):
-            pset.renameArguments(**{"ARG" + str(i): self.list_feature[i].value})
-        return pset
-
-    def evaluate_heuristic(self, individual, domains) -> float:
-        vals = []
-        func_heuristic = self.toolbox.compile(expr=individual)
-        # print('individual', individual)
-        for domain in domains:
-
-            ###
-            initial_state = domain.get_initial_state()
-
-            do_model = build_do_domain(domain)
-            modes = [
-                initial_state.tasks_mode.get(j, 1)
-                for j in sorted(domain.get_tasks_ids())
-            ]
-            modes = modes[1:-1]
-
-            cpm = self.cpm_data[domain]["cpm"]
-            cpm_esd = self.cpm_data[domain]["cpm_esd"]
-
-            raw_values = []
-            for task_id in domain.get_available_tasks(initial_state):
-                input_features = [
-                    feature_function_map[lf](
-                        domain=domain,
-                        cpm=cpm,
-                        cpm_esd=cpm_esd,
-                        task_id=task_id,
-                        state=initial_state,
-                    )
-                    for lf in self.list_feature
-                ]
-                output_value = func_heuristic(*input_features)
-                raw_values.append(output_value)
-
-            normalized_values = [
-                x + 1
-                for x in sorted(
-                    range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
-                )
-            ]
-            normalized_values_for_do = [
-                normalized_values[i] - 2
-                for i in range(len(normalized_values))
-                if normalized_values[i] not in {1, len(normalized_values)}
-            ]
-
-            solution = RCPSPSolution(
-                problem=do_model,
-                rcpsp_permutation=normalized_values_for_do,
-                rcpsp_modes=modes,
-            )
-            last_activity = max(list(solution.rcpsp_schedule.keys()))
-            do_makespan = solution.rcpsp_schedule[last_activity]["end_time"]
-            vals.append(do_makespan)
-
-        fitness = [np.mean(vals)]
-        # fitness = [np.max(vals)]
-        return fitness
-
-    # def evaluate_heuristic_sgs_deviation(self, individual, domains) -> float:
-    #     vals = []
-    #     func_heuristic = self.toolbox.compile(expr=individual)
-    #     # selected_domains = random.sample(domains, 3)
-    #     selected_domains = domains
-    #
-    #     for domain in selected_domains:
-    #         policy = GPHHPolicy(domain, domain,
-    #                             func_heuristic,
-    #                             features=self.list_feature,
-    #                             params_gphh=self.params_gphh, recompute_cpm=False, cpm_data=self.cpm_data
-    #                             )
-    #         state = domain.get_initial_state().copy()
-    #         domain.set_inplace_environment(True)  # we can use True because we don't use the value
-    #
-    #         states, actions, values = rollout_episode(domain=domain,
-    #                                                   max_steps=10000,
-    #                                                   solver=policy,
-    #                                                   from_memory=state,
-    #                                                   verbose=False,
-    #                                                   outcome_formatter=lambda
-    #                                                       o: f'{o.observation} - cost: {o.value.cost:.2f}')
-    #
-    #         makespan = states[-1].t
-    #         ref_makespan = self.reference_makespans[domain]
-    #         makespan_deviation = (makespan - ref_makespan) / ref_makespan
-    #         # print('mk: ', makespan, ' - mk_dev: ', makespan_deviation, ' - ref: ', ref_makespan)
-    #         vals.append(makespan_deviation)
-    #
-    #     # fitness = [np.mean(vals)]
-    #     fitness = [np.mean(vals)]
-    #     return fitness
-
-    def initialize_cpm_data_for_training(self):
-        self.cpm_data = {}
-        for domain in self.training_domains:
-            do_model = build_do_domain(domain)
-            cpm, cpm_esd = compute_cpm(do_model)
-            self.cpm_data[domain] = {"cpm": cpm, "cpm_esd": cpm_esd}
-
-    def evaluate_heuristic_permutation(self, individual, domains) -> float:
-        vals = []
-        func_heuristic = self.toolbox.compile(expr=individual)
-        # print('individual', individual)
-
-        for domain in domains:
-
-            raw_values = []
-            initial_state = domain.get_initial_state()
-
-            regenerate_cpm = False
-            if regenerate_cpm:
-                do_model = build_do_domain(domain)
-                cpm, cpm_esd = compute_cpm(do_model)
-            else:
-                cpm = self.cpm_data[domain]["cpm"]
-                cpm_esd = self.cpm_data[domain]["cpm_esd"]
-
-            for task_id in domain.get_available_tasks(state=initial_state):
-
-                input_features = [
-                    feature_function_map[lf](
-                        domain=domain,
-                        cpm=cpm,
-                        cpm_esd=cpm_esd,
-                        task_id=task_id,
-                        state=initial_state,
-                    )
-                    for lf in self.list_feature
-                ]
-                output_value = func_heuristic(*input_features)
-                raw_values.append(output_value)
-
-            most_common_raw_val = max(raw_values, key=raw_values.count)
-            most_common_count = raw_values.count(most_common_raw_val)
-
-            heuristic_permutation = [
-                x + 1
-                for x in sorted(
-                    range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
-                )
-            ]
-
-            if self.permutation_distance == PermutationDistance.KTD:
-                dist, p_value = stats.kendalltau(
-                    heuristic_permutation, self.reference_permutations[domain]
-                )
-                dist = -dist
-
-            if self.permutation_distance == PermutationDistance.HAMMING:
-                dist = distance.hamming(
-                    heuristic_permutation, self.reference_permutations[domain]
-                )
-
-            if self.permutation_distance == PermutationDistance.KTD_HAMMING:
-                ktd, _ = stats.kendalltau(
-                    heuristic_permutation, self.reference_permutations[domain]
-                )
-                dist = -ktd + distance.hamming(
-                    heuristic_permutation, self.reference_permutations[domain]
-                )
-
-            penalty = most_common_count / len(raw_values)
-            # penalty = 0.
-            penalized_distance = dist + penalty
-            vals.append(penalized_distance)
-        fitness = [np.mean(vals)]
-        # fitness = [np.max(vals)]
-        return fitness
-
-    def test_features(self, domain, task_id, observation):
-        for f in FeatureEnum:
-            print("feature: ", f)
-            calculated_feature = feature_function_map[f](
-                domain=domain, task_id=task_id, state=observation
-            )
-            print("\tcalculated_feature: ", calculated_feature)
-
-    def set_domain(self, domain):
-        self.domain = domain
-        if self.policy is not None:
-            self.policy.domain = domain
-
-
-class GPHHPolicy(DeterministicPolicies):
-    def __init__(
-        self,
-        domain: SchedulingDomain,
-        domain_model: SchedulingDomain,
-        func_heuristic,
-        features: List[FeatureEnum] = None,
-        params_gphh=None,
-        recompute_cpm=True,
-        cpm_data=None,
-    ):
-        self.domain = domain
-        self.domain_model = domain_model
-        self.func_heuristic = func_heuristic
-        self.list_feature = features
-        self.params_gphh = params_gphh
-        self.recompute_cpm = recompute_cpm
-        self.cpm_data = cpm_data
-
-    def reset(self):
-        pass
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        run_sgs = True
-        cheat_mode = False
-
-        do_model = build_do_domain(self.domain_model)
-        modes = [
-            observation.tasks_mode.get(j, 1)
-            for j in sorted(self.domain.get_tasks_ids())
-        ]
-        modes = modes[1:-1]
-        scheduled_tasks_start_times = {}
-        if run_sgs:
-            tasks_details = rebuild_all_tasks_dict(observation)
-            for j in tasks_details:
-                if tasks_details[j].start is not None:
-                    scheduled_tasks_start_times[j] = tasks_details[j].start
-                    do_model.mode_details[j][1]["duration"] = tasks_details[
-                        j
-                    ].sampled_duration
-            # needed to update the numba functions to take into account
-            # the sampled durations of the current scheduling state.
-            do_model.update_functions()
-
-        # do_model = build_do_domain(self.domain)
-        # modes = [observation.tasks_mode.get(j, 1) for j in sorted(self.domain.get_tasks_ids())]
-        # modes = modes[1:-1]
-        #
-        # if run_sgs:
-        #     scheduled_tasks_start_times = {}
-        #     for j in observation.tasks_details.keys():
-        #         if observation.tasks_details[j].start is not None:
-        #             scheduled_tasks_start_times[j] = observation.tasks_details[j].start
-        #         else:
-        #             if not cheat_mode:
-        #                 do_model.mode_details[j][1]['duration'] = self.domain_model.sample_task_duration(j, 1, 0.)
-
-        if self.recompute_cpm:
-            cpm, cpm_esd = compute_cpm(do_model)
-        else:
-            cpm = self.cpm_data[self.domain]["cpm"]
-            cpm_esd = self.cpm_data[self.domain]["cpm_esd"]
-
-        t = observation.t
-        raw_values = []
-        for task_id in self.domain.get_available_tasks(observation):
-            input_features = [
-                feature_function_map[lf](
-                    domain=self.domain,
-                    cpm=cpm,
-                    cpm_esd=cpm_esd,
-                    task_id=task_id,
-                    state=observation,
-                )
-                for lf in self.list_feature
-            ]
-            output_value = self.func_heuristic(*input_features)
-            raw_values.append(output_value)
-
-        normalized_values = [
-            x + 1
-            for x in sorted(
-                range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
-            )
-        ]
-        normalized_values_for_do = [
-            normalized_values[i] - 2
-            for i in range(len(normalized_values))
-            if normalized_values[i] not in {1, len(normalized_values)}
-        ]
-
-        # print(t, ': ', normalized_values)
-        # print('normalized_values_for_do: ', normalized_values_for_do)
-
-        modes_dictionnary = {}
-        for i in range(len(normalized_values)):
-            modes_dictionnary[i + 1] = 1
-
-        if run_sgs:
-            tasks_complete_dict = rebuild_tasks_complete_details_dict(observation)
-            # Force the scheduler_tasks_start_times to be disjoint with the complete tasks,
-            # this avoid a corner effect giving wrong results in the numba SGS implementation
-            # (sgs_fast_partial_schedule_incomplete_permutation_tasks)
-            scheduled_tasks_start_times = {
-                j: scheduled_tasks_start_times[j]
-                for j in scheduled_tasks_start_times
-                if j not in tasks_complete_dict
-            }
-            solution = RCPSPSolution(
-                problem=do_model,
-                rcpsp_permutation=normalized_values_for_do,
-                rcpsp_modes=modes,
-            )
-            solution.generate_schedule_from_permutation_serial_sgs_2(
-                current_t=t,
-                completed_tasks=tasks_complete_dict,
-                scheduled_tasks_start_times=scheduled_tasks_start_times,
-            )
-
-            schedule = solution.rcpsp_schedule
-        else:
-            schedule = None
-
-        sgs_policy = PolicyRCPSP(
-            domain=self.domain,
-            schedule=schedule,
-            policy_method_params=PolicyMethodParams(
-                # base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
-                # base_policy_method=BasePolicyMethod.SGS_READY,
-                base_policy_method=self.params_gphh.base_policy_method,
-                delta_index_freedom=self.params_gphh.delta_index_freedom,
-                delta_time_freedom=self.params_gphh.delta_time_freedom,
-            ),
-            permutation_task=normalized_values,
-            modes_dictionnary=modes_dictionnary,
-        )
-        action: SchedulingAction = sgs_policy.sample_action(observation)
-        # print('action_2: ', action.action)
-        return action
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
-
-
-class PoolAggregationMethod(Enum):
-    MEAN = "mean"
-    MEDIAN = "median"
-    RANDOM = "random"
-
-
-class PooledGPHHPolicy(DeterministicPolicies):
-    def __init__(
-        self,
-        domain: SchedulingDomain,
-        domain_model: SchedulingDomain,
-        func_heuristics,
-        pool_aggregation_method: PoolAggregationMethod = PoolAggregationMethod.MEAN,
-        remove_extremes_values: int = 0,
-        features: List[FeatureEnum] = None,
-        params_gphh=None,
-    ):
-        self.domain = domain
-        self.domain_model = domain_model
-        self.func_heuristics = func_heuristics
-        self.list_feature = features
-        self.params_gphh = params_gphh
-        self.pool_aggregation_method = pool_aggregation_method
-        self.remove_extremes_values = remove_extremes_values
-
-    def reset(self):
-        pass
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-
-        run_sgs = True
-        cheat_mode = False
-        regenerate_cpm = True
-
-        do_model = build_do_domain(self.domain_model)
-        modes = [
-            observation.tasks_mode.get(j, 1)
-            for j in sorted(self.domain.get_tasks_ids())
-        ]
-        modes = modes[1:-1]
-
-        if run_sgs:
-            scheduled_tasks_start_times = {}
-            tasks_details = rebuild_all_tasks_dict(observation)
-            for j in tasks_details:
-                if tasks_details[j].start is not None:
-                    scheduled_tasks_start_times[j] = tasks_details[j].start
-                    do_model.mode_details[j][1]["duration"] = tasks_details[
-                        j
-                    ].sampled_duration
-
-        # do_model = build_do_domain(self.domain)
-        # modes = [observation.tasks_mode.get(j, 1) for j in sorted(self.domain.get_tasks_ids())]
-        # modes = modes[1:-1]
-        #
-        # if run_sgs:
-        #     scheduled_tasks_start_times = {}
-        #     for j in observation.tasks_details.keys():
-        #         # schedule[j] = {}
-        #         if observation.tasks_details[j].start is not None:
-        #             # schedule[j]["start_time"] = observation.tasks_details[j].start
-        #             scheduled_tasks_start_times[j] = observation.tasks_details[j].start
-        #         # if observation.tasks_details[j].end is not None:
-        #         #     schedule[j]["end_time"] = observation.tasks_details[j].end
-        #         else:
-        #             if not cheat_mode:
-        #                 do_model.mode_details[j][1]['duration'] = self.domain_model.sample_task_duration(j, 1, 0.)
-
-        if regenerate_cpm:
-            cpm, cpm_esd = compute_cpm(do_model)
-
-        t = observation.t
-        raw_values = []
-        for task_id in self.domain.get_available_tasks(observation):
-            input_features = [
-                feature_function_map[lf](
-                    domain=self.domain,
-                    cpm=cpm,
-                    cpm_esd=cpm_esd,
-                    task_id=task_id,
-                    state=observation,
-                )
-                for lf in self.list_feature
-            ]
-            output_values = []
-            for f in self.func_heuristics:
-                output_value = f(*input_features)
-                output_values.append(output_value)
-
-            # print('output_values: ', output_values)
-            if self.remove_extremes_values > 0:
-                the_median = float(np.median(output_values))
-                tmp = {}
-                for i in range(len(output_values)):
-                    tmp[i] = abs(output_values[i] - the_median)
-                tmp = sorted(tmp.items(), key=lambda x: x[1], reverse=True)
-                to_remove = [tmp[i][0] for i in range(self.remove_extremes_values)]
-                output_values = list(np.delete(output_values, to_remove))
-
-            # print('output_values filtered: ', output_values)
-            if self.pool_aggregation_method == PoolAggregationMethod.MEAN:
-                agg_value = np.mean(output_values)
-            elif self.pool_aggregation_method == PoolAggregationMethod.MEDIAN:
-                agg_value = np.median(output_values)
-            elif self.pool_aggregation_method == PoolAggregationMethod.RANDOM:
-                index = random.randint(len(output_values))
-                agg_value = output_values[index]
-
-            # print('agg_value: ', agg_value)
-            raw_values.append(agg_value)
-
-        normalized_values = [
-            x + 1
-            for x in sorted(
-                range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
-            )
-        ]
-        normalized_values_for_do = [
-            normalized_values[i] - 2
-            for i in range(len(normalized_values))
-            if normalized_values[i] not in {1, len(normalized_values)}
-        ]
-
-        # print('normalized_values: ', normalized_values)
-        # print('normalized_values_for_do: ', normalized_values_for_do)
-
-        modes_dictionnary = {}
-        for i in range(len(normalized_values)):
-            modes_dictionnary[i + 1] = 1
-
-        if run_sgs:
-
-            solution = RCPSPSolution(
-                problem=do_model,
-                rcpsp_permutation=normalized_values_for_do,
-                rcpsp_modes=modes,
-            )
-            tasks_complete_dict = rebuild_tasks_complete_details_dict(observation)
-            solution.generate_schedule_from_permutation_serial_sgs_2(
-                current_t=t,
-                completed_tasks=tasks_complete_dict,
-                scheduled_tasks_start_times=scheduled_tasks_start_times,
-            )
-
-            schedule = solution.rcpsp_schedule
-        else:
-            schedule = None
-
-        sgs_policy = PolicyRCPSP(
-            domain=self.domain,
-            schedule=schedule,
-            policy_method_params=PolicyMethodParams(
-                # base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
-                # base_policy_method=BasePolicyMethod.SGS_READY,
-                base_policy_method=self.params_gphh.base_policy_method,
-                delta_index_freedom=self.params_gphh.delta_index_freedom,
-                delta_time_freedom=self.params_gphh.delta_time_freedom,
-            ),
-            permutation_task=normalized_values,
-            modes_dictionnary=modes_dictionnary,
-        )
-        action: SchedulingAction = sgs_policy.sample_action(observation)
-        # print('action_2: ', action.action)
-        return action
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
-
-
-class FixedPermutationPolicy(DeterministicPolicies):
-    def __init__(
-        self, domain: SchedulingDomain, domain_model: SchedulingDomain, fixed_perm
-    ):
-        self.domain = domain
-        self.domain_model = domain_model
-        self.fixed_perm = fixed_perm
-
-    def reset(self):
-        pass
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        run_sgs = True
-        cheat_mode = False
-
-        do_model = build_do_domain(self.domain_model)
-        modes = [
-            observation.tasks_mode.get(j, 1)
-            for j in sorted(self.domain.get_tasks_ids())
-        ]
-        modes = modes[1:-1]
-
-        if run_sgs:
-            scheduled_tasks_start_times = {}
-            tasks_details = rebuild_all_tasks_dict(observation)
-            for j in tasks_details.keys():
-                if tasks_details[j].start is not None:
-                    scheduled_tasks_start_times[j] = tasks_details[j].start
-                    do_model.mode_details[j][1]["duration"] = tasks_details[
-                        j
-                    ].sampled_duration
-
-        # do_model = build_do_domain(self.domain)
-        # modes = [observation.tasks_mode.get(j, 1) for j in sorted(self.domain.get_tasks_ids())]
-        # modes = modes[1:-1]
-        #
-        # if run_sgs:
-        #     scheduled_tasks_start_times = {}
-        #     for j in observation.tasks_details.keys():
-        #         # schedule[j] = {}
-        #         if observation.tasks_details[j].start is not None:
-        #             # schedule[j]["start_time"] = observation.tasks_details[j].start
-        #             scheduled_tasks_start_times[j] = observation.tasks_details[j].start
-        #         # if observation.tasks_details[j].end is not None:
-        #         #     schedule[j]["end_time"] = observation.tasks_details[j].end
-        #         else:
-        #             if not cheat_mode:
-        #                 # print('do_model: ', do_model)
-        #                 do_model.mode_details[j][1]['duration'] = self.domain_model.sample_task_duration(j, 1, 0.)
-
-        normalized_values = self.fixed_perm
-
-        normalized_values_for_do = [
-            normalized_values[i] - 2
-            for i in range(len(normalized_values))
-            if normalized_values[i] not in {1, len(normalized_values)}
-        ]
-
-        # print('normalized_values: ', normalized_values)
-        # print('normalized_values_for_do: ', normalized_values_for_do)
-        t = observation.t
-
-        modes_dictionnary = {}
-        for i in range(len(normalized_values)):
-            modes_dictionnary[i + 1] = 1
-
-        if run_sgs:
-
-            solution = RCPSPSolution(
-                problem=do_model,
-                rcpsp_permutation=normalized_values_for_do,
-                rcpsp_modes=modes,
-            )
-            tasks_details_complete = rebuild_tasks_complete_details_dict(observation)
-            solution.generate_schedule_from_permutation_serial_sgs_2(
-                current_t=t,
-                completed_tasks=tasks_details_complete,
-                scheduled_tasks_start_times=scheduled_tasks_start_times,
-            )
-
-            schedule = solution.rcpsp_schedule
-        else:
-            schedule = None
-
-        sgs_policy = PolicyRCPSP(
-            domain=self.domain,
-            schedule=schedule,
-            policy_method_params=PolicyMethodParams(
-                # base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
-                # base_policy_method=BasePolicyMethod.SGS_READY,
-                base_policy_method=BasePolicyMethod.FOLLOW_GANTT,
-                # delta_index_freedom=self.params_gphh.delta_index_freedom,
-                # delta_time_freedom=self.params_gphh.delta_time_freedom
-            ),
-            permutation_task=normalized_values,
-            modes_dictionnary=modes_dictionnary,
-        )
-        action: SchedulingAction = sgs_policy.sample_action(observation)
-        # print('action_2: ', action.action)
-        return action
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import operator
+import random
+from enum import Enum
+from typing import Callable, Dict, List, Set
+
+import numpy as np
+from deap import algorithms, creator, gp, tools
+from deap.base import Fitness, Toolbox
+from deap.gp import PrimitiveSet, PrimitiveTree, genHalfAndHalf
+from discrete_optimization.rcpsp.rcpsp_model import RCPSPSolution
+from discrete_optimization.rcpsp.solver.cpm import CPM
+from scipy import stats
+from scipy.spatial import distance
+
+from skdecide import Solver
+from skdecide.builders.domain.scheduling.modes import SingleMode
+from skdecide.builders.domain.scheduling.scheduling_domains import D, SchedulingDomain
+from skdecide.builders.domain.scheduling.scheduling_domains_modelling import (
+    SchedulingAction,
+    State,
+    rebuild_all_tasks_dict,
+    rebuild_tasks_complete_details_dict,
+)
+from skdecide.builders.solver.policy import DeterministicPolicies
+from skdecide.hub.solver.do_solver.do_solver_scheduling import (
+    DOSolver,
+    PolicyMethodParams,
+    PolicyRCPSP,
+    SolvingMethod,
+)
+from skdecide.hub.solver.do_solver.sgs_policies import BasePolicyMethod
+from skdecide.hub.solver.do_solver.sk_to_do_binding import build_do_domain
+
+
+def if_then_else(input, output1, output2):
+    if input:
+        return output1
+    else:
+        return output2
+
+
+def protected_div(left, right):
+    if right != 0.0:
+        return left / right
+    else:
+        return 1.0
+
+
+def max_operator(left, right):
+    return max(left, right)
+
+
+def min_operator(left, right):
+    return min(left, right)
+
+
+def feature_task_duration(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    return domain.sample_task_duration(task_id)
+
+
+def feature_total_n_res(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
+    val = 0
+    mode_consumption = domain.get_task_modes(task_id)[1]
+    for res in mode_consumption.get_ressource_names():
+        val += mode_consumption.get_resource_need(res)
+    return val
+
+
+def feature_n_successors(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    return len(domain.get_successors_task(task_id)) / len(domain.get_tasks_ids())
+
+
+def feature_n_predecessors(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    return len(domain.get_predecessors_task(task_id)) / len(domain.get_tasks_ids())
+
+
+def get_resource_requirements_across_duration(
+    domain: SchedulingDomain, task_id: int, **kwargs
+):
+    values = []
+    mode_consumption = domain.get_task_modes(task_id)[1]
+    duration = domain.get_latest_sampled_duration(task_id, 1, 0.0)
+    if duration > 0:
+        for res in mode_consumption.get_ressource_names():
+            tmp = 0
+            for t in range(duration):
+                need = mode_consumption.get_resource_need_at_time(res, t)
+                total = domain.sample_quantity_resource(res, t)
+                tmp += need / total
+            values.append(tmp / duration)
+    else:
+        values = [0.0]
+    # print(task_id,':', values)
+    return values
+
+
+def feature_average_resource_requirements(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
+    val = np.mean(values)
+    return val
+
+
+def feature_minimum_resource_requirements(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
+    val = np.min(values)
+    return val
+
+
+def feature_non_zero_minimum_resource_requirements(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
+    if np.sum(values) > 0.0:
+        val = np.min([x for x in values if x > 0.0])
+    else:
+        val = np.min(values)
+    return val
+
+
+def feature_maximum_resource_requirements(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
+    val = np.max(values)
+    return val
+
+
+def feature_resource_requirements(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    values = get_resource_requirements_across_duration(domain=domain, task_id=task_id)
+    val = len([x for x in values if x > 0.0]) / len(values)
+    return val
+
+
+def feature_all_descendants(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs
+):
+    return len(domain.full_successors[task_id]) / len(domain.get_tasks_ids())
+
+
+def feature_precedence_done(
+    domain: SchedulingDomain, cpm, cpm_esd, task_id: int, state: State, **kwargs
+):
+    return task_id in domain.task_possible_to_launch_precedence(state=state)
+
+
+def compute_cpm(do_domain):
+    cpm_solver = CPM(do_domain)
+    path = cpm_solver.run_classic_cpm()
+    cpm = cpm_solver.map_node
+    cpm_esd = cpm[path[-1]]._ESD  # to normalize...
+    return cpm, cpm_esd
+
+
+def feature_esd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
+    """Will only work if you store cpm results into the object"""
+    return cpm[task_id]._ESD / cpm_esd
+
+
+def feature_lsd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
+    """Will only work if you store cpm results into the object"""
+    return cpm[task_id]._LSD / cpm_esd
+
+
+def feature_efd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
+    """Will only work if you store cpm results into the object"""
+    return cpm[task_id]._EFD / cpm_esd
+
+
+def feature_lfd(domain: SchedulingDomain, cpm, cpm_esd, task_id: int, **kwargs):
+    """Will only work if you store cpm results into the object"""
+    return cpm[task_id]._LFD / cpm_esd
+
+
+class D(SchedulingDomain, SingleMode):
+    pass
+
+
+class FeatureEnum(Enum):
+    TASK_DURATION = "task_duration"
+    RESSOURCE_TOTAL = "total_nres"
+    N_SUCCESSORS = "n_successors"
+    N_PREDECESSORS = "n_predecessors"
+    RESSOURCE_REQUIRED = "res_requ"
+    RESSOURCE_AVG = "avg_res_requ"
+    RESSOURCE_MIN = "min_res_requ"
+    RESSOURCE_NZ_MIN = "nz_min_res_requ"
+    RESSOURCE_MAX = "max_res_requ"
+    ALL_DESCENDANTS = "all_descendants"
+    PRECEDENCE_DONE = "precedence_done"
+    EARLIEST_START_DATE = "ESD"
+    LATEST_START_DATE = "LSD"
+    EARLIEST_FINISH_DATE = "EFD"
+    LATEST_FINISH_DATE = "LFD"
+
+
+feature_function_map = {
+    FeatureEnum.TASK_DURATION: feature_task_duration,
+    FeatureEnum.RESSOURCE_TOTAL: feature_total_n_res,
+    FeatureEnum.N_SUCCESSORS: feature_n_successors,
+    FeatureEnum.N_PREDECESSORS: feature_n_predecessors,  #
+    FeatureEnum.RESSOURCE_REQUIRED: feature_resource_requirements,  #
+    FeatureEnum.RESSOURCE_AVG: feature_average_resource_requirements,  #
+    FeatureEnum.RESSOURCE_MIN: feature_minimum_resource_requirements,  #
+    FeatureEnum.RESSOURCE_NZ_MIN: feature_non_zero_minimum_resource_requirements,  #
+    FeatureEnum.RESSOURCE_MAX: feature_maximum_resource_requirements,  #
+    FeatureEnum.ALL_DESCENDANTS: feature_all_descendants,  #
+    FeatureEnum.PRECEDENCE_DONE: feature_precedence_done,
+    FeatureEnum.EARLIEST_START_DATE: feature_esd,  #
+    FeatureEnum.EARLIEST_FINISH_DATE: feature_efd,  #
+    FeatureEnum.LATEST_START_DATE: feature_lsd,  #
+    FeatureEnum.LATEST_FINISH_DATE: feature_lfd,
+}  #
+
+feature_static_map = {
+    FeatureEnum.TASK_DURATION: True,
+    FeatureEnum.RESSOURCE_TOTAL: True,
+    FeatureEnum.N_SUCCESSORS: True,
+    FeatureEnum.N_PREDECESSORS: True,  #
+    FeatureEnum.RESSOURCE_REQUIRED: True,  #
+    FeatureEnum.RESSOURCE_AVG: True,  #
+    FeatureEnum.RESSOURCE_MIN: True,  #
+    FeatureEnum.RESSOURCE_NZ_MIN: True,  #
+    FeatureEnum.RESSOURCE_MAX: True,  #
+    FeatureEnum.ALL_DESCENDANTS: True,  #
+    FeatureEnum.PRECEDENCE_DONE: False,
+    FeatureEnum.EARLIEST_START_DATE: True,  #
+    FeatureEnum.EARLIEST_FINISH_DATE: True,  #
+    FeatureEnum.LATEST_START_DATE: True,  #
+    FeatureEnum.LATEST_FINISH_DATE: True,
+}  #
+
+
+class EvaluationGPHH(Enum):
+    SGS = 0
+    PERMUTATION_DISTANCE = 1
+    # SGS_DEVIATION = 2
+
+
+class PermutationDistance(Enum):
+    KTD = 0
+    HAMMING = 1
+    KTD_HAMMING = 2
+
+
+class ParametersGPHH:
+    set_feature: Set[FeatureEnum] = None
+    set_primitves: PrimitiveSet = None
+    tournament_ratio: float = None
+    pop_size: int = None
+    n_gen: int = None
+    min_tree_depth: int = None
+    max_tree_depth: int = None
+    crossover_rate: float = None
+    mutation_rate: float = None
+    base_policy_method = None
+    delta_index_freedom: int = None
+    delta_time_freedom: int = None
+    deap_verbose: bool = None
+    evaluation: EvaluationGPHH = None
+    permutation_distance = PermutationDistance.KTD
+
+    def __init__(
+        self,
+        set_feature,
+        set_primitves,
+        tournament_ratio,
+        pop_size,
+        n_gen,
+        min_tree_depth,
+        max_tree_depth,
+        crossover_rate,
+        mutation_rate,
+        base_policy_method,
+        delta_index_freedom,
+        delta_time_freedom,
+        deap_verbose,
+        evaluation,
+        permutation_distance,
+    ):
+        self.set_feature = set_feature
+        self.set_primitves = set_primitves
+        self.tournament_ratio = tournament_ratio
+        self.pop_size = pop_size
+        self.n_gen = n_gen
+        self.min_tree_depth = min_tree_depth
+        self.max_tree_depth = max_tree_depth
+        self.crossover_rate = crossover_rate
+        self.mutation_rate = mutation_rate
+        self.base_policy_method = base_policy_method
+        self.delta_index_freedom = delta_index_freedom
+        self.delta_time_freedom = delta_time_freedom
+        self.deap_verbose = deap_verbose
+        self.evaluation = evaluation
+        self.permutation_distance = permutation_distance
+
+    @staticmethod
+    def default():
+        set_feature = {
+            FeatureEnum.EARLIEST_FINISH_DATE,
+            FeatureEnum.EARLIEST_START_DATE,
+            FeatureEnum.LATEST_FINISH_DATE,
+            FeatureEnum.LATEST_START_DATE,
+            FeatureEnum.N_PREDECESSORS,
+            FeatureEnum.N_SUCCESSORS,
+            FeatureEnum.ALL_DESCENDANTS,
+            FeatureEnum.RESSOURCE_REQUIRED,
+            FeatureEnum.RESSOURCE_AVG,
+            FeatureEnum.RESSOURCE_MAX,
+            # FeatureEnum.RESSOURCE_MIN
+            FeatureEnum.RESSOURCE_NZ_MIN,
+        }
+
+        pset = PrimitiveSet("main", len(set_feature))
+        pset.addPrimitive(operator.add, 2)
+        pset.addPrimitive(operator.sub, 2)
+        pset.addPrimitive(operator.mul, 2)
+        pset.addPrimitive(protected_div, 2)
+        pset.addPrimitive(max_operator, 2)
+        pset.addPrimitive(min_operator, 2)
+        pset.addPrimitive(operator.neg, 1)
+
+        return ParametersGPHH(
+            set_feature=set_feature,
+            set_primitves=pset,
+            tournament_ratio=0.1,
+            pop_size=40,
+            n_gen=100,
+            min_tree_depth=1,
+            max_tree_depth=4,
+            crossover_rate=0.7,
+            mutation_rate=0.3,
+            base_policy_method=BasePolicyMethod.FOLLOW_GANTT,
+            delta_index_freedom=0,
+            delta_time_freedom=0,
+            deap_verbose=True,
+            # evaluation=EvaluationGPHH.PERMUTATION_DISTANCE,
+            evaluation=EvaluationGPHH.SGS,
+            permutation_distance=PermutationDistance.KTD,
+        )
+
+    @staticmethod
+    def fast_test():
+        set_feature = {
+            FeatureEnum.EARLIEST_FINISH_DATE,
+            FeatureEnum.EARLIEST_START_DATE,
+            FeatureEnum.LATEST_FINISH_DATE,
+            FeatureEnum.LATEST_START_DATE,
+            FeatureEnum.N_PREDECESSORS,
+            FeatureEnum.N_SUCCESSORS,
+            FeatureEnum.ALL_DESCENDANTS,
+            FeatureEnum.RESSOURCE_REQUIRED,
+            FeatureEnum.RESSOURCE_AVG,
+            FeatureEnum.RESSOURCE_MAX,
+            # FeatureEnum.RESSOURCE_MIN
+            FeatureEnum.RESSOURCE_NZ_MIN,
+        }
+
+        pset = PrimitiveSet("main", len(set_feature))
+        pset.addPrimitive(operator.add, 2)
+        pset.addPrimitive(operator.sub, 2)
+        pset.addPrimitive(operator.mul, 2)
+        pset.addPrimitive(protected_div, 2)
+        pset.addPrimitive(max_operator, 2)
+        pset.addPrimitive(min_operator, 2)
+        pset.addPrimitive(operator.neg, 1)
+
+        return ParametersGPHH(
+            set_feature=set_feature,
+            set_primitves=pset,
+            tournament_ratio=0.1,
+            pop_size=10,
+            n_gen=2,
+            min_tree_depth=1,
+            max_tree_depth=4,
+            crossover_rate=0.7,
+            mutation_rate=0.3,
+            base_policy_method=BasePolicyMethod.FOLLOW_GANTT,
+            delta_index_freedom=0,
+            delta_time_freedom=0,
+            deap_verbose=True,
+            evaluation=EvaluationGPHH.SGS,
+            # evaluation=EvaluationGPHH.PERMUTATION_DISTANCE,
+            permutation_distance=PermutationDistance.KTD,
+        )
+
+    @staticmethod
+    def default_for_set_features(set_feature: Set[FeatureEnum]):
+        pset = PrimitiveSet("main", len(set_feature))
+        pset.addPrimitive(operator.add, 2)
+        pset.addPrimitive(operator.sub, 2)
+        pset.addPrimitive(operator.mul, 2)
+        # pset.addPrimitive(protected_div, 2)
+        pset.addPrimitive(max_operator, 2)
+        pset.addPrimitive(min_operator, 2)
+        pset.addPrimitive(operator.neg, 1)
+
+        return ParametersGPHH(
+            set_feature=set_feature,
+            set_primitves=pset,
+            tournament_ratio=0.25,
+            pop_size=20,
+            n_gen=20,
+            min_tree_depth=1,
+            max_tree_depth=4,
+            crossover_rate=0.7,
+            mutation_rate=0.1,
+            base_policy_method=BasePolicyMethod.SGS_READY,
+            delta_index_freedom=0,
+            delta_time_freedom=0,
+            deap_verbose=True,
+            evaluation=EvaluationGPHH.PERMUTATION_DISTANCE,
+            permutation_distance=PermutationDistance.KTD,
+        )
+
+
+class GPHH(Solver, DeterministicPolicies):
+    T_domain = D
+
+    training_domains: List[T_domain]
+    verbose: bool
+    weight: int
+    pset: PrimitiveSet
+    toolbox: Toolbox
+    policy: DeterministicPolicies
+    params_gphh: ParametersGPHH
+    # policy: GPHHPolicy
+    evaluation_method: EvaluationGPHH
+    reference_permutations: Dict
+    permutation_distance: PermutationDistance
+
+    def __init__(
+        self,
+        domain_factory: Callable[[], SchedulingDomain],
+        training_domains: List[T_domain],
+        domain_model: SchedulingDomain,
+        weight: int,
+        # set_feature: Set[FeatureEnum]=None,
+        params_gphh: ParametersGPHH = ParametersGPHH.default(),
+        reference_permutations=None,
+        # reference_makespans=None,
+        training_domains_names=None,
+        verbose: bool = False,
+    ):
+        Solver.__init__(self, domain_factory=domain_factory)
+        self.training_domains = training_domains
+        self.domain_model = domain_model
+        self.params_gphh = params_gphh
+        # self.set_feature = set_feature
+        self.set_feature = self.params_gphh.set_feature
+        print("self.set_feature: ", self.set_feature)
+        print("Evaluation: ", self.params_gphh.evaluation)
+        # if set_feature is None:
+        #     self.set_feature = {FeatureEnum.RESSOURCE_TOTAL,
+        #                         FeatureEnum.TASK_DURATION,
+        #                         FeatureEnum.N_SUCCESSORS,
+        #                         FeatureEnum.N_SUCCESSORS,
+        #                         FeatureEnum.RESSOURCE_AVG}
+        self.list_feature = list(self.set_feature)
+        self.verbose = verbose
+        self.pset = self.init_primitives(self.params_gphh.set_primitves)
+        self.weight = weight
+        self.evaluation_method = self.params_gphh.evaluation
+        self.initialize_cpm_data_for_training()
+        if self.evaluation_method == EvaluationGPHH.PERMUTATION_DISTANCE:
+            self.init_reference_permutations(
+                reference_permutations, training_domains_names
+            )
+            self.permutation_distance = self.params_gphh.permutation_distance
+        # if self.evaluation_method == EvaluationGPHH.SGS_DEVIATION:
+        #     self.init_reference_makespans(reference_makespans, training_domains_names)
+
+    def init_reference_permutations(
+        self, reference_permutations={}, training_domains_names=[]
+    ) -> None:
+        self.reference_permutations = {}
+        for i in range(len(self.training_domains)):
+            td = self.training_domains[i]
+            td_name = training_domains_names[i]
+            if td_name not in reference_permutations.keys():
+                # Run CP
+                td.set_inplace_environment(False)
+                solver = DOSolver(
+                    domain_factory=lambda: td,
+                    policy_method_params=PolicyMethodParams(
+                        base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
+                        delta_index_freedom=0,
+                        delta_time_freedom=0,
+                    ),
+                    method=SolvingMethod.CP,
+                )
+                solver.solve()
+                raw_permutation = solver.best_solution.rcpsp_permutation
+                full_permutation = [x + 2 for x in raw_permutation]
+                full_permutation.insert(0, 1)
+                full_permutation.append(np.max(full_permutation) + 1)
+                print("full_perm: ", full_permutation)
+                self.reference_permutations[td] = full_permutation
+            else:
+                self.reference_permutations[td] = reference_permutations[td_name]
+
+    def _solve(self) -> None:
+        self.domain = self._domain_factory()
+
+        tournament_ratio = self.params_gphh.tournament_ratio
+        pop_size = self.params_gphh.pop_size
+        n_gen = self.params_gphh.n_gen
+        min_tree_depth = self.params_gphh.min_tree_depth
+        max_tree_depth = self.params_gphh.max_tree_depth
+        crossover_rate = self.params_gphh.crossover_rate
+        mutation_rate = self.params_gphh.mutation_rate
+
+        creator.create("FitnessMin", Fitness, weights=(self.weight,))
+        creator.create("Individual", PrimitiveTree, fitness=creator.FitnessMin)
+
+        self.toolbox = Toolbox()
+        self.toolbox.register(
+            "expr",
+            genHalfAndHalf,
+            pset=self.pset,
+            min_=min_tree_depth,
+            max_=max_tree_depth,
+        )
+        self.toolbox.register(
+            "individual", tools.initIterate, creator.Individual, self.toolbox.expr
+        )
+        self.toolbox.register(
+            "population", tools.initRepeat, list, self.toolbox.individual
+        )
+        self.toolbox.register("compile", gp.compile, pset=self.pset)
+
+        if self.evaluation_method == EvaluationGPHH.SGS:
+            self.toolbox.register(
+                "evaluate", self.evaluate_heuristic, domains=self.training_domains
+            )
+        # if self.evaluation_method == EvaluationGPHH.SGS_DEVIATION:
+        #     self.toolbox.register("evaluate", self.evaluate_heuristic_sgs_deviation, domains=self.training_domains)
+        elif self.evaluation_method == EvaluationGPHH.PERMUTATION_DISTANCE:
+            self.toolbox.register(
+                "evaluate",
+                self.evaluate_heuristic_permutation,
+                domains=self.training_domains,
+            )
+        # self.toolbox.register("evaluate", self.evaluate_heuristic, domains=[self.training_domains[1]])
+
+        self.toolbox.register(
+            "select", tools.selTournament, tournsize=int(tournament_ratio * pop_size)
+        )
+        self.toolbox.register("mate", gp.cxOnePoint)
+        self.toolbox.register("expr_mut", gp.genFull, min_=0, max_=max_tree_depth)
+        self.toolbox.register(
+            "mutate", gp.mutUniform, expr=self.toolbox.expr_mut, pset=self.pset
+        )
+
+        self.toolbox.decorate(
+            "mate", gp.staticLimit(key=operator.attrgetter("height"), max_value=17)
+        )
+        self.toolbox.decorate(
+            "mutate", gp.staticLimit(key=operator.attrgetter("height"), max_value=17)
+        )
+
+        stats_fit = tools.Statistics(lambda ind: ind.fitness.values)
+        stats_size = tools.Statistics(len)
+        mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)
+        mstats.register("avg", np.mean)
+        mstats.register("std", np.std)
+        mstats.register("min", np.min)
+        mstats.register("max", np.max)
+
+        pop = self.toolbox.population(n=pop_size)
+        hof = tools.HallOfFame(1)
+        self.hof = hof
+        pop, log = algorithms.eaSimple(
+            pop,
+            self.toolbox,
+            crossover_rate,
+            mutation_rate,
+            n_gen,
+            stats=mstats,
+            halloffame=hof,
+            verbose=True,
+        )
+
+        self.best_heuristic = hof[0]
+        print("best_heuristic: ", self.best_heuristic)
+
+        self.func_heuristic = self.toolbox.compile(expr=self.best_heuristic)
+        self.policy = GPHHPolicy(
+            self.domain,
+            self.domain_model,
+            self.func_heuristic,
+            features=self.list_feature,
+            params_gphh=self.params_gphh,
+            recompute_cpm=True,
+        )
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        action = self.policy.sample_action(observation)
+        # print('action_1: ', action.action)
+        return action
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
+
+    def init_primitives(self, pset) -> PrimitiveSet:
+        for i in range(len(self.list_feature)):
+            pset.renameArguments(**{"ARG" + str(i): self.list_feature[i].value})
+        return pset
+
+    def evaluate_heuristic(self, individual, domains) -> float:
+        vals = []
+        func_heuristic = self.toolbox.compile(expr=individual)
+        # print('individual', individual)
+        for domain in domains:
+
+            ###
+            initial_state = domain.get_initial_state()
+
+            do_model = build_do_domain(domain)
+            modes = [
+                initial_state.tasks_mode.get(j, 1)
+                for j in sorted(domain.get_tasks_ids())
+            ]
+            modes = modes[1:-1]
+
+            cpm = self.cpm_data[domain]["cpm"]
+            cpm_esd = self.cpm_data[domain]["cpm_esd"]
+
+            raw_values = []
+            for task_id in domain.get_available_tasks(initial_state):
+                input_features = [
+                    feature_function_map[lf](
+                        domain=domain,
+                        cpm=cpm,
+                        cpm_esd=cpm_esd,
+                        task_id=task_id,
+                        state=initial_state,
+                    )
+                    for lf in self.list_feature
+                ]
+                output_value = func_heuristic(*input_features)
+                raw_values.append(output_value)
+
+            normalized_values = [
+                x + 1
+                for x in sorted(
+                    range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
+                )
+            ]
+            normalized_values_for_do = [
+                normalized_values[i] - 2
+                for i in range(len(normalized_values))
+                if normalized_values[i] not in {1, len(normalized_values)}
+            ]
+
+            solution = RCPSPSolution(
+                problem=do_model,
+                rcpsp_permutation=normalized_values_for_do,
+                rcpsp_modes=modes,
+            )
+            last_activity = max(list(solution.rcpsp_schedule.keys()))
+            do_makespan = solution.rcpsp_schedule[last_activity]["end_time"]
+            vals.append(do_makespan)
+
+        fitness = [np.mean(vals)]
+        return fitness
+
+    def initialize_cpm_data_for_training(self):
+        self.cpm_data = {}
+        for domain in self.training_domains:
+            do_model = build_do_domain(domain)
+            cpm, cpm_esd = compute_cpm(do_model)
+            self.cpm_data[domain] = {"cpm": cpm, "cpm_esd": cpm_esd}
+
+    def evaluate_heuristic_permutation(self, individual, domains) -> float:
+        vals = []
+        func_heuristic = self.toolbox.compile(expr=individual)
+        # print('individual', individual)
+
+        for domain in domains:
+
+            raw_values = []
+            initial_state = domain.get_initial_state()
+
+            regenerate_cpm = False
+            if regenerate_cpm:
+                do_model = build_do_domain(domain)
+                cpm, cpm_esd = compute_cpm(do_model)
+            else:
+                cpm = self.cpm_data[domain]["cpm"]
+                cpm_esd = self.cpm_data[domain]["cpm_esd"]
+
+            for task_id in domain.get_available_tasks(state=initial_state):
+
+                input_features = [
+                    feature_function_map[lf](
+                        domain=domain,
+                        cpm=cpm,
+                        cpm_esd=cpm_esd,
+                        task_id=task_id,
+                        state=initial_state,
+                    )
+                    for lf in self.list_feature
+                ]
+                output_value = func_heuristic(*input_features)
+                raw_values.append(output_value)
+
+            most_common_raw_val = max(raw_values, key=raw_values.count)
+            most_common_count = raw_values.count(most_common_raw_val)
+
+            heuristic_permutation = [
+                x + 1
+                for x in sorted(
+                    range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
+                )
+            ]
+
+            if self.permutation_distance == PermutationDistance.KTD:
+                dist, p_value = stats.kendalltau(
+                    heuristic_permutation, self.reference_permutations[domain]
+                )
+                dist = -dist
+
+            if self.permutation_distance == PermutationDistance.HAMMING:
+                dist = distance.hamming(
+                    heuristic_permutation, self.reference_permutations[domain]
+                )
+
+            if self.permutation_distance == PermutationDistance.KTD_HAMMING:
+                ktd, _ = stats.kendalltau(
+                    heuristic_permutation, self.reference_permutations[domain]
+                )
+                dist = -ktd + distance.hamming(
+                    heuristic_permutation, self.reference_permutations[domain]
+                )
+
+            penalty = most_common_count / len(raw_values)
+            # penalty = 0.
+            penalized_distance = dist + penalty
+            vals.append(penalized_distance)
+        fitness = [np.mean(vals)]
+        # fitness = [np.max(vals)]
+        return fitness
+
+    def test_features(self, domain, task_id, observation):
+        for f in FeatureEnum:
+            print("feature: ", f)
+            calculated_feature = feature_function_map[f](
+                domain=domain, task_id=task_id, state=observation
+            )
+            print("\tcalculated_feature: ", calculated_feature)
+
+    def set_domain(self, domain):
+        self.domain = domain
+        if self.policy is not None:
+            self.policy.domain = domain
+
+
+class GPHHPolicy(DeterministicPolicies):
+    def __init__(
+        self,
+        domain: SchedulingDomain,
+        domain_model: SchedulingDomain,
+        func_heuristic,
+        features: List[FeatureEnum] = None,
+        params_gphh=None,
+        recompute_cpm=True,
+        cpm_data=None,
+    ):
+        self.domain = domain
+        self.domain_model = domain_model
+        self.func_heuristic = func_heuristic
+        self.list_feature = features
+        self.params_gphh = params_gphh
+        self.recompute_cpm = recompute_cpm
+        self.cpm_data = cpm_data
+
+    def reset(self):
+        pass
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        run_sgs = True
+        cheat_mode = False
+
+        do_model = build_do_domain(self.domain_model)
+        modes = [
+            observation.tasks_mode.get(j, 1)
+            for j in sorted(self.domain.get_tasks_ids())
+        ]
+        modes = modes[1:-1]
+        scheduled_tasks_start_times = {}
+        if run_sgs:
+            tasks_details = rebuild_all_tasks_dict(observation)
+            for j in tasks_details:
+                if tasks_details[j].start is not None:
+                    scheduled_tasks_start_times[j] = tasks_details[j].start
+                    do_model.mode_details[j][1]["duration"] = tasks_details[
+                        j
+                    ].sampled_duration
+            # needed to update the numba functions to take into account
+            # the sampled durations of the current scheduling state.
+            do_model.update_functions()
+
+        # do_model = build_do_domain(self.domain)
+        # modes = [observation.tasks_mode.get(j, 1) for j in sorted(self.domain.get_tasks_ids())]
+        # modes = modes[1:-1]
+        #
+        # if run_sgs:
+        #     scheduled_tasks_start_times = {}
+        #     for j in observation.tasks_details.keys():
+        #         if observation.tasks_details[j].start is not None:
+        #             scheduled_tasks_start_times[j] = observation.tasks_details[j].start
+        #         else:
+        #             if not cheat_mode:
+        #                 do_model.mode_details[j][1]['duration'] = self.domain_model.sample_task_duration(j, 1, 0.)
+
+        if self.recompute_cpm:
+            cpm, cpm_esd = compute_cpm(do_model)
+        else:
+            cpm = self.cpm_data[self.domain]["cpm"]
+            cpm_esd = self.cpm_data[self.domain]["cpm_esd"]
+
+        t = observation.t
+        raw_values = []
+        for task_id in self.domain.get_available_tasks(observation):
+            input_features = [
+                feature_function_map[lf](
+                    domain=self.domain,
+                    cpm=cpm,
+                    cpm_esd=cpm_esd,
+                    task_id=task_id,
+                    state=observation,
+                )
+                for lf in self.list_feature
+            ]
+            output_value = self.func_heuristic(*input_features)
+            raw_values.append(output_value)
+
+        normalized_values = [
+            x + 1
+            for x in sorted(
+                range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
+            )
+        ]
+        normalized_values_for_do = [
+            normalized_values[i] - 2
+            for i in range(len(normalized_values))
+            if normalized_values[i] not in {1, len(normalized_values)}
+        ]
+
+        # print(t, ': ', normalized_values)
+        # print('normalized_values_for_do: ', normalized_values_for_do)
+
+        modes_dictionnary = {}
+        for i in range(len(normalized_values)):
+            modes_dictionnary[i + 1] = 1
+
+        if run_sgs:
+            tasks_complete_dict = rebuild_tasks_complete_details_dict(observation)
+            # Force the scheduler_tasks_start_times to be disjoint with the complete tasks,
+            # this avoid a corner effect giving wrong results in the numba SGS implementation
+            # (sgs_fast_partial_schedule_incomplete_permutation_tasks)
+            scheduled_tasks_start_times = {
+                j: scheduled_tasks_start_times[j]
+                for j in scheduled_tasks_start_times
+                if j not in tasks_complete_dict
+            }
+            solution = RCPSPSolution(
+                problem=do_model,
+                rcpsp_permutation=normalized_values_for_do,
+                rcpsp_modes=modes,
+            )
+            solution.generate_schedule_from_permutation_serial_sgs_2(
+                current_t=t,
+                completed_tasks=tasks_complete_dict,
+                scheduled_tasks_start_times=scheduled_tasks_start_times,
+            )
+
+            schedule = solution.rcpsp_schedule
+        else:
+            schedule = None
+
+        sgs_policy = PolicyRCPSP(
+            domain=self.domain,
+            schedule=schedule,
+            policy_method_params=PolicyMethodParams(
+                # base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
+                # base_policy_method=BasePolicyMethod.SGS_READY,
+                base_policy_method=self.params_gphh.base_policy_method,
+                delta_index_freedom=self.params_gphh.delta_index_freedom,
+                delta_time_freedom=self.params_gphh.delta_time_freedom,
+            ),
+            permutation_task=normalized_values,
+            modes_dictionnary=modes_dictionnary,
+        )
+        action: SchedulingAction = sgs_policy.sample_action(observation)
+        # print('action_2: ', action.action)
+        return action
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
+
+
+class PoolAggregationMethod(Enum):
+    MEAN = "mean"
+    MEDIAN = "median"
+    RANDOM = "random"
+
+
+class PooledGPHHPolicy(DeterministicPolicies):
+    def __init__(
+        self,
+        domain: SchedulingDomain,
+        domain_model: SchedulingDomain,
+        func_heuristics,
+        pool_aggregation_method: PoolAggregationMethod = PoolAggregationMethod.MEAN,
+        remove_extremes_values: int = 0,
+        features: List[FeatureEnum] = None,
+        params_gphh=None,
+    ):
+        self.domain = domain
+        self.domain_model = domain_model
+        self.func_heuristics = func_heuristics
+        self.list_feature = features
+        self.params_gphh = params_gphh
+        self.pool_aggregation_method = pool_aggregation_method
+        self.remove_extremes_values = remove_extremes_values
+
+    def reset(self):
+        pass
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+
+        run_sgs = True
+        cheat_mode = False
+        regenerate_cpm = True
+
+        do_model = build_do_domain(self.domain_model)
+        modes = [
+            observation.tasks_mode.get(j, 1)
+            for j in sorted(self.domain.get_tasks_ids())
+        ]
+        modes = modes[1:-1]
+
+        if run_sgs:
+            scheduled_tasks_start_times = {}
+            tasks_details = rebuild_all_tasks_dict(observation)
+            for j in tasks_details:
+                if tasks_details[j].start is not None:
+                    scheduled_tasks_start_times[j] = tasks_details[j].start
+                    do_model.mode_details[j][1]["duration"] = tasks_details[
+                        j
+                    ].sampled_duration
+
+        # do_model = build_do_domain(self.domain)
+        # modes = [observation.tasks_mode.get(j, 1) for j in sorted(self.domain.get_tasks_ids())]
+        # modes = modes[1:-1]
+        #
+        # if run_sgs:
+        #     scheduled_tasks_start_times = {}
+        #     for j in observation.tasks_details.keys():
+        #         # schedule[j] = {}
+        #         if observation.tasks_details[j].start is not None:
+        #             # schedule[j]["start_time"] = observation.tasks_details[j].start
+        #             scheduled_tasks_start_times[j] = observation.tasks_details[j].start
+        #         # if observation.tasks_details[j].end is not None:
+        #         #     schedule[j]["end_time"] = observation.tasks_details[j].end
+        #         else:
+        #             if not cheat_mode:
+        #                 do_model.mode_details[j][1]['duration'] = self.domain_model.sample_task_duration(j, 1, 0.)
+
+        if regenerate_cpm:
+            cpm, cpm_esd = compute_cpm(do_model)
+
+        t = observation.t
+        raw_values = []
+        for task_id in self.domain.get_available_tasks(observation):
+            input_features = [
+                feature_function_map[lf](
+                    domain=self.domain,
+                    cpm=cpm,
+                    cpm_esd=cpm_esd,
+                    task_id=task_id,
+                    state=observation,
+                )
+                for lf in self.list_feature
+            ]
+            output_values = []
+            for f in self.func_heuristics:
+                output_value = f(*input_features)
+                output_values.append(output_value)
+
+            # print('output_values: ', output_values)
+            if self.remove_extremes_values > 0:
+                the_median = float(np.median(output_values))
+                tmp = {}
+                for i in range(len(output_values)):
+                    tmp[i] = abs(output_values[i] - the_median)
+                tmp = sorted(tmp.items(), key=lambda x: x[1], reverse=True)
+                to_remove = [tmp[i][0] for i in range(self.remove_extremes_values)]
+                output_values = list(np.delete(output_values, to_remove))
+
+            # print('output_values filtered: ', output_values)
+            if self.pool_aggregation_method == PoolAggregationMethod.MEAN:
+                agg_value = np.mean(output_values)
+            elif self.pool_aggregation_method == PoolAggregationMethod.MEDIAN:
+                agg_value = np.median(output_values)
+            elif self.pool_aggregation_method == PoolAggregationMethod.RANDOM:
+                index = random.randint(len(output_values))
+                agg_value = output_values[index]
+
+            # print('agg_value: ', agg_value)
+            raw_values.append(agg_value)
+
+        normalized_values = [
+            x + 1
+            for x in sorted(
+                range(len(raw_values)), key=lambda k: raw_values[k], reverse=False
+            )
+        ]
+        normalized_values_for_do = [
+            normalized_values[i] - 2
+            for i in range(len(normalized_values))
+            if normalized_values[i] not in {1, len(normalized_values)}
+        ]
+
+        # print('normalized_values: ', normalized_values)
+        # print('normalized_values_for_do: ', normalized_values_for_do)
+
+        modes_dictionnary = {}
+        for i in range(len(normalized_values)):
+            modes_dictionnary[i + 1] = 1
+
+        if run_sgs:
+
+            solution = RCPSPSolution(
+                problem=do_model,
+                rcpsp_permutation=normalized_values_for_do,
+                rcpsp_modes=modes,
+            )
+            tasks_complete_dict = rebuild_tasks_complete_details_dict(observation)
+            solution.generate_schedule_from_permutation_serial_sgs_2(
+                current_t=t,
+                completed_tasks=tasks_complete_dict,
+                scheduled_tasks_start_times=scheduled_tasks_start_times,
+            )
+
+            schedule = solution.rcpsp_schedule
+        else:
+            schedule = None
+
+        sgs_policy = PolicyRCPSP(
+            domain=self.domain,
+            schedule=schedule,
+            policy_method_params=PolicyMethodParams(
+                # base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
+                # base_policy_method=BasePolicyMethod.SGS_READY,
+                base_policy_method=self.params_gphh.base_policy_method,
+                delta_index_freedom=self.params_gphh.delta_index_freedom,
+                delta_time_freedom=self.params_gphh.delta_time_freedom,
+            ),
+            permutation_task=normalized_values,
+            modes_dictionnary=modes_dictionnary,
+        )
+        action: SchedulingAction = sgs_policy.sample_action(observation)
+        # print('action_2: ', action.action)
+        return action
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
+
+
+class FixedPermutationPolicy(DeterministicPolicies):
+    def __init__(
+        self, domain: SchedulingDomain, domain_model: SchedulingDomain, fixed_perm
+    ):
+        self.domain = domain
+        self.domain_model = domain_model
+        self.fixed_perm = fixed_perm
+
+    def reset(self):
+        pass
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        run_sgs = True
+        cheat_mode = False
+
+        do_model = build_do_domain(self.domain_model)
+        modes = [
+            observation.tasks_mode.get(j, 1)
+            for j in sorted(self.domain.get_tasks_ids())
+        ]
+        modes = modes[1:-1]
+
+        if run_sgs:
+            scheduled_tasks_start_times = {}
+            tasks_details = rebuild_all_tasks_dict(observation)
+            for j in tasks_details.keys():
+                if tasks_details[j].start is not None:
+                    scheduled_tasks_start_times[j] = tasks_details[j].start
+                    do_model.mode_details[j][1]["duration"] = tasks_details[
+                        j
+                    ].sampled_duration
+
+        # do_model = build_do_domain(self.domain)
+        # modes = [observation.tasks_mode.get(j, 1) for j in sorted(self.domain.get_tasks_ids())]
+        # modes = modes[1:-1]
+        #
+        # if run_sgs:
+        #     scheduled_tasks_start_times = {}
+        #     for j in observation.tasks_details.keys():
+        #         # schedule[j] = {}
+        #         if observation.tasks_details[j].start is not None:
+        #             # schedule[j]["start_time"] = observation.tasks_details[j].start
+        #             scheduled_tasks_start_times[j] = observation.tasks_details[j].start
+        #         # if observation.tasks_details[j].end is not None:
+        #         #     schedule[j]["end_time"] = observation.tasks_details[j].end
+        #         else:
+        #             if not cheat_mode:
+        #                 # print('do_model: ', do_model)
+        #                 do_model.mode_details[j][1]['duration'] = self.domain_model.sample_task_duration(j, 1, 0.)
+
+        normalized_values = self.fixed_perm
+
+        normalized_values_for_do = [
+            normalized_values[i] - 2
+            for i in range(len(normalized_values))
+            if normalized_values[i] not in {1, len(normalized_values)}
+        ]
+
+        # print('normalized_values: ', normalized_values)
+        # print('normalized_values_for_do: ', normalized_values_for_do)
+        t = observation.t
+
+        modes_dictionnary = {}
+        for i in range(len(normalized_values)):
+            modes_dictionnary[i + 1] = 1
+
+        if run_sgs:
+
+            solution = RCPSPSolution(
+                problem=do_model,
+                rcpsp_permutation=normalized_values_for_do,
+                rcpsp_modes=modes,
+            )
+            tasks_details_complete = rebuild_tasks_complete_details_dict(observation)
+            solution.generate_schedule_from_permutation_serial_sgs_2(
+                current_t=t,
+                completed_tasks=tasks_details_complete,
+                scheduled_tasks_start_times=scheduled_tasks_start_times,
+            )
+
+            schedule = solution.rcpsp_schedule
+        else:
+            schedule = None
+
+        sgs_policy = PolicyRCPSP(
+            domain=self.domain,
+            schedule=schedule,
+            policy_method_params=PolicyMethodParams(
+                # base_policy_method=BasePolicyMethod.SGS_PRECEDENCE,
+                # base_policy_method=BasePolicyMethod.SGS_READY,
+                base_policy_method=BasePolicyMethod.FOLLOW_GANTT,
+                # delta_index_freedom=self.params_gphh.delta_index_freedom,
+                # delta_time_freedom=self.params_gphh.delta_time_freedom
+            ),
+            permutation_task=normalized_values,
+            modes_dictionnary=modes_dictionnary,
+        )
+        action: SchedulingAction = sgs_policy.sample_action(observation)
+        # print('action_2: ', action.action)
+        return action
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
```

## Comparing `skdecide/hub/solver/graph_explorer/DFS_Uncertain_Exploration.py` & `skdecide/hub/domain/graph_domain/graph_domain_builders/DFS_Uncertain_Exploration.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,97 +1,104 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from heapq import heappop, heappush
-from itertools import count
-from typing import Any, Dict, Tuple
-
-from skdecide import D, DeterministicPlanningDomain, GoalMDPDomain, MDPDomain, Memory
-from skdecide.hub.solver.graph_explorer.GraphDomain import (
-    GraphDomain,
-    GraphDomainUncertain,
-)
-from skdecide.hub.solver.graph_explorer.GraphExploration import GraphExploration
-
-# WARNING : adapted for the scheduling domains.
-
-
-class DFSExploration(GraphExploration):
-    def __init__(
-        self,
-        domain: GoalMDPDomain,
-        score_function=None,
-        max_edges=None,
-        max_nodes=None,
-        max_path=None,
-    ):
-        self.domain = domain
-        self.score_function = score_function
-        self.c = count()
-        if score_function is None:
-            self.score_function = lambda s: (next(self.c))
-        self.max_edges = max_edges
-        self.max_nodes = max_nodes
-        self.max_path = max_path
-
-    def build_graph_domain(self, init_state: Any = None) -> GraphDomainUncertain:
-        if init_state is None:
-            initial_state = self.domain.get_initial_state()
-        else:
-            initial_state = init_state
-        stack = [(self.score_function(initial_state), initial_state)]
-        domain = self.domain
-        goal_states = set()
-        terminal_states = set()
-        num_s = 0
-        state_to_ind = {}
-        nb_states = 1
-        nb_edges = 0
-        result = {initial_state}
-        next_state_map: Dict[
-            D.T_state, Dict[D.T_event, Dict[D.T_state, Tuple[float, float]]]
-        ] = {}
-        state_terminal: Dict[D.T_state, bool] = {}
-        state_goal: Dict[D.T_state, bool] = {}
-        state_terminal[initial_state] = self.domain.is_terminal(initial_state)
-        state_goal[initial_state] = self.domain.is_goal(initial_state)
-        while len(stack) > 0:
-            if not len(result) % 100 and len(result) > nb_states:
-                print("Expanded {} states.".format(len(result)))
-                nb_states = len(result)
-            tuple, s = heappop(stack)
-            if s not in state_to_ind:
-                state_to_ind[s] = num_s
-                num_s += 1
-            if domain.is_terminal(s):
-                terminal_states.add(s)
-            if domain.is_goal(s):
-                goal_states.add(s)
-            if domain.is_goal(s) or domain.is_terminal(s):
-                continue
-            actions = domain.get_applicable_actions(s).get_elements()
-            for action in actions:
-                successors = domain.get_next_state_distribution(s, action).get_values()
-                for succ, prob in successors:
-                    if s not in next_state_map:
-                        next_state_map[s] = {}
-                    if action not in next_state_map[s]:
-                        next_state_map[s][action] = {}
-                    if prob != 0 and succ not in result:
-                        nb_states += 1
-                        nb_edges += 1
-                        result.add(succ)
-                        heappush(stack, (self.score_function(succ), succ))
-                        cost = domain.get_transition_value(s, action, succ)
-                        next_state_map[s][action][succ] = (prob, cost.cost)
-                        state_goal[succ] = domain.is_goal(succ)
-                        state_terminal[succ] = domain.is_terminal(succ)
-            if (nb_states > self.max_nodes) or (nb_edges > self.max_edges):
-                break
-        return GraphDomainUncertain(
-            next_state_map=next_state_map,
-            state_terminal=state_terminal,
-            state_goal=state_goal,
-        )
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from heapq import heappop, heappush
+from itertools import count
+from typing import Any, Dict, Optional, Tuple
+
+from skdecide import D, GoalMDPDomain
+from skdecide.hub.domain.graph_domain.graph_domain_builders.GraphExploration import (
+    GraphExploration,
+)
+from skdecide.hub.domain.graph_domain.GraphDomain import GraphDomainUncertain
+
+# WARNING : adapted for the scheduling domains.
+
+
+class DFSExploration(GraphExploration):
+    """DFS based exploration for MDP domains"""
+
+    def __init__(
+        self,
+        domain: GoalMDPDomain,
+        score_function=None,
+        max_edges: Optional[int] = None,
+        max_nodes: Optional[int] = None,
+        max_path: Optional[int] = None,
+    ):
+        self.domain = domain
+        self.score_function = score_function
+        self.c = count()
+        if score_function is None:
+            self.score_function = lambda s: (next(self.c))
+        self.max_edges = max_edges
+        self.max_nodes = max_nodes
+        self.max_path = max_path
+        if self.max_edges is None:
+            self.max_edges = float("inf")
+        if self.max_nodes is None:
+            self.max_nodes = float("inf")
+        if self.max_path is None:
+            self.max_path = float("inf")
+
+    def build_graph_domain(self, init_state: Any = None) -> GraphDomainUncertain:
+        if init_state is None:
+            initial_state = self.domain.get_initial_state()
+        else:
+            initial_state = init_state
+        stack = [(self.score_function(initial_state), initial_state)]
+        domain = self.domain
+        goal_states = set()
+        terminal_states = set()
+        num_s = 0
+        state_to_ind = {}
+        nb_states = 1
+        nb_edges = 0
+        result = {initial_state}
+        next_state_map: Dict[
+            D.T_state, Dict[D.T_event, Dict[D.T_state, Tuple[float, float]]]
+        ] = {}
+        state_terminal: Dict[D.T_state, bool] = dict()
+        state_goal: Dict[D.T_state, bool] = dict()
+        state_terminal[initial_state] = self.domain.is_terminal(initial_state)
+        state_goal[initial_state] = self.domain.is_goal(initial_state)
+        while len(stack) > 0:
+            if not len(result) % 100 and len(result) > nb_states:
+                print("Expanded {} states.".format(len(result)))
+                nb_states = len(result)
+            _, s = heappop(stack)
+            if s not in state_to_ind:
+                state_to_ind[s] = num_s
+                num_s += 1
+            if domain.is_terminal(s):
+                terminal_states.add(s)
+            if domain.is_goal(s):
+                goal_states.add(s)
+            if domain.is_goal(s) or domain.is_terminal(s):
+                continue
+            actions = domain.get_applicable_actions(s).get_elements()
+            for action in actions:
+                successors = domain.get_next_state_distribution(s, action).get_values()
+                for succ, prob in successors:
+                    if s not in next_state_map:
+                        next_state_map[s] = {}
+                    if action not in next_state_map[s]:
+                        next_state_map[s][action] = {}
+                    if prob != 0 and succ not in result:
+                        nb_states += 1
+                        nb_edges += 1
+                        result.add(succ)
+                        heappush(stack, (self.score_function(succ), succ))
+                        cost = domain.get_transition_value(s, action, succ)
+                        next_state_map[s][action][succ] = (prob, cost.cost)
+                        state_goal[succ] = domain.is_goal(succ)
+                        state_terminal[succ] = domain.is_terminal(succ)
+            if (nb_states > self.max_nodes) or (nb_edges > self.max_edges):
+                break
+        return GraphDomainUncertain(
+            next_state_map=next_state_map,
+            state_terminal=state_terminal,
+            state_goal=state_goal,
+        )
```

## Comparing `skdecide/hub/solver/graph_explorer/DFSExploration.py` & `skdecide/hub/domain/graph_domain/graph_domain_builders/DFSExploration.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,82 +1,97 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any
-
-from skdecide import DeterministicPlanningDomain, Memory
-from skdecide.hub.solver.graph_explorer.GraphDomain import GraphDomain
-from skdecide.hub.solver.graph_explorer.GraphExploration import GraphExploration
-
-
-class DFSExploration(GraphExploration):
-    def __init__(
-        self,
-        domain: DeterministicPlanningDomain,
-        max_edges=None,
-        max_nodes=None,
-        max_path=None,
-    ):
-        self.domain = domain
-        self.max_edges = max_edges
-        self.max_nodes = max_nodes
-        self.max_path = max_path
-
-    def build_graph_domain(
-        self, init_state: Any = None, transition_extractor=None, verbose=True
-    ) -> GraphDomain:
-        if transition_extractor is None:
-            transition_extractor = lambda s, a, s_prime: {
-                "cost": self.domain.get_transition_value(s, a, s_prime).cost
-            }
-        next_state_map = {}
-        next_state_attributes = {}
-        if init_state is None:
-            init_state = self.domain.get_initial_state()
-        stack = [(init_state, [init_state])]
-        nb_nodes = 1
-        nb_edges = 0
-        nb_path = 0
-        next_state_map[init_state] = {}
-        next_state_attributes[init_state] = {}
-        paths_dict = {}
-        while stack:
-            (vertex, path) = stack.pop()
-            actions = self.domain.get_applicable_actions(vertex).get_elements()
-            for action in actions:
-                next = self.domain.get_next_state(Memory([vertex]), action)
-                if action not in next_state_map[vertex]:
-                    nb_edges += 1
-                else:
-                    continue
-                next_state_map[vertex][action] = next
-                next_state_attributes[vertex][action] = transition_extractor(
-                    vertex, action, next
-                )
-                if self.domain.is_goal(next):
-                    nb_path += 1
-                    if verbose:
-                        print(nb_path, " / ", self.max_path)
-                        print("nodes  ", nb_nodes, " / ", self.max_nodes)
-                        print("edges  ", nb_edges, " / ", self.max_edges)
-                else:
-                    if next not in next_state_map:
-                        stack.append((next, path + [next]))
-                        paths_dict[next] = set(tuple(path + [next]))
-                    # else:
-                    #     if tuple(path+[next]) not in paths_dict[next]:
-                    #        stack.append((next, path + [next]))
-                    #        paths_dict[next].add(tuple(path + [next]))
-                if next not in next_state_map:
-                    next_state_map[next] = {}
-                    next_state_attributes[next] = {}
-                    nb_nodes += 1
-            if (
-                nb_path > self.max_path
-                or (nb_nodes > self.max_nodes and nb_path >= 1)
-                or (nb_edges > self.max_edges and nb_path >= 1)
-            ):
-                break
-        return GraphDomain(next_state_map, next_state_attributes, None, None)
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Optional
+
+from skdecide import DeterministicPlanningDomain, Memory
+from skdecide.hub.domain.graph_domain.graph_domain_builders.GraphExploration import (
+    GraphExploration,
+)
+from skdecide.hub.domain.graph_domain.GraphDomain import GraphDomain
+
+
+class DFSExploration(GraphExploration):
+    """Depth first search based method storing graph search into a GraphDomain object,
+    Main interest of using DFS is that it is possible to limit number of edges and paths to goal if necessary.
+    """
+
+    def __init__(
+        self,
+        domain: DeterministicPlanningDomain,
+        max_edges: Optional[int] = None,
+        max_nodes: Optional[int] = None,
+        max_path: Optional[int] = None,
+    ):
+        self.domain = domain
+        self.max_edges = max_edges
+        self.max_nodes = max_nodes
+        self.max_path = max_path
+        if self.max_edges is None:
+            self.max_edges = float("inf")
+        if self.max_nodes is None:
+            self.max_nodes = float("inf")
+        if self.max_path is None:
+            self.max_path = float("inf")
+
+    def build_graph_domain(
+        self, init_state: Any = None, transition_extractor=None, verbose=True
+    ) -> GraphDomain:
+        if transition_extractor is None:
+            transition_extractor = lambda s, a, s_prime: {
+                "cost": self.domain.get_transition_value(s, a, s_prime).cost
+            }
+        next_state_map = {}
+        next_state_attributes = {}
+        if init_state is None:
+            init_state = self.domain.get_initial_state()
+        stack = [(init_state, [init_state])]
+        nb_nodes = 1
+        nb_edges = 0
+        nb_path = 0
+        next_state_map[init_state] = {}
+        next_state_attributes[init_state] = {}
+        paths_dict = {}
+        targets = set()
+        while stack:
+            (vertex, path) = stack.pop()
+            actions = self.domain.get_applicable_actions(vertex).get_elements()
+            for action in actions:
+                next = self.domain.get_next_state(vertex, action)
+                if action not in next_state_map[vertex]:
+                    nb_edges += 1
+                else:
+                    continue
+                next_state_map[vertex][action] = next
+                next_state_attributes[vertex][action] = transition_extractor(
+                    vertex, action, next
+                )
+                if self.domain.is_goal(next):
+                    targets.add(next)
+                    nb_path += 1
+                    if verbose:
+                        print(nb_path, " / ", self.max_path)
+                        print("nodes  ", nb_nodes, " / ", self.max_nodes)
+                        print("edges  ", nb_edges, " / ", self.max_edges)
+                else:
+                    if next not in next_state_map:
+                        stack.append((next, path + [next]))
+                        paths_dict[next] = set(tuple(path + [next]))
+                if next not in next_state_map:
+                    next_state_map[next] = {}
+                    next_state_attributes[next] = {}
+                    nb_nodes += 1
+            if (
+                nb_path > self.max_path
+                or (nb_nodes > self.max_nodes and nb_path >= 1)
+                or (nb_edges > self.max_edges and nb_path >= 1)
+            ):
+                break
+        return GraphDomain(
+            next_state_map,
+            next_state_attributes,
+            targets=targets,
+            attribute_weight="cost",
+        )
```

## Comparing `skdecide/hub/solver/graph_explorer/FullSpaceExploration.py` & `skdecide/hub/domain/graph_domain/graph_domain_builders/FullSpaceExploration.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,91 +1,104 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any
-
-from skdecide import DeterministicPlanningDomain, Memory
-from skdecide.hub.solver.graph_explorer.GraphDomain import GraphDomain
-from skdecide.hub.solver.graph_explorer.GraphExploration import GraphExploration
-
-
-class FullSpaceExploration(GraphExploration):
-    def __init__(
-        self,
-        domain: DeterministicPlanningDomain,
-        max_edges=None,
-        max_nodes=None,
-        max_path=None,
-    ):
-        self.domain = domain
-        self.max_edges = max_edges
-        self.max_nodes = max_nodes
-        self.max_path = max_path
-
-    def build_graph_domain(self, init_state: Any = None) -> GraphDomain:
-        next_state_map = {}
-        next_state_attributes = {}
-        if init_state is None:
-            init_state = self.domain.get_initial_state()
-        stack = [(init_state, [init_state])]
-        nb_nodes = 1
-        nb_edges = 0
-        nb_path = 0
-        next_state_map[init_state] = {}
-        next_state_attributes[init_state] = {}
-        while stack:
-            (vertex, path) = stack.pop()
-            actions = self.domain.get_applicable_actions(vertex).get_elements()
-            for action in actions:
-                next = self.domain.get_next_state(vertex, action)
-                if next not in next_state_map:
-                    next_state_map[next] = {}
-                    next_state_attributes[next] = {}
-                    nb_nodes += 1
-                if action not in next_state_map[vertex]:
-                    nb_edges += 1
-                next_state_map[vertex][action] = next
-                next_state_attributes[vertex][action] = {
-                    "cost": self.domain.get_transition_value(
-                        Memory([vertex]), action, next
-                    ).cost,
-                    "reward": self.domain.get_transition_value(
-                        Memory([vertex]), action, next
-                    ).reward,
-                }
-                if self.domain.is_goal(next):
-                    nb_path += 1
-                else:
-                    if next not in next_state_map:
-                        stack.append((next, path + [next]))
-            if (
-                nb_path > self.max_path
-                or (nb_nodes > self.max_nodes and nb_path >= 1)
-                or (nb_edges > self.max_edges and nb_path >= 1)
-            ):
-                break
-        return GraphDomain(next_state_map, next_state_attributes, None, None)
-
-
-def reachable_states(self, s0: Any):
-    """Computes all states reachable from s0."""
-    result = {s0}
-    stack = [s0]
-    domain = self._domain
-    while len(stack) > 0:
-        if not len(result) % 100:
-            print("Expanded {} states.".format(len(result)))
-        s = stack.pop()
-        if domain.is_terminal(s):
-            continue
-        # Add successors
-        actions = domain.get_applicable_actions(s).get_elements()
-        for action in actions:
-            successors = domain.get_next_state_distribution(s, action).get_values()
-            for succ, prob in successors:
-                if prob != 0 and succ not in result:
-                    result.add(succ)
-                    stack.append(succ)
-    return result
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from typing import Any, Optional
+
+from skdecide import DeterministicPlanningDomain
+from skdecide.hub.domain.graph_domain.graph_domain_builders.GraphExploration import (
+    GraphExploration,
+)
+from skdecide.hub.domain.graph_domain.GraphDomain import GraphDomain
+
+
+class FullSpaceExploration(GraphExploration):
+    """Exhaustive computation of deterministic domain transitions to build a GraphDomain from it."""
+
+    def __init__(
+        self,
+        domain: DeterministicPlanningDomain,
+        max_edges: Optional[int] = None,
+        max_nodes: Optional[int] = None,
+        max_path: Optional[int] = None,
+    ):
+        self.domain = domain
+        self.max_edges = max_edges
+        self.max_nodes = max_nodes
+        self.max_path = max_path
+        if self.max_edges is None:
+            self.max_edges = float("inf")
+        if self.max_nodes is None:
+            self.max_nodes = float("inf")
+        if self.max_path is None:
+            self.max_path = float("inf")
+
+    def build_graph_domain(self, init_state: Any = None) -> GraphDomain:
+        next_state_map = {}
+        next_state_attributes = {}
+        if init_state is None:
+            init_state = self.domain.get_initial_state()
+        stack = [(init_state, [init_state])]
+        nb_nodes = 1
+        nb_edges = 0
+        nb_path = 0
+        next_state_map[init_state] = {}
+        next_state_attributes[init_state] = {}
+        targets = set()
+        while stack:
+            (vertex, path) = stack.pop()
+            actions = self.domain.get_applicable_actions(vertex).get_elements()
+            for action in actions:
+                next = self.domain.get_next_state(vertex, action)
+                if next not in next_state_map:
+                    next_state_map[next] = {}
+                    next_state_attributes[next] = {}
+                    stack.append((next, path + [next]))
+                    nb_nodes += 1
+                if action not in next_state_map[vertex]:
+                    nb_edges += 1
+                next_state_map[vertex][action] = next
+                next_state_attributes[vertex][action] = {
+                    "cost": self.domain.get_transition_value(vertex, action, next).cost,
+                    "reward": self.domain.get_transition_value(
+                        vertex, action, next
+                    ).reward,
+                }
+                if self.domain.is_goal(next):
+                    nb_path += 1
+                    targets.add(next)
+            if (
+                nb_path > self.max_path
+                or (nb_nodes > self.max_nodes and nb_path >= 1)
+                or (nb_edges > self.max_edges and nb_path >= 1)
+            ):
+                break
+        return GraphDomain(
+            next_state_map,
+            next_state_attributes,
+            targets=targets,
+            attribute_weight="cost",
+        )
+
+
+def reachable_states(self, s0: Any):
+    """Computes all states reachable from s0."""
+    result = {s0}
+    stack = [s0]
+    domain = self._domain
+    while len(stack) > 0:
+        if not len(result) % 100:
+            print("Expanded {} states.".format(len(result)))
+        s = stack.pop()
+        if domain.is_terminal(s):
+            continue
+        # Add successors
+        actions = domain.get_applicable_actions(s).get_elements()
+        for action in actions:
+            successors = domain.get_next_state_distribution(s, action).get_values()
+            for succ, prob in successors:
+                if prob != 0 and succ not in result:
+                    result.add(succ)
+                    stack.append(succ)
+    return result
```

## Comparing `skdecide/hub/solver/meta_policy/meta_policies.py` & `skdecide/hub/solver/meta_policy_scheduling/meta_policies.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,71 +1,84 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from typing import Any, Dict
-
-from skdecide import rollout_episode
-from skdecide.builders.domain.scheduling.scheduling_domains import D, SchedulingDomain
-from skdecide.builders.solver import DeterministicPolicies
-
-
-class MetaPolicy(DeterministicPolicies):
-    T_domain = D
-
-    def __init__(
-        self,
-        policies: Dict[Any, DeterministicPolicies],
-        execution_domain: SchedulingDomain,
-        known_domain: SchedulingDomain,
-        nb_rollout_estimation=1,
-        verbose=True,
-    ):
-        self.known_domain = known_domain
-        self.known_domain.fast = True
-        self.execution_domain = execution_domain
-        self.policies = policies
-        self.current_states = {method: None for method in policies}
-        self.nb_rollout_estimation = nb_rollout_estimation
-        self.verbose = verbose
-
-    def reset(self):
-        self.current_states = {method: None for method in self.policies}
-
-    def _get_next_action(
-        self, observation: D.T_agent[D.T_observation]
-    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
-        results = {}
-        actions_map = {}
-        self.known_domain.set_inplace_environment(True)
-        actions_c = [
-            self.policies[method].get_next_action(observation)
-            for method in self.policies
-        ]
-        if len(set(actions_c)) > 1:
-            for method in self.policies:
-                results[method] = 0.0
-                for j in range(self.nb_rollout_estimation):
-                    states, actions, values = rollout_episode(
-                        domain=self.known_domain,
-                        solver=self.policies[method],
-                        outcome_formatter=None,
-                        action_formatter=None,
-                        verbose=False,
-                        from_memory=observation.copy(),
-                    )
-                    # cost = sum(v.cost for v in values)
-                    results[method] += (
-                        states[-1].t - observation.t
-                    )  # TODO, this is a trick...
-                    actions_map[method] = actions[0]
-            if self.verbose:
-                # print(results)
-                print(actions_map[min(results, key=lambda x: results[x])])
-            return actions_map[min(results, key=lambda x: results[x])]
-        else:
-            return actions_c[0]
-
-    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
-        return True
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+import logging
+from typing import Any, Dict
+
+from skdecide import rollout
+from skdecide.builders.domain.scheduling.scheduling_domains import D, SchedulingDomain
+from skdecide.builders.solver import DeterministicPolicies
+
+logger = logging.getLogger(__name__)
+
+
+class MetaPolicy(DeterministicPolicies):
+    """
+    Utility policy function that represents a meta policy :
+    At a given state, it launches a rollout for each policy to evaluate each of them.
+    Then the policy for the given state is obtained with the policy that is giving the lowest estimated cost.
+    """
+
+    T_domain = D
+
+    def __init__(
+        self,
+        policies: Dict[Any, DeterministicPolicies],
+        domain: SchedulingDomain,
+        nb_rollout_estimation=1,
+        verbose=True,
+    ):
+        """
+        # Parameters
+        policies: dictionaries of different policies to evaluate
+        domain: domain on which to evaluate the policies
+        nb_rollout_estimation: relevant if the domain is stochastic,
+        run nb_rollout_estimation time(s) the rollout to estimate the expected cost of the policy.
+
+        """
+        self.domain = domain
+        self.domain.fast = True
+        self.policies = policies
+        self.current_states = {method: None for method in policies}
+        self.nb_rollout_estimation = nb_rollout_estimation
+        self.verbose = verbose
+
+    def reset(self):
+        self.current_states = {method: None for method in self.policies}
+
+    def _get_next_action(
+        self, observation: D.T_agent[D.T_observation]
+    ) -> D.T_agent[D.T_concurrency[D.T_event]]:
+        results = {}
+        actions_map = {}
+        self.domain.set_inplace_environment(True)
+        actions_c = [
+            self.policies[method].get_next_action(observation)
+            for method in self.policies
+        ]
+        if len(set(actions_c)) > 1:
+            for method in self.policies:
+                results[method] = 0.0
+                for j in range(self.nb_rollout_estimation):
+                    states, actions, values = rollout(
+                        domain=self.domain,
+                        solver=self.policies[method],
+                        outcome_formatter=None,
+                        action_formatter=None,
+                        verbose=False,
+                        goal_logging_level=logging.DEBUG,
+                        from_memory=observation.copy(),
+                        return_episodes=True,
+                    )[0]
+                    results[method] += states[-1].t - observation.t
+                    actions_map[method] = actions[0]
+            if self.verbose:
+                logger.debug(f"{actions_map[min(results, key=lambda x: results[x])]}")
+            return actions_map[min(results, key=lambda x: results[x])]
+        else:
+            return actions_c[0]
+
+    def _is_policy_defined_for(self, observation: D.T_agent[D.T_observation]) -> bool:
+        return True
```

## Comparing `skdecide/hub/solver/policy_evaluators/policy_evaluator.py` & `skdecide/hub/solver/meta_policy_scheduling/policy_evaluator.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,182 +1,168 @@
-# Copyright (c) AIRBUS and its affiliates.
-# This source code is licensed under the MIT license found in the
-# LICENSE file in the root directory of this source tree.
-
-from __future__ import annotations
-
-from collections import defaultdict
-from typing import Any, Dict, List, Set, Tuple
-
-from skdecide import GoalMDPDomain
-from skdecide.builders.domain.scheduling.scheduling_domains import SchedulingDomain
-from skdecide.builders.solver.policy import DeterministicPolicies
-
-
-# Adapted from skdecide/hub/solver/cssp/utils/cost_shift_solver.py works.
-def construct_dict_policy(
-    domain: GoalMDPDomain, policy: DeterministicPolicies
-) -> Tuple[Dict[Any, Any], Dict[Any, Set[Any]], Dict[Any, List[Tuple[Any, float]]]]:
-    stack = [domain.get_initial_state()]
-    # We store predecessors to make it easier to retrieve the expected costs
-    # later on
-    preds = defaultdict(set)
-    succs = defaultdict()
-    policy_dict = {}
-    while len(stack) > 0:
-        s = stack.pop()
-        if domain.is_terminal(s) or s in policy_dict:
-            continue
-        action = policy.get_next_action(s)
-        policy_dict[s] = action
-        successors = domain.get_next_state_distribution(s, action).get_values()
-        succs[s] = successors
-        for succ, prob in successors:
-            if prob != 0:
-                stack.append(succ)
-                preds[succ].add(s)
-    # Sanity check that successors and predecessors are equal
-    for state, successor_pairs in succs.items():
-        for succ, prob in successor_pairs:
-            assert state in preds[succ]
-    return policy_dict, preds, succs
-
-
-def expected_costs_for_policy(domain, policy_dict, preds, succs):
-    # Compute value function for states that are explored by the policy.
-    opt_val = dict()
-    # Initialize states where all successors have potentially known values
-    stack = set()
-    for s in preds.keys():
-        if domain.is_goal(s):
-            opt_val[s] = 0
-            stack.update(preds[s])
-    while len(stack) > 0:
-        s = stack.pop()
-        # Assert that all successors have known optimal values
-        if s in opt_val or not successor_value_is_known(succs[s], opt_val):
-            continue
-        a = policy_dict[s]
-        main_cost = 0
-        for succ, prob in succs[s]:
-            # evaluate objective function on transition
-            val = domain.get_transition_value(s, a, succ)
-            main_cost += prob * (val.cost + opt_val[succ])
-        opt_val[s] = main_cost
-        stack.update(preds[s])
-    return opt_val
-
-
-def compute_expected_cost_for_policy(domain, policy):
-    policy_dict, preds, succs = construct_dict_policy(domain, policy)
-    value_function_dict = expected_costs_for_policy(domain, policy_dict, preds, succs)
-    return value_function_dict, policy_dict, preds, succs
-
-
-def my_custom_rollout(domain: GoalMDPDomain, state, policy: DeterministicPolicies):
-    states = [state]
-    values = []
-    summed_value = 0.0
-    actions = []
-    while True:
-        action = policy.get_next_action(states[-1])
-        next_state = SchedulingDomain._state_sample(domain, states[-1], action).state
-        value = domain.get_transition_value(states[-1], action, next_state)
-        values += [value.cost]
-        summed_value += value.cost
-        states += [next_state]
-        actions += [action]
-        if domain.is_goal(states[-1]):
-            break
-        if domain.is_terminal(states[-1]):
-            summed_value += 1000  # penalty
-            break
-    return states, summed_value, values, actions
-
-
-# for uncertain domain leading to intractable number of states. which is the case for non trivial scheduling domains
-# for example
-import numpy as np
-
-
-def rollout_based_policy_estimation(
-    domain: GoalMDPDomain, policy: DeterministicPolicies, nb_rollout: int = 1
-) -> Tuple[Dict[Any, Any], Dict[Any, Any], Dict[Any, Set[Any]], Dict[Any, Set[Any]]]:
-    policy_dict = {}
-    nb_visit_dict = {}
-    summed_value = {}
-    final_value = {}
-    preds = {}
-    succs = {}
-    for rollout in range(nb_rollout):
-        states, summed_value_rollout, values, actions = my_custom_rollout(
-            domain, domain.get_initial_state(), policy
-        )
-        values_np = np.array(values[::-1]).cumsum()
-        k = 0
-        for j in range(len(states) - 2, -1, -1):
-            if states[j] not in nb_visit_dict:
-                nb_visit_dict[states[j]] = 0
-                summed_value[states[j]] = 0
-                final_value[states[j]] = 0
-                policy_dict[states[j]] = actions[j]
-                preds[states[j]] = set()
-                succs[states[j]] = set()
-            summed_value[states[j]] += values_np[k]
-            nb_visit_dict[states[j]] += 1
-            if j > 0:
-                preds[states[j]].add(states[j - 1])
-            succs[states[j]].add(states[j + 1])
-            k += 1
-    final_value = {st: summed_value[st] / nb_visit_dict[st] for st in summed_value}
-    return final_value, policy_dict, preds, succs
-
-
-def rollout_based_policy_estimation_fast_scheduling(
-    domain: SchedulingDomain, policy: DeterministicPolicies, nb_rollout: int = 1
-) -> Tuple[Dict[Any, Any], Dict[Any, Any], Dict[Any, Set[Any]], Dict[Any, Set[Any]]]:
-    policy_dict = {}
-    nb_visit_dict = {}
-    summed_value = {}
-    final_value = {}
-    preds = {}
-    succs = {}
-    s = domain.get_initial_state()
-    summed_value[s] = 0
-    nb_visit_dict[s] = 0
-    domain.set_inplace_environment(True)
-    for rollout in range(nb_rollout):
-        states, summed_value_rollout, values, actions = my_custom_rollout(
-            domain, s.copy(), policy
-        )
-        summed_value[s] += states[-1].t - s.t
-        nb_visit_dict[s] += 1
-    final_value = {st: summed_value[st] / nb_visit_dict[st] for st in summed_value}
-    return final_value, policy_dict, preds, succs
-
-
-def rollout_based_compute_expected_cost_for_policy(domain, policy, nb_rollout=100):
-    final_value, policy_dict, preds, succs = rollout_based_policy_estimation(
-        domain=domain, policy=policy, nb_rollout=nb_rollout
-    )
-    return final_value, policy_dict, preds, succs
-
-
-def rollout_based_compute_expected_cost_for_policy_scheduling(
-    domain, policy, nb_rollout=100
-):
-    (
-        final_value,
-        policy_dict,
-        preds,
-        succs,
-    ) = rollout_based_policy_estimation_fast_scheduling(
-        domain=domain, policy=policy, nb_rollout=nb_rollout
-    )
-    return final_value, policy_dict, preds, succs
-
-
-def successor_value_is_known(successors, opt_val):
-    for succ, prob in successors:
-        if prob != 0 and succ not in opt_val:
-            return False
-    return True
+# Copyright (c) AIRBUS and its affiliates.
+# This source code is licensed under the MIT license found in the
+# LICENSE file in the root directory of this source tree.
+
+from __future__ import annotations
+
+from collections import defaultdict
+from typing import Any, Dict, List, Set, Tuple
+
+import numpy as np
+
+from skdecide import D, GoalMDPDomain
+from skdecide.builders.domain.scheduling.scheduling_domains import SchedulingDomain
+from skdecide.builders.solver.policy import DeterministicPolicies
+
+# Adapted from skdecide/hub/solver/cssp/utils/cost_shift_solver.py works.
+
+
+def my_custom_rollout(
+    domain: GoalMDPDomain, state: GoalMDPDomain.T_state, policy: DeterministicPolicies
+):
+    states = [state]
+    values = []
+    summed_value = 0.0
+    actions = []
+    while True:
+        action = policy.get_next_action(states[-1])
+        next_transition = domain.sample(states[-1], action)
+        next_state = next_transition.observation
+        value = next_transition.value
+        values += [value.cost]
+        summed_value += value.cost
+        states += [next_state]
+        actions += [action]
+        if domain.is_goal(states[-1]):
+            break
+        if domain.is_terminal(states[-1]):
+            summed_value += 1000  # penalty
+            break
+    return states, summed_value, values, actions
+
+
+def rollout_based_policy_estimation(
+    domain: GoalMDPDomain, policy: DeterministicPolicies, nb_rollout: int = 1
+) -> Tuple[Dict[Any, Any], Dict[Any, Any], Dict[Any, Set[Any]], Dict[Any, Set[Any]]]:
+    policy_dict = {}
+    nb_visit_dict = {}
+    summed_value = {}
+    final_value = {}
+    preds = {}
+    succs = {}
+    for rollout in range(nb_rollout):
+        states, summed_value_rollout, values, actions = my_custom_rollout(
+            domain, domain.get_initial_state(), policy
+        )
+        values_np = np.array(values[::-1]).cumsum()
+        k = 0
+        for j in range(len(states) - 2, -1, -1):
+            if states[j] not in nb_visit_dict:
+                nb_visit_dict[states[j]] = 0
+                summed_value[states[j]] = 0
+                final_value[states[j]] = 0
+                policy_dict[states[j]] = actions[j]
+                preds[states[j]] = set()
+                succs[states[j]] = set()
+            summed_value[states[j]] += values_np[k]
+            nb_visit_dict[states[j]] += 1
+            if j > 0:
+                preds[states[j]].add(states[j - 1])
+            succs[states[j]].add(states[j + 1])
+            k += 1
+    final_value = {st: summed_value[st] / nb_visit_dict[st] for st in summed_value}
+    return final_value, policy_dict, preds, succs
+
+
+def rollout_based_policy_estimation_fast_scheduling(
+    domain: SchedulingDomain, policy: DeterministicPolicies, nb_rollout: int = 1
+) -> Tuple[Dict[Any, Any], Dict[Any, Any], Dict[Any, Set[Any]], Dict[Any, Set[Any]]]:
+    policy_dict = {}
+    nb_visit_dict = {}
+    summed_value = {}
+    preds = {}
+    succs = {}
+    s = domain.get_initial_state()
+    summed_value[s] = 0
+    nb_visit_dict[s] = 0
+    domain.set_inplace_environment(True)
+    for rollout in range(nb_rollout):
+        states, summed_value_rollout, values, actions = my_custom_rollout(
+            domain, s.copy(), policy
+        )
+        summed_value[s] += states[-1].t - s.t
+        nb_visit_dict[s] += 1
+    final_value = {st: summed_value[st] / nb_visit_dict[st] for st in summed_value}
+    return final_value, policy_dict, preds, succs
+
+
+def construct_dict_policy(
+    domain: GoalMDPDomain, policy: DeterministicPolicies
+) -> Tuple[Dict[Any, Any], Dict[Any, Set[Any]], Dict[Any, List[Tuple[Any, float]]]]:
+    stack = [domain.get_initial_state()]
+    # We store predecessors to make it easier to retrieve the expected costs
+    # later on
+    preds = defaultdict(set)
+    succs = defaultdict()
+    policy_dict = {}
+    while len(stack) > 0:
+        s = stack.pop()
+        if domain.is_terminal(s) or s in policy_dict:
+            continue
+        action = policy.get_next_action(s)
+        policy_dict[s] = action
+        successors = domain.get_next_state_distribution(s, action).get_values()
+        succs[s] = successors
+        for succ, prob in successors:
+            if prob != 0:
+                stack.append(succ)
+                preds[succ].add(s)
+    # Sanity check that successors and predecessors are equal
+    for state, successor_pairs in succs.items():
+        for succ, prob in successor_pairs:
+            assert state in preds[succ]
+    return policy_dict, preds, succs
+
+
+def expected_costs_for_policy(
+    domain: GoalMDPDomain,
+    policy_dict: Dict[D.T_state, D.T_event],
+    preds: Dict[D.T_state, Set[D.T_state]],
+    succs: Dict[D.T_state, List[Tuple[D.T_state, float]]],
+):
+    # Compute value function for states that are explored by the policy.
+    opt_val = dict()
+    # Initialize states where all successors have potentially known values
+    stack = set()
+    for s in preds.keys():
+        if domain.is_goal(s):
+            opt_val[s] = 0
+            stack.update(preds[s])
+    while len(stack) > 0:
+        s = stack.pop()
+        # Assert that all successors have known optimal values
+        if s in opt_val or not successor_value_is_known(succs[s], opt_val):
+            continue
+        a = policy_dict[s]
+        main_cost = 0
+        for succ, prob in succs[s]:
+            # evaluate objective function on transition
+            val = domain.get_transition_value(s, a, succ)
+            main_cost += prob * (val.cost + opt_val[succ])
+        opt_val[s] = main_cost
+        stack.update(preds[s])
+    return opt_val
+
+
+def compute_expected_cost_for_policy(
+    domain: GoalMDPDomain, policy: DeterministicPolicies
+):
+    policy_dict, preds, succs = construct_dict_policy(domain, policy)
+    value_function_dict = expected_costs_for_policy(domain, policy_dict, preds, succs)
+    return value_function_dict, policy_dict, preds, succs
+
+
+def successor_value_is_known(successors, opt_val):
+    for succ, prob in successors:
+        if prob != 0 and succ not in opt_val:
+            return False
+    return True
```

## Comparing `skdecide/hub/lib/cmake/nng/nng-config-version.cmake` & `skdecide/hub/lib64/cmake/nng/nng-config-version.cmake`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,65 +1,65 @@
-# This is a basic version file for the Config-mode of find_package().
-# It is used by write_basic_package_version_file() as input file for configure_file()
-# to create a version-file which can be installed along a config.cmake file.
-#
-# The created file sets PACKAGE_VERSION_EXACT if the current version string and
-# the requested version string are exactly the same and it sets
-# PACKAGE_VERSION_COMPATIBLE if the current version is >= requested version,
-# but only if the requested major version is the same as the current one.
-# The variable CVF_VERSION must be set before calling configure_file().
-
-
-set(PACKAGE_VERSION "1.6.0")
-
-if(PACKAGE_VERSION VERSION_LESS PACKAGE_FIND_VERSION)
-  set(PACKAGE_VERSION_COMPATIBLE FALSE)
-else()
-
-  if("1.6.0" MATCHES "^([0-9]+)\\.")
-    set(CVF_VERSION_MAJOR "${CMAKE_MATCH_1}")
-    if(NOT CVF_VERSION_MAJOR VERSION_EQUAL 0)
-      string(REGEX REPLACE "^0+" "" CVF_VERSION_MAJOR "${CVF_VERSION_MAJOR}")
-    endif()
-  else()
-    set(CVF_VERSION_MAJOR "1.6.0")
-  endif()
-
-  if(PACKAGE_FIND_VERSION_RANGE)
-    # both endpoints of the range must have the expected major version
-    math (EXPR CVF_VERSION_MAJOR_NEXT "${CVF_VERSION_MAJOR} + 1")
-    if (NOT PACKAGE_FIND_VERSION_MIN_MAJOR STREQUAL CVF_VERSION_MAJOR
-        OR ((PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "INCLUDE" AND NOT PACKAGE_FIND_VERSION_MAX_MAJOR STREQUAL CVF_VERSION_MAJOR)
-          OR (PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "EXCLUDE" AND NOT PACKAGE_FIND_VERSION_MAX VERSION_LESS_EQUAL CVF_VERSION_MAJOR_NEXT)))
-      set(PACKAGE_VERSION_COMPATIBLE FALSE)
-    elseif(PACKAGE_FIND_VERSION_MIN_MAJOR STREQUAL CVF_VERSION_MAJOR
-        AND ((PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "INCLUDE" AND PACKAGE_VERSION VERSION_LESS_EQUAL PACKAGE_FIND_VERSION_MAX)
-        OR (PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "EXCLUDE" AND PACKAGE_VERSION VERSION_LESS PACKAGE_FIND_VERSION_MAX)))
-      set(PACKAGE_VERSION_COMPATIBLE TRUE)
-    else()
-      set(PACKAGE_VERSION_COMPATIBLE FALSE)
-    endif()
-  else()
-    if(PACKAGE_FIND_VERSION_MAJOR STREQUAL CVF_VERSION_MAJOR)
-      set(PACKAGE_VERSION_COMPATIBLE TRUE)
-    else()
-      set(PACKAGE_VERSION_COMPATIBLE FALSE)
-    endif()
-
-    if(PACKAGE_FIND_VERSION STREQUAL PACKAGE_VERSION)
-      set(PACKAGE_VERSION_EXACT TRUE)
-    endif()
-  endif()
-endif()
-
-
-# if the installed or the using project don't have CMAKE_SIZEOF_VOID_P set, ignore it:
-if("${CMAKE_SIZEOF_VOID_P}" STREQUAL "" OR "8" STREQUAL "")
-  return()
-endif()
-
-# check that the installed version has the same 32/64bit-ness as the one which is currently searching:
-if(NOT CMAKE_SIZEOF_VOID_P STREQUAL "8")
-  math(EXPR installedBits "8 * 8")
-  set(PACKAGE_VERSION "${PACKAGE_VERSION} (${installedBits}bit)")
-  set(PACKAGE_VERSION_UNSUITABLE TRUE)
-endif()
+# This is a basic version file for the Config-mode of find_package().
+# It is used by write_basic_package_version_file() as input file for configure_file()
+# to create a version-file which can be installed along a config.cmake file.
+#
+# The created file sets PACKAGE_VERSION_EXACT if the current version string and
+# the requested version string are exactly the same and it sets
+# PACKAGE_VERSION_COMPATIBLE if the current version is >= requested version,
+# but only if the requested major version is the same as the current one.
+# The variable CVF_VERSION must be set before calling configure_file().
+
+
+set(PACKAGE_VERSION "1.6.0")
+
+if(PACKAGE_VERSION VERSION_LESS PACKAGE_FIND_VERSION)
+  set(PACKAGE_VERSION_COMPATIBLE FALSE)
+else()
+
+  if("1.6.0" MATCHES "^([0-9]+)\\.")
+    set(CVF_VERSION_MAJOR "${CMAKE_MATCH_1}")
+    if(NOT CVF_VERSION_MAJOR VERSION_EQUAL 0)
+      string(REGEX REPLACE "^0+" "" CVF_VERSION_MAJOR "${CVF_VERSION_MAJOR}")
+    endif()
+  else()
+    set(CVF_VERSION_MAJOR "1.6.0")
+  endif()
+
+  if(PACKAGE_FIND_VERSION_RANGE)
+    # both endpoints of the range must have the expected major version
+    math (EXPR CVF_VERSION_MAJOR_NEXT "${CVF_VERSION_MAJOR} + 1")
+    if (NOT PACKAGE_FIND_VERSION_MIN_MAJOR STREQUAL CVF_VERSION_MAJOR
+        OR ((PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "INCLUDE" AND NOT PACKAGE_FIND_VERSION_MAX_MAJOR STREQUAL CVF_VERSION_MAJOR)
+          OR (PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "EXCLUDE" AND NOT PACKAGE_FIND_VERSION_MAX VERSION_LESS_EQUAL CVF_VERSION_MAJOR_NEXT)))
+      set(PACKAGE_VERSION_COMPATIBLE FALSE)
+    elseif(PACKAGE_FIND_VERSION_MIN_MAJOR STREQUAL CVF_VERSION_MAJOR
+        AND ((PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "INCLUDE" AND PACKAGE_VERSION VERSION_LESS_EQUAL PACKAGE_FIND_VERSION_MAX)
+        OR (PACKAGE_FIND_VERSION_RANGE_MAX STREQUAL "EXCLUDE" AND PACKAGE_VERSION VERSION_LESS PACKAGE_FIND_VERSION_MAX)))
+      set(PACKAGE_VERSION_COMPATIBLE TRUE)
+    else()
+      set(PACKAGE_VERSION_COMPATIBLE FALSE)
+    endif()
+  else()
+    if(PACKAGE_FIND_VERSION_MAJOR STREQUAL CVF_VERSION_MAJOR)
+      set(PACKAGE_VERSION_COMPATIBLE TRUE)
+    else()
+      set(PACKAGE_VERSION_COMPATIBLE FALSE)
+    endif()
+
+    if(PACKAGE_FIND_VERSION STREQUAL PACKAGE_VERSION)
+      set(PACKAGE_VERSION_EXACT TRUE)
+    endif()
+  endif()
+endif()
+
+
+# if the installed or the using project don't have CMAKE_SIZEOF_VOID_P set, ignore it:
+if("${CMAKE_SIZEOF_VOID_P}" STREQUAL "" OR "8" STREQUAL "")
+  return()
+endif()
+
+# check that the installed version has the same 32/64bit-ness as the one which is currently searching:
+if(NOT CMAKE_SIZEOF_VOID_P STREQUAL "8")
+  math(EXPR installedBits "8 * 8")
+  set(PACKAGE_VERSION "${PACKAGE_VERSION} (${installedBits}bit)")
+  set(PACKAGE_VERSION_UNSUITABLE TRUE)
+endif()
```

## Comparing `skdecide/hub/lib/cmake/nng/nng-targets-release.cmake` & `skdecide/hub/lib64/cmake/nng/nng-targets-release.cmake`

 * *Files 24% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-#----------------------------------------------------------------
-# Generated CMake target import file for configuration "Release".
-#----------------------------------------------------------------
-
-# Commands may need to know the format version.
-set(CMAKE_IMPORT_FILE_VERSION 1)
-
-# Import target "nng::nng" for configuration "Release"
-set_property(TARGET nng::nng APPEND PROPERTY IMPORTED_CONFIGURATIONS RELEASE)
-set_target_properties(nng::nng PROPERTIES
-  IMPORTED_LINK_INTERFACE_LANGUAGES_RELEASE "C"
-  IMPORTED_LOCATION_RELEASE "${_IMPORT_PREFIX}/lib/nng.lib"
-  )
-
-list(APPEND _cmake_import_check_targets nng::nng )
-list(APPEND _cmake_import_check_files_for_nng::nng "${_IMPORT_PREFIX}/lib/nng.lib" )
-
-# Commands beyond this point should not need to know the version.
-set(CMAKE_IMPORT_FILE_VERSION)
+#----------------------------------------------------------------
+# Generated CMake target import file for configuration "Release".
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Import target "nng::nng" for configuration "Release"
+set_property(TARGET nng::nng APPEND PROPERTY IMPORTED_CONFIGURATIONS RELEASE)
+set_target_properties(nng::nng PROPERTIES
+  IMPORTED_LINK_INTERFACE_LANGUAGES_RELEASE "C"
+  IMPORTED_LOCATION_RELEASE "${_IMPORT_PREFIX}/lib64/libnng.a"
+  )
+
+list(APPEND _cmake_import_check_targets nng::nng )
+list(APPEND _cmake_import_check_files_for_nng::nng "${_IMPORT_PREFIX}/lib64/libnng.a" )
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
```

## Comparing `skdecide/hub/lib/cmake/nng/nng-targets.cmake` & `skdecide/hub/lib64/cmake/nng/nng-targets.cmake`

 * *Files 17% similar despite different names*

```diff
@@ -1,108 +1,108 @@
-# Generated by CMake
-
-if("${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}" LESS 2.8)
-   message(FATAL_ERROR "CMake >= 2.8.0 required")
-endif()
-if(CMAKE_VERSION VERSION_LESS "2.8.3")
-   message(FATAL_ERROR "CMake >= 2.8.3 required")
-endif()
-cmake_policy(PUSH)
-cmake_policy(VERSION 2.8.3...3.25)
-#----------------------------------------------------------------
-# Generated CMake target import file.
-#----------------------------------------------------------------
-
-# Commands may need to know the format version.
-set(CMAKE_IMPORT_FILE_VERSION 1)
-
-# Protect against multiple inclusion, which would fail when already imported targets are added once more.
-set(_cmake_targets_defined "")
-set(_cmake_targets_not_defined "")
-set(_cmake_expected_targets "")
-foreach(_cmake_expected_target IN ITEMS nng::nng)
-  list(APPEND _cmake_expected_targets "${_cmake_expected_target}")
-  if(TARGET "${_cmake_expected_target}")
-    list(APPEND _cmake_targets_defined "${_cmake_expected_target}")
-  else()
-    list(APPEND _cmake_targets_not_defined "${_cmake_expected_target}")
-  endif()
-endforeach()
-unset(_cmake_expected_target)
-if(_cmake_targets_defined STREQUAL _cmake_expected_targets)
-  unset(_cmake_targets_defined)
-  unset(_cmake_targets_not_defined)
-  unset(_cmake_expected_targets)
-  unset(CMAKE_IMPORT_FILE_VERSION)
-  cmake_policy(POP)
-  return()
-endif()
-if(NOT _cmake_targets_defined STREQUAL "")
-  string(REPLACE ";" ", " _cmake_targets_defined_text "${_cmake_targets_defined}")
-  string(REPLACE ";" ", " _cmake_targets_not_defined_text "${_cmake_targets_not_defined}")
-  message(FATAL_ERROR "Some (but not all) targets in this export set were already defined.\nTargets Defined: ${_cmake_targets_defined_text}\nTargets not yet defined: ${_cmake_targets_not_defined_text}\n")
-endif()
-unset(_cmake_targets_defined)
-unset(_cmake_targets_not_defined)
-unset(_cmake_expected_targets)
-
-
-# Compute the installation prefix relative to this file.
-get_filename_component(_IMPORT_PREFIX "${CMAKE_CURRENT_LIST_FILE}" PATH)
-get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
-get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
-get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
-if(_IMPORT_PREFIX STREQUAL "/")
-  set(_IMPORT_PREFIX "")
-endif()
-
-# Create imported target nng::nng
-add_library(nng::nng STATIC IMPORTED)
-
-set_target_properties(nng::nng PROPERTIES
-  INTERFACE_COMPILE_DEFINITIONS "NNG_STATIC_LIB"
-  INTERFACE_INCLUDE_DIRECTORIES "${_IMPORT_PREFIX}/include"
-  INTERFACE_LINK_LIBRARIES "\$<LINK_ONLY:ws2_32>;\$<LINK_ONLY:mswsock>;\$<LINK_ONLY:advapi32>"
-)
-
-if(CMAKE_VERSION VERSION_LESS 2.8.12)
-  message(FATAL_ERROR "This file relies on consumers using CMake 2.8.12 or greater.")
-endif()
-
-# Load information for each installed configuration.
-file(GLOB _cmake_config_files "${CMAKE_CURRENT_LIST_DIR}/nng-targets-*.cmake")
-foreach(_cmake_config_file IN LISTS _cmake_config_files)
-  include("${_cmake_config_file}")
-endforeach()
-unset(_cmake_config_file)
-unset(_cmake_config_files)
-
-# Cleanup temporary variables.
-set(_IMPORT_PREFIX)
-
-# Loop over all imported files and verify that they actually exist
-foreach(_cmake_target IN LISTS _cmake_import_check_targets)
-  foreach(_cmake_file IN LISTS "_cmake_import_check_files_for_${_cmake_target}")
-    if(NOT EXISTS "${_cmake_file}")
-      message(FATAL_ERROR "The imported target \"${_cmake_target}\" references the file
-   \"${_cmake_file}\"
-but this file does not exist.  Possible reasons include:
-* The file was deleted, renamed, or moved to another location.
-* An install or uninstall procedure did not complete successfully.
-* The installation package was faulty and contained
-   \"${CMAKE_CURRENT_LIST_FILE}\"
-but not all the files it references.
-")
-    endif()
-  endforeach()
-  unset(_cmake_file)
-  unset("_cmake_import_check_files_for_${_cmake_target}")
-endforeach()
-unset(_cmake_target)
-unset(_cmake_import_check_targets)
-
-# This file does not depend on other imported targets which have
-# been exported from the same project but in a separate export set.
-
-# Commands beyond this point should not need to know the version.
-set(CMAKE_IMPORT_FILE_VERSION)
-cmake_policy(POP)
+# Generated by CMake
+
+if("${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}" LESS 2.8)
+   message(FATAL_ERROR "CMake >= 2.8.0 required")
+endif()
+if(CMAKE_VERSION VERSION_LESS "2.8.12")
+   message(FATAL_ERROR "CMake >= 2.8.12 required")
+endif()
+cmake_policy(PUSH)
+cmake_policy(VERSION 2.8.12...3.27)
+#----------------------------------------------------------------
+# Generated CMake target import file.
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Protect against multiple inclusion, which would fail when already imported targets are added once more.
+set(_cmake_targets_defined "")
+set(_cmake_targets_not_defined "")
+set(_cmake_expected_targets "")
+foreach(_cmake_expected_target IN ITEMS nng::nng)
+  list(APPEND _cmake_expected_targets "${_cmake_expected_target}")
+  if(TARGET "${_cmake_expected_target}")
+    list(APPEND _cmake_targets_defined "${_cmake_expected_target}")
+  else()
+    list(APPEND _cmake_targets_not_defined "${_cmake_expected_target}")
+  endif()
+endforeach()
+unset(_cmake_expected_target)
+if(_cmake_targets_defined STREQUAL _cmake_expected_targets)
+  unset(_cmake_targets_defined)
+  unset(_cmake_targets_not_defined)
+  unset(_cmake_expected_targets)
+  unset(CMAKE_IMPORT_FILE_VERSION)
+  cmake_policy(POP)
+  return()
+endif()
+if(NOT _cmake_targets_defined STREQUAL "")
+  string(REPLACE ";" ", " _cmake_targets_defined_text "${_cmake_targets_defined}")
+  string(REPLACE ";" ", " _cmake_targets_not_defined_text "${_cmake_targets_not_defined}")
+  message(FATAL_ERROR "Some (but not all) targets in this export set were already defined.\nTargets Defined: ${_cmake_targets_defined_text}\nTargets not yet defined: ${_cmake_targets_not_defined_text}\n")
+endif()
+unset(_cmake_targets_defined)
+unset(_cmake_targets_not_defined)
+unset(_cmake_expected_targets)
+
+
+# Compute the installation prefix relative to this file.
+get_filename_component(_IMPORT_PREFIX "${CMAKE_CURRENT_LIST_FILE}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+if(_IMPORT_PREFIX STREQUAL "/")
+  set(_IMPORT_PREFIX "")
+endif()
+
+# Create imported target nng::nng
+add_library(nng::nng STATIC IMPORTED)
+
+set_target_properties(nng::nng PROPERTIES
+  INTERFACE_COMPILE_DEFINITIONS "NNG_STATIC_LIB"
+  INTERFACE_INCLUDE_DIRECTORIES "${_IMPORT_PREFIX}/include"
+  INTERFACE_LINK_LIBRARIES "\$<LINK_ONLY:Threads::Threads>;\$<LINK_ONLY:rt>;\$<LINK_ONLY:pthread>;\$<LINK_ONLY:pthread>;\$<LINK_ONLY:pthread>;\$<LINK_ONLY:nsl>"
+)
+
+# Load information for each installed configuration.
+file(GLOB _cmake_config_files "${CMAKE_CURRENT_LIST_DIR}/nng-targets-*.cmake")
+foreach(_cmake_config_file IN LISTS _cmake_config_files)
+  include("${_cmake_config_file}")
+endforeach()
+unset(_cmake_config_file)
+unset(_cmake_config_files)
+
+# Cleanup temporary variables.
+set(_IMPORT_PREFIX)
+
+# Loop over all imported files and verify that they actually exist
+foreach(_cmake_target IN LISTS _cmake_import_check_targets)
+  if(CMAKE_VERSION VERSION_LESS "3.28"
+      OR NOT DEFINED _cmake_import_check_xcframework_for_${_cmake_target}
+      OR NOT IS_DIRECTORY "${_cmake_import_check_xcframework_for_${_cmake_target}}")
+    foreach(_cmake_file IN LISTS "_cmake_import_check_files_for_${_cmake_target}")
+      if(NOT EXISTS "${_cmake_file}")
+        message(FATAL_ERROR "The imported target \"${_cmake_target}\" references the file
+   \"${_cmake_file}\"
+but this file does not exist.  Possible reasons include:
+* The file was deleted, renamed, or moved to another location.
+* An install or uninstall procedure did not complete successfully.
+* The installation package was faulty and contained
+   \"${CMAKE_CURRENT_LIST_FILE}\"
+but not all the files it references.
+")
+      endif()
+    endforeach()
+  endif()
+  unset(_cmake_file)
+  unset("_cmake_import_check_files_for_${_cmake_target}")
+endforeach()
+unset(_cmake_target)
+unset(_cmake_import_check_targets)
+
+# This file does not depend on other imported targets which have
+# been exported from the same project but in a separate export set.
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
+cmake_policy(POP)
```

## Comparing `scikit_decide-0.9.8.dist-info/entry_points.txt` & `scikit_decide-1.0.0.dist-info/entry_points.txt`

 * *Files 14% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 [skdecide.domains]
 CostDeterministicGymDomain=skdecide.hub.domain.gym:CostDeterministicGymDomain[domains]
 DeterministicGymDomain=skdecide.hub.domain.gym:DeterministicGymDomain[domains]
 FlightPlanningDomain=skdecide.hub.domain.flight_planning:FlightPlanningDomain[domains]
 GymDomain=skdecide.hub.domain.gym:GymDomain[domains]
 GymPlanningDomain=skdecide.hub.domain.gym:GymPlanningDomain[domains]
-GymWidthPlanningDomain=skdecide.hub.domain.gym:GymWidthPlanningDomain[domains]
+GymWidthDomain=skdecide.hub.domain.gym:GymWidthDomain[domains]
 MRCPSP=skdecide.hub.domain.rcpsp:MRCPSP[domains]
 MRCPSPCalendar=skdecide.hub.domain.rcpsp:MRCPSPCalendar[domains]
 MSRCPSP=skdecide.hub.domain.rcpsp:MSRCPSP[domains]
 MSRCPSPCalendar=skdecide.hub.domain.rcpsp:MSRCPSPCalendar[domains]
 MasterMind=skdecide.hub.domain.mastermind:MasterMind[domains]
 Maze=skdecide.hub.domain.maze:Maze[domains]
 RCPSP=skdecide.hub.domain.rcpsp:RCPSP[domains]
@@ -22,26 +22,26 @@
 [skdecide.solvers]
 AOstar=skdecide.hub.solver.aostar:AOstar[solvers]
 Astar=skdecide.hub.solver.astar:Astar[solvers]
 AugmentedRandomSearch=skdecide.hub.solver.ars:AugmentedRandomSearch[solvers]
 BFWS=skdecide.hub.solver.bfws:BFWS[solvers]
 CGP=skdecide.hub.solver.cgp:CGP[solvers]
 DOSolver=skdecide.hub.solver.do_solver:DOSolver[solvers]
-GPHH=skdecide.hub.solver.gphh:GPHH[solvers]
+GPHH=skdecide.hub.solver.do_solver:GPHH[solvers]
 ILAOstar=skdecide.hub.solver.ilaostar:ILAOstar[solvers]
 IW=skdecide.hub.solver.iw:IW[solvers]
 LRTAstar=skdecide.hub.solver.lrtastar:LRTAstar[solvers]
 LRTDP=skdecide.hub.solver.lrtdp:LRTDP[solvers]
 LazyAstar=skdecide.hub.solver.lazy_astar:LazyAstar[solvers]
 MAHD=skdecide.hub.solver.mahd:MAHD[solvers]
 MARTDP=skdecide.hub.solver.martdp:MARTDP[solvers]
 MCTS=skdecide.hub.solver.mcts:MCTS[solvers]
 MaxentIRL=skdecide.hub.solver.maxent_irl:MaxentIRL[solvers]
 POMCP=skdecide.hub.solver.pomcp:POMCP[solvers]
-PilePolicy=skdecide.hub.solver.pile_policy:PilePolicy[solvers]
+PilePolicy=skdecide.hub.solver.pile_policy_scheduling:PilePolicy[solvers]
 RIW=skdecide.hub.solver.riw:RIW[solvers]
 RayRLlib=skdecide.hub.solver.ray_rllib:RayRLlib[solvers]
 SimpleGreedy=skdecide.hub.solver.simple_greedy:SimpleGreedy[solvers]
 StableBaseline=skdecide.hub.solver.stable_baselines:StableBaseline[solvers]
 UCT=skdecide.hub.solver.mcts:UCT[solvers]
 UPSolver=skdecide.hub.solver.up:UPSolver[solvers]
```

## Comparing `scikit_decide-0.9.8.dist-info/LICENSE` & `scikit_decide-1.0.0.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-The MIT License
-
-Copyright (c) 2019 AIRBUS http://airbus.com
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+The MIT License
+
+Copyright (c) 2019 AIRBUS http://airbus.com
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
```

## Comparing `scikit_decide-0.9.8.dist-info/METADATA` & `scikit_decide-1.0.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: scikit-decide
-Version: 0.9.8
+Version: 1.0.0
 Summary: The AI framework for Reinforcement Learning, Automated Planning and Scheduling
 Home-page: https://airbus.github.io/scikit-decide/
 License: MIT
 Keywords: reinforcement learning,planning,scheduling
 Author: Airbus AI Research
 Author-email: scikit-decide@airbus.com
 Requires-Python: >=3.8,<4.0
@@ -28,47 +28,47 @@
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Software Development
 Provides-Extra: all
 Provides-Extra: domains
 Provides-Extra: solvers
 Requires-Dist: cartopy (>=0.22.0) ; (python_version >= "3.9") and (extra == "domains" or extra == "all")
-Requires-Dist: discrete-optimization (>=0.2.3) ; extra == "domains" or extra == "solvers" or extra == "all"
+Requires-Dist: discrete-optimization (>=0.3.0) ; extra == "domains" or extra == "solvers" or extra == "all"
 Requires-Dist: gymnasium (>=0.28.1) ; extra == "domains" or extra == "solvers" or extra == "all"
 Requires-Dist: joblib (>=1.0.1) ; extra == "solvers" or extra == "all"
 Requires-Dist: matplotlib (>=3.3.4) ; extra == "domains" or extra == "all"
 Requires-Dist: numpy (>=1.20.1) ; extra == "domains" or extra == "solvers" or extra == "all"
-Requires-Dist: openap (>=1.3) ; extra == "domains" or extra == "all"
+Requires-Dist: openap (>=1.5) ; (python_version >= "3.9") and (extra == "domains" or extra == "all")
 Requires-Dist: pathos (>=0.2.7)
 Requires-Dist: pygeodesy (>=23.6.12) ; extra == "domains" or extra == "all"
 Requires-Dist: pygrib (>=2.1.5) ; (sys_platform == "darwin") and (extra == "domains" or extra == "all")
 Requires-Dist: pygrib (>=2.1.5) ; (sys_platform == "linux") and (extra == "domains" or extra == "all")
 Requires-Dist: pynng (>=0.6.2)
 Requires-Dist: ray[rllib] (>=2.7.0) ; extra == "solvers" or extra == "all"
 Requires-Dist: scipy (>=1.9.2)
 Requires-Dist: stable-baselines3 (>=2.0.0) ; extra == "solvers" or extra == "all"
-Requires-Dist: unified-planning (>=1.0.0.378.dev1,<2.0.0.0) ; (python_version >= "3.10") and (extra == "domains" or extra == "solvers" or extra == "all")
-Requires-Dist: up-enhsp (>=0.0.23,<0.0.24) ; (python_version >= "3.10") and (extra == "solvers" or extra == "all")
-Requires-Dist: up-fast-downward (>=0.4.1,<0.5.0) ; (python_version >= "3.10") and (extra == "solvers" or extra == "all")
-Requires-Dist: up-pyperplan (>=1.0.0.7.dev1,<2.0.0.0) ; (python_version >= "3.10") and (extra == "solvers" or extra == "all")
-Requires-Dist: up-tamer (>=1.0.0.8.dev1,<2.0.0.0) ; (platform_machine == "x86_64" and python_version >= "3.10") and (extra == "solvers" or extra == "all")
+Requires-Dist: unified-planning (>=1.1.0) ; (python_version >= "3.10") and (extra == "domains" or extra == "solvers" or extra == "all")
+Requires-Dist: up-enhsp (>=0.0.25) ; (python_version >= "3.10") and (extra == "solvers" or extra == "all")
+Requires-Dist: up-fast-downward (>=0.4.1) ; (python_version >= "3.10") and (extra == "solvers" or extra == "all")
+Requires-Dist: up-pyperplan (>=1.1.0) ; (python_version >= "3.10") and (extra == "solvers" or extra == "all")
+Requires-Dist: up-tamer (>=1.1.2) ; (platform_machine == "x86_64" and python_version >= "3.10") and (extra == "solvers" or extra == "all")
 Project-URL: Repository, https://github.com/airbus/scikit-decide
 Description-Content-Type: text/markdown
 
 
                     _  __    _  __              __             _      __
        _____ _____ (_)/ /__ (_)/ /_        ____/ /___   _____ (_)____/ /___
       / ___// ___// // //_// // __/______ / __  // _ \ / ___// // __  // _ \
      (__  )/ /__ / // ,<  / // /_ /_____// /_/ //  __// /__ / // /_/ //  __/
     /____/ \___//_//_/|_|/_/ \__/        \__,_/ \___/ \___//_/ \__,_/ \___/
 
 <br>
 <p align="center">
-  <a href="https://github.com/airbus/scikit-decide/actions/workflows/build.yml?query=branch%3Amaster">
-    <img src="https://img.shields.io/github/actions/workflow/status/airbus/scikit-decide/build.yml?branch=master&logo=github&label=CI%20status" alt="actions status">
+  <a href="https://github.com/airbus/scikit-decide/actions/workflows/ci.yml?query=branch%3Amaster">
+    <img src="https://img.shields.io/github/actions/workflow/status/airbus/scikit-decide/ci.yml?branch=master&logo=github&label=CI%20status" alt="actions status">
   </a>
   <a href="https://github.com/airbus/scikit-decide/tags">
     <img src="https://img.shields.io/github/tag/airbus/scikit-decide.svg?label=current%20version" alt="version">
   </a>
   <a href="https://github.com/airbus/scikit-decide/stargazers">
     <img src="https://img.shields.io/github/stars/airbus/scikit-decide.svg" alt="stars">
   </a>
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: scikit-decide Version: 0.9.8 Summary: The AI
+Metadata-Version: 2.1 Name: scikit-decide Version: 1.0.0 Summary: The AI
 framework for Reinforcement Learning, Automated Planning and Scheduling Home-
 page: https://airbus.github.io/scikit-decide/ License: MIT Keywords:
 reinforcement learning,planning,scheduling Author: Airbus AI Research Author-
 email: scikit-decide@airbus.com Requires-Python: >=3.8,<4.0 Classifier:
 Development Status :: 4 - Beta Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research Classifier: License :: OSI
 Approved :: MIT License Classifier: Natural Language :: English Classifier:
@@ -13,42 +13,42 @@
 Language :: Python :: 3.8 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10 Classifier: Programming
 Language :: Python :: 3.11 Classifier: Programming Language :: Python :: 3.12
 Classifier: Programming Language :: Python :: 3.7 Classifier: Topic ::
 Scientific/Engineering Classifier: Topic :: Software Development Provides-
 Extra: all Provides-Extra: domains Provides-Extra: solvers Requires-Dist:
 cartopy (>=0.22.0) ; (python_version >= "3.9") and (extra == "domains" or extra
-== "all") Requires-Dist: discrete-optimization (>=0.2.3) ; extra == "domains"
+== "all") Requires-Dist: discrete-optimization (>=0.3.0) ; extra == "domains"
 or extra == "solvers" or extra == "all" Requires-Dist: gymnasium (>=0.28.1) ;
 extra == "domains" or extra == "solvers" or extra == "all" Requires-Dist:
 joblib (>=1.0.1) ; extra == "solvers" or extra == "all" Requires-Dist:
 matplotlib (>=3.3.4) ; extra == "domains" or extra == "all" Requires-Dist:
 numpy (>=1.20.1) ; extra == "domains" or extra == "solvers" or extra == "all"
-Requires-Dist: openap (>=1.3) ; extra == "domains" or extra == "all" Requires-
-Dist: pathos (>=0.2.7) Requires-Dist: pygeodesy (>=23.6.12) ; extra ==
-"domains" or extra == "all" Requires-Dist: pygrib (>=2.1.5) ; (sys_platform ==
-"darwin") and (extra == "domains" or extra == "all") Requires-Dist: pygrib
-(>=2.1.5) ; (sys_platform == "linux") and (extra == "domains" or extra ==
-"all") Requires-Dist: pynng (>=0.6.2) Requires-Dist: ray[rllib] (>=2.7.0) ;
-extra == "solvers" or extra == "all" Requires-Dist: scipy (>=1.9.2) Requires-
-Dist: stable-baselines3 (>=2.0.0) ; extra == "solvers" or extra == "all"
-Requires-Dist: unified-planning (>=1.0.0.378.dev1,<2.0.0.0) ; (python_version
->= "3.10") and (extra == "domains" or extra == "solvers" or extra == "all")
-Requires-Dist: up-enhsp (>=0.0.23,<0.0.24) ; (python_version >= "3.10") and
-(extra == "solvers" or extra == "all") Requires-Dist: up-fast-downward
-(>=0.4.1,<0.5.0) ; (python_version >= "3.10") and (extra == "solvers" or extra
-== "all") Requires-Dist: up-pyperplan (>=1.0.0.7.dev1,<2.0.0.0) ;
-(python_version >= "3.10") and (extra == "solvers" or extra == "all") Requires-
-Dist: up-tamer (>=1.0.0.8.dev1,<2.0.0.0) ; (platform_machine == "x86_64" and
-python_version >= "3.10") and (extra == "solvers" or extra == "all") Project-
-URL: Repository, https://github.com/airbus/scikit-decide Description-Content-
-Type: text/markdown _ __ _ __ __ _ __ _____ _____ (_)/ /__ (_)/ /_ ____/ /___
-_____ (_)____/ /___ / ___// ___// // //_// // __/______ / __ // _ \ / ___// /
-/ __ // _ \ (__ )/ /__ / // ,< / // /_ /_____// /_/ // __// /__ / // /_/ // __/
-/____/ \___//_//_/|_|/_/ \__/ \__,_/ \___/ \___//_/ \__,_/ \___/
+Requires-Dist: openap (>=1.5) ; (python_version >= "3.9") and (extra ==
+"domains" or extra == "all") Requires-Dist: pathos (>=0.2.7) Requires-Dist:
+pygeodesy (>=23.6.12) ; extra == "domains" or extra == "all" Requires-Dist:
+pygrib (>=2.1.5) ; (sys_platform == "darwin") and (extra == "domains" or extra
+== "all") Requires-Dist: pygrib (>=2.1.5) ; (sys_platform == "linux") and
+(extra == "domains" or extra == "all") Requires-Dist: pynng (>=0.6.2) Requires-
+Dist: ray[rllib] (>=2.7.0) ; extra == "solvers" or extra == "all" Requires-
+Dist: scipy (>=1.9.2) Requires-Dist: stable-baselines3 (>=2.0.0) ; extra ==
+"solvers" or extra == "all" Requires-Dist: unified-planning (>=1.1.0) ;
+(python_version >= "3.10") and (extra == "domains" or extra == "solvers" or
+extra == "all") Requires-Dist: up-enhsp (>=0.0.25) ; (python_version >= "3.10")
+and (extra == "solvers" or extra == "all") Requires-Dist: up-fast-downward
+(>=0.4.1) ; (python_version >= "3.10") and (extra == "solvers" or extra ==
+"all") Requires-Dist: up-pyperplan (>=1.1.0) ; (python_version >= "3.10") and
+(extra == "solvers" or extra == "all") Requires-Dist: up-tamer (>=1.1.2) ;
+(platform_machine == "x86_64" and python_version >= "3.10") and (extra ==
+"solvers" or extra == "all") Project-URL: Repository, https://github.com/
+airbus/scikit-decide Description-Content-Type: text/markdown _ __ _ __ __ _ __
+_____ _____ (_)/ /__ (_)/ /_ ____/ /___ _____ (_)____/ /___ / ___// ___// // //
+_// // __/______ / __ // _ \ / ___// // __ // _ \ (__ )/ /__ / // ,< / // /_ /
+_____// /_/ // __// /__ / // /_/ // __/ /____/ \___//_//_/|_|/_/ \__/ \__,_/
+\___/ \___//_/ \__,_/ \___/
                     _[_a_c_t_i_o_n_s_ _s_t_a_t_u_s_]_[_v_e_r_s_i_o_n_]_[_s_t_a_r_s_]_[_f_o_r_k_s_]
 
 # Scikit-decide for Python Scikit-decide is an AI framework for Reinforcement
 Learning, Automated Planning and Scheduling. ## Installation Quick version:
 ```shell pip install scikit-decide[all] ``` For more details, see the [online
 documentation](https://airbus.github.io/scikit-decide/install). ##
 Documentation The latest documentation is available [online](https://
```

## Comparing `scikit_decide-0.9.8.dist-info/RECORD` & `scikit_decide-1.0.0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,191 +1,208 @@
-LICENSE,sha256=VlhkRbo8Dvt3iasWcJexCYTwV-qi23svC9rXmWkyV0o,1106
-README.md,sha256=jwG1ZlfdglgmVSFRnZq8pnidhc_9OaDXu2eLGYrjS0k,2274
-skdecide/__init__.py,sha256=sbtWwN457Jbq850uqCwmnF-9khdxMx5vz5XD7cHgz8E,346
-skdecide/builders/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/builders/domain/__init__.py,sha256=9oIA4gzpRX6nhPG_vYtSGJ0VA1exuSKkRNxJXoanPoI,720
-skdecide/builders/domain/agent.py,sha256=4DmUnHCa5SbZ5WJ5yEXWYzLcAUL84ebHbUl2TqB691A,1184
-skdecide/builders/domain/concurrency.py,sha256=gyXBkMSLrOGUEdFjSa7mEb6qAAxbUG-E3HEaiQicfjE,681
-skdecide/builders/domain/constraints.py,sha256=NlU96MkFlq5E5S9epGiig-ZmwUxy4QcMTgxx2EG4h98,2340
-skdecide/builders/domain/dynamics.py,sha256=FRYmhqYKGJZdurorFLfSaOTVPNu8Yjp-J6yT_j0ZwC4,24067
-skdecide/builders/domain/events.py,sha256=MRVn5PvLBGTxd-fAUue5ytwjZFZ6CE-PRa_rPJ0CTBA,14312
-skdecide/builders/domain/goals.py,sha256=5q-8SvT6bXd6J76vtVZPKMZAHb0Qp9QkNTCbFIL-AtY,4276
-skdecide/builders/domain/initialization.py,sha256=sjlzgAiV4Ry0WQdF7QyLbTFedeW0ph39RnRnqUq2prM,6096
-skdecide/builders/domain/memory.py,sha256=slw-RLvJWTWwtOg8q1yXQtn47B2T_yJnyuuVDrinzJM,4064
-skdecide/builders/domain/observability.py,sha256=xRsbNwJFxmBqRVQFq98FxrtLHS9iAln19m5JNhs05Rw,8150
-skdecide/builders/domain/renderability.py,sha256=R5DPtE14TdGmXioPGRKLHBb3jk_ffoluAPX3Gk3brZo,2642
-skdecide/builders/domain/scheduling/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/builders/domain/scheduling/conditional_tasks.py,sha256=J_gQ6DJvYJ0vaaBGLfTm1lqxufb3c1gI3QCm-dJ9Kqs,8453
-skdecide/builders/domain/scheduling/graph_toolbox.py,sha256=6kKTlG03t4dmG_Jc-2YB-eKDUZLBWZ94PNBNPfOzHmY,3990
-skdecide/builders/domain/scheduling/modes.py,sha256=7NMztUDiXY3h-i8BGdBBsYY02vgUmWxPs068Tt25q4o,8060
-skdecide/builders/domain/scheduling/preallocations.py,sha256=pDPl1mlf9UiEoZ_K8CLsWW5IYGmGcyEgk8F35uNunHU,1349
-skdecide/builders/domain/scheduling/precedence.py,sha256=DGnXdWB2fnnCdFJH7S9TjT8HFQNV0PrasbWjcZqx9SQ,4052
-skdecide/builders/domain/scheduling/preemptivity.py,sha256=1Sp5CdJ-zHDa5wN5h4Hnt433flkh7Oukw2wcF_2G9GI,4585
-skdecide/builders/domain/scheduling/resource_availability.py,sha256=ykJ5pqlgT7Rt9kX5jpP9SavVdkNPzE2m9KSbWZBv--U,4740
-skdecide/builders/domain/scheduling/resource_consumption.py,sha256=PJUOWHcxQ9GZ73zbTcol-ta7s9sMgV1PENoj_rQWngU,1437
-skdecide/builders/domain/scheduling/resource_costs.py,sha256=2WG16Iin_AfTtqWHdL_FBhHcAaI9V9EF09qXBmO1wyQ,2911
-skdecide/builders/domain/scheduling/resource_renewability.py,sha256=OpxBj-fe1ZEHRfnIchu43zyW3eIVFnjvF91RYcokowg,3652
-skdecide/builders/domain/scheduling/resource_type.py,sha256=eo1wpFTFbQJ1f7jyST79o28-LstTH0T8HHlp4mP5F_k,2860
-skdecide/builders/domain/scheduling/scheduling_domains.py,sha256=orP8V4NUzNfqjMiPUCdS41_4Z9qkfmSFL4XokLc4eu0,75012
-skdecide/builders/domain/scheduling/scheduling_domains_modelling.py,sha256=Mn5jrIlhRNifKKY4wRzrsfW_WjsmQ6RxONhPzUUzM4k,11504
-skdecide/builders/domain/scheduling/skills.py,sha256=aZCz9TSXkNwJPSxQadOlzK9i8gtEkAMldTppnVCnq-Q,5956
-skdecide/builders/domain/scheduling/task.py,sha256=X2NR5_xI-zlzoe7WTj85u-Cm3ObxPq8S3iLkKatTE6Y,1724
-skdecide/builders/domain/scheduling/task_duration.py,sha256=8wAn90-nFFuwwVSw4aTYPGACmsyORyPQ1NmKlVUZ2CY,13202
-skdecide/builders/domain/scheduling/task_progress.py,sha256=BaDpzfAF5_-sFTSlus0Bsm2ttMTFhfx1rQCorxoEhYw,2071
-skdecide/builders/domain/scheduling/time_lag.py,sha256=cXMO_DpLXHIfqYFCfrWvM6zlWPLwza1S_cqhyMnYof4,3324
-skdecide/builders/domain/scheduling/time_windows.py,sha256=m9Fa5dPjrpQX2rBUguhKMwbSlxlEyTUK5_tMYGZ-kIM,5890
-skdecide/builders/domain/value.py,sha256=Muz-PrhHe5LzNz5mCg8pWKENG3zURngq6940RuGIgV0,2468
-skdecide/builders/solver/__init__.py,sha256=w1zHVkjVYiqUM0vromt2LInUJMvAqgUXt3RckSLwWvs,383
-skdecide/builders/solver/assessability.py,sha256=RVMERn3wqTOTTNywWp8UNoVj90wjTPDimj_rwvu--Ng,4071
-skdecide/builders/solver/parallelability.py,sha256=cO-P4igVkRqFaM2JQJOwOkEz6bp1R9W4bp0edesog68,3970
-skdecide/builders/solver/policy.py,sha256=0YeCXh3o8tO4Rwh7snq3IaaNK7easFiX_PGwqAwmL1I,4962
-skdecide/builders/solver/restorability.py,sha256=chlQK3bk1eKnd883aNqytzNKZfT_9E5lKdiR7XxsREg,1711
-skdecide/core.py,sha256=wF9dGxo8d-83SlJ-FKHvq-gVfv62Bd0phBk8KuUtxCE,27850
-skdecide/domains.py,sha256=EkF6s7PfwxTFjIX3Bk7rrt2CX0UQspOD4a-qnnlEKdE,12000
-skdecide/hub/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/hub/domain/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/hub/domain/flight_planning/__init__.py,sha256=DJScntu1d-7vFV0J-6bg7wxOeERZsLtukuJXcba_5E8,254
-skdecide/hub/domain/flight_planning/domain.py,sha256=giLnaiy3DiLWgMfu4x-LZZfB0OOk8oCgibjWF-kRqtA,59170
-skdecide/hub/domain/flight_planning/flightplanning_utils.py,sha256=rkGrBC9FlEyzxqQgIbjEyux1KOLugGzey85a_NC_FMs,8073
-skdecide/hub/domain/flight_planning/weather_interpolator/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/common_utils.py,sha256=U8gE0TwbfvoudmmCl2kNxXmKVLVKllYlKI-PccRiDGI,4567
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/get_weather_noaa.py,sha256=ipOXjWeOgXb8atppTgrb2spGrLuT0pYJrFuFxDLktwg,16822
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/GenericInterpolator.py,sha256=qsWmCk5bJ42PrDYs_ApmzPi5gfZmWAZmRLMw5HAllts,23309
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/intergrid.py,sha256=6305Q92CUZpheNchBq-ZfcASEIWO-O7pLSZtmmA4JwU,9329
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/WeatherInterpolator.py,sha256=_rMHpTXHgMvVURBJeLMlxSqxcTBUR6M13g3i6F0x7Q4,23337
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/parser_pygrib.py,sha256=uS3WR1NfyoZnIRm5lrr9C5jiYbLhsKYeQJH1i8gEtUk,23705
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/std_atm.py,sha256=PM9QruEfYlg5mDWcOYBKOkvLaYzu4xw0hrV_-u3soyw,40593
-skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/unit_conversion.py,sha256=cSjprZLPP9eg3j4-lmZtT_mIrGYBwdqPLmL6XCK5BMw,23006
-skdecide/hub/domain/gym/__init__.py,sha256=F7MwNfDoEi__K9rKV_CLfwPZP7bS0HEn-fVKBwtojx8,483
-skdecide/hub/domain/gym/gym.py,sha256=Cm3Pr1cB955oEl8wRaU_WZlPfI-gBJisrVlTT5Meu9g,49048
-skdecide/hub/domain/mastermind/__init__.py,sha256=NZPKTpDEW4-zrz3bGkLDhOAWAmJfdRotn2lEAXYq774,208
-skdecide/hub/domain/mastermind/mastermind.py,sha256=t3XaOm0by7xb-TcjqySILVUlQJrjN-w5mgRxw2TEIJU,5226
-skdecide/hub/domain/maze/__init__.py,sha256=J8n9JGLTRWpHUwtvIjKGkxFUl0GPChvXWVjH_G3zmvc,196
-skdecide/hub/domain/maze/maze.py,sha256=quZEOD3Qc1sanhDfUUWyhpHBbtF8vIfVF8vVUKs90ew,5380
-skdecide/hub/domain/rcpsp/__init__.py,sha256=nYCBAfxVubxHDYVLzt-7Np90Aza-VtA9NEh9BEpn3gA,347
-skdecide/hub/domain/rcpsp/rcpsp_sk.py,sha256=NTsR-GYDNypp_NmK5ISBr3aMYjjHg-hACbd4jw9kLNY,25414
-skdecide/hub/domain/rcpsp/rcpsp_sk_parser.py,sha256=obsal990EKsqbLRlQA-NheSklEl17fkOqk-43mej1DU,3568
-skdecide/hub/domain/rock_paper_scissors/__init__.py,sha256=ELZaN64MgZR0c3o6OHPMvMk9A7c2hJi2DQCanLKahWU,224
-skdecide/hub/domain/rock_paper_scissors/rock_paper_scissors.py,sha256=B1ymOPEm7rcXJ2-032Ho7Q6KZKSzq3etaZl1GDnA0_M,3343
-skdecide/hub/domain/simple_grid_world/__init__.py,sha256=p1jRSprDoQe5kZ3dNwj2n1e-jkY6yrTVN0i-MSzxPLA,220
-skdecide/hub/domain/simple_grid_world/simple_grid_world.py,sha256=cp8extpaGai2UdCV4cyMkQRQzWBjahF_4orVr1Fjnlk,2981
-skdecide/hub/domain/up/__init__.py,sha256=rbaRs_vcLHaIdYa12QQcYPtT6rJRaWPaDzMwN5v7H0k,221
-skdecide/hub/domain/up/up.py,sha256=wqHJ21pyiLL-V60rScc4UXzW2EWHwz8eyB3QAPAm_5A,22912
-skdecide/hub/solver/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/hub/solver/aostar/__init__.py,sha256=UaYYXDWa5RKr_hc_EF333-rdk0iFlWk37-ajv6nCttQ,200
-skdecide/hub/solver/aostar/aostar.py,sha256=PSlSV6kvrukltC24ssNPeH6Rd2tGdYXwmFbTB8HbVr0,4608
-skdecide/hub/solver/ars/__init__.py,sha256=ood2D240GLMOxZezaphP4YebMK_ivDNZr8QDKJc0xnU,212
-skdecide/hub/solver/ars/ars.py,sha256=CZ7c4Ohq90JF4ViSXg6gZzsPQUPph-cRhis5mqFkoLg,7903
-skdecide/hub/solver/astar/__init__.py,sha256=YnbZvS6STkSFgqZMQR4UH1q6yitGgHkfWze1ay1l7Io,198
-skdecide/hub/solver/astar/astar.py,sha256=uvyOm1iHTOLnygkUMVh69MBoGhTga7A_RiHhZUoe3Pc,4196
-skdecide/hub/solver/bfws/__init__.py,sha256=v178I2fq3c_TeKHBHGfGbi22H91TUSqzquUvBDHez_E,196
-skdecide/hub/solver/bfws/bfws.py,sha256=N5zu0SP-ruzVLz7mNLhJO0xYnZ7QRDbKbIf66oaXqFQ,4894
-skdecide/hub/solver/cgp/__init__.py,sha256=4c_S0inmcyOsxVc7lMepb9uAptzllL5zApyQFohZTBs,208
-skdecide/hub/solver/cgp/cgp.py,sha256=MTk_z9HIGJ4Jk75LLZVHnS_7nkZC1UFt6KFmQeTWvD8,13040
-skdecide/hub/solver/cgp/pycgp/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/hub/solver/cgp/pycgp/cgp.py,sha256=44Dq8_PLM-4-xFtarcp7SwUgVwmkd0iuzvP6qonc5Wg,13284
-skdecide/hub/solver/cgp/pycgp/cgpes.py,sha256=0rRa97BHNd9bWasPGas6sfKGvqiRlfKR3b5NmNYYfN4,4635
-skdecide/hub/solver/cgp/pycgp/cgpfunctions.py,sha256=PiVMxUs0O7pvQqa_DzUopWgbEOfdHt0n64eAkKsXyKg,1497
-skdecide/hub/solver/cgp/pycgp/evaluator.py,sha256=lY0Jj8AMr4FaWqsCjEUYrcycxoXv27qoQnvzVPWGn2E,413
-skdecide/hub/solver/do_solver/__init__.py,sha256=55I8BjtSp3FWENOjqBMlsVEJPXAEz3Lstm_ltY1a_Ig,216
-skdecide/hub/solver/do_solver/do_solver_scheduling.py,sha256=0_Gf4iS7t4GYZX2gJdTd_oZLSasWi0nrfKmS5fqGGas,8292
-skdecide/hub/solver/do_solver/sk_to_do_binding.py,sha256=Shwx4e00yR4RSNsi9Sr1uxPeXmcW_ygyyz_Q-icIB3o,18087
-skdecide/hub/solver/gphh/__init__.py,sha256=4Yu4ypE4DevpVt8RiBMjO-J2HbZSPOYhlulbu_DcWAY,390
-skdecide/hub/solver/gphh/gphh.py,sha256=zVCmGE-wT0EJeXGGOhpP3LslBu86p3wuV9b_KZOrWbo,48433
-skdecide/hub/solver/graph_explorer/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/hub/solver/graph_explorer/DFS_Uncertain_Exploration.py,sha256=ubJg8yHRTl9Sn7ZPH_r9SCZGDQMWwXz3P9X10EChgC0,3931
-skdecide/hub/solver/graph_explorer/DFSExploration.py,sha256=-8080lo-m_U0FJyjzj5UEuBM2-5riULRLxvm6pzi2kI,3363
-skdecide/hub/solver/graph_explorer/FullSpaceExploration.py,sha256=QRdX-JPHAq2_OI3o8J5NDD63aP-i1kuB8Qsi_VV7Lto,3476
-skdecide/hub/solver/graph_explorer/GraphDomain.py,sha256=cchp9VhhWukgsT1nSbHE3CWlyDrxYbwvWqDVmtyoLwY,7880
-skdecide/hub/solver/graph_explorer/GraphExploration.py,sha256=8O05SbIlG5Z-WR7NR53XDxTJqU0FyOdiWJfyyd0bO24,567
-skdecide/hub/solver/ilaostar/__init__.py,sha256=BaGPvCPMrg9gqe3MbX28_PAauvnxjORv_1j2WRWEfrg,204
-skdecide/hub/solver/ilaostar/ilaostar.py,sha256=wYrOz1lKUM_38N3aDnT7zqXPF_TjIrHF4z6RNSRpvWk,4900
-skdecide/hub/solver/iw/__init__.py,sha256=Gpnd0dpBFUi9RNAHiAg0jan1W9amWjRvu3T5cLKCuQg,192
-skdecide/hub/solver/iw/iw.py,sha256=l8mLflnjNEChcoam2vAoatZQzVxEyfqfIpBXX0miKwM,5085
-skdecide/hub/solver/lazy_astar/__init__.py,sha256=K_UZFrQZ4jT6UmQz_-mXIynav0bUC1phQt58if1Xyyc,207
-skdecide/hub/solver/lazy_astar/lazy_astar.py,sha256=lHYjqMFnExkRCHE5aKdfMrIQbWMg1oomoJACJ4A1s8E,7301
-skdecide/hub/solver/lrtastar/__init__.py,sha256=8GQFzAMroz1fbueHPsXRuWIRqEbWXirCjbhTytM4tpA,204
-skdecide/hub/solver/lrtastar/lrtastar.py,sha256=JK7ZS3wyoPrPS29xn9rJDJIP-_7NDKyDk31wEbi-JwI,6062
-skdecide/hub/solver/lrtdp/__init__.py,sha256=O3Yos4QndnSHLz75BbAFhZ6Y9UJTYmJSpeuh71oaTmg,198
-skdecide/hub/solver/lrtdp/lrtdp.py,sha256=ZUuXvK2scuwEXX8PtcMT0s6HRDdJP3OqoEUfZ97A54M,6848
-skdecide/hub/solver/mahd/__init__.py,sha256=rXvO1USRlMBYOcrV8Mur2zvDmloocrd1mcoBPwYwwQQ,196
-skdecide/hub/solver/mahd/mahd.py,sha256=0r0AEsYm5YpaTf83n0SEydFDl2ahKnLTVzF9lza2zcQ,7909
-skdecide/hub/solver/martdp/__init__.py,sha256=aHxAgbHMMYurKqh2Wvrb9ORHp2Hykp4RelCcT40BJJ4,200
-skdecide/hub/solver/martdp/martdp.py,sha256=3E4fSJzcgeSx-LUm-_cY32rXVb0V_UpN-xqkOWu5RA8,7645
-skdecide/hub/solver/maxent_irl/__init__.py,sha256=MkQAoF9U5Wgj5D_wlxzt_ZhOuix2LtUbLPDfqDSSbjg,207
-skdecide/hub/solver/maxent_irl/maxent_irl.py,sha256=rAXA0M0ttDY-CVD2mYrCcvQdRLNXAqSbQHxFnPrLAK4,9855
-skdecide/hub/solver/mcts/__init__.py,sha256=LXwa2k76qpraqix1qI8xyHse4hRsrM83L-AcPvfPe0Y,214
-skdecide/hub/solver/mcts/mcts.py,sha256=_Y1Q4UO82GhBrS4Q3Nql75VCfHEc0RYh_T-M7fp0i7U,18581
-skdecide/hub/solver/meta_policy/__init__.py,sha256=mxUl5d5tDS8o3_riL3sn9mM0FBTPqRE8IpKG2kLY8Xc,211
-skdecide/hub/solver/meta_policy/meta_policies.py,sha256=0heq1zEwc5PAUSNMQGPMo6btwkUT6PJZDm5wK6n_SJs,2729
-skdecide/hub/solver/pile_policy/__init__.py,sha256=t4Udy14rnDMfWMNGZEfw1UdXbff3R5V3V1Xz1Ueikrk,223
-skdecide/hub/solver/pile_policy/pile_policy.py,sha256=QdUwsA7fl1sxyfaHDeMBDOBBUqivy9-ulA3N3EBRchI,5114
-skdecide/hub/solver/policy_evaluators/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/hub/solver/policy_evaluators/policy_evaluator.py,sha256=GswU-hO_nWoay0jD_qR1kmYKKfuSiPC6Hv1ngdyp1Ek,6796
-skdecide/hub/solver/pomcp/__init__.py,sha256=vYguGEAI_7Bmo_OHgBLkSv2RrNwltH-dRB0aQJdigLY,198
-skdecide/hub/solver/pomcp/pomcp.py,sha256=BurnGTVaaHGyn_RSTJUijs5Qse_5BO4ojVIFYAikfnQ,10208
-skdecide/hub/solver/ray_rllib/__init__.py,sha256=74tlRz6v3tddKexZvBRxIiebzMKZTBQmrgFagQwx-rs,205
-skdecide/hub/solver/ray_rllib/custom_models.py,sha256=HUIEVh8YOfb4qpyxlqI_hp0f3I5rH9nzaM82Q8rBFx0,6412
-skdecide/hub/solver/ray_rllib/ray_rllib.py,sha256=n4CvB0usNErfoDwX_837-5WQcBtt6lgeTFw-YOnbONQ,20567
-skdecide/hub/solver/riw/__init__.py,sha256=3VezmKB4tnSxIxOlLBifg7M4rNtTUCXK0yC9CyFasMI,194
-skdecide/hub/solver/riw/riw.py,sha256=mISSI5VOEVZpna3Y_zekwOXK2Fwn1of3rKcjk4Y0Au8,7255
-skdecide/hub/solver/sgs_policies/__init__.py,sha256=nD7y3dF6k6fWgVQXHlftu4P0sUik7PVuiosF8YlSOco,249
-skdecide/hub/solver/sgs_policies/sgs_policies.py,sha256=9Muyk_SuV83UWB_ajEs9-dDwKP_6njW2E6verSIFx3k,18069
-skdecide/hub/solver/simple_greedy/__init__.py,sha256=ZlePF1mbho7pH4vlemeYpUjdNuk0g7YCnDOdWQEtKOg,213
-skdecide/hub/solver/simple_greedy/simple_greedy.py,sha256=jQFzgZocY4GdEYifHlabobBFAEfRYwoxb0esxDTwfSk,2382
-skdecide/hub/solver/stable_baselines/__init__.py,sha256=hZmdUoss-4nMMDmNZstOt_IqN-1rdfGQNgTVegTab-c,218
-skdecide/hub/solver/stable_baselines/stable_baselines.py,sha256=l1dRyxCkpZE8L28uql7IzsjIrkp3oKtwCAxzslzrq-Q,3558
-skdecide/hub/solver/up/__init__.py,sha256=nrsxo2u71FAb12P1GP7OmJAg797ljOuZ9_pHceLhW2I,198
-skdecide/hub/solver/up/up.py,sha256=17Yb8ReNdeEFPqJn970rsEFF9SpIijyYWfy6EOXEAJI,3670
-skdecide/hub/space/__init__.py,sha256=WcESdNTheFc84BScxVjfik8UIv4VI_8PaBKaD49ZQak,170
-skdecide/hub/space/gym/__init__.py,sha256=KgKNRtwFS3GURfMhDsk4iYCscMMr6xN-z0-RJGHxw70,389
-skdecide/hub/space/gym/gym.py,sha256=NN7sBCJrNcjl6_PgOQeAfvjWnLygqTPuZho7S-2ZhAk,17837
-skdecide/parallel_domains.py,sha256=GOPyeuI6E5naWWL5vYewrb2ICsvGz02bBTjfL9arQX8,25047
-skdecide/solvers.py,sha256=sfVTLPUIB2iOW370TMHgBV_mxSYAvtNx85OtAxk8yLc,11087
-skdecide/utils.py,sha256=yY_ZueT2rCotwq9SdfI2PpUkCJAt7UZCjZp4IArWnZs,16419
-skdecide/hub/__skdecide_hub_cpp.cp39-win_amd64.pyd,sha256=pdMYGA1DAI7unS_0y9lmgtAOLba8bns_iFIC3G1ZvOs,10720768
-skdecide/hub/include/nng/compat/nanomsg/bus.h,sha256=gpy8t8hb4eK-SycoJCGVpGNo5a8hAQ4G6qKj3q4Ww1k,975
-skdecide/hub/include/nng/compat/nanomsg/inproc.h,sha256=-O-S9BGDznTfjr0HWuE7bsFULS7Vzmd1bTrpsXb6Pw0,955
-skdecide/hub/include/nng/compat/nanomsg/ipc.h,sha256=8M1xEsO-eXFfCZzF43Zm0mauZZftI5kbMGHsqMZXVaE,1296
-skdecide/hub/include/nng/compat/nanomsg/nn.h,sha256=e_RwfqUkIF9d58YNewrvjju5cQ21xGGXsKBB8L904a0,8179
-skdecide/hub/include/nng/compat/nanomsg/pair.h,sha256=ZueoAUhihSh_T3LDonOKgxKhyGzqAAK3lfQHEX4jVSY,1286
-skdecide/hub/include/nng/compat/nanomsg/pipeline.h,sha256=cJQvIrFzq4fdLkn9qFrgy3GZ4Jns5gAH-WurwDy74m4,1068
-skdecide/hub/include/nng/compat/nanomsg/pubsub.h,sha256=dVLWfQ3_JlskyGFS9uJ6Ny0OmZ8KAvlyGUVbOscqI14,1141
-skdecide/hub/include/nng/compat/nanomsg/reqrep.h,sha256=tFyMWILaAPjn8wOY6wPbw9XVoinNAoBhUfedQKdool0,1096
-skdecide/hub/include/nng/compat/nanomsg/survey.h,sha256=iQY3eePMHRk2q9Yx7S0YRxhDwfRWRH_7xmZ0Hf_3Ieo,1142
-skdecide/hub/include/nng/compat/nanomsg/tcp.h,sha256=2WI5mBNSIbs93sbCjN4ETcUETqma243Qm0VpLQhm5s4,951
-skdecide/hub/include/nng/compat/nanomsg/ws.h,sha256=p4xI_9wHfAK9aClsqNzMrSqQ7c2RgqpHfp2DhV2_U7g,1313
-skdecide/hub/include/nng/nng.h,sha256=F20pA97V_EFcB7T3OrlMYZ57Il4bl8kNr1fFvT6WOaI,65650
-skdecide/hub/include/nng/protocol/bus0/bus.h,sha256=T7pc87hERqK_e5Jmz1Ixy0julf9T6yAwGzE5Bhrxe9M,947
-skdecide/hub/include/nng/protocol/pair0/pair.h,sha256=WaMhXW9i97bJNv_nglQp0XGAnTHM6dF_Vqn0FaTOh1A,835
-skdecide/hub/include/nng/protocol/pair1/pair.h,sha256=mu_5jTxt590RPm1WfY00gOW8Xc4BLlpuNFJ0mvgPRNk,1064
-skdecide/hub/include/nng/protocol/pipeline0/pull.h,sha256=5ZL6L14Nl2nRG0lkhLJ4Dvi7jDjF4LHabm-ubwwOwAM,845
-skdecide/hub/include/nng/protocol/pipeline0/push.h,sha256=iYK3OkjovkFyKYr3Yhd8TBDegVb23ZgPRp3q2KG1-88,845
-skdecide/hub/include/nng/protocol/pubsub0/pub.h,sha256=2tT3nElP7ioTCj2nnsAsyfqS2yXBHv89WMuHLiIMW_U,828
-skdecide/hub/include/nng/protocol/pubsub0/sub.h,sha256=xJzN0iUhMACcPogw2P-Rhn_jT2D1hk5Sst0xXCcmJSA,975
-skdecide/hub/include/nng/protocol/reqrep0/rep.h,sha256=3W6FTmbDkUvhx3DY5gLI8GrN0blK5_lgIRz9kWdonmM,954
-skdecide/hub/include/nng/protocol/reqrep0/req.h,sha256=OcYjrkE05Kl557-W-s_VCduKREpx0ui63jmIS0lZ7Kw,1004
-skdecide/hub/include/nng/protocol/survey0/respond.h,sha256=H3s0PtoPgfJtoN5G2y05vzlxqmX_LtEVbfhCzZx7fYQ,1062
-skdecide/hub/include/nng/protocol/survey0/survey.h,sha256=5O6DEtFeDJr9ZjW3ujKIYnVXvGQItiM5ov-lg9I2Owo,1097
-skdecide/hub/include/nng/supplemental/http/http.h,sha256=9iMVOxdPMFL0kGpArMq8-_5cx7KqtAob0L2mva6hKHs,26428
-skdecide/hub/include/nng/supplemental/tls/engine.h,sha256=hMOdWf0aW9v_kF0XeKv0vH_NIumSopnEGQNhLGz_Ang,9902
-skdecide/hub/include/nng/supplemental/tls/tls.h,sha256=8qZM-KZWDPoRSqDjRJQfw45w6Btkn08zBEx2x21RxGk,6322
-skdecide/hub/include/nng/supplemental/util/options.h,sha256=so1WjllkLzlVN9YVsqERLD7GfwOMES1d9XfHGslCCD8,1818
-skdecide/hub/include/nng/supplemental/util/platform.h,sha256=PhrGgcPydyRPYYZ0x6NzFaBqeiKk5glTtuINmYfUBc0,4285
-skdecide/hub/include/nng/transport/inproc/inproc.h,sha256=UJLM49aXwoaqQ2cMX8YMK8N5Qr6CoqLFmfjxP3B-gB4,771
-skdecide/hub/include/nng/transport/ipc/ipc.h,sha256=STZMitIggzVWmAEq7ozvpxX-vZVx7EjmnKq9H_A4bAM,779
-skdecide/hub/include/nng/transport/tcp/tcp.h,sha256=ysurJzgXw9hF5UJgGBSWG8RgPgW20yhoy9M1maIw1LU,747
-skdecide/hub/include/nng/transport/tls/tls.h,sha256=E2G6_vZY0kmovwNeJCPqruDFijVpJ-gwtWOYQ_NnsNM,760
-skdecide/hub/include/nng/transport/ws/websocket.h,sha256=2KOyISVpOo1ZxyL5XM2LsX2-KODm9jWSsqyNOsNKGLw,989
-skdecide/hub/include/nng/transport/zerotier/zerotier.h,sha256=B7_GnrLwBcH1ZI69n5tsbO76as6yWk8mMLDynuphqTQ,7462
-skdecide/hub/lib/cmake/nng/nng-config-version.cmake,sha256=kW0YEArKlrHns39tYNpwaSl1vNCuD80xRFXTDHdoyZE,2827
-skdecide/hub/lib/cmake/nng/nng-config.cmake,sha256=fY0VecGGHCA3FMj6cQiERSCZgL0UA0PqePhtB5VMqG4,1635
-skdecide/hub/lib/cmake/nng/nng-targets-release.cmake,sha256=Z97U960Uj9ZNdVApri1KwHTP-toiit3lEddviv7a0pY,822
-skdecide/hub/lib/cmake/nng/nng-targets.cmake,sha256=XFsa40B-1FsATC0vi2CyxmZQiXypvEpEgK7WkU6AQJ0,4257
-skdecide/hub/lib/nng.lib,sha256=-5_7IUGeQDtN_P-ebwiMgFt1wul8KJTkKbWljOw4Wc0,1637286
-scikit_decide-0.9.8.dist-info/entry_points.txt,sha256=Qlm8rFH_tTMB9uFvhi-uBsrWYDUjmoZnXPsULr0Cs7s,2552
-scikit_decide-0.9.8.dist-info/LICENSE,sha256=VlhkRbo8Dvt3iasWcJexCYTwV-qi23svC9rXmWkyV0o,1106
-scikit_decide-0.9.8.dist-info/METADATA,sha256=O_mY6SpN47EjRbLjbUszbM-anSp8PRjpZLJvDRWRiwc,5490
-scikit_decide-0.9.8.dist-info/WHEEL,sha256=T7hzPzFWHJiWCVylm2UCj5payilA7ulisMC0IiBEe3o,96
-scikit_decide-0.9.8.dist-info/RECORD,,
+README.md,sha256=VyzsaHtwJIsEEFVwW34l_HfK9nvBKcXeBoW6uKYru30,2216
+LICENSE,sha256=RjKIgXK0GE1ZKoj3LOeYY9aGXixxbSr77VSCzRgHNyc,1085
+scikit_decide-1.0.0.dist-info/WHEEL,sha256=7uIoyXgzBj-ZrdtoFsgpYMn6gnyMv0KOrzstC7oW_qQ,149
+scikit_decide-1.0.0.dist-info/LICENSE,sha256=RjKIgXK0GE1ZKoj3LOeYY9aGXixxbSr77VSCzRgHNyc,1085
+scikit_decide-1.0.0.dist-info/entry_points.txt,sha256=8Lr3WfsKk1DrccFFX9BPfxeqRey9b2ogFt0zPI4tJdQ,2552
+scikit_decide-1.0.0.dist-info/RECORD,,
+scikit_decide-1.0.0.dist-info/METADATA,sha256=R32vCwAtQQUWQTJjxSCflIvM5P0LSMMpCp-GHBeKvXU,5451
+skdecide/__init__.py,sha256=V6-tz-ZBakx7FnzHi2V-kIjh4HacaTPmf2gLzAYf2dU,335
+skdecide/parallel_domains.py,sha256=b_XbHbluuaconscamC6gnLpbKLOsX8kQAKFvgsEJDTU,24640
+skdecide/solvers.py,sha256=5nDSfxllUNIEHLX48YLFa1AwgalNre27Prs-xDKi97c,7808
+skdecide/utils.py,sha256=4Ph3PozESL-G-VWwT3LW-0q5CxILdMQKx8pqpUIDl5o,11776
+skdecide/core.py,sha256=IcKsjprFhTth6pB0itdiadGy8DyrhMn96FlkGHa0t8Q,27026
+skdecide/domains.py,sha256=crCxvsG_9KukaFAqlIsM4m7nN5Z9TLxM42nenWd2UEQ,10412
+skdecide/hub/__init__.py,sha256=aGvlg4HXXM3-ZMna8aRs8JUG5wHqSunRRb3QBtLh4Wg,167
+skdecide/hub/__skdecide_hub_cpp.cpython-311-x86_64-linux-gnu.so,sha256=2XffPPndhYeLx5DbcIpu2YbkgUIKu7xiVAYKSoRNJcU,15818569
+skdecide/hub/space/__init__.py,sha256=aGvlg4HXXM3-ZMna8aRs8JUG5wHqSunRRb3QBtLh4Wg,167
+skdecide/hub/space/gym/__init__.py,sha256=AEQbUeevTkXiOFWSmToeDgy6lpMduzEmJQODksDgHlk,372
+skdecide/hub/space/gym/gym.py,sha256=nXJfP-3e8KxozD6WVfqgfHie59YuOCOPucmRCcAV4c8,17326
+skdecide/hub/solver/__init__.py,sha256=aGvlg4HXXM3-ZMna8aRs8JUG5wHqSunRRb3QBtLh4Wg,167
+skdecide/hub/solver/meta_policy_scheduling/__init__.py,sha256=jXiIchBTa_1_18PpWCVi0E2KfuWHqlwHa7ZQ1adw5b8,206
+skdecide/hub/solver/meta_policy_scheduling/meta_policies.py,sha256=uwXRdHoXTpnGVJYrLqndnrF7LV1PqlXUJRQaZeTlsYw,3128
+skdecide/hub/solver/meta_policy_scheduling/policy_evaluator.py,sha256=kwPxn61ziwGDTyIBVhYVSIwFST0M_Jk0GARn0i30iPA,6032
+skdecide/hub/solver/martdp/__init__.py,sha256=Z90dn5j06HoHEAX8kHfufozQVlIksxDqsw5UqDtJvV8,195
+skdecide/hub/solver/martdp/martdp.py,sha256=whuCGsUB67rTgh2IKcEoVX6e7SRYHFEdDufqEa7EkmE,16289
+skdecide/hub/solver/bfws/__init__.py,sha256=gaPt-PBFiDHVkonx7OW8CEJ2gdifp1Vg9FuSxalA5Dk,191
+skdecide/hub/solver/bfws/bfws.py,sha256=_AlL5PopRzwDanltfznXP9lxQ_KF7DEGSXZv_9OZ0bo,12300
+skdecide/hub/solver/iw/__init__.py,sha256=f5enG05zP-omlkHHSdKXi6DofbGra7Lb36o6nCfgmVI,187
+skdecide/hub/solver/iw/iw.py,sha256=aCyUJ7UdijZ2TXHJY2rk_8tlSLIOl6pYixhyGdCuiVw,12324
+skdecide/hub/solver/simple_greedy/__init__.py,sha256=tpuPQOGnCLQ7VAuMup8SpmD5KjhfEWiIK6u8rMf-NbU,208
+skdecide/hub/solver/simple_greedy/simple_greedy.py,sha256=SfvcjxKnKa6uHcDfqQqaEE6ZsAFjmQLhpts6XIC4fL0,2288
+skdecide/hub/solver/ray_rllib/ray_rllib.py,sha256=dUKCHe6WMcX3ZKSWuSktazehhU-CxP2mNzAx6e3-HKs,26361
+skdecide/hub/solver/ray_rllib/__init__.py,sha256=J8hKrzZSmrwbQlFl_PQbrA34wurPQntefcCWP4dURX0,200
+skdecide/hub/solver/ray_rllib/custom_models.py,sha256=ZUf6gdPOsD8ADPkqltDvv-Mkgw7oMlZfrRz9jM8rtYQ,6266
+skdecide/hub/solver/stable_baselines/__init__.py,sha256=grlDaqRfF8AdFiPRufF90awlCf4Jxa7CQpbWa7z0KsE,213
+skdecide/hub/solver/stable_baselines/stable_baselines.py,sha256=VRUCnhZEH_yvLVdQ0BbX7hrDnK2ZPWy0KLoLGTk9_xk,5442
+skdecide/hub/solver/mahd/__init__.py,sha256=CtS6Big1QTKg_8Rry5g5fgio4HT3dNjzYQ6nGJrz0gQ,191
+skdecide/hub/solver/mahd/mahd.py,sha256=TLhhYxBxjT33e930RvJl_n3xDcWTj3cM-ywu7X3leDY,14449
+skdecide/hub/solver/pomcp/__init__.py,sha256=uKq4Jp9WQVHrPyiKUna7A5NPlxDhGmwHOHudTzJyuTw,193
+skdecide/hub/solver/pomcp/pomcp.py,sha256=XpK094aBLkEcSTmx6SpgqLeDucWw_rXEHbnYuVlhSCg,10564
+skdecide/hub/solver/lazy_astar/__init__.py,sha256=8T0YwRM7Yj37RdLa_OMM0-PaxlnQhljwo5g2Ef7giXE,202
+skdecide/hub/solver/lazy_astar/lazy_astar.py,sha256=_kjQqG5dIyUVLGaHzdBEMCIadMhUWv1dEVVTKZzE0ZQ,8329
+skdecide/hub/solver/aostar/__init__.py,sha256=P2K5u1Il3Rd3tjBJoUey0scQJVkhMhUvWYufpmirqkE,195
+skdecide/hub/solver/aostar/aostar.py,sha256=OgENG9XmItuJat7H2EWubZIf2Pmzmn2nyXJsxXLHxPw,11616
+skdecide/hub/solver/lrtdp/__init__.py,sha256=O3Yos4QndnSHLz75BbAFhZ6Y9UJTYmJSpeuh71oaTmg,198
+skdecide/hub/solver/lrtdp/lrtdp.py,sha256=mu3x9FbQP892WfqIKcFx0rZa09lOq0FLlFXXLskWhoI,15227
+skdecide/hub/solver/do_solver/__init__.py,sha256=ALcwxGyjemQonJDccc-0ryZXfSfgYGHGEI8tF2Avh_0,494
+skdecide/hub/solver/do_solver/do_solver_scheduling.py,sha256=ojbSbzcDKPvb1Ic3OcZvoTwOpDb9VCQ9it6Ml-C3Vv8,10973
+skdecide/hub/solver/do_solver/sk_to_do_binding.py,sha256=FzS7aVWZxDyhnEZTuOoBp1ErM6PG5_nUYLdFnG8U6Zg,18192
+skdecide/hub/solver/do_solver/sgs_policies.py,sha256=8diBqoU-z9fue6Tm8qyZUSc3UVVkv0FYv0pXp6kVXcA,20879
+skdecide/hub/solver/do_solver/gphh.py,sha256=dxHg5iHuj5JQu8Ikbmp6VVRS1TkLuLLIZCt2DNR_bQ4,43650
+skdecide/hub/solver/lrtastar/__init__.py,sha256=Q7b8snp9VbXxHkuKp5_nDa-vN2KKVVnCBeb2rW_E3Yg,199
+skdecide/hub/solver/lrtastar/lrtastar.py,sha256=E5mqVz4tuYuf7J9rm0Wv2FWazK0cReNKsLxQV5_P3TI,6882
+skdecide/hub/solver/pile_policy_scheduling/__init__.py,sha256=uDM0B0pt-VlrysIjxrM3XhnALiOalGG7SAJ-CCOIIVA,218
+skdecide/hub/solver/pile_policy_scheduling/pile_policy.py,sha256=hf705SaiJYkEdAIDK490Tw2NA7tTexe2iAcUEpHbfqM,6217
+skdecide/hub/solver/riw/__init__.py,sha256=UJYMnMZR6-3CejiBIpM-ochjsBGXO1IYGUiTNqz3BNc,189
+skdecide/hub/solver/riw/riw.py,sha256=k3ZaIDDigydehtU8CUZ_BN9n6wVmR5uUNkpptfrujEo,17605
+skdecide/hub/solver/cgp/__init__.py,sha256=b_ff1H-VaZXA5-6TN53rZ-EpJWINaw1B8z9IWZlj-ok,203
+skdecide/hub/solver/cgp/cgp.py,sha256=8I8EjpbyirmF0-RellnGlgiQpjypE_bCujo2b6PgXY4,13319
+skdecide/hub/solver/cgp/pycgp/evaluator.py,sha256=7pHy7rAbTPIImjwBjTY3SVrWxhzdgCHv8eUGw8-tvyE,400
+skdecide/hub/solver/cgp/pycgp/__init__.py,sha256=aGvlg4HXXM3-ZMna8aRs8JUG5wHqSunRRb3QBtLh4Wg,167
+skdecide/hub/solver/cgp/pycgp/cgpes.py,sha256=IyD3-LhjLqW_ctJ_fZ2bRTBRAu5U33XPWYkyNYdQDH4,4986
+skdecide/hub/solver/cgp/pycgp/cgpfunctions.py,sha256=5WhycmT-5NpIXPQzDfx-jgNjDStkhaDZpb31WMNcIFg,1403
+skdecide/hub/solver/cgp/pycgp/cgp.py,sha256=6UJFvEDrSa4SyRmXr5jZHGAydnCoXRqtLVVfHYHVxgA,12934
+skdecide/hub/solver/ars/__init__.py,sha256=WhsjGPOg-bjuEUvNWDVuolUoycoAGIravhI_o_xiCaM,207
+skdecide/hub/solver/ars/ars.py,sha256=gJBbzDledN7WUJN73rB76OCeTu3SARF6jD2Od72kB_A,8620
+skdecide/hub/solver/up/__init__.py,sha256=GdaQD0YopJUquXPtGeUY1KgjjE4ojjHsSyb-BSO_8b8,193
+skdecide/hub/solver/up/up.py,sha256=xcH133VBPrd5-YqU4owcKp4Kp6NZvG5moSP1R_ogXFk,3930
+skdecide/hub/solver/astar/astar.py,sha256=j9FQ8LGRWUk-ooKmENF-pnapdS5VLo9PFzIR4g4gd5k,12116
+skdecide/hub/solver/astar/__init__.py,sha256=UYCIT7jNBzCEMRqcHHVKzzqzFcNwOJZSW9WIkVFdCbM,193
+skdecide/hub/solver/mcts/__init__.py,sha256=KYm-L6PkOI-rvemXAAimwakzgS6WnjBbj_gi5any3S0,209
+skdecide/hub/solver/mcts/mcts.py,sha256=iWofavR9F27b7lBvkzMXnPlkDMUFoGTzotrXNfaJNiY,52414
+skdecide/hub/solver/ilaostar/__init__.py,sha256=UfQDWrmTIvUCpM2Tner2ND3d_O3oUNuCfepGrro2fqM,199
+skdecide/hub/solver/ilaostar/ilaostar.py,sha256=FPxa3HLxtgzaLyCDl-qFsMpkz5DYHKQlhcfEBpgRvpQ,10665
+skdecide/hub/solver/maxent_irl/__init__.py,sha256=nLn2f0aEOqaEZL4atjnmpYVDGp5vocCXxa_l2mpWhA8,202
+skdecide/hub/solver/maxent_irl/maxent_irl.py,sha256=Iq-27kj1vWT2F8VAhEsiz_MFlIKcpZ4xrWIBnrjD6Ns,10417
+skdecide/hub/include/backward.hpp,sha256=QEqibsw2vgj5LAOwVQVWHgZPbx98_8vad6fUlZ5MB_I,141149
+skdecide/hub/include/nng/nng.h,sha256=AT5XjB_btbiw-ccBXgp8yaYmejzvwQkeuTJo6JUB_dw,64317
+skdecide/hub/include/nng/transport/inproc/inproc.h,sha256=IDy0fs1GS8VAqckYg03xI7DXhL8WHfN6vPg7LF7OsZY,742
+skdecide/hub/include/nng/transport/zerotier/zerotier.h,sha256=bJx-zFILkZFiBPLdhZqQIWwA7gEYOKsJzRBRcVmEnuk,7301
+skdecide/hub/include/nng/transport/ws/websocket.h,sha256=5v5hisLQpDwoX6MFH12nLSYRwlkB85ICRtcRClReBec,954
+skdecide/hub/include/nng/transport/ipc/ipc.h,sha256=9CR8f8rMSXngLqCGDEWZzigtwOZVD7-Z9mz0gsq-PH0,748
+skdecide/hub/include/nng/transport/tcp/tcp.h,sha256=MIfXMrFFujLzEZIODArmddYt4ZPJZRL4xa8-TM05frM,717
+skdecide/hub/include/nng/transport/tls/tls.h,sha256=DjqzJeMrebVQ1nZgzK7MNdUrLPTyGWyMz65ED5VVAL4,730
+skdecide/hub/include/nng/supplemental/util/options.h,sha256=zjeCJZxZpov6lR16j_kwRKRdURXZkKWE_9Mo4PhDEQg,1770
+skdecide/hub/include/nng/supplemental/util/platform.h,sha256=0AAj5cy09aLzp_xc2C0L2qt0Nc6iZ2GxFnw4HxJbFAY,4174
+skdecide/hub/include/nng/supplemental/tls/tls.h,sha256=_63yKbzn2LmkNO2J3jLQxg2-H83tISnCNtEVnn-BUqw,6180
+skdecide/hub/include/nng/supplemental/tls/engine.h,sha256=3zgNGnRijt_LnaH_SF9L80tBvF1PmoqBK2E1x0wul8o,9687
+skdecide/hub/include/nng/supplemental/http/http.h,sha256=PSteuG2zZf8F9rZbru6l7oWMF1GfEhkj3MsTywcvAfg,25889
+skdecide/hub/include/nng/compat/nanomsg/nn.h,sha256=aUVb6aV4I3ifzk8EoFRP2qdkKgA34yi4j8Jbyti6cTU,7895
+skdecide/hub/include/nng/compat/nanomsg/survey.h,sha256=BhxXVjBYi4vF_bGHKNyvnL354QmcyXM064TLGzCHrXg,1106
+skdecide/hub/include/nng/compat/nanomsg/ipc.h,sha256=CbMaG16DL94zVhmsZ_JTvxVYn3dWK5iQ63qWVzUKZY0,1257
+skdecide/hub/include/nng/compat/nanomsg/bus.h,sha256=Wgkc3HjDKwCG8kqVirEbDUoBfEYpIgBT774epY0H1po,942
+skdecide/hub/include/nng/compat/nanomsg/pipeline.h,sha256=mfJ4MTQOxOeprengZyzho9QXQkKfV345FuTGyp0ACzk,1034
+skdecide/hub/include/nng/compat/nanomsg/pair.h,sha256=YRENvZrKwMxCEPnYdjfDAnFUTVo7GTJrTMI5kOMYVhw,1247
+skdecide/hub/include/nng/compat/nanomsg/ws.h,sha256=e4v5ZRJWfPZPkfQzP9xJ4Uw9bH0EF8uyskcxnHEr-sM,1272
+skdecide/hub/include/nng/compat/nanomsg/inproc.h,sha256=0dBC-hJK6zeHXHIgMifDyPxGmzuJx-CmTd7QZ-M4H-g,924
+skdecide/hub/include/nng/compat/nanomsg/reqrep.h,sha256=yk24kWeKJlbbYt79GMWOfa1QhSjzZbn5yZctDLfmnms,1061
+skdecide/hub/include/nng/compat/nanomsg/tcp.h,sha256=oC2QypHq5niPS6266AFYLmWgC2JFmc_gxesttk_JJ-o,918
+skdecide/hub/include/nng/compat/nanomsg/pubsub.h,sha256=wL9hM04CJo0aELof79GgQVY05R3bL2-p0YyhtIVK35M,1105
+skdecide/hub/include/nng/protocol/bus0/bus.h,sha256=PhbCwYd06Bb96Wpx288DrR8n6ZNx4G9bvoARf2ImTWs,908
+skdecide/hub/include/nng/protocol/pair1/pair.h,sha256=qRw-9qDO7lxp2LLvlYUKVDlXX9Adnu4KGjBznmEMJYk,1024
+skdecide/hub/include/nng/protocol/pubsub0/pub.h,sha256=idD8ixaqjgR8KoHZSJ7NjQgQWAe4dAt4-vf2yMgY1ek,795
+skdecide/hub/include/nng/protocol/pubsub0/sub.h,sha256=MZoZgPuDj3a8kf3FEzlIBRxsOyXdhmd1siqMdUCFEOc,936
+skdecide/hub/include/nng/protocol/pair0/pair.h,sha256=88AkRGB0vSASxk93LCufimIf9kMeabSzM32M-M5usXM,801
+skdecide/hub/include/nng/protocol/survey0/survey.h,sha256=TlaO215sEmalxR1EFMX6-d8KTWNcg282xT2idevDhos,1057
+skdecide/hub/include/nng/protocol/survey0/respond.h,sha256=SSDxTpBwKJOdto9DJ70YhM_X8DP9P4d4OlkFV9HITX8,1024
+skdecide/hub/include/nng/protocol/reqrep0/rep.h,sha256=8iSPK58CQtE0sICLmRHd9q0kmTavz-tm3LdeV4g0Hzo,916
+skdecide/hub/include/nng/protocol/reqrep0/req.h,sha256=KSYVzt0SLZVpSY1rSLfuP7LQbDnjaEfJVZ3w3jeuvuE,965
+skdecide/hub/include/nng/protocol/pipeline0/pull.h,sha256=ttDrNp25ehQHW8Jg59I38RO6Oo2F-8taDsoQ8bpxxZU,812
+skdecide/hub/include/nng/protocol/pipeline0/push.h,sha256=2sZZYamGEhiOSdlAGTzlJikcVEUrSzU68FcMFk9q69Y,812
+skdecide/hub/lib64/libnng.a,sha256=boG7v91y-WmxXbFyrrHNvotKp3B73v90IdI0dLSUmlI,1042954
+skdecide/hub/lib64/backward/BackwardConfig.cmake,sha256=i3_wEM3_7_z_jANciqkxYjGfOMZZXiB6XYANJmDZPD4,9384
+skdecide/hub/lib64/cmake/nng/nng-targets-release.cmake,sha256=m1IOhdjcltnRlROSePf4M_euHm4d2kQAR3ks7-LRe94,809
+skdecide/hub/lib64/cmake/nng/nng-targets.cmake,sha256=TB4RgMSY7GoCwO1I3D4VlU3bnGXEttOJZmUC3OpHfec,4303
+skdecide/hub/lib64/cmake/nng/nng-config-version.cmake,sha256=qy9oYqL8ZoB-zptv2cF03isxTGDmJizPh6qIv1ZvJxU,2762
+skdecide/hub/lib64/cmake/nng/nng-config.cmake,sha256=I8BZhFhCs-8TjGRR7ZDPp4xQzV0Mg6G6xIlo7f-JGAc,1592
+skdecide/hub/domain/__init__.py,sha256=aGvlg4HXXM3-ZMna8aRs8JUG5wHqSunRRb3QBtLh4Wg,167
+skdecide/hub/domain/maze/maze.py,sha256=n3Wub-xoqlRRZ0YqyygA_55H5SfTgY6qkChpFp69loE,5216
+skdecide/hub/domain/maze/__init__.py,sha256=02H58hV5dIioseVyl6dI5Pa5LyFMkypvCQzKHjgeUkc,191
+skdecide/hub/domain/gym/__init__.py,sha256=k5mBwK2XOgEIMI8amWQ5RVYul7u6CRsxy7L8u7VmDgU,466
+skdecide/hub/domain/gym/gym.py,sha256=R7v2Pz3acfVqm5gegvMFrxMSTwpRS0DgiQ2VIe4bnYo,47914
+skdecide/hub/domain/flight_planning/__init__.py,sha256=5NnvUc5bAmNsO2eUNLKYxZnWGHJlMI8Cv6Y5e5JVbF0,249
+skdecide/hub/domain/flight_planning/flightplanning_utils.py,sha256=LaXs4vNXHBo3r4e2I1l3O3EcjbIh94BOXpWJiqpq9w4,12633
+skdecide/hub/domain/flight_planning/domain.py,sha256=Bqe90Zr4TUICasFQpTPayHFfpyWqqIRH5Q1fAEt1mxQ,62254
+skdecide/hub/domain/flight_planning/aircraft_performance/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/flight_planning/aircraft_performance/base.py,sha256=p4iTyyedXEMXEHGCtoRQK3iygYekll1A5L17RtDAn04,2871
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/pollschumann.py,sha256=qDL5uYvYnP2ECSfl_XZBWpvMz30xrh-ajj86rAomI_I,6665
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/engine_loader.py,sha256=ZhQPWTsohBF8RFqZWPRX-JkiDAVsK-rJjRu2uc7vEVo,2905
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/data/aircraft_engine_params.csv,sha256=lZ_gzhOfB-Ul8VUnzyiffYyLTRJ3wab1rlOgh_N-byA,14679
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/utils/aero.py,sha256=WkLv_8wZ4aWLci2S-gPQesNJq6ARuKo1hfyFDL5Xdho,53
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/units.py,sha256=KukCM93GYmk59hsE0OeR7AISUANMYAqmaOq-2ynnN14,2104
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/atmospheric_parameters.py,sha256=Gs-Bi_K0XHNbLnwm5ZDOh4OIoHBgryjCiIFpvC58m9Y,15186
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/aircraft_parameters.py,sha256=khKg9fT3tlR3rFhlaqzHusal4NWaGVQ-CPWCE3TACRc,2997
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/jet.py,sha256=utM0-ZeadRHr59WLEIfzMiTqegNf1efCm8v1ASErS3c,3141
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/operational_limits.py,sha256=BdxV60z0zZ96UEs2fv0Lp881_vkqM_7absHT92EE5PQ,3197
+skdecide/hub/domain/flight_planning/aircraft_performance/poll_schumann_utils/parameters/constants.py,sha256=lT7TRYtLh373OF5gT5d4e3u73DgryBGpO3-Fm3HpSr8,483
+skdecide/hub/domain/flight_planning/weather_interpolator/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/unit_conversion.py,sha256=nFjyASCyW-11e9CtYY6cQmwU1anAN8Jl6FJ53w8VIn4,22331
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/get_weather_noaa.py,sha256=HWJpQwhnKhpDkdaVLKEgX9A7sGXD5xmCFn1UnJ5hJgw,16330
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/parser_pygrib.py,sha256=3xzi6BIS-2eyjGnDQHuo5U0ICLk-P3hrDaMEKYL8boE,22926
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/std_atm.py,sha256=rrvtsxodkrGbgbZYoQ6dBri2Ff47LvwW_Ls9Zv2joQ0,39321
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/common_utils.py,sha256=PNsgu6zgij_cNWX0c8KiS4pV9rIUKZvcuipD5fq1TUA,4407
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/WeatherInterpolator.py,sha256=xRJwhTGxw4auKAbAXCtqCleYDiUOc8CIeOrb1Mb3I8A,22793
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/GenericInterpolator.py,sha256=l-QhQDpszQUrluRY8QFAYMxM2rVwYYjx-tJo7pCbHPw,23000
+skdecide/hub/domain/flight_planning/weather_interpolator/weather_tools/interpolator/intergrid.py,sha256=U0VoEg4vkVwJnDUB1uCf_EtfUpyuQlxAaS1O8zuCkMo,9084
+skdecide/hub/domain/graph_domain/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+skdecide/hub/domain/graph_domain/GraphDomain.py,sha256=qrARFLRTa6Mlraoeq-bohPRzqpP82MKyDQNhPvl7HUA,8350
+skdecide/hub/domain/graph_domain/graph_domain_builders/__init__.py,sha256=TmmMrbVvxVXYDe3r2EiUsQt_7CITWjw9vwRKiGTTz5A,175
+skdecide/hub/domain/graph_domain/graph_domain_builders/DFSExploration.py,sha256=cnKT89lfRinyNHY9hpRuILU25AB4e-EUDCXbz23eRWc,3708
+skdecide/hub/domain/graph_domain/graph_domain_builders/GraphExploration.py,sha256=rTxGhku0bBfsHuXW_zKwpwZlmkQaVnVTLjgXfDRDo4M,631
+skdecide/hub/domain/graph_domain/graph_domain_builders/FullSpaceExploration.py,sha256=OBs2YcYnSXcsGMUZZj0xa3poKTXsonwAahYW4nR-sW0,3804
+skdecide/hub/domain/graph_domain/graph_domain_builders/DFS_Uncertain_Exploration.py,sha256=3aZkZmtx7D9NpGHVit8DFbJaKL801SYAilr5LHH9w7g,4130
+skdecide/hub/domain/mastermind/__init__.py,sha256=PQCYJIUIXh3Cj5zjctTrCfSvoDn4LaYS3oVlSV0xVDg,203
+skdecide/hub/domain/mastermind/mastermind.py,sha256=Zr4xa1P6dewnrsd_mI5w2um-4mpt7TaQqM3TmhpGJeQ,5080
+skdecide/hub/domain/simple_grid_world/__init__.py,sha256=cFHHbHcvwbn6U59d3zATnWOHshpm5FoI-kFmcyn-pNE,215
+skdecide/hub/domain/simple_grid_world/simple_grid_world.py,sha256=JozNC0Xjxdtqg_mYHoyZIe9La7Hfeu1JRb7-Q4VuZls,2892
+skdecide/hub/domain/rcpsp/__init__.py,sha256=-hLb5UlBhnrvhdeERHW4-adN784yLpKEX_d551pyZkE,333
+skdecide/hub/domain/rcpsp/rcpsp_sk.py,sha256=9UC6zO6dv91zofBQVM2cVxWu8G6DK3VXNyx41tULrgA,29705
+skdecide/hub/domain/rcpsp/rcpsp_sk_parser.py,sha256=9lcl7B32Lf_I2fdSZfGhsY8wiPurmkrGUIHwZciSeT0,3488
+skdecide/hub/domain/rock_paper_scissors/__init__.py,sha256=5dOttM10fPzIvFiWHJp02wItcHQA429IcpIiacdwrVA,219
+skdecide/hub/domain/rock_paper_scissors/rock_paper_scissors.py,sha256=R4YLajVGpZMPObtA8rv_cdJlVY2ujlfRhoXculUywQw,3238
+skdecide/hub/domain/up/__init__.py,sha256=NBHNkgpNxoMrYfznz1Df-d2q9ArhG9-T7S7U7uFzXJA,216
+skdecide/hub/domain/up/up.py,sha256=6UTvVrGuNlhfs5gaZQGfkCR9dpf8_ZCRbFUHhWMvq8Q,23101
+skdecide/builders/__init__.py,sha256=aGvlg4HXXM3-ZMna8aRs8JUG5wHqSunRRb3QBtLh4Wg,167
+skdecide/builders/solver/parallelability.py,sha256=wh3_rlyvA5FVy4D5LCurudn1OZC3tUxx9CvniNTeEYc,3591
+skdecide/builders/solver/__init__.py,sha256=ts1TGZTbrc3tXyVf35czvu4m74fezm6voI6XgvS5rGI,438
+skdecide/builders/solver/assessability.py,sha256=t6EGdIHgZeS2YtMaA0QTq0uFaywj7_Y0XZowLRz5RNI,3976
+skdecide/builders/solver/restorability.py,sha256=0ObJ0qzCn0mEVx3UGnKhJno0XV00YlU0FubXxgDcdBU,1457
+skdecide/builders/solver/fromanystatesolvability.py,sha256=LR3qPWX9mDheghti59rfgMqOag9jeS7ePXXGD2gaPjQ,4644
+skdecide/builders/solver/policy.py,sha256=-dK0BAYW91XOgODu_0riQxHu-LxqjuLBNTu6pZBDsxU,4824
+skdecide/builders/domain/constraints.py,sha256=PNYg-31Qwquk5UJl0E6z3GdufiogDhaBS217YGZ5go4,2265
+skdecide/builders/domain/renderability.py,sha256=ktlxgE-MJQX49Kl01N9xH2NHoBNiw3vuzjGVlcBWBJE,2576
+skdecide/builders/domain/__init__.py,sha256=x_c7mdA7luM5iMWTZCE0MkzwKjLKQtudOmjbPkZ0ZUU,705
+skdecide/builders/domain/events.py,sha256=W7sN_fg9hjaiIJOo9DVn6-IF1jeQYtQ2dT_w0Q1bkXY,13963
+skdecide/builders/domain/concurrency.py,sha256=tmXVZyifulpUrWY7it4_B-Jc-jOWkTXRnTvUd8pa5Rg,660
+skdecide/builders/domain/goals.py,sha256=8-Cbg6xjtVyDRP3sRuimWOD7drf41Z7GKWXP1tdRviA,4170
+skdecide/builders/domain/value.py,sha256=Y9319T3TWxP0XuNUXn-L7Vura5loUVEQauTUQsS93kU,2393
+skdecide/builders/domain/initialization.py,sha256=7GxtJXZw-HmMyTrxGKXP12VPDPj8MePh0HiVcWdBOQE,5948
+skdecide/builders/domain/memory.py,sha256=nOzOvpm1Fh0876iQLaPHxk2W9xcqHn_WK8O04pYWK20,3946
+skdecide/builders/domain/observability.py,sha256=FmvDO1hSBxyKxHnxq29Az5f-mT-AQAJVjzAFs6Ny0zc,7946
+skdecide/builders/domain/dynamics.py,sha256=MrQu9uVkXbSICc6LYaeiPINer2mzVUkSRYlJs8mp078,23481
+skdecide/builders/domain/agent.py,sha256=GA8QMD-_QGxQhOGKvjiW6egSrELSR_vHu-HyrSURIPc,1145
+skdecide/builders/domain/scheduling/resource_type.py,sha256=ELFwYTkyRZpXqaPrqAFzbc0J3pm_mqCN-aHHA-ORdLU,2783
+skdecide/builders/domain/scheduling/modes.py,sha256=P8OOxKojGQUBM6Hh0JOLKS091LPrkDJEGKtI6oWrAls,7874
+skdecide/builders/domain/scheduling/conditional_tasks.py,sha256=7Y2UDD2aa9CuZ-CYSo9vExQOhEG6WoZ8Hg0kH7UR4M0,8269
+skdecide/builders/domain/scheduling/__init__.py,sha256=aGvlg4HXXM3-ZMna8aRs8JUG5wHqSunRRb3QBtLh4Wg,167
+skdecide/builders/domain/scheduling/precedence.py,sha256=xjxp9OoBJDOVQcBhgxV42yZiIvqLC7phlaucjByCpGo,3946
+skdecide/builders/domain/scheduling/graph_toolbox.py,sha256=E_DgQbaE3O-O1DZdJDHVGjRvQqbaI62Gs1y0WQhLiNw,3873
+skdecide/builders/domain/scheduling/time_windows.py,sha256=tnt5i1tOFT2SpcjCYejuGbU50X9qaXYQjyV3b5D969k,5711
+skdecide/builders/domain/scheduling/resource_consumption.py,sha256=BR2dQBINE8cAc7qRDSL9d-wVKk-LU-nqH9K9y0oVKK4,1405
+skdecide/builders/domain/scheduling/resource_availability.py,sha256=fhKq1b1bSmitIP9mlIG7HROCGtbyfbSOrgtgc0_H3EA,4656
+skdecide/builders/domain/scheduling/resource_renewability.py,sha256=P3Il94XIiEa69Ztl17feNmJ9YaIVeiobkgzA8haRe68,3569
+skdecide/builders/domain/scheduling/skills.py,sha256=Ku5wmhPwK2D88-l6P_xBevnoF0tVRESEtq_NNV_9abo,5826
+skdecide/builders/domain/scheduling/preallocations.py,sha256=K6Bgjo5CZ1Mz3LFT6gVZbiOboIRVULgcwlAy9HrrdHg,1313
+skdecide/builders/domain/scheduling/scheduling_domains_modelling.py,sha256=QLMn5B-xjEQEYLti8jvWzVCZmwt5FdEBc390pQl6fLs,11316
+skdecide/builders/domain/scheduling/preemptivity.py,sha256=qaluWjSF4BWMdKPBWpaYm2MlJ2XMt8b_uYqdXy-P4bw,4461
+skdecide/builders/domain/scheduling/time_lag.py,sha256=rszVldG4aqaI4tMh4hli4iRVNkIBclYD_x8_OS-tpHE,3224
+skdecide/builders/domain/scheduling/task_duration.py,sha256=bvuz3J9IowhDu3EO2EuWcjhGanLSLtTO-LJCn74ce8Q,12910
+skdecide/builders/domain/scheduling/scheduling_domains.py,sha256=CzVF6ouZCef7wYKuPRtQmTKpyUKMiaS9WJCbXJ2Ydao,79426
+skdecide/builders/domain/scheduling/task.py,sha256=M6UBREb4yayu2RRnoeQpbrNBNfzcfV_-ocIHo6wJd4Y,1660
+skdecide/builders/domain/scheduling/resource_costs.py,sha256=f_-Fsh0i1Pg924i5Fel2lKN_2MGdgm-JnThYzjvPcJs,2831
+skdecide/builders/domain/scheduling/task_progress.py,sha256=SSBIF7c6RDkGIRUzXwofD92fcCIwtWaQSV4rJaki74M,2002
+scikit_decide.libs/libgomp-a34b3233.so.1.0.0,sha256=On6uznIxkRvi-7Gz58tMtcLg-E4MK7c3OUcrWh_uyME,168193
```

